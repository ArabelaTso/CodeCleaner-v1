{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.refactor import *\n",
    "from utils.preprocess import *\n",
    "from copy import copy\n",
    "import ast\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "refactorers = {\n",
    "    'IFF':   GroupRefactor(IfBranchFliper()),\n",
    "    'Loop':  GroupRefactor(While2For(), For2While()),\n",
    "    'Iter':  GroupRefactor(List2Range()),\n",
    "    'Comm':  GroupRefactor(CommLaw()),\n",
    "    'Deco':  GroupRefactor(FnDecorator('@timeing', '@measure_memory_usage')),\n",
    "    'Param': GroupRefactor(FnVarargAppender(), FnKwargAppender()),\n",
    "    'Renm':  GroupRefactor(VarRenamer()),\n",
    "    'Styl':  GroupRefactor(CamelSnakeExchange()),\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def encode_data(self, data, attributes):\n",
      "    current_row = 0\n",
      "    num_attributes = len(attributes)\n",
      "    for row in data:\n",
      "        new_data = []\n",
      "        if len(row) > 0 and max(row) >= num_attributes:\n",
      "            raise BadObject('Instance %d has %d attributes, expected %d' % (current_row, max(row) + 1, num_attributes))\n",
      "        for col in sorted(row):\n",
      "            v = row[col]\n",
      "            if v is None or v == '' or v != v:\n",
      "                s = '?'\n",
      "            else:\n",
      "                s = encode_string(str(v))\n",
      "            new_data.append('%d %s' % (col, s))\n",
      "        current_row += 1\n",
      "        yield ' '.join(['{', ','.join(new_data), '}'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "code = '''\\\n",
    "def encode_data(self, data, attributes):\n",
    "    current_row = 0\n",
    "    num_attributes = len(attributes)\n",
    "    for row in data:\n",
    "        new_data = []\n",
    "        if len(row) > 0 and max(row) >= num_attributes:\n",
    "            raise BadObject('Instance %d has %d attributes, expected %d' % (current_row, max(row) + 1, num_attributes))\n",
    "        for col in sorted(row):\n",
    "            v = row[col]\n",
    "            if v is None or v == '' or v != v:\n",
    "                s = '?'\n",
    "            else:\n",
    "                s = encode_string(str(v))\n",
    "            new_data.append('%d %s' % (col, s))\n",
    "        current_row += 1\n",
    "        yield ' '.join(['{', ','.join(new_data), '}'])\n",
    "'''\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " = = = = = = = = = = = = = = = = = = = = Opr: IFF\t Succ: True\n",
      "def encode_data(self, data, attributes):\n",
      "    current_row = 0\n",
      "    num_attributes = len(attributes)\n",
      "    for row in data:\n",
      "        new_data = []\n",
      "        if not (len(row) > 0 and max(row) >= num_attributes):\n",
      "            pass\n",
      "        else:\n",
      "            raise BadObject('Instance %d has %d attributes, expected %d' % (current_row, max(row) + 1, num_attributes))\n",
      "        for col in sorted(row):\n",
      "            v = row[col]\n",
      "            if v is None or v == '' or v != v:\n",
      "                s = '?'\n",
      "            else:\n",
      "                s = encode_string(str(v))\n",
      "            new_data.append('%d %s' % (col, s))\n",
      "        current_row += 1\n",
      "        yield ' '.join(['{', ','.join(new_data), '}'])\n",
      "\n",
      " = = = = = = = = = = = = = = = = = = = = Opr: Loop\t Succ: True\n",
      "def encode_data(self, data, attributes):\n",
      "    current_row = 0\n",
      "    num_attributes = len(attributes)\n",
      "    _iter0 = data\n",
      "    while True:\n",
      "        try:\n",
      "            row = next(_iter0)\n",
      "        except StopIteration:\n",
      "            break\n",
      "        new_data = []\n",
      "        if len(row) > 0 and max(row) >= num_attributes:\n",
      "            raise BadObject('Instance %d has %d attributes, expected %d' % (current_row, max(row) + 1, num_attributes))\n",
      "        for col in sorted(row):\n",
      "            v = row[col]\n",
      "            if v is None or v == '' or v != v:\n",
      "                s = '?'\n",
      "            else:\n",
      "                s = encode_string(str(v))\n",
      "            new_data.append('%d %s' % (col, s))\n",
      "        current_row += 1\n",
      "        yield ' '.join(['{', ','.join(new_data), '}'])\n",
      "\n",
      " = = = = = = = = = = = = = = = = = = = = Opr: Iter\t Succ: True\n",
      "def encode_data(self, data, attributes):\n",
      "    current_row = 0\n",
      "    num_attributes = len(attributes)\n",
      "    for row in range(len(data)):\n",
      "        new_data = []\n",
      "        if len(data[row]) > 0 and max(data[row]) >= num_attributes:\n",
      "            raise BadObject('Instance %d has %d attributes, expected %d' % (current_row, max(data[row]) + 1, num_attributes))\n",
      "        for col in sorted(data[row]):\n",
      "            v = data[row][col]\n",
      "            if v is None or v == '' or v != v:\n",
      "                s = '?'\n",
      "            else:\n",
      "                s = encode_string(str(v))\n",
      "            new_data.append('%d %s' % (col, s))\n",
      "        current_row += 1\n",
      "        yield ' '.join(['{', ','.join(new_data), '}'])\n",
      "\n",
      " = = = = = = = = = = = = = = = = = = = = Opr: Comm\t Succ: True\n",
      "def encode_data(self, data, attributes):\n",
      "    current_row = 0\n",
      "    num_attributes = len(attributes)\n",
      "    for row in data:\n",
      "        new_data = []\n",
      "        if max(row) >= num_attributes and len(row) > 0:\n",
      "            raise BadObject('Instance %d has %d attributes, expected %d' % (current_row, max(row) + 1, num_attributes))\n",
      "        for col in sorted(row):\n",
      "            v = row[col]\n",
      "            if v is None or v == '' or v != v:\n",
      "                s = '?'\n",
      "            else:\n",
      "                s = encode_string(str(v))\n",
      "            new_data.append('%d %s' % (col, s))\n",
      "        current_row += 1\n",
      "        yield ' '.join(['{', ','.join(new_data), '}'])\n",
      "\n",
      " = = = = = = = = = = = = = = = = = = = = Opr: Deco\t Succ: True\n",
      "@timeing\n",
      "@measure_memory_usage\n",
      "def encode_data(self, data, attributes):\n",
      "    current_row = 0\n",
      "    num_attributes = len(attributes)\n",
      "    for row in data:\n",
      "        new_data = []\n",
      "        if len(row) > 0 and max(row) >= num_attributes:\n",
      "            raise BadObject('Instance %d has %d attributes, expected %d' % (current_row, max(row) + 1, num_attributes))\n",
      "        for col in sorted(row):\n",
      "            v = row[col]\n",
      "            if v is None or v == '' or v != v:\n",
      "                s = '?'\n",
      "            else:\n",
      "                s = encode_string(str(v))\n",
      "            new_data.append('%d %s' % (col, s))\n",
      "        current_row += 1\n",
      "        yield ' '.join(['{', ','.join(new_data), '}'])\n",
      "\n",
      " = = = = = = = = = = = = = = = = = = = = Opr: Param\t Succ: True\n",
      "def encode_data(self, data, attributes, *args):\n",
      "    current_row = 0\n",
      "    num_attributes = len(attributes)\n",
      "    for row in data:\n",
      "        new_data = []\n",
      "        if len(row) > 0 and max(row) >= num_attributes:\n",
      "            raise BadObject('Instance %d has %d attributes, expected %d' % (current_row, max(row) + 1, num_attributes))\n",
      "        for col in sorted(row):\n",
      "            v = row[col]\n",
      "            if v is None or v == '' or v != v:\n",
      "                s = '?'\n",
      "            else:\n",
      "                s = encode_string(str(v))\n",
      "            new_data.append('%d %s' % (col, s))\n",
      "        current_row += 1\n",
      "        yield ' '.join(['{', ','.join(new_data), '}'])\n",
      "\n",
      "fetched synonyms for col: ['abyss', 'abyss', 'canyon', 'canyon', 'cañon', 'cañon', 'couloir', 'couloir', 'defile', 'defile', 'flume', 'flume', 'gap', 'gap', 'gap', 'gill', 'gill', 'glen', 'glen', 'gorge', 'gorge', 'gulch', 'gulch', 'kloof', 'kloof', 'linn', 'linn', 'mountain pass', 'notch', 'pass', 'pass', 'ravine', 'ravine', 'saddle', 'saddle', 'valley', 'valley', 'wind gap']\n",
      "renaming col => abyss\n",
      " = = = = = = = = = = = = = = = = = = = = Opr: Renm\t Succ: True\n",
      "def encode_data(self, data, attributes):\n",
      "    current_row = 0\n",
      "    num_attributes = len(attributes)\n",
      "    for row in data:\n",
      "        new_data = []\n",
      "        if len(row) > 0 and max(row) >= num_attributes:\n",
      "            raise BadObject('Instance %d has %d attributes, expected %d' % (current_row, max(row) + 1, num_attributes))\n",
      "        for abyss in sorted(row):\n",
      "            v = row[abyss]\n",
      "            if v is None or v == '' or v != v:\n",
      "                s = '?'\n",
      "            else:\n",
      "                s = encode_string(str(v))\n",
      "            new_data.append('%d %s' % (abyss, s))\n",
      "        current_row += 1\n",
      "        yield ' '.join(['{', ','.join(new_data), '}'])\n",
      "\n",
      "renaming num_attributes => numAttributes\n",
      " = = = = = = = = = = = = = = = = = = = = Opr: Styl\t Succ: True\n",
      "def encode_data(self, data, attributes):\n",
      "    current_row = 0\n",
      "    numAttributes = len(attributes)\n",
      "    for row in data:\n",
      "        new_data = []\n",
      "        if len(row) > 0 and max(row) >= numAttributes:\n",
      "            raise BadObject('Instance %d has %d attributes, expected %d' % (current_row, max(row) + 1, numAttributes))\n",
      "        for col in sorted(row):\n",
      "            v = row[col]\n",
      "            if v is None or v == '' or v != v:\n",
      "                s = '?'\n",
      "            else:\n",
      "                s = encode_string(str(v))\n",
      "            new_data.append('%d %s' % (col, s))\n",
      "        current_row += 1\n",
      "        yield ' '.join(['{', ','.join(new_data), '}'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for refactor_name, refactorer in refactorers.items():\n",
    "    root = ast.parse(code)\n",
    "    root, count = refactorer.refactor(root, rand=True, max_count=1)\n",
    "    refactored_code = ast.unparse(root)\n",
    "    refactor_succ = count > 0\n",
    "    \n",
    "    print(\" =\" * 20, f\"Opr: {refactor_name}\\t Succ: {refactor_succ}\")\n",
    "    print(refactored_code)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduction Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refactor the-stack-dedup-python-preprocessed-2021-sample384\n",
    "\n",
    "import json\n",
    "with open(f\"data/the-stack-dedup-python-preprocessed-2021-sample384.jsonl\", 'r') as f:\n",
    "    data = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "for refector_name, refectorer in refectorers.items():\n",
    "    refectored_data = []\n",
    "    print(refector_name)\n",
    "    for d in tqdm(data):\n",
    "        dd = copy(d)\n",
    "        dd['original_content'] = dd['content']\n",
    "        root = ast.parse(dd['content'])\n",
    "        root, count = refectorer.refactor(root, rand=True, max_count=1)\n",
    "        dd['content'] = ast.unparse(root)\n",
    "        assert ast.parse(dd['content'])\n",
    "        dd['refactored'] = count > 0\n",
    "        refectored_data.append(dd)\n",
    "\n",
    "    with open(f'data/the-stack-dedup-python-preprocessed-2021-sample384-refactor-{refector_name}.jsonl', 'w') as f:\n",
    "        for d in refectored_data:\n",
    "            f.write(json.dumps(d))\n",
    "            f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:birdcorrect]",
   "language": "python",
   "name": "conda-env-birdcorrect-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
