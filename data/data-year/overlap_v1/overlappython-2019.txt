--- 0 --
Question ID: 6aa3d8a2d51ddee0c116a30642335f490fa0e9c1_52
Original Code:
```
def get_perl_exports(tmpdir=None):
    """Environmental exports to use conda installed perl.
    """
    perl_path = os.path.dirname(perl_cmd())
    out = "unset PERL5LIB && export PATH=%s:\"$PATH\"" % (perl_path)
    if tmpdir:
        out += " && export TMPDIR=%s" % (tmpdir)
    return out
```


Overlapping Code:
```
e):
"""Environmental exports to use conda installed perl.
"""
perl_path = os.path.dirname(perl_cmd())
out = "unset PERL5LIB && export PATH=%s:\"$PATH\"" % (perl_path)
if tmpdir:
out += " && export TMP
```
<Overlap Ratio: 0.7692307692307693>

---

--- 1 --
Question ID: 2c12bcc26b0502ec1ee956edcf1918d5fca9de40_2
Original Code:
```
def test_substitution_layer_width():
    masters, instances = load_to_ufos(glyphs_file_path(), include_instances=True)
    assert masters[0]["B"].width == 500
    assert masters[1]["B"].width == 600
    assert masters[0]["B.BRACKET.40"].width == 510
    assert masters[1]["B.BRACKET.40"].width == 610
```


Overlapping Code:
```
):
masters, instances = load_to_ufos(glyphs_file_path(), include_instances=True)
assert masters[0]["B"].width == 500
assert masters[1]["B"].width == 600
assert masters[0]["B.BRACKET.40"].width == 510

```
<Overlap Ratio: 0.7142857142857143>

---

--- 2 --
Question ID: b939c92a48869b8074e19ed7baecfbab1de0f936_2
Original Code:
```
def public_enc_rsa(public_key: str, data: str) -> str:
    """
     RSA 암호화

    :param public_key: CODEF 회원에게 제공되는 PublicKey
    :param data: 암호화할 데이터
    :return: RSA256 암호화된 데이터
    """
    key_der = base64.b64decode(public_key)
    key_pub = RSA.import_key(key_der)
    cipher = PKCS1.new(key_pub)
    cipher_text = cipher.encrypt(data.encode())

    encrypted_data = base64.b64encode(cipher_text).decode('utf-8')

    return encrypted_data
```


Overlapping Code:
```
ey: str, data: str) -> str:
"""
RSA 암호화
:param public_key: CODEF 회원에게 제공되는 PublicKey
:param data: 암호화할 데이터
:return: RSA256 암호화된 데이터
"""
key_der = base64.b64decode(public_key)
key_pub = RSA.import_key(key_der)
cipher = PKCS1.new(key_pub)
cipher_text = cipher.encrypt(data.encode())
encrypted_data = base64.b64encode(cipher_text).decode('utf-8')
return
```
<Overlap Ratio: 0.8928571428571429>

---

--- 3 --
Question ID: 9169fa35c114b645c37ad3dc3dd8e4f2affdbec5_4
Original Code:
```
def dark_correction(msi, dark):
    """" subtract dark current from multi spectral image.

    The dark msi should either be of the same shape
    as msi or 1xnr_wavelengths (see tests)."""
    msi.set_image(msi.get_image() - dark.get_image())
    return msi
```


Overlapping Code:
```
, dark):
"""" subtract dark current from multi spectral image.
The dark msi should either be of the same shape
as msi or 1xnr_wavelengths (see tests)."""
msi.set_image(msi.get_image() - dark.get_image
```
<Overlap Ratio: 0.8438818565400844>

---

--- 4 --
Question ID: 7ccc725acf9b7e6719083bd5d3c9a3289225526d_0
Original Code:
```
def run(parsed_args):
    sonos = common.get_sonos(parsed_args)
    sonos.next()
    change_track_common.send_notification(sonos)
```


Overlapping Code:
```
n(parsed_args):
sonos = common.get_sonos(parsed_args)
sonos.next()
change_track_common.send
```
<Overlap Ratio: 0.7777777777777778>

---

--- 5 --
Question ID: 698f02953478fff7d6e072a1e7d9ed8fc0f5214f_2
Original Code:
```
@extra_info
def test(data: pandas.DataFrame):
    some_var = 1
    return some_var
```


Overlapping Code:
```
f test(data: pandas.DataFrame):
some_var = 1
retur
```
<Overlap Ratio: 0.6756756756756757>

---

--- 6 --
Question ID: 1ace6e50fe9a696ec49d4b81bdfd2e95eea3942f_8
Original Code:
```
def spew(t):
    """Prints a string based on DEBUG_OUTPUT bool

    Parameters
    ----------
    t : str
        * string to debug print
    """
    if DEBUG_OUTPUT:
        print("DEBUG::{}".format(t))
```


Overlapping Code:
```
DEBUG_OUTPUT bool
Parameters
----------
t : str
* string to debug print
"""
if DEBUG_OUTPUT:
print("
```
<Overlap Ratio: 0.6172839506172839>

---

--- 7 --
Question ID: 38aa0f11b040c6e2b0f15e6b26ecdcb95217d8c4_0
Original Code:
```
def bootstrap(config):
	#
	# BACnet デーモンの管理用変数
	#
	config.registry.bacnetd = None

	#
	# Scan controller
	#
	config.add_route('api::bacnetd:status', '/status')
	config.add_route('api::bacnetd:start', '/start')
	config.scan('.controller')
```


Overlapping Code:
```
 デーモンの管理用変数
#
config.registry.bacnetd = None
#
# Scan controller
#
config.add_route('api::bacnetd:status', '/status')
config.add_route('api::bacnetd:s
```
<Overlap Ratio: 0.6637168141592921>

---

--- 8 --
Question ID: b21e2a9cf0676b4d382d841a6736d7dc02963669_5
Original Code:
```
@pytest.fixture
def w3(base_tester):
    web3 = Web3(EthereumTesterProvider(base_tester))
    web3.eth.setGasPriceStrategy(zero_gas_price_strategy)
    return web3
```


Overlapping Code:
```
eb3.eth.setGasPriceStrategy(zero_gas_price_strateg
```
<Overlap Ratio: 0.33112582781456956>

---

--- 9 --
Question ID: 4199cc03aaf7f34f0b78c80dab33d55347950cc7_0
Original Code:
```
def clearDisplay():
    """
        Connector function to clear OLED Display
        :param img:
        :return: None
    """
    disp.clear()
```


Overlapping Code:
```
o clear OLED Display
:param img:
:return: None
"""
```
<Overlap Ratio: 0.4672897196261682>

---

--- 10 --
Question ID: 8be0012372e23d7bba2f7554a9919a24bc4ffd81_2
Original Code:
```
def _swig_getattr(self, class_type, name):
    if (name == "thisown"):
        return self.this.own()
    method = class_type.__swig_getmethods__.get(name, None)
    if method:
        return method(self)
    raise AttributeError("'%s' object has no attribute '%s'" % (class_type.__name__, name))
```


Overlapping Code:
```
def _swig_getattr(self, class_type, name):
if (name == "thisown"):
return self.this.own()
method = class_type.__swig_getmethods__.get(name, None)
if method:
return method(self)
raise AttributeError("'%s' object has no attribute '%s'" % (class_type.__name__, name))
```
<Overlap Ratio: 1.0>

---

--- 11 --
Question ID: cca0ae0b0e53349589c0da2ebf78e2b30c8c3489_3
Original Code:
```
def calculate_all_sentiment_features(entry):
    post_title_sentiment = calculate_sentiment_features([entry["postText"][0]])
    article_title_sentiment = calculate_sentiment_features([entry["targetTitle"]])
    article_desc_sentiment = calculate_sentiment_features([entry["targetDescription"]])
    article_keywords_sentiment = calculate_sentiment_features([entry["targetKeywords"]])
    article_paragraphs_sentiment = calculate_sentiment_features(entry["targetParagraphs"])
    lst = [post_title_sentiment, article_title_sentiment, article_desc_sentiment, article_keywords_sentiment,
            article_paragraphs_sentiment]
    return list(sum(lst, ()))
```


Overlapping Code:
```
iment_features(entry):
post_title_sentiment = calculate_sentiment_features([entry["postText"][0]])
article_title_sentiment = calculate_sentiment_features([entry["targetTitle"]])
article_desc_sentiment = calculate_sentiment_features([entry["targetDescription"]])
article_keywords_sentiment = calculate_sentiment_features([entry["targetKeywords"]])
article_paragraphs_sentiment = calculate_sentiment_features(entry["targetParagraphs"])
lst = [post_title_sentiment, article_title_sentiment, article_desc_sentiment, article_keywords_sentiment,
article_pa
```
<Overlap Ratio: 0.8914100486223663>

---

--- 12 --
Question ID: a258a8955ed91c65e8a9d1eb87848c8b38bd9c1c_2
Original Code:
```
def run_trials(p, args):
    """
    Run trials.

    """
    # Model
    m = p['model']

    # ntrials: Number of trials for each condition
    try:
        ntrials = int(args[0])
    except:
        ntrials = 100

    ntrials *= m.nconditions

    # RNN
    rng = np.random.RandomState(p['seed'])
    rnn = RNN(p['savefile'], {'dt': p['dt']}, verbose=False)

    # Trials
    w = len(str(ntrials))
    trials = []
    backspaces = 0
    try:
        for i in xrange(ntrials):
            b = i % m.nconditions
            # All conditions
            intensity = m.intensity_range[b]

            # Trial
            trial_func = m.generate_trial
            trial_args = {
                'name': 'test',
                'catch': False,
                'intensity': intensity,
            }
            info = rnn.run(inputs=(trial_func, trial_args), rng=rng)

            # Display trial type
            s = ("Trial {:>{}}/{}: intentsity: {:>+3}"
                 .format(i + 1 , w, ntrials, info['intensity']))
            sys.stdout.write(backspaces * '\b' + s)
            sys.stdout.flush()
            backspaces = len(s)

            # Save
            dt = rnn.t[1] - rnn.t[0]
            step = int(p['dt_save'] / dt)
            trial = {
                't': rnn.t[::step],
                'u': rnn.u[:, ::step],
                'r': rnn.r[:, ::step],
                'z': rnn.z[:, ::step],
                'info': info
            }
            trials.append(trial)
    except KeyboardInterrupt:
        pass
    print("")

    # Save all
    filename = get_trialsfile(p)
    with open(filename, 'wb') as f:
        pickle.dump(trials, f, pickle.HIGHEST_PROTOCOL)
    size = os.path.getsize(filename) * 1e-9
    print("[ {}.run_trials ] Trials saved to {} ({:.1f} GB)".format(THIS, filename, size))
```


Overlapping Code:
```
run_trials(p, args):
"""
Run trials.
"""
# Model
m = p['model']
# ntrials: Number of trials for each condition
try:
ntrials = int(args[0])
except:
ntrials = 100
ntrials *= m.nconditions
# RNN
rng = np.random.RandomState(p['seed'])
rnn = RNN(p['savefile'], {'dt': p['dt']}, verbose=False)
# Trials
w = len(str(ntrials))
trials = []
backspaces = 0
try:
for i in xrange(ntrials):
b = i % m.nconditions
# All conditions
intensity = m.intensity_range[b]
# Trial
trial_func = m.generate_trial
trial_args = {
'name': 'test',
'catch': False,
'intensity': intensity,
}
info = rnn.run(inputs=(trial_func, trial_args), rng=rng)
# Display trial type
s = ("Trial {:>{}}/{}: intentsity: {:>+3}"
.format(i + 1 , w, ntrials, info['intensity']))
sys.stdout.write(backspaces * '\b' + s)
sys.stdout.flush()
backspaces = len(s)
# Save
dt = rnn.t[1] - rnn.t[0]
step = int(p['dt_save'] / dt)
trial = {
't': rnn.t[::step],
'u': rnn.u[:, ::step],
'r': rnn.r[:, ::step],
'z': rnn.z[:, ::step],
'info': info
}
trials.append(trial)
except KeyboardInterrupt:
pass
print("")
# Save all
filename = get_trialsfile(p)
with open(filename, 'wb') as f:
pickle.dump(trials, f, pickle.HIGHEST_PROTOCOL)
size = os.path.getsize(filename) * 1e-9
print("[ {}.run_trials ] Trials saved to {} ({:.1f} GB)".format(THIS, filename, size
```
<Overlap Ratio: 0.9953703703703703>

---

--- 13 --
Question ID: 37249a4b4f2e000a76c6fe26af8aab48e98cee37_1
Original Code:
```
def plot_rain_case_poster(cases_r, save=SAVE_DEFAULT):
    c = copy.deepcopy(cases_r.loc['140812T02'].case)
    c.data = c.data.loc[:,:, '2014-08-12 03:40':].copy()
    fig_kws = dict(fig_w_factor=0.6)
    fig, axarr = c.plot(params=['kdp', 'zh', 'zdr'],
                        n_extra_ax=0, plot_extras=['cl'],
                        t_contour_ax_ind='all',
                        t_levels=[-40, -20, -10, -8, -3],
                        fig_scale_factor=0.85, fig_kws=fig_kws)
    formatter = plotting.concise_formatter()
    axarr[-1].xaxis.set_major_formatter(formatter)
    if save:
        fig.savefig(path.join(conf.POSTER_FIG_DIR, 'case_rain.png'), **SAVE_KWS)
    return fig, axarr
```


Overlapping Code:
```
e_poster(cases_r, save=SAVE_DEFAULT):
c = copy.deepcopy(cases_r.loc['140812T02'].case)
c.data = c.data.loc[:,:, '2014-08-12 03:40':].copy()
fig_kws = dict(fig_w_factor=0.6)
fig, axarr = c.plot(params=['kdp', 'zh', 'zdr'],
n_extra_ax=0, plot_extras=['cl'],
t_contour_ax_ind='all',
t_levels=[-40, -20, -10, -8, -3],
fig_scale_factor=0.85, fig_kws=fig_kws)
formatter = plotting.concise_formatter()
axarr[-1].xaxis.set_major_formatter(formatter)
if save:
fig.savefig(path.join(conf.POSTER_FIG_DIR, 'case_rain.png'), **SAVE_KWS)
return fig, 
```
<Overlap Ratio: 0.9605734767025089>

---

--- 14 --
Question ID: 5a213431867a3dd8f2c35ba55578f95b1f4daf8b_6
Original Code:
```
def main():
    parser = argparse.ArgumentParser(prog=os.path.basename(sys.argv[0]),description="Lumi DB schema operations.")
    # add the arguments
    parser.add_argument('-c',dest='connect',action='store',required=True,help='connect string to lumiDB')
    parser.add_argument('-P',dest='authpath',action='store',help='path to authentication file')
    parser.add_argument('action',choices=['create','drop','describe','addindex','dropindex'],help='action on the schema')
    parser.add_argument('--validationTab',dest='validationTab',action='store_true',help='validation table only')
    parser.add_argument('--verbose',dest='verbose',action='store_true',help='verbose')
    parser.add_argument('--debug',dest='debug',action='store_true',help='debug mode')
    # parse arguments
    args=parser.parse_args()
    connectstring=args.connect
    if args.debug:
        msg=coral.MessageStream('')
        msg.setMsgVerbosity(coral.message_Level_Debug)
    svc = coral.ConnectionService()
    if args.authpath and len(args.authpath)!=0:
        os.environ['CORAL_AUTH_PATH']=args.authpath
    session=svc.connect(connectstring,accessMode=coral.access_Update)
    if args.action == 'create':
       if args.validationTab:
           createValidation(session)
       else:
           createLumi(session)
    if args.action == 'drop':
       dropLumi(session)
    if args.action == 'describe':
       describeLumi(session)
    if args.action == 'addindex':
       createIndex(session)
    if args.action == 'dropindex':
       dropIndex(session)
    if args.verbose :
        print('verbose mode')
```


Overlapping Code:
```
def main():
parser = argparse.ArgumentParser(prog=os.path.basename(sys.argv[0]),description="Lumi DB schema operations.")
# add the arguments
parser.add_argument('-c',dest='connect',action='store',required=True,help='connect string to lumiDB')
parser.add_argument('-P',dest='authpath',action='store',help='path to authentication file')
parser.add_argument('action',choices=['create','drop','describe','addindex','dropindex'],help='action on the schema')
parser.add_argument('--validationTab',dest='validationTab',action='store_true',help='validation table only')
parser.add_argument('--verbose',dest='verbose',action='store_true',help='verbose')
parser.add_argument('--debug',dest='debug',action='store_true',help='debug mode')
# parse arguments
args=parser.parse_args()
connectstring=args.connect
if args.debug:
msg=coral.MessageStream('')
msg.setMsgVerbosity(coral.message_Level_Debug)
svc = coral.ConnectionService()
if args.authpath and len(args.authpath)!=0:
os.environ['CORAL_AUTH_PATH']=args.authpath
session=svc.connect(connectstring,accessMode=coral.access_Update)
if args.action == 'create':
if args.validationTab:
createValidation(session)
else:
createLumi(session)
if args.action == 'drop':
dropLumi(session)
if args.action == 'describe':
describeLumi(session)
if args.action == 'addindex':
createIndex(session)
if args.action == 'dropindex':
dropIndex(session)
if
```
<Overlap Ratio: 0.9738145789101204>

---

--- 15 --
Question ID: 2bad962a0dc8bb788093ce90927202a39b225396_6
Original Code:
```
def _validate_registers(registers: t.Sequence[Register]) -> None:
    # Check that no registers overlap
    register_intervals = IntervalTree.from_tuples(
        [(register.byte_range[0], register.byte_range[1], register) for register in registers]
    )
    overlaps = find_overlapping_intervals(register_intervals)
    if overlaps:
        description = "\n".join(f"- {overlap.data.name}" for overlap in overlaps)
        raise ValueError(f"Overlapping registers:\n{description}")
```


Overlapping Code:
```
ef _validate_registers(registers: t.Sequence[Register]) -> None:
# Check that no registers overlap
register_intervals = IntervalTree.from_tuples(
[(register.byte_range[0], register.byte_range[1], register) for register in registers]
)
overlaps = find_overlapping_intervals(register_intervals)
if overlaps:
description = "\n".join(f"- {overlap.data.name}" for overlap in overlaps)
raise ValueError(f"O
```
<Overlap Ratio: 0.9111617312072893>

---

--- 16 --
Question ID: 61673a3563c904c8f16b45554119722ec7269453_0
Original Code:
```
def rule2struct(rule):
    """
    Returns the structure of a rule used to partition a knowledge base
    :param rule: a rule
    :return: a tuple representing the structure of the rule
    """
    predicates = {}
    constants = {}
    variables = {}
    struct = []
    for predicate, args in rule:
        atom_struct = []
        if predicate not in predicates:
            predicates[predicate] = "p" + str(len(predicates))
        atom_struct.append(predicates[predicate])
        for arg in args:
            if is_variable(arg):
                if arg not in variables:
                    variables[arg] = "X" + str(len(variables))
                atom_struct.append(variables[arg])
            else:
                if arg not in constants:
                    constants[arg] = "c" # + str(len(constants))
                atom_struct.append(constants[arg])
        struct.append(tuple(atom_struct))
    return tuple(struct)
```


Overlapping Code:
```
ucture of a rule used to partition a knowledge base
:param rule: a rule
:return: a tuple representing the structure of the rule
"""
predicates = {}
constants = {}
variables = {}
struct = []
for predicate, args in rule:
atom_struct = []
if predicate not in predicates:
predicates[predicate] = "p" + str(len(predicates))
atom_struct.append(predicates[predicate])
for arg in args:
if is_variable(arg):
if arg not in variables:
variables[arg] = "X" + str(len(variables))
atom_struct.append(variables[arg])
else:
if arg not in constants:
constants[arg] = "c" # + str(len(constants))
atom_struct.append(constants[arg])
struct.append(tuple(atom_struct))
ret
```
<Overlap Ratio: 0.9167842031029619>

---

--- 17 --
Question ID: 3ccf6fc84327865b8aa888d62745e83f24193085_3
Original Code:
```
def write_example_config(example_file_path: str):
    """
    Writes an example config file using the config values declared so far

    :param example_file_path: path to write to
    """
    document = tomlkit.document()
    for header_line in _get_header():
        document.add(tomlkit.comment(header_line))
    config_keys = _aggregate_config_values(ConfigValue.config_values)
    _add_config_values_to_toml_object(document, config_keys)
    _doc_as_str = document.as_string().replace(f'"{_NOT_SET}"', '')
    with open(example_file_path, 'w') as stream:
        stream.write(_doc_as_str)
```


Overlapping Code:
```
le_file_path: str):
"""
Writes an example config file using the config values declared so far
:param example_file_path: path to write to
"""
document = tomlkit.document()
for header_line in _get_header():
document.add(tomlkit.comment(header_line))
config_keys = _aggregate_config_values(ConfigValue.config_values)
_add_config_values_to_toml_object(document, config_keys)
_doc_as_str = document.as_string().replace(f'"{_NOT_SET}"', '')
with open(example_file_path, 'w') as stream:
stream.write(_doc_as
```
<Overlap Ratio: 0.9345794392523364>

---

--- 18 --
Question ID: 71cf6c963cea2a625de05fc4fdf2a497bd64100f_2
Original Code:
```
@pytest.fixture
def prep_org_w_identifier():
    o = Organization(name='test org')
    i = Identifier(system=US_NPI, value='123-45')
    o.identifiers.append(i)
    with SessionScope(db):
        db.session.add(o)
        db.session.commit()
    o = db.session.merge(o)
    OrgTree().invalidate_cache()
    yield o

    OrgTree().invalidate_cache()
```


Overlapping Code:
```
@pytest.fixture
def prep_org_w_identifier():
o = Organization(name='test org')
i = Identifier(system=US_NPI, value='123-45')
o.identifiers.append(i)
with SessionScope(db):
db.session.add(o)
db.session.commit()
o = db.session.merge(o)
OrgTree().invali
```
<Overlap Ratio: 0.8361204013377926>

---

--- 19 --
Question ID: 5272ecc406dad5983dea69832350714c88f9489d_0
Original Code:
```
def send_data(ip, port, data):
	try:
		s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
		s.connect((ip, port))
		s.send(data)
		s.close()
	except socket.error:
		raise Exception("[*] Error: No se pudo conectar al socket deseado")
```


Overlapping Code:
```
ata):
try:
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
s.connect((ip, port))
s.send(data)
s.close()
except socket.error:
raise Exception("[*] Error: No 
```
<Overlap Ratio: 0.726457399103139>

---

--- 20 --
Question ID: abbf7c07f692163b76a1278b954739edd1aeedd2_1
Original Code:
```
def get_curve_set(curves):
    if isinstance(curves, str):
        curves = curve_sets[curves]
    return [get_curve(curve) for curve in curves]
```


Overlapping Code:
```
def get_curve_set(curves):
if isinstance(curves, str):
curves = curve_sets[curves]
return [get_curve
```
<Overlap Ratio: 0.78125>

---

--- 21 --
Question ID: c1e959297079c8b361ed050bf40e71e5c0711833_1
Original Code:
```
def test_stack_enque():
  test_stack.push(1)
  assert not test_stack.is_empty()
  assert test_stack.peek() == 1
  test_stack.push(2)
  test_stack.push(3)
  test_stack.push(4)
  assert test_stack.peek() == 4
```


Overlapping Code:
```

test_stack.push(1)
assert not test_stack.is_empty()
assert test_stack.peek() == 1
test_stack.push(2)
test_stack.push(3)
test_stack.push(4)
assert tes
```
<Overlap Ratio: 0.78125>

---

--- 22 --
Question ID: 8815d4975da480fc89fc030b18d7376c5bed88c1_0
Original Code:
```
def _next_and_end(cls: "StateMirror") -> "StateMirror":
    """Add "Next" and "End" parameters to the class.
    Also adds the "then()" and "end()" helper methods.
    """

    def _validate_next(instance, attribute: attr.Attribute, value: Any):
        if value is not None and instance.End is not None:
            raise ValueError("Only one of 'Next' and 'End' is allowed")

    cls.Next = RHODES_ATTRIB(validator=(optional(instance_of(str)), _validate_next))
    cls.__doc__ = docstring_with_param(cls, "Next", description="The state that will follow this state")

    def _validate_end(instance, attribute: attr.Attribute, value: Any):
        if value is not None and instance.Next is not None:
            raise ValueError("Only one of 'Next' and 'End' is allowed")

        if value is not None and value is not True:
            raise ValueError("If 'End' is set, value must be True")

    cls.End = RHODES_ATTRIB(validator=(optional(instance_of(bool)), _validate_end))
    cls.__doc__ = docstring_with_param(cls, "End", bool, description="This state is a terminal state")

    def _then(instance, next_state):
        """Set the next state in this state machine."""

        if instance.End is not None:
            raise InvalidDefinitionError(
                f"Cannot set state transition. State {instance.title!r} already has an end condition."
            )

        if instance.Next is not None:
            raise InvalidDefinitionError(
                f"Cannot set state transition. State {instance.title!r} already has a state transition."
            )

        instance.member_of.add_state(next_state)
        # TODO: set reference rather than extracting name
        instance.Next = next_state.title
        return next_state

    cls.then = _then

    def _end(instance):
        """Make this state a terminal state."""

        if instance.Next is not None:
            raise InvalidDefinitionError(
                "Cannot set end condition." f"State {instance.title!r} already has a state transition."
            )

        instance.End = True

        return instance

    cls.end = _end

    return cls
```


Overlapping Code:
```
eMirror":
"""Add "Next" and "End" parameters to the class.
Also adds the "then()" and "end()" helper methods.
"""
def _validate_next(instance, attribute: attr.Attribute, value: Any):
if value is not None and instance.End is not None:
raise ValueError("Only one of 'Next' and 'End' is allowed")
cls.Next = RHODES_ATTRIB(validator=(optional(instance_of(str)), _validate_next))
cls.__doc__ = docstring_with_param(cls, "Next", description="The state that will follow this state")
def _validate_end(instance, attribute: attr.Attribute, value: Any):
if value is not None and instance.Next is not None:
raise ValueError("Only one of 'Next' and 'End' is allowed")
if value is not None and value is not True:
raise ValueError("If 'End' is set, value must be True")
cls.End = RHODES_ATTRIB(validator=(optional(instance_of(bool)), _validate_end))
cls.__doc__ = docstring_with_param(cls, "End", bool, description="This state is a terminal state")
def _then(instance, next_state):
"""Set the next state in this state machine."""
if instance.End is not None:
raise InvalidDefinitionError(
f"Cannot set state transition. State {instance.title!r} already has an end condition."
)
if instance.Next is not None:
raise InvalidDefinitionError(
f"Cannot set state transition. State {instance.title!r} already has a state transition."
)
instance.member_of.add_state(next_state)
# TODO: set reference rather than extracting name
instance.Next = next_state.title
return next_state
cls.then = _then
def _end(instance):
"""Make this state a terminal state."""
if instance.Next is not None:
raise InvalidDefinitionError(
"Cannot set end condition." f"State {instance.title!r} already has a state transition."
)
instance.End = T
```
<Overlap Ratio: 0.9491903964265773>

---

--- 23 --
Question ID: 57f38f69d31e27bf6baf07a4993e242ed3f28f7a_4
Original Code:
```
def get_summary_path(folder, fname, kind = 'train'):
    import os
    from time import gmtime, strftime
    
    o_fold = os.path.join(folder, kind)
    time_str = strftime("%d_%b_%Y_%H_%M", gmtime())
    summ_path = os.path.join(o_fold,'{}_{}'.format(fname, time_str))
    if not os.path.exists(summ_path):
        os.makedirs(summ_path)
    return summ_path
```


Overlapping Code:
```
ry_path(folder, fname, kind = 'train'):
import os
from time import gmtime, strftime

o_fold = os.path.join(folder, kind)
time_str = strftime("%d_%b_%Y_%H_%M", gmtime())
summ_path = os.path.join(o_fold,'{}_{}'.format(fname, time_str))
if not os.path.exists(summ_path):
os.makedirs(summ_path)
return su
```
<Overlap Ratio: 0.9375>

---

--- 24 --
Question ID: bf82db3de227ccc8eb0094315264afca9dd76fca_0
Original Code:
```
def login():
    # Load a previous session if one exists, otherwise make a new session
    try:
        with open(session_cache_path, 'rb') as f:
            s = pickle.load(f)
    except (IOError, EOFError):
        s = requests.Session()
        s.mount('https://', TLSAdapter())

    # Make a simple request to see if a login is required
    r = s.get(BASE_URL)

    if "auth_redirect" in r.url:
        # SSO redirection - login
        parsed_url = urlparse(r.url)
        params = parse_qs(parsed_url.query)
        sysparm_url = params['sysparm_url'][0]

        r = s.get(sysparm_url)
        print("Navigated to " + r.url)
        if r.url == "https://iam.auckland.ac.nz/profile/SAML2/Redirect/SSO?execution=e1s1":
            r = s.post(r.url, { "j_username": config.username, "j_password": config.password, "submitted": 0, "_eventId_proceed": "" })
            print("Entered username and password")
            if INCORRECT_CREDENTIAL_STRING in r.text:
                print(INCORRECT_CREDENTIAL_STRING + ". Check config.py")
                exit(1)
            while "j_token" in r.text:
                two_factor = input("Please enter your 2FA token: ")
                r = s.post(r.url, { "submitted": "", "j_token": two_factor, "rememberMe": "on", "_eventId_proceed": "" })
                if INCORRECT_2FA_STRING in r.text:
                    print("Incorrect 2FA token, try again: ")
            soup = BeautifulSoup(r.content, 'html.parser')
            # login success, submit form
            form = {}
            form_inputs = soup.find_all("input", attrs = {'name' : True})
            for input_elem in form_inputs:
                form[input_elem['name']] = input_elem['value']
            r = s.post(form['RelayState'], form)
            print("Navigated to " + r.url)
            csrf_token = re.search(r"var g_ck = '(\w+)';", r.text).group(1)
            s.headers['X-UserToken'] = csrf_token
            with open(session_cache_path, 'wb') as f:
                pickle.dump(s, f)

    return s
```


Overlapping Code:
```
ogin():
# Load a previous session if one exists, otherwise make a new session
try:
with open(session_cache_path, 'rb') as f:
s = pickle.load(f)
except (IOError, EOFError):
s = requests.Session()
s.mount('https://', TLSAdapter())
# Make a simple request to see if a login is required
r = s.get(BASE_URL)
if "auth_redirect" in r.url:
# SSO redirection - login
parsed_url = urlparse(r.url)
params = parse_qs(parsed_url.query)
sysparm_url = params['sysparm_url'][0]
r = s.get(sysparm_url)
print("Navigated to " + r.url)
if r.url == "https://iam.auckland.ac.nz/profile/SAML2/Redirect/SSO?execution=e1s1":
r = s.post(r.url, { "j_username": config.username, "j_password": config.password, "submitted": 0, "_eventId_proceed": "" })
print("Entered username and password")
if INCORRECT_CREDENTIAL_STRING in r.text:
print(INCORRECT_CREDENTIAL_STRING + ". Check config.py")
exit(1)
while "j_token" in r.text:
two_factor = input("Please enter your 2FA token: ")
r = s.post(r.url, { "submitted": "", "j_token": two_factor, "rememberMe": "on", "_eventId_proceed": "" })
if INCORRECT_2FA_STRING in r.text:
print("Incorrect 2FA token, try again: ")
soup = BeautifulSoup(r.content, 'html.parser')
# login success, submit form
form = {}
form_inputs = soup.find_all("input", attrs = {'name' : True})
for input_elem in form_inputs:
form[input_elem['name']] = input_elem['value']
r = s.post(form['RelayState'], form)
print("Navigated to " + r.url)
csrf_token = re.search(r"var g_ck = '(\w+)';", r.text).group(1)
s.headers['X-UserToken'] = csrf_token
with open(session_cach
```
<Overlap Ratio: 0.9681449094316052>

---

--- 25 --
Question ID: 08671982ae844a113a420a3cf7e1c4041265c5cd_0
Original Code:
```
def nonzero_groups(a, minlen=1, include_any=None):
    '''Return groups of indexes where elements are non-zero. This function
is similar to numpy's `nonzero()`, but instead of returning a single array of
indexes, a tuple of consecutive groups of indexes is returned. Unlike
`nonzero()` only 1d arrays are supported.

Parameters
----------

a : array
The input array to search. The `dtype` must be boolean or coerceable to
boolean.

minlen : int
The minimum length of a run in order to be included in the output.
Runs with fewer than `minlen` elements are excluded.

include_any : scalar or array_like, optional
One or more indexes that the output runs must include. Any runs that
contain at least one of the indexes provided by `include_any` are
in the output. Runs that do not contain at least one of the indexes
are excluded. This parameter does not guarantee that all

Returns
-------

runs : tuple of arrays
Tuple of arrays in which the contents of each array are the indexes
into `a` that represent a run of consecutive `True` values.

'''
    # Coerce to array of (0, 1) values.
    a = np.asanyarray(a).astype(bool).astype(int)

    # By taking the diff of `a` we detect transitions between True
    # and False values. A value of `1` marks a transition from False
    # to True, `-1` marks a transition from True to False, and `0`
    # indicates a steady state from the previous True or False value.
    # `0` is padded to the edges of `a` so that we can detect
    # transitions to/from True values at the beginning and end.
    try:
        states = np.diff(a, prepend=0, append=0)
    except TypeError:  # For older numpy
        states = np.diff(np.hstack([0, a, 0]))

    # Indexes of transitions to true and false.
    true_starts = (states == 1).nonzero()[0]
    false_starts = (states == -1).nonzero()[0]
    try:
        assert(np.all(true_starts < false_starts))
    except:
        raise RuntimeError('Unexpected state in nonzero_groups().')
    if include_any is not None:
        runs = tuple((
            np.arange(tidx, fidx) \
                for tidx, fidx in zip(true_starts, false_starts) \
                    if (fidx - tidx) >= minlen \
                        and np.any(np.isin(np.arange(tidx, fidx), include_any)) 
        ))
    else:
        runs = tuple((
            np.arange(tidx, fidx) \
                for tidx, fidx in zip(true_starts, false_starts) \
                    if (fidx - tidx) >= minlen
        ))
    return runs
```


Overlapping Code:
```
 include_any=None):
'''Return groups of indexes where elements are non-zero. This function
is similar to numpy's `nonzero()`, but instead of returning a single array of
indexes, a tuple of consecutive groups of indexes is returned. Unlike
`nonzero()` only 1d arrays are supported.
Parameters
----------
a : array
The input array to search. The `dtype` must be boolean or coerceable to
boolean.
minlen : int
The minimum length of a run in order to be included in the output.
Runs with fewer than `minlen` elements are excluded.
include_any : scalar or array_like, optional
One or more indexes that the output runs must include. Any runs that
contain at least one of the indexes provided by `include_any` are
in the output. Runs that do not contain at least one of the indexes
are excluded. This parameter does not guarantee that all
Returns
-------
runs : tuple of arrays
Tuple of arrays in which the contents of each array are the indexes
into `a` that represent a run of consecutive `True` values.
'''
# Coerce to array of (0, 1) values.
a = np.asanyarray(a).astype(bool).astype(int)
# By taking the diff of `a` we detect transitions between True
# and False values. A value of `1` marks a transition from False
# to True, `-1` marks a transition from True to False, and `0`
# indicates a steady state from the previous True or False value.
# `0` is padded to the edges of `a` so that we can detect
# transitions to/from True values at the beginning and end.
try:
states = np.diff(a, prepend=0, append=0)
except TypeError: # For older numpy
states = np.diff(np.hstack([0, a, 0]))
# Indexes of transitions to true and false.
true_starts = (states == 1).nonzero()[0]
false_starts = (states == -1).nonzero()[0]
try:
assert(np.all(true_starts < false_starts))
except:
raise RuntimeError('Unexpected state in nonzero_groups().')
if include_any is not None:
runs = tuple((
np.arange(tidx, fidx) \
for tidx, fidx in zip(true_starts, false_starts) \
if (fidx - tidx) >= minlen \
and np.any(np.isin(np.arange(tidx, fidx), include_any)) 
))
else:
runs = tuple((
np.arange(tidx, fidx) \
for tidx, fidx in zip(true_starts, false_starts) \
if (fidx - tidx) >= mi
```
<Overlap Ratio: 0.9772727272727273>

---

--- 26 --
Question ID: 13e0ccfeb2e3e97056a8e67acb62fb222daefc23_21
Original Code:
```
@pytest.mark.vcr()
def test_agentgroups_delete_agent_from_group_scanner_id_typeerror(api):
    with pytest.raises(TypeError):
        api.agent_groups.delete_agent(1, 1, scanner_id='nope')
```


Overlapping Code:
```
@pytest.mark.vcr()
def test_agentgroups_delete_agent_from_group_scanner_id_typeerror(api):
with pytest.raises(TypeError):
api.agent_groups.delete_agent(1, 1, scanner_id='no
```
<Overlap Ratio: 0.9772727272727273>

---

--- 27 --
Question ID: fe0afc609e2786e16798981e25f86a20131701c7_5
Original Code:
```
def get_node_info():
  """ Creates a list of JSON objects that contain node information and are
  needed to perform a backup/restore task on the current AppScale deployment.
  """

  # TODO
  # Add logic for choosing minimal set of nodes that need to perform a task.
  # e.g. Only the node that owns the entire keyspace.

  nodes = [{
    NodeInfoTags.HOST: get_br_service_url(appscale_info.get_db_master_ip()),
    NodeInfoTags.ROLE: 'db_master',
    NodeInfoTags.INDEX: None
  }]

  index = 0
  for node in appscale_info.get_db_slave_ips():
    host = get_br_service_url(node)
    # Make sure we don't send the same request on DB roles that reside on the
    # same node.
    if host not in nodes[0].values():
      nodes.append({
        NodeInfoTags.HOST: host,
        NodeInfoTags.ROLE: 'db_slave',
        NodeInfoTags.INDEX: index
      })
      index += 1

  index = 0
  for node in appscale_info.get_zk_node_ips():
    nodes.append({
      NodeInfoTags.HOST: get_br_service_url(node),
      NodeInfoTags.ROLE: 'zk',
      NodeInfoTags.INDEX: index
    })
    index += 1

  return nodes
```


Overlapping Code:
```
_info():
""" Creates a list of JSON objects that contain node information and are
needed to perform a backup/restore task on the current AppScale deployment.
"""
# TODO
# Add logic for choosing minimal set of nodes that need to perform a task.
# e.g. Only the node that owns the entire keyspace.
nodes = [{
NodeInfoTags.HOST: get_br_service_url(appscale_info.get_db_master_ip()),
NodeInfoTags.ROLE: 'db_master',
NodeInfoTags.INDEX: None
}]
index = 0
for node in appscale_info.get_db_slave_ips():
host = get_br_service_url(node)
# Make sure we don't send the same request on DB roles that reside on the
# same node.
if host not in nodes[0].values():
nodes.append({
NodeInfoTags.HOST: host,
NodeInfoTags.ROLE: 'db_slave',
NodeInfoTags.INDEX: index
})
index += 1
index = 0
for node in appscale_info.get_zk_node_ips():
nodes.append({
NodeInfoTags.HOST: get_br_service_url(node),
NodeInfoTags.ROLE: 'zk',
NodeInfoTags.INDEX: index
})
index += 1
return nod
```
<Overlap Ratio: 0.9854771784232366>

---

--- 28 --
Question ID: 249cd3e855842f095ddeb112f4f22c4de4942320_17
Original Code:
```
def test_add_delete_prefix():
    ipam.add_prefix('to_be_removed','10.0.0.0/16')
    ipam.delete_prefix('10.0.0.0/16')
    with db() as conn:
        sql = "SELECT * FROM netrino_prefix WHERE a4=? " \
              "AND prefix_len=? ORDER BY prefix_len"
        rows = conn.execute(sql, (167772160,16)).fetchall()
    assert len(rows) == 0
```


Overlapping Code:
```
efix('to_be_removed','10.0.0.0/16')
ipam.delete_prefix('10.0.0.0/16')
with db() as conn:
sql = "SELECT * FROM netrino_prefix WHERE a4=? " \
"AND prefix_len=? ORDER BY prefix_len"
rows = conn.execute(sql, (167772160,16)).fetchall()
assert len(rows) ==
```
<Overlap Ratio: 0.8532423208191127>

---

--- 29 --
Question ID: ed2c780bbbff996e3c06eeeb0b34fa0e9db60490_7
Original Code:
```
def patch_node(node, docpath, docname=None):
    '''
    Recursively patches links in nodes.
    '''
    node_name = node.localName

    # if node is <img>
    if node_name == "img":
        src = node.getAttributeNode("src")
        # if this is relative path (internal link)
        if src.value.startswith(".."):
            src.value = docpath + src.value
        src.value = collapse_path(src.value)
    # if node is hyperlink
    elif node_name == "a":
        ref = node.getAttributeNode("href")
        # skip anchor links <a name="anchor1"></a>, <a name="more"/>
        if ref != None:
            # patch links only - either starting with "../" or having
            # "internal" class
            is_relative = ref.value.startswith("../")
            if is_relative or "internal" in node.getAttribute("class"):
                ref.value = docpath + ref.value

            # html anchor with missing post.html
            # e.g. href="2012/08/23/#the-cross-compiler"
            # now href="2012/08/23/a_post.html#the-cross-compiler"
            ref.value = ref.value.replace("/#", "/%s.html#" % docname)

            # normalize urls so "2012/08/23/../../../_static/" becomes
            # "_static/" - we can use normpath for this, just make sure
            # to revert change on protocol prefix as normpath deduplicates
            # // (http:// becomes http:/)
            ref.value = collapse_path(ref.value)

    # recurse
    for node in node.childNodes:
        patch_node(node, docpath, docname)
```


Overlapping Code:
```
name=None):
'''
Recursively patches links in nodes.
'''
node_name = node.localName
# if node is <img>
if node_name == "img":
src = node.getAttributeNode("src")
# if this is relative path (internal link)
if src.value.startswith(".."):
src.value = docpath + src.value
src.value = collapse_path(src.value)
# if node is hyperlink
elif node_name == "a":
ref = node.getAttributeNode("href")
# skip anchor links <a name="anchor1"></a>, <a name="more"/>
if ref != None:
# patch links only - either starting with "../" or having
# "internal" class
is_relative = ref.value.startswith("../")
if is_relative or "internal" in node.getAttribute("class"):
ref.value = docpath + ref.value
# html anchor with missing post.html
# e.g. href="2012/08/23/#the-cross-compiler"
# now href="2012/08/23/a_post.html#the-cross-compiler"
ref.value = ref.value.replace("/#", "/%s.html#" % docname)
# normalize urls so "2012/08/23/../../../_static/" becomes
# "_static/" - we can use normpath for this, just make sure
# to revert change on protocol prefix as normpath deduplicates
# // (http:// becomes http:/)
ref.value = collapse_path(ref.value)
# recurse
for node in node.child
```
<Overlap Ratio: 0.9395424836601307>

---

--- 30 --
Question ID: ab0cd55646c58aabfd0f34b5dd50c3e2d5945efb_14
Original Code:
```
def test_journeys_organisation_weekday(load_org):
    date = datetime.date(2019, 4, 8)
    result = _query_journeys(SERVICE, DIRECTION, date).all()

    # Services associated with organisations still only run on specified days
    assert not result
```


Overlapping Code:
```
organisation_weekday(load_org):
date = datetime.date(2019, 4, 8)
result = _query_journeys(SERVICE, DIRECTION, date).all()
# Services associated with organisations still only run on specified days
asse
```
<Overlap Ratio: 0.8658008658008658>

---

--- 31 --
Question ID: 280f872f49d0aaa77bb8772fcb26ba2d7e6df157_1
Original Code:
```
def send_message(msg_type, data):
    panel_config = load_config()
    ws = WebSocket()
    ws.connect("ws://" + panel_config['uri'][0] + "/core")
    message = '{"type": "' + msg_type + '", "data":' + data + '}'
    ws.send(message)
    ws.recv()
    ws.close()
```


Overlapping Code:
```
l_config = load_config()
ws = WebSocket()
ws.connect("ws://" + panel_config['uri'][0] + "/core")
message = '{"type": "' + msg_type + '", "data":' + da
```
<Overlap Ratio: 0.6410256410256411>

---

--- 32 --
Question ID: 352ab043ccc828a575977f5e6c14834db88b7602_16
Original Code:
```
def plot_1d_field(
    coords,
    values,
    fig=None,
    ax=None,
    color="k",
    alpha=1.0,
    lw=1.0,
    ls="-",
    marker=None,
    markersize=None,
    minorticks_on=True,
    x_lims=None,
    y_lims=None,
    log_x=False,
    log_y=False,
    extra_artists=None,
    extra_patches=None,
    xlabel=None,
    ylabel=None,
    label=None,
    legend_loc=None,
    legend_fontsize=None,
    title=None,
    zorder=2,
    output_path=None,
    render_now=True,
    fig_kwargs={},
):

    if fig is None or ax is None:
        fig, ax = create_2d_subplots(**fig_kwargs)
    (lines,) = ax.plot(
        coords,
        values,
        color=color,
        alpha=alpha,
        lw=lw,
        ls=ls,
        marker=marker,
        markersize=markersize,
        markeredgewidth=0,
        label=label,
        zorder=zorder,
    )

    if extra_artists is not None:
        for artist in extra_artists:
            ax.add_artist(artist)

    if extra_patches is not None:
        for patch in extra_patches:
            ax.add_patch(patch)

    if log_x:
        ax.set_xscale("log")
    if log_y:
        ax.set_yscale("log")

    set_2d_plot_extent(ax, x_lims, y_lims)
    set_2d_axis_labels(ax, xlabel, ylabel)

    if minorticks_on:
        ax.minorticks_on()

    if title is not None:
        ax.set_title(title)

    if legend_loc is not None:
        ax.legend(loc=legend_loc, fontsize=legend_fontsize)

    if render_now:
        render(fig, output_path=output_path)

    return fig, ax, lines
```


Overlapping Code:
```
ax=None,
color="k",
alpha=1.0,
lw=1.0,
ls="-",
marker=None,
markersize=None,
minorticks_on=True,
x_lims=None,
y_lims=None,
log_x=False,
log_y=False,
extra_artists=None,
extra_patches=None,
xlabel=None,
ylabel=None,
label=None,
legend_loc=None,
legend_fontsize=None,
title=None,
zorder=2,
output_path=None,
render_now=True,
fig_kwargs={},
):
if fig is None or ax is None:
fig, ax = create_2d_subplots(**fig_kwargs)
(lines,) = ax.plot(
coords,
values,
color=color,
alpha=alpha,
lw=lw,
ls=ls,
marker=marker,
markersize=markersize,
markeredgewidth=0,
label=label,
zorder=zorder,
)
if extra_artists is not None:
for artist in extra_artists:
ax.add_artist(artist)
if extra_patches is not None:
for patch in extra_patches:
ax.add_patch(patch)
if log_x:
ax.set_xscale("log")
if log_y:
ax.set_yscale("log")
set_2d_plot_extent(ax, x_lims, y_lims)
set_2d_axis_labels(ax, xlabel, ylabel)
if minorticks_on:
ax.minorticks_on()
if title is not None:
ax.set_title(title)
if legend_loc is not None:
ax.legend(loc=legend_loc, fontsize=legend_fontsize)
if render_now:
render(fig, output_path=output_path)
return fig, ax,
```
<Overlap Ratio: 0.9557291666666666>

---

--- 33 --
Question ID: 6449df6c32e60e7984c5e8dea2c96d853c68056e_0
Original Code:
```
@pytest.mark.parametrize("port", [PORT_DEFAULT])
def test_slider(port):
    nexSerial = PySerialNex(port)
    nexSerial.init()

    nexPage = NexPage(nexSerial, "pg_slider", pid=11)

    nexSlider = NexSlider(nexSerial, "h0", cid=4)

    nexPage.show()

    time.sleep(0.1)

    nexSlider.value = 43691  # 0-65535

    time.sleep(1)

    # nexSlider.cursor.color = NamedColor.GRAY
    nexSlider.forecolor = NamedColor.GRAY

    time.sleep(1)

    w = 10
    nexSlider.cursor.width = w
    assert nexSlider.cursor.width == w

    time.sleep(1)

    h = 13
    nexSlider.cursor.height = h
    assert nexSlider.cursor.height == h

    time.sleep(1)

    nexSerial.close()
```


Overlapping Code:
```
est.mark.parametrize("port", [PORT_DEFAULT])
def test_slider(port):
nexSerial = PySerialNex(port)
nexSerial.init()
nexPage = NexPage(nexSerial, "pg_slider", pid=11)
nexSlider = NexSlider(nexSerial, "h0", cid=4)
nexPage.show()
time.sleep(0.1)
nexSlider.value = 43691 # 0-65535
time.sleep(1)
# nexSlider.cursor.color = NamedColor.GRAY
nexSlider.forecolor = NamedColor.GRAY
time.sleep(1)
w = 10
nexSlider.cursor.width = w
assert nexSlider.cursor.width == w
time.sleep(1)
h = 13
nexSlider.cursor.height = h
assert nexSlider.cursor.height == h
time.sleep(1)
nexSerial.cl
```
<Overlap Ratio: 0.9843205574912892>

---

--- 34 --
Question ID: 642c188d74b4a92bf70d867e87ae07bd7728aac5_1
Original Code:
```
def main(env=_environment):
    args = parse_arguments()
    if args.verbose:
        logging.getLogger().setLevel(logging.INFO)
    logging.info("arguments read: %s", args)

    assert "method" in args
    assert "resource_type" not in args or args.resource_type in [
        "jobs",
        "jobs.reports",
        "reportTypes",
    ]
    if args.method == "fetch":
        r = api.fetch_report(env, job_id=args.jobId, report_id=args.reportId)
    elif args.resource_type == "jobs":
        assert args.method in ["create", "delete", "get", "list"]
        if args.method == "create":
            r = api.jobs_create(env, report_type_id=args.reportType, job_name=args.name)
        elif args.method == "delete":
            r = api.jobs_delete(env, job_id=args.jobId)
        elif args.method == "get":
            r = api.jobs_get(env, job_id=args.jobId)
        else:  # args.method == "list":
            r = api.jobs_list(env)
    elif args.resource_type == "jobs.reports":
        assert args.method in ["get", "list"]
        if args.method == "get":
            r = api.reports_get(env, job_id=args.jobId, report_id=args.reportId)
        else:  # args.method == "list":
            r = api.reports_list(
                env,
                job_id=args.jobId,
                created_after=args.created_after,
                start_time_at_or_after=args.start_time_at_or_after,
                start_time_before=args.start_time_before,
            )
    else:  # args.resource_type == "reportTypes":
        assert args.method in ["list"]
        r = api.reporttypes_list(env)

    if isinstance(r, str):
        print(r, end="")
    elif isinstance(r, dict):
        print(json.dumps(r, indent=2, sort_keys=True))
    else:
        print(r)

    return ExitStatus.SUCCESS
```


Overlapping Code:
```
):
args = parse_arguments()
if args.verbose:
logging.getLogger().setLevel(logging.INFO)
logging.info("arguments read: %s", args)
assert "method" in args
assert "resource_type" not in args or args.resource_type in [
"jobs",
"jobs.reports",
"reportTypes",
]
if args.method == "fetch":
r = api.fetch_report(env, job_id=args.jobId, report_id=args.reportId)
elif args.resource_type == "jobs":
assert args.method in ["create", "delete", "get", "list"]
if args.method == "create":
r = api.jobs_create(env, report_type_id=args.reportType, job_name=args.name)
elif args.method == "delete":
r = api.jobs_delete(env, job_id=args.jobId)
elif args.method == "get":
r = api.jobs_get(env, job_id=args.jobId)
else: # args.method == "list":
r = api.jobs_list(env)
elif args.resource_type == "jobs.reports":
assert args.method in ["get", "list"]
if args.method == "get":
r = api.reports_get(env, job_id=args.jobId, report_id=args.reportId)
else: # args.method == "list":
r = api.reports_list(
env,
job_id=args.jobId,
created_after=args.created_after,
start_time_at_or_after=args.start_time_at_or_after,
start_time_before=args.start_time_before,
)
else: # args.resource_type == "reportTypes":
assert args.method in ["list"]
r = api.reporttypes_list(env)
if isinstance(r, str):
print(r, end="")
elif isinstance(r, dict):
print(json.dumps(r, indent=2, sort_keys=True))
else:
print(r)
return Exit
```
<Overlap Ratio: 0.9723991507430998>

---

--- 35 --
Question ID: b4b43a8392d0261cde1a0313b6522209eb4356d3_9
Original Code:
```
@main.command()
@click.argument("issue_key", type=str)
def rm(issue_key):
    config = read_config()
    conn = get_conn(config)
    issue = get_issue_by_key(conn, issue_key)
    issue.delete()
```


Overlapping Code:
```
ommand()
@click.argument("issue_key", type=str)
def rm(issue_key):
config = read_config()
conn = get_conn(config)
issue = get_issue_by_key(conn, issue_key)
```
<Overlap Ratio: 0.8757062146892656>

---

--- 36 --
Question ID: 00e7bf1ae8d8c8a3db1e716f8b5d3881f7ff39c3_16
Original Code:
```
def _validate_file_has_start_and_end_lines(user_input, path, identifier):
    try:
        update_file_chunk_content(path=path, code=[], identifier=identifier, check_only=True)
    except ValueError as e:
        print(e)
        return False
    else:
        return True
```


Overlapping Code:
```
d_end_lines(user_input, path, identifier):
try:
update_file_chunk_content(path=path, code=[], identifier=identifier, check_only=True)
except ValueErro
```
<Overlap Ratio: 0.6578947368421053>

---

--- 37 --
Question ID: 48057c1f8910600a4abc42782b3354be12d45d0d_2
Original Code:
```
def fetch_environment_json(args, text):
    # Load or extract environment.json
    if args.env_json_path:
        with open(args.env_json_path) as f:
            env = json.load(f)
    else:
        env = None
        start = 0
        while True:
            start = text.find("\n+ cat /", start)
            if start == -1: break
            start = text.find("/environment.json\n", start)
            if start == -1: break
            start = text.find("{", start)
            end = text.find("\n}", start)
            j = text[start:end+2]
            start = end
            env = json.loads(j)

    if not env:
        log.error("environment.json has not been created yet or the build failed earlier")
        sys.exit(1)

    return env
```


Overlapping Code:
```
rgs, text):
# Load or extract environment.json
if args.env_json_path:
with open(args.env_json_path) as f:
env = json.load(f)
else:
env = None
start = 0
while True:
start = text.find("\n+ cat /", start)
if start == -1: break
start = text.find("/environment.json\n", start)
if start == -1: break
start = text.find("{", start)
end = text.find("\n}", start)
j = text[start:end+2]
start = end
env = json.loads(j)
if not env:
log.error("environment.json has not been created yet or the build failed earlier
```
<Overlap Ratio: 0.9041591320072333>

---

--- 38 --
Question ID: fff96ec350f97de4db3150975c7d7f55f2b80f58_5
Original Code:
```
def find_project_files(window, folders=None, hash_files=True):
    """
    Given a list of folder entries and a potential project path, return a list
    of all files that exist at that particular path.
    """
    path = None
    if folders is None:
        data = window.project_data()
        folders = data.get("folders", None) if data else None
        path = window.project_file_name()
        if path:
            path = os.path.split(path)[0]

    files = {}
    if not folders:
        view = window.active_view()
        if view and view.file_name() is not None:
            base_folder, filename = os.path.split(view.file_name())
            files[base_folder] = _get_file_details(base_folder, filename, hash_files)

        return files

    for folder in folders:
        base_folder, folder_files = _files_for_folder(window, folder, path, hash_files)
        files[base_folder] = folder_files

    return _coalesce_folders(files)
```


Overlapping Code:
```
ers=None, hash_files=True):
"""
Given a list of folder entries and a potential project path, return a list
of all files that exist at that particular path.
"""
path = None
if folders is None:
data = window.project_data()
folders = data.get("folders", None) if data else None
path = window.project_file_name()
if path:
path = os.path.split(path)[0]
files = {}
if not folders:
view = window.active_view()
if view and view.file_name() is not None:
base_folder, filename = os.path.split(view.file_name())
files[base_folder] = _get_file_details(base_folder, filename, hash_files)
return files
for folder in folders:
base_folder, folder_files = _files_for_folder(window, folder, path, hash_files)
files[base_folder] = folder_files
return _coalesce_folders(
```
<Overlap Ratio: 0.9481668773704172>

---

--- 39 --
Question ID: 72ede3f0b4df0445ed7632e462b1c022df0aaa15_1
Original Code:
```
def cross_correlation_plot(ticker, emps, srange=(-180, 180), smoothing=0, plot=True, resolution=1):
    """
    Calculates the cross correlation plot and optimal lags
    :param ticker: Stock ticker pandas.Series
    :param emps: LinkedIn employment pandas.Series
    :param srange: Tuple of timeshifts defining min and max
    :param smoothing: Span parameter for exponential weighted smoothing function
    :param plot: Bool, if True plots the cross correlation and dataframe
    :param resolution: Step in timeshift within range
    :return: Cleaned dataframe, location of optimal lag, correlation at optimal lag, list of calculated correlations
    """
    cors = []
    for shift in range(srange[0], srange[1], resolution):
        df, cor = correlation(ticker, emps, shift, smoothing)
        if len(df) < 100:
            cors.append(np.nan)  # Too few datapoints to correlate
        else:
            cors.append(cor)

    if np.isnan(cors).all():
        print("Can't calculate correlaction")
        return (None, None, None, None)

    max_cor = np.nanmax(cors)
    max_lag = range(srange[0], srange[1], resolution)[np.nanargmax(cors)]

    print('Max correlation at t=' + str(max_lag))
    print('Max correlation:' + str(max_cor))

    df, cor = correlation(ticker, emps, max_lag, smoothing=smoothing)

    if plot:
        fig, ax = plt.subplots(1, 2, figsize=(20, 5))
        plt.title(ticker.name)
        ax[0].plot(range(srange[0], srange[1], resolution), cors, marker='.', linestyle='None', alpha=0.5)
        df.plot(ax=ax[1])
        ax[0].set_xlabel('Time shift of series (Negative is LinkedIn employee count leading stock price)')
        ax[0].set_ylabel('Series Cross Correlation')
        ax[1].set_ylabel('Normalized price / employee count')

    return df, max_lag, max_cor, cors
```


Overlapping Code:
```
nge=(-180, 180), smoothing=0, plot=True, resolution=1):
"""
Calculates the cross correlation plot and optimal lags
:param ticker: Stock ticker pandas.Series
:param emps: LinkedIn employment pandas.Series
:param srange: Tuple of timeshifts defining min and max
:param smoothing: Span parameter for exponential weighted smoothing function
:param plot: Bool, if True plots the cross correlation and dataframe
:param resolution: Step in timeshift within range
:return: Cleaned dataframe, location of optimal lag, correlation at optimal lag, list of calculated correlations
"""
cors = []
for shift in range(srange[0], srange[1], resolution):
df, cor = correlation(ticker, emps, shift, smoothing)
if len(df) < 100:
cors.append(np.nan) # Too few datapoints to correlate
else:
cors.append(cor)
if np.isnan(cors).all():
print("Can't calculate correlaction")
return (None, None, None, None)
max_cor = np.nanmax(cors)
max_lag = range(srange[0], srange[1], resolution)[np.nanargmax(cors)]
print('Max correlation at t=' + str(max_lag))
print('Max correlation:' + str(max_cor))
df, cor = correlation(ticker, emps, max_lag, smoothing=smoothing)
if plot:
fig, ax = plt.subplots(1, 2, figsize=(20, 5))
plt.title(ticker.name)
ax[0].plot(range(srange[0], srange[1], resolution), cors, marker='.', linestyle='None', alpha=0.5)
df.plot(ax=ax[1])
ax[0].set_xlabel('Time shift of series (Negative is LinkedIn employee count leading stock price)')
ax[0].set_ylabel('Series Cross Correlation')
ax[1].set_ylabel('Normalized price / employee count')
return df, max_lag, max_cor, cors
```
<Overlap Ratio: 0.9725>

---

--- 40 --
Question ID: 0767a77da79f15e4d316cc051c157cd2837ede5d_0
Original Code:
```
def openSocket(client, port):
    hostServer = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    hostServer.bind((client, port))
    hostServer.listen(0)
    return hostServer
```


Overlapping Code:
```
tServer = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
hostServer.bind((client, port))
hostServer.listen(0)
re
```
<Overlap Ratio: 0.7055214723926381>

---

--- 41 --
Question ID: ac24946cfeae81abae7e8a0419790e2c34948387_1
Original Code:
```
@app.route('/', methods=['POST'])
def post_index():
    # Process data sent from Comapi
    try:
        # Grab the body data
        raw_body = request.get_data().decode("utf-8")

        if (raw_body is None):
            # No body, bad request.
            return "Bad request - No JSON body found!", status.HTTP_400_BAD_REQUEST

        # We have a request body so lets look at what we have

        # First lets ensure it hasn't been tampered with and it came from Comapi
        # We do this by checking the HMAC from the X-Comapi-Signature header
        request_hmac = request.headers.get("x-comapi-signature")

        if (request_hmac is None):
            # No HMAC, invalid request.
            return "Invalid request: No HMAC value found!", status.HTTP_401_UNAUTHORIZED
        else:
            # Validate the HMAC, ensure you has exposed the rawBody, see app.js for how to do this
            hash = hmac_sha1(raw_body, ">>>YOUR SECRET<<<")

            if (request_hmac != hash):
                # The request is not from Comapi or has been tampered with
                return "Invalid request: HMAC hash check failed!", status.HTTP_401_UNAUTHORIZED

        # Store the received event for later processing, remember you only have 10 secs to process, in this simple example we output to the console
        eventObj = json.loads(raw_body)

        print ("")        
        print ("Received a {0} event id: {1}".format(eventObj.get('name',''), eventObj.get('eventId','')))
        print(json.dumps(eventObj, indent=2)) # Pretty print the JSON
        print ("")

        # You could use queuing tech such as RabbitMQ, or possibly a distributed cache such as Redis       

        # Send worked
        return "Data accepted", status.HTTP_200_OK

    except Exception as ex:
        # Send failed
        print ("An error occurred: ")
        print ("{0}".format(ex))
        raise
```


Overlapping Code:
```
app.route('/', methods=['POST'])
def post_index():
# Process data sent from Comapi
try:
# Grab the body data
raw_body = request.get_data().decode("utf-8")
if (raw_body is None):
# No body, bad request.
return "Bad request - No JSON body found!", status.HTTP_400_BAD_REQUEST
# We have a request body so lets look at what we have
# First lets ensure it hasn't been tampered with and it came from Comapi
# We do this by checking the HMAC from the X-Comapi-Signature header
request_hmac = request.headers.get("x-comapi-signature")
if (request_hmac is None):
# No HMAC, invalid request.
return "Invalid request: No HMAC value found!", status.HTTP_401_UNAUTHORIZED
else:
# Validate the HMAC, ensure you has exposed the rawBody, see app.js for how to do this
hash = hmac_sha1(raw_body, ">>>YOUR SECRET<<<")
if (request_hmac != hash):
# The request is not from Comapi or has been tampered with
return "Invalid request: HMAC hash check failed!", status.HTTP_401_UNAUTHORIZED
# Store the received event for later processing, remember you only have 10 secs to process, in this simple example we output to the console
eventObj = json.loads(raw_body)
print ("") 
print ("Received a {0} event id: {1}".format(eventObj.get('name',''), eventObj.get('eventId','')))
print(json.dumps(eventObj, indent=2)) # Pretty print the JSON
print ("")
# You could use queuing tech such as RabbitMQ, or possibly a distributed cache such as Redis 
# Send worked
return "Data accepted", status.HTTP_200_OK
except Exception as ex:
# Send failed
print ("An error occurred: ")
print ("{0}".format(ex)
```
<Overlap Ratio: 0.9949109414758269>

---

--- 42 --
Question ID: 559d1153e6387191e5d6f5c6e18e97a9e57296db_33
Original Code:
```
def test_fees_update_on_verifier_remove(erc20_relay):
    ERC20Relay = erc20_relay.ERC20Relay
    owner = ERC20Relay.owner

    ERC20Relay.functions.addVerifier(int_to_address(1)).transact({'from': owner})
    ERC20Relay.functions.addVerifier(int_to_address(2)).transact({'from': owner})
    amount = ERC20Relay.functions.fees().call()
    assert amount == calculate_fees(5)

    ERC20Relay.functions.removeVerifier(int_to_address(2)).transact({'from': owner})
    amount = ERC20Relay.functions.fees().call()

    assert amount == calculate_fees(4)
```


Overlapping Code:
```
(erc20_relay):
ERC20Relay = erc20_relay.ERC20Relay
owner = ERC20Relay.owner
ERC20Relay.functions.addVerifier(int_to_address(1)).transact({'from': owner})
ERC20Relay.functions.addVerifier(int_to_address(2)).transact({'from': owner})
amount = ERC20Relay.functions.fees().call()
assert amount == calculate_fees(5)
ERC20Relay.functions.removeVerifier(int_to_address(2)).transact({'from': owner})
amount = ERC20Relay.functions.fees().call()
assert amount == calcula
```
<Overlap Ratio: 0.9037328094302554>

---

--- 43 --
Question ID: 43a8676f30b9618e6a6407d51d65db865b9b4523_12
Original Code:
```
def process_message_file(realm_id: int,
                         slim_mode: bool,
                         fn: str,
                         fn_id: str,
                         files_dir: str,
                         get_recipient_id: Callable[[ZerverFieldsT], int],
                         message_key: str,
                         subscriber_map: Dict[int, Set[int]],
                         data_dir: str,
                         output_dir: str,
                         is_pm_data: bool,
                         masking_content: bool,
                         user_id_mapper: IdMapper,
                         user_handler: UserHandler,
                         attachment_handler: AttachmentHandler) -> None:

    def get_raw_messages(fn: str) -> List[ZerverFieldsT]:
        with open(fn) as f:
            data = ujson.load(f)

        flat_data = [
            d[message_key]
            for d in data
            if message_key in d
        ]

        def get_raw_message(d: Dict[str, Any]) -> Optional[ZerverFieldsT]:
            sender_id = get_hipchat_sender_id(
                realm_id=realm_id,
                slim_mode=slim_mode,
                message_dict=d,
                user_id_mapper=user_id_mapper,
                user_handler=user_handler,
            )

            if sender_id is None:
                return None

            if is_pm_data:
                # We need to compare with str() on both sides here.
                # In Stride, user IDs are strings, but in HipChat,
                # they are integers, and fn_id is always a string.
                if str(sender_id) != str(fn_id):
                    # PMs are in multiple places in the Hipchat export,
                    # and we only use the copy from the sender
                    return None

            content = d['message']

            if masking_content:
                content = re.sub('[a-z]', 'x', content)
                content = re.sub('[A-Z]', 'X', content)

            return dict(
                fn_id=fn_id,
                sender_id=sender_id,
                receiver_id=d.get('receiver', {}).get('id'),
                content=content,
                mention_user_ids=d.get('mentions', []),
                pub_date=str_date_to_float(d['timestamp']),
                attachment=d.get('attachment'),
                files_dir=files_dir,
            )

        raw_messages = []

        for d in flat_data:
            raw_message = get_raw_message(d)
            if raw_message is not None:
                raw_messages.append(raw_message)

        return raw_messages

    raw_messages = get_raw_messages(fn)

    def process_batch(lst: List[Any]) -> None:
        process_raw_message_batch(
            realm_id=realm_id,
            raw_messages=lst,
            subscriber_map=subscriber_map,
            user_id_mapper=user_id_mapper,
            user_handler=user_handler,
            attachment_handler=attachment_handler,
            get_recipient_id=get_recipient_id,
            is_pm_data=is_pm_data,
            output_dir=output_dir,
        )

    chunk_size = 1000

    process_list_in_batches(
        lst=raw_messages,
        chunk_size=chunk_size,
        process_batch=process_batch,
    )
```


Overlapping Code:
```
ge_file(realm_id: int,
slim_mode: bool,
fn: str,
fn_id: str,
files_dir: str,
get_recipient_id: Callable[[ZerverFieldsT], int],
message_key: str,
subscriber_map: Dict[int, Set[int]],
data_dir: str,
output_dir: str,
is_pm_data: bool,
masking_content: bool,
user_id_mapper: IdMapper,
user_handler: UserHandler,
attachment_handler: AttachmentHandler) -> None:
def get_raw_messages(fn: str) -> List[ZerverFieldsT]:
with open(fn) as f:
data = ujson.load(f)
flat_data = [
d[message_key]
for d in data
if message_key in d
]
def get_raw_message(d: Dict[str, Any]) -> Optional[ZerverFieldsT]:
sender_id = get_hipchat_sender_id(
realm_id=realm_id,
slim_mode=slim_mode,
message_dict=d,
user_id_mapper=user_id_mapper,
user_handler=user_handler,
)
if sender_id is None:
return None
if is_pm_data:
# We need to compare with str() on both sides here.
# In Stride, user IDs are strings, but in HipChat,
# they are integers, and fn_id is always a string.
if str(sender_id) != str(fn_id):
# PMs are in multiple places in the Hipchat export,
# and we only use the copy from the sender
return None
content = d['message']
if masking_content:
content = re.sub('[a-z]', 'x', content)
content = re.sub('[A-Z]', 'X', content)
return dict(
fn_id=fn_id,
sender_id=sender_id,
receiver_id=d.get('receiver', {}).get('id'),
content=content,
mention_user_ids=d.get('mentions', []),
pub_date=str_date_to_float(d['timestamp']),
attachment=d.get('attachment'),
files_dir=files_dir,
)
raw_messages = []
for d in flat_data:
raw_message = 
```
<Overlap Ratio: 0.9752925877763329>

---

--- 44 --
Question ID: 829873fc6f1a1f642a59c1fafb6774755f276baf_12
Original Code:
```
@pytest.mark.parametrize('varname, axis_name, to, roll, roll_axis, swap_order',
    [('data_c', 'X', 'left', 1, 1, False),
    ('data_c', 'Y', 'left', 1, 0, False),
    ('data_g', 'X', 'center', -1, 1, True),
    ('data_g', 'Y', 'center', -1, 0, True)]
)
def test_axis_neighbor_pairs_2d(periodic_2d, varname, axis_name, to, roll,
                                roll_axis, swap_order):
    ds, periodic, expected = periodic_2d

    axis = Axis(ds, axis_name)

    data = ds[varname]
    data_left, data_right = axis._get_neighbor_data_pairs(data, to)
    if swap_order:
        data_left, data_right = data_right, data_left
    np.testing.assert_allclose(data_left, np.roll(data.data,
                                                  roll, axis=roll_axis))
    np.testing.assert_allclose(data_right, data.data)
```


Overlapping Code:
```
_name, to, roll, roll_axis, swap_order',
[('data_c', 'X', 'left', 1, 1, False),
('data_c', 'Y', 'left', 1, 0, False),
('data_g', 'X', 'center', -1, 1, True),
('data_g', 'Y', 'center', -1, 0, True)]
)
def test_axis_neighbor_pairs_2d(periodic_2d, varname, axis_name, to, roll,
roll_axis, swap_order):
ds, periodic, expected = periodic_2d
axis = Axis(ds, axis_name)
data = ds[varname]
data_left, data_right = axis._get_neighbor_data_pairs(data, to)
if swap_order:
data_left, data_right = data_right, data_left
np.testing.assert_allclose(data_left, np.roll(data.data,
roll, axis=roll_axis))
np.testing.as
```
<Overlap Ratio: 0.8888888888888888>

---

--- 45 --
Question ID: 56d74a577d16f0cada4e896799c573d4ab7e649c_0
Original Code:
```
def dnf_base():
    """Return a fully configured dnf Base object."""
    base = dnf.Base()
    # Configure base
    conf = base.conf
    conf.debuglevel = 0
    conf.assumeyes = True
    conf.read()

    base.read_all_repos()
    base.fill_sack(load_system_repo='auto')
    return base
```


Overlapping Code:
```
turn a fully configured dnf Base object."""
base = dnf.Base()
# Configure base
conf = base.conf
conf.debuglevel = 0
conf.assumeyes = True
conf.read()
base.read_all_repos()
base.fill_sack(load_system_repo='
```
<Overlap Ratio: 0.8401639344262295>

---

--- 46 --
Question ID: d7cea5bb2dbd77cb6888b1f35dbd4048d8df8794_2
Original Code:
```
@app.route('/red')
def on():
    ser.write(b"r")
    return redirect('/')
```


Overlapping Code:
```

```
<Overlap Ratio: 0.0>

---

--- 47 --
Question ID: 725ebbbbdb4cbc3d0e76dbdbd9e1ae325f4efbb1_5
Original Code:
```
def test_dtype_category():
    """Test that categorical variables of dtype category are supported."""
    # Setup
    data = pd.DataFrame({'a': ['a', 'b', 'c']}, dtype='category')

    # Run
    ht = HyperTransformer()
    ht.detect_initial_config(data)
    ht.fit(data)
    transformed = ht.transform(data)
    reverse = ht.reverse_transform(transformed)

    # Assert
    pd.testing.assert_frame_equal(reverse, data)
```


Overlapping Code:
```
 that categorical variables of dtype category are supported."""
# Setup
data = pd.DataFrame({'a': ['a', 'b', 'c']}, dtype='category')
# Run
ht = HyperTransformer()
ht.detect_initial_config(data)
ht.fit(data)
transformed = ht.transform(data)
reverse = ht.reverse_transform(transformed)
# Assert
pd.testing.assert_frame_equal(reverse, data
```
<Overlap Ratio: 0.9059139784946236>

---

--- 48 --
Question ID: 3c5029f17ae60f20b37d5457d5f9a7cc3f079b7e_0
Original Code:
```
def debug(bp):
    #bp = [0xea0,0xd31,0xc52]
    #bp = [0x00000dfb,0x00000b7c,0x00000d10]
    script = ""
    PIE = get_PIE(sh)
    PAPA = PIE
    print(hex(PIE))
    for x in bp:
        script += "b *0x%x\n"%(PIE+x)
    gdb.attach(sh,gdbscript=script) 
```


Overlapping Code:
```
def debug(bp):
#bp = [0xea0,0xd31,0xc52]
#bp = [0x00000dfb,0x00000b7c,0x00000d10]
script = ""
PIE = get_PIE(sh)
PAPA = PIE
print(hex(PIE))
for x in bp:
script += "b *0x%x\n"%(PIE+x)
gdb.attach(sh,gdb
```
<Overlap Ratio: 0.9342723004694836>

---

--- 49 --
Question ID: 4e47f325da8f0f87a8ea4a6ee5a0cdf303b80b3b_3
Original Code:
```
def setLastPassword():
    global OTPConfig
    global Password
    global LastPassword

    LastPassword = Password
    OTPConfig['LastPassword'] = LastPassword
```


Overlapping Code:
```
obal OTPConfig
global Password
global LastPassword
LastPassword = Password
OTPConfig['LastPassword']
```
<Overlap Ratio: 0.7142857142857143>

---

--- 50 --
Question ID: 717ad56f2bb129120333fd8ab53bc274dbd8aea0_0
Original Code:
```
def join_path(src_cls, dest_cls):
    from collections import defaultdict
    from django.apps import apps

    models = apps.get_models()

    def key(m):
        return m._meta.db_table

    def join_graph():
        edges = defaultdict(list)
        edge_fields = defaultdict(dict)
        for model in models:
            for field in model._meta.get_fields():
                if field.is_relation and hasattr(field, 'column') and not field.null:
                    edges[key(model)].append(key(field.related_model))
                    edge_fields[key(model)][key(field.related_model)] = field

        return edges, edge_fields

    def bfs(join_graph):
        frontier = set([key(src_cls)])
        visited = set()
        paths = {key(src_cls): []}

        while len(frontier) > 0:
            new_frontier = set()
            for node in frontier:
                adjacent_unvisited = set(join_graph[node]) - visited - frontier
                for other in adjacent_unvisited:
                    paths[other] = paths[node] + [node]
                new_frontier |= adjacent_unvisited

            visited |= frontier
            frontier = new_frontier

        return {k: v + [k] for k, v in paths.items()}

    keymap = {key(m): m for m in models}
    graph, fields = join_graph()
    paths = bfs(graph)
    path = paths[key(dest_cls)]
    return [
        fields[path[i]][path[i+1]]
        for i in range(len(path) - 1)
    ]
```


Overlapping Code:
```
, dest_cls):
from collections import defaultdict
from django.apps import apps
models = apps.get_models()
def key(m):
return m._meta.db_table
def join_graph():
edges = defaultdict(list)
edge_fields = defaultdict(dict)
for model in models:
for field in model._meta.get_fields():
if field.is_relation and hasattr(field, 'column') and not field.null:
edges[key(model)].append(key(field.related_model))
edge_fields[key(model)][key(field.related_model)] = field
return edges, edge_fields
def bfs(join_graph):
frontier = set([key(src_cls)])
visited = set()
paths = {key(src_cls): []}
while len(frontier) > 0:
new_frontier = set()
for node in frontier:
adjacent_unvisited = set(join_graph[node]) - visited - frontier
for other in adjacent_unvisited:
paths[other] = paths[node] + [node]
new_frontier |= adjacent_unvisited
visited |= frontier
frontier = new_frontier
return {k: v + [k] for k, v in paths.items()}
keymap = {key(m): m for m in models}
graph, fields = join_graph()
paths = bfs(graph)
path = paths[key(dest_cls)]
return [
fields[path[i]][path[i+1]
```
<Overlap Ratio: 0.9510869565217391>

---

--- 51 --
Question ID: 566e2f5954672b5e51587b206d9832cf0f5600de_10
Original Code:
```
def check_bq_table(table):
    """ Check connection string to BigQuery """
    bq_client = None
    try:
        bq_client = bigquery.Client.from_service_account_json(settings.BQ_SETTING_FILE)
    except Exception as ex:
        print("Authentication with BigQuery failed. (check settings.BQ_SETTING_FILE)")
        return False

    tables = []
    try:
        bq_dataset = bq_client.dataset(settings.DATASET_NAME)
        tables = list(bq_client.list_tables(bq_dataset))
    except Exception as ex:
        print("Dataset '{}' not found in BigQuery. Command failed.".format(settings.DATASET_NAME))
        return False

    exist = table in [t.table_id for t in tables]
    if not exist:
        print("Table '{}' not found in BigQuery. Command failed.".format(table))
    return exist
```


Overlapping Code:
```
e(table):
""" Check connection string to BigQuery """
bq_client = None
try:
bq_client = bigquery.Client.from_service_account_json(settings.BQ_SETTING_FILE)
except Exception as ex:
print("Authentication with BigQuery failed. (check settings.BQ_SETTING_FILE)")
return False
tables = []
try:
bq_dataset = bq_client.dataset(settings.DATASET_NAME)
tables = list(bq_client.list_tables(bq_dataset))
except Exception as ex:
print("Dataset '{}' not found in BigQuery. Command failed.".format(settings.DATASET_NAME))
return False
exist = table in [t.table_id for t in tables]
if not exist:
print("Table '{}' not found in BigQuery. Command failed.".format(table
```
<Overlap Ratio: 0.9530791788856305>

---

--- 52 --
Question ID: 41236aba427df80cf7a2b637e35861491c8b0e0c_5
Original Code:
```
def shn_pr_rheader(jr, tabs=[]):

    """ Person Registry page headers """

    if jr.representation == "html":

        rheader_tabs = shn_rheader_tabs(jr, tabs)

        if jr.name == "person":

            _next = jr.here()
            _same = jr.same()

            person = jr.record

            if person:
                rheader = DIV(TABLE(

                    TR(TH(T("Name: ")),
                       vita.fullname(person),
                       TH(T("ID Label: ")),
                       "%(pe_label)s" % person),

                    TR(TH(T("Date of Birth: ")),
                       "%s" % (person.date_of_birth or T("unknown")),
                       TH(T("Gender: ")),
                       "%s" % pr_gender_opts.get(person.gender, T("unknown"))),

                    TR(TH(T("Nationality: ")),
                       "%s" % pr_nations.get(person.nationality, T("unknown")),
                       TH(T("Age Group: ")),
                       "%s" % pr_age_group_opts.get(person.age_group, T("unknown"))),

                    #))
                    ), rheader_tabs)

                return rheader

        elif jr.name == "group":

            _next = jr.here()
            _same = jr.same()

            group = jr.record

            if group:
                rheader = DIV(TABLE(

                    TR(TH(T("Name: ")),
                       group.name,
                       TH(""),
                       ""),
                    TR(TH(T("Description: ")),
                       group.description,
                       TH(""),
                       "")

                    ), rheader_tabs)

                return rheader

    return None
```


Overlapping Code:
```
):
""" Person Registry page headers """
if jr.representation == "html":
rheader_tabs = shn_rheader_tabs(jr, tabs)
if jr.name == "person":
_next = jr.here()
_same = jr.same()
person = jr.record
if person:
rheader = DIV(TABLE(
TR(TH(T("Name: ")),
vita.fullname(person),
TH(T("ID Label: ")),
"%(pe_label)s" % person),
TR(TH(T("Date of Birth: ")),
"%s" % (person.date_of_birth or T("unknown")),
TH(T("Gender: ")),
"%s" % pr_gender_opts.get(person.gender, T("unknown"))),
TR(TH(T("Nationality: ")),
"%s" % pr_nations.get(person.nationality, T("unknown")),
TH(T("Age Group: ")),
"%s" % pr_age_group_opts.get(person.age_group, T("unknown"))),
#))
), rheader_tabs)
return rheader
elif jr.name == "group":
_next = jr.here()
_same = jr.same()
group = jr.record
if group:
rheader = DIV(TABLE(
TR(TH(T("Name: ")),
group.name,
TH(""),
""),
TR(TH(T("Description: ")),
group.description,
TH(""),
"")
), rheader_tabs)
return rhea
```
<Overlap Ratio: 0.9530271398747391>

---

--- 53 --
Question ID: be36b25e573e9d6482f6a39dad790637e8e31240_5
Original Code:
```
def remove_license_file(license_file):
    if not click.confirm(f"Remove {green(str(license_file.absolute()))}?"):
        click.echo("Not removing license.")
        sys.exit(0)

    try:
        license_file.unlink()
        click.echo(f"Removed {green(str(license_file.absolute()))}.")
    except Exception:
        click.echo(f"Could not remove {green(str(license_file.absolute()))}.", err=True)
```


Overlapping Code:
```
nse_file):
if not click.confirm(f"Remove {green(str(license_file.absolute()))}?"):
click.echo("Not removing license.")
sys.exit(0)
try:
license_file.unlink()
click.echo(f"Removed {green(str(license_file.absolute()))}.")
except Exception:
click.echo(f"Could not remove {green(str(license_file.absolute
```
<Overlap Ratio: 0.8670520231213873>

---

--- 54 --
Question ID: 1bf8f41c1e9b7cf2e6801da679657578b5d57c76_4
Original Code:
```
def sample_id_to_stft_frame_id(sample, window_length, shift, fading=True):
    """
    Calculates the best frame index for a given sample index
    :param sample: Sample index in time domain.
    :param size: FFT size.
    :param shift: Hop in samples.
    :return: Best STFT frame index.


    ## ## ## ##
       ## ## ## ##
          ## ## ## ##
             ## ## ## ##
    00 00 01 12 23 34 45


    ## ## ## ##
     # ## ## ## #
       ## ## ## ##
        # ## ## ## #
    00 00 01 23 5 ...
          12 34 6 ...

    ## ## ## #
       ## ## ## #
          ## ## ## #
             ## ## ## #
    ## ## ## #
    00 00 01 12 23 34 45

    >>> [sample_id_to_stft_frame_id(i, 8, 1, fading=False) for i in range(12)]
    [0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8]
    >>> [sample_id_to_stft_frame_id(i, 8, 2, fading=False) for i in range(10)]
    [0, 0, 0, 0, 1, 1, 2, 2, 3, 3]
    >>> [sample_id_to_stft_frame_id(i, 7, 2, fading=False) for i in range(10)]
    [0, 0, 0, 0, 1, 1, 2, 2, 3, 3]
    >>> [sample_id_to_stft_frame_id(i, 7, 1, fading=False) for i in range(10)]
    [0, 0, 0, 0, 1, 2, 3, 4, 5, 6]

    >>> [sample_id_to_stft_frame_id(i, 8, 1, fading=True) for i in range(12)]
    [7, 7, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15]
    >>> [sample_id_to_stft_frame_id(i, 8, 2, fading=True) for i in range(10)]
    [3, 3, 3, 3, 4, 4, 5, 5, 6, 6]
    >>> [sample_id_to_stft_frame_id(i, 7, 2, fading=True) for i in range(10)]
    [3, 3, 3, 3, 4, 4, 5, 5, 6, 6]
    >>> [sample_id_to_stft_frame_id(i, 7, 1, fading=True) for i in range(10)]
    [6, 6, 6, 6, 7, 8, 9, 10, 11, 12]

    >>> stft(np.zeros([8]), size=8, shift=2).shape
    (7, 5)
    >>> stft(np.zeros([8]), size=8, shift=1).shape
    (15, 5)
    >>> stft(np.zeros([8]), size=8, shift=4).shape
    (3, 5)
    """

    if (window_length + 1) // 2 > sample:
        frame = 0
    else:
        frame = (sample - (window_length + 1) // 2) // shift + 1

    if fading:
        frame = frame + ceil((window_length - shift) / shift)

    return frame
```


Overlapping Code:
```
_to_stft_frame_id(sample, window_length, shift, fading=True):
"""
Calculates the best frame index for a given sample index
:param sample: Sample index in time domain.
:param size: FFT size.
:param shift: Hop in samples.
:return: Best STFT frame index.
## ## ## ##
## ## ## ##
## ## ## ##
## ## ## ##
00 00 01 12 23 34 45
## ## ## ##
# ## ## ## #
## ## ## ##
# ## ## ## #
00 00 01 23 5 ...
12 34 6 ...
## ## ## #
## ## ## #
## ## ## #
## ## ## #
## ## ## #
00 00 01 12 23 34 45
>>> [sample_id_to_stft_frame_id(i, 8, 1, fading=False) for i in range(12)]
[0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8]
>>> [sample_id_to_stft_frame_id(i, 8, 2, fading=False) for i in range(10)]
[0, 0, 0, 0, 1, 1, 2, 2, 3, 3]
>>> [sample_id_to_stft_frame_id(i, 7, 2, fading=False) for i in range(10)]
[0, 0, 0, 0, 1, 1, 2, 2, 3, 3]
>>> [sample_id_to_stft_frame_id(i, 7, 1, fading=False) for i in range(10)]
[0, 0, 0, 0, 1, 2, 3, 4, 5, 6]
>>> [sample_id_to_stft_frame_id(i, 8, 1, fading=True) for i in range(12)]
[7, 7, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15]
>>> [sample_id_to_stft_frame_id(i, 8, 2, fading=True) for i in range(10)]
[3, 3, 3, 3, 4, 4, 5, 5, 6, 6]
>>> [sample_id_to_stft_frame_id(i, 7, 2, fading=True) for i in range(10)]
[3, 3, 3, 3, 4, 4, 5, 5, 6, 6]
>>> [sample_id_to_stft_frame_id(i, 7, 1, fading=True) for i in range(10)]
[6, 6, 6, 6, 7, 8, 9, 10, 11, 12]
>>> stft(np.zeros([8]), size=8, shift=2).shape
(7, 5)
>>> stft(np.zeros([8]), size=8, shift=1).shape
(15, 5)
>>> stft(np.zeros([8]), size=8, shift=4).shape
(3, 5)
"""
if (window_length + 1) // 2 > sample:
frame = 0
else:
frame = (sample - (window_length + 1) // 2) // shift + 1
if fading:
frame = frame + cei
```
<Overlap Ratio: 0.9649122807017544>

---

--- 55 --
Question ID: c54a9788e7a189d623e8f3728d46069cef94a2a0_1
Original Code:
```
def load_tree_object(filename):
    """
    Load scikit-learn decision tree ensemble object from file.
    
    Parameters
    ----------
    filename : str
        Name of the pickle file containing the tree object.
    
    Returns
    -------
    tree ensemble object
    """
    with open(filename) as file_obj:
        tree_ensemble_obj = pickle.load(file_obj)
    return tree_ensemble_obj
```


Overlapping Code:
```
t(filename):
"""
Load scikit-learn decision tree ensemble object from file.

Parameters
----------
filename : str
Name of the pickle file containing the tree object.

Returns
-------
tree ensemble object
"""
with open(filename) as file_obj:
tree_ensemble_obj 
```
<Overlap Ratio: 0.7944785276073619>

---

--- 56 --
Question ID: bbe4897ba0221b59de6a01b5a4d7a01e83b0015f_2
Original Code:
```
def get_schema(cursor):
    """Get the sqlite schema for all the tables"""
    tables = query_sqlite(cursor, "name", "sqlite_master", "type='table'")
    schema_dict = {}
    for table in tables:
        # print(row[0])
        # print(table[0])
        cursor.execute("PRAGMA table_info('%s')" % table[0])
        schema_list = cursor.fetchall()
        schema = {}
        for row in schema_list:
            schema[row[1]] = row[0]
            # print(row)
        schema_dict[table[0]] = schema
    return schema_dict
```


Overlapping Code:
```
et_schema(cursor):
"""Get the sqlite schema for all the tables"""
tables = query_sqlite(cursor, "name", "sqlite_master", "type='table'")
schema_dict = {}
for table in tables:
# print(row[0])
# print(table[0])
cursor.execute("PRAGMA table_info('%s')" % table[0])
schema_list = cursor.fetchall()
schema = {}
for row in schema_list:
schema[row[1]] = row[0]
# print(row)
schema_dict[table[0]] = schema
re
```
<Overlap Ratio: 0.9501187648456056>

---

--- 57 --
Question ID: 4e3d9574adf2dc9d717e461ff90951fa77ac1631_2
Original Code:
```
def ko_model(model, field_names=None, data=None):
    """
    Given a model, returns the Knockout Model and the Knockout ViewModel.
    Takes optional field names and data.
    """

    try:
        if isinstance(model, str):
            modelName = model
        else:
            modelName = model.__class__.__name__

        if field_names:
            fields = field_names
        else:
            fields = get_fields(model)

        if hasattr(model, "comparator"):
            comparator = str(model.comparator())
        else:
            comparator = 'id'

        modelViewString = render_to_string(
            "knockout_modeler/model.js",
            {'modelName': modelName, 'fields': fields, 'data': data, 'comparator': comparator}
        )

        return modelViewString
    except Exception as e:
        logger.exception(e)
        return ''
```


Overlapping Code:
```
odel(model, field_names=None, data=None):
"""
Given a model, returns the Knockout Model and the Knockout ViewModel.
Takes optional field names and data.
"""
try:
if isinstance(model, str):
modelName = model
else:
modelName = model.__class__.__name__
if field_names:
fields = field_names
else:
fields = get_fields(model)
if hasattr(model, "comparator"):
comparator = str(model.comparator())
else:
comparator = 'id'
modelViewString = render_to_string(
"knockout_modeler/model.js",
{'modelName': modelName, 'fields': fields, 'data': data, 'comparator': comparator}
)
return modelViewString
except Exception as e:
logger.exception(e)
return '
```
<Overlap Ratio: 0.9860896445131375>

---

--- 58 --
Question ID: bd3afe39a69fd4c12579800c0a62417708b1e78e_2
Original Code:
```
def learn_embeddings(walks):
    '''
    Learn embeddings by optimizing the Skipgram objective using SGD.
    '''
    walks = [list(map(str, walk)) for walk in walks]
    model = Word2Vec(walks, size=args.dimensions, window=args.window_size, min_count=0, sg=1, workers=args.workers,
                     iter=args.iter)
    model.wv.save_word2vec_format(args.output)

    return
```


Overlapping Code:
```
def learn_embeddings(walks):
'''
Learn embeddings by optimizing the Skipgram objective using SGD.
'''
walks = [list(map(str, walk)) for walk in walks]
model = Word2Vec(walks, size=args.dimensions, window=args.window_size, min_count=0, sg=1, workers=args.workers,
iter=args.iter)
model.wv.save_word2vec_format(args.output)
```
<Overlap Ratio: 0.9786585365853658>

---

--- 59 --
Question ID: 245fded2214972a135a908e8b9a8522e0733038d_2
Original Code:
```
def parse_modifiers(modifiers, args):
    unrecognized = []
    recognized = {}
    for arg in (args or []):
        try:
            key, value = arg.split('=', 1)
            if key in modifiers:
                modifiers[key](recognized, key, value)
            else:
                unrecognized.append(arg)
        except:
            unrecognized.append(arg)
    return recognized, unrecognized
```


Overlapping Code:
```

unrecognized = []
recognized = {}
for arg in (args or []):
try:
key, value = arg.split('=', 1)
if key in modifiers:
modifiers[key](recognized, key, value)
else:
unrecognized.append(arg)
except:
unrecognized.append(arg)
return recognized, unrecognize
```
<Overlap Ratio: 0.8680555555555556>

---

--- 60 --
Question ID: af1a2e6b9b1bf3aca976508a10b163371a64c6aa_0
Original Code:
```
def residential(params):

	print(params)

	# geo_name,geo_id,pop,adult_obesity,income_below_poverty,high_school_graduation,unemployment,violent_crime,age,median_property_value,owner_occupied_housing_units,population_living_in_a_rural_area,grads_total

	data_cols = ["geo_name","geo_id","pop","obesity","poverty",
	"high_school_graduation","unemployment","violent_crime",
	"age","median_property_value",
	"own_housing_percentage",
	"rural","grads_total"]

	path = str(os.path.dirname(os.path.realpath(__file__)))

	data = pd.read_csv(path+"/../data/data1.csv", sep=",", names=data_cols, encoding="latin-1")

	# weight data and return

	imp = 1
	# weighter. this decreases importance by .1 for each param
	for i in params.order():

		# make sure best option is highest

		if params[i] == "education":

			normalise(data, "grads_total", "grads_total", 1)
			normalise(data, "high_school_graduation", "high_school_graduation", 1)
			
			data["education"] = data["high_school_graduation"] + data["grads_total"]
			
			normalise(data, "education", "education", 1)

			order = data[["education"]]
			o_scaled = min_max_scaler.fit_transform(order)
			order = pd.DataFrame(o_scaled)
			data[["education"]] = order*imp
 
		elif params[i] == "jobs":

			# as we want lowest unemployment
			normalise(data, "employment", "unemployment", -1)

			order = data[["employment"]]
			o_scaled = min_max_scaler.fit_transform(order)
			order = pd.DataFrame(o_scaled)
			data[["employment"]] = order*imp

		elif params[i] == "health":

			# as violent crimes is per 100,000
			data["health"] = data["obesity"] + (data["violent_crime"] / 100000)

			normalise(data, "health", "health", -1)

			order = data[["health"]]
			o_scaled = min_max_scaler.fit_transform(order)
			order = pd.DataFrame(o_scaled)
			data[["health"]] = order*imp

		elif params[i] == "home":

			normalise(data, "home", "own_housing_percentage", 1)

			order = data[["home"]]
			o_scaled = min_max_scaler.fit_transform(order)
			order = pd.DataFrame(o_scaled)
			data[["home"]] = order*imp

		elif params[i] == "wealth":

			normalise(data, "wealth", "median_property_value", 1)

			order = data[["wealth"]]
			o_scaled = min_max_scaler.fit_transform(order)
			order = pd.DataFrame(o_scaled)
			data[["wealth"]] = order*imp


		imp -= .2

	data["population"] = data["pop"]

	for k in params.prefs.keys():

		# the best is closest to 0 for these

		if k == "pop":

			data["pop"] = abs(params.prefs[k] - data["pop"])
			
		elif k == "price":

			data["price"] = abs(params.prefs[k] - data["median_property_value"])

		elif k == "urban":

			# urban should be a percentage

			data["urban"] = abs(params.prefs[k] - (1 - data["rural"]))


	# now normalise the data once again using sklearn


	prefs = data[["pop", "price", "urban"]]
	p_scaled = min_max_scaler.fit_transform(prefs)
	prefs = pd.DataFrame(p_scaled)
	data[["pop", "price", "urban"]] = prefs


	return {
		"order": data[["geo_name", "geo_id", "education", "employment", "health", "home", "wealth"]],
		"prefs": data[["geo_name", "geo_id", "pop", "price", "urban",    "population", "median_property_value"]]
	}
```


Overlapping Code:
```
sidential(params):
print(params)
# geo_name,geo_id,pop,adult_obesity,income_below_poverty,high_school_graduation,unemployment,violent_crime,age,median_property_value,owner_occupied_housing_units,population_living_in_a_rural_area,grads_total
data_cols = ["geo_name","geo_id","pop","obesity","poverty",
"high_school_graduation","unemployment","violent_crime",
"age","median_property_value",
"own_housing_percentage",
"rural","grads_total"]
path = str(os.path.dirname(os.path.realpath(__file__)))
data = pd.read_csv(path+"/../data/data1.csv", sep=",", names=data_cols, encoding="latin-1")
# weight data and return
imp = 1
# weighter. this decreases importance by .1 for each param
for i in params.order():
# make sure best option is highest
if params[i] == "education":
normalise(data, "grads_total", "grads_total", 1)
normalise(data, "high_school_graduation", "high_school_graduation", 1)

data["education"] = data["high_school_graduation"] + data["grads_total"]

normalise(data, "education", "education", 1)
order = data[["education"]]
o_scaled = min_max_scaler.fit_transform(order)
order = pd.DataFrame(o_scaled)
data[["education"]] = order*imp

elif params[i] == "jobs":
# as we want lowest unemployment
normalise(data, "employment", "unemployment", -1)
order = data[["employment"]]
o_scaled = min_max_scaler.fit_transform(order)
order = pd.DataFrame(o_scaled)
data[["employment"]] = order*imp
elif params[i] == "health":
# as violent crimes is per 100,000
data["health"] = data["obesity"] + (data["violent_crime"] / 100000)
normalise(data, "health", "health", -1)
order = data[["health"]]
o_scaled = min_max_scaler.fit_transform(order)
order = pd.DataFrame(o_scaled)
data[["health"]] = order*imp
elif params[i] == "home":
normalise(data, "home", "own_housing_percentage", 1)
order = data[["home"]]
o_scaled = min_max_scaler.fit_transform(order)
order = pd.DataFrame(o_scaled)
data[["home"]] = order*imp
elif params[i] == "wealth":
normalise(data, "wealth", "median_property_value", 1)
order = data[["wealth"]]
o_scaled = min_max_scaler.fit_transform(order)
order = pd.DataFrame(o_scaled)
data[["wealth"]] = order*imp
imp -= .2
data["population"] = data["pop"]
for k in params.prefs.keys():
# the best is closest to 0 for these
if k == "pop":
data["pop"] = abs(params.prefs[k] - data["pop"])

elif k
```
<Overlap Ratio: 0.9896729776247849>

---

--- 61 --
Question ID: 62f9e4f70aaca02aa6392b481ad4bc121505d4b9_4
Original Code:
```
@patch('helga_poems.util.get_api')
def test_tweet_handles_unicode(api):
    settings.TWITTER_CONSUMER_KEY = 'foo'
    settings.TWITTER_CONSUMER_SECRET = 'foo'
    settings.TWITTER_OAUTH_TOKEN = 'foo'
    settings.TWITTER_OAUTH_TOKEN_SECRET = 'foo'
    settings.TWITTER_USERNAME = 'helgabot'

    api.return_value = api
    api.update_status.return_value = Mock(id=123456789)

    assert twitter.tweet(u'☃') == 'http://twitter.com/helgabot/status/123456789'
```


Overlapping Code:
```
t_handles_unicode(api):
settings.TWITTER_CONSUMER_KEY = 'foo'
settings.TWITTER_CONSUMER_SECRET = 'foo'
settings.TWITTER_OAUTH_TOKEN = 'foo'
settings.TWITTER_OAUTH_TOKEN_SECRET = 'foo'
settings.TWITTER_USERNAME = 'helgabot'
api.return_value = api
api.update_status.return_value = Mock(id=123456789)
assert twitter.tweet(u'☃') == 'http://twitter.com/helgabot/status/123456789
```
<Overlap Ratio: 0.8838862559241706>

---

--- 62 --
Question ID: 79d852c09bad4e71f2e3342e4ab8b2c72f245488_0
Original Code:
```
def join_bbox(bbox1, bbox2):
	x1_t, y1_t, x2_t, y2_t = bbox1[0], bbox1[1], bbox1[2]+bbox1[0], bbox1[3]+bbox1[1]
	x1_p, y1_p, x2_p, y2_p = bbox2[0], bbox2[1], bbox2[2]+bbox2[0], bbox2[3]+bbox2[1]
	
	# x1_n = max(x1_t, x1_p)
	# y1_n = max(y1_t, y1_p)
	# x2_n = min(x2_t, x2_p)
	# y2_n = min(y2_t, y2_p)

	x1_n = min(x1_t, x1_p)
	y1_n = min(y1_t, y1_p)
	x2_n = max(x2_t, x2_p)
	y2_n = max(y2_t, y2_p)

	# x1_n = (x1_t + x1_p)//2
	# y1_n = (y1_t + y1_p)//2
	# x2_n = (x2_t + x2_p)//2
	# y2_n = (y2_t + y2_p)//2	

	return x1_n, y1_n, x2_n - x1_n, y2_n - y1_n
```


Overlapping Code:
```
_t, y1_t, x2_t, y2_t = bbox1[0], bbox1[1], bbox1[2]+bbox1[0], bbox1[3]+bbox1[1]
x1_p, y1_p, x2_p, y2_p = bbox2[0], bbox2[1], bbox2[2]+bbox2[0], bbox2[3]+bbox2[1]

# x1_n = max(x1_t, x1_p)
# y1_n = max(y1_t, y1_p)
# x2_n = min(x2_t, x2_p)
# y2_n = min(y2_t, y2_p)
x1_n = min(x1_t, x1_p)
y1_n = min(y1_t, y1_p)
x2_n = max(x2_t, x2_p)
y2_n = max(y2_t, y2_p)
# x1_n = (x1_t + x1_p)//2
# y1_n = (y1_t + y1_p)//2
# x2_n = (x2_t + x2_p)//2
# y2_n = (y2_t + y2_p)//2 
return x1_n, y1_n, x2_n - x1_n, y2_n - y
```
<Overlap Ratio: 0.9363295880149812>

---

--- 63 --
Question ID: 658885ee39fbcc21373a5c5ce565d321c36d0786_0
Original Code:
```
@warehouse_router.get("/", response_model=List[str])
def get_warehouse_names():
    """ Gets all unique names of warehouses
    Returns:
        list of names (strings), STATUS 200 (list can be empty)
    """
    return warehouse_database.warehouse_names()
```


Overlapping Code:
```
outer.get("/", response_model=List[str])
def get_warehouse_names():
""" Gets all unique names of warehouses
Returns:
list of names (strings), STATUS 200 (list can be empty)
"""
return warehouse_databa
```
<Overlap Ratio: 0.8620689655172413>

---

--- 64 --
Question ID: 67be26eb7d827e8abc0ef2092c83f55b63992c5f_26
Original Code:
```
@login_required
def ordersection(request):
    if request.POST['section-order']:
        order_array = request.POST['section-order']
        order_array = order_array.split(',')

        i = 1
        for section_id in order_array:
            section = get_object_or_404(Section, pk=section_id)
            section.order = i
            section.save()
            i += 1
```


Overlapping Code:
```
est):
if request.POST['section-order']:
order_array = request.POST['section-order']
order_array = order_array.split(',')
i = 1
for section_id in order_array:
section = get_object_or_404(Section, pk=section_id)

```
<Overlap Ratio: 0.7342657342657343>

---

--- 65 --
Question ID: 0d9729d4702a0197af9c0cf39b95180399c7dc21_7
Original Code:
```
def print_Connections(Connections_arr):
    print("Connections:")
    for x in range(len(Connections_arr)):
        print("   Id:", Connections_arr[x].id, " From:", Connections_arr[x].fromCardinality, " To:",
              Connections_arr[x].toCardinality)
        print("  ", Connections_arr[x].connection_type_name, ":")
        print("      ", Connections_arr[x].from_type, ":", Connections_arr[x].from_id)
        print("      ", Connections_arr[x].to_type, ":", Connections_arr[x].to_id)
    print("=========================================")
```


Overlapping Code:
```
 print_Connections(Connections_arr):
print("Connections:")
for x in range(len(Connections_arr)):
print(" Id:", Connections_arr[x].id, " From:", Connections_arr[x].fromCardinality, " To:",
Connections_arr[x].toCardinality)
print(" ", Connections_arr[x].connection_type_name, ":")
print(" ", Connections_arr[x].from_type, ":", Connections_arr[x].from_id)
print(" ", Connections_arr[x].to_type, ":", Connections_arr[x].to_id)
print("=========================================")
```
<Overlap Ratio: 0.9936974789915967>

---

--- 66 --
Question ID: c30ac5ef1835e2b761745642f33943630393bf9d_11
Original Code:
```
def config_tempest(**kwargs):
    # convert a list of remove values to a dict
    remove = parse_values_to_remove(kwargs.get('remove', []))
    add = parse_values_to_append(kwargs.get('append', []))
    set_logging(kwargs.get('debug', False), kwargs.get('verbose', False))

    accounts_path = kwargs.get('test_accounts')
    if kwargs.get('create_accounts_file') is not None:
        accounts_path = kwargs.get('create_accounts_file')
    conf = TempestConf(write_credentials=accounts_path is None)
    set_options(conf, kwargs.get('deployer_input'),
                kwargs.get('non_admin', False),
                kwargs.get('image_path', C.DEFAULT_IMAGE),
                kwargs.get('overrides', []),
                accounts_path,
                kwargs.get('cloud_creds'))

    credentials = Credentials(conf, not kwargs.get('non_admin', False))
    clients = ClientManager(conf, credentials)
    services = Services(clients, conf, credentials)

    if kwargs.get('create', False) and kwargs.get('test_accounts') is None:
        users = Users(clients.projects, clients.roles, clients.users, conf)
        users.create_tempest_users()

    if services.is_service(**{"type": "compute"}):
        flavors = Flavors(clients.flavors, kwargs.get('create', False), conf,
                          kwargs.get('flavor_min_mem', C.DEFAULT_FLAVOR_RAM),
                          kwargs.get('flavor_min_disk', C.DEFAULT_FLAVOR_DISK),
                          no_rng=kwargs.get('no_rng', False))
        flavors.create_tempest_flavors()

    if services.is_service(**{"type": "image"}):
        image = services.get_service('image')
        image.set_image_preferences(kwargs.get('image_disk_format',
                                               C.DEFAULT_IMAGE_FORMAT),
                                    kwargs.get('non_admin', False),
                                    no_rng=kwargs.get('no_rng', False),
                                    convert=kwargs.get('convert_to_raw',
                                                       False))
        image.create_tempest_images(conf)

    if services.is_service(**{"type": "network"}):
        network = services.get_service("network")
        network.create_tempest_networks(conf, kwargs.get('network_id'))

    services.post_configuration()
    services.set_supported_api_versions()
    services.set_service_extensions()

    if accounts_path is not None and kwargs.get('test_accounts') is None:
        LOG.info("Creating an accounts.yaml file in: %s", accounts_path)
        accounts.create_accounts_file(kwargs.get('create', False),
                                      accounts_path,
                                      conf)

    # remove all unwanted values if were specified
    if remove != {}:
        LOG.info("Removing configuration: %s", str(remove))
        conf.remove_values(remove)
    if add != {}:
        LOG.info("Adding configuration: %s", str(add))
        conf.append_values(add)
    out_path = kwargs.get('out', 'etc/tempest.conf')
    conf.write(out_path)
```


Overlapping Code:
```
ist of remove values to a dict
remove = parse_values_to_remove(kwargs.get('remove', []))
add = parse_values_to_append(kwargs.get('append', []))
set_logging(kwargs.get('debug', False), kwargs.get('verbose', False))
accounts_path = kwargs.get('test_accounts')
if kwargs.get('create_accounts_file') is not None:
accounts_path = kwargs.get('create_accounts_file')
conf = TempestConf(write_credentials=accounts_path is None)
set_options(conf, kwargs.get('deployer_input'),
kwargs.get('non_admin', False),
kwargs.get('image_path', C.DEFAULT_IMAGE),
kwargs.get('overrides', []),
accounts_path,
kwargs.get('cloud_creds'))
credentials = Credentials(conf, not kwargs.get('non_admin', False))
clients = ClientManager(conf, credentials)
services = Services(clients, conf, credentials)
if kwargs.get('create', False) and kwargs.get('test_accounts') is None:
users = Users(clients.projects, clients.roles, clients.users, conf)
users.create_tempest_users()
if services.is_service(**{"type": "compute"}):
flavors = Flavors(clients.flavors, kwargs.get('create', False), conf,
kwargs.get('flavor_min_mem', C.DEFAULT_FLAVOR_RAM),
kwargs.get('flavor_min_disk', C.DEFAULT_FLAVOR_DISK),
no_rng=kwargs.get('no_rng', False))
flavors.create_tempest_flavors()
if services.is_service(**{"type": "image"}):
image = services.get_service('image')
image.set_image_preferences(kwargs.get('image_disk_format',
C.DEFAULT_IMAGE_FORMAT),
kwargs.get('non_admin', False),
no_rng=kwargs.get('no_rng', False),
convert=kwargs.get('convert_to_raw',
False))
image.create_tempest_images(conf)
if services.is_service(**{"type": "network"}):
network = services.get_service("network")
network.create_tempest_networks(conf, kwargs.get('network_id'))
services.post_configuration()
services.set_supported_api_versions()
services.set_service_extensions()
if accounts_path is not None and kwargs.get('test_accounts') is None:
LOG.info("Creating an acco
```
<Overlap Ratio: 0.9698825931597754>

---

--- 67 --
Question ID: 76ba63c14a08313afcb2dc4e9820bf99718875b9_1
Original Code:
```
def main():
    """Go Main Go"""
    pgconn = get_dbconn('coop')
    ccursor = pgconn.cursor()

    fn = sys.argv[1]
    station = sys.argv[2]
    with ncopen(fn) as nc:
        byear = nc.variables['byear'][:]
        maxt = nc.variables['maxt'][:]
        mint = nc.variables['mint'][:]
        pcpn = nc.variables['pcpn'][:]
        snow = nc.variables['snow'][:]
        snwg = nc.variables['snwg'][:]

    current = read_sql("""
        SELECT day, high, low, precip, snow, snowd from
        alldata_ia WHERE station = %s ORDER by day ASC
    """, pgconn, params=(station,), index_col='day')

    added = 0
    for yr in range(byear, 2016):
        for mo in range(12):
            for dy in range(31):
                try:
                    date = datetime.date(yr, mo + 1, dy + 1)
                except ValueError:
                    continue
                high = maxt[yr-byear, mo, dy]
                if (np.ma.is_masked(high) or np.isnan(high) or
                        high < -100 or high > 150):
                    high = None
                else:
                    high = int(high)

                low = mint[yr-byear, mo, dy]
                if (np.ma.is_masked(low) or np.isnan(low) or
                        low < -100 or low > 150):
                    low = None
                else:
                    low = int(low)

                precip = convert(pcpn[yr-byear, mo, dy], 2)
                snowfall = convert(snow[yr-byear, mo, dy], 1)
                snowd = convert(snwg[yr-byear, mo, dy], 1)
                if all([a is None
                        for a in [high, low, precip, snowfall, snowd]]):
                    continue
                if date not in current.index.values:
                    sday = "%02i%02i" % (date.month, date.day)
                    added += 1
                    ccursor.execute("""
                        INSERT into alldata_ia(station, day, high,
                        low, precip, snow, sday, year, month, snowd) VALUES
                        (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    """, (station, date, high, low, precip, snowfall,
                          sday, int(date.year), int(date.month), snowd))

    print("added %s" % (added,))
    ccursor.close()
    pgconn.commit()
```


Overlapping Code:
```
def main():
"""Go Main Go"""
pgconn = get_dbconn('coop')
ccursor = pgconn.cursor()
fn = sys.argv[1]
station = sys.argv[2]
with ncopen(fn) as nc:
byear = nc.variables['byear'][:]
maxt = nc.variables['maxt'][:]
mint = nc.variables['mint'][:]
pcpn = nc.variables['pcpn'][:]
snow = nc.variables['snow'][:]
snwg = nc.variables['snwg'][:]
current = read_sql("""
SELECT day, high, low, precip, snow, snowd from
alldata_ia WHERE station = %s ORDER by day ASC
""", pgconn, params=(station,), index_col='day')
added = 0
for yr in range(byear, 2016):
for mo in range(12):
for dy in range(31):
try:
date = datetime.date(yr, mo + 1, dy + 1)
except ValueError:
continue
high = maxt[yr-byear, mo, dy]
if (np.ma.is_masked(high) or np.isnan(high) or
high < -100 or high > 150):
high = None
else:
high = int(high)
low = mint[yr-byear, mo, dy]
if (np.ma.is_masked(low) or np.isnan(low) or
low < -100 or low > 150):
low = None
else:
low = int(low)
precip = convert(pcpn[yr-byear, mo, dy], 2)
snowfall = convert(snow[yr-byear, mo, dy], 1)
snowd = convert(snwg[yr-byear, mo, dy], 1)
if all([a is None
for a in [high, low, precip, snowfall, snowd]]):
continue
if date not in current.index.values:
sday = "%02i%02i" % (date.month, date.day)
added += 1
ccursor.execute("""
INSERT into alldata_ia(station, day, high,
low, precip, snow, sday, year, month, snowd) VALUES
(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
""", (station, date, high, low, precip, snowfall,
sday, int(date.year), int(date.month), snowd))
print("added %s" % (added,))
ccursor.c
```
<Overlap Ratio: 0.9857235561323816>

---

--- 68 --
Question ID: 2754a06c0a41969a9c50cd0caa65f9b1ecfdfdb3_11
Original Code:
```
def test_whitening_tensor_e2_m1():
    rng = np.random.RandomState(12)

    n_features = 300
    n_components = 25
    min_count = 3
    alpha0 = 10.
    n_samples = rng.randint(100, 150)
    doc_word_mtx = rng.randint(0, 3, size=(n_samples, n_features)).astype('float')
    doc_word_mtx = sp.csr_matrix(doc_word_mtx)

    m1, _ = first_order_moments(doc_word_mtx, min_words=min_count)
    e2, _ = cooccurrence_expectation(doc_word_mtx, min_words=min_count)

    # create M2 directly
    m2 = (alpha0 + 1.) * e2.toarray()
    m2 -= (alpha0 * m1) * m1[:, np.newaxis]
    m2_vals, m2_vecs = sp.linalg.eigsh(m2, k=n_components)
    # create whitening matrix
    W = whitening(m2_vals, m2_vecs)

    # optimized method
    wt_m1 = np.dot(W.T, m1)
    u1_2_3 = whitening_tensor_e2_m1(wt_m1, alpha0)

    # compute directly
    u1_2_3_true = _compute_e2_m1_directly(doc_word_mtx, W, wt_m1)
    assert_array_almost_equal(u1_2_3_true, u1_2_3)
```


Overlapping Code:
```
or_e2_m1():
rng = np.random.RandomState(12)
n_features = 300
n_components = 25
min_count = 3
alpha0 = 10.
n_samples = rng.randint(100, 150)
doc_word_mtx = rng.randint(0, 3, size=(n_samples, n_features)).astype('float')
doc_word_mtx = sp.csr_matrix(doc_word_mtx)
m1, _ = first_order_moments(doc_word_mtx, min_words=min_count)
e2, _ = cooccurrence_expectation(doc_word_mtx, min_words=min_count)
# create M2 directly
m2 = (alpha0 + 1.) * e2.toarray()
m2 -= (alpha0 * m1) * m1[:, np.newaxis]
m2_vals, m2_vecs = sp.linalg.eigsh(m2, k=n_components)
# create whitening matrix
W = whitening(m2_vals, m2_vecs)
# optimized method
wt_m1 = np.dot(W.T, m1)
u1_2_3 = whitening_tensor_e2_m1(wt_m1, alpha0)
# compute directly
u1_2_3_true = _compute_e2_m1_directly(doc_word_mtx, W, wt_m1)
assert_array_almost_equal(u1
```
<Overlap Ratio: 0.9512485136741974>

---

--- 69 --
Question ID: 727dd09d0225f5fb80118f341167b00f79332277_1
Original Code:
```
def load_svhn(folder, max_train, max_test):
    '''
    Loads SVHN dataset from file

    Arguments:


    Returns:
    train_X, np array (num_train, 32, 32, 3) - training images
    train_y, np array of int (num_train) - training labels
    test_X, np array (num_test, 32, 32, 3) - test images
    test_y, np array of int (num_test) - test labels
    '''
    train_X, train_y = load_data_mat(os.path.join(folder, "train_32x32.mat"), max_train)
    test_X, test_y = load_data_mat(os.path.join(folder, "test_32x32.mat"), max_test)
    return train_X, train_y, test_X, test_y
```


Overlapping Code:
```
rain, max_test):
'''
Loads SVHN dataset from file
Arguments:
Returns:
train_X, np array (num_train, 32, 32, 3) - training images
train_y, np array of int (num_train) - training labels
test_X, np array (num_test, 32, 32, 3) - test images
test_y, np array of int (num_test) - test labels
'''
train_X, train_y = load_data_mat(os.path.join(folder, "train_32x32.mat"), max_train)
test_X, test_y = load_data_mat(os.path.join(folder, "test_32x32.mat"), max_
```
<Overlap Ratio: 0.8620689655172413>

---

--- 70 --
Question ID: ea21300009d923f7eaca8d5a9a2f0367da37b10a_1
Original Code:
```
def main():

    args = ARG_LIST.parse_args(sys.argv[1:])
    logging.basicConfig(level=LEVELS[args.log_level])

    run_dmdismod(
        file=args.file,
        dm_commands=args.dm_commands
    )
```


Overlapping Code:
```
n():
args = ARG_LIST.parse_args(sys.argv[1:])
logging.basicConfig(level=LEVELS[args.log_level])
run_dmdismo
```
<Overlap Ratio: 0.656441717791411>

---

--- 71 --
Question ID: 86642cf9af1550ffb25d6350e4add25e9661e3ee_1
Original Code:
```
def _create_time_series(series):
    x_series = []

    fake_day = datetime.date(2010, 1, 1)
    first_time = None

    for x, point in enumerate(series[TIME_COL]):
        # point is something like: 11:10:46.215
        h, m, s = [int(n) for n in point[:-4].split(':')]
        milli = int(point[-3:])
        u = datetime.time(h, m, s, milli * 1000)

        if not first_time:
            first_time = datetime.datetime.combine(fake_day, u)

        delta = (datetime.datetime.combine(fake_day, u) - first_time)
        x_series.append(delta.total_seconds())

    return x_series
```


Overlapping Code:
```
create_time_series(series):
x_series = []
fake_day = datetime.date(2010, 1, 1)
first_time = None
for x, point in enumerate(series[TIME_COL]):
# point is something like: 11:10:46.215
h, m, s = [int(n) for n in point[:-4].split(':')]
milli = int(point[-3:])
u = datetime.time(h, m, s, milli * 1000)
if not first_time:
first_time = datetime.datetime.combine(fake_day, u)
delta = (datetime.datetime.combine(fake_day, u) - first_time)
x_series.append(delta.total_seconds())
return x
```
<Overlap Ratio: 0.9754601226993865>

---

--- 72 --
Question ID: b62424aee5b812da6d5f8e0ddaf4c5c38bbe2584_33
Original Code:
```
def api_repositories():
    root = sorted(os.listdir(config['public-directory']))
    output = []

    for user in root:
        target = os.path.join(config['public-directory'], user)

        # ignore files (eg: .keep file)
        if not os.path.isdir(target):
            continue

        official = (user in config['PUBLIC_OFFICIALS'])
        output.append({'name': user, 'official': official})

    return output
```


Overlapping Code:
```
ot = sorted(os.listdir(config['public-directory']))
output = []
for user in root:
target = os.path.join(config['public-directory'], user)
# ignore files (eg: .keep file)
if not os.path.isdir(target):
continue
official = (user in config['PUBLIC_OFFICIALS'])
output.append({'name': user, 'official': of
```
<Overlap Ratio: 0.8620689655172413>

---

--- 73 --
Question ID: fcac755a616fb4075c3ad8a8f9bde5fcebff6cb7_0
Original Code:
```
def create(large_person_group_id, name=None, user_data=None):
    """Create a new large person group with specified `large_person_group_id`,
    `name` and user-provided `user_data`.

    Args:
        large_person_group_id: User-provided `large_person_group_id` as a
            string. The valid characters include numbers, English letters in
            lower case, '-' and '_'.  The maximum length is 64.
        name: Name of the created large person group, maximum length is 128.
        user_data: Optional user defined data for the large person group.
            Length should not exceed 16KB.

    Returns:
        An empty response body.
    """
    name = name or large_person_group_id
    url = 'largepersongroups/{}'.format(large_person_group_id)
    json = {
        'name': name,
        'userData': user_data,
    }

    return util.request('PUT', url, json=json)
```


Overlapping Code:
```
, name=None, user_data=None):
"""Create a new large person group with specified `large_person_group_id`,
`name` and user-provided `user_data`.
Args:
large_person_group_id: User-provided `large_person_group_id` as a
string. The valid characters include numbers, English letters in
lower case, '-' and '_'. The maximum length is 64.
name: Name of the created large person group, maximum length is 128.
user_data: Optional user defined data for the large person group.
Length should not exceed 16KB.
Returns:
An empty response body.
"""
name = name or large_person_group_id
url = 'largepersongroups/{}'.format(large_person_group_id)
json = {
'name': name,
'userData': user_data,
}
return util.request('PUT', url, json=jso
```
<Overlap Ratio: 0.9547872340425532>

---

--- 74 --
Question ID: ac78bf62ab378563a0db408197919b7b483bf4fb_4
Original Code:
```
def repeated(n, f, x):
    if n == 0:
        return x
    else:
        return App(f, repeated(n-1, f, x))
```


Overlapping Code:
```
n, f, x):
if n == 0:
return x
else:
return App(f, 
```
<Overlap Ratio: 0.6024096385542169>

---

--- 75 --
Question ID: 477b5544eacaaded928575f9725294e6c1f34a72_5
Original Code:
```
def create_directory(directory):
    if not os.path.isdir(directory):
        path = directory.rstrip('/').split('/')
        for i in range(len(path)):
            path_chunk = '/'.join(path[:i+1])
            if not os.path.isdir(path_chunk):
                os.mkdir(path_chunk)
```


Overlapping Code:
```
def create_directory(directory):
if not os.path.isdir(directory):
path = directory.rstrip('/').split('/')
for i in range(len(path)):
path_chunk = '/'.join(path[:i+1])
if not os.path.isdir(path_chunk):
os.mkdir(path_chunk)
```
<Overlap Ratio: 1.0>

---

--- 76 --
Question ID: 5ff29770c9534576e0f205848798ac3b81eb79a0_5
Original Code:
```
def general_stats(x, rel_threshold_outliers=2.5):
    r"""Computes some general statistical properties of a set of values
    :math:`\mathbf{X}=\{x_j\}_{j=1}^n`

    * quartiles :math:`Q_1(\mathbf{X}),\,Q_2(\mathbf{X}),\,Q_3(\mathbf{X})`
    * inter-quartile range
        :math:`IQR(\mathbf{X}) = Q_3(\mathbf{X}) - Q_1(\mathbf{X})`
    * outlier threshold :math:`\theta = \beta \cdot IQR(\mathbf{X})`
    * mean: :math:`\mu_\mathbf{x'} = ave(\mathbf{X'})`
    * standard deviation. :math:`\sigma_\mathbf{x'} = std(\mathbf{X'})`
    * mean/IQR: :math:`\mu_\mathbf{x'}/IQR(\mathbf{X})`

    where :math:`\mathbf{X}'=\{x \in \mathbf{X} \,:\,\, |x-m_x| < \theta\}`
    is the set of points without its outliers.

    :param x: vector of values
    :param rel_threshold_outliers: outlier threshold :math:`\beta` relative to
        the inter-quartile range.
    :return: dictionary with general statistics
    """
    quartiles = np.nanquantile(x, (0.25, 0.5, 0.75))
    iqr = quartiles[2] - quartiles[0]
    threshold = rel_threshold_outliers*iqr
    is_ok = np.abs(x - quartiles[1]) < threshold
    mean = x[is_ok].mean()
    gen_stats = {'quartiles': quartiles,
                 'threshold': threshold,
                 'mean': mean,
                 'std': x[is_ok].std(),
                 'mean/iqr': mean/iqr}
    return gen_stats
```


Overlapping Code:
```
threshold_outliers=2.5):
r"""Computes some general statistical properties of a set of values
:math:`\mathbf{X}=\{x_j\}_{j=1}^n`
* quartiles :math:`Q_1(\mathbf{X}),\,Q_2(\mathbf{X}),\,Q_3(\mathbf{X})`
* inter-quartile range
:math:`IQR(\mathbf{X}) = Q_3(\mathbf{X}) - Q_1(\mathbf{X})`
* outlier threshold :math:`\theta = \beta \cdot IQR(\mathbf{X})`
* mean: :math:`\mu_\mathbf{x'} = ave(\mathbf{X'})`
* standard deviation. :math:`\sigma_\mathbf{x'} = std(\mathbf{X'})`
* mean/IQR: :math:`\mu_\mathbf{x'}/IQR(\mathbf{X})`
where :math:`\mathbf{X}'=\{x \in \mathbf{X} \,:\,\, |x-m_x| < \theta\}`
is the set of points without its outliers.
:param x: vector of values
:param rel_threshold_outliers: outlier threshold :math:`\beta` relative to
the inter-quartile range.
:return: dictionary with general statistics
"""
quartiles = np.nanquantile(x, (0.25, 0.5, 0.75))
iqr = quartiles[2] - quartiles[0]
threshold = rel_threshold_outliers*iqr
is_ok = np.abs(x - quartiles[1]) < threshold
mean = x[is_ok].mean()
gen_stats = {'quartiles': quartiles,
'threshold': threshold,
'mean': mean,
'std': x[is_ok].std(),
'm
```
<Overlap Ratio: 0.9474590869939707>

---

--- 77 --
Question ID: 8d4a49565b30a8d5c68c86e60ba2796eb53b98bd_1
Original Code:
```
@app.route('/hello/')
@app.route('/hello/<name>')
def hello_world(name=None):
    return 'Hello World! Welcome ' + str(name)

```


Overlapping Code:
```
app.route('/hello/')
@app.route('/hello/<name>')
def hello_world(name=None):
retur
```
<Overlap Ratio: 0.6833333333333333>

---

--- 78 --
Question ID: 393f23c6e0e997ce7723da08a72f575d21cf7b6c_5
Original Code:
```
@frappe.whitelist()
def fetch_total_basic_da_hra(parent):
	total_basic_da_hra = 0
	salary_details = frappe.db.sql(""" select amount,salary_component from `tabSalary Detail` where parent=%s and 
					parentfield='earnings' """, parent, as_dict=1)
	if len(salary_details)!=0:
		for data in salary_details:
			amount = data['amount']
			salary_component = data['salary_component']
			if salary_component == 'Basic':
				total_basic_da_hra = float(total_basic_da_hra) + float(amount)
			if salary_component == 'DA':
				total_basic_da_hra = float(total_basic_da_hra) + float(amount)
			if salary_component == 'House Rent Allowance':
				total_basic_da_hra = float(total_basic_da_hra) + float(amount)
			if salary_component == 'Conveyance':
				total_basic_da_hra = float(total_basic_da_hra) + float(amount)
			if salary_component == 'Special Allowance':
				total_basic_da_hra = float(total_basic_da_hra) + float(amount)
	return total_basic_da_hra
```


Overlapping Code:
```
ic_da_hra(parent):
total_basic_da_hra = 0
salary_details = frappe.db.sql(""" select amount,salary_component from `tabSalary Detail` where parent=%s and 
parentfield='earnings' """, parent, as_dict=1)
if len(salary_details)!=0:
for data in salary_details:
amount = data['amount']
salary_component = data['salary_component']
if salary_component == 'Basic':
total_basic_da_hra = float(total_basic_da_hra) + float(amount)
if salary_component == 'DA':
total_basic_da_hra = float(total_basic_da_hra) + float(amount)
if salary_component == 'House Rent Allowance':
total_basic_da_hra = float(total_basic_da_hra) + float(amount)
if salary_component == 'Conveyance':
total_basic_da_hra = float(total_basic_da_hra) + float(amount)
if salary_component == 'Special Allowance':
total_basic_da_hra = float(total_basic_da_hra) + float(amount)
return total_basic_da_h
```
<Overlap Ratio: 0.9539842873176206>

---

--- 79 --
Question ID: 87c08181005716ca929b1a5364f26feaec9fff85_2
Original Code:
```
def eval_fn(goldstd_positive_domains, searchresult, 
            ignore_search_keyerror=False):
    """
    Evaluate the false negative rate for different score cutoffs
    and print table to stdout.
    
    Parameters:
       goldstd_positive_domains - 
                       list of identifiers that the query
                       should match i.e. the 'gold standard' list of 
                       hits.
       searchresult -  list of (score, domainid), sorted by ascending score
        ignore_search_keyerror - If True, ignore key errors in search result.
                      Usually this should not happen, but when using external
                      results i.e. those not from same database (ASTRAL subset)
                      used here, it can. Eg. using TableauSearch webserver
                      results which have older SCOP as database,
                      so there are  SCOP sids in our database that are
                      not in the serach results at all. Then this option
                      just ignores them rather than raising exception KeyError.

    Return value:
       None - table written to stdout.
       
    """
        
    sys.stdout.write('score  fp_count     tpr     fpr\n')
    sys.stdout.write('#------------------------------\n')

    fprlist = []
    tprlist = []

    resultlist = searchresult

    # remove gold standard SCOP domains that are not in the search
    # result, which can happen from using external results, also
    # happens for some domains where for some reason the Bio.SCOP
    # isDomainInId(95) does not contain some domains that actually
    # are in the downlaoded ASTRAL SCOP 95% set (e.g. d2aeph1)
    # This can also happen when the search got an error for a domain
    # so it is not in the search results.
    # Use the -x option (ignore_search_keyerror) to handle these cases
    # (not always on by default since these things "shouldn't" happen).
    if ignore_search_keyerror:
        search_dict = dict([(pdbid, (score, rank)) for (rank, (score, pdbid))
                            in enumerate(searchresult)])
        our_goldstd_positive_domains = [scopdom for scopdom in goldstd_positive_domains if search_dict.has_key(scopdom) ]
    else:
        our_goldstd_positive_domains = goldstd_positive_domains

#    sys.stderr.write('original len, reduced len ' +str(len(goldstd_positive_domains)) +  ' , ' + str(len(our_goldstd_positive_domains)) + '\n')

    
    # convert goldstd list of domainids to dictionary
    # keyed by domainid for fast lookup as we iterate through search results.
    # The dictionary is { domainid : True } (we don't have a value,
    # just need to quickly test for presendce of domainid in gold stad
    # postive list0

    goldstd_pos_dict = dict([(scopdom, True) for
                             scopdom in our_goldstd_positive_domains])
    
    # start at classifying all as true (TPR=FPR=1)
    tp_count = len(our_goldstd_positive_domains)
    fp_count = len(resultlist) - len(our_goldstd_positive_domains)
    for cutoff_rank in xrange(len(resultlist)):
        cutoff_score = resultlist[cutoff_rank][0]
        if cutoff_rank > 0:
            # we are now classifying the previous one and all below as negative
            prev_scopsid =  resultlist[cutoff_rank - 1][1]
            if goldstd_pos_dict.has_key(prev_scopsid):
                tp_count -= 1
            else:
                fp_count -= 1

        tpr = float(tp_count) / float(len(our_goldstd_positive_domains)) #sensitivity = true pos rate
        fpr = float(fp_count) / float(len(resultlist) - len(our_goldstd_positive_domains)) #FP rate
        specificity = 1.0 - fpr

        fprlist.append(fpr)
        tprlist.append(tpr)
            
        sys.stdout.write('%5.1f %8d    %5.3f   %5.3f\n' %
                         (cutoff_score, fp_count, tpr, fpr))

    fprlist.reverse()
    tprlist.reverse()
    auc = compute_auc(fprlist, tprlist)
    sys.stdout.write('\n')
    sys.stdout.write('# AUC = %5.3f\n' % auc)
```


Overlapping Code:
```
eval_fn(goldstd_positive_domains, searchresult, 
ignore_search_keyerror=False):
"""
Evaluate the false negative rate for different score cutoffs
and print table to stdout.

Parameters:
goldstd_positive_domains - 
list of identifiers that the query
should match i.e. the 'gold standard' list of 
hits.
searchresult - list of (score, domainid), sorted by ascending score
ignore_search_keyerror - If True, ignore key errors in search result.
Usually this should not happen, but when using external
results i.e. those not from same database (ASTRAL subset)
used here, it can. Eg. using TableauSearch webserver
results which have older SCOP as database,
so there are SCOP sids in our database that are
not in the serach results at all. Then this option
just ignores them rather than raising exception KeyError.
Return value:
None - table written to stdout.

"""

sys.stdout.write('score fp_count tpr fpr\n')
sys.stdout.write('#------------------------------\n')
fprlist = []
tprlist = []
resultlist = searchresult
# remove gold standard SCOP domains that are not in the search
# result, which can happen from using external results, also
# happens for some domains where for some reason the Bio.SCOP
# isDomainInId(95) does not contain some domains that actually
# are in the downlaoded ASTRAL SCOP 95% set (e.g. d2aeph1)
# This can also happen when the search got an error for a domain
# so it is not in the search results.
# Use the -x option (ignore_search_keyerror) to handle these cases
# (not always on by default since these things "shouldn't" happen).
if ignore_search_keyerror:
search_dict = dict([(pdbid, (score, rank)) for (rank, (score, pdbid))
in enumerate(searchresult)])
our_goldstd_positive_domains = [scopdom for scopdom in goldstd_positive_domains if search_dict.has_key(scopdom) ]
else:
our_goldstd_positive_domains = goldstd_positive_domains
# sys.stderr.write('original len, reduced len ' +str(len(goldstd_positive_domains)) + ' , ' + str(len(our_goldstd_positive_domains)) + '\n')

#
```
<Overlap Ratio: 0.9770395701025891>

---

--- 80 --
Question ID: 9df86b84b9037fca72144612aafd758c97264d6c_4
Original Code:
```
def main():
    filename = 'data/steam_resetera_2017_goty.txt'

    data = load_input(filename)

    observations = parse_data(data)

    verbose = False
    prior = choose_prior(observations, verbose)

    ranking = compute_ranking(observations, prior)

    print_ranking(ranking, observations, prior)

    return True
```


Overlapping Code:
```
esetera_2017_goty.txt'
data = load_input(filename)
observations = parse_data(data)
verbose = False
prior = choose_prior(observations, verbose)
ranking = compute_ranking(observations, prior)
print_rank
```
<Overlap Ratio: 0.7117437722419929>

---

--- 81 --
Question ID: babffeae0626d2dcf86f8338a29d4af7614544b4_0
Original Code:
```
def get_file_content(filename):
    assert os.path.exists(filename), filename+' not exists'
    _, extension = os.path.splitext(filename)
    if extension == '':
        with open(filename) as fd:
            output = fd.read()
        return output
    else:
        linux_darwin_config_table = {
            '.Z': {
                'command': 'uncompress',
                'args': ['-c',],
            },
            '.xz': {
                'command': 'xz',
                'args': ['-c', '-d'],
            },
            '.gz': {
                'command': 'gzip',
                'args': ['-c', '-d'],
            },
        }
        buff = StringIO()
        if platform.system() in ['Darwin', 'Linux']:
            config_table = linux_darwin_config_table
            assert extension in config_table, extension+' has not config'
            config_table = config_table[extension]
            command = config_table['command']
            args    = config_table['args']
            args.append(filename)
            args = tuple(args)
            sh.Command(command).__call__(*args, _out=buff)
        elif platform.system() in ['Windows']:
            raise NotImplementedError('.Z not support windows for now')
        else:
            raise NotImplementedError('Unknown system')
        return buff.getvalue()
```


Overlapping Code:
```
ilename):
assert os.path.exists(filename), filename+' not exists'
_, extension = os.path.splitext(filename)
if extension == '':
with open(filename) as fd:
output = fd.read()
return output
else:
linux_darwin_config_table = {
'.Z': {
'command': 'uncompress',
'args': ['-c',],
},
'.xz': {
'command': 'xz',
'args': ['-c', '-d'],
},
'.gz': {
'command': 'gzip',
'args': ['-c', '-d'],
},
}
buff = StringIO()
if platform.system() in ['Darwin', 'Linux']:
config_table = linux_darwin_config_table
assert extension in config_table, extension+' has not config'
config_table = config_table[extension]
command = config_table['command']
args = config_table['args']
args.append(filename)
args = tuple(args)
sh.Command(command).__call__(*args, _out=buff)
elif platform.system() in ['Windows']:
raise NotImplementedError('.Z not support windows for now')
else:
raise NotImplement
```
<Overlap Ratio: 0.924812030075188>

---

--- 82 --
Question ID: 3f9ec282ed4547f2862e2f1365aea29123eb3226_3
Original Code:
```
def test_snips_component_mqtt_connection_with_tls_and_authentication(fs, mocker):
    """Test whether a `MQTTSnipsComponent` object with TLS and MQTT
    authentication connects to the MQTT broker correctly.
    """

    config_file = '/etc/snips.toml'
    fs.create_file(config_file,
                   contents='[snips-common]\n'
                            'mqtt = "mqtt.example.com:4883"\n'
                            'mqtt_username = "foobar"\n'
                            'mqtt_password = "secretpassword"\n'
                            'mqtt_tls_hostname="mqtt.example.com"\n'
                            'mqtt_tls_cafile="/etc/ssl/certs/ca-certificates.crt"\n')

    mocker.patch('paho.mqtt.client.Client.connect')
    mocker.patch('paho.mqtt.client.Client.loop_forever')
    mocker.patch('paho.mqtt.client.Client.tls_set')
    mocker.patch('paho.mqtt.client.Client.username_pw_set')
    mocker.patch.object(SimpleMQTTComponent, 'initialize')

    component = SimpleMQTTComponent()

    # Check configuration
    assert component.snips.mqtt.broker_address == 'mqtt.example.com:4883'
    assert component.snips.mqtt.auth.username == 'foobar'
    assert component.snips.mqtt.auth.password == 'secretpassword'
    assert component.snips.mqtt.tls.hostname == 'mqtt.example.com'
    assert component.snips.mqtt.tls.ca_file == '/etc/ssl/certs/ca-certificates.crt'

    # Check MQTT connection
    component.mqtt.username_pw_set.assert_called_once_with('foobar',
                                                           'secretpassword')
    component.mqtt.tls_set.assert_called_once_with(ca_certs='/etc/ssl/certs/ca-certificates.crt',
                                                   certfile=None,
                                                   keyfile=None)
    assert component.mqtt.loop_forever.call_count == 1
    component.mqtt.connect.assert_called_once_with('mqtt.example.com', 4883,
                                                   60, '')

    # Check whether `initialize()` method is called.
    assert component.initialize.call_count == 1
```


Overlapping Code:
```
nent_mqtt_connection_with_tls_and_authentication(fs, mocker):
"""Test whether a `MQTTSnipsComponent` object with TLS and MQTT
authentication connects to the MQTT broker correctly.
"""
config_file = '/etc/snips.toml'
fs.create_file(config_file,
contents='[snips-common]\n'
'mqtt = "mqtt.example.com:4883"\n'
'mqtt_us\n'
'mqtt_tls_hostname="mqtt.example.com"\n'
'mqtt_tls_cafile="/etc/ssl/certs/ca-certificates.crt"\n')
mocker.patch('paho.mqtt.client.Client.connect')
mocker.patch('paho.mqtt.client.Client.loop_forever')
mocker.patch('paho.mqtt.client.Client.tls_set')
mocker.patch('paho.mqtt.client.Client.username_pw_set')
mocker.patch.object(SimpleMQTTComponent, 'initialize')
component = SimpleMQTTComponent()
# Check configuration
assert component.snips.mqtt.broker_address == 'mqtt.example.com:4883'
assert component.snips.mqtt.auth.username == 'foobar'
assert component.snips.mqtt.aut
assert component.snips.mqtt.tls.hostname == 'mqtt.example.com'
assert component.snips.mqtt.tls.ca_file == '/etc/ssl/certs/ca-certificates.crt'
# Check MQTT connection
component.mqtt.username_pw_set.assert_called_once_with('foobar',
'secretpassword')
component.mqtt.tls_set.assert_called_once_with(ca_certs='/etc/ssl/certs/ca-certificates.crt',
certfile=None,
keyfile=None)
assert component.mqtt.loop_forever.call_count == 1
component.mqtt.connect.assert_called_once_with('mqtt.example.com', 4883,
60, '')
# Check whether `initialize()` method is called.
assert component.initialize.call_count == 1
```
<Overlap Ratio: 0.9346323067253299>

---

--- 83 --
Question ID: f2a92934d973e2f01682833efb1f2012845ab910_24
Original Code:
```
def test_place_properties():
    amount = 5
    for value in {4, 5, 6, 8, 9, 10}:
        bet = CBPlace(value, amount)
        assert bet.value == value
        assert bet.is_working
        assert bet.amount == amount
        if bet.value in {4, 10}:
            assert bet.win_amount() == amount * 9 / 5
        elif bet.value in {5, 9}:
            assert bet.win_amount() == amount * 7 / 5
        else:
            assert bet.win_amount() == amount * 7 / 6
        bet.set_working(False)
        assert not bet.is_working
```


Overlapping Code:
```
roperties():
amount = 5
for value in {4, 5, 6, 8, 9, 10}:
bet = CBPlace(value, amount)
assert bet.value == value
assert bet.is_working
assert bet.amount == amount
if bet.value in {4, 10}:
assert bet.win_amount() == amount * 9 / 5
elif bet.value in {5, 9}:
assert bet.win_amount() == amount * 7 / 5
else:
assert bet.win_amount() == amount * 7 / 6
bet.
```
<Overlap Ratio: 0.8536585365853658>

---

--- 84 --
Question ID: d5fecf49f1bddaeee44aebd23a276dc45480c7f5_3
Original Code:
```
def main(args):
    model = load_config(args.model)
    dataset = load_config(args.dataset)

    cuda = model["common"]["cuda"]

    if cuda and not torch.cuda.is_available():
        sys.exit("Error: CUDA requested but not available")

    global size
    size = args.tile_size

    global token
    token = os.getenv("MAPBOX_ACCESS_TOKEN")

    if not token:
        sys.exit("Error: map token needed visualizing results; export MAPBOX_ACCESS_TOKEN")

    global session
    session = requests.Session()

    global tiles
    tiles = args.url

    global predictor
    predictor = Predictor(args.checkpoint, model, dataset)

    app.run(host=args.host, port=args.port, threaded=False)
```


Overlapping Code:
```
load_config(args.model)
dataset = load_config(args.dataset)
cuda = model["common"]["cuda"]
if cuda and not torch.cuda.is_available():
sys.exit("Error: CUDA requested but not available")
global size
size = args.tile_size
global token
token = os.getenv("MAPBOX_ACCESS_TOKEN")
if not token:
sys.exit("Error: map token needed visualizing results; export MAPBOX_ACCESS_TOKEN")
global session
session = requests.Session()
global tiles
tiles = args.url
global predictor
predictor = Predictor(args.checkpoint, model, dataset)
app.run(host=args.host, port=args.port, threaded=Fa
```
<Overlap Ratio: 0.9530988274706867>

---

--- 85 --
Question ID: fb4dcbf1b279172ef53eeea7e1fb7934f906f01a_0
Original Code:
```
def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('publisher',
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('modified_at', sa.DateTime(), nullable=False),
    sa.Column('id', sa.String(length=255), nullable=False),
    sa.Column('name', sa.Text(), nullable=False),
    sa.Column('total_datasets', sa.Integer(), nullable=False),
    sa.Column('first_published_on', sa.Date(), nullable=True),
    sa.Column('last_checked_at', sa.DateTime(), nullable=True),
    sa.Column('queued_at', sa.DateTime(), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('contact',
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('modified_at', sa.DateTime(), nullable=False),
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('name', sa.Text(), nullable=False),
    sa.Column('email', sa.Text(), nullable=False),
    sa.Column('publisher_id', sa.String(length=255), nullable=False),
    sa.Column('active', sa.Boolean(), nullable=False),
    sa.Column('confirmed_at', sa.DateTime(), nullable=True),
    sa.Column('last_messaged_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['publisher_id'], ['publisher.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('email', 'publisher_id')
    )
    op.create_table('dataseterror',
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('modified_at', sa.DateTime(), nullable=False),
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('dataset_id', sa.String(length=255), nullable=False),
    sa.Column('dataset_name', sa.Text(), nullable=False),
    sa.Column('dataset_url', sa.String(length=255), nullable=False),
    sa.Column('publisher_id', sa.String(length=255), nullable=False),
    sa.Column('error_type', sa.String(length=20), nullable=True),
    sa.Column('last_status', sa.String(length=20), nullable=False),
    sa.Column('error_count', sa.Integer(), nullable=False),
    sa.Column('check_count', sa.Integer(), nullable=False),
    sa.Column('last_errored_at', sa.DateTime(), nullable=False),
    sa.ForeignKeyConstraint(['publisher_id'], ['publisher.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('dataset_id')
    )
```


Overlapping Code:
```
def upgrade():
# ### commands auto generated by Alembic - please adjust! ###
op.create_table('publisher',
sa.Column('created_at', sa.DateTime(), nullable=False),
sa.Column('modified_at', sa.DateTime(), nullable=False),
sa.Column('id', sa.String(length=255), nullable=False),
sa.Column('name', sa.Text(), nullable=False),
sa.Column('total_datasets', sa.Integer(), nullable=False),
sa.Column('first_published_on', sa.Date(), nullable=True),
sa.Column('last_checked_at', sa.DateTime(), nullable=True),
sa.Column('queued_at', sa.DateTime(), nullable=True),
sa.PrimaryKeyConstraint('id')
)
op.create_table('contact',
sa.Column('created_at', sa.DateTime(), nullable=False),
sa.Column('modified_at', sa.DateTime(), nullable=False),
sa.Column('id', sa.Integer(), nullable=False),
sa.Column('name', sa.Text(), nullable=False),
sa.Column('email', sa.Text(), nullable=False),
sa.Column('publisher_id', sa.String(length=255), nullable=False),
sa.Column('active', sa.Boolean(), nullable=False),
sa.Column('confirmed_at', sa.DateTime(), nullable=True),
sa.Column('last_messaged_at', sa.DateTime(), nullable=True),
sa.ForeignKeyConstraint(['publisher_id'], ['publisher.id'], ondelete='CASCADE'),
sa.PrimaryKeyConstraint('id'),
sa.UniqueConstraint('email', 'publisher_id')
)
op.create_table('dataseterror',
sa.Column('created_at', sa.DateTime(), nullable=False),
sa.Column('modified_at', sa.DateTime(), nullable=False),
sa.Column('id', sa.Integer(), nullable=False),
sa.Column('dataset_id', sa.String(length=255), nullable=False),
sa.Column('dataset_name', sa.Text(), nullable=False),
sa.Column('dataset_url', sa.String(length=255), nullable=False),
sa.Column('publisher_id', sa.String(length=255), nullable=False),
sa.Column('error_type', sa.String(length=20), nullable=True),
sa.Column('last_status', sa.String(length=20), nullable=False),
sa.Column('error_count', sa.Integer(), nullable=False),
sa.Column('check_count', sa.Integer(), nullable=False),
sa.Column('last_errored_at', sa.DateTime(), nullable=False),
sa.ForeignKeyConstraint(['publisher_id'], ['publisher.id'], ondelete='CASCADE'),
sa.PrimaryKeyConstraint('id'),
sa.UniqueConstraint('datas
```
<Overlap Ratio: 0.9958061509785647>

---

--- 86 --
Question ID: 3bad42d8a50abd9b7592a29fe46bc7ff0b7fd6fa_6
Original Code:
```
def ordinary_least_squares(y, x=[], fe=[], data=None, **kwargs):
    # base poisson distribution
    link = links['identity']
    loss0 = losses['least_squares']
    extra = ['lsigma']

    # zero inflation
    def loss(par, yh, y):
        lsigma = par[0]
        sigma2 = np.exp(2*lsigma)
        like = -lsigma + 0.5*loss0(yh, y)/sigma2
        return like

    return glm(y, x=x, fe=fe, data=data, extra=extra, link=link, loss=loss, **kwargs)
```


Overlapping Code:
```
y, x=[], fe=[], data=None, **kwargs):
# base poisson distribution
link = links['identity']
loss0 = losses['least_squares']
extra = ['lsigma']
# zero inflation
def loss(par, yh, y):
lsigma = par[0]
sigma2 = np.exp(2*lsigma)
like = -lsigma + 0.5*loss0(yh, y)/sigma2
return like
return glm(y, x=x, fe=fe, data=data, extra=extra, link=link, loss=loss, **kwa
```
<Overlap Ratio: 0.9192708333333334>

---

--- 87 --
Question ID: f72482536502a08c92fdd47d1959c93914af950f_1
Original Code:
```
def FindWhat(f,value,weight,i,j,item,num):
    if i>=0:
        if f[i][j]==f[i-1][j]:
            item[i]=0
            FindWhat(f,value,weight,i-1,j,item,num)
        elif j-weight[i]>=0:
            for k in range(num[i]+1):
                if f[i][j]==f[i-1][j-k*weight[i]]+k*value[i]:
                    item[i]=k
                    break
            FindWhat(f,value,weight,i-1,j-item[i]*weight[i],item,num)
```


Overlapping Code:
```
FindWhat(f,value,weight,i,j,item,num):
if i>=0:
if f[i][j]==f[i-1][j]:
item[i]=0
FindWhat(f,value,weight,i-1,j,item,num)
elif j-weight[i]>=0:
for k in range(num[i]+1):
if f[i][j]==f[i-1][j-k*weight[i]]+k*value[i]:
item[i]=k
break
FindWhat(f,value,weight,i-1
```
<Overlap Ratio: 0.8831615120274914>

---

--- 88 --
Question ID: 9a773e8f298f148474d228615c69ac551e2e3b1e_0
Original Code:
```
def chunks(l, n):
    """ Yield successive n-sized chunks from l.
    """
    for i in xrange(0, len(l), n):
        yield l[i:i+n]
```


Overlapping Code:
```
def chunks(l, n):
""" Yield successive n-sized chunks from l.
"""
for i in xrange(0, len(l), n):
yield l[i:i+n]
```
<Overlap Ratio: 1.0>

---

--- 89 --
Question ID: a3d236377598bd489b860be65905b840d2921e33_16
Original Code:
```
def segment_length2(seg):
    '''Return the square of the length of a segment.

    Returns: Square of Euclidian distance between centres of points in seg
    '''
    return point_dist2(seg[0], seg[1])
```


Overlapping Code:
```
seg):
'''Return the square of the length of a segment.
Returns: Square of Euclidian distance between centres of points in seg
'''
return point_dist2(s
```
<Overlap Ratio: 0.8152173913043478>

---

--- 90 --
Question ID: 5f58f94187f53dbc0249e07f7f5bb6124b773112_2
Original Code:
```
def site_analytics(request):
    '''Add settings relating to site analytics to the context.
    Currently consists of:

    * GOOGLE_ANALYTICS_ENABLED
    * GOOGLE_SITE_VERIFICATION

    '''
    keys = [
        'GOOGLE_ANALYTICS_ENABLED',
        'GOOGLE_SITE_VERIFICATION',
    ]
    return dict((k, getattr(settings, k, '')) for k in keys)
```


Overlapping Code:
```
est):
'''Add settings relating to site analytics to the context.
Currently consists of:
* GOOGLE_ANALYTICS_ENABLED
* GOOGLE_SITE_VERIFICATION
'''
keys = [
'GOOGLE_ANALYTICS_ENABLED',
'GOOGLE_SITE_VERIFICATION',
]
return dict((k, getattr(settings, k, 
```
<Overlap Ratio: 0.8561643835616438>

---

--- 91 --
Question ID: b16cc1646ad4dbe41303de150cd50b7d001e0910_3
Original Code:
```
@bp.route('/month/<month>', methods=['GET'])
def get_events_by_month(month):
    events = Date.query.filter((Date.events != None) | (Date.events != 0)).filter(Date.day.month == int(month))
    return event_schema.jsonify(events)
```


Overlapping Code:
```
hods=['GET'])
def get_events_by_month(month):
events = Date.query.filter((Date.events != None) | (Date.events != 0)).filter(Date.day.month == int(mont
```
<Overlap Ratio: 0.6818181818181818>

---

--- 92 --
Question ID: 8abca9050609c9b11dbe6046932271d762d68c70_0
Original Code:
```
def login(username, password):
    session = requests.session()
    mobileAgent = 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Droid Build/FRG22D) AppleWebKit/533.1 (KHTML, like Gecko) \
                   Version/4.0 Mobile Safari/533.1'
    session.headers.update({'User-Agent': mobileAgent})
    anonResponse = session.get('https://www.linkedin.com/')
    try:
        loginCSRF = re.findall(r'name="loginCsrfParam".*?value="(.*?)"', anonResponse.text)[0]
    except:
        print('Having trouble with loading the page... try the command again.')
        exit()

    authPayload = {
        'session_key': username,
        'session_password': password,
        'loginCsrfParam': loginCSRF
        }

    response = session.post('https://www.linkedin.com/uas/login-submit', data=authPayload)

    if bool(re.search('<title>*?LinkedIn*?</title>', response.text)): # users get slightly different responses here
        print('[+] Successfully logged in.\n')
        return session
    elif '<title>Sign-In Verification</title>' in response.text:
        print('[!] LinkedIn doesn\'t like something about this login. Maybe you\'re being sneaky on a VPN or')
        print('    something. You may get an email with a verification token. You can ignore that.')
        print('    Try logging in with the same account in your browser first, then try this tool again.\n')
        exit()
    elif '<title>Sign In</title>' in response.text:
        print('[!] You\'ve been returned to the login page. Check your password and try again.\n')
        exit()
    elif '<title>Security Verification' in response.text:
        print('[!] You\'ve triggered the security verification. Please verify your login details and try again.\n')
        exit()
    else:
        print('[!] Some unknown error logging in. If this persists, please open an issue on github.\n')
        exit()
```


Overlapping Code:
```
def login(username, password):
session = requests.session()
mobileAgent = 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Droid Build/FRG22D) AppleWebKit/533.1 (KHTML, like Gecko) \
Version/4.0 Mobile Safari/533.1'
session.headers.update({'User-Agent': mobileAgent})
anonResponse = session.get('https://www.linkedin.com/')
try:
loginCSRF = re.findall(r'name="loginCsrfParam".*?value="(.*?)"', anonResponse.text)[0]
except:
print('Having trouble with loading the page... try the command again.')
exit()
authPayload = {
'session_key': username,
'session_password': password,
'loginCsrfParam': loginCSRF
}
response = session.post('https://www.linkedin.com/uas/login-submit', data=authPayload)
if bool(re.search('<title>*?LinkedIn*?</title>', response.text)): # users get slightly different responses here
print('[+] Successfully logged in.\n')
return session
elif '<title>Sign-In Verification</title>' in response.text:
print('[!] LinkedIn doesn\'t like something about this login. Maybe you\'re being sneaky on a VPN or')
print(' something. You may get an email with a verification token. You can ignore that.')
print(' Try logging in with the same account in your browser first, then try this tool again.\n')
exit()
elif '<title>Sign In</title>' in response.text:
print('[!] You\'ve been returned to the login page. Check your password and try again.\n')
exit()
elif '<title>Security Verification' in response.text:
print('[!] You\'ve triggered the security verification. Please verify your login details and try again.\n')
exit()
else:
print('[!] Some unknown error logging in. If this persists, please open an issue on github.\n')
exit
```
<Overlap Ratio: 0.9987760097919217>

---

--- 93 --
Question ID: 12161c783a7dc81226285827d8bf0ac22aacf252_2
Original Code:
```
def use_rdkit2():
    # substructure matching
    m6 = Chem.MolFromSmiles('c1ccccc1O')
    patt = Chem.MolFromSmarts('ccO')
    print('Boolean if substructure matches --> ', m6.HasSubstructMatch(patt))
    print('Atoms in structure which match --> ',m6.GetSubstructMatch(patt))
    print('if multiple structures match--> ',m6.GetSubstructMatches(patt))
    
    # chemical transformations
    # deleting a substructure
    rm = AllChem.DeleteSubstructs(m6, patt)
    print ('The removed atoms -->', Chem.MolToSmiles(rm))
    Draw.MolToFile(rm,'/home/stokm006/thesis/images/molecule_rm.png')
    # replacing a substructure
    m7 = Chem.MolFromSmiles('CC(=O)N')
    patt2 = Chem.MolFromSmarts('[$(NC(=O))]')
    repl = Chem.MolFromSmiles('OC')
    rms = AllChem.ReplaceSubstructs(m7,patt2,repl)
    print('New SMILE -->', Chem.MolToSmiles(rms[0]))
```


Overlapping Code:
```
bstructure matching
m6 = Chem.MolFromSmiles('c1ccccc1O')
patt = Chem.MolFromSmarts('ccO')
print('Boolean if substructure matches --> ', m6.HasSubstructMatch(patt))
print('Atoms in structure which match --> ',m6.GetSubstructMatch(patt))
print('if multiple structures match--> ',m6.GetSubstructMatches(patt))

# chemical transformations
# deleting a substructure
rm = AllChem.DeleteSubstructs(m6, patt)
print ('The removed atoms -->', Chem.MolToSmiles(rm))
Draw.MolToFile(rm,'/home/stokm006/thesis/images/molecule_rm.png')
# replacing a substructure
m7 = Chem.MolFromSmiles('CC(=O)N')
patt2 = Chem.MolFromSmarts('[$(NC(=O))]')
repl = Chem.MolFromSmiles('OC')
rms = AllChem.ReplaceSubstructs(m7,patt2,repl)
print('New SMILE -->', Chem.MolToSmiles(rms[0]
```
<Overlap Ratio: 0.9689922480620154>

---

--- 94 --
Question ID: 2a857724911d0a4211d79737e630d72d68a9fbd4_0
Original Code:
```
def _handle_error(response):
    if response.status_code == 429:
        raise errors.RateLimitException(response)

    body = None
    try:
        body = response.json()
    except ValueError:
        raise errors.PDFShiftException('Invalid response from the server.', 500)

    if body.get('code') == 400:
        if body.get('message', None):
            raise errors.InvalidRequestException(body.get('error'))

        raise errors.InvalidRequestException(body.get('errors'))

    if str(body.get('code')) in errors.codes:
        raise getattr(errors, errors.codes.get(str(body['code'])))()

    raise errors.PDFShiftException('An unknown error occured.', 500)
```


Overlapping Code:
```
se.status_code == 429:
raise errors.RateLimitException(response)
body = None
try:
body = response.json()
except ValueError:
raise errors.PDFShiftException('Invalid response from the server.', 500)
if body.get('code') == 400:
if body.get('message', None):
raise errors.InvalidRequestException(body.get('error'))
raise errors.InvalidRequestException(body.get('errors'))
if str(body.get('code')) in errors.codes:
raise getattr(errors, errors.codes.get(str(body['code'])))()
raise errors.PDFShiftExceptio
```
<Overlap Ratio: 0.8726003490401396>

---

--- 95 --
Question ID: b16cc1646ad4dbe41303de150cd50b7d001e0910_2
Original Code:
```
@bp.route('/name/<name>', methods=['GET'])
def get_event_by_name(name):
    event = Event.query.filter_by(name=name).scalar()
    return event_schema.jsonify(event)
```


Overlapping Code:
```
T'])
def get_event_by_name(name):
event = Event.query.filter_by(name=name).scalar()
return event_schema.json
```
<Overlap Ratio: 0.6923076923076923>

---

--- 96 --
Question ID: e1ccabb5cf6098b3a2a0c1620ba64369ee04087b_1
Original Code:
```
def filelist(path):
    r = []
    n = os.listdir(path)
    for f in n:
        if not os.path.isdir(f):
            r.append(f)
    return r
```


Overlapping Code:
```
(path):
r = []
n = os.listdir(path)
for f in n:
if
```
<Overlap Ratio: 0.47619047619047616>

---

--- 97 --
Question ID: c7c6415b744176918ca31da98e09adaf690729fa_3
Original Code:
```
@cli.command()
@pass_ctx
def create(ctx):
    """Create a new CloudFormation stack."""
    validate_and_upload(ctx.region, ctx.config)
    ctx.stack.create()
```


Overlapping Code:
```
"""Create a new CloudFormation stack."""
validate_and_upload(ctx.region, ctx.config)
ctx.stack.creat
```
<Overlap Ratio: 0.6896551724137931>

---

--- 98 --
Question ID: 5d8822c368be141023cdb99c2879432fb6294ab1_3
Original Code:
```
def convnet(repr_dim, inputs, num_layers, conv_width=3, activation=tf.nn.relu, **kwargs):
    # dim reduction
    output = inputs
    for i in range(num_layers):
        output = _convolutional_block(output, repr_dim, conv_width=conv_width, name="conv_%d" % i)
    return output
```


Overlapping Code:
```
 num_layers, conv_width=3, activation=tf.nn.relu, **kwargs):
# dim reduction
output = inputs
for i in range(num_layers):
output = _convolutional_block(output, repr_dim, conv_width=conv_width, name="co
```
<Overlap Ratio: 0.7874015748031497>

---

--- 99 --
Question ID: e3573fed0b03b0133d480240a87c50a8883c61ce_0
Original Code:
```
def load_models():
    parent_dir = os.path.dirname(os.path.realpath(__file__))
    data_models_yml = Path(parent_dir) / "data_models.yml"
    with open(data_models_yml) as f:
        data_models = yaml.safe_load(f)
    model_list = []
    for data_model in data_models:
        module = importlib.import_module(data_model["parent_module"])
        model_list.append(getattr(module, data_model["model_class"]))
    return model_list
```


Overlapping Code:
```
):
parent_dir = os.path.dirname(os.path.realpath(__file__))
data_models_yml = Path(parent_dir) / "data_models.yml"
with open(data_models_yml) as f:
data_models = yaml.safe_load(f)
model_list = []
for data_model in data_models:
module = importlib.import_module(data_model["parent_module"])
model_list.append(getattr(module, data_model["model_class"]))
r
```
<Overlap Ratio: 0.9166666666666666>

---

--- 100 --
Question ID: 329555674d8a6531145cd02a07fa0ffd300ca2e5_1
Original Code:
```
def getfileby_func(dirPath,func=lambda r,f:True):
    '''
    func is a function that defined by you to filter the file
    you wanted to operate
    the function func has two parameter,the directory path of the file
    and the filename
    '''
    file_all = []
    gene = os.walk(dirPath)
    for dirpath,dirnames,filenames in gene:
        for file in filenames:
            if func(dirpath,file):
                file_all.append(os.path.join(dirpath, file))
    return file_all
```


Overlapping Code:
```
f:True):
'''
func is a function that defined by you to filter the file
you wanted to operate
the function func has two parameter,the directory path of the file
and the filename
'''
file_all = []
gene = os.walk(dirPath)
for dirpath,dirnames,filenames in gene:
for file in filenames:
if func(dirpath,file):
file_all.append(os.path.join(dirpath, file))
return 
```
<Overlap Ratio: 0.8793103448275862>

---

--- 101 --
Question ID: 160a24baa158808f31426c2f2a50e9da3e700399_8
Original Code:
```
def test_meta_present():
    reg = get_builtin_sites()

    greenwich = reg['greenwich']
    assert greenwich.info.meta['source'] == ('Ordnance Survey via '
           'http://gpsinformation.net/main/greenwich.htm and UNESCO')
```


Overlapping Code:
```
 get_builtin_sites()
greenwich = reg['greenwich']
assert greenwich.info.meta['source'] == ('Ordnance Survey via '
'http://gpsinformation.net/main/greenwich.htm a
```
<Overlap Ratio: 0.7970297029702971>

---

--- 102 --
Question ID: c472825b5f6c0668eb3307f778eca0bcc6c0718c_1
Original Code:
```
def chunk(s):
    w = u''
    t0 = 0
    for c in s:
        if c.isdigit():
            t1 = 1
        elif c.isalpha():
            if ord(c) < 256:
                t1 = 2
            else:
                t1 = 3
        else:
            t1 = 0
        if t0 != t1 and w:
            yield w
            w = u''
        t0 = t1
        w += c
    if w:
        yield w
    return
```


Overlapping Code:
```
:
if c.isdigit():
t1 = 1
elif c.isalpha():
if ord(c) < 256:
t1 = 2
else:
t1 = 3
else:
t1 = 0
if t0 != t1 and w:
yield w
w = u''
t0 = t1
w += c
if w:
y
```
<Overlap Ratio: 0.7425742574257426>

---

--- 103 --
Question ID: 7c1fca17abea1cb3d462e00f82098fc5716ad3a4_0
Original Code:
```
def control(**kwargs):
    if kwargs['payload'] in Encoders().shellcode:
        data = open(kwargs['files'][0], "r").read().strip()

        if kwargs['payload'] == "encoders/shellcode/intel/x86/xor86.py":
            from .xor import prestart
        elif kwargs['payload'] == "encoders/shellcode/intel/x86/xor_b3m.py":
            from .xor_b3m import prestart

        with open(kwargs['files'][0], "w") as encoded:
            encoded.write(prestart((data.replace("\\x", "")), kwargs['iteration']))
```


Overlapping Code:
```
['payload'] in Encoders().shellcode:
data = open(kwargs['files'][0], "r").read().strip()
if kwargs['payload'] == "encoders/shellcode/intel/x86/xor86.py":
from .xor import prestart
elif kwargs['payload'] == "encoders/shellcode/intel/x86/xor_b3m.py":
from .xor_b3m import prestart
with open(kwargs['files'][0], "w") as encoded:
encoded.write(prestart((
```
<Overlap Ratio: 0.8158508158508159>

---

--- 104 --
Question ID: 49d039db53e401ea452ec1cdb12ff96ae55c9a0e_10
Original Code:
```
@click.command()
@click_region_option
@click.argument("stack_name", required=True)
def wait_for_complete(stack_name, region):
    """Wait for the stack status to be *_COMPLETE

    Wait for the stack status to become complete (any status
    ending in '_COMPLETE' is considered complete.
    """
    # how long to wait before the next check for complete (seconds)
    period = 60

    try:
        while True:
            status = _get_stack_status(stack_name, region)
            _highlight('{time}: {status}'.format(time=time.strftime('%H:%M:%S'), status=click.style(status, fg='yellow')))

            complete = status.endswith('_COMPLETE')
            if complete:
                break;

            time.sleep(period)
    except ClientError as e:
        # if waiting for delete to complete, then this is expected, but still should be reported specially just in case
        _highlight('{code}: {msg}'.format(code=e.response['Error']['Code'], msg=e.response['Error']['Message']), fg='red')
```


Overlapping Code:
```
k.command()
@click_region_option
@click.argument("stack_name", required=True)
def wait_for_complete(stack_name, region):
"""Wait for the stack status to be *_COMPLETE
Wait for the stack status to become complete (any status
ending in '_COMPLETE' is considered complete.
"""
# how long to wait before the next check for complete (seconds)
period = 60
try:
while True:
status = _get_stack_status(stack_name, region)
_highlight('{time}: {status}'.format(time=time.strftime('%H:%M:%S'), status=click.style(status, fg='yellow')))
complete = status.endswith('_COMPLETE')
if complete:
break;
time.sleep(period)
except ClientError as e:
# if waiting for delete to complete, then this is expected, but still should be reported specially just in case
_highlight('{code}: {msg}'.format(code=e.response['Error']['Code'], msg=e.response['Error']['Message']), fg='
```
<Overlap Ratio: 0.9883720930232558>

---

--- 105 --
Question ID: f4e36dc11497b3f68670ada79948a547be9ca946_0
Original Code:
```
@pytest.fixture
def dir_examples(request):
    tests_dir = Path(request.fspath).parent
    return tests_dir.parent / 'examples'
```


Overlapping Code:
```
equest):
tests_dir = Path(request.fspath).parent
r
```
<Overlap Ratio: 0.42016806722689076>

---

--- 106 --
Question ID: c382277e65ca74c7ee0c5c3853bca8cac8886eba_6
Original Code:
```
@then('the text is substituted as expected')
def step_impl(context):
    assert context.saved_text, 'context.saved_text is %r!!' % (context.saved_text, )
    expected = TEXT.replace('ipsum', context.active_outline['ipsum'])
    context.saved_text.assert_equals(expected)
```


Overlapping Code:
```
tuted as expected')
def step_impl(context):
assert context.saved_text, 'context.saved_text is %r!!' % (context.saved_text, )
expected = TEXT.replace('ipsum', context.active_outline['ipsum'])
context.s
```
<Overlap Ratio: 0.7751937984496124>

---

--- 107 --
Question ID: 7c80933d5b2e98d963d6420181a06d08257f1993_31
Original Code:
```
def test_create_dir_isfile(tmpdir):
    entry = {'assembly_accession': 'FAKE0.1'}
    output = tmpdir.mkdir('output')
    output.join('refseq', 'bacteria', 'FAKE0.1').write('foo', ensure=True)
    with pytest.raises(OSError):
        core.create_dir(entry, 'refseq', 'bacteria', str(output), flat_output=False)
```


Overlapping Code:
```
_dir_isfile(tmpdir):
entry = {'assembly_accession': 'FAKE0.1'}
output = tmpdir.mkdir('output')
output.join('refseq', 'bacteria', 'FAKE0.1').write('foo', ensure=True)
with pytest.raises(OSError):
core.create_dir(entry, 'refseq', 'bacteria', str(output), flat_output=
```
<Overlap Ratio: 0.9265734265734266>

---

--- 108 --
Question ID: 8e750dec9420b5672d2d12c2ffc899a7ef185fac_1
Original Code:
```
def test_job_priority():
    client = mock.MagicMock()
    assert models.Job(client, "1", "hive", "SELECT COUNT(1) FROM nasdaq", priority=-2).priority == "VERY LOW"
    assert models.Job(client, "2", "hive", "SELECT COUNT(1) FROM nasdaq", priority=-1).priority == "LOW"
    assert models.Job(client, "3", "hive", "SELECT COUNT(1) FROM nasdaq", priority=0).priority == "NORMAL"
    assert models.Job(client, "4", "hive", "SELECT COUNT(1) FROM nasdaq", priority=1).priority == "HIGH"
    assert models.Job(client, "5", "hive", "SELECT COUNT(1) FROM nasdaq", priority=2).priority == "VERY HIGH"
    assert models.Job(client, "42", "hive", "SELECT COUNT(1) FROM nasdaq", priority=42).priority == "42"
```


Overlapping Code:
```
.MagicMock()
assert models.Job(client, "1", "hive", "SELECT COUNT(1) FROM nasdaq", priority=-2).priority == "VERY LOW"
assert models.Job(client, "2", "hive", "SELECT COUNT(1) FROM nasdaq", priority=-1).priority == "LOW"
assert models.Job(client, "3", "hive", "SELECT COUNT(1) FROM nasdaq", priority=0).priority == "NORMAL"
assert models.Job(client, "4", "hive", "SELECT COUNT(1) FROM nasdaq", priority=1).priority == "HIGH"
assert models.Job(client, "5", "hive", "SELECT COUNT(1) FROM nasdaq", priority=2).priority == "VERY HIGH"
assert models.Job(client, "42", "hive", "SELECT COUNT(1) FROM nasdaq",
```
<Overlap Ratio: 0.8982035928143712>

---

--- 109 --
Question ID: ffc2bf43fd107f0d6feb4cf24564e2deca3e57a5_7
Original Code:
```
def youtube_command(message, handler, args):
    try:
        '''
        voice = handler.client.join_voice_channel(message.author.voice_channel)
        player = voice.create_ytdl_player('https://www.youtube.com/watch?v=d62TYemN6MQ')
        player.start()
        '''
        return ":microphone: Lets Rock 'n Roll :notes:"
    except Exception as e:
        template = "An exception of type {0} occurred. Arguments:\n{1!r}"
        message = template.format(type(e).__name__, e.args)
        print(message)
```


Overlapping Code:
```
try:
'''
voice = handler.client.join_voice_channel(message.author.voice_channel)
player = voice.create_ytdl_player('https://www.youtube.com/watch?v=d62TYemN6MQ')
player.start()
'''
return ":microphone: Lets Rock 'n Roll :notes:"
except Exception as e:
template = "An exception of type {0} occurred. Arguments:\n{1!r}"
message = template.format(type(e).__name__, e.args)
print(message)
```
<Overlap Ratio: 0.8951048951048951>

---

--- 110 --
Question ID: 6a4d0f34aecce7494685901d6143e8f64efb9d1b_14
Original Code:
```
@testing.requires_testing_data
def test_csr_csc(tmpdir):
    """Test CSR and CSC."""
    info = read_info(sss_ctc_fname)
    info = pick_info(info, pick_types(info, meg=True, exclude=[]))
    sss_ctc = info['proc_history'][0]['max_info']['sss_ctc']
    ct = sss_ctc['decoupler'].copy()
    # CSC
    assert isinstance(ct, sparse.csc_matrix)
    fname = tmpdir.join('test.fif')
    write_info(fname, info)
    info_read = read_info(fname)
    ct_read = info_read['proc_history'][0]['max_info']['sss_ctc']['decoupler']
    assert isinstance(ct_read, sparse.csc_matrix)
    assert_array_equal(ct_read.toarray(), ct.toarray())
    # Now CSR
    csr = ct.tocsr()
    assert isinstance(csr, sparse.csr_matrix)
    assert_array_equal(csr.toarray(), ct.toarray())
    info['proc_history'][0]['max_info']['sss_ctc']['decoupler'] = csr
    fname = tmpdir.join('test1.fif')
    write_info(fname, info)
    info_read = read_info(fname)
    ct_read = info_read['proc_history'][0]['max_info']['sss_ctc']['decoupler']
    assert isinstance(ct_read, sparse.csc_matrix)  # this gets cast to CSC
    assert_array_equal(ct_read.toarray(), ct.toarray())
```


Overlapping Code:
```
csr_csc(tmpdir):
"""Test CSR and CSC."""
info = read_info(sss_ctc_fname)
info = pick_info(info, pick_types(info, meg=True, exclude=[]))
sss_ctc = info['proc_history'][0]['max_info']['sss_ctc']
ct = sss_ctc['decoupler'].copy()
# CSC
assert isinstance(ct, sparse.csc_matrix)
fname = tmpdir.join('test.fif')
write_info(fname, info)
info_read = read_info(fname)
ct_read = info_read['proc_history'][0]['max_info']['sss_ctc']['decoupler']
assert isinstance(ct_read, sparse.csc_matrix)
assert_array_equal(ct_read.toarray(), ct.toarray())
# Now CSR
csr = ct.tocsr()
assert isinstance(csr, sparse.csr_matrix)
assert_array_equal(csr.toarray(), ct.toarray())
info['proc_history'][0]['max_info']['sss_ctc']['decoupler'] = csr
fname = tmpdir.join('test1.fif')
write_info(fname, info)
info_read = read_info(fname)
ct_read = info_read['proc_history'][0]['max_info']['sss_ctc']['decoupler']
assert isinstance(ct_read, sparse.csc_matrix) # this gets cast to CSC
asser
```
<Overlap Ratio: 0.916988416988417>

---

--- 111 --
Question ID: 8fc1e85b663356eedcd79653007e1c7b80cec659_0
Original Code:
```
def runserver():
    parse_command_line()
    app = tornado.web.Application(handlers=get_routes(), debug=settings.DEBUG)
    app.listen(address=options.host, port=options.port)
    tornado.ioloop.IOLoop.current().start()
```


Overlapping Code:
```
def runserver():
parse_command_line()
app = tornado.web.Application(handlers=get_routes(), debug=settings.DEBUG)
app.listen(address=options.host, port=options.port)
tornado.ioloop.IOLoop.current().start()
```
<Overlap Ratio: 1.0>

---

--- 112 --
Question ID: 76f3b457fe3d25fbb8d49ce255ae30cc71794149_11
Original Code:
```
def parse_namespace_and_name(monitoring_info_proto):
  """Returns the (namespace, name) tuple of the URN in the monitoring info."""
  # Remove the URN prefix which indicates that it is a user counter.
  if is_user_monitoring_info(monitoring_info_proto):
    labels = monitoring_info_proto.labels
    return labels[NAMESPACE_LABEL], labels[NAME_LABEL]

  # If it is not a user counter, just use the first part of the URN, i.e. 'beam'
  split = monitoring_info_proto.urn.split(':', 1)
  return split[0], split[1]
```


Overlapping Code:
```
and_name(monitoring_info_proto):
"""Returns the (namespace, name) tuple of the URN in the monitoring info."""
# Remove the URN prefix which indicates that it is a user counter.
if is_user_monitoring_info(monitoring_info_proto):
labels = monitoring_info_proto.labels
return labels[NAMESPACE_LABEL], labels[NAME_LABEL]
# If it is not a user counter, just use the first part of the URN, i.e. 'beam'
split = monitoring_info_proto.urn.split(':', 1)
return split[0], split[1]
```
<Overlap Ratio: 0.9591002044989775>

---

--- 113 --
Question ID: c68b67c4fc305f84122bedd5c13bed700e413e69_11
Original Code:
```
def annotations(pairs, s, p, o):
    n0 = rdflib.BNode()
    yield n0, rdf.type, owl.Axiom
    yield n0, owl.annotatedSource, s
    yield n0, owl.annotatedProperty, p
    yield n0, owl.annotatedTarget, check_value(o)
    for predicate, object in pairs:
        yield n0, predicate, check_value(object)
```


Overlapping Code:
```
lib.BNode()
yield n0, rdf.type, owl.Axiom
yield n0, owl.annotatedSource, s
yield n0, owl.annotatedProperty, p
yield n0, owl.annotatedTarget, check_value(o)
for predicate, object in pairs:
yield n0, pr
```
<Overlap Ratio: 0.7434944237918215>

---

--- 114 --
Question ID: bb965a997cb0f8f4f1428568aaef9bf6f7320e63_1
Original Code:
```
def train(args, trainer, task, epoch_itr):
    """Train the model for one epoch."""

    # Initialize data iterator
    itr = epoch_itr.next_epoch_itr()
    progress = progress_bar.build_progress_bar(args, itr, epoch_itr.epoch, no_progress_bar='simple')

    # update parameters every N batches
    if epoch_itr.epoch <= len(args.update_freq):
        update_freq = args.update_freq[epoch_itr.epoch - 1]
    else:
        update_freq = args.update_freq[-1]

    if args.enable_parallel_backward_allred_opt and update_freq > 1:
        raise RuntimeError('--enable-parallel-backward-allred-opt is incompatible with --update-freq > 1')

    extra_meters = collections.defaultdict(lambda: AverageMeter())
    first_valid = args.valid_subset.split(',')[0]
    max_update = args.max_update or math.inf
    num_batches = len(epoch_itr)
    #begin = time.time()
    #inside = 0
    for i, sample in enumerate(progress, start=epoch_itr.iterations_in_epoch):
        #newbegin = time.time()
        #print("iter time", newbegin - begin, inside, (newbegin - begin - inside)*1000)
        #begin = newbegin
        if i < num_batches - 1 and (i + 1) % update_freq > 0:
            # buffer updates according to --update-freq
            trainer.train_step(sample, update_params=False, last_step=(i == len(itr)-1))
            continue
        else:
            log_output = trainer.train_step(sample, update_params=True, last_step=(i == len(itr)-1))

        # log mid-epoch stats
        stats = get_training_stats(trainer)
        for k, v in log_output.items():
            if k in ['loss', 'nll_loss', 'sample_size']:
                continue  # these are already logged above
            if 'loss' in k:
                extra_meters[k].update(v, log_output['sample_size'])
            else:
                extra_meters[k].update(v)
            stats[k] = extra_meters[k].avg
        progress.log(stats)

        # ignore the first mini-batch in words-per-second calculation
        if i == 0:
            trainer.get_meter('wps').reset()

        if args.profile is not None and i == args.profile:
            import sys
            sys.exit()

        num_updates = trainer.get_num_updates()
        if args.save_interval_updates > 0 and num_updates % args.save_interval_updates == 0:
            valid_losses = validate(args, trainer, task, epoch_itr, [first_valid])
            save_checkpoint(args, trainer, epoch_itr, valid_losses[0])

        if num_updates >= max_update:
            break
        #end = time.time()
        #inside = end - begin

    # log end-of-epoch stats
    stats = get_training_stats(trainer)
    for k, meter in extra_meters.items():
        stats[k] = meter.avg
    progress.print(stats)

    # reset training meters
    for k in ['train_loss', 'train_nll_loss', 'wps', 'ups', 'wpb', 'bsz', 'clip']:
        meter = trainer.get_meter(k)
        if meter is not None:
            meter.reset()
```


Overlapping Code:
```
ain(args, trainer, task, epoch_itr):
"""Train the model for one epoch."""
# Initialize data iterator
itr = epoch_itr.next_epoch_itr()
progress = progress_bar.build_progress_bar(args, itr, epoch_itr.epoch, no_progress_bar='simple')
# update parameters every N batches
if epoch_itr.epoch <= len(args.update_freq):
update_freq = args.update_freq[epoch_itr.epoch - 1]
else:
update_freq = args.update_freq[-1]
if args.enable_parallel_backward_allred_opt and update_freq > 1:
raise RuntimeError('--enable-parallel-backward-allred-opt is incompatible with --update-freq > 1')
extra_meters = collections.defaultdict(lambda: AverageMeter())
first_valid = args.valid_subset.split(',')[0]
max_update = args.max_update or math.inf
num_batches = len(epoch_itr)
#begin = time.time()
#inside = 0
for i, sample in enumerate(progress, start=epoch_itr.iterations_in_epoch):
#newbegin = time.time()
#print("iter time", newbegin - begin, inside, (newbegin - begin - inside)*1000)
#begin = newbegin
if i < num_batches - 1 and (i + 1) % update_freq > 0:
# buffer updates according to --update-freq
trainer.train_step(sample, update_params=False, last_step=(i == len(itr)-1))
continue
else:
log_output = trainer.train_step(sample, update_params=True, last_step=(i == len(itr)-1))
# log mid-epoch stats
stats = get_training_stats(trainer)
for k, v in log_output.items():
if k in ['loss', 'nll_loss', 'sample_size']:
continue # these are already logged above
if 'loss' in k:
extra_meters[k].update(v, log_output['sample_size'])
else:
extra_meters[k].update(v)
stats[k] = extra_meters[k].avg
progress.log(stats)
# ignore the first mini-batch in words-per-second calculation
if i == 0:
trainer.get_meter('wps').reset()
if args.profile is not None and i == args.profile:
import sys
sys.exit()
num_updates = trainer.get_num_updates()
if args.save_interval_updates > 0 and num_updates % args.save_interval_updates == 0:
valid_losses = validate(args, trainer, task, epoch_itr, [first_valid])
save_checkpoint(args, trainer, epoch_itr, valid_losses[0])
if num_updates >= max_update:
brea
```
<Overlap Ratio: 0.9966035904900534>

---

--- 115 --
Question ID: 559d52f3610fcb535e53d457b1766f696c43f428_0
Original Code:
```
def rectangle(x, y, width, height):                             # rectangle(x, y, width, height) 함수
    "Draw rectangle at (x, y) with given width and height."     # 이 함수는 게임판을 초기화하는 함수이다.
    up()
    goto(x, y)
    down()
    begin_fill()
    for count in range(2):
        forward(width)
        left(90)
        forward(height)
        left(90)
    end_fill()
```


Overlapping Code:
```
ht): # rectangle(x, y, width, height) 함수
"Draw rectangle at (x, y) with given width and height." # 이 함수는 게임판을 초기화하는 함수이다.
up()
goto(x, y)
down()
begin_fill()
for count in range(2):
forward(width)
left(90)
forward(height)
left(90)
end_fill
```
<Overlap Ratio: 0.8782287822878229>

---

--- 116 --
Question ID: 7eceddef13801c878c30f3c472cc75fd73ad78d6_1
Original Code:
```
def readStrFromFile(filePath):
	"""
	从文件中读取字符串str
	param filePath: 文件路径
	return string : 文本字符串
	"""
	with open(filePath, "rb") as f:
		string = f.read()
	return string
```


Overlapping Code:
```
eadStrFromFile(filePath):
"""
从文件中读取字符串str
param filePath: 文件路径
return string : 文本字符串
"""
with open(filePath, "rb") as f:
string = f.read()
return str
```
<Overlap Ratio: 0.9493670886075949>

---

--- 117 --
Question ID: 3dcb8340aa86856ec9981efc2a42ec3178f7c664_3
Original Code:
```
@bp.route('/search', methods=['GET'])
def search():
    searchcontent = request.args.get("content")
    if searchcontent=="" or searchcontent is None:
        return ""
    try:
      result=  zjb_search(browser, searchcontent)
    except:
        print("Error with searchcontent " + searchcontent)
        sys.exit(1)

    content = json.dumps(result)
    resp = httputil.Response_headers(content)
    return resp
```


Overlapping Code:
```
bp.route('/search', methods=['GET'])
def search():
searchcontent = request.args.get("content")
if searchcontent=="" or searchcontent is None:
return ""
try:
result= zjb_search(browser, searchcontent)
except:
print("Error with searchcontent " + searchcontent)
sys.exit(1)
content = json.dumps(result)
resp = httputil.Response_head
```
<Overlap Ratio: 0.9293785310734464>

---

--- 118 --
Question ID: cb3525a7d07e02414bdc4f95e6b95eab2b68b284_6
Original Code:
```
@airflow.command()
@click.option('--name', prompt='What is the name of your dag?',
              help="Name of the new dag to create",
              metavar='<DAG>')
@click.option('-f', '--format', 'output_format',
              help="format of the configuration file (default is hocon)",
              type=click.Choice(['json', 'hocon']),
              default='hocon')
@click.argument('path', type=click.Path())
@click.version_option(version=__version__)
def new(name, output_format, path):
    """Create a new DAG job"""
    # TODO to implement
    logging.error("Not implemented yet %s %s %s",
                  name, output_format, path)
```


Overlapping Code:
```
()
@click.option('--name', prompt='What is the name of your dag?',
help="Name of the new dag to create",
metavar='<DAG>')
@click.option('-f', '--format', 'output_format',
help="format of the configuration file (default is hocon)",
type=click.Choice(['json', 'hocon']),
default='hocon')
@click.argument('path', type=click.Path())
@click.version_option(version=__version__)
def new(name, output_format, path):
"""Create a new DAG job"""
# TODO to implement
logging.error("Not implemented yet %s %s %s",
name
```
<Overlap Ratio: 0.9300184162062615>

---

--- 119 --
Question ID: 3c820e9c53d427ea0cd4f8ddd361fd3b7d37f04b_1
Original Code:
```
@pytest.yield_fixture
def rmock():
    with requests_mock.mock() as rmock:
        real_register_uri = rmock.register_uri

        def register_uri_with_complete_qs(*args, **kwargs):
            if 'complete_qs' not in kwargs:
                kwargs['complete_qs'] = True

            return real_register_uri(*args, **kwargs)

        rmock.register_uri = register_uri_with_complete_qs

        yield rmock
```


Overlapping Code:
```
@pytest.yield_fixture
def rmock():
with requests_mock.mock() as rmock:
real_register_uri = rmock.register_uri
def register_uri_with_complete_qs(*args, **kwargs):
if 'complete_qs' not in kwargs:
kwargs['complete_qs'] = True
return real_register_uri(*args, **kwargs)
rmock.register_uri = register_uri_with_com
```
<Overlap Ratio: 0.9388379204892966>

---

--- 120 --
Question ID: 542190e3b5ee0862eefa27377bd21469fe4daedc_1
Original Code:
```
def main(argv = None):
	if argv is None:
		argv = sys.argv[1:] # pragma: no cover

	sumode = 'not'
	if '--sumode-pre' in argv:
		argv.remove('--sumode-pre')
		sumode = 'pre'
	elif '--sumode-post' in argv:
		argv.remove('--sumode-post')
		sumode = 'post'

	_parser = flags.new('sadm', desc = 'deploy sadm env')
	args = _getArgs(_parser, argv)
	log.debug("deploy %s/%s sumode=%s" % (args.profile, args.env, sumode))

	if sumode == 'not' and sh.getuid() == 0:
		log.error('do not run as root')
		return 9

	try:
		cmd = args.command
	except AttributeError: # pragma: no cover
		log.error('invalid usage')
		_parser.print_usage()
		return 1
	log.debug("dispatch command %s" % cmd)

	if args.command == 'import':
		return loader.main(args)

	return deploy.main(args, sumode)
```


Overlapping Code:
```
def main(argv = None):
if argv is None:
argv = sys.argv[1:] # pragma: no cover
sumode = 'not'
if '--sumode-pre' in argv:
argv.remove('--sumode-pre')
sumode = 'pre'
elif '--sumode-post' in argv:
argv.remove('--sumode-post')
sumode = 'post'
_parser = flags.new('sadm', desc = 'deploy sadm env')
args = _getArgs(_parser, argv)
log.debug("deploy %s/%s sumode=%s" % (args.profile, args.env, sumode))
if sumode == 'not' and sh.getuid() == 0:
log.error('do not run as root')
return 9
try:
cmd = args.command
except AttributeError: # pragma: no cover
log.error('invalid usage')
_parser.print_usage()
return 1
log.debug("dispatch command %s" % cmd)
if args.command == 'import':
return loader.main(args)
retu
```
<Overlap Ratio: 0.9614325068870524>

---

--- 121 --
Question ID: d20aa03a15a837c91185bec2a28b723f48ec4b9e_0
Original Code:
```
@app.route("/upload", methods=["POST"], cors=True)
@app.pass_event
def upload_job_spec(event: Dict, body: str) -> Tuple[str, str, str]:
    """Send Job definition to process."""
    if event.get("isBase64Encoded"):
        body = base64.b64decode(body).decode()

    jobid = get_hash(body=body, version=app_version)
    body = json.loads(body)

    # Check if we are not overwriding a mosaic
    mosaicid = body.get("mosaicid", jobid)

    # TODO
    # Validate schema
    key = f"jobs/{jobid}.json"
    bucket = os.environ["MOSAIC_BUCKET"]
    _aws_put_data(key, bucket, json.dumps(body).encode("utf-8"))
    return ("OK", "text/plain", mosaicid)
```


Overlapping Code:
```
POST"], cors=True)
@app.pass_event
def upload_job_spec(event: Dict, body: str) -> Tuple[str, str, str]:
"""Send Job definition to process."""
if event.get("isBase64Encoded"):
body = base64.b64decode(body).decode()
jobid = get_hash(body=body, version=app_version)
body = json.loads(body)
# Check if we are not overwriding a mosaic
mosaicid = body.get("mosaicid", jobid)
# TODO
# Validate schema
key = f"jobs/{jobid}.json"
bucket = os.environ["MOSAIC_BUCKET"]
_aws_put_data(key, bucket, json.dumps(body).encode("utf-8"))
return ("OK", "text/plain", mos
```
<Overlap Ratio: 0.935374149659864>

---

--- 122 --
Question ID: 7ca1eae2e575cb3df492f94b04f0fb4f95a03c9b_0
Original Code:
```
def test_direct_dependencies(mock_packages):
    out = dependencies('mpileaks')
    actual = set(re.split(r'\s+', out.strip()))
    expected = set(['callpath'] + mpis)
    assert expected == actual
```


Overlapping Code:
```
irect_dependencies(mock_packages):
out = dependencies('mpileaks')
actual = set(re.split(r'\s+', out.strip()))
expected = set(['callpath'] + mpis)
asse
```
<Overlap Ratio: 0.8287292817679558>

---

--- 123 --
Question ID: 5e3ad83c20d80570bad4f49c935e0ac2dcf12632_2
Original Code:
```
def ToggleFullscreen():
	global_status["settings"]["display"]["fullscreen"] = not global_status["settings"]["display"]["fullscreen"]
	if global_status["settings"]["display"]["fullscreen"]:
		global_status["player"]["pos"][1] += GetSystemMetrics(1)-global_status["settings"]["display"]["size"][1]
		window = pygame.display.set_mode((GetSystemMetrics(0), GetSystemMetrics(1)), pygame.FULLSCREEN)
		global_status["settings"]["display"]["size"] = [GetSystemMetrics(0), GetSystemMetrics(1)]
	else:
		global_status["player"]["pos"][1] += 640-global_status["settings"]["display"]["size"][1]
		global_status["settings"]["display"]["size"] = [1024, 640]
		window = pygame.display.set_mode((global_status["settings"]["display"]["size"][0], global_status["settings"]["display"]["size"][1]), pygame.RESIZABLE)
	if "back" in global_status["assets"]: global_status["assets"]["back"] = pygame.transform.scale(global_status["assets"]["back"], global_status['settings']['display']['size']).convert()
	global_status["assets"]["mmback"] = pygame.transform.scale(global_status["assets"]["mmback"], global_status['settings']['display']['size']).convert()
	global_status['assets']['opacity'] = global_status['assets']['opacity'] = pygame.transform.scale(pygame.image.load('assets/ui/opacity.png'), global_status["settings"]["display"]["size"])
```


Overlapping Code:
```
tatus["settings"]["display"]["fullscreen"] = not global_status["settings"]["display"]["fullscreen"]
if global_status["settings"]["display"]["fullscreen"]:
global_status["player"]["pos"][1] += GetSystemMetrics(1)-global_status["settings"]["display"]["size"][1]
window = pygame.display.set_mode((GetSystemMetrics(0), GetSystemMetrics(1)), pygame.FULLSCREEN)
global_status["settings"]["display"]["size"] = [GetSystemMetrics(0), GetSystemMetrics(1)]
else:
global_status["player"]["pos"][1] += 640-global_status["settings"]["display"]["size"][1]
global_status["settings"]["display"]["size"] = [1024, 640]
window = pygame.display.set_mode((global_status["settings"]["display"]["size"][0], global_status["settings"]["display"]["size"][1]), pygame.RESIZABLE)
if "back" in global_status["assets"]: global_status["assets"]["back"] = pygame.transform.scale(global_status["assets"]["back"], global_status['settings']['display']['size']).convert()
global_status["assets"]["mmback"] = pygame.transform.scale(global_status["assets"]["mmback"], global_status['settings']['display']['size']).convert()
global_status['assets']['opacity'] = global_status['assets']['opacity'] = pygame.transform.scale(pygame.image.load('assets/ui/opacity.png'), global_status["settings"]["display"]["size"]
```
<Overlap Ratio: 0.9746738296239448>

---

--- 124 --
Question ID: 52b7a9b3d521ecd2170c2282c7b86cccfa2131c6_2
Original Code:
```
def main():
    grid = []
    with open('input', 'r') as fp:
        for line in fp.read().split('\n'):
            grid.append([strToInt(c) for c in line])
    gridLen = len(grid)
    frame = 0
    
    while frame < 100:
        newGrid = [[0 for _ in range(gridLen)] for _ in range(gridLen)]
        for x in range(gridLen):
            for y in range(gridLen):
                s = getArround(grid, x, y)
                if (s == 2 or s == 3) and grid[x][y] == 1:
                    newGrid[x][y] = 1
                elif s == 3 and grid[x][y] == 0:
                    newGrid[x][y] = 1
                # enable this condition for part 2
                # elif (x,y) in [(0,0), (0, gridLen-1), (gridLen-1, 0), (gridLen-1, gridLen-1)]:
                #     newGrid[x][y] = 1
                else:
                    newGrid[x][y] = 0
        grid = newGrid
        frame += 1

    total = 0
    for line in grid:
        total += sum(line)

    print(total)
```


Overlapping Code:
```
with open('input', 'r') as fp:
for line in fp.read().split('\n'):
grid.append([strToInt(c) for c in line])
gridLen = len(grid)
frame = 0

while frame < 100:
newGrid = [[0 for _ in range(gridLen)] for _ in range(gridLen)]
for x in range(gridLen):
for y in range(gridLen):
s = getArround(grid, x, y)
if (s == 2 or s == 3) and grid[x][y] == 1:
newGrid[x][y] = 1
elif s == 3 and grid[x][y] == 0:
newGrid[x][y] = 1
# enable this condition for part 2
# elif (x,y) in [(0,0), (0, gridLen-1), (gridLen-1, 0), (gridLen-1, gridLen-1)]:
# newGrid[x][y] = 1
else:
newGrid[x][y] = 0
grid = newGrid
frame += 1
total = 0
for line in grid:
total += sum(line)
print(tot
```
<Overlap Ratio: 0.9630723781388478>

---

--- 125 --
Question ID: d5fd514c368625c8aa388aea35074a0228fce326_7
Original Code:
```
def test_build_classifier_input_output_shapes():
    classifier = build_classifier()
    assert classifier.input.get_shape().as_list() == [None, None, None, 3]
    assert classifier.output.get_shape().as_list() == [None, 2]
```


Overlapping Code:
```
lassifier_input_output_shapes():
classifier = build_classifier()
assert classifier.input.get_shape().as_list() == [None, None, None, 3]
assert classif
```
<Overlap Ratio: 0.7109004739336493>

---

--- 126 --
Question ID: 6c01ec447021c6f4e78ec4a05f0cef94c058a5fb_1
Original Code:
```
async def link(task1, task2, propagate=False, logger=None):
    """
    Create a unidirectional link between two tasks,
    such that an exception raised in task2 
    result in cancellation of task1.
    """
    logger = logger or logging.getLogger(__name__)
    try:
        await task2
    except:
        logger.info("link triggered on task {} following exception from task {}".format(task1, task2))
        task1.cancel()
        if propagate:
            raise
```


Overlapping Code:
```
 def link(task1, task2, propagate=False, logger=None):
"""
Create a unidirectional link between two tasks,
such that an exception raised in task2 
result in cancellation of task1.
"""
logger = logger or logging.getLogger(__name__)
try:
await task2
except:
logger.info("link triggered on task {} following exception from task {}".format(task1, task2))
```
<Overlap Ratio: 0.8974358974358975>

---

--- 127 --
Question ID: 682faf08aee493a8daa4bb569a9cfe1509ad93dc_0
Original Code:
```
@app.route('/', methods=['GET', 'POST'])
def index():
    form = MDForm()
    if form.validate_on_submit():
        # 传进来的数据初始状态为字符串
        inputs = form.packets.data
        if not inputs:
            flash('你还没有输入数据')
            return render_template('index.html', form=form)
        # feed in string
        convertor = MDConvertor(inputs.strip())
        des = form.des.data
        args = form.args.data
        ultra = form.ultra.data
        # ''.split(',') -> ['']
        bonus_values = args.split(",")  # 实际类型
        title = ultra.split(",")  # 类型域
        bonus_values = list(filter(None, bonus_values))
        title = list(filter(None, title))  # 去除空白字符
        markdown = convertor.gimmeThat(des, bonus_values, title)
        return render_template("index.html", form=form, markdown=markdown, set_tab=1)

    return render_template("index.html", form=form)
```


Overlapping Code:
```
@app.route('/', methods=['GET', 'POST'])
def index():
form = MDForm()
if form.validate_on_submit():
# 传进来的数据初始状态为字符串
inputs = form.packets.data
if not inputs:
flash('你还没有输入数据')
return render_template('index.html', form=form)
# feed in string
convertor = MDConvertor(inputs.strip())
des = form.des.data
args = form.args.data
ultra = form.ultra.data
# ''.split(',') -> ['']
bonus_values = args.split(",") # 实际类型
title = ultra.split(",") # 类型域
bonus_values = list(filter(None, bonus_values))
title = list(filter(None, title)) # 去除空白字符
markdown = convertor.gimmeThat(des, bonus_values, title)
return render_template("index.html", form=form, markdown=markdown, set_tab=1)

```
<Overlap Ratio: 0.9341736694677871>

---

--- 128 --
Question ID: 95754b0d82888e92ec67beda7a4ca0f430c704ca_2
Original Code:
```
def mocked_get_user_profiles(usernames, token=None):
    """
    mocks get_user_profiles in src/utils/user_profiles.py

    :param usernames:
    :return:
    """
    profiles = []
    for username in usernames:
        found, profile = get_data(f'UserProfile/get_profile/{username}.json')
        if not found:
            profiles.append(None)
        else:
            profiles.append(profile)
    return profiles
```


Overlapping Code:
```
f mocked_get_user_profiles(usernames, token=None):
"""
mocks get_user_profiles in src/utils/user_profiles.py
:param usernames:
:return:
"""
profiles = []
for username in usernames:
found, profile = get_data(f'UserProfile/get_profile/{username}.json')
if not found:
profiles.append(None)
else:
profile
```
<Overlap Ratio: 0.8955223880597015>

---

--- 129 --
Question ID: df21750d2032e4a1fe0859fbab7247878e3650dc_7
Original Code:
```
def test_env(monkeypatch):
    monkeypatch.setenv('CLEANROOM_ENV_VAR', '42')

    proxy = factory.create_instance(DummyClass)
    assert proxy.env() == '42'
```


Overlapping Code:
```
(monkeypatch):
monkeypatch.setenv('CLEANROOM_ENV_VAR', '42')
proxy = factory.create_instance(DummyClass)
asser
```
<Overlap Ratio: 0.7692307692307693>

---

--- 130 --
Question ID: 5b610df30a28e843f346f99db2221d8220bc29c8_1
Original Code:
```
@when('I try to publish something that is not of type Py_ps_image_data_msg')
def step_impl(context):
    bad_obj = "not the right type of object!"
    context.exception = None

    try:
        publish(bad_obj)
    except Exception as e:
        context.exception = e
```


Overlapping Code:
```
@when('I try to publish something that is not of type Py_ps_image_data_msg')
def step_impl(context):
bad_obj = "not the right type of object!"
context.exception = None
try:
publish(bad_obj)
except Exception as e:
context.exception = 
```
<Overlap Ratio: 0.9957264957264957>

---

--- 131 --
Question ID: 29fa653158c379c607c80942cfb1360111d01bae_0
Original Code:
```
def inject_config(binder):
    config_manager = SwitchBotHubConfigManager(os.path.dirname(os.path.abspath(__file__)))
    binder.bind(AbstractConfigurationManager, config_manager)
    binder.bind(AbstractMqttClient, CloudIoTCoreClient(config_manager))
    binder.bind(AbstractBotController, MockBotController(config_manager))
```


Overlapping Code:
```
_config(binder):
config_manager = SwitchBotHubConfigManager(os.path.dirname(os.path.abspath(__file__)))
binder.bind(AbstractConfigurationManager, config_manager)
binder.bind(AbstractMqttClient, CloudIoTCoreClient(config_manager))
binder.bind(Abstract
```
<Overlap Ratio: 0.8090614886731392>

---

--- 132 --
Question ID: 2466ab033bb80ae175af1d8873a42351c8e440a8_0
Original Code:
```
@mock.patch('spreadsplug.hidtrigger.hidapi.enumerate')
@mock.patch('spreadsplug.hidtrigger.hidapi.Device')
def test_trigger_loop(devicecls, hid_enumerate, plugin):
    mock_dev = mock.Mock()
    mock_dev.read.side_effect = chain(
        list(chain(repeat(None, 10), ('foo',), repeat(None, 10), ('bar',)))*6,
        repeat(None))
    hid_enumerate.return_value = [mock.Mock(), mock.Mock()]
    devicecls.return_value = mock_dev
    mock_cb = mock.Mock()
    plugin.start_trigger_loop(mock_cb)
    time.sleep(1.3)
    plugin.stop_trigger_loop()
    assert not plugin._loop_thread.is_alive()
    assert mock_cb.call_count == 6
```


Overlapping Code:
```
gger.hidapi.enumerate')
@mock.patch('spreadsplug.hidtrigger.hidapi.Device')
def test_trigger_loop(devicecls, hid_enumerate, plugin):
mock_dev = mock.Mock()
mock_dev.read.side_effect = chain(
list(chain(repeat(None, 10), ('foo',), repeat(None, 10), ('bar',)))*6,
repeat(None))
hid_enumerate.return_value = [mock.Mock(), mock.Mock()]
devicecls.return_value = mock_dev
mock_cb = mock.Mock()
plugin.start_trigger_loop(mock_cb)
time.sleep(1.3)
plugin.stop_trigger_loop()
assert not plugin._loop_thread.is_
```
<Overlap Ratio: 0.8787346221441125>

---

--- 133 --
Question ID: 5a6f639acb1b161fc4c758cee5e0d6b1c99b56d6_6
Original Code:
```
def make_index(host, port, bucket):

    s3 = boto3.client('s3')
    response = s3.list_objects_v2(Bucket=bucket, Prefix='{host}:{port}/'.format(host=host, port=port), Delimiter='/')

    print(response)

    prefixes = [p['Prefix'] for p in response.get('CommonPrefixes', [])]

    with tempfile.NamedTemporaryFile() as tmp:

        tmp.write('''
<html><head><title>Reports for {host}:{port}</title></head>
<h1>Reports for {host}:{port}</h1>
<ul>
        '''.format(**locals()).encode('utf-8'))

        for prefix in sorted(prefixes):
            print(prefix)
            dirname = prefix.split('/')[1]
            tmp.write('''
<li>
  <a href="/{prefix}report.html">
    {dirname}
  </a>
</li>
'''.format(**locals()).encode('utf-8'))

        tmp.write(b'''
</ul>
''')

        tmp.flush()
        tmp.seek(0)

        key = '{host}:{port}/index.html'.format(**locals())
        s3.put_object(Bucket=bucket, Key=key, Body=tmp, ContentType='text/html; charset=utf-8')

        print('create index:', key)
```


Overlapping Code:
```
, bucket):
s3 = boto3.client('s3')
response = s3.list_objects_v2(Bucket=bucket, Prefix='{host}:{port}/'.format(host=host, port=port), Delimiter='/')
print(response)
prefixes = [p['Prefix'] for p in response.get('CommonPrefixes', [])]
with tempfile.NamedTemporaryFile() as tmp:
tmp.write('''
<html><head><title>Reports for {host}:{port}</title></head>
<h1>Reports for {host}:{port}</h1>
<ul>
'''.format(**locals()).encode('utf-8'))
for prefix in sorted(prefixes):
print(prefix)
dirname = prefix.split('/')[1]
tmp.write('''
<li>
<a href="/{prefix}report.html">
{dirname}
</a>
</li>
'''.format(**locals()).encode('utf-8'))
tmp.write(b'''
</ul>
''')
tmp.flush()
tmp.seek(0)
key = '{host}:{port}/index.html'.format(**locals())
s3.put_object(Bucket=bucket, Key=key, Body=tmp, ContentType='text/html; charse
```
<Overlap Ratio: 0.9280742459396751>

---

--- 134 --
Question ID: 83f68b9586d37d5c9d44e476e2e2a6e285a3c124_0
Original Code:
```
def parse_config_file(config_file_path, validate=False):
    """Parse the config file and return a mapping.

    Arguments:
        config_file_path {click.Path}   -- A path to a valid YAML config file.
        validate {boolean}              -- Validate config file against schema

    """
    with open(config_file_path, 'r') as stream:
        try:
            loguru.logger.info('Parse configuration file with path: {}'.format(config_file_path))
            config = yaml.safe_load(stream)
        except yaml.YAMLError as error:
            raise exceptions.InvalidConfigFileException('Config file is invalid. '
                                                        'Following error occured: {}'.format(error))
        else:
            try:
                schemas.DOCKER_CONFIG_SCHEMA.validate(config['docker'])
            except schema.SchemaError as error:
                raise exceptions.InvalidConfigFileException('Config file is invalid. '
                                                            'Following error occured: {}'.format(error))

            else:
                loguru.logger.success('Configuration file is valid.')
                return config
```


Overlapping Code:
```
_config_file(config_file_path, validate=False):
"""Parse the config file and return a mapping.
Arguments:
config_file_path {click.Path} -- A path to a valid YAML config file.
validate {boolean} -- Validate config file against schema
"""
with open(config_file_path, 'r') as stream:
try:
loguru.logger.info('Parse configuration file with path: {}'.format(config_file_path))
config = yaml.safe_load(stream)
except yaml.YAMLError as error:
raise exceptions.InvalidConfigFileException('Config file is invalid. '
'Following error occured: {}'.format(error))
else:
try:
schemas.DOCKER_CONFIG_SCHEMA.validate(config['docker'])
except schema.SchemaError as error:
raise exceptions.InvalidConfigFileException('Config file is invalid. '
'Following error occured: {}'.format(error))
else:
loguru.logger.success('
```
<Overlap Ratio: 0.9378663540445487>

---

--- 135 --
Question ID: 97ff55103330230c0917ec1e7fcd7025f28507be_3
Original Code:
```
def get_header_row():
    header = ['Country', 'Person', 'Scorer']
    for question in TCB_QUESTIONS:
        header.append(f'{question}_relevancy')
        header.append(f'{question}_priority')
        header.append(f'{question}_score')
        header.append(f'{question}_notes')
    return header
```


Overlapping Code:
```
r_row():
header = ['Country', 'Person', 'Scorer']
for question in TCB_QUESTIONS:
header.append(f'{question}_relevancy')
header.append(f'{question}_priority')
header.append(f'{question}_score')
header.
```
<Overlap Ratio: 0.7874015748031497>

---

--- 136 --
Question ID: ae7158d6c11da91ba8f01310a5aad3a671b9e9ee_0
Original Code:
```
def polish_string(title, useless_ending='xxx'):
    """Return a safe directory name."""
    title = re.sub("《|》", "", title).strip()
    title = re.sub("[/\\\?\|<>:\"\*]", "_", title).strip()
    uselessEndings = [".txt", "txt", '全文阅读', '最新章节', useless_ending]
    # for ending in uselessEndings:
    #     if title[-len(ending):] == ending:
    #         title = title[0:-len(ending)]
    for ending in uselessEndings:
        position = title.find(ending)
        position = position if position != -1 else len(title)
        # print('{0}-{1}-{2}'.format(ending, title, position))
        title = title[0:position]
    return title
```


Overlapping Code:
```
x'):
"""Return a safe directory name."""
title = re.sub("《|》", "", title).strip()
title = re.sub("[/\\\?\|<>:\"\*]", "_", title).strip()
uselessEndings = [".txt", "txt", '全文阅读', '最新章节', useless_ending]
# for ending in uselessEndings:
# if title[-len(ending):] == ending:
# title = title[0:-len(ending)]
for ending in uselessEndings:
position = title.find(ending)
position = position if position != -1 else len(title)
# print('{0}-{1}-{2}'.format(ending, title, position))
title = title[0:position]
re
```
<Overlap Ratio: 0.9041591320072333>

---

--- 137 --
Question ID: 73ddfa2398fea7404aa54690d3a3b3f61838dee1_1
Original Code:
```
def process_expertise_change(inputs):
    sent = []
    for i in inputs:
        sent.append(Expertise.query.filter_by(course_prefix=i.split('-')[0],
                                              course_level=i.split('-')[1]).first())

    user = User.query.get(current_user.id)
    current = user.fields.all()

    # checks the sent fields against current fields
    # looks for expertise that exist in sent but not in current fields
    # adds the new fields
    for s in sent:
        if s not in current:
            user.fields.append(s)

    # looks for expertise that exist in current but not in sent
    # removes them from current
    for c in current:
        if c not in sent:
            user.fields.remove(c)

    db.session.commit()
```


Overlapping Code:
```
_change(inputs):
sent = []
for i in inputs:
sent.append(Expertise.query.filter_by(course_prefix=i.split('-')[0],
course_level=i.split('-')[1]).first())
user = User.query.get(current_user.id)
current = user.fields.all()
# checks the sent fields against current fields
# looks for expertise that exist in sent but not in current fields
# adds the new fields
for s in sent:
if s not in current:
user.fields.append(s)
# looks for expertise that exist in current but not in sent
# removes them from current
for c in current:
if c not in sent:
user.fields.
```
<Overlap Ratio: 0.9166666666666666>

---

--- 138 --
Question ID: 0250c17ee0f5b6ecbb27511538c3b3e5ff4e7c73_1
Original Code:
```
def read_forcefield_template(template_filename):
    """Read-in the forcefield template. The template is constructed from a functional forcefield file by replacing all optimizable numerical values with variable names enclosed within dual angled brackets << and >>.

    :param template_filename: Name of the forcefield template file to be read-in
    :type template_filename: str
    """
    while True: # Force-read the template forcefield. This will loop until something is read-in. This is required if multiple ranks read the same file at the same time
        time.sleep(np.random.rand())
        with open(template_filename) as forcefield_template_file:
            template_string = forcefield_template_file.read()
        if len(template_string) > 0:
            break

    return template_string
```


Overlapping Code:
```
ef read_forcefield_template(template_filename):
"""Read-in the forcefield template. The template is constructed from a functional forcefield file by replacing all optimizable numerical values with variable names enclosed within dual angled brackets << and >>.
:param template_filename: Name of the forcefield template file to be read-in
:type template_filename: str
"""
while True: # Force-read the template forcefield. This will loop until something is read-in. This is required if multiple ranks read the same file at the same time
time.sleep(np.random.rand())
with open(template_filename) as forcefield_template_file:
template_string = forcefield_template_file.read()
if len(template_string) > 0:

```
<Overlap Ratio: 0.9602194787379973>

---

--- 139 --
Question ID: b3eda0810900ed468f05f7bf351efa2c5217f283_12
Original Code:
```
def binary_error(preds, train_data):
    labels = train_data.get_label()
    e=np.mean(np.square(np.log10(preds+1)-np.log10(labels+1)))
    return 'myloss',e,False
```


Overlapping Code:
```
ef binary_error(preds, train_data):
labels = train_data.get_label()
e=np.mean(np.square(np.log10(preds+1)
```
<Overlap Ratio: 0.695364238410596>

---

--- 140 --
Question ID: 3b2206a3c64fbcf5d5a7d28a82c6e758a7a76d84_9
Original Code:
```
def no_response_from_crawl(stats: Optional[Dict]) -> bool:
    """
    Check that the stats dict has received an HTTP 200 response

    :param stats: Crawl stats dictionary
    :return: True if the dict exists and has no 200 response
    """
    if not stats or not isinstance(stats, Dict):
        return False

    status_codes = stats.get("status_codes", {})
    if not status_codes or not isinstance(status_codes, Dict):
        return False

    return 200 not in status_codes
```


Overlapping Code:
```
nal[Dict]) -> bool:
"""
Check that the stats dict has received an HTTP 200 response
:param stats: Crawl stats dictionary
:return: True if the dict exists and has no 200 response
"""
if not stats or not isinstance(stats, Dict):
return False
status_codes = stats.get("status_codes", {})
if not status_codes or not isinstance(status_codes, Dict):
return
```
<Overlap Ratio: 0.8215962441314554>

---

--- 141 --
Question ID: a7bcb84b6ba27514334838fadcbe124f27d5d9c4_0
Original Code:
```
@pytest.mark.parametrize(
    "input_text, end_session",
    [
        ("Test", False),
        ("Test", True),
        ("\n\t", False),
        (1, False),
        (True, False),
        (0.5, False)
    ]
)
def test_build_text_response(input_text, end_session):
    """
    response.text_response(text) should format the text for Alexa so that Alexa
    will read the text to the user in response to their query
    """
    res = response.plaintext_response(input_text, end_session=end_session)

    res_json = json.loads(res)

    assert res_json['body']['response']['outputSpeech']['type'] == 'PlainText'
    assert res_json['body']['response']['outputSpeech']['text'] == str(input_text)
    assert res_json['body']['response']['shouldEndSession'] == end_session
```


Overlapping Code:
```
ion",
[
("Test", False),
("Test", True),
("\n\t", False),
(1, False),
(True, False),
(0.5, False)
]
)
def test_build_text_response(input_text, end_session):
"""
response.text_response(text) should format the text for Alexa so that Alexa
will read the text to the user in response to their query
"""
res = response.plaintext_response(input_text, end_session=end_session)
res_json = json.loads(res)
assert res_json['body']['response']['outputSpeech']['type'] == 'PlainText'
assert res_json['body']['response']['outputSpeech']['text'] == str(input_text)
assert res_json['body']['response']['shouldEndSes
```
<Overlap Ratio: 0.8982035928143712>

---

--- 142 --
Question ID: 51b536d9c1fbc9f9bf6246ab80344c713f280b7d_1
Original Code:
```
def create_schema(name, **options):
    """
    This function creates a schema and perform a syncdb on it.
    As we call some syncdb and migrate management commands, we can't rely on
    transaction support.
    We are going to catch any exception (including SystemExit).
    """
    try:
        cursor = connection.cursor()
        # We can't use params with system names
        cursor.execute('CREATE SCHEMA "%s"' % escape_schema_name(name))
        transaction.commit_unless_managed()
    except BaseException:
        transaction.rollback_unless_managed()
        raise

    try:
        defaults = {
            'verbosity': 0,
            'traceback': None,
            'noinput': True
        }
        defaults.update(options)

        sync_options = options
        # We never want migration to launch with syncdb call
        sync_options['migrate'] = False

        _, isolated_apps = get_apps()

        _syncdb_apps(isolated_apps, schema=name, force_close=False, **sync_options)
        _migrate_apps(get_migration_candidates(isolated_apps), schema=name, force_close=False, **options)
        schema_store.reset_path()
    except BaseException:
        transaction.rollback_unless_managed()
        drop_schema(name)
        raise
```


Overlapping Code:
```
a(name, **options):
"""
This function creates a schema and perform a syncdb on it.
As we call some syncdb and migrate management commands, we can't rely on
transaction support.
We are going to catch any exception (including SystemExit).
"""
try:
cursor = connection.cursor()
# We can't use params with system names
cursor.execute('CREATE SCHEMA "%s"' % escape_schema_name(name))
transaction.commit_unless_managed()
except BaseException:
transaction.rollback_unless_managed()
raise
try:
defaults = {
'verbosity': 0,
'traceback': None,
'noinput': True
}
defaults.update(options)
sync_options = options
# We never want migration to launch with syncdb call
sync_options['migrate'] = False
_, isolated_apps = get_apps()
_syncdb_apps(isolated_apps, schema=name, force_close=False, **sync_options)
_migrate_apps(get_migration_candidates(isolated_apps), schema=name, force_close=False, **options)
schema_store.reset_path()
except BaseException:
transaction.r
```
<Overlap Ratio: 0.9368836291913215>

---

--- 143 --
Question ID: c0357787df28351bf9d0dfc1d6097653540be386_22
Original Code:
```
def supplyNamesEFOTU(ef_otu, ef_name, otu_name):
    ef_otu_new = []
    for pert in ef_otu:
        ef1 = ef_name[pert[0]]
        otu1 = otu_name[pert[1]]
        weight = pert[2]
        ef_otu_new.append([ef1, otu1, weight])
    
    return ef_otu_new
```


Overlapping Code:
```
me, otu_name):
ef_otu_new = []
for pert in ef_otu:
ef1 = ef_name[pert[0]]
otu1 = otu_name[pert[1]]
weight = pert[2]
ef_otu_new.append([ef1, otu1, weig
```
<Overlap Ratio: 0.7246376811594203>

---

--- 144 --
Question ID: 1163848a901f0841c800345b1f75dc8b119d3611_1
Original Code:
```
def part_1(puzzle):
    answer = -1
    pattern = re.compile("^0{5}")
    while True:
        answer += 1
        hasher = md5()
        attempt = puzzle + str(answer)
        hasher.update(attempt.encode("utf-8"))
        digest = hasher.hexdigest()
        if re.search(pattern, digest):
            return answer
```


Overlapping Code:
```
r = -1
pattern = re.compile("^0{5}")
while True:
answer += 1
hasher = md5()
attempt = puzzle + str(answer)
hasher.update(attempt.encode("utf-8"))
digest = hasher.hexdigest()
if re.search(pattern, digest):
r
```
<Overlap Ratio: 0.8477366255144033>

---

--- 145 --
Question ID: 95025b8ecc0433bcac856af7d80552724c5265d7_18
Original Code:
```
def listPersons(date, computer_id=None, shift_id=None):
  global _PERSONS, _PERSONS_PER_PID

  if not _PERSONS:
    listShifts()
    listComputers()
    where = [('start_date', '<=', date), 'and', ('end_date', '>=', date)]
    _PERSONS = database.select('persons', where=where, order='name')
    _PERSONS_PER_PID.update({ p['pid']: p for p in _PERSONS })
    for p in _PERSONS: _updatePerson(p, date)

  pl = _PERSONS

  if computer_id is not None:
    pl = [p for p in pl if p['computer_id'] == computer_id]
  if shift_id is not None:
    pl = [p for p in pl if p['shift_id'] == shift_id]

  return pl
```


Overlapping Code:
```
date, computer_id=None, shift_id=None):
global _PERSONS, _PERSONS_PER_PID
if not _PERSONS:
listShifts()
listComputers()
where = [('start_date', '<=', date), 'and', ('end_date', '>=', date)]
_PERSONS = database.select('persons', where=where, order='name')
_PERSONS_PER_PID.update({ p['pid']: p for p in _PERSONS })
for p in _PERSONS: _updatePerson(p, date)
pl = _PERSONS
if computer_id is not None:
pl = [p for p in pl if p['computer_id'] == computer_id]
if shift_id is not None:
pl = [p for p in pl i
```
<Overlap Ratio: 0.9025270758122743>

---

--- 146 --
Question ID: 6229d1560e40771a89efe3b988f92cb260998cb2_0
Original Code:
```
def get_template(template_name):
    """ Function to get the psrfits template from the templates module dir

       Parameter
       ---------
       template_name: str
           The name of the built-in template.
       Return
       ------
           Full path to the template file. If the request file does not exists,
           it will return None. 
    """
    template_path = os.path.join(__module_dir__, template_name)
    if os.path.exists(template_path):
        return template_path
    else:
        return None
```


Overlapping Code:
```
Function to get the psrfits template from the templates module dir
Parameter
---------
template_name: str
The name of the built-in template.
Return
------
Full path to the template file. If the request file does not exists,
it will return None. 
"""
template_path = os.path.join(__module_dir__, template_name)
if os.path.exists(template_path):
return template_path
el
```
<Overlap Ratio: 0.8758949880668258>

---

--- 147 --
Question ID: 85641744f156aac3d10e36e2fade7a219b65e031_0
Original Code:
```
def find_modules():
  """Finds all the modules in the core package imported."""

  tf_modules = []
  for _, name, _ in pkgutil.walk_packages(
      core.__path__, prefix=core.__name__ + '.'):
    try:
      tf_modules.append(__import__(name, fromlist=['']))
    except (ImportError, AttributeError):
      pass

  return tf_modules
```


Overlapping Code:
```
ind_modules():
"""Finds all the modules in the core package imported."""
tf_modules = []
for _, name, _ in pkgutil.walk_packages(
core.__path__, prefix=core.__name__ + '.'):
try:
tf_modules.append(__import__(name, fromlist=['']))
except (ImportError, AttributeError):
pass
return t
```
<Overlap Ratio: 0.9525423728813559>

---

--- 148 --
Question ID: 13c1c0b85cfc57cbefee6425cbf5890b144bd8df_0
Original Code:
```
def remove_blank(x):
	"""creating a function to remove the empty words"""
	if(x != ""):
		return(x)
```


Overlapping Code:
```
remove_blank(x):
"""creating a function to remove the empty words"""
if(x 
```
<Overlap Ratio: 0.7789473684210526>

---

--- 149 --
Question ID: ef3baf31c452befa79cb785eae94479a8ef80ff8_2
Original Code:
```
def json_date_handler(object):
    if isinstance(object, (datetime.datetime, datetime.date)):
        return object.isoformat()

    return None
```


Overlapping Code:
```
def json_date_handler(object):
if isinstance(object, (datetime.datetime, datetime.date)):
return object.isoformat()
return No
```
<Overlap Ratio: 0.984251968503937>

---

--- 150 --
Question ID: 721fdfeb6f8ae6f20c3b89353ed74fcc6649c7f5_0
Original Code:
```
@pytest.mark.parametrize(
    'added_exchanges',
    [(Location.BINANCE, Location.POLONIEX, Location.BITTREX, Location.BITMEX, Location.KRAKEN)],
)
@pytest.mark.parametrize('ethereum_accounts', [[ETH_ADDRESS1, ETH_ADDRESS2, ETH_ADDRESS3]])
@pytest.mark.parametrize('mocked_price_queries', [prices])
@pytest.mark.parametrize(
    'start_ts,end_ts',
    [(0, 1601040361), (1539713237, 1539713238)],
)
def test_query_history(rotkehlchen_api_server_with_exchanges, start_ts, end_ts):
    """Test that the history processing REST API endpoint works. Similar to test_history.py

    Both a test for full and limited time range.
    """
    report_id, report_result, events_result = query_api_create_and_get_report(
        server=rotkehlchen_api_server_with_exchanges,
        start_ts=start_ts,
        end_ts=end_ts,
        prepare_mocks=True,
    )

    # Simply check that the results got returned here. The actual correctness of
    # accounting results is checked in other tests such as test_simple_accounting
    assert report_result['entries_found'] == 1
    assert report_result['entries_limit'] == FREE_REPORTS_LOOKUP_LIMIT
    report = report_result['entries'][0]
    assert len(report) == 11  # 11 entries in the report api endpoint
    assert report['first_processed_timestamp'] == 1428994442
    assert report['last_processed_timestamp'] == end_ts if end_ts == 1539713238 else 1566572401
    assert report['identifier'] == report_id
    assert report['size_on_disk'] > 0

    overview = report['overview']
    if start_ts == 0:
        assert len(overview) == 6
        assert overview[str(AccountingEventType.ASSET_MOVEMENT)] is not None
        assert overview[str(AccountingEventType.LOAN)] is not None
        assert overview[str(AccountingEventType.MARGIN_POSITION)] is not None
        assert overview[str(AccountingEventType.TRANSACTION_EVENT)] is not None
    else:
        assert len(overview) == 2
    assert overview[str(AccountingEventType.TRADE)] is not None
    assert overview[str(AccountingEventType.FEE)] is not None

    settings = report['settings']
    assert len(settings) == 6
    assert settings['profit_currency'] == 'EUR'
    assert settings['account_for_assets_movements'] is True
    assert settings['calculate_past_cost_basis'] is True
    assert settings['include_crypto2crypto'] is True
    assert settings['include_gas_costs'] is True
    assert settings['taxfree_after_period'] == 31536000

    assert events_result['entries_limit'] == FREE_PNL_EVENTS_LIMIT
    entries_length = 47 if start_ts == 0 else 44
    assert events_result['entries_found'] == entries_length
    assert isinstance(events_result['entries'], list)
    # TODO: These events are not actually checked anywhere for correctness
    #       A test should probably be made for their correctness, even though
    #       they are assumed correct if the overview is correct
    assert len(events_result['entries']) == entries_length

    # And now make sure that warnings have also been generated for the query of
    # the unsupported/unknown assets
    rotki = rotkehlchen_api_server_with_exchanges.rest_api.rotkehlchen
    warnings = rotki.msg_aggregator.consume_warnings()
    assert len(warnings) == 10
    assert 'poloniex trade with unknown asset NOEXISTINGASSET' in warnings[0]
    assert 'poloniex trade with unsupported asset BALLS' in warnings[1]
    assert 'withdrawal of unknown poloniex asset IDONTEXIST' in warnings[2]
    assert 'withdrawal of unsupported poloniex asset DIS' in warnings[3]
    assert 'deposit of unknown poloniex asset IDONTEXIST' in warnings[4]
    assert 'deposit of unsupported poloniex asset EBT' in warnings[5]
    assert 'poloniex loan with unsupported asset BDC' in warnings[6]
    assert 'poloniex loan with unknown asset NOTEXISTINGASSET' in warnings[7]
    assert 'bittrex trade with unsupported asset PTON' in warnings[8]
    assert 'bittrex trade with unknown asset IDONTEXIST' in warnings[9]

    errors = rotki.msg_aggregator.consume_errors()
    assert len(errors) == 3
    assert 'bittrex trade with unprocessable pair %$#%$#%#$%' in errors[0]
    assert 'Failed to read ledger event from kraken' in errors[1]
    assert 'Failed to read ledger event from kraken ' in errors[2]

    response = requests.get(
        api_url_for(
            rotkehlchen_api_server_with_exchanges,
            'historyactionableitemsresource',
        ),
    )
    assert_proper_response_with_result(response=response, status_code=HTTPStatus.OK)
    assert len(response.json()['result']['missing_acquisitions']) == 10
    assert len(response.json()['result']['missing_prices']) == 0

```


Overlapping Code:
```
@pytest.mark.parametrize(
'added_exchanges',
[(Location.BINANCE, Location.POLONIEX, Location.BITTREX, Location.BITMEX, Location.KRAKEN)],
)
@pytest.mark.parametrize('ethereum_accounts', [[ETH_ADDRESS1, ETH_ADDRESS2, ETH_ADDRESS3]])
@pytest.mark.parametrize('mocked_price_queries', [prices])
@pytest.mark.parametrize(
'start_ts,end_ts',
[(0, 1601040361), (1539713237, 1539713238)],
)
def test_query_history(rotkehlchen_api_server_with_exchanges, start_ts, end_ts):
"""Test that the history processing REST API endpoint works. Similar to test_history.py
Both a test for full and limited time range.
"""
report_id, report_result, events_result = query_api_create_and_get_report(
server=rotkehlchen_api_server_with_exchanges,
start_ts=start_ts,
end_ts=end_ts,
prepare_mocks=True,
)
# Simply check that the results got returned here. The actual correctness of
# accounting results is checked in other tests such as test_simple_accounting
assert report_result['entries_found'] == 1
assert report_result['entries_limit'] == FREE_REPORTS_LOOKUP_LIMIT
report = report_result['entries'][0]
assert len(report) == 11 # 11 entries in the report api endpoint
assert report['first_processed_timestamp'] == 1428994442
assert report['last_processed_timestamp'] == end_ts if end_ts == 1539713238 else 1566572401
assert report['identifier'] == report_id
assert report['size_on_disk'] > 0
overview = report['overview']
if start_ts == 0:
assert len(overview) == 6
assert overview[str(AccountingEventType.ASSET_MOVEMENT)] is not None
assert overview[str(AccountingEventType.LOAN)] is not None
assert overview[str(AccountingEventType.MARGIN_POSITION)] is not None
assert overview[str(AccountingEventType.TRANSACTION_EVENT)] is not None
else:
assert len(overview) == 2
assert overview[str(AccountingEventType.TRADE)] is not None
assert overview[str(AccountingEventType.FEE)] is not None
settings = report['settings']
assert len(settings) == 6
assert settings['profit_currency'] == 'EUR'
assert settings['account_for_assets_movements'] is True
assert settings['calculate_past_cost_basis'] is True
assert settings['include_crypto2crypto'] is True
assert settings['include_gas_costs'] is True
assert settings['taxfree_after_period'] == 31536000
assert events_result['entries_limit'
```
<Overlap Ratio: 0.9885964912280701>

---

--- 151 --
Question ID: fc728cedccf53c3365f38a9ea23a88c0ce989db3_13
Original Code:
```
def emit(level, message, exc_info=None, **extras):
  """Log in JSON."""
  logger = get_logger()
  if not logger:
    return

  # Include extras passed as an argument and default extras.
  all_extras = _default_extras.copy()
  all_extras.update(extras)

  path_name, line_number, method_name = get_source_location()

  if (level >= logging.ERROR and _is_running_on_app_engine()):
    # App Engine only reports errors if there is an exception stacktrace, so we
    # generate one. We don't create an exception here and then format it, as
    # that will not include frames below this emit() call. We do [:-2] on
    # the stacktrace to exclude emit() and the logging function below it (e.g.
    # log_error).
    message = (
        message + '\n' + 'Traceback (most recent call last):\n' + ''.join(
            traceback.format_stack()[:-2]) + 'LogError: ' + message)

  # We need to make a dict out of it because member of the dict becomes the
  # first class attributes of LogEntry. It is very tricky to identify the extra
  # attributes. Therefore, we wrap extra fields under the attribute 'extras'.
  logger.log(
      level,
      truncate(message, LOCAL_LOG_MESSAGE_LIMIT),
      exc_info=exc_info,
      extra={
          'extras': all_extras,
          'location': {
              'path': path_name,
              'line': line_number,
              'method': method_name
          }
      })
```


Overlapping Code:
```
 emit(level, message, exc_info=None, **extras):
"""Log in JSON."""
logger = get_logger()
if not logger:
return
# Include extras passed as an argument and default extras.
all_extras = _default_extras.copy()
all_extras.update(extras)
path_name, line_number, method_name = get_source_location()
if (level >= logging.ERROR and _is_running_on_app_engine()):
# App Engine only reports errors if there is an exception stacktrace, so we
# generate one. We don't create an exception here and then format it, as
# that will not include frames below this emit() call. We do [:-2] on
# the stacktrace to exclude emit() and the logging function below it (e.g.
# log_error).
message = (
message + '\n' + 'Traceback (most recent call last):\n' + ''.join(
traceback.format_stack()[:-2]) + 'LogError: ' + message)
# We need to make a dict out of it because member of the dict becomes the
# first class attributes of LogEntry. It is very tricky to identify the extra
# attributes. Therefore, we wrap extra fields under the attribute 'extras'.
logger.log(
level,
truncate(message, LOCAL_LOG_MESSAGE_LIMIT),
exc_info=exc_info,
extra={
'extras': all_extras,
'location': {
'path': path_name,
'line': line_number,
'method':
```
<Overlap Ratio: 0.9836065573770492>

---

--- 152 --
Question ID: 5f06325672cf4e056618b4384cfdf4036ccab257_2
Original Code:
```
def parse_args():
    """
    Parse Arguments from component
    :return:
    """
    parser = argparse.ArgumentParser()
    parser.add_argument("--input-model", help="Path of input model to create")
    parser.add_argument("--input-file", help = "Path of the file to process")
    parser.add_argument("--threshold", help = "Threshold on minimum distance from closes center")
    parser.add_argument("--temp-shared-path", help="Temporary shared path for model transfer")
    options = parser.parse_args()
    return options
```


Overlapping Code:
```
e_args():
"""
Parse Arguments from component
:return:
"""
parser = argparse.ArgumentParser()
parser.add_argument("--input-model", help="Path of input model to create")
parser.add_argument("--input-file", help = "Path of the file to process")
parser.add_argument("--threshold", help = "Threshold on minimum distance from closes center")
parser.add_argument("--temp-shared-path", help="Temporary shared path for model transfer")
options = parser.parse_args()
ret
```
<Overlap Ratio: 0.9603340292275574>

---

--- 153 --
Question ID: 85fbe81154e86cc8fbe011d9ee9e5188b8d4fcea_2
Original Code:
```
def test_shortest_path():
    test_node1 = Node(node_id=1, adjacency_dict={2: {'weight': 10, 'status': True}})
    test_node2 = Node(node_id=2, adjacency_dict={3: {'weight': 5, 'status': True}})
    test_node3 = Node(node_id=3, adjacency_dict={4: {'weight': 3, 'status': True}})
    test_node4 = Node(node_id=4, adjacency_dict={1: {'weight': 6, 'status': True}})
    test_node5 = Node(node_id=5, adjacency_dict={1: {'weight': 1, 'status': True},
                                                 3: {'weight': 2, 'status': True}})
    test_net = Network({test_node1.node_id: test_node1,
                        test_node2.node_id: test_node2,
                        test_node3.node_id: test_node3,
                        test_node4.node_id: test_node4,
                        test_node5.node_id: test_node5})

    dijkstra = Dijkstra(graph=test_net, source=test_node1.node_id)
    path, weight = dijkstra.shortest_path(destination=test_node3.node_id)
    assert path == [1, 5, 3]
    assert weight is 3

    test_net.remove_node(test_node5.node_id)
    dijkstra = Dijkstra(graph=test_net, source=test_node1.node_id)
    path, weight = dijkstra.shortest_path(destination=test_node3.node_id)
    assert path == [1, 4, 3]
    assert weight is 9

    test_net.remove_node(test_node4.node_id)
    dijkstra = Dijkstra(graph=test_net, source=test_node1.node_id)
    path, weight = dijkstra.shortest_path(destination=test_node3.node_id)
    assert path == [1, 2, 3]
    assert weight is 15

    test_net.remove_node(test_node2.node_id)
    dijkstra = Dijkstra(graph=test_net, source=test_node1.node_id)
    path, weight = dijkstra.shortest_path(destination=test_node3.node_id)
    assert path is None
    assert weight == float('inf')
```


Overlapping Code:
```
node1 = Node(node_id=1, adjacency_dict={2: {'weight': 10, 'status': True}})
test_node2 = Node(node_id=2, adjacency_dict={3: {'weight': 5, 'status': True}})
test_node3 = Node(node_id=3, adjacency_dict={4: {'weight': 3, 'status': True}})
test_node4 = Node(node_id=4, adjacency_dict={1: {'weight': 6, 'status': True}})
test_node5 = Node(node_id=5, adjacency_dict={1: {'weight': 1, 'status': True},
3: {'weight': 2, 'status': True}})
test_net = Network({test_node1.node_id: test_node1,
test_node2.node_id: test_node2,
test_node3.node_id: test_node3,
test_node4.node_id: test_node4,
test_node5.node_id: test_node5})
dijkstra = Dijkstra(graph=test_net, source=test_node1.node_id)
path, weight = dijkstra.shortest_path(destination=test_node3.node_id)
assert path == [1, 5, 3]
assert weight is 3
test_net.remove_node(test_node5.node_id)
dijkstra = Dijkstra(graph=test_net, source=test_node1.node_id)
path, weight = dijkstra.shortest_path(destination=test_node3.node_id)
assert path == [1, 4, 3]
assert weight is 9
test_net.remove_node(test_node4.node_id)
dijkstra = Dijkstra(graph=test_net, source=test_node1.node_id)
path, weight = dijkstra.shortest_path(destination=test_node3.node_id)
assert path == [1, 2, 3]
assert weight is 15
test_net.remove_node(test_node2.node_id)
dijkstra = Dijkstra(graph=test_net, source=test_node1.node_id)
path, weight = dijkstra.shortest_path(destination=test_node3.node_id)
assert
```
<Overlap Ratio: 0.9499661933739013>

---

--- 154 --
Question ID: d9bef0062335735f85138ca286bea734ef9177cd_45
Original Code:
```
def derivative(requestContext, seriesList):
  """
  This is the opposite of the integral function.  This is useful for taking a
  running total metric and calculating the delta between subsequent data points.

  This function does not normalize for periods of time, as a true derivative would.
  Instead see the perSecond() function to calculate a rate of change over time.

  Example:

  .. code-block:: none

    &target=derivative(company.server.application01.ifconfig.TXPackets)

  Each time you run ifconfig, the RX and TXPackets are higher (assuming there
  is network traffic.) By applying the derivative function, you can get an
  idea of the packets per minute sent or received, even though you're only
  recording the total.
  """
  results = []
  for series in seriesList:
    newValues = []
    prev = None
    for val in series:
      if None in (prev,val):
        newValues.append(None)
        prev = val
        continue
      newValues.append(val - prev)
      prev = val
    newName = "derivative(%s)" % series.name
    newSeries = TimeSeries(newName, series.start, series.end, series.step, newValues)
    newSeries.pathExpression = newName
    results.append(newSeries)
  return results
```


Overlapping Code:
```
ivative(requestContext, seriesList):
"""
This is the opposite of the integral function. This is useful for taking a
running total metric and calculating the delta between subsequent data points.
This function does not normalize for periods of time, as a true derivative would.
Instead see the perSecond() function to calculate a rate of change over time.
Example:
.. code-block:: none
&target=derivative(company.server.application01.ifconfig.TXPackets)
Each time you run ifconfig, the RX and TXPackets are higher (assuming there
is network traffic.) By applying the derivative function, you can get an
idea of the packets per minute sent or received, even though you're only
recording the total.
"""
results = []
for series in seriesList:
newValues = []
prev = None
for val in series:
if None in (prev,val):
newValues.append(None)
prev = val
continue
newValues.append(val - prev)
prev = val
newName = "derivative(%s)" % series.name
newSeries = TimeSeries(newName, series.start, series.end, series.step, newValues)
newSeries.pathExpression = newName
results.append(newSeries)
return result
```
<Overlap Ratio: 0.9927007299270073>

---

--- 155 --
Question ID: b941f20836b283bad2664e6fbca953fbea25b1b5_19
Original Code:
```
def _get_type(s):
    """Reads a string to see if it can be converted into int or float.

    Parameters
    ----------
    s : str
        A string to be parsed.

    Returns
    -------
    str, int or float
        The parsed value.
    """
    try:
        float(s)
        if '.' not in s:
            return 'i'
        else:
            return 'f'
    except ValueError:
        return 's'
```


Overlapping Code:
```
 to see if it can be converted into int or float.
Parameters
----------
s : str
A string to be parsed.
Returns
-------
str, int or float
The parsed value.
"""
try:
float(s)
if '.' not in s:
return 'i'
```
<Overlap Ratio: 0.7092198581560284>

---

--- 156 --
Question ID: ce72f7d71f6ae021c620ab6d7510d352f841e52b_5
Original Code:
```
def add_three_mirrors(context):
    datadir_config = _write_datadir_config_for_three_mirrors()
    mirror_config_output_file = "/tmp/test_gpaddmirrors.config"

    cmd_str = 'gpaddmirrors -o %s -m %s' % (mirror_config_output_file, datadir_config)
    Command('generate mirror_config file', cmd_str).run(validateAfter=True)

    cmd = Command('gpaddmirrors ', 'gpaddmirrors -a -i %s ' % mirror_config_output_file)
    cmd.run(validateAfter=True)
```


Overlapping Code:
```
ntext):
datadir_config = _write_datadir_config_for_three_mirrors()
mirror_config_output_file = "/tmp/test_gpaddmirrors.config"
cmd_str = 'gpaddmirrors -o %s -m %s' % (mirror_config_output_file, datadir_config)
Command('generate mirror_config file', cmd_str).run(validateAfter=True)
cmd = Command('gpaddmirrors ', 'gpaddmirrors -a -i %s ' % mirror_config_outpu
```
<Overlap Ratio: 0.8588516746411483>

---

--- 157 --
Question ID: f74eace79f4f8bf8c10bb8c07aba841d848d9d58_2
Original Code:
```
@pytest.mark.skip("https://github.com/rotkehlchenio/rotkehlchen/issues/377")
@pytest.mark.parametrize('should_mock_price_queries', [False])
def test_price_queries(price_historian):
    """Test some cryptocompare price queries making sure our querying mechanism works"""
    # TODO: Get rid of the cache here and then try again with the cache
    # TODO2: Once historical price of DASH and other token stabilize perhaps also
    #        include them in the tests
    do_queries_for(A_BTC, A_EUR, price_historian)
    do_queries_for(A_ETH, A_EUR, price_historian)
```


Overlapping Code:
```
pytest.mark.skip("https://github.com/rotkehlchenio/rotkehlchen/issues/377")
@pytest.mark.parametrize('should_mock_price_queries', [False])
def test_price_queries(price_historian):
"""Test some cryptocompare price queries making sure our querying mechanism works"""
# TODO: Get rid of the cache here and then try again with the cache
# TODO2: Once historical price of DASH and other token stabilize perhaps also
# include them in the tests
do_queries_for(A_BTC, A_EUR, price_historian)
do_queries_for(A
```
<Overlap Ratio: 0.943502824858757>

---

--- 158 --
Question ID: 1d10744a8ebf8809ee640fe7b28884cb8c71d4ba_2
Original Code:
```
def flag_update_status(f, s, stat):
    f.update_status.setdefault(stat, []).append(s)
    if s is not None:
        s.update_status.setdefault(stat, []).append(f)
```


Overlapping Code:
```
ag_update_status(f, s, stat):
f.update_status.setdefault(stat, []).append(s)
if s is not None:
s.update_status.setdefault(stat, []).a
```
<Overlap Ratio: 0.9047619047619048>

---

--- 159 --
Question ID: ca1c6f902d469fc0533950126137c3edbfba755e_1
Original Code:
```
def getusb():  
    drives = []  
    sign = win32file.GetLogicalDrives()
    ALLDRIVES = ["A:\\","B:\\","C:\\","D:\\","E:\\","F:\\","G:\\","H:\\",
                 "I:\\","J:\\","K:\\","L:\\","M:\\","N:\\","O:\\","P:\\",
                 "Q:\\","R:\\","S:\\","T:\\","U:\\","V:\\","W:\\","X:\\",
                 "Y:\\","Z:\\"]  
    for i in range(25):  
        if (sign&1<<i):  
            if win32file.GetDriveType(ALLDRIVES[i]) == \
                win32file.DRIVE_REMOVABLE:  
                drives.append(ALLDRIVES[i])  
    return drives
```


Overlapping Code:
```
def getusb(): 
drives = [] 
sign = win32file.GetLogicalDrives()
ALLDRIVES = ["A:\\","B:\\","C:\\","D:\\","E:\\","F:\\","G:\\","H:\\",
"I:\\","J:\\","K:\\","L:\\","M:\\","N:\\","O:\\","P:\\",
"Q:\\","R:\\","S:\\","T:\\","U:\\","V:\\","W:\\","X:\\",
"Y:\\","Z:\\"] 
for i in range(25): 
if (sign&1<<i): 
if win32file.GetDriveType(ALLDRIVES[i]) == \
win32file.DRIVE_REMOVABLE: 
drives.append(ALLDRIVES[i
```
<Overlap Ratio: 0.9592326139088729>

---

--- 160 --
Question ID: 30ba5390ae67857af456ae2787d75573c28e66b3_35
Original Code:
```
def send_mail(mail_name,mail_host,mail_user,mail_pass,mail_postfix,to_list,subject,content): 
    me=mail_name+"<"+mail_user+"@"+mail_postfix+">"
    msg = MIMEText(content,_subtype='html',_charset='utf-8')
    msg['Subject'] = subject
    msg['From'] = me  
    msg['To'] = ";".join(to_list)  
    try:  
        s = smtplib.SMTP()  
        s.connect(mail_host) 
        s.login(mail_user,mail_pass) 
        s.sendmail(me, to_list, msg.as_string()) 
        s.close()  
        return True  
    except Exception as e:  
        print(str(e)  )
        return False  
```


Overlapping Code:
```
_host,mail_user,mail_pass,mail_postfix,to_list,subject,content): 
me=mail_name+"<"+mail_user+"@"+mail_postfix+">"
msg = MIMEText(content,_subtype='html',_charset='utf-8')
msg['Subject'] = subject
msg['From'] = me 
msg['To'] = ";".join(to_list) 
try: 
s = smtplib.SMTP() 
s.connect(mail_host) 
s.login(mail_user,mail_pass) 
s.sendmail(me, to_list, msg.as_string()) 
s.close() 
return True 
except Exception as e: 
print
```
<Overlap Ratio: 0.8931623931623932>

---

--- 161 --
Question ID: 3a2d856395d3eb7764d567716d1f16e603f91e66_0
Original Code:
```
def antijoin(
    left: Union[pd.DataFrame, gs.DataFile],
    right: Union[pd.DataFrame, gs.DataFile],
    on: list = None,
    left_on: list = None,
    right_on: list = None) -> pd.DataFrame:
    """Filtering join: extract rows in 'left' with no match in 'right'.

    The `left` frame is filtered by the `right` frame.

    Parameters
    ----------
    left : Data to be filtered.
    right : Data to do the filtering.
    on : List of columns common to `left` and `right` to be used for filtering.
        If this is anything but `None` the parameters `left_on` and `right_on`
        will be ignored.
    left_on : List of columns from `left` to match on. Must be for the same
        column types and in sequence specified with `right_on`.
    right_on : List of columns from `right` to match on. Must be for the same
        column types and in sequence specified with `left_on`.

    Return
    ------
    The data `left` is returned minus rows that have no match in `right` for
    the given list of columns (`on` or `left_on` + `right_on`).

    Example
    -------

    import pandas.util.testing as tm

    # Set default rows and columns for Pandas testing utilities.
    tm.N, tm.K = 5, 3

    # Make dummy DataFrames
    right = tm.makeDataFrame()\
        .set_index(tm.makeCategoricalIndex(k=5, name="bhid"))\
        .reset_index()

    # Convert the `bhid` column to numeric.
    dtfl, dhdict = alpha2numeric(df)

    print("Original DataFrame:\n", df, "\n")
    print("Updated DataFrame:\n", dtfl, "\n")
    print("Hole id dictionary:\n", dhdict)

    """

    # Handle gs.DataFile.
    if isinstance(left, gs.DataFile):
        left = left.data
    if isinstance(right, gs.DataFile):
        right = right.data

    # Handle the `on` parameters.
    if on is not None:
        left_on = on
        right_on = on
    elif left_on is not None:
        if right_on is None:
            raise Exception("If specifying `left_on` or `right_on` both must be supplied")
        if len(right_on) != len(left_on):
            raise Eception("The `left_on` and `right_on` list must have the same number of items")

    filt = left[~left[left_on].apply(tuple, 1).isin(right[right_on].apply(tuple, 1))]

    return filt
```


Overlapping Code:
```
aFrame, gs.DataFile],
right: Union[pd.DataFrame, gs.DataFile],
on: list = None,
left_on: list = None,
right_on: list = None) -> pd.DataFrame:
"""Filtering join: extract rows in 'left' with no match in 'right'.
The `left` frame is filtered by the `right` frame.
Parameters
----------
left : Data to be filtered.
right : Data to do the filtering.
on : List of columns common to `left` and `right` to be used for filtering.
If this is anything but `None` the parameters `left_on` and `right_on`
will be ignored.
left_on : List of columns from `left` to match on. Must be for the same
column types and in sequence specified with `right_on`.
right_on : List of columns from `right` to match on. Must be for the same
column types and in sequence specified with `left_on`.
Return
------
The data `left` is returned minus rows that have no match in `right` for
the given list of columns (`on` or `left_on` + `right_on`).
Example
-------
import pandas.util.testing as tm
# Set default rows and columns for Pandas testing utilities.
tm.N, tm.K = 5, 3
# Make dummy DataFrames
right = tm.makeDataFrame()\
.set_index(tm.makeCategoricalIndex(k=5, name="bhid"))\
.reset_index()
# Convert the `bhid` column to numeric.
dtfl, dhdict = alpha2numeric(df)
print("Original DataFrame:\n", df, "\n")
print("Updated DataFrame:\n", dtfl, "\n")
print("Hole id dictionary:\n", dhdict)
"""
# Handle gs.DataFile.
if isinstance(left, gs.DataFile):
left = left.data
if isinstance(right, gs.DataFile):
right = right.data
# Handle the `on` parameters.
if on is not None:
left_on = on
right_on = on
elif left_on is not None:
if right_on is None:
raise Exception("If specifying `left_on` or `right_on` both must be supplied")
if len(right_on) != len(left_on):
raise Eception("The `left_on` and `right_on` list must have the same number of items")
filt = left[~left[left_on].apply(tuple, 1).isin(right[right_on].apply(tuple, 1))]
return
```
<Overlap Ratio: 0.980898296334538>

---

--- 162 --
Question ID: 8fe41949e056d46badadc0165fafcde1384f74d2_2
Original Code:
```
def print_bytes(seq):
    out = []
    for i in seq:
        out.append("{:02X}".format(i))
    return out
```


Overlapping Code:
```
int_bytes(seq):
out = []
for i in seq:
out.append(
```
<Overlap Ratio: 0.5813953488372093>

---

--- 163 --
Question ID: 77508dd2aeb0c35af663e0129bb4b22cb9713ce8_5
Original Code:
```
@C.funcs
def theme_infographic() -> Bar:
    c = (
        Bar(init_opts=opts.InitOpts(theme=ThemeType.INFOGRAPHIC))
        .add_xaxis(Faker.choose())
        .add_yaxis("商家A", Faker.values())
        .add_yaxis("商家B", Faker.values())
        .add_yaxis("商家C", Faker.values())
        .add_yaxis("商家D", Faker.values())
        .set_global_opts(title_opts=opts.TitleOpts("Theme-infographic"))
    )
    return c
```


Overlapping Code:
```
_infographic() -> Bar:
c = (
Bar(init_opts=opts.InitOpts(theme=ThemeType.INFOGRAPHIC))
.add_xaxis(Faker.choose())
.add_yaxis("商家A", Faker.values())
.add_yaxis("商家B", Faker.values())
.add_yaxis("商家C", Faker.values())
.add_yaxis("商家D", Faker.values())
.set_global_opts(title_opts=opts.TitleOpts("Theme-
```
<Overlap Ratio: 0.8746355685131195>

---

--- 164 --
Question ID: f7cd31781b011723ebdc34860cfef948b5991c38_7
Original Code:
```
def get_relative_path(filepath, root, return_name_if_fail=True):
    # without '/' in head/foot
    filepath = same_slash(filepath)
    root = same_slash(root)
    if filepath and root and filepath.startswith(root+'/'):
        return filepath.replace(root, '').strip('/')
    elif filepath == root:
        return ''
    else:
        if return_name_if_fail:
            return os.path.split(filepath)[-1]
        else:
            return filepath
```


Overlapping Code:
```
def get_relative_path(filepath, root, return_name_if_fail=True):
# without '/' in head/foot
filepath = same_slash(filepath)
root = same_slash(root)
if filepath and root and filepath.startswith(root+'/'):
return filepath.replace(root, '').strip('/')
elif filepath == root:
return ''
else:
if return_name_if_fail:
return os.path.split(filepath)[-1]
els
```
<Overlap Ratio: 0.9510869565217391>

---

--- 165 --
Question ID: 987e5461de1316dcbe99ae34707833866b4ceec8_5
Original Code:
```
def evil_player(lines, columns, white_positions, black_positions):
    move = []
    board = [lines, columns, white_positions, black_positions]
    current_score = evaluation(*board)
    possible_moves = {}

    #print(current_score)

    for move in get_possible_moves(*board):
        if move[1][0] == lines:
            return move
        wp, bp = simulate_move(move, white_positions, black_positions)
        score = evaluation(lines, columns, wp, bp)
        possible_moves[move] = (score - current_score)
        
    if possible_moves:
        max_value = max(possible_moves.values())
        best_moves = list(filter(lambda key: possible_moves[key] == max_value, possible_moves.keys()))
        index = random.randint(0, abs(len(best_moves) - 1))
        move = best_moves[index]

    return move
```


Overlapping Code:
```
_player(lines, columns, white_positions, black_positions):
move = []
board = [lines, columns, white_positions, black_positions]
current_score = evaluation(*board)
possible_moves = {}
#print(current_score)
for move in get_possible_moves(*board):
if move[1][0] == lines:
return move
wp, bp = simulate_move(move, white_positions, black_positions)
score = evaluation(lines, columns, wp, bp)
possible_moves[move] = (score - current_score)

if possible_moves:
max_value = max(possible_moves.values())
best_moves = list(filter(lambda key: possible_moves[key] == max_value, possible_moves.keys()))
index = random.randint(0, abs(len(best_m
```
<Overlap Ratio: 0.9183673469387755>

---

--- 166 --
Question ID: f3de7c7c082891154829a5c40c57d69c82b9fdee_0
Original Code:
```
@click.command(
    epilog="See 'slcli dedicatedhost create-options' for valid options.")
@click.option('--hostnames', '-H',
              help="Host portion of the FQDN",
              required=True,
              prompt=True)
@click.option('--router', '-r',
              help="Router hostname ex. fcr02a.dal13",
              show_default=True)
@click.option('--domain', '-D',
              help="Domain portion of the FQDN",
              required=True,
              prompt=True)
@click.option('--datacenter', '-d', help="Datacenter shortname",
              required=True,
              prompt=True)
@click.option('--flavor', '-f', help="Dedicated Virtual Host flavor",
              required=True,
              prompt=True)
@click.option('--billing',
              type=click.Choice(['hourly', 'monthly']),
              default='hourly',
              show_default=True,
              help="Billing rate")
@click.option('--verify',
              is_flag=True,
              help="Verify dedicatedhost without creating it.")
@click.option('--template', '-t',
              is_eager=True,
              callback=template.TemplateCallback(list_args=['key']),
              help="A template file that defaults the command-line options",
              type=click.Path(exists=True, readable=True, resolve_path=True))
@click.option('--export',
              type=click.Path(writable=True, resolve_path=True),
              help="Exports options to a template file")
@environment.pass_env
def cli(env, **kwargs):
    """Order/create a dedicated host."""
    mgr = SoftLayer.DedicatedHostManager(env.client)

    order = {
        'hostnames': kwargs['hostnames'].split(','),
        'domain': kwargs['domain'],
        'flavor': kwargs['flavor'],
        'location': kwargs['datacenter'],
        'hourly': kwargs.get('billing') == 'hourly',
    }

    if kwargs['router']:
        order['router'] = kwargs['router']

    do_create = not (kwargs['export'] or kwargs['verify'])

    output = None

    result = mgr.verify_order(**order)
    table = formatting.Table(['Item', 'cost'])
    table.align['Item'] = 'r'
    table.align['cost'] = 'r'
    if len(result['prices']) != 1:
        raise exceptions.ArgumentError("More than 1 price was found or no "
                                       "prices found")
    price = result['prices']
    if order['hourly']:
        total = float(price[0].get('hourlyRecurringFee', 0.0))
    else:
        total = float(price[0].get('recurringFee', 0.0))

    if order['hourly']:
        table.add_row(['Total hourly cost', "%.2f" % total])
    else:
        table.add_row(['Total monthly cost', "%.2f" % total])

    output = []

    if kwargs['export']:
        export_file = kwargs.pop('export')
        template.export_to_template(export_file, kwargs,
                                    exclude=['wait', 'verify'])
        env.fout('Successfully exported options to a template file.')

    if do_create:
        if not env.skip_confirmations and not formatting.confirm(
                "This action will incur charges on your account. "
                "Continue?"):
            raise exceptions.CLIAbort('Aborting dedicated host order.')

        result = mgr.place_order(**order)

        hosts = _wait_for_host_ids(result['orderId'], mgr)

        table = formatting.KeyValueTable(['name', 'value'])
        table.align['name'] = 'r'
        table.align['value'] = 'l'
        table.add_row(['id', result['orderId']])
        table.add_row(['created', result['orderDate']])
        table.add_row(['hosts', hosts])
        output.append(table)

    env.fout(output)
```


Overlapping Code:
```
 'slcli dedicatedhost create-options' for valid options.")
@click.option('--hostnames', '-H',
help="Host portion of the FQDN",
required=True,
prompt=True)
@click.option('--router', '-r',
help="Router hostname ex. fcr02a.dal13",
show_default=True)
@click.option('--domain', '-D',
help="Domain portion of the FQDN",
required=True,
prompt=True)
@click.option('--datacenter', '-d', help="Datacenter shortname",
required=True,
prompt=True)
@click.option('--flavor', '-f', help="Dedicated Virtual Host flavor",
required=True,
prompt=True)
@click.option('--billing',
type=click.Choice(['hourly', 'monthly']),
default='hourly',
show_default=True,
help="Billing rate")
@click.option('--verify',
is_flag=True,
help="Verify dedicatedhost without creating it.")
@click.option('--template', '-t',
is_eager=True,
callback=template.TemplateCallback(list_args=['key']),
help="A template file that defaults the command-line options",
type=click.Path(exists=True, readable=True, resolve_path=True))
@click.option('--export',
type=click.Path(writable=True, resolve_path=True),
help="Exports options to a template file")
@environment.pass_env
def cli(env, **kwargs):
"""Order/create a dedicated host."""
mgr = SoftLayer.DedicatedHostManager(env.client)
order = {
'hostnames': kwargs['hostnames'].split(','),
'domain': kwargs['domain'],
'flavor': kwargs['flavor'],
'location': kwargs['datacenter'],
'hourly': kwargs.get('billing') == 'hourly',
}
if kwargs['router']:
order['router'] = kwargs['router']
do_create = not (kwargs['export'] or kwargs['verify'])
output = None
result = mgr.verify_order(**order)
table = formatting.Table(['Item', 'cost'])
table.align['Item'] = 'r'
table.align['cost'] = 'r'
if len(result['prices']) != 1:
raise exceptions.ArgumentError("More than 1 price was found or no "
"prices found")
price = result['prices']
if order['hourly']:
total = float(price[0].get('hourlyRecurringFee', 0.0))
else:
total = float(price[0].get('recurringFee', 0.0))

```
<Overlap Ratio: 0.9858442871587462>

---

--- 167 --
Question ID: 83ea449458a6b6b0d591e3c4956d210a610d8344_1
Original Code:
```
def test_types():
    """Ensure source code static typing."""
    result = PoeThePoet(Path("."))(["types"])
    assert result == 0
```


Overlapping Code:
```
e code static typing."""
result = PoeThePoet(Path(
```
<Overlap Ratio: 0.423728813559322>

---

--- 168 --
Question ID: bc86398eecf3833614c097df7bf622fb746c9a2a_11
Original Code:
```
@pytest.mark.parametrize(
    ("fragment", "canonical_name", "expected"),
    [
        # Trivial.
        ("pip-18.0", "pip", "18.0"),
        ("zope-interface-4.5.0", "zope-interface", "4.5.0"),

        # Canonicalized name match non-canonicalized egg info. (pypa/pip#5870)
        ("Jinja2-2.10", "jinja2", "2.10"),
        ("zope.interface-4.5.0", "zope-interface", "4.5.0"),
        ("zope_interface-4.5.0", "zope-interface", "4.5.0"),

        # Should be smart enough to parse ambiguous names from the provided
        # package name.
        ("foo-2-2", "foo", "2-2"),
        ("foo-2-2", "foo-2", "2"),
        ("zope.interface--4.5.0", "zope-interface", "-4.5.0"),
        ("zope.interface--", "zope-interface", "-"),

        # Should be able to detect collapsed characters in the egg info.
        ("foo--bar-1.0", "foo-bar", "1.0"),
        ("foo-_bar-1.0", "foo-bar", "1.0"),

        # Invalid.
        ("the-package-name-8.19", "does-not-match", None),
        ("zope.interface.-4.5.0", "zope.interface", None),
        ("zope.interface-", "zope-interface", None),
        ("zope.interface4.5.0", "zope-interface", None),
        ("zope.interface.4.5.0", "zope-interface", None),
        ("zope.interface.-4.5.0", "zope-interface", None),
        ("zope.interface", "zope-interface", None),
    ],
)
def test_extract_version_from_fragment(fragment, canonical_name, expected):
    version = _extract_version_from_fragment(fragment, canonical_name)
    assert version == expected
```


Overlapping Code:
```
test.mark.parametrize(
("fragment", "canonical_name", "expected"),
[
# Trivial.
("pip-18.0", "pip", "18.0"),
("zope-interface-4.5.0", "zope-interface", "4.5.0"),
# Canonicalized name match non-canonicalized egg info. (pypa/pip#5870)
("Jinja2-2.10", "jinja2", "2.10"),
("zope.interface-4.5.0", "zope-interface", "4.5.0"),
("zope_interface-4.5.0", "zope-interface", "4.5.0"),
# Should be smart enough to parse ambiguous names from the provided
# package name.
("foo-2-2", "foo", "2-2"),
("foo-2-2", "foo-2", "2"),
("zope.interface--4.5.0", "zope-interface", "-4.5.0"),
("zope.interface--", "zope-interface", "-"),
# Should be able to detect collapsed characters in the egg info.
("foo--bar-1.0", "foo-bar", "1.0"),
("foo-_bar-1.0", "foo-bar", "1.0"),
# Invalid.
("the-package-name-8.19", "does-not-match", None),
("zope.interface.-4.5.0", "zope.interface", None),
("zope.interface-", "zope-interface", None),
("zope.interface4.5.0", "zope-interface", None),
("zope.interface.4.5.0", "zope-interface", None),
("zope.interface.-4.5.0", "zope-interface", None),
("zope.interface", "zope-interface", None),
],
)
def test_extract_version_from_fragment(fragment, canonical_name, expected):
version = _extract_version_from_fragment(fragment, canonical_name)
a
```
<Overlap Ratio: 0.9780907668231612>

---

--- 169 --
Question ID: 34889ac9488b56eb626d3c7f88669e596c3bd0cd_2
Original Code:
```
def test_load_file():
    response_dict = {}
    test_folder = path.abspath(path.join(__file__, ".."))
    setting_file = "settings.yml"
    settings = test_folder + "/" + setting_file
    client = EtcdTool(host="127.0.0.1")
    client.load(settings)

    response = client.read("/", recursive=True)

    for result in response.children:
        response_dict[result.key] = result.value

    assert response_dict["/key_1"] == "1000"
    assert response_dict["/key_2"] == "1000"
    assert response_dict["/key_3"] == "1000.0"
    assert response_dict["/key_4"] == "1000.0"
    assert response_dict["/key_5"] == "1000"
    assert response_dict["/key_6"] == "Yes"
    assert response_dict["/key_7"] == "True"

    assert response_dict["/one_level/key_1"] == "1000"
    assert response_dict["/one_level/key_2"] == "1000"
    assert response_dict["/one_level/key_3"] == "1000.0"
    assert response_dict["/one_level/key_4"] == "1000.0"
    assert response_dict["/one_level/key_5"] == "1000"
    assert response_dict["/one_level/key_6"] == "Yes"
    assert response_dict["/one_level/key_7"] == "True"

    assert response_dict["/two_levels/intermediate_level/key_1"] == "1000"
    assert response_dict["/two_levels/intermediate_level/key_2"] == "1000"
    assert response_dict["/two_levels/intermediate_level/key_3"] == "1000.0"
    assert response_dict["/two_levels/intermediate_level/key_4"] == "1000.0"
    assert response_dict["/two_levels/intermediate_level/key_5"] == "1000"
    assert response_dict["/two_levels/intermediate_level/key_6"] == "Yes"
    assert response_dict["/two_levels/intermediate_level/key_7"] == "True"
```


Overlapping Code:
```
ct = {}
test_folder = path.abspath(path.join(__file__, ".."))
setting_file = "settings.yml"
settings = test_folder + "/" + setting_file
client = EtcdTool(host="127.0.0.1")
client.load(settings)
response = client.read("/", recursive=True)
for result in response.children:
response_dict[result.key] = result.value
assert response_dict["/key_1"] == "1000"
assert response_dict["/key_2"] == "1000"
assert response_dict["/key_3"] == "1000.0"
assert response_dict["/key_4"] == "1000.0"
assert response_dict["/key_5"] == "1000"
assert response_dict["/key_6"] == "Yes"
assert response_dict["/key_7"] == "True"
assert response_dict["/one_level/key_1"] == "1000"
assert response_dict["/one_level/key_2"] == "1000"
assert response_dict["/one_level/key_3"] == "1000.0"
assert response_dict["/one_level/key_4"] == "1000.0"
assert response_dict["/one_level/key_5"] == "1000"
assert response_dict["/one_level/key_6"] == "Yes"
assert response_dict["/one_level/key_7"] == "True"
assert response_dict["/two_levels/intermediate_level/key_1"] == "1000"
assert response_dict["/two_levels/intermediate_level/key_2"] == "1000"
assert response_dict["/two_levels/intermediate_level/key_3"] == "1000.0"
assert response_dict["/two_levels/intermediate_level/key_4"] == "1000.0"
assert response_dict["/two_levels/intermediate_level/key_5"] == "1000"
assert response_dict["/two_levels/intermediate_level/key_6"] == "Yes"
assert response_dict["/two_levels/intermediate_level/key_7"
```
<Overlap Ratio: 0.9705488621151271>

---

--- 170 --
Question ID: 2a9dc6426014f9522215548d1e14daf472274ee1_1
Original Code:
```
def update_proteinsequenceannotation(nex_session, dbentity_id, taxonomy_id, contig_id, seq_version, genomerelease_id, file_header, seq):

    print ("Update protein:", dbentity_id, taxonomy_id, contig_id, seq_version, genomerelease_id, file_header, seq)
    
    x = nex_session.query(Proteinsequenceannotation).filter_by(dbentity_id=dbentity_id, taxonomy_id=taxonomy_id, contig_id=contig_id).one_or_none()
    if x is None:
        print ("No Proteinsequenceannotation row found for dbentity_id=", dbentity_id, ", taxonomy_id=", taxonomy_id, ", contig_id=", contig_id)
    x.seq_version = seq_version
    x.genomerelease_id = genomerelease_id
    x.file_header = file_header
    x.residues = seq
    nex_session.add(x)         
```


Overlapping Code:
```
ion, dbentity_id, taxonomy_id, contig_id, seq_version, genomerelease_id, file_header, seq):
print ("Update protein:", dbentity_id, taxonomy_id, contig_id, seq_version, genomerelease_id, file_header, seq)

x = nex_session.query(Proteinsequenceannotation).filter_by(dbentity_id=dbentity_id, taxonomy_id=taxonomy_id, contig_id=contig_id).one_or_none()
if x is None:
print ("No Proteinsequenceannotation row found for dbentity_id=", dbentity_id, ", taxonomy_id=", taxonomy_id, ", contig_id=", contig_id)
x.seq_version = seq_version
x.genomerelease_id = genomerelease_id
x.file_header = file_header
x.residues = seq
nex_sess
```
<Overlap Ratio: 0.9183976261127597>

---

--- 171 --
Question ID: f425368a6dd7f12816034c1199455fe915409f79_0
Original Code:
```
def remove_old_revisions_for_page(request, page_id):
    page = get_object_or_404(Page, id=page_id)

    perms = page.permissions_for_user(request.user)
    if not request.user.is_superuser and not perms.can_edit():
        return HttpResponseForbidden()

    next = request.META.get("HTTP_REFERER", None)

    # get revisions for page
    revisions = (
        PageRevision.objects.filter(page_id=page.id)
        .filter(submitted_for_moderation=False)
        .filter(approved_go_live_at__isnull=True)
        .exclude(id=page.live_revision_id)
        .filter(created_at__lt=page.live_revision.created_at)
    )

    if request.POST:
        revisions.delete()

        messages.success(
            request, ugettext('Old revisions of "{}" have been deleted.'.format(page))
        )

        next = request.POST.get("next", next)

        if next:
            return redirect(next)

        return redirect(reverse("wagtailadmin_pages:revisions_index", args=[page_id]))

    else:
        return render(
            request,
            "xr_wagtail/revisions/remove_for_page_confirm.html",
            context={
                "page": page,
                "revisions": revisions,
                "next": reverse("wagtailadmin_pages:revisions_index", args=[page_id]),
            },
        )
```


Overlapping Code:
```
ve_old_revisions_for_page(request, page_id):
page = get_object_or_404(Page, id=page_id)
perms = page.permissions_for_user(request.user)
if not request.user.is_superuser and not perms.can_edit():
return HttpResponseForbidden()
next = request.META.get("HTTP_REFERER", None)
# get revisions for page
revisions = (
PageRevision.objects.filter(page_id=page.id)
.filter(submitted_for_moderation=False)
.filter(approved_go_live_at__isnull=True)
.exclude(id=page.live_revision_id)
.filter(created_at__lt=page.live_revision.created_at)
)
if request.POST:
revisions.delete()
messages.success(
request, ugettext('Old revisions of "{}" have been deleted.'.format(page))
)
next = request.POST.get("next", next)
if next:
return redirect(next)
return redirect(reverse("wagtailadmin_pages:revisions_index", args=[page_id]))
else:
return render(
request,
"xr_wagtail/revisions/remove_for_page_confirm.html",
context={
"page": page,
"revisions": revisions,
"next": reverse("wagtailadmin_pages:revisions_ind
```
<Overlap Ratio: 0.9667318982387475>

---

--- 172 --
Question ID: daf6d637fc70dfc88256c42fe847cb88fc9cbc0e_1
Original Code:
```
def get_facebook_text(uri, api):
    """
    take in a facebook id and pattern facebook API instance
    return a string of profile blurb + recent posts
    if nothing interesting is returned, return empty string
        - returns: string
    """
    if isinstance(uri, str): 
        uri = unicode(uri)
        
    if isinstance(uri, unicode):
        if not all([c.isdigit() for c in uri]):
            fid = requests.get(url='http://graph.facebook.com/' + uri).json().get('id')  # get the Facebook id from graph
        else:
            fid = uri  # numeric id
    elif isinstance(uri, int):
        fid = uri

    fetched = False

    while not fetched:
        user_text = []
        try:
            for post in api.search(fid, type=NEWS, count=100):
                post_text = []
                if not any([x in post.text for x in settings.useless_keywords]):  # i.e. `if the post isn't "Charlie Hack likes a photo":`
                    post_text.append(unicode(remove_nonascii(post.text)))
                if post.comments > 0:
                    post_text.extend([unicode(remove_nonascii(r.text)) for r in api.search(post.id, type=COMMENTS)])
                user_text.append(' '.join(post_text))

            user_text  = unicode(' '.join(user_text))
            fetched    = True

        except URLTimeout as e:
            print('URLTimeout:', e)
            time.sleep(settings.sleep_time)
        except URLError as e:
            print('URLError:', e)
            break

    if isinstance(user_text, list):
        if len(user_text) >= 1:
            user_text = unicode(' '.join(user_text))  # sometimes these get popped off before the join
        else:
            user_text = u''  # return empty string

    assert isinstance(user_text, unicode), "facebook {user_text} isn't unicode, it's {type}.".format(user_text=user_text, type=type(user_text))
    return remove_nonascii(user_text)
```


Overlapping Code:
```
i):
"""
take in a facebook id and pattern facebook API instance
return a string of profile blurb + recent posts
if nothing interesting is returned, return empty string
- returns: string
"""
if isinstance(uri, str): 
uri = unicode(uri)

if isinstance(uri, unicode):
if not all([c.isdigit() for c in uri]):
fid = requests.get(url='http://graph.facebook.com/' + uri).json().get('id') # get the Facebook id from graph
else:
fid = uri # numeric id
elif isinstance(uri, int):
fid = uri
fetched = False
while not fetched:
user_text = []
try:
for post in api.search(fid, type=NEWS, count=100):
post_text = []
if not any([x in post.text for x in settings.usellikes a photo":`
post_text.append(unicode(remove_nonascii(post.text)))
if post.comments > 0:
post_text.extend([unicode(remove_nonascii(r.text)) for r in api.search(post.id, type=COMMENTS)])
user_text.append(' '.join(post_text))
user_text = unicode(' '.join(user_text))
fetched = True
except URLTimeout as e:
print('URLTimeout:', e)
time.sleep(settings.sleep_time)
except URLError as e:
print('URLError:', e)
break
if isinstance(user_text, list):
if len(user_text) >= 1:
user_text = unicode(' '.join(user_text)) # sometimes these get popped off before the join
else:
user_text = u'' # return empty string
assert isinstance(user_text, unicode), "facebook {user_text} isn't unicode, it's {type}.".format(user_text=user_text, type=type(user_text))
return
```
<Overlap Ratio: 0.9259259259259259>

---

--- 173 --
Question ID: 0d3fbd1633338c602c4cddbabb702cde97e629d9_0
Original Code:
```
def main(argv):
    # dataset load
    data, MAX_LENGTH, MAX_ARGS, VOCAB_SIZE, vocab = load_all_datasets()

    # parameter setup
    MAX_LENGTH += 2
    BATCH_SIZE = 50
    VALUE_SIZE = 150
    MIN_RETURN_WIDTH = VALUE_SIZE
    STACK_SIZE = 5

    d4_params = d4InitParams(stack_size=STACK_SIZE,
                             value_size=VALUE_SIZE,
                             batch_size=BATCH_SIZE,
                             min_return_width=MIN_RETURN_WIDTH)

    data_params = DataParams(vocab_size=VOCAB_SIZE,
                             max_length=MAX_LENGTH,
                             max_args=MAX_ARGS)

    train_params = TrainParams(train=True,
                               learning_rate=0.02,
                               num_steps_train=7,
                               num_steps_test=7)

    def load_sketch_from_file(filename):
        with open(filename, "r") as f:
            scaffold = f.read()
        return scaffold

    # building batcher
    batcher_train = ArithmeticDatasetBatcher(data.train, BATCH_SIZE)

    # build the model
    sketch = load_sketch_from_file("./experiments/wap/sketch_wap.d4")
    # print(sketch)
    model = AlgebraD4Model(sketch, d4_params, data_params, train_params)
    model.build_graph()

    directory_save = "./tmp/wap/checkpoints/"
    import os
    if not os.path.exists(directory_save):
        os.makedirs(directory_save)

    epoch_count = tf.Variable(0, name="epoch", trainable=False)
    max_accuracy = float('-inf')

    with tf.Session() as sess:

        # if True:
        #     model.load_model(sess, directory_save)
        #     print('loaded model')
        #     accuracy = model.run_eval_step(sess, data.dev, debug=False)
        #     print(accuracy)
        #     # accuracy, partial_accuracy = model.run_eval_step(sess, dataset_dev)
        #     exit(0)

        summary_writer = tf.train.SummaryWriter("./tmp/summaries/wap", tf.get_default_graph())
        sess.run(tf.initialize_all_variables())

        for epoch in range(50):
            epoch_count.assign_add(1)
            print('epoch', epoch)

            # TRAIN
            total_loss = 0.0
            for batch_no in range(batcher_train.batch_number):
                batch = batcher_train.next_batch()
                _, summaries, loss, global_step = model.run_train_step(sess, batch)
                # print('    Loss per batch: ', loss / BATCH_SIZE)
                total_loss += loss
                summary_writer.add_summary(summaries, global_step)

            total_loss /= (batcher_train.batch_number * BATCH_SIZE)
            print('  loss per epoch: ', total_loss)

            # logging summaries
            summary_loss = tf.Summary(
                value=[tf.Summary.Value(tag="loss_per_epoch", simple_value=total_loss)]
            )
            summary_writer.add_summary(summary_loss, epoch)
            summary_writer.flush()

            # if epoch % 10 == 0:
            #     model.run_test_step(sess, batch)

            print("  train set eval...")
            if epoch % 1 == 0:
                model.run_eval_step(sess, data.train, debug=False)

            print("  dev set eval...")
            if epoch % 1 == 0:
                accuracy = model.run_eval_step(sess, data.dev)
                if accuracy > max_accuracy and accuracy > 0.94:
                    max_accuracy = accuracy
                    print('Saving model...')

                    model.save_model(sess, directory_save + "model.checkpoint",
                                     global_step=global_step)
                    print('Model saved...')
```


Overlapping Code:
```
 dataset load
data, MAX_LENGTH, MAX_ARGS, VOCAB_SIZE, vocab = load_all_datasets()
# parameter setup
MAX_LENGTH += 2
BATCH_SIZE = 50
VALUE_SIZE = 150
MIN_RETURN_WIDTH = VALUE_SIZE
STACK_SIZE = 5
d4_params = d4InitParams(stack_size=STACK_SIZE,
value_size=VALUE_SIZE,
batch_size=BATCH_SIZE,
min_return_width=MIN_RETURN_WIDTH)
data_params = DataParams(vocab_size=VOCAB_SIZE,
max_length=MAX_LENGTH,
max_args=MAX_ARGS)
train_params = TrainParams(train=True,
learning_rate=0.02,
num_steps_train=7,
num_steps_test=7)
def load_sketch_from_file(filename):
with open(filename, "r") as f:
scaffold = f.read()
return scaffold
# building batcher
batcher_train = ArithmeticDatasetBatcher(data.train, BATCH_SIZE)
# build the model
sketch = load_sketch_from_file("./experiments/wap/sketch_wap.d4")
# print(sketch)
model = AlgebraD4Model(sketch, d4_params, data_params, train_params)
model.build_graph()
directory_save = "./tmp/wap/checkpoints/"
import os
if not os.path.exists(directory_save):
os.makedirs(directory_save)
epoch_count = tf.Variable(0, name="epoch", trainable=False)
max_accuracy = float('-inf')
with tf.Session() as sess:
# if True:
# model.load_model(sess, directory_save)
# print('loaded model')
# accuracy = model.run_eval_step(sess, data.dev, debug=False)
# print(accuracy)
# # accuracy, partial_accuracy = model.run_eval_step(sess, dataset_dev)
# exit(0)
summary_writer = tf.train.SummaryWriter("./tmp/summaries/wap", tf.get_default_graph())
sess.run(tf.initialize_all_variables())
for epoch in range(50):
epoch_count.assign_add(1)
print('epoch', epoch)
# TRAIN
total_loss = 0.0
for batch_no in range(batcher_train.batch_number):
batch = batcher_train.next_batch()
_, summaries, loss, global_step = model.run_train_step(sess, batch)
# print(' Loss per batch: ', loss / BATCH_SIZE)
total_loss += l
```
<Overlap Ratio: 0.9656652360515021>

---

--- 174 --
Question ID: 435d6317d476f9dd97265f66987c6a2d71512eb8_22
Original Code:
```
def applyNonMaximaSuppression(nmsThreshold, labels, scores, coords, ignore_background=False):
    # generate input for nms
    allIndices = []
    nmsRects = [[[]] for _ in range(max(labels) + 1)]
    coordsWithScores = np.hstack((coords, np.array([scores]).T))
    for i in range(max(labels) + 1):
        indices = np.where(np.array(labels) == i)[0]
        nmsRects[i][0] = coordsWithScores[indices,:]
        allIndices.append(indices)

    # call nms
    _, nmsKeepIndicesList = apply_nms(nmsRects, nmsThreshold, ignore_background=ignore_background)

    # map back to original roi indices
    nmsKeepIndices = []
    for i in range(max(labels) + 1):
        for keepIndex in nmsKeepIndicesList[i][0]:
            nmsKeepIndices.append(allIndices[i][keepIndex]) # for keepIndex in nmsKeepIndicesList[i][0]]
    assert (len(nmsKeepIndices) == len(set(nmsKeepIndices)))  # check if no roi indices was added >1 times
    return nmsKeepIndices
```


Overlapping Code:
```
nMaximaSuppression(nmsThreshold, labels, scores, coords, ignore_background=False):
# generate input for nms
allIndices = []
nmsRects = [[[]] for _ in range(max(labels) + 1)]
coordsWithScores = np.hstack((coords, np.array([scores]).T))
for i in range(max(labels) + 1):
indices = np.where(np.array(labels) == i)[0]
nmsRects[i][0] = coordsWithScores[indices,:]
allIndices.append(indices)
# call nms
_, nmsKeepIndicesList = apply_nms(nmsRects, nmsThreshold, ignore_background=ignore_background)
# map back to original roi indices
nmsKeepIndices = []
for i in range(max(labels) + 1):
for keepIndex in nmsKeepIndicesList[i][0]:
nmsKeepIndices.append(allIndices[i][keepIndex]) # for keepIndex in nmsKeepIndicesList[i][0]]
assert (len(nmsKeepIndices) == len(set(nmsKeepIndices))) # check if no roi indices was added
```
<Overlap Ratio: 0.950530035335689>

---

--- 175 --
Question ID: 74bab1cf6d76463e3de0c503106e22b9ce29949a_2
Original Code:
```
def add_cp_cs(data, Ncp, Ncs):
    if Ncp > 0 :
        return np.concatenate([data[-Ncp:],data,data[:Ncs]])
    else :
        return add_cs(data, Ncs)
```


Overlapping Code:
```
cp_cs(data, Ncp, Ncs):
if Ncp > 0 :
return np.concatenate([data[-Ncp:],data,data[:Ncs]])
else :
retu
```
<Overlap Ratio: 0.78125>

---

--- 176 --
Question ID: fe8e83568da2ce47771ba805d32005c8947cc724_0
Original Code:
```
def add_CustomerServiceServicer_to_server(servicer, server):
  rpc_method_handlers = {
      'GetCustomer': grpc.unary_unary_rpc_method_handler(
          servicer.GetCustomer,
          request_deserializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.GetCustomerRequest.FromString,
          response_serializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_resources_dot_customer__pb2.Customer.SerializeToString,
      ),
      'MutateCustomer': grpc.unary_unary_rpc_method_handler(
          servicer.MutateCustomer,
          request_deserializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.MutateCustomerRequest.FromString,
          response_serializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.MutateCustomerResponse.SerializeToString,
      ),
      'ListAccessibleCustomers': grpc.unary_unary_rpc_method_handler(
          servicer.ListAccessibleCustomers,
          request_deserializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.ListAccessibleCustomersRequest.FromString,
          response_serializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.ListAccessibleCustomersResponse.SerializeToString,
      ),
      'CreateCustomerClient': grpc.unary_unary_rpc_method_handler(
          servicer.CreateCustomerClient,
          request_deserializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.CreateCustomerClientRequest.FromString,
          response_serializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.CreateCustomerClientResponse.SerializeToString,
      ),
  }
  generic_handler = grpc.method_handlers_generic_handler(
      'google.ads.googleads.v3.services.CustomerService', rpc_method_handlers)
  server.add_generic_rpc_handlers((generic_handler,))
```


Overlapping Code:
```
f add_CustomerServiceServicer_to_server(servicer, server):
rpc_method_handlers = {
'GetCustomer': grpc.unary_unary_rpc_method_handler(
servicer.GetCustomer,
request_deserializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.GetCustomerRequest.FromString,
response_serializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_resources_dot_customer__pb2.Customer.SerializeToString,
),
'MutateCustomer': grpc.unary_unary_rpc_method_handler(
servicer.MutateCustomer,
request_deserializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.MutateCustomerRequest.FromString,
response_serializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.MutateCustomerResponse.SerializeToString,
),
'ListAccessibleCustomers': grpc.unary_unary_rpc_method_handler(
servicer.ListAccessibleCustomers,
request_deserializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.ListAccessibleCustomersRequest.FromString,
response_serializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.ListAccessibleCustomersResponse.SerializeToString,
),
'CreateCustomerClient': grpc.unary_unary_rpc_method_handler(
servicer.CreateCustomerClient,
request_deserializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.CreateCustomerClientRequest.FromString,
response_serializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.CreateCustomerClientResponse.SerializeToString,
),
}
generic_handler = grpc.method_handlers_generic_handler(
'google.ads.googleads.v3.services.CustomerService', rpc_method_handlers)
server.add_generic_rpc_handlers((generic_handler,))
```
<Overlap Ratio: 0.9988636363636364>

---

--- 177 --
Question ID: 4c564e7cef6fda6a38a7d4069341781afb25f3ca_1
Original Code:
```
def json2paramater(x, is_rand, random_state, oldy=None, Rand=False, name=NodeType.Root.value):
    '''
    Json to pramaters.
    '''
    if isinstance(x, dict):
        if NodeType.Type.value in x.keys():
            _type = x[NodeType.Type.value]
            _value = x[NodeType.Value.value]
            name = name + '-' + _type
            Rand |= is_rand[name]
            if Rand is True:
                if _type == 'choice':
                    _index = random_state.randint(len(_value))
                    y = {
                        NodeType.Index.value: _index,
                        NodeType.Value.value: json2paramater(x[NodeType.Value.value][_index],
                                                             is_rand,
                                                             random_state,
                                                             None,
                                                             Rand,
                                                             name=name+"[%d]" % _index)
                    }
                else:
                    y = eval('parameter_expressions.' +
                             _type)(*(_value + [random_state]))
            else:
                y = copy.deepcopy(oldy)
        else:
            y = dict()
            for key in x.keys():
                y[key] = json2paramater(x[key], is_rand, random_state, oldy[key]
                                        if oldy != None else None, Rand, name + "[%s]" % str(key))
    elif isinstance(x, list):
        y = list()
        for i, x_i in enumerate(x):
            y.append(json2paramater(x_i, is_rand, random_state, oldy[i]
                                    if oldy != None else None, Rand, name + "[%d]" % i))
    else:
        y = copy.deepcopy(x)
    return y
```


Overlapping Code:
```
son2paramater(x, is_rand, random_state, oldy=None, Rand=False, name=NodeType.Root.value):
'''
Json to pramaters.
'''
if isinstance(x, dict):
if NodeType.Type.value in x.keys():
_type = x[NodeType.Type.value]
_value = x[NodeType.Value.value]
name = name + '-' + _type
Rand |= is_rand[name]
if Rand is True:
if _type == 'choice':
_index = random_state.randint(len(_value))
y = {
NodeType.Index.value: _index,
NodeType.Value.value: json2paramater(x[NodeType.Value.value][_index],
is_rand,
random_state,
None,
Rand,
name=name+"[%d]" % _index)
}
else:
y = eval('parameter_expressions.' +
_type)(*(_value + [random_state]))
else:
y = copy.deepcopy(oldy)
else:
y = dict()
for key in x.keys():
y[key] = json2paramater(x[key], is_rand, random_state, oldy[key]
if oldy != None else None, Rand, name + "[%s]" % str(key))
elif isinstance(x, list):
y = list()
for i, x_i in enumerate(x):
y.append(json2paramater(x_i, is_rand, random_state, oldy[i]
if oldy != None else None, Rand, name + "[%d]" % i))
else:
y = co
```
<Overlap Ratio: 0.9727626459143969>

---

--- 178 --
Question ID: 036a4a271cba9a7f33d36bfe2f346f0ff2ac4bd1_29
Original Code:
```
def multi_search(search_str):
    response = get_tmdb_data("search/multi?query=%s&" % url_quote(search_str), 1)
    if response and "results" in response:
        return response["results"]
    else:
        log("Error when searching for %s" % search_str)
        return ""
```


Overlapping Code:
```
= get_tmdb_data("search/multi?query=%s&" % url_quote(search_str), 1)
if response and "results" in response:
return response["results"]
else:
log("Erro
```
<Overlap Ratio: 0.6329113924050633>

---

--- 179 --
Question ID: c9c10e0aa5b560f3cce9a55087728b0f5cccdc71_4
Original Code:
```
def get_file_pairs_from_composition_wikitext(wikitext):
    """
    CPDL Wikitext has lines like this:
    *{{PostedDate|2014-11-24}} {{CPDLno|33477}} [[Media:Torrejon-A_este_sol_peregrino.pdf|{{pdf}}]] [[Media:Torrejon-A_este_sol_peregrino.mid|{{mid}}]] [[Media:Torrejon-A_este_sol_peregrino.mxl|{{XML}}]] [[Media:Torrejon-A_este_sol_peregrino.musx|{{F14}}]] (Finale 2014)
    Look for these, and return ones that include an {{XML}} link. If there is also a PDF, return that too
    """
    parsed = mwph.parse(wikitext['content'])

    # Look for nodes which are {{CPDLno}} templates
    cpdl_nodes = [template for template in parsed.filter_templates() if template.name == 'CPDLno']
    cpdl_nodes.append(parsed.nodes[-1])

    ret = []

    # For each of these nodes, from the node to the next, see if there is
    # a wikilink with {{XML}}. If so, return both the pdf in this range if it exists
    # and the xml file
    # e.g. nodes 3, 12, 15. We append the last node so that we can group them
    # into 3-12, 12-15, 15-end
    parsed_nodes = parsed.nodes
    for i in range(len(cpdl_nodes)-1):
        start = cpdl_nodes[i]
        end = cpdl_nodes[i+1]
        try:
            start_i = parsed_nodes.index(start)
            end_i = parsed_nodes.index(end)
        except ValueError:
            continue
        relevant_nodes = parsed_nodes[start_i:end_i]
        wikilinks = [n for n in relevant_nodes if isinstance(n, mwph.nodes.Wikilink)]
        xml_templates = [str(n.title) for n in wikilinks if n.text == "{{XML}}"]
        pdf_templates = [str(n.title) for n in wikilinks if n.text == "{{pdf}}"]

        if len(xml_templates) == 1 and len(pdf_templates) in [0, 1]:
            xml = xml_templates[0]
            pdf = pdf_templates[0] if len(pdf_templates) else None
            data = {"xml": xml.replace("Media:", "File:")}
            if pdf:
                data["pdf"] = pdf.replace("Media:", "File:")

            ret.append(data)

    return ret
```


Overlapping Code:
```
text):
"""
CPDL Wikitext has lines like this:
*{{PostedDate|2014-11-24}} {{CPDLno|33477}} [[Media:Torrejon-A_este_sol_peregrino.pdf|{{pdf}}]] [[Media:Torrejon-A_este_sol_peregrino.mid|{{mid}}]] [[Media:Torrejon-A_este_sol_peregrino.mxl|{{XML}}]] [[Media:Torrejon-A_este_sol_peregrino.musx|{{F14}}]] (Finale 2014)
Look for these, and return ones that include an {{XML}} link. If there is also a PDF, return that too
"""
parsed = mwph.parse(wikitext['content'])
# Look for nodes which are {{CPDLno}} templates
cpdl_nodes = [template for template in parsed.filter_templates() if template.name == 'CPDLno']
cpdl_nodes.append(parsed.nodes[-1])
ret = []
# For each of these nodes, from the node to the next, see if there is
# a wikilink with {{XML}}. If so, return both the pdf in this range if it exists
# and the xml file
# e.g. nodes 3, 12, 15. We append the last node so that we can group them
# into 3-12, 12-15, 15-end
parsed_nodes = parsed.nodes
for i in range(len(cpdl_nodes)-1):
start = cpdl_nodes[i]
end = cpdl_nodes[i+1]
try:
start_i = parsed_nodes.index(start)
end_i = parsed_nodes.index(end)
except ValueError:
continue
relevant_nodes = parsed_nodes[start_i:end_i]
wikilinks = [n for n in relevant_nodes if isinstance(n, mwph.nodes.Wikilink)]
xml_templates = [str(n.title) for n in wikilinks if n.text == "{{XML}}"]
pdf_templates = [str(n.title) for n in wikilinks if n.text == "{{pdf}}"]
if len(xml_templates) == 1 and len(pdf_templates) in [0, 1]:
xml = xml_templates[0]
pdf = pdf_templates[0] if len(pdf_templates) else None
data = {"xml": xml.replace("Media:", "File:")}
if pdf:
data["pdf"] = pdf.replace("Media:", "File:")
ret.append(data
```
<Overlap Ratio: 0.9643483343074225>

---

--- 180 --
Question ID: 44fd57093cd4ae65f6ed17ef9aa879c90208cf5e_5
Original Code:
```
def toFollower(term):
    global currentTerm, state, timer, votedFor
    state = FOLLOWER
    currentTerm = term
    votedFor = -1
    timer = time()
```


Overlapping Code:
```
rentTerm, state, timer, votedFor
state = FOLLOWER

```
<Overlap Ratio: 0.3875968992248062>

---

--- 181 --
Question ID: 76341f6f83129e754888ee4c7c7b0c415cb48793_3
Original Code:
```
def DWM_enable_blur_behind_window(widget, enable=True):
    """
    Enable or disable blur behind window on a window.
    """
    if not has_dwm:
        return False

    bb = DWM_BLURBEHIND()
    bb.fEnable = c_bool(enable)
    bb.dwFlags = DWM_BB_ENABLE
    bb.hRgnBlur = None

    widget.setAttribute(Qt.WA_TranslucentBackground, enable)
    widget.setAttribute(Qt.WA_NoSystemBackground, enable)

    result = _DwmEnableBlurBehindWindow(pythonapi.PyCObject_AsVoidPtr(
                widget.winId()), bb)
    
    return not result
```


Overlapping Code:
```
et, enable=True):
"""
Enable or disable blur behind window on a window.
"""
if not has_dwm:
return False
bb = DWM_BLURBEHIND()
bb.fEnable = c_bool(enable)
bb.dwFlags = DWM_BB_ENABLE
bb.hRgnBlur = None
widget.setAttribute(Qt.WA_TranslucentBackground, enable)
widget.setAttribute(Qt.WA_NoSystemBackground, enable)
result = _DwmEnableBlurBehindWindow(pythonapi.PyCObject_AsVoidPtr(
widget.winId()), bb)

```
<Overlap Ratio: 0.8771929824561403>

---

--- 182 --
Question ID: 658b23bbf8aec7d5caf921a1991f906232e3f093_2
Original Code:
```
@pytest.mark.asyncio
@pytest.mark.messages_list
async def test_request_room_messages_that_do_not_exist(auth_token):
    """
    ...
    """
    communicator = WebsocketCommunicator(MessageConsumer, "/ws/chat/")
    connected, _ = await communicator.connect()
    assert connected

    # Test sending json
    await communicator.send_json_to(
        {
            "method": "R",
            "values": {"room_id": 100},
            "token": auth_token["super_user_admin"],
        }
    )

    await communicator.receive_json_from()
    # response = await communicator.receive_json_from()
    # assert response == 'y'

    # Close
    await communicator.disconnect()
```


Overlapping Code:
```
k.asyncio
@pytest.mark.messages_list
async def test_request_room_messages_that_do_not_exist(auth_token):
"""
...
"""
communicator = WebsocketCommunicator(MessageConsumer, "/ws/chat/")
connected, _ = await communicator.connect()
assert connected
# Test sending json
await communicator.send_json_to(
{
"method": "R",
"values": {"ro
)
await communicator.receive_json_from()
# response = await communicator.receive_json_from()
# assert response == 'y'
# Close
await communicator.disc
```
<Overlap Ratio: 0.8646209386281588>

---

--- 183 --
Question ID: 1f2aea5e6b4fe2f969e1898654f9b9ef365dffe5_5
Original Code:
```
def complain(what: str, iwant_object) -> dict:
    print(f'INFO: More than 1 {what} was found.')
    if what == 'behest':
        listing = f"`{'`, `'.join(iwant_object.possible_behests)}`"
    elif what == 'activity':
        listing = f"`{'`, `'.join(iwant_object.possible_activities)}`"
    else:
        print(f'WARNING: Someone complain to "{what}", but unknown meaning.')
        return {'text': 'You cannot want this.'}

    return {'text': f'You can use only one {what} from {listing} at the same time.'}
```


Overlapping Code:
```
 str, iwant_object) -> dict:
print(f'INFO: More than 1 {what} was found.')
if what == 'behest':
listing = f"`{'`, `'.join(iwant_object.possible_behests)}`"
elif what == 'activity':
listing = f"`{'`, `'.join(iwant_object.possible_activities)}`"
else:
print(f'WARNING: Someone complain to "{what}", but unknown meaning.')
return {'text': 'You cannot want this.'}
return {'text': f'You can use only one 
```
<Overlap Ratio: 0.8714596949891068>

---

--- 184 --
Question ID: 1100651f69c86cccb4a06a87f3e5a059cd119a6a_1
Original Code:
```
def precision_recall(classifier):
    refsets = collections.defaultdict(set)
    testsets = collections.defaultdict(set)
    print('pos precision:', classifier.metrics.precision(refsets['pos'], testsets['pos']))
    print('pos recall:', classifier.metrics.recall(refsets['pos'], testsets['pos']))
    print('neg precision:', classifier.metrics.precision(refsets['neg'], testsets['neg']))
    print('neg recall:', classifier.metrics.recall(refsets['neg'], testsets['neg']))
```


Overlapping Code:
```
ision_recall(classifier):
refsets = collections.defaultdict(set)
testsets = collections.defaultdict(set)
print('pos precision:', classifier.metrics.precision(refsets['pos'], testsets['pos']))
print('pos recall:', classifier.metrics.recall(refsets['pos'], testsets['pos']))
print('neg precision:', classifier.metrics.precision(refsets['neg'], testsets['neg']))
print('neg recall:', classifier.metrics.recall(refsets['neg'], testsets['neg
```
<Overlap Ratio: 0.9732142857142857>

---

--- 185 --
Question ID: 539d4089c3e564ccea592e9dbf344f4b3f55b04e_10
Original Code:
```
def test_runner(region, q, key_name, extra_args):
    global success
    global failure
    global results_lock

    while True:
        item = q.get()

        retval = 1
        # just in case we miss an exception in run_test, don't abort everything...
        try:
            if not prochelp.termination_caught():
                run_test(
                    region=region,
                    distro=item["distro"],
                    scheduler=item["scheduler"],
                    instance_type=item["instance_type"],
                    key_name=key_name,
                    expected_asg_capacity=item["expected_asg_capacity"],
                    expected_compute_nodes=item["expected_compute_nodes"],
                    extra_args=extra_args,
                )
                retval = 0
        except (ReleaseCheckException, prochelp.ProcessHelperError, sub.CalledProcessError):
            pass
        except Exception as exc:
            print("[test_runner] Unexpected exception %s: %s\n" % (str(type(exc)), str(exc)))

        results_lock.acquire(True)
        if retval == 0:
            success += 1
        else:
            failure += 1
        results_lock.release()
        q.task_done()
```


Overlapping Code:
```
t_runner(region, q, key_name, extra_args):
global success
global failure
global results_lock
while True:
item = q.get()
retval = 1
# just in case we miss an exception in run_test, don't abort everything...
try:
if not prochelp.termination_caught():
run_test(
region=region,
distro=item["distro"],
scheduler=item["scheduler"],
instance_type=item["instance_type"],
key_name=key_name,
expected_asg_capacity=item["expected_asg_capacity"],
expected_compute_nodes=item["expected_compute_nodes"],
extra_args=extra_args,
)
retval = 0
except (ReleaseCheckException, prochelp.ProcessHelperError, sub.CalledProcessError):
pass
except Exception as exc:
print("[test_runner] Unexpected exception %s: %s\n" % (str(type(exc)), str(exc)))
results_lock.acquire(True)
if retval == 0:
success += 1
else:
failure += 1
results_lock.rel
```
<Overlap Ratio: 0.9678953626634959>

---

--- 186 --
Question ID: 821ecd85ba25c5ff3a4ed642fbe2f4c4e182a428_1
Original Code:
```
def produce_feed(sermons, links, connection):
    from feedgen.feed import FeedGenerator
    from datetime import datetime
    import pytz #lib to make datetime objects timezone aware.
    print("========== PRODUCING FEED! ===========")
    org_name = cf.read_config('MAIN', 'org_name')
    org_email = cf.read_config('MAIN', 'org_email')
    org_link = cf.read_config('MAIN', 'org_link')
    org_logo_link = "https://s3-ap-southeast-2.amazonaws.com/sermon-skeleton/index.png"
    # org_logo_link = fl.url_for('static', filename='img/ico.ico')

    fg = FeedGenerator()
    fg.load_extension('podcast')

    fg.title(org_name+" Podcast")
    fg.author({'name': org_name, 'email': org_email})
    fg.link(href=org_link)
    fg.logo(org_logo_link)
    fg.description(org_name+" sermons. Available for all.")
    fg.language('en')

    fg.podcast.itunes_category('Religion & Spirituality', 'Christianity')
    fg.podcast.itunes_explicit("clean")

    for sermon in sermons:
        fe = fg.add_entry()
        fe.id(links[sermon.id][0])
        fe.title(sermon.title)
        if sermon.description == '':
            fe.description("No description for this sermon.")
        else:
            fe.description(description=sermon.description, isSummary=True)
            print(sermon.description)
        fe.enclosure(links[sermon.id][0], str(sermon.length), 'audio/mpeg')
        
        # published takes in a datetime object, but we record date (time is
        # irrelevant...) so we need to instantiate a time to supply Feedgen
        date = datetime.combine(sermon.date_given, datetime.min.time())
        timezone = pytz.timezone("Australia/Sydney")
        date_tz = timezone.localize(date)
        fe.published(date_tz)

    fg.rss_file('podcast.xml')
    uploaded = connection.upload_resource('podcast.xml', 'xml', 'podcast.xml')
    if not uploaded:
        print("false for upload")
        old_podcast = connection.get_obj('podcast.xml')
        print("current object: "+ str(old_podcast))
        print("will we delete? "+ str(connection.rm_objs([old_podcast]) ))
        print("Trying again... "+ str(connection.upload_resource('podcast.xml', 'xml', 'podcast.xml')))

    else:
        # initial run case
        pass
```


Overlapping Code:
```
d(sermons, links, connection):
from feedgen.feed import FeedGenerator
from datetime import datetime
import pytz #lib to make datetime objects timezone aware.
print("========== PRODUCING FEED! ===========")
org_name = cf.read_config('MAIN', 'org_name')
org_email = cf.read_config('MAIN', 'org_email')
org_link = cf.read_config('MAIN', 'org_link')
org_logo_link = "https://s3-ap-southeast-2.amazonaws.com/sermon-skeleton/index.png"
# org_logo_link = fl.url_for('static', filename='img/ico.ico')
fg = FeedGenerator()
fg.load_extension('podcast')
fg.title(org_name+" Podcast")
fg.author({'name': org_name, 'email': org_email})
fg.link(href=org_link)
fg.logo(org_logo_link)
fg.description(org_name+" sermons. Available for all.")
fg.language('en')
fg.podcast.itunes_category('Religion & Spirituality', 'Christianity')
fg.podcast.itunes_explicit("clean")
for sermon in sermons:
fe = fg.add_entry()
fe.id(links[sermon.id][0])
fe.title(sermon.title)
if sermon.description == '':
fe.description("No description for this sermon.")
else:
fe.description(description=sermon.description, isSummary=True)
print(sermon.description)
fe.enclosure(links[sermon.id][0], str(sermon.length), 'audio/mpeg')

# published takes in a datetime object, but we record date (time is
# irrelevant...) so we need to instantiate a time to supply Feedgen
date = datetime.combine(sermon.date_given, datetime.min.time())
timezone = pytz.timezone("Australia/Sydney")
date_tz = timezone.localize(date)
fe.published(date_tz)
fg.rss_file('podcast.xml')
uploaded = connection.upload_resource('podcast.xml', 'xml', 'podcast.xml')
if not uploaded:
print("false for upload")
old_podcast = connection.get_obj('podcast.xml')
print("current object: "+ str(old_podcast))
print("will we delete? "+ str(connection.rm_objs([old_podcast]) ))
print("Trying again... "+ str(connection.upload_resource('podcast.xml', 'xml', 'podcast.xml')))
else:
# initia
```
<Overlap Ratio: 0.9844559585492227>

---

--- 187 --
Question ID: e626735d3c9fbbadf839f399c8163bb28aa204dc_5
Original Code:
```
@mark.gate
@mark.platform_incompatible(['ostl'])
def test_ecmp_dstip_enable(netop_login, topology, step, sanity_check):

    # enable ecmp dest ip

    ECMP_PATCH[0]["value"]["hash_dstip_enabled"] = (
        ECMP_PATCH[0]["value"].pop(list(ECMP_PATCH[0]["value"])[0])
    )
    ECMP_PATCH[0]["value"]["hash_dstip_enabled"] = TRUE

    status_code, response_data = execute_request(
        PATH, "PATCH", json.dumps(ECMP_PATCH), SWITCH_IP,
        False, xtra_header=cookie_header
    )

    assert status_code == http.client.NO_CONTENT, \
        "Error patching ecmp dest ip enable Status code: " \
        "%s Response data: %s " % (status_code, response_data)
    step("### Enable Dest IP ECMP Patched. "
         "Status code is 204 NO CONTENT  ###\n")

    # Verify data
    status_code, response_data = execute_request(
        PATH, "GET", None, SWITCH_IP, False,
        xtra_header=cookie_header
    )

    assert status_code == http.client.OK, "Failed to query ecmp config"
    json_data = get_json(response_data)
    assert json_data["configuration"]["ecmp_config"]["hash_dstip_enabled"] \
        == TRUE, "ECMP dest IP enable failed"
    step("### ECMP dest IP enable validated ###\n")
```


Overlapping Code:
```
mark.gate
@mark.platform_incompatible(['ostl'])
def test_ecmp_dstip_enable(netop_login, topology, step, sanity_check):
# enable ecmp dest ip
ECMP_PATCH[0]["value"]["hash_dstip_enabled"] = (
ECMP_PATCH[0]["value"].pop(list(ECMP_PATCH[0]["value"])[0])
)
ECMP_PATCH[0]["value"]["hash_dstip_enabled"] = TRUE
status_code, response_data = execute_request(
PATH, "PATCH", json.dumps(ECMP_PATCH), SWITCH_IP,
False, xtra_header=cookie_header
)
assert status_code == http.client.NO_CONTENT, \
"Error patching ecmp dest ip enable Status code: " \
"%s Response data: %s " % (status_code, response_data)
step("### Enable Dest IP ECMP Patched. "
"Status code is 204 NO CONTENT ###\n")
# Verify data
status_code, response_data = execute_request(
PATH, "GET", None, SWITCH_IP, False,
xtra_header=cookie_header
)
assert status_code == http.client.OK, "Failed to query ecmp config"
json_data = get_json(response_data)
assert json_data["configuration"]["ecmp_config"]["hash_dstip_enabled"] \
== TRUE, "ECMP dest IP enable failed"
step("
```
<Overlap Ratio: 0.9603399433427762>

---

--- 188 --
Question ID: 5c7f7d1cad4c4947e6ca038c4d1651b3134a707f_17
Original Code:
```
def test_midcurve_vol():
    replace = Replacer()
    mock_usd = Currency('MA890', 'USD')
    xrefs = replace('gs_quant.timeseries.measures.GsAssetApi.get_asset_xrefs', Mock())
    xrefs.return_value = [GsTemporalXRef(dt.date(2019, 1, 1), dt.date(2952, 12, 31), XRef(bbid='USD', ))]
    identifiers = replace('gs_quant.timeseries.measures.GsAssetApi.map_identifiers', Mock())
    identifiers.return_value = {'USD-LIBOR-BBA': 'MA123'}
    replace('gs_quant.timeseries.measures.GsDataApi.get_market_data', mock_curr)
    actual = tm.midcurve_vol(mock_usd, '3m', '1y', '1y', 50)
    assert_series_equal(pd.Series([1, 2, 3], index=_index * 3, name='midcurveVol'), actual)
    with pytest.raises(NotImplementedError):
        tm.midcurve_vol(..., '3m', '1y', '1y', 50, real_time=True)
    replace.restore()
```


Overlapping Code:
```
ef test_midcurve_vol():
replace = Replacer()
mock_usd = Currency('MA890', 'USD')
xrefs = replace('gs_quant.timeseries.measures.GsAssetApi.get_asset_xrefs', Mock())
xrefs.return_value = [GsTemporalXRef(dt.date(2019, 1, 1), dt.date(2952, 12, 31), XRef(bbid='USD', ))]
identifiers = replace('gs_quant.timeseries.measures.GsAssetApi.map_identifiers', Mock())
identifiers.return_value = {'USD-LIBOR-BBA': 'MA123'}
replace('gs_quant.timeseries.measures.GsDataApi.get_market_data', mock_curr)
actual = tm.midcurve_vol(mock_usd, '3m', '1y', '1y', 50)
assert_series_equal(pd.Series([1, 2, 3], index=_index * 3, name='midcurveVol'), actual)
with pytest.raises(NotImplementedError):
tm.midcurve_vol(..., '3m', '1y', '1y', 50, real_time=True)
replace.restore(
```
<Overlap Ratio: 0.9973297730307076>

---

--- 189 --
Question ID: c7794e99fc646416806c03a485b55a23b082ff62_10
Original Code:
```
def export_papers_table(filename, rows):
    results = []
    for row in rows:
        numpt = row['NumLANLIsolatesQCPassed']
        if not numpt:
            continue
        results.append({
            'PubMedID': row['PubMedID'],
            'PubYear': row['PubYear'],
            'NumPatients': numpt,
            'RxStatus': row['RxStatus'],
            'Title': row['Title'],
            'Subtypes': row['Subtypes'],
            'Authors': row['Authors'],
        })
    csv_writer(filename, results, CLEAN_TABLE_HEADERS)
```


Overlapping Code:
```
t_papers_table(filename, rows):
results = []
for row in rows:
numpt = row['NumLANLIsolatesQCPassed']
if not numpt:
continue
results.append({
'PubMedID': row['PubMedID'],
'PubYear': row['PubYear'],
'NumPatients': numpt,
'RxStatus': row['RxStatus'],
'Title': row['Title'],
'Subtypes': row['Subtypes'],
'Authors': row['Authors'],
})
csv_writer(filename,
```
<Overlap Ratio: 0.8997429305912596>

---

--- 190 --
Question ID: 581dc1b573fdb022e2a285aaa5826218f438ca2f_3
Original Code:
```
def create_babel_i18n(_app):
    """ i18n configuration
    :param _app: Flask app
    :return: Babel configuration
    """
    return Babel(_app)
```


Overlapping Code:
```
_app):
""" i18n configuration
:param _app: Flask app
:return: Babel configuration
"""
return Babel(_
```
<Overlap Ratio: 0.7936507936507936>

---

--- 191 --
Question ID: 4c8f26472ed09522208b73357645ffd2a4092d1f_2
Original Code:
```
def handlefile(file):
    if this.usefilesize:
        tuple = (str(os.path.basename(file)), max(1, int(os.path.getsize(file))))
        return tuple
    else:
        return str(os.path.basename(file))
```


Overlapping Code:
```
ilesize:
tuple = (str(os.path.basename(file)), max(1, int(os.path.getsize(file))))
return tuple
else
```
<Overlap Ratio: 0.5882352941176471>

---

--- 192 --
Question ID: 73595d0356a1da6efdacc82d9051b1ca7e85e85b_19
Original Code:
```
def main(prog_name=os.path.basename(sys.argv[0]), args=None):
    if args is None:
        args = sys.argv[1:]
    parser = create_parser(prog_name)
    args = parser.parse_args(args)

    if args.verbose is None:
        verbose_level = 0
    else:
        verbose_level = args.verbose

    setup_loggers(verbose_level=verbose_level)

    config = load_config()

    if args.command == "create":
        do_create_artifact(args, config) 
    elif args.command == "list-artifact":
        do_list_artifact(args, config)
    elif args.command == "retrieve":
        do_retrieve_artifact(args, config)
    elif args.command == "amend":
        do_amend_artifact(args, config)    
    elif args.command == "AddArtifact":
        do_add_sub_artifact(args, config)  
    elif args.command == "AddURI":
        do_add_uri_to_artifact(args,config)
    else:    
        raise ArtifactException("invalid command {}".format(args.command))
```


Overlapping Code:
```
def main(prog_name=os.path.basename(sys.argv[0]), args=None):
if args is None:
args = sys.argv[1:]
parser = create_parser(prog_name)
args = parser.parse_args(args)
if args.verbose is None:
verbose_level = 0
else:
verbose_level = args.verbose
setup_loggers(verbose_level=verbose_level)
config = load_config()
if args.command == "create":
do_create_artifact(args, config) 
elif args.command == "list-artifact":
do_list_artifact(args, config)
elif args.command == "retrieve":
do_retrieve_artifact(args, config)
elif args.command == "amend":
do_amend_artifact(args, config) 
elif args.command == "AddArtifact":
do_add_sub_artifact(args, config) 
elif args.command == "AddURI":
do_add_uri_to_artifact(args,config)
else: 
raise ArtifactException("inv
```
<Overlap Ratio: 0.9514066496163683>

---

--- 193 --
Question ID: aa875c2026f5a8927de62ff56dd5fbb29ebe876b_9
Original Code:
```
def moveFilesToFolder(lst, destFolderPath):
    for f in lst:
        base = basename(f)
        dest = os.path.join(destFolderPath, base)
        print("Moving: ", f, "      To: ", dest)
        shutil.move(f, dest)
```


Overlapping Code:
```
, destFolderPath):
for f in lst:
base = basename(f)
dest = os.path.join(destFolderPath, base)
print("Moving: ", f, " To: ", dest)
shutil.move(f, dest)
```
<Overlap Ratio: 0.8571428571428571>

---

--- 194 --
Question ID: e00b74faa37845674d4a561d04e62314a13a9c89_1
Original Code:
```
def ensure_string(obj):
    """Return String and if Unicode convert to string.

    :param obj: ``str`` || ``unicode``
    :return: ``str``
    """

    if sys.version_info < (3, 2, 0) and isinstance(obj, unicode):
        return str(obj.encode('utf8'))
    else:
        return obj
```


Overlapping Code:
```
"""Return String and if Unicode convert to string.
:param obj: ``str`` || ``unicode``
:return: ``str``
"""
if sys.version_info < (3, 2, 0) and isinstance(obj, unicode):
return str(obj.encode('utf8'))

```
<Overlap Ratio: 0.8333333333333334>

---

--- 195 --
Question ID: 8bade1deeb24afd4b054cc023315e1438a266c8b_1
Original Code:
```
def get_args():
    parser = argparse.ArgumentParser(description='Echo')
    parser.add_argument('host', default=HOST, help='', nargs='?')
    parser.add_argument('port', default=PORT,
                        help='Port',
                        nargs='?')

    args = parser.parse_args()

    return args
```


Overlapping Code:
```
def get_args():
parser = argparse.ArgumentParser(description='Echo')
parser.add_argument('host', default=HOST, help='', nargs='?')
parser.add_argument('port', default=PORT,
help='Port',
nargs='?')
args = parser.parse_args()
return ar
```
<Overlap Ratio: 0.9914893617021276>

---

--- 196 --
Question ID: 75e96f1beb2324c685a831777a0aa3d0918f1302_0
Original Code:
```
def extract(
    ho_start: "YYYY-MM-dd",  # noqa: F821
    spark,
    ho_win=7,
    model_win=120,
    samp_fraction=0.1,
    sample_ids=[0],
    check_min_users=50000,
    source="hive",
    bigquery_parameters=None,
) -> Tuple[pd.DataFrame, int]:
    """
    check_min_users: minimum number of users that should be pulled
    TODO: heuristic to get a high enough sample size
    """
    dfs_all, _q = run_rec_freq_spk(
        model_win=model_win,
        ho_start=ho_start,
        sample_ids=sample_ids,
        spark=spark,
        holdout=True,
        ho_win=ho_win,
        source=source,
        bigquery_parameters=bigquery_parameters,
    )
    df = dfs_all.sample(fraction=samp_fraction)
    user_col = "n_custs"
    dfpr = (
        reduce_rec_freq_spk(df, rfn_cols=["Recency", "Frequency", "N"])
        .toPandas()
        # Rename to conform to api
        .rename(columns=str.lower)
        .rename(columns={"n_users": user_col})
    )
    n_users = dfpr[user_col].sum()
    print("{:,.0f} users pulled".format(n_users))
    assert (
        dfpr[user_col].sum() > check_min_users
    ), "Assuming we're training on at least {} clients".format(check_min_users)

    return dfpr, n_users
```


Overlapping Code:
```
def extract(
ho_start: "YYYY-MM-dd", # noqa: F821
spark,
ho_win=7,
model_win=120,
samp_fraction=0.1,
sample_ids=[0],
check_min_users=50000,
source="hive",
bigquery_parameters=None,
) -> Tuple[pd.DataFrame, int]:
"""
check_min_users: minimum number of users that should be pulled
TODO: heuristic to get a high enough sample size
"""
dfs_all, _q = run_rec_freq_spk(
model_win=model_win,
ho_start=ho_start,
sample_ids=sample_ids,
spark=spark,
holdout=True,
ho_win=ho_win,
source=source,
bigquery_parameters=bigquery_parameters,
)
df = dfs_all.sample(fraction=samp_fraction)
user_col = "n_custs"
dfpr = (
reduce_rec_freq_spk(df, rfn_cols=["Recency", "Frequency", "N"])
.toPandas()
# Rename to conform to api
.rename(columns=str.lower)
.rename(columns={"n_users": user_col})
)
n_users = dfpr[user_col].sum()
print("{:,.0f} users pulled".format(n_users))
assert (
dfpr[user_col].sum() > check_min_users
), "Assuming we're training on at least {} clients".f
```
<Overlap Ratio: 0.9566968781470292>

---

--- 197 --
Question ID: a2046a045297bcf697640e8b3d61277c84c39f8c_0
Original Code:
```
@pytest.fixture
def exp_dispatcher(mocker, networked_nodes_base):   # noqa: F811
    api = mocker.Mock()
    api.get_nodes = mocker.Mock(
        return_value={'items': networked_nodes_base}
    )
    yield descs_runner.ExperimentDispatcher("test.yaml", api=api)
```


Overlapping Code:
```
networked_nodes_base): # noqa: F811
api = mocker.Mock()
api.get_nodes = mocker.Mock(
return_value={'items': networked_nodes_base}
)
yield descs_runner
```
<Overlap Ratio: 0.635593220338983>

---

--- 198 --
Question ID: 0858bdf07307dd7bb8a3aca228e2e86a3fd595f6_1
Original Code:
```
def test_message_handler_commands_two_handlers(bot: vk_bot.VkBot):
    @bot.message_handler(commands=['start'])
    def command_handler(message):
        message.text_lower = 'not got'

    @bot.message_handler(commands=['help'])
    def help_handler(message):
        message.text_lower = 'got'

    msg = vk_bot.Message.from_dict(create_message(text='!help something'))
    bot._process_new_message(msg)

    assert msg.command == 'help' and msg.text == 'something' and msg.text_lower == 'got'
```


Overlapping Code:
```
ef test_message_handler_commands_two_handlers(bot: vk_bot.VkBot):
@bot.message_handler(commands=['start'])
def command_handler(message):
message.text_lower = 'not got'
@bot.message_handler(commands=['help'])
def help_handler(message):
message.text_lower = 'got'
msg = vk_bot.Message.from_dict(create_message(text='!help something'))
bot._process_new_message(msg)
assert msg.command == 'help' and msg.
```
<Overlap Ratio: 0.8928571428571429>

---

--- 199 --
Question ID: 5b20f43d1e8858c0cecff4f03261d9d1d9c3d1bf_14
Original Code:
```
def concat_dicts(d1, d2):
    d = d1.copy()
    d.update(d2)
    return d
```


Overlapping Code:
```

```
<Overlap Ratio: 0.0>

---

--- 200 --
Question ID: ec5796792eda1d6437f4f053abebce1203f89657_6
Original Code:
```
def test_ct():
    N_TURBINES = 4

    turbine_data = SampleInputs().turbine
    turbine = Turbine.from_dict(turbine_data)
    turbine_type_map = np.array(N_TURBINES * [turbine.turbine_type])
    turbine_type_map = turbine_type_map[None, None, :]

    # Single turbine
    # yaw angle / fCt are (n wind direction, n wind speed, n turbine)
    wind_speed = 10.0
    thrust = Ct(
        velocities=wind_speed * np.ones((1, 1, 1, 3, 3)),
        yaw_angle=np.zeros((1, 1, 1)),
        fCt=np.array([(turbine.turbine_type, turbine.fCt_interp)]),
        turbine_type_map=turbine_type_map[:,:,0]
    )

    truth_index = turbine_data["power_thrust_table"]["wind_speed"].index(wind_speed)
    np.testing.assert_allclose(thrust, turbine_data["power_thrust_table"]["thrust"][truth_index])

    # Multiple turbines with index filter
    # 4 turbines with 3 x 3 grid arrays
    thrusts = Ct(
        velocities=np.ones((N_TURBINES, 3, 3)) * WIND_CONDITION_BROADCAST,  # 3 x 4 x 4 x 3 x 3
        yaw_angle=np.zeros((1, 1, N_TURBINES)),
        fCt=np.array([(turbine.turbine_type, turbine.fCt_interp)]),
        turbine_type_map=turbine_type_map,
        ix_filter=INDEX_FILTER,
    )
    assert len(thrusts[0, 0]) == len(INDEX_FILTER)

    for i in range(len(INDEX_FILTER)):
        truth_index = turbine_data["power_thrust_table"]["wind_speed"].index(WIND_SPEEDS[0])
        np.testing.assert_allclose(thrusts[0, 0, i], turbine_data["power_thrust_table"]["thrust"][truth_index])
```


Overlapping Code:
```
= 4
turbine_data = SampleInputs().turbine
turbine = Turbine.from_dict(turbine_data)
turbine_type_map = np.array(N_TURBINES * [turbine.turbine_type])
turbine_type_map = turbine_type_map[None, None, :]
# Single turbine
# yaw angle / fCt are (n wind direction, n wind speed, n turbine)
wind_speed = 10.0
thrust = Ct(
velocities=wind_speed * np.ones((1, 1, 1, 3, 3)),
yaw_angle=np.zeros((1, 1, 1)),
fCt=np.array([(turbine.turbine_type, turbine.fCt_interp)]),
turbine_type_map=turbine_type_map[:,:,0]
)
truth_index = turbine_data["power_thrust_table"]["wind_speed"].index(wind_speed)
np.testing.assert_allclose(thrust, turbine_data["power_thrust_table"]["thrust"][truth_index])
# Multiple turbines with index filter
# 4 turbines with 3 x 3 grid arrays
thrusts = Ct(
velocities=np.ones((N_TURBINES, 3, 3)) * WIND_CONDITION_BROADCAST, # 3 x 4 x 4 x 3 x 3
yaw_angle=np.zeros((1, 1, N_TURBINES)),
fCt=np.array([(turbine.turbine_type, turbine.fCt_interp)]),
turbine_type_map=turbine_type_map,
ix_filter=INDEX_FILTER,
)
assert len(thrusts[0, 0]) == len(INDEX_FILTER)
for i in range(len(INDEX_FILTER)):
truth_index = turbine_data["power_thrust_table"]["wind_speed"].index(WIND_SPEEDS[0])
np.testing.assert_allclose(thrusts[0, 0, i], turbine_data["power_thrust_table"]["thrust"][truth_
```
<Overlap Ratio: 0.9747126436781609>

---

--- 201 --
Question ID: 5ce0d38f64d98f27c8796affbb3105766dfea656_13
Original Code:
```
@given(
    data_stack_depth=data_stack_depths(with_room_for_values=2),
    tos=unsigned_numbers,
    nos=unsigned_numbers,
)
def test_unsigned_greaterthan(emulator, data_stack, data_stack_depth, tos, nos):
    # Arrange
    data_stack.set_depth_in_bytes(data_stack_depth)
    data_stack.push_word(nos)
    data_stack.push_word(tos)
    # Act
    _do_test_thread(emulator, "forth.core.ext.U>")
    # Assert
    assert (nos > tos) == data_stack.pop_flag()
    assert data_stack_depth == len(data_stack)
```


Overlapping Code:
```
given(
data_stack_depth=data_stack_depths(with_room_for_values=2),
tos=unsigned_numbers,
nos=unsigned_numbers,
)
def test_unsigned_greaterthan(emulator, data_stack, data_stack_depth, tos, nos):
# Arrange
data_stack.set_depth_in_bytes(data_stack_depth)
data_stack.push_word(nos)
data_stack.push_word(tos)
# Act
_do_test_thread(emulator, "forth.core.ext.U>")
# Assert
assert (nos > tos) == data_stack.pop_flag()
assert data_stack_depth == le
```
<Overlap Ratio: 0.9690949227373068>

---

--- 202 --
Question ID: ce393ab101de5c7a2c49b55dc56aa4e3b86fa56c_1
Original Code:
```
def evaluate(model, path, iou_thres, conf_thres, nms_thres, img_size, batch_size):
    model.eval()

    # Get dataloader
    dataset = ListDataset(path, img_size=img_size, augment=False, multiscale=False)
    dataloader = torch.utils.data.DataLoader(
        dataset, batch_size=batch_size, shuffle=False, num_workers=1, collate_fn=dataset.collate_fn
    )

    Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor

    labels = []
    sample_metrics = []  # List of tuples (TP, confs, pred)
    itime=[]
    results=[]
    count = len(results)
    for batch_i, (imname, imgs, targets) in enumerate(tqdm.tqdm(dataloader, desc="Detecting objects")):
        
        # Extract labels
        labels += targets[:, 1].tolist()
        # Rescale target
        targets[:, 2:] = xywh2xyxy(targets[:, 2:])
        targets[:, 2:] *= img_size

        imgs = Variable(imgs.type(Tensor), requires_grad=False)
        prev_time = time.time()
        with torch.no_grad():
            outputs = model(imgs)
            outputs = non_max_suppression(outputs, conf_thres=conf_thres, nms_thres=nms_thres)
        current_time = time.time()
        inference_time = current_time - prev_time
        itime.append(inference_time) 
        sample_metrics += get_batch_statistics(outputs, targets, iou_threshold=iou_thres)
        anns,count = get_results(outputs,imname,count)
        if anns is not None:
            results.append(anns)
    print ('Mean inference time',np.mean(itime))
    # Concatenate sample statistics
    true_positives, pred_scores, pred_labels = [np.concatenate(x, 0) for x in list(zip(*sample_metrics))]
    precision, recall, AP, f1, ap_class = ap_per_class(true_positives, pred_scores, pred_labels, labels)
    json.dump(results, open('output/results.json','w'))
    return precision, recall, AP, f1, ap_class
```


Overlapping Code:
```
el, path, iou_thres, conf_thres, nms_thres, img_size, batch_size):
model.eval()
# Get dataloader
dataset = ListDataset(path, img_size=img_size, augment=False, multiscale=False)
dataloader = torch.utils.data.DataLoader(
dataset, batch_size=batch_size, shuffle=False, num_workers=1, collate_fn=dataset.collate_fn
)
Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor
labels = []
sample_metrics = [] # List of tuples (TP, confs, pred)
itime=[]
results=[]
count = len(results)
for batch_i, (imname, imgs, targets) in enumerate(tqdm.tqdm(dataloader, desc="Detecting objects")):

# Extract labels
labels += targets[:, 1].tolist()
# Rescale target
targets[:, 2:] = xywh2xyxy(targets[:, 2:])
targets[:, 2:] *= img_size
imgs = Variable(imgs.type(Tensor), requires_grad=False)
prev_time = time.time()
with torch.no_grad():
outputs = model(imgs)
outputs = non_max_suppression(outputs, conf_thres=conf_thres, nms_thres=nms_thres)
current_time = time.time()
inference_time = current_time - prev_time
itime.append(inference_time) 
sample_metrics += get_batch_statistics(outputs, targets, iou_threshold=iou_thres)
anns,count = get_results(outputs,imname,count)
if anns is not None:
results.append(anns)
print ('Mean inference time',np.mean(itime))
# Concatenate sample statistics
true_positives, pred_scores, pred_labels = [np.concatenate(x, 0) for x in list(zip(*sample_metrics))]
precision, recall, AP, f1, ap_class = ap_per_class(true_positives, pred_scores, pred_labels, labels)
json.dump(results, open('output/results.json','w')
```
<Overlap Ratio: 0.9627329192546584>

---

--- 203 --
Question ID: 5c79f4a7efe63998a601d6528e27c87f02edeb2b_4
Original Code:
```
def add_noise (df, n_columns, ammount):
    '''
    Given a dataframe add noise to n_columns
    '''
    columns = list(df)
    for column in np.random.choice(columns, n_columns):
        
        if df[column].dtype == 'object':
            df[column] = categorical_noise(df[column], ammount)
        elif df[column].dtype in ['int64', 'int32', 'float64', 'float32']:
            df[column] = scalar_noise(df[column], ammount)
    
    return df
```


Overlapping Code:
```
olumns, ammount):
'''
Given a dataframe add noise to n_columns
'''
columns = list(df)
for column in np.random.choice(columns, n_columns):

if df[column].dtype == 'object':
df[column] = categorical_noise(df[column], ammount)
elif df[column].dtype in ['int64', 'int32', 'float64', 'float32']:
df[column
```
<Overlap Ratio: 0.8108108108108109>

---

--- 204 --
Question ID: 8f1aca9e6196f7def8e8a7695baa06c4092d0d61_0
Original Code:
```
def test_Thompson2003Spatial():
    # Thompson2003Spatial automatically sets `radius`:
    model = Thompson2003Spatial(engine='serial', xystep=5)
    # User can set `radius`:
    model.radius = 123
    npt.assert_equal(model.radius, 123)
    model.build(radius=987)
    npt.assert_equal(model.radius, 987)

    # Nothing in, None out:
    npt.assert_equal(model.predict_percept(ArgusI()), None)

    # Converting ret <=> dva
    model2 = Thompson2003Spatial(retinotopy=Watson2014DisplaceMap())
    npt.assert_equal(isinstance(model2.retinotopy, Watson2014DisplaceMap),
                     True)

    implant = ArgusI(stim=np.zeros(16))
    # Zero in = zero out:
    percept = model.predict_percept(implant)
    npt.assert_equal(isinstance(percept, Percept), True)
    npt.assert_equal(percept.shape, list(model.grid.x.shape) + [1])
    npt.assert_almost_equal(percept.data, 0)

    # Multiple frames are processed independently:
    model = Thompson2003Spatial(engine='serial', radius=200, xystep=5,
                                xrange=(-20, 20), yrange=(-15, 15))
    model.build()
    percept = model.predict_percept(ArgusI(stim={'A1': [1, 0], 'B3': [0, 2]}))
    npt.assert_equal(percept.shape, list(model.grid.x.shape) + [2])
    pmax = percept.data.max(axis=(0, 1))
    npt.assert_almost_equal(percept.data[2, 3, 0], pmax[0])
    npt.assert_almost_equal(percept.data[2, 3, 1], 0)
    npt.assert_almost_equal(percept.data[3, 4, 0], 0)
    npt.assert_almost_equal(percept.data[3, 4, 1], pmax[1])
    npt.assert_almost_equal(percept.time, [0, 1])
```


Overlapping Code:
```
t_Thompson2003Spatial():
# Thompson2003Spatial automatically sets `radius`:
model = Thompson2003Spatial(engine='serial', xystep=5)
# User can set `radius`:
model.radius = 123
npt.assert_equal(model.radius, 123)
model.build(radius=987)
npt.assert_equal(model.radius, 987)
# Nothing in, None out:
npt.assert_equal(model.predict_percept(ArgusI()), None)
# Converting ret <=> dva
model2 = Thompson2003Spatial(retinotopy=Watson2014DisplaceMap())
npt.assert_equal(isinstance(model2.retinotopy, Watson2014DisplaceMap),
True)
implant = ArgusI(stim=np.zeros(16))
# Zero in = zero out:
percept = model.predict_percept(implant)
npt.assert_equal(isinstance(percept, Percept), True)
npt.assert_equal(percept.shape, list(model.grid.x.shape) + [1])
npt.assert_almost_equal(percept.data, 0)
# Multiple frames are processed independently:
model = Thompson2003Spatial(engine='serial', radius=200, xystep=5,
xrange=(-20, 20), yrange=(-15, 15))
model.build()
percept = model.predict_percept(ArgusI(stim={'A1': [1, 0], 'B3': [0, 2]}))
npt.assert_equal(percept.shape, list(model.grid.x.shape) + [2])
pmax = percept.data.max(axis=(0, 1))
npt.assert_almost_equal(percept.data[2, 3, 0], pmax[0])
npt.assert_almost_equal(percept.data[2, 3, 1], 0)
npt.assert_almost_equal(percept.data[3, 4, 0], 0)
npt.assert_almost_equal(percept.data[3, 4, 1], pmax[1])
npt.assert_almost_equal(percep
```
<Overlap Ratio: 0.9840464104423495>

---

--- 205 --
Question ID: a3400fed982201c13a6ae40f5aae4e5b1dc56603_0
Original Code:
```
def not_none(arg_name):
    def wrapper(func):
        def inner(self, *args, **kwargs):
            arg = getattr(self, arg_name)
            if arg is None:
                raise TypeError(
                    arg_name + " is not initialized! Use init_" + arg_name + "() or load_"+ arg_name + "() to initialize "
                    + arg_name + " first.")
            return  func(self, *args, **kwargs)
        return inner

    return wrapper
```


Overlapping Code:
```
def not_none(arg_name):
def wrapper(func):
def inner(self, *args, **kwargs):
arg = getattr(self, arg_name)
if arg is None:
raise TypeError(
arg_name + " is not initialized! Use init_" + arg_name + "() or load_"+ arg_name + "() to initialize "
+ arg_name + " first.")
return func(self, *args, **kwargs)
return inner
return wrapper
```
<Overlap Ratio: 1.0>

---

--- 206 --
Question ID: c0173e2df03e13aa3f3df73dd0a1d470656714ca_1
Original Code:
```
def main():
    n, m = read_list_int()
    islands = []
    for _ in range(n):
        row = list(sys.stdin.readline().strip())
        islands.append(row)
    print(solution(n, m, islands))
```


Overlapping Code:
```

islands = []
for _ in range(n):
row = list(sys.stdin.readline().strip())
islands.append(row)
print(
```
<Overlap Ratio: 0.6329113924050633>

---

--- 207 --
Question ID: 46a766a86230f7ed856136d090c8c0408f00fa5e_5
Original Code:
```
@manager.route('/<job_id>/<role>/<party_id>/cancel', methods=['POST'])
def cancel_job(job_id, role, party_id):
    res = JobController.cancel_job(job_id=job_id, role=role, party_id=int(party_id),
                                   job_initiator=request.json.get('job_initiator', {}))
    if res:
        return get_json_result(retcode=0, retmsg='cancel job success')
    return get_json_result(retcode=101, retmsg='cancel job failed')
```


Overlapping Code:
```
<role>/<party_id>/cancel', methods=['POST'])
def cancel_job(job_id, role, party_id):
res = JobController.cancel_job(job_id=job_id, role=role, party_id=int(party_id),
job_initiator=request.json.get('job_initiator', {}))
if res:
return get_json_result(retcode=0, retmsg='cancel job success')
return get_json_result(retcode=101, retmsg='cancel job faile
```
<Overlap Ratio: 0.9234828496042217>

---

--- 208 --
Question ID: a3da0f36dc0edcaead0767f88813529235989b4a_8
Original Code:
```
def create_readme(template_path, project_dir, project_name):
    """Check if a readme exists, and if not create one."""
    file_path = os.path.join(project_dir, 'README.md')
    if not os.path.isfile(file_path):
        if template_path:
            # Makes a copy of the template file
            shutil.copyfile(template_path, file_path)
            click.echo('Created a README file based on the provided template')
        else:
            # No template file was provided, use the standard
            with open(file_path, 'w') as f:
                f.write(f'# {project_name}\n\n## TODO\n\n## Hylla\nThis file was generated by [Hylla](https://github.com/adelhult/hylla). If you wish to use a template of your own. Specifiy the environmental varible HYLLA_README_TEMPLATE.')
            click.echo('Created a standard README file')
    else:
        click.echo('A README does already exist in the folder')
```


Overlapping Code:
```
mplate_path, project_dir, project_name):
"""Check if a readme exists, and if not create one."""
file_path = os.path.join(project_dir, 'README.md')
if not os.path.isfile(file_path):
if template_path:
# Makes a copy of the template file
shutil.copyfile(template_path, file_path)
click.echo('Created a README file based on the provided template')
else:
# No template file was provided, use the standard
with open(file_path, 'w') as f:
f.write(f'# {project_name}\n\n## TODO\n\n## Hylla\nThis file was generated by [Hylla](https://github.com/adelhult/hylla). If you wish to use a template of your own. Specifiy the environmental varible HYLLA_README_TEMPLATE.')
click.echo('Created a standard README file')
else:
click.echo('A README does already exist in
```
<Overlap Ratio: 0.9578544061302682>

---

--- 209 --
Question ID: 16b9d1d37c54317b50dfdee5ab5fb6e1d4c2af90_0
Original Code:
```
def test_numpyarray():
    for dtype1 in ("i1", "i2", "i4", "i8", "u1", "u2", "u4", "u8", "f4", "f8", "?"):
        for dtype2 in ("i1", "i2", "i4", "i8", "u1", "u2", "u4", "u8", "f4", "f8", "?"):
            for dtype3 in (
                "i1",
                "i2",
                "i4",
                "i8",
                "u1",
                "u2",
                "u4",
                "u8",
                "f4",
                "f8",
                "?",
            ):
                for dtype4 in (
                    "i1",
                    "i2",
                    "i4",
                    "i8",
                    "u1",
                    "u2",
                    "u4",
                    "u8",
                    "f4",
                    "f8",
                    "?",
                ):
                    one = np.array([0, 1, 2], dtype=dtype1)
                    two = np.array([3, 0], dtype=dtype2)
                    three = np.array([], dtype=dtype3)
                    four = np.array([4, 5, 0, 6, 7], dtype=dtype4)
                    combined = np.concatenate([one, two, three, four])

                    ak_combined = ak.layout.NumpyArray(one).mergemany(
                        [
                            ak.layout.NumpyArray(two),
                            ak.layout.NumpyArray(three),
                            ak.layout.NumpyArray(four),
                        ]
                    )

                    assert ak.to_list(ak_combined) == combined.tolist()
                    assert ak.to_numpy(ak_combined).dtype == combined.dtype

                    ak_combined = ak.layout.NumpyArray(one).mergemany(
                        [
                            ak.layout.NumpyArray(two),
                            ak.layout.EmptyArray(),
                            ak.layout.NumpyArray(four),
                        ]
                    )

                    assert ak.to_list(ak_combined) == combined.tolist()
                    assert (
                        ak.to_numpy(ak_combined).dtype
                        == np.concatenate([one, two, four]).dtype
                    )
```


Overlapping Code:
```
():
for dtype1 in ("i1", "i2", "i4", "i8", "u1", "u2", "u4", "u8", "f4", "f8", "?"):
for dtype2 in ("i1", "i2", "i4", "i8", "u1", "u2", "u4", "u8", "f4", "f8", "?"):
for dtype3 in (
"i1",
"i2",
"i4",
"i8",
"u1",
"u2",
"u4",
"u8",
"f4",
"f8",
"?",
):
for dtype4 in (
"i1",
"i2",
"i4",
"i8",
"u1",
"u2",
"u4",
"u8",
"f4",
"f8",
"?",
):
one = np.array([0, 1, 2], dtype=dtype1)
two = np.array([3, 0], dtype=dtype2)
three = np.array([], dtype=dtype3)
four = np.array([4, 5, 0, 6, 7], dtype=dtype4)
combined = np.concatenate([one, two, three, four])
ak_combined = ak.layout.NumpyArray(one).mergemany(
[
ak.layout.NumpyArray(two),
ak.layout.NumpyArray(three),
ak.layout.NumpyArray(four),
]
)
assert ak.to_list(ak_combined) == combined.tolist()
assert ak.to_numpy(ak_combined).dtype == combined.dtype
ak_combined = ak.layout.NumpyArray(one).mergemany(
[
ak.layout.NumpyArray(two),
ak.layout.EmptyArray(),
ak.layout.NumpyArray(four),
]
)
assert ak.to_list(ak_combined) == combined.tolist()
assert (
ak.to_numpy(ak_combined).dtype
== np.concatenate([one, two, 
```
<Overlap Ratio: 0.9695290858725761>

---

--- 210 --
Question ID: 8aac7ad2641c37bd8f65034205a1512380e6f979_11
Original Code:
```
@pytest.mark.parametrize('env_vars, expected', [
    (dict(), None),
    (dict(CI='true'), None),
    (dict(GCLOUD_PROJECT='example'), 'It is GCP but deal is enabled'),
    (dict(LAMBDA_TASK_ROOT='/home/'), 'It is AWS but deal is enabled'),
])
def test_enable__warnings(restore_state, env_vars, set_env_vars, expected):
    os.environ.clear()
    set_env_vars(env_vars)
    ewarn = RuntimeWarning if expected else None
    with pytest.warns(ewarn) as warns:
        deal.enable()
    if expected:
        assert len(warns) == 1
        assert str(warns[0].message) == f'{expected}. Is it intentional?'
    else:
        assert len(warns) == 0

    with pytest.warns(None) as warns:
        deal.enable(warn=False)
    assert len(warns) == 0
```


Overlapping Code:
```
ed', [
(dict(), None),
(dict(CI='true'), None),
(dict(GCLOUD_PROJECT='example'), 'It is GCP but deal is enabled'),
(dict(LAMBDA_TASK_ROOT='/home/'), 'It is AWS but deal is enabled'),
])
def test_enable__warnings(restore_state, env_vars, set_env_vars, expected):
os.environ.clear()
set_env_vars(env_vars)
ewarn = RuntimeWarning if expected else None
with pytest.warns(ewarn) as warns:
deal.enable()
if expected:
assert len(warns) == 1
assert str(warns[0].message) == f'{expected}. Is it intentional?'
else:
assert len(warns) == 0
with pytest.warns(None) as warns:
deal.enable(warn=False)
assert len(wa
```
<Overlap Ratio: 0.9216589861751152>

---

--- 211 --
Question ID: fa13b418dadba5b166b403a1291e9a20622ff124_0
Original Code:
```
def delete_id(impact_id, flash_msg=True):
	impact = Impact.query.filter_by(id=impact_id).limit(1).first()

	if impact:
		dbo.session.delete(impact)
		dbo.session.commit()

		if flash_msg:
			flash("Deleted Impact {}".format(impact.name), category='success')
```


Overlapping Code:
```
id, flash_msg=True):
impact = Impact.query.filter_by(id=impact_id).limit(1).first()
if impact:
dbo.session.delete(impact)
dbo.session.commit()
if flash_msg:
flash("Deleted Impact {}".format(impact.nam
```
<Overlap Ratio: 0.819672131147541>

---

--- 212 --
Question ID: 89fb95166632cbcb60d2dc648add95de85a6ad64_6
Original Code:
```
def pytest_addoption(parser):
    parser.addoption(
        "--no-conv-assertions", action="store_true", default=1,
        help='''
        Disable assertiong on Convolution class.
        ''')

    parser.addoption(
        "--test-level", action="store", type=int, default=2,
        help='''
        0= test Tensile.Convolution class;
        1= 0 plus generate YAML;
        2= 1 plus run tensile client and compare generated contraction vs CPU;
        3= 2 plus run tensile_client with convolution-vs-contraction (only forward conv tests which define Spatial will PASS )
        '''
        )
    parser.addoption(
        "--problem-level", action="store", type=int, default=2,
        help='''
        How many exact configurations to generate for contraction testing for non-src solutions (typically asm).
        1= single problem
        2= tens of problems
        3= hundreds of problems
        '''
        )
```


Overlapping Code:
```
def pytest_addoption(parser):
parser.addoption(
"--no-conv-assertions", action="store_true", default=1,
help='''
Disable assertiong on Convolution class.
''')
parser.addoption(
"--test-level", action="store", type=int, default=2,
help='''
0= test Tensile.Convolution class;
1= 0 plus generate YAML;
2= 1 plus run tensile client and compare generated contraction vs CPU;
3= 2 plus run tensile_client with convolution-vs-contraction (only forward conv tests which define Spatial will PASS )
'''
)
parser.addoption(
"--problem-level", action="store", type=int, default=2,
help='''
How many exact configurations to generate for contraction testing for non-src solutions (typically asm).
1= single problem
2= tens of problems
3= hundreds
```
<Overlap Ratio: 0.976>

---

--- 213 --
Question ID: 4812e9b0d21ad189393c62303d4d25cfa33481f2_1
Original Code:
```
def file_ref(*args, **kwargs):
    args = args[1:] if len(args) > 1 else []
    file_ref_str = "_".join(
        [f"{date.today():%Y%m%d}"]
        + [str(vv) for vv in args]
        + [str(vv) for vv in kwargs.values()]
    )
    return file_ref_str
```


Overlapping Code:
```
ef(*args, **kwargs):
args = args[1:] if len(args) > 1 else []
file_ref_str = "_".join(
[f"{date.today():%Y%m%d}"]
+ [str(vv) for vv in args]
+ [str(vv) for vv in kwargs.values()]
)
return file_ref_str
```
<Overlap Ratio: 0.9523809523809523>

---

--- 214 --
Question ID: 5994f22d2cb4c39e1e53070447029e3a3dbc5a7d_32
Original Code:
```
def headerfix(header):
    ## this code fix the header problem of fits out from CASA 5.4+ which leads to a streched solar image
    import copy
    hdr = copy.copy(header)
    for hd in header:
        if hd.upper().startswith('PC'):
            if not hd.upper().startswith('PC0'):
                hd_ = 'PC0' + hd.upper().replace('PC', '')
                hdr.pop(hd)
                hdr[hd_] = header[hd]
    return hdr
```


Overlapping Code:
```
r problem of fits out from CASA 5.4+ which leads t
```
<Overlap Ratio: 0.1497005988023952>

---

--- 215 --
Question ID: a680fd0271f4381d3a34de9ee580a642cbbd47ad_4
Original Code:
```
def regExpIn(x):
  """show time-formatted countdown."""
  if x==None or x==False:
    return "INVALID KEY"
  secInDay=60*60*24
  x=x-time.time()
  if x<=0:
    return "EXPIRED"
  d=int(x/(60*60*24));  x-=(60*60*24)*d
  h=int(x/(60*60));     x-=(60*60)*h
  m=int(x/60);          x-=(60)*m
  s=x
  return "%d days, %02d hours, %02d minutes, %02d seconds"%(d,h,m,s)
```


Overlapping Code:
```
atted countdown."""
if x==None or x==False:
return "INVALID KEY"
secInDay=60*60*24
x=x-time.time()
if x<=0:
return "EXPIRED"
d=int(x/(60*60*24)); x-=(60*60*24)*d
h=int(x/(60*60)); x-=(60*60)*h
m=int(x/60); x-=(60)*m
s=x
return "%d days, %02d hours, %
```
<Overlap Ratio: 0.78125>

---

--- 216 --
Question ID: 0c588378bd5401215cabdd21bf0ac6979ca81716_10
Original Code:
```
def user_music_dir():
    r"""Return full path to the user's music directory.

    Typical user desktop directories are:
        Mac OS X:   ~/Music
        Unix:       ~/Music  # or under $XDG_MUSIC_DIR if defined
        Windows:    C:\Users\<username>\Music

    Returns
    -------
    path : str
        Returns a full path to the directory.
    """
    if system == "darwin":
        path = os.path.expanduser('~/Music')
    elif system == "win32":
        path = _get_win_folder_from_knownid('{4BD8D571-6D19-48D3-BE97-422220080E43}')
    else:
        path = os.getenv('XDG_MUSIC_DIR', xdg_user_dirs['XDG_MUSIC_DIR'])
    return path
```


Overlapping Code:
```
 user_music_dir():
r"""Return full path to the user's music directory.
Typical user desktop directories are:
Mac OS X: ~/Music
Unix: ~/Music # or under $XDG_MUSIC_DIR if defined
Windows: C:\Users\<username>\Music
Returns
-------
path : str
Returns a full path to the directory.
"""
if system == "darwin":
path = os.path.expanduser('~/Music')
elif system == "win32":
path = _get_win_folder_from_knownid('{4BD8D571-6D19-48D3-BE97-422220080E43}')
else:
path = os.getenv('XDG_MUSIC_DIR', xdg_user_dirs['X
```
<Overlap Ratio: 0.9433962264150944>

---

--- 217 --
Question ID: 5314e2610299d51feaf0fb680356a310055b3292_0
Original Code:
```
def find_program_win(name, program_to_find='SOFTWARE\\7-Zip'):
    log = Log(name=name)
    try:
        h_key = winreg.CreateKey(winreg.HKEY_LOCAL_MACHINE, program_to_find)
        try:
            prog_path = (winreg.QueryValueEx(h_key, 'Path'))[0]
            return prog_path + '7z'
        except OSError:
            log("7-Zip isn't correctly installed!! ")
            return None
    except PermissionError:
        log("7-Zip not found!! ")
        answer = query_yes_no("Do you wish to install 7zip? ", default='yes')
        if answer:

            url = "https://www.7-zip.org/a/7z1900-x64.msi"
            log("Attempting to download {}".format(url))
            local_filename = url.split('/')[-1]

            with requests.get(url, stream=True) as r:
                r.raise_for_status()
                homepath = os.environ.get('HOMEPATH', ".")
                parentpath = "C:" + homepath + "\\Downloads\\"
                filepath = parentpath + local_filename
                with open(filepath, 'wb') as f:
                    for chunk in r.iter_content(chunk_size=8192):
                        if chunk:  # filter out keep-alive new chunks
                            f.write(chunk)

            log("Attempting to install {}".format(local_filename))
            print("Please check for a Windows Installer icon on the Task Bar and follow the prompts.")
            subprocess.call('msiexec /i "{fp}" /passive /norestart /l*v {pp}7zip_install.log'.format(fp=filepath,
                                                                                                     pp=parentpath))
            return find_program_win()
        else:
            return None
```


Overlapping Code:
```
OFTWARE\\7-Zip'):
log = Log(name=name)
try:
h_key = winreg.CreateKey(winreg.HKEY_LOCAL_MACHINE, program_to_find)
try:
prog_path = (winreg.QueryValueEx(h_key, 'Path'))[0]
return prog_path + '7z'
except OSError:
log("7-Zip isn't correctly installed!! ")
return None
except PermissionError:
log("7-Zip not found!! ")
answer = query_yes_no("Do you wish to install 7zip? ", default='yes')
if answer:
url = "https://www.7-zip.org/a/7z1900-x64.msi"
log("Attempting to download {}".format(url))
local_filename = url.split('/')[-1]
with requests.get(url, stream=True) as r:
r.raise_for_status()
homepath = os.environ.get('HOMEPATH', ".")
parentpath = "C:" + homepath + "\\Downloads\\"
filepath = parentpath + local_filename
with open(filepath, 'wb') as f:
for chunk in r.iter_content(chunk_size=8192):
if chunk: # filter out keep-alive new chunks
f.write(chunk)
log("Attempting to install {}".format(local_filename))
print("Please check for a Windows Installer icon on the Task Bar and follow the prompts.")
subprocess.call('msiexec /i "{fp}" /passive /norestart /l*v {pp}7zip_install.log'.format(fp=filepath,
pp=parentpath))
return find_program_win()
else:
r
```
<Overlap Ratio: 0.9543568464730291>

---

--- 218 --
Question ID: 0841c73dd70c1d4f6142fa61561322a01b38bdd0_7
Original Code:
```
def test_gzz():
    "gravmag.sphere.gzz python vs cython implementation"
    py = _sphere_numpy.gzz(xp, yp, zp, model)
    cy = sphere.gzz(xp, yp, zp, model)
    diff = np.abs(py - cy)
    assert np.all(diff <= precision), 'max diff: %g' % (max(diff))
```


Overlapping Code:
```
phere.gzz python vs cython implementation"
py = _sphere_numpy.gzz(xp, yp, zp, model)
cy = sphere.gzz(xp, yp, zp, model)
diff = np.abs(py - cy)
assert np.all(diff <= precision), 'max diff: %g' % (max(d
```
<Overlap Ratio: 0.8658008658008658>

---

--- 219 --
Question ID: d8fff4907cd423ef5771529f6e5c4e334f4a0123_1
Original Code:
```
def createPlotFile(startNonce, nonces):
    cmdLine = [ plotterPathName, "-k", str(key), "-d", tmpDirName, "-t", str(threads), "-x", plotCore,
                "-s", str(startNonce), "-n", str(nonces) ]
    print(BRIGHTGREEN + f"Compute {nonces} missing nonces through running:")
    print("  " + " ".join(cmdLine))
    if bDryRun :
        return None
    prc = subprocess.run(cmdLine, stdout = subprocess.PIPE, stderr = subprocess.PIPE)
    print(BRIGHTGREEN + prc.stdout.decode("utf-8"))
    print(BRIGHTRED + prc.stderr.decode("utf-8") + RESET_ALL)
    if prc.returncode :
        print(BRIGHTRED + f"Error: Plotter returned with error code {prc.returncode}!" + RESET_ALL)
        sys.exit(1)
    return os.path.join(tmpDirName, f"{key}_{startNonce}_{nonces}_{nonces}")
```


Overlapping Code:
```
startNonce, nonces):
cmdLine = [ plotterPathName, "-k", str(key), "-d", tmpDirName, "-t", str(threads), "-x", plotCore,
"-s", str(startNonce), "-n", str(nonces) ]
print(BRIGHTGREEN + f"Compute {nonces} missing nonces through running:")
print(" " + " ".join(cmdLine))
if bDryRun :
return None
prc = subprocess.run(cmdLine, stdout = subprocess.PIPE, stderr = subprocess.PIPE)
print(BRIGHTGREEN + prc.stdout.decode("utf-8"))
print(BRIGHTRED + prc.stderr.decode("utf-8") + RESET_ALL)
if prc.returncode :
print(BRIGHTRED + f"Error: Plotter returned with error code {prc.returncode}!" + RESET_ALL)
sys.exit(1)
return os.path.join(tmpDirName, f"{key}_{start
```
<Overlap Ratio: 0.935251798561151>

---

--- 220 --
Question ID: 709597dd0405ea27b693a5c8be92d4a3cb761c36_2
Original Code:
```
def test_adder_gain_bias():
    unit_step = basic_signals.UnitStep()
    upsampled_unit_step = building_blocks.SplitSignal(4, unit_step)
    source1 = building_blocks.Adder(upsampled_unit_step, upsampled_unit_step)
    source2 = building_blocks.Gain(2., upsampled_unit_step)
    source3 = building_blocks.Bias(1., upsampled_unit_step)

    for _ in range(test_basic_signals.MAX_TEARDOWNS):
        for _ in range(test_basic_signals.MAX_STEPS):
            assert all_equal(
                source1.next_value(),
                source2.next_value(),
                source3.next_value())
        source1.rewind()
        source2.rewind()
        source3.rewind()
```


Overlapping Code:
```
tep = basic_signals.UnitStep()
upsampled_unit_step = building_blocks.SplitSignal(4, unit_step)
source1 = building_blocks.Adder(upsampled_unit_step, upsampled_unit_step)
source2 = building_blocks.Gain(2., upsampled_unit_step)
source3 = building_blocks.Bias(1., upsampled_unit_step)
for _ in range(test_basic_signals.MAX_TEARDOWNS):
for _ in range(test_basic_signals.MAX_STEPS):
assert all_equal(
source1.next_value(),
source2.next_value(),
source3.next_value())
source1.rewind()
source2.rewind()
sourc
```
<Overlap Ratio: 0.9174311926605505>

---

--- 221 --
Question ID: 033285e745073ad33da98bba96cbfa2ebbc523f0_5
Original Code:
```
def read_OIB_data(xy0, W, reread_file=None, hemisphere=-1, blockmedian_scale=100, SRS_proj4=None):
    """
    Read indexed files for standard datasets
    """
    sensor_dict={1:'ICESat1', 2:'ICESat2'}
    if reread_file is None:
        GI=geo_index().from_file(GI_files(hemisphere)['ICESat2'], read_file=False)
        D = read_ICESat2(xy0, W, GI,  SRS_proj4=SRS_proj4)
        GI=None    
        GI=geo_index().from_file(GI_files(hemisphere)['ICESat1'], read_file=False)
        D += read_ICESat(xy0, W, GI)    
        GI=None
        data=point_data(list_of_fields=['x','y','z','time','sigma','sigma_corr','sensor','cycle','rgt', 'BP','LR']).from_list(D)
        data.assign({'day':np.floor(data.time)})
        data.time=matlabToYear(data.time)
        for field in data.list_of_fields:
            setattr(data, field, getattr(data, field).astype(np.float64))
        data.index(np.isfinite(data.z) & np.isfinite(data.sigma_corr) & np.isfinite(data.sigma))
    else:
        data=dict()
        with h5py.File(reread_file,'r') as h5f:
            for key in h5f['data'].keys():
                data[key]=np.array(h5f['data'][key])
        data=point_data(list_of_fields=data.keys()).from_dict(data)
    return data, sensor_dict
```


Overlapping Code:
```
xy0, W, reread_file=None, hemisphere=-1, blockmedian_scale=100, SRS_proj4=None):
"""
Read indexed files for standard datasets
"""
sensor_dict={1:'ICESat1', 2:'ICESat2'}
if reread_file is None:
GI=geo_index().from_file(GI_files(hemisphere)['ICESat2'], read_file=False)
D = read_ICESat2(xy0, W, GI, SRS_proj4=SRS_proj4)
GI=None 
GI=geo_index().from_file(GI_files(hemisphere)['ICESat1'], read_file=False)
D += read_ICESat(xy0, W, GI) 
GI=None
data=point_data(list_of_fields=['x','y','z','time','sigma','sigma_corr','sensor','cycle','rgt', 'BP','LR']).from_list(D)
data.assign({'day':np.floor(data.time)})
data.time=matlabToYear(data.time)
for field in data.list_of_fields:
setattr(data, field, getattr(data, field).astype(np.float64))
data.index(np.isfinite(data.z) & np.isfinite(data.sigma_corr) & np.isfinite(data.sigma))
else:
data=dict()
with h5py.File(reread_file,'r') as h5f:
for key in h5f['data'].keys():
data[key]=np.array(h5f['data'][key])
data=point_data(list_of_fields=data.keys()).from_dict
```
<Overlap Ratio: 0.9532888465204957>

---

--- 222 --
Question ID: aec5f2829dffd715cb37bd89dfdef58bbc4baa7c_2
Original Code:
```
def soft_jaccard_binary_loss(output, label, weight=1):
    """
        Original:
        class LossBinary:
        Loss defined as BCE - log(soft_jaccard)
        Vladimir Iglovikov, Sergey Mushinskiy, Vladimir Osin,
        Satellite Imagery Feature Detection using Deep Convolutional Neural Network: A Kaggle Competition
        arXiv:1706.06169

        def __init__(self, jaccard_weight=0):
            self.nll_loss = nn.BCEWithLogitsLoss()
            self.jaccard_weight = jaccard_weight

        def __call__(self, outputs, targets):
            loss = self.nll_loss(outputs, targets)

            if self.jaccard_weight:
                eps = 1e-15
                jaccard_target = (targets == 1).float()
                jaccard_output = F.sigmoid(outputs)

                intersection = (jaccard_output * jaccard_target).sum()
                union = jaccard_output.sum() + jaccard_target.sum()

                loss -= self.jaccard_weight * torch.log((intersection + eps) / (union - intersection + eps))
            return loss
        or,
        class Loss:
            def __init__(self, dice_weight=1):
                self.nll_loss = nn.BCELoss()
                self.dice_weight = dice_weight

            def __call__(self, outputs, targets):
                loss = self.nll_loss(outputs, targets)
                if self.dice_weight:
                    eps = 1e-15
                    dice_target = (targets == 1).float()
                    dice_output = outputs
                    intersection = (dice_output * dice_target).sum()
                    union = dice_output.sum() + dice_target.sum() + eps

                    loss -= torch.log(2 * intersection / union)

                return loss
    """
    label = tf.cast(tf.greater(label, 0), tf.float32)
    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=label))

    if weight > 0:
        output = tf.nn.sigmoid(output)
        smooth = 1e-15
        intersection = tf.reduce_sum(output * label)
        union = tf.reduce_sum(output) + tf.reduce_sum(label)
        loss -= weight *  tf.log((intersection + smooth) / (union - intersection + smooth))

    return loss
```


Overlapping Code:
```
binary_loss(output, label, weight=1):
"""
Original:
class LossBinary:
Loss defined as BCE - log(softlite Imagery Feature Detection using Deep Convolutional Neural Network: A Kaggle Competition
arXiv:1706.06169
def __init__(self, jaccard_weight=0):
self.nll_loss = nn.BCEWithLogitsLoss()
self.jaccard_weight = jaccard_weight
def __call__(self, outputs, targets):
loss = self.nll_loss(outputs, targets)
if self.jaccard_weight:
eps = 1e-15
jaccard_target = (targets == 1).float()
jaccard_output = F.sigmoid(outputs)
intersection = (jaccard_output * jaccard_target).sum()
union = jaccard_output.sum() + jaccard_target.sum()
loss -= self.jaccard_weight * torch.log((intersection + eps) / (union - intersection + eps))
return loss
or,
class Loss:
def __init__(self, dice_weight=1):
self.nll_loss = nn.BCELoss()
self.dice_weight = dice_weight
def __call__(self, outputs, targets):
loss = self.nll_loss(outputs, targets)
if self.dice_weight:
eps = 1e-15
dice_target = (targets == 1).float()
dice_output = outputs
intersection = (dice_output * dice_target).sum()
union = dice_output.sum() + dice_target.sum() + eps
loss -= torch.log(2 * intersection / union)
return loss
"""
label = tf.cast(tf.greater(label, 0), tf.float32)
loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=label))
if weight > 0:
output = tf.nn.sigmoid(output)
smooth = 1e-15
intersection = tf.reduce_sum(output * label)
union = tf.reduce_sum(output) + tf.reduce_sum(label)
loss -= weight * tf.log((intersection + smooth) / (union - intersection + smooth))
return loss
```
<Overlap Ratio: 0.9477838494231937>

---

--- 223 --
Question ID: e92e3c9656813cdfb0f28d57fec510c2fd4e1cf2_3
Original Code:
```
def test_replace_in_file_regex(tmp_path):
    original = " * @see https://unite.org/en/developer-reference#version"
    expected_result = " * @see https://docs.unit-e.io/reference/p2p/version.html"

    file_name = tmp_path / "test"
    with file_name.open("w") as file:
        file.write(original)

    Processor(ForkConfig()).replace_in_file_regex(file_name,
            r"https://unite.org/en/developer-reference#(\w+)",
            r"https://docs.unit-e.io/reference/p2p/\1.html")

    with file_name.open() as result_file:
        result = result_file.read()

    assert result == expected_result
```


Overlapping Code:
```
regex(tmp_path):
original = " * @see https://unite.org/en/developer-reference#version"
expected_result = " * @see https://docs.unit-e.io/reference/p2p/version.html"
file_name = tmp_path / "test"
with file_name.open("w") as file:
file.write(original)
Processor(ForkConfig()).replace_in_file_regex(file_name,
r"https://unite.org/en/developer-reference#(\w+)",
r"https://docs.unit-e.io/reference/p2p/\1.html")
with file_name.open() as result_file:
result = result_file.read()
assert result == expected_r
```
<Overlap Ratio: 0.9433962264150944>

---

--- 224 --
Question ID: aa093c98adeec96dee4cb7f2bf5f0ca109010e44_0
Original Code:
```
def pip_upgrade():
    import pip
    for dist in pip.get_installed_distributions():
        local("pip install --upgrade {0}".format(dist.project_name))
```


Overlapping Code:
```
ip
for dist in pip.get_installed_distributions():
local("pip install --upgrade {0}".format(dist.proj
```
<Overlap Ratio: 0.7299270072992701>

---

--- 225 --
Question ID: 87bfda7300e1119f035696bfa7de46cc22a53763_3
Original Code:
```
def delete(client, path):
    """ Recursively delete a path

    Args:
        client: Pookeeper client
        path: the path to recursively delete
    """
    if not client.exists(path): return

    children, stat = client.get_children(path)
    for child in children:
        delete(client, path + '/' + child)
    client.delete(path, stat.version)
    LOGGER.debug('Deleted %s', path)
```


Overlapping Code:
```
lient, path):
""" Recursively delete a path
Args:
client: Pookeeper client
path: the path to recursively delete
"""
if not client.exists(path): return
children, stat = client.get_children(path)
for child in children:
delete(client, path + '/' + child)
client.delete(path, stat.version)
LOGGER.debug('
```
<Overlap Ratio: 0.9090909090909091>

---

--- 226 --
Question ID: 535ed34734f101303343363d324bc1103c6c1f13_3
Original Code:
```
@app.route('/make_video/<task_id>', methods=['POST'])
def make_video(task_id):
  try:
    os.mkdir(video_buffer)
  except Exception as e:
    print(e)
  raw_files = sorted(os.listdir(frame_buffer))
  files = map(lambda f: os.path.join(frame_buffer, f), raw_files)
  taichi.tools.video.make_video(list(files), output_path=os.path.join(video_buffer, task_id + '.mp4'))
  return ''
```


Overlapping Code:
```
k_id>', methods=['POST'])
def make_video(task_id):
try:
os.mkdir(video_buffer)
except Exception as e:
print(e)
raw_files = sorted(os.listdir(frame_buffer))
files = map(lambda f: os.path.join(frame_buffer, f), raw_files)
taichi.tools.video.make_video(list(files), output_path=os.path.join(video_buffer
```
<Overlap Ratio: 0.8379888268156425>

---

--- 227 --
Question ID: 2a47ed9898e2a53116482213b411096d827afda2_14
Original Code:
```
def test_get_route_types(client):
    """Tests the GET RouteTypes endpoint"""
    json = client.get_route_types()
    assert isinstance(json, dict)
    assert EXPECTED_ROUTE_TYPE_KEYS.issubset(json.keys())
    assert json['status']['health'] == 1
```


Overlapping Code:
```
e_types(client):
"""Tests the GET RouteTypes endpoint"""
json = client.get_route_types()
assert isinstance(json, dict)
assert EXPECTED_ROUTE_TYPE_KEYS.issubset(json.keys())
assert json['status']['health'] == 1
```
<Overlap Ratio: 0.9247787610619469>

---

--- 228 --
Question ID: 291f843a1d44829c3b2e71f3b304e4751fc07586_8
Original Code:
```
def parse_theory(lines, **debuginfo):
    lines = remove_comments_and_add_padding(lines)
    rules = parse_lines_to_rules(lines, **debuginfo)
    lines = erase_rules_from_lines(rules, lines, **debuginfo)
    facts = parse_lines_to_facts(lines, **debuginfo)
    return {'facts': facts, 'rules': rules}
```


Overlapping Code:
```
s = remove_comments_and_add_padding(lines)
rules = parse_lines_to_rules(lines, **debuginfo)
lines = erase_rules_from_lines(rules, lines, **debuginfo)
facts = parse_lines_to_facts(lines, **debuginfo)
r
```
<Overlap Ratio: 0.7142857142857143>

---

--- 229 --
Question ID: 4e7a6e833f6d3fd7a0daae31da01afe7204c5fbd_0
Original Code:
```
def read_seqs(infile, filter_list=None):
    """
    Reads up sequences from a path to a fasta file
    :param infile: path to fasta file
    :param filter_list: Strings that should be in the description of the sequences
    :return: a list of strings
    """
    r = []
    f = open_possible_gzip(infile)
    for seq in SeqIO.parse(f, "fasta"):
        if filter_list is not None:
            assert isinstance(filter_list, list)
            if any([x in seq.description for x in filter_list]):
                r.append(seq)
        else:
            r.append(seq)
    f.close()
    return r
```


Overlapping Code:
```
, filter_list=None):
"""
Reads up sequences from a path to a fasta file
:param infile: path to fasta file
:param filter_list: Strings that should be in the description of the sequences
:return: a list of strings
"""
r = []
f = open_possible_gzip(infile)
for seq in SeqIO.parse(f, "fasta"):
if filter_list is not None:
assert isinstance(filter_list, list)
if any([x in seq.description for x in filter_list]):
r.append(seq)
else:
r.append(seq)
f.close(
```
<Overlap Ratio: 0.9375>

---

--- 230 --
Question ID: 340a33e53b2d20aa5e7efa8a18e86223184f852e_4
Original Code:
```
def _reverse(x, bits):
    y = 0
    for i in xrange(bits):
        y = (y << 1) | (x & 1)
        x >>= 1
    return y
```


Overlapping Code:
```
):
y = 0
for i in xrange(bits):
y = (y << 1) | (x 
```
<Overlap Ratio: 0.5494505494505495>

---

--- 231 --
Question ID: 53e74672e205e38a5a0582d1841b67f14497dd48_4
Original Code:
```
def should_validate_while_training(iteration, val_every, val_after, resume, start_iteration):
    if val_every is None:
        return False
    return (iteration % val_every == 0 and iteration >= val_after) or (resume and iteration == start_iteration)
```


Overlapping Code:
```
validate_while_training(iteration, val_every, val_after, resume, start_iteration):
if val_every is None:
return False
return (iteration % val_every == 0 and iteration >= val_after) or (resume and iter
```
<Overlap Ratio: 0.847457627118644>

---

--- 232 --
Question ID: db78dfb1c03c1fde2ef325ec3db4849b32bc70b7_4
Original Code:
```
def get_deployment_history_services(deployment):
    template_name = 'deployments/_cell_services.html'
    services = {}
    for service in deployment.description['services']:
        service_type = service['?']['type']
        if service_type.find('/') != -1:
            service_type = service_type[:service_type.find('/')]
        services[service.get('name', service['?']['name'])] = service_type
    context = {
        "services": services,
    }
    return template.loader.render_to_string(template_name, context)
```


Overlapping Code:
```
yment_history_services(deployment):
template_name = 'deployments/_cell_services.html'
services = {}
for service in deployment.description['services']:
service_type = service['?']['type']
if service_type.find('/') != -1:
service_type = service_type[:service_type.find('/')]
services[service.get('name', service['?']['name'])] = service_type
context = {
"services": services,
}
return template.loader.render_to_string(template_name, context)
```
<Overlap Ratio: 0.9712389380530974>

---

--- 233 --
Question ID: 8e532b5f7c6cadae6cb69d97a5ebd9605c1f72df_2
Original Code:
```
def _setup(filename):
    if not os.path.exists(filename):
        msg = "Unable to find {}. Exiting.".format(filename)
        raise NotFoundError(msg)

    working_dirs = [config._get_lock_dir(), config._get_clone_dir()]
    for working_dir in working_dirs:
        if not os.path.exists(working_dir):
            os.makedirs(working_dir)
```


Overlapping Code:
```
up(filename):
if not os.path.exists(filename):
msg = "Unable to find {}. Exiting.".format(filename)
raise NotFoundError(msg)
working_dirs = [config._get_lock_dir(), config._get_clone_dir()]
for working_dir in working_dirs:
if not os.path.exists(working_dir):
os.makedirs(working_dir)
```
<Overlap Ratio: 0.9725085910652921>

---

--- 234 --
Question ID: 96e75851e0f2b6848587bc6bd77bfae25227348f_5
Original Code:
```
def test_implicit_label():
    nlp = Language()
    nlp.add_pipe("tagger")
    train_examples = []
    for t in TRAIN_DATA:
        train_examples.append(Example.from_dict(nlp.make_doc(t[0]), t[1]))
    nlp.initialize(get_examples=lambda: train_examples)
```


Overlapping Code:
```
st_implicit_label():
nlp = Language()
nlp.add_pipe("tagger")
train_examples = []
for t in TRAIN_DATA:
train_examples.append(Example.from_dict(nlp.make_doc(t[0]), t[1]))
nlp.initialize(get_examples=lambda: train_examples)
```
<Overlap Ratio: 0.9734513274336283>

---

--- 235 --
Question ID: 73d42cd85530f7cdacfa7fe123df893bce39d102_5
Original Code:
```
def add_user(data, username):
        if usr_already_exists(data) == True:
                return "User already exists"
        try:
                connect = connect_to_sql()
                cursor = connect.cursor()
                cursor.execute("INSERT INTO user (user_id, username) VALUES ('%s', '%s')"
                % (data, username))
                connect.commit()

                cursor.close()
                connect.close()
                return "User created"
        except:
              pass
```


Overlapping Code:
```
ername):
if usr_already_exists(data) == True:
return "User already exists"
try:
connect = connect_to_sql()
cursor = connect.cursor()
cursor.execute("INSERT INTO user (user_id, username) VALUES ('%s', '%s')"
% (data, username))
connect.commit()
cursor.close()
connect.close()
return "User created"
exc
```
<Overlap Ratio: 0.9090909090909091>

---

--- 236 --
Question ID: a7e3852cc2ba11d5ab68c9aeaa32949fb2d31c3a_8
Original Code:
```
def test_web_authorize(client_with_auth):
    env = client_with_auth.config.env

    global KEY_PAIR
    KEY_PAIR[env] = utility.create_key_pair()

    res = client_with_auth.dapp.web_authorize(APP_ADDRESS[env])
    assert res.status_code == 200
    data = res.json()
    global CODE
    CODE[env] = data['code']
    assert CODE[env]
```


Overlapping Code:
```
_with_auth):
env = client_with_auth.config.env
global KEY_PAIR
KEY_PAIR[env] = utility.create_key_pair()
res = client_with_auth.dapp.web_authorize(APP_ADDRESS[env])
assert res.status_code == 200
data = res.json()
global CODE
CODE[env] = data['code']
assert CODE
```
<Overlap Ratio: 0.8847457627118644>

---

--- 237 --
Question ID: 63d9db81366c5aaa02808ea12f9ec81eade531b2_2
Original Code:
```
def to_midnight(dt: datetime):
    '''
    Round the provided datetime object to the last day
    Usage:
        >>> to_midnight(datetime.strptime('14 Aug 1993 10:21', '%d %b %Y %H:%M')).strftime('%d %b %Y %H:%M')
        "14 Aug 1993 00:00"
    '''
    return dt.replace(hour=0, minute=0, second=0, microsecond=0)
```


Overlapping Code:
```
(dt: datetime):
'''
Round the provided datetime object to the last day
Usage:
>>> to_midnight(datetime.strptime('14 Aug 1993 10:21', '%d %b %Y %H:%M')).strftime('%d %b %Y %H:%M')
"14 Aug 1993 00:00"
'''
return dt.replace(hour=0, minute=0, second=0, microsecond=0)
```
<Overlap Ratio: 0.9460431654676259>

---

--- 238 --
Question ID: ee11deaec446d784f5f955b46864d0df98eee2e0_2
Original Code:
```
def is_numeric(s):

    try:
        x = int(s)
    except:
        try:
            x = float(s)
        except:
            x = None
    return x
```


Overlapping Code:
```
 int(s)
except:
try:
x = float(s)
except:
x = None
return x
```
<Overlap Ratio: 0.686046511627907>

---

--- 239 --
Question ID: bfe3a04e069c7f4d3004ff9df76068a84d732c36_4
Original Code:
```
def update_localhost_alias(hostname):
    def not_local(alias):
        return alias.partition(".")[0] not in ("localhost", "localhost4", "localhost6", "centralnode")

    localhost_ips = list(__get_ips_for('localhost'))
    data = __list_aliases()
    for ip, aliases in data.items():
        if ip not in localhost_ips:
            continue
        map(data[ip].remove, filter(not_local, aliases))
        if hostname not in data[ip]:
            data[ip].append(hostname)

    __write_aliases(data)
```


Overlapping Code:
```
:
def not_local(alias):
return alias.partition(".")[0] not in ("localhost", "localhost4", "localhost6", "centralnode")
localhost_ips = list(__get_ips_for('localhost'))
data = __list_aliases()
for ip, aliases in data.items():
if ip not in localhost_ips:
continue
map(data[ip].remove, filter(not_local, aliases))
if hostname not in data[ip]:
data[ip].a
```
<Overlap Ratio: 0.8274231678486997>

---

--- 240 --
Question ID: 7f566f4323956f8462afe9d022ea2bd119514e64_8
Original Code:
```
def number_parser(num_str, num_type=float):
    '''converts number strings using metric prefixes into numbers'''
    postfixes = " kMGTPE"
    power = 0
    if num_str[-1] in postfixes:
        power = postfixes.index(num_str[-1])
        num_str = num_str[:-1]
    return num_type(float(num_str.replace(',','')) * 1000**power)
```


Overlapping Code:
```
oat):
'''converts number strings using metric prefixes into numbers'''
postfixes = " kMGTPE"
power = 0
if num_str[-1] in postfixes:
power = postfixes.index(num_str[-1])
num_str = num_str[:-1]
return num_type(float(num_str.replace(',','')) * 1000**pow
```
<Overlap Ratio: 0.8591065292096219>

---

--- 241 --
Question ID: 756ad5c7ac0752f3a54427ce2fc2b1a0ec562221_0
Original Code:
```
def stock(request):
    
    if request.method != 'GET':
        return JsonResponse(status=405, data={
            'error': 'Please use get request'
        })

    stockName = request.GET.get('NAME', '')
    # without a name, hard to know what to request
    if stockName == '':
        return JsonResponse(status=400, data={
            'error': 'Please include stock symbol'
        })

    # the "2018-01-01" is the default value if STARTDATE isn't set
    startDate = request.GET.get('STARTDATE', "2018-01-01"
                                )
    try:
        datetime.datetime.strptime(startDate, '%Y-%m-%d')
    except ValueError:
        return JsonResponse(status=400, data={
            'error': 'Please include a valid date in the format YYYY-MM-DD'
        })
    endDate = request.GET.get('ENDDATE', "2018-01-02"
                              )
    try:
        datetime.datetime.strptime(endDate, '%Y-%m-%d')
    except ValueError:
        return JsonResponse(status=400, data={
            'error': 'Please include a valid date in the format YYYY-MM-DD'
        })

    # gets FIELDS, converts to uppercase, then splits into an array
    fields = request.GET.get('FIELDS', "Close").upper().split(',')

    # DL data from the Quandl API
    quandl.ApiConfig.api_key = config('QUANDL_API_KEY')
    try:
        df = quandl.get(f"WIKI/{stockName}", start_date=startDate,
                        end_date=endDate)
    except:
        # This might need to get changed to a more generic answer
        print("Query error: please change your inputs (possibly invaild NAME, STARTDATE, ENDDATE) or check your API "
              "key.")
        return JsonResponse(status=500, data={
            'error': 'query error'
        })
    # frustratingly enough is quandl doesn't have data due to something be impossible it won't error, it'll just
    # return an empty dataframe. For example requesting google stock from 1999, before they went public. This won't
    # pop if the dates are set wrong, but sometimes will if they're set to the same day.
    if df.empty:
        return JsonResponse(status=404, data={
            'error': 'Data was not found for this stock, please verify that the dates and stock symbol are valid and '
                     'try again '
        })

    returnObj = {'symbol': stockName, 'startDate': startDate,
                 'endDate': endDate, 'data': []}

    # check if study exists in the database, if it does, then it returns the study
    check_study = Study.objects.all().filter(stock_name=stockName, start_date=startDate, end_date=endDate)
    if check_study:
        print('already here')
        temp = {}
        for check_data in check_study.values("data"):
            # json.loads allow for our data to be "unstringified" so we can return it as readable data
            temp = json.loads(check_data['data'])
        returnObj['data'] = temp
        return JsonResponse(status=200, data=returnObj)

    # this moves the date from being a row key, to another column, then converts the whole dataframe to strings. Even
    # all the numbers. This is to avoid problems with handling the date
    df_r = df.reset_index().astype(str)

    # this preps the return value by iterating over all the df rows then shoving them inside the data array in
    # returnObj. I was unsure if I should use an object instead of an array but using a date as a key seemed much
    # messier then letting an array preserve order
    for index, row in df_r.iterrows():
        rowObj = {'date': row['Date']}

        # if 'OPEN' in fields:
        rowObj['open'] = row['Open']
        # if 'CLOSE' in fields:
        rowObj['close'] = row['Close']
        # if 'LOW' in fields:
        rowObj['low'] = row['Low']
        # if 'HIGH' in fields:
        rowObj['high'] = row['High']
        if 'EXDIVIDEND' in fields:
            rowObj['exdividend'] = row['Ex-Dividend']
        # if 'VOLUME' in fields:
        rowObj['volume'] = row['Volume']
        if 'SPLITRATIO' in fields:
            rowObj['splitRatio'] = row['Split Ratio']
        if 'ADJHIGH' in fields:
            rowObj['adjHigh'] = row['Adj. High']
        if 'ADJOPEN' in fields:
            rowObj['adjOpen'] = row['Adj. Open']
        if 'ADJCLOSE' in fields:
            rowObj['adjClose'] = row['Adj. Close']
        if 'ADJLOW' in fields:
            rowObj['adjLow'] = row['Adj. Low']
        if 'ADJVOLUME' in fields:
            rowObj['adjVolume'] = row['Adj. Volume']

        returnObj["data"].append(rowObj)

    string_json = json.dumps(returnObj["data"])
    stock = Stock.objects.all().filter(symbol=returnObj['symbol']).first()
    if not stock:
        stock = Stock(symbol=returnObj['symbol'])
        stock.save()
    # Data is being saved as a stringified json
    new_study = Study(start_date=returnObj["startDate"], end_date=returnObj["endDate"], data=string_json)
    new_study.save()
    stock.study_set.add(new_study)

    # TODO: Need to save study into user's portfolio when this route becomes protected.

    return JsonResponse(status=200, data=returnObj)
```


Overlapping Code:
```
ET':
return JsonResponse(status=405, data={
'error': 'Please use get request'
})
stockName = request.GET.get('NAME', '')
# without a name, hard to know what to request
if stockName == '':
return JsonResponse(status=400, data={
'error': 'Please include stock symbol'
})
# the "2018-01-01" is the default value if STARTDATE isn't set
startDate = request.GET.get('STARTDATE', "2018-01-01"
)
try:
datetime.datetime.strptime(startDate, '%Y-%m-%d')
except ValueError:
return JsonResponse(status=400, data={
'error': 'Please include a valid date in the format YYYY-MM-DD'
})
endDate = request.GET.get('ENDDATE', "2018-01-02"
)
try:
datetime.datetime.strptime(endDate, '%Y-%m-%d')
except ValueError:
return JsonResponse(status=400, data={
'error': 'Please include a valid date in the format YYYY-MM-DD'
})
# gets FIELDS, converts to uppercase, then splits into an array
fields = request.GET.get('FIELDS', "Close").upper().split(',')
# DL data from the Quandl API
quandl.ApiConfig.api_key = config('QUANDL_API_KEY')
try:
df = quandl.get(f"WIKI/{stockName}", start_date=startDate,
end_date=endDate)
except:
# This might need to get changed to a more generic answer
print("Query error: please change your inputs (possibly invaild NAME, STARTDATE, ENDDATE) or check your API "
"key.")
return JsonResponse(status=500, data={
'error': 'query error'
})
# frustratingly enough is quandl doesn't have data due to something be impossible it won't error, it'll just
# return an empty dataframe. For example requesting google stock from 1999, before they went public. This won't
# pop if the dates are set wrong, but sometimes will if they're set to the same day.
if df.empty:
return JsonResponse(status=404, data={
'error': 'Data was not found for this stock, please verify that the dates and stock symbol are valid and '
'try again '
})
returnObj = {'symbol': stockName, 'startDate': startDate,
'endDate': endDate, 'data': []}
# check if study exists in the database, if it does, then it returns the study
check_study 
```
<Overlap Ratio: 0.9770395701025891>

---

--- 242 --
Question ID: 26e8e774cd29bfc5a8f663013a9a38404d393b76_1
Original Code:
```
def main():
	args = handleArgs()
	imgs_folder = args['path']

	print('Searching {0!s} for images'.format(imgs_folder))

	# calibration_images = '%s/left*.jpg' % (imgs_folder)
	calibration_images = '{0!s}/shot_*.png'.format((imgs_folder))
	images = []
	images = glob.glob(calibration_images)

	print('Number images found: {0:d}'.format(len(images)))
	# print(images)

	cal = CameraCalibration()
	cal.save_file = args['matrix']
	cal.marker_size = (args['target_size'][0], args['target_size'][1])

	print('Marker size:', cal.marker_size)

	if args['target'] == 'chessboard':
		cal.marker_checkerboard = True
	else:
		cal.marker_checkerboard = False
	cal.calibrate(images)

	cal.printMat()

	# save data to file
	cal.save('calibration.npy')

	# -----------------------------------------------------------------

	# read back in
	cal.read('calibration.npy')

	# crop the image
	# x,y,w,h = roi
	# crop the distorted edges off
	# # dst = dst[y:y+h, x:x+w]
	# cv2.imwrite('calibresult.png',dst)

	image = cv2.imread(images[0], 0)
	dst = cal.undistort(image)
	cv2.imshow('calibrated image', dst)
	# cv2.imshow('original image', image)
	cv2.waitKey(0)

	cv2.destroyAllWindows()
```


Overlapping Code:
```
def main():
args = handleArgs()
imgs_folder = args['path']
print('Searching {0!s} for images'.format(imgs_folder))
# calibration_images = '%s/left*.jpg' % (imgs_folder)
calibration_images = '{0!s}/shot_*.png'.format((imgs_folder))
images = []
images = glob.glob(calibration_images)
print('Number images found: {0:d}'.format(len(images)))
# print(images)
cal = CameraCalibration()
cal.save_file = args['matrix']
cal.marker_size = (args['target_size'][0], args['target_size'][1])
print('Marker size:', cal.marker_size)
if args['target'] == 'chessboard':
cal.marker_checkerboard = True
else:
cal.marker_checkerboard = False
cal.calibrate(images)
cal.printMat()
# save data to file
cal.save('calibration.npy')
# -----------------------------------------------------------------
# read back in
cal.read('calibration.npy')
# crop the image
# x,y,w,h = roi
# crop the distorted edges off
# # dst = dst[y:y+h, x:x+w]
# cv2.imwrite('calibresult.png',dst)
image = cv2.imread(images[0], 0)
dst = cal.undistort(image)
cv2.imshow('calibrated image', dst)
# cv2.imshow('original image', image)
cv2.waitKey(0)
cv2.destroyAllWindows()
```
<Overlap Ratio: 1.0>

---

--- 243 --
Question ID: 8b7cd38085bcad945d55ace6374f2cfb4247b0bd_5
Original Code:
```
def test_no_class_type_in_event():
    event = TransferEvent(web3_transfer_event, 10, 1000)

    dumped = schemas.AnyEventSchema().dump(event)

    assert dumped.get(schemas.AnyEventSchema.type_field) is None
    assert dumped["amount"] == str(event.value)
    assert dumped["from"] == event.from_
    assert dumped["extraData"] == event.extra_data.hex()
```


Overlapping Code:
```
s_type_in_event():
event = TransferEvent(web3_transfer_event, 10, 1000)
dumped = schemas.AnyEventSchema().dump(event)
assert dumped.get(schemas.AnyEventSchema.type_field) is None
assert dumped["amount"] == str(event.value)
assert dumped["from"] == event.from_
assert dumped["extraData"] == event.extr
```
<Overlap Ratio: 0.9146341463414634>

---

--- 244 --
Question ID: 21b63c6f23f455912da461c7bb010989f8ececaa_4
Original Code:
```
def _pack_kvec(L, n):
    """
    Utility function to find 
      k:= 2 pi / L * (u, v, w)
    for the sequence of u,v,w 
       (0,0,0), (1,0,0), (1,1,0), (1,1,1), (2,0,0), (2,1,0), (2,1,1),... (M-1,M-1,M-1)
    where M := 1 + n//2

    i.e. u >= v >= w >= 0 and the last index is rolling fastest.

    L - size of the box
    n - Size for (n,n,n) grid this is equivalent to (i.e. your fft-size)

    retiurns 2d array of (M(M+1)(M+2)/6, 3) k-vectors
    """
    mid = 1+n//2 # indices [0,1,..., m-1]
    
    vals = empty(((mid*(mid+1)*(mid+2))//6, 3), dtype=int32)
    idx = 0
    kw = arange(mid)
    for i in range(mid):
        ni = ((i+1)*(i+2))//2
        vals[idx:idx+ni,0] = i
        for j in range(i+1):
            nk = j+1
            vals[idx:idx+nk,1] = j
            vals[idx:idx+nk,2] = kw[:nk]
            idx += nk

    assert(idx==len(vals))
    return (2*pi/L) * vals
```


Overlapping Code:
```
c(L, n):
"""
Utility function to find 
k:= 2 pi / L * (u, v, w)
for the sequence of u,v,w 
(0,0,0), (1,0,0), (1,1,0), (1,1,1), (2,0,0), (2,1,0), (2,1,1),... (M-1,M-1,M-1)
where M := 1 + n//2
i.e. u >= v >= w >= 0 and the last index is rolling fastest.
L - size of the box
n - Size for (n,n,n) grid this is equivalent to (i.e. your fft-size)
retiurns 2d array of (M(M+1)(M+2)/6, 3) k-vectors
"""
mid = 1+n//2 # indices [0,1,..., m-1]

vals = empty(((mid*(mid+1)*(mid+2))//6, 3), dtype=int32)
idx = 0
kw = arange(mid)
for i in range(mid):
ni = ((i+1)*(i+2))//2
vals[idx:idx+ni,0] = i
for j in range(i+1):
nk = j+1
vals[idx:idx+nk,1] = j
vals[idx:idx+nk,2] = kw[:nk]
idx += nk
assert(idx==len(vals))
ret
```
<Overlap Ratio: 0.9562841530054644>

---

--- 245 --
Question ID: 79f30e89a28b9ecbbafd616848542eeb26655202_0
Original Code:
```
def solution():
    n = 4
    edges = [[0,1,1],[0,2,5],[1,2,1],[2,3,1]]
    src = 0
    dst = 3
    k = 1
    problem = Problem()
    return problem.find_cheapest_price(n, edges, src, dst, k)
```


Overlapping Code:
```
n = 4
edges = [[0,1,1],[0,2,5],[1,2,1],[2,3,1]]
src = 0
dst = 3
k = 1
problem = Problem()
return problem.find_cheapest_price(
```
<Overlap Ratio: 0.7668711656441718>

---

--- 246 --
Question ID: a07802b34f124785381c058781894542f06e4f8a_0
Original Code:
```
def var_of_means(n):
    """Construct a random matrix A with values drawn from the standard normal
    distribution. Calculate the mean value of each row, then calculate the
    variance of these means. Return the variance.

    Inputs:
        n (int): The number of rows and columns in the matrix A.

    Returns:
        (float) The variance of the means of each row.
    """
    A = np.random.randn(n,n)
    return A.mean(axis=1).var()
```


Overlapping Code:
```
f_means(n):
"""Construct a random matrix A with values drawn from the standard normal
distribution. Calculate the mean value of each row, then calculate the
variance of these means. Return the variance.
Inputs:
n (int): The number of rows and columns in the matrix A.
Returns:
(float) The variance of the means of each row.
"""
A = np.random.randn(n,n)
retur
```
<Overlap Ratio: 0.9203084832904884>

---

--- 247 --
Question ID: cd1363d9ddd3a2c959305968ea85e71439df7ac8_2
Original Code:
```
def test_get_receipts_without_node_url(mocker):
    """
    Case: get a list of the transaction's receipts without passing node URL.
    Expect: a list of the transaction's receipts is returned from a node on localhost.
    """
    expected_list_of_receipts = [
        {
            'data': [],
            'events': [],
            'id': 'e79a883581c184787360de8607c5f970cdeeaa684af3e50d8532aa9dd07afa8e'
                  '7fc92f0dc509b41b9695e795704bdd50455bebd1ed327a5330710ba40698b492',
            'state_changes': [
                {
                    'address': '00b10c0100000000000000000000000000000000000000000000000000000000000000',
                    'type': 'SET',
                    'value': 'CL0BGIACIKwC',
                },
                {
                    'address': '00b10c00000000000000000000000000000000000000000000000000000000000000bd',
                    'type': 'SET',
                    'value': 'CL0BEoABZmQ3ODBjZTA3NjQwYmE0MTEyMjQ4NjkxNTgxYTU5NTg0NWZlNzYyYmYzZmViNDliODQzOTc0Y'
                             'WFlNTc4NDc4YzZiZjUxODczOWVjZGM0OWQ3MDE5MzgzZDNiZDllM2FhNmZhMGFmODM4NGI0NDkxOGYwYm'
                             'ZmMzc0MDJiNTEwYjIaQjAyZDFmYmRhNTBkYmNkMGQzYzI4NmE2YTlmYTcxYWE3Y2UyZDk3MTU5YjkwZGR'
                             'kNDYzZTA4MTY0MjJkNjIxZTEzNSKAAWZlNTZhMTZkYWIwMDljYzk2ZTcxMjVjNjQ3YjZjNzFlYjEwNjM4'
                             'MThjZjhkZWNlMjgzYjEyNTQyM2VjYjE4NGY3ZjFlNjE4MDJiZjY2MzgyZGE5MDQ2OTg0MTNmODA4MzEwM'
                             'zFmOGExYjI5MTUwMjYwYzNmYTRkYjUzN2ZkZjRjKIzggeYF',
                },
            ],
        },
        {
            'data': [],
            'events': [],
            'id': '6593d21046519022ba32c98e934d7dfc81e8b4edf6c064dbf70feb13db431087'
                  '3ec00816bce8660cafd4fa2a8c80d0147d63cf616c624babd03142c694272017',
            'state_changes': [
                {
                    'address': '00b10c00000000000000000000000000000000000000000000000000000000000000bc',
                    'type': 'SET',
                    'value': 'CLwBEoABOWI4Y2NhODk3Nzk2NDJiYWEyMGMwZWUyZjEzOWVlMGNlMWNjYjEwMjY5OTVjNDY3NDYzZDEzOT'
                             'I0ZDg3YTg3NjNlODMzOWI2YzIyMzNmMTZiY2I5ZDVjNjEwMzVmNzAzY2FiNjBiNzQxMGJlMjJkZjkzNWEy'
                             'YWE4YmIzNGE1NTcaQjAyZDFmYmRhNTBkYmNkMGQzYzI4NmE2YTlmYTcxYWE3Y2UyZDk3MTU5YjkwZGRkND'
                             'YzZTA4MTY0MjJkNjIxZTEzNSKAAWZkNzgwY2UwNzY0MGJhNDExMjI0ODY5MTU4MWE1OTU4NDVmZTc2MmJm'
                             'M2ZlYjQ5Yjg0Mzk3NGFhZTU3ODQ3OGM2YmY1MTg3MzllY2RjNDlkNzAxOTM4M2QzYmQ5ZTNhYTZmYTBhZj'
                             'gzODRiNDQ5MThmMGJmZjM3NDAyYjUxMGIyKMzfgeYF',
                },
                {
                    'address': '00b10c0100000000000000000000000000000000000000000000000000000000000000',
                    'type': 'SET',
                    'value': 'CLwBGIACIKwC',
                },
            ],
        },
    ]

    mock_get_receipts = mocker.patch('cli.receipt.service.loop.run_until_complete')
    mock_get_receipts.return_value = expected_list_of_receipts

    runner = CliRunner()
    result = runner.invoke(cli, [
        'receipt',
        'get',
        '--ids',
        TRANSACTION_IDENTIFIERS_PRESENTED_ON_THE_TEST_NODE,
    ])

    expected_node_information = {
        'result': expected_list_of_receipts,
    }

    assert PASSED_EXIT_FROM_COMMAND_CODE == result.exit_code
    assert expected_node_information == json.loads(result.output)
```


Overlapping Code:
```
"""
Case: get a list of the transaction's receipts without passing node URL.
Expect: a list of the transaction's receipts is returned from a node on localhost.
"""
expected_list_of_receipts = [
{
'data': [],
'events': [],
'id': 'e79a883581c184787360de8607c5f970cdeeaa684af3e50d8532aa9dd07afa8e'
'7fc92f0dc509b41b9695e795704bdd50455bebd1ed327a5330710ba40698b492',
'state_changes': [
{
'address': '00b10c0100000000000000000000000000000000000000000000000000000000000000',
'type': 'SET',
'value': 'CL0BGIACIKwC',
},
{
'address': '00b10c00000000000000000000000000000000000000000000000000000000000000bd',
'DBjZTA3NjQwYmE0MTEyMjQ4NjkxNTgxYTU5NTg0NWZlNzYyYmYzZmViNDljUxODczOWVjZGM0OWQ3MDE5MzgzZDNiZDllM2FhNmZhMGFmODM4NGI0NDkxOGYwYm'
'ZmMzc0MDJiNTEwYjIaQjAyZDFmYmRhNTBkYmNkMGQzYzI4NmE2YTlmYTcxYWE3Y2UyZDk3MTU5YjkwZGR'
'kNDYzZTA4MTY0MjJkNjIxZTEzNSKAAWZlNTZhMTZkYWIwMDljYzk2ZTcxMjVjNjQ3YjZjNzFlYjEwNjM4'
'MThjZjhkZWNlMjgzYjEyNTQyM2VjYjE4NGY3ZjFlNjE4MDJiZjY2MzgyZGE5MDQ2OTg0MTNmODA4MzEwM'
'zFmOGExYjI5MTUwMjYwYzNmYTRkYjUzN2ZkZjRjKIzggeYF',
},
],
},
{
'data': [],
'events': [],
'id': '6593d21046519022ba32c98e934d7dfc81e8b4edf6c064dbf70feb13db431087'
'3ec00816bce8660cafd4fa2a8c80d0147d63cf616c624babd03142c694272017',
'state_changes': [
{
'address': '00b10c00000000000000000000000000000000000000000000000000000000000000b2NhODk3Nzk2NDJiYWEyMGMwZWUyZjEzOWVlMGNlMWNjYjEwMjY5OTVjNDY3NDYzZTZiY2I5ZDVjNjEwMzVmNzAzY2FiNjBiNzQxMGJlMjJkZjkzNWEmIzNGE1NTcaQjAyZDFmYmRhNTBkYmNkMGQzYzI4NmE2YTlmYTcxYWE3Y2UyZDk3MTU5YjkwZGRkND'
'YzZTA4MTY0MjJkNjIxZTEzNSKAAWZkNzgwY2UwNzY0MGJhNDExMjI0ODY5MTU4MWE1OTU4NDVmZTc2MmJ
```
<Overlap Ratio: 0.8848518725544997>

---

--- 248 --
Question ID: 0aa8a507d6e7432199c19d487284ee7d3c686f01_5
Original Code:
```
def ensure_file_exists(filename, context=None):
    real_filename = filename
    if context:
        real_filename = realpath_with_context(filename, context)
    if not os.path.exists(real_filename):
        create_textfile_with_contents(real_filename, "")
    assert os.path.exists(real_filename), "ENSURE file exists: %s" % filename
```


Overlapping Code:
```
def ensure_file_exists(filename, context=None):
real_filename = filename
if context:
real_filename = realpath_with_context(filename, context)
if not os.path.exists(real_filename):
create_textfile_with_contents(real_filename, "")
assert os.path.exists(real_filename), "ENSURE file exists: %s" % filena
```
<Overlap Ratio: 0.9933774834437086>

---

--- 249 --
Question ID: 9c567b2891941129bd56e6f4b018599badf7c2a5_8
Original Code:
```
def test_nonsilent_region_cpu():
    pipe = Pipeline(batch_size=batch_size, num_threads=4, device_id=None)
    test_data_shape = [200]
    def get_data():
        out = [np.random.randint(0, 255, size = test_data_shape, dtype = np.uint8) for _ in range(batch_size)]
        out[0][0] = 0
        out[1][0] = 0
        out[1][1] = 0
        return out
    data = fn.external_source(source = get_data)
    processed, _ = fn.nonsilent_region(data)
    pipe.set_outputs(processed)
    pipe.build()
    for _ in range(3):
        pipe.run()
```


Overlapping Code:
```
egion_cpu():
pipe = Pipeline(batch_size=batch_size, num_threads=4, device_id=None)
test_data_shape = [200]
def get_data():
out = [np.random.randint(0, 255, size = test_data_shape, dtype = np.uint8) for _ in range(batch_size)]
out[0][0] = 0
out[1][0] = 0
out[1][1] = 0
return out
data = fn.external_source(source = get_data)
processed, _ = fn.nonsilent_region(data)
pipe.set_outputs(processed)
pipe.build()
for _ in range(3):
pipe.run(
```
<Overlap Ratio: 0.9538461538461539>

---

--- 250 --
Question ID: 0dbd18b25b829660d44fc32931458d4e9a388188_7
Original Code:
```
def AddLoadBalancingScheme(parser,
                           include_l7_ilb=False,
                           include_gfe3=False,
                           include_l7_rxlb=False,
                           include_psc_google_apis=False,
                           include_target_service_attachment=False):
  """Adds the load-balancing-scheme flag."""
  td_proxies = ('--target-http-proxy, --target-https-proxy, '
                '--target-grpc-proxy, --target-tcp-proxy')
  load_balancing_choices = {
      'EXTERNAL':
          'External load balancing or forwarding, used with one of '
          '--target-http-proxy, --target-https-proxy, --target-tcp-proxy, '
          '--target-ssl-proxy, --target-pool, --target-vpn-gateway, '
          '--target-instance.',
      'INTERNAL':
          'Internal load balancing or forwarding, used with --backend-service.',
      'INTERNAL_SELF_MANAGED':
          """Traffic Director load balancing or forwarding, used with
          {0}.""".format(td_proxies)
  }

  if include_l7_ilb:
    load_balancing_choices.update({
        'INTERNAL_MANAGED': 'Internal HTTP(S) Load Balancing, used with '
                            '--target-http-proxy, --target-https-proxy.'
    })

  if include_gfe3 or include_l7_rxlb:
    load_balancing_choices.update({
        'EXTERNAL_MANAGED':
            'Envoy based External HTTP(S) Load Balancing, used with '
            '--target-http-proxy, --target-https-proxy.'
    })

  # There isn't a default load-balancing-scheme for PSC forwarding rules.
  # But the default is EXTERNAL for non-PSC forwarding rules.
  include_psc = (include_psc_google_apis or include_target_service_attachment)
  parser.add_argument(
      '--load-balancing-scheme',
      choices=load_balancing_choices,
      type=lambda x: x.replace('-', '_').upper(),
      default=None if include_psc else 'EXTERNAL',
      help="This defines the forwarding rule's load balancing scheme. Note that it defaults to EXTERNAL and is not applicable for Private Service Connect forwarding rules."
      if include_psc else
      "This defines the forwarding rule's load balancing scheme.")
```


Overlapping Code:
```
7_ilb=False,
include_gfe3=False,
include_l7_rxlb=False,
include_psc_google_apis=False,
include_target_service_attachment=False):
"""Adds the load-balancing-scheme flag."""
td_proxies = ('--target-http-proxy, --target-https-proxy, '
'--target-grpc-proxy, --target-tcp-proxy')
load_balancing_choices = {
'EXTERNAL':
'External load balancing or forwarding, used with one of '
'--target-http-proxy, --target-https-proxy, --target-tcp-proxy, '
'--target-ssl-proxy, --target-pool, --target-vpn-gateway, '
'--target-instance.',
'INTERNAL':
'Internal load balancing or forwarding, used with --backend-service.',
'INTERNAL_SELF_MANAGED':
"""Traffic Director load balancing or forwarding, used with
{0}.""".format(td_proxies)
}
if include_l7_ilb:
load_balancing_choices.update({
'INTERNAL_MANAGED': 'Internal HTTP(S) Load Balancing, used with '
'--target-http-proxy, --target-https-proxy.'
})
if include_gfe3 or include_l7_rxlb:
load_balancing_choices.update({
'EXTERNAL_MANAGED':
'Envoy based External HTTP(S) Load Balancing, used with '
'--target-http-proxy, --target-https-proxy.'
})
# There isn't a default load-balancing-scheme for PSC forwarding rules.
# But the default is EXTERNAL for non-PSC forwarding rules.
include_psc = (include_psc_google_apis or include_target_service_attachment)
parser.add_argument(
'--load-balancing-scheme',
choices=load_balancing_choices,
type=lambda x: x.replace('-', '_').upper(),
default=None if include_psc else 'EXTERNAL',
help="This defines the forwarding rule's load balancing scheme. Note that it defaults to EXTERNAL and is not applicable for Private Service Connect forwarding rules."
if include_psc else
"This defines the forwarding rule's load balancing scheme.
```
<Overlap Ratio: 0.9736540664375716>

---

--- 251 --
Question ID: d9e89989f24ddd8018772c7d57dea385966e9438_3
Original Code:
```
def table_generic(dbse, serrors,
    mtd, bas, columnplan, rowplan=['bas', 'mtd'],
    opt=['CP'], err=['mae'], sset=['default'],
    landscape=False, standalone=True, subjoin=True, suppressblanks=False,
    footnotes=[], title='', indextitle='',
    plotpath='', theme=''):
    """
    Arrays *mtd* and *bas* contain the keys to the qcdb.Method and
    qcdb.BasisSet objects that span all those that the table may
    encompass. If method and basis are to be scanned over, the arrays
    should be in the desired order.

    """
    def table_header(kw, abbr, head1, head0, head2):
        """Form table header"""
        ref = r"""tbl:qcdb-%s-%s""" % (theme, '-'.join([kw[bit] for bit in tag]))
        fancy_kw = {k: (mc_archive[k][v].latex if k in mc_archive else v) for k, v in items(kw)}
        text.append('')
        text.append(r"""\begingroup""")
        text.append(r"""\squeezetable""")
        text.append(r"""\begin{%s}[h!tp]""" % ('sidewaystable' if landscape else 'table'))
        text.append(r"""\renewcommand{\baselinestretch}{1}""")
        text.append(r"""\caption{%s""" % (title.format(**fancy_kw).replace('_', '\\_')))
        text.append(r"""\label{%s}}""" % (ref))
        indices.append(r"""\scriptsize \ref{%s} & \scriptsize %s \\ """ % \
            (ref, indextitle.format(**fancy_kw)))
        text.append(r"""\begin{ruledtabular}""")
        text.append(r"""\begin{tabular}{%s}""" % (abbr))
        text.append(head1)
        text.append(head0)
        text.append(head2)
        text.append(hline)

    def table_footer():
        """Form table footer"""

        # search-and-replace footnotes
        fnmatch = re.compile(r"""(?P<cellpre>.*)""" + r"""(\\footnotemark)\{(?P<fntext>.*)\}""" + r"""(?P<cellpost>.*)""")
        otfcounter = len(footnotes) + 1
        lines2replace = {}
        otffootnotes = collections.OrderedDict()
        for idx, line in enumerate(text):
            newcells = []
            changed = False
            for cell in line.split('&'):
                res = fnmatch.match(cell)
                if res:
                    if res.group('fntext') in otffootnotes:
                        localcounter = otffootnotes[res.group('fntext')]
                    else:
                        localcounter = otfcounter
                        if localcounter == 52:  # fn symbols run out at "zz"
                            otffootnotes['Missing some reactions'] = localcounter
                        else:
                            otfcounter += 1
                            otffootnotes[res.group('fntext')] = localcounter
                    newcells.append(res.group('cellpre') + r"""\footnotemark[""" + str(localcounter) + ']' + res.group('cellpost'))
                    changed = True
                else:
                    newcells.append(cell)
            if changed:
                lines2replace[idx] = '&'.join(newcells)
        for idx, line in items(lines2replace):
            text[idx] = line

        # search-and-suppress "blank" lines
        if suppressblanks:
            for idx, line in enumerate(text):
                if line.strip().endswith('\\'):
                    innards = ''.join(line.rstrip(""" \\""").split('&')[1:])
                    if innards.isspace():
                        text[idx] = '%' + text[idx]

        # finish out table
        text.append(r"""\end{tabular}""")
        text.append(r"""\end{ruledtabular}""")
        for idx, fn in enumerate(footnotes):
            text.append(r"""\footnotetext[%d]{%s}""" % (idx + 1, fn))
        for fn, idx in items(otffootnotes):
            text.append(r"""\footnotetext[%d]{%s}""" % (idx, fn))
        text.append(r"""\end{%s}""" % ('sidewaystable' if landscape else 'table'))
        text.append(r"""\endgroup""")
        text.append(r"""\clearpage""")
        text.append('')

    def matelem(dict_row, dict_col):
        """Return merge of index dictionaries *dict_row* and *dict_col* (precedence) with error string from serrors appended at key 'matelem'."""
        kw = dict(dict_row, **dict_col)
        errpiece = serrors['-'.join([kw[bit] for bit in ['mtd', 'opt', 'bas']])][kw['sset']][kw['dbse']]
        kw['matelem'] = errpiece[kw['err']]
        if 'tgtcnt' in errpiece:
            kw['count'] = errpiece['tgtcnt']
        if 'misscnt' in errpiece and errpiece['misscnt'] != 0 and 'tgtcnt' in errpiece:
            kw['footnote'] = r"""\footnotemark{Missing %d of %d reactions.}""" % (errpiece['misscnt'], errpiece['tgtcnt'])
        else:
            kw['footnote'] = ''
        return kw

    # avoid misunderstandings
    keysincolumnplan = set(sum([col[-1].keys() for col in columnplan], []))
    for key in ['dbse', 'sset', 'mtd', 'opt', 'bas', 'err']:
        if len(locals()[key]) > 1:
            if key not in rowplan and key not in keysincolumnplan:
                print("""Warning: non-first values in argument '{0}' won't """
                      """get used. Add '{0}' to rowplan to iterate over """
                      """the values or add to columnplan to access"""
                      """different values.""".format(key))
                sys.exit()

    # form LaTeX reference tag
    tag = []
    for key in ['dbse', 'sset', 'mtd', 'opt', 'bas', 'err']:
        if len(locals()[key]) == 1 or (key == rowplan[0] and not subjoin):
            tag.append(key)
    tag = set(tag)
    for col in columnplan:
        tag -= set(col[4].keys())

    # form column headers
    start = 1
    stop = 1
    head0 = ''
    for index in range(2, len(columnplan)):
        if columnplan[index][1] == columnplan[index - 1][1]:
            stop = index
        else:
            head0 += r"""\cline{%d-%d}""" % (start + 1, stop + 1)
            start = index
            stop = index
        if index + 1 == len(columnplan):
            head0 += r"""\cline{%d-%d}""" % (start + 1, stop + 1)

    abbr = ''.join([col[0] for col in columnplan])
    h1 = [(k, len(list(g))) for k, g in itertools.groupby([col[1] for col in columnplan])]
    head1 = ' & '.join([r"""\multicolumn{%d}{c}{\textbf{%s}}""" % (repeat, label) for (label, repeat) in h1]) + r""" \\ """
    h2 = [(k, len(list(g))) for k, g in itertools.groupby([col[2] for col in columnplan])]
    head2 = ' & '.join([r"""\multicolumn{%d}{c}{\textbf{%s}}""" % (repeat, label) for (label, repeat) in h2]) + r""" \\ """

    # form table body
    text = []
    indices = []
    nH = len(rowplan)
    hline = r"""\hline"""
    kw = {'plotpath': plotpath, 'sset': sset[0], 'dbse': dbse[0], 'err': err[0],
          'mtd': mtd[0], 'opt': opt[0], 'bas': bas[0]}

    if standalone:
        text += begin_latex_document()

    if nH == 1:
        subjoin = True

    if subjoin:
        table_header(kw, abbr, head1, head0, head2)
        if text[-1] != hline:
            text.append(hline)

    for hier0 in locals()[rowplan[0]]:
        kw[rowplan[0]] = hier0
        kw['target'] = rowplan[0]
        if nH > 1:

            if not subjoin:
                table_header(kw, abbr, head1, head0, head2)
            if text[-1] != hline:
                text.append(hline)
            #text.append(r"""\textbf{%s} \\ """ % (mc_archive[rowplan[0]][hier0].latex))
            text.append(r"""\textbf{%s} \\ """ % (label2(hier0)))

            for hier1 in locals()[rowplan[1]]:
                kw[rowplan[1]] = hier1
                kw['target'] = rowplan[1]
                if nH > 2:
                    #text.append(r"""\enspace\textbf{%s} \\ """ % (mc_archive[rowplan[1]][hier1].latex))
                    text.append(r"""\enspace\textbf{%s} \\ """ % (label2(hier1)))

                    for hier2 in locals()[rowplan[2]]:
                        kw[rowplan[2]] = hier2
                        kw['target'] = rowplan[2]

                        text.append(r"""\enspace\enspace""" + ' & '.join([col[3](matelem(kw, col[4])) for col in columnplan]) + r""" \\ """)
                else:
                    text.append(r"""\enspace""" + ' & '.join([col[3](matelem(kw, col[4])) for col in columnplan]) + r""" \\ """)
            if not subjoin:
                table_footer()
        else:
            text.append(' & '.join([col[3](matelem(kw, col[4])) for col in columnplan]) + r""" \\ """)

    if subjoin:
        table_footer()

    if standalone:
        text += end_latex_document()

    return text, indices
```


Overlapping Code:
```

```
<Overlap Ratio: 0.0>

---

--- 252 --
Question ID: 79881a9843be0db7191e35e2fc0199373f3983d0_5
Original Code:
```
def loop_through_books(book_orderedpages_dict, collection_sourcepath, collection_outputpath, books_needing_converting):
    for book_name, ordered_pages_pointers in sorted(book_orderedpages_dict.items()):
        if book_name not in books_needing_converting:
            continue
        convert_a_book(
            book_name,
            ordered_pages_pointers,
            collection_sourcepath,
            collection_outputpath
        )
```


Overlapping Code:
```
llection_sourcepath, collection_outputpath, books_needing_converting):
for book_name, ordered_pages_pointers in sorted(book_orderedpages_dict.items()):
if book_name not in books_needing_converting:
continue
convert_a_book(
book_name,
ordered_pages_pointers,
collection_sourcepath,
collection_outputpa
```
<Overlap Ratio: 0.8498583569405099>

---

--- 253 --
Question ID: dcfdfb7190b8531c9a888be1c5fb2e556ea714f0_16
Original Code:
```
def ip_CallBack(ip_entry,page):
    global ip
    ip = ip_entry.get()
    page.withdraw()
    myStr = ""
    for x in range(len(directory_List)):
        myStr = myStr + "From: " + directory_List[x][0] + " To: " + directory_List[x][1] + "\n"
        init_Client(x)
        print("Done: ", myStr)

    messagebox.showinfo(message="Sync Complete: \n" + myStr)
```


Overlapping Code:
```
ip = ip_entry.get()
page.withdraw()
myStr = ""
for x in range(len(directory_List)):
myStr = myStr + "From: " + directory_List[x][0] + " To: " + directory_List[x][1] + "\n"
init_Client(x)
print("Done: ", myStr)
messagebox.showinfo(message="Sync Comple
```
<Overlap Ratio: 0.8116883116883117>

---

--- 254 --
Question ID: f6894fc552c5927f9a2d0715eec985f4c410a9fc_4
Original Code:
```
def test_getgenre_stations_cache_disabled(
    config, get_genre_stations_return_value_mock
):
    with mock.patch.object(
        APIClient,
        "get_genre_stations",
        return_value=get_genre_stations_return_value_mock,
    ):
        cache_config = config
        cache_config["pandora"]["cache_time_to_live"] = 0
        backend = conftest.get_backend(cache_config)

        assert backend.api.genre_stations_cache.currsize == 0

        assert len(backend.api.get_genre_stations()) == 1
        assert backend.api.genre_stations_cache.currsize == 0
```


Overlapping Code:
```
abled(
config, get_genre_stations_return_value_mock
):
with mock.patch.object(
APIClient,
"get_genre_stations",
return_value=get_genre_stations_return_value_mock,
):
cache_config = config
cache_config["pandora"]["cache_time_to_live"] = 0
backend = conftest.get_backend(cache_config)
assert backend.api.genre_stations_cache.currsize == 0
assert len(backend.api.get_genre_stations()) == 1
assert backen
```
<Overlap Ratio: 0.8403361344537815>

---

--- 255 --
Question ID: 2792a0709a569714392afdcea2c2862d0bea2e03_0
Original Code:
```
def install(externalsdir, installdir, builddir):
  # installdir = "/usr/local"
  pi = PackageInstall(os.path.join(externalsdir, "Xdmf_13_02_2018.tgz"), installdir, builddir)
  os.environ["HDF5_ROOT"] = "/usr/local"
  #XDMF_WRAP_PYTHON
  cmakeoptions="-DBUILD_SHARED_LIBS=1 -DXDMF_WRAP_PYTHON=1 -Wno-dev -DXDMF_BUILD_TESTING=1"
  pi.install_cmake(cmakeoptions=cmakeoptions)
```


Overlapping Code:
```
, installdir, builddir):
# installdir = "/usr/local"
pi = PackageInstall(os.path.join(externalsdir, "Xdmf_13_02_2018.tgz"), installdir, builddir)
os.environ["HDF5_ROOT"] = "/usr/local"
#XDMF_WRAP_PYTHON
cmakeoptions="-DBUILD_SHARED_LIBS=1 -DXDMF_WRAP_PYTHON=1 -Wno-dev -DXDMF_BUILD_TESTING=1"
pi.inst
```
<Overlap Ratio: 0.8333333333333334>

---

--- 256 --
Question ID: 81a5899b0055966583cbf93f22c2fbaf3992b2f1_1
Original Code:
```
def check_np_array(item, field_name, ndim, parent_class, channel_num=None):
    """
    Check a numpy array's shape and dtype against required
    specifications.

    Parameters
    ----------
    item : numpy array
        The numpy array to check
    field_name : str
        The name of the field to check
    ndim : int
        The required number of dimensions
    parent_class : type
        The parent class of the dtype. ie. np.integer, np.floating.
    channel_num : int, optional
        If not None, indicates that the item passed in is a subelement
        of a list. Indicate this in the error message if triggered.

    """
    # Check shape
    if item.ndim != ndim:
        error_msg = 'Field `%s` must have ndim == %d' % (field_name, ndim)
        if channel_num is not None:
            error_msg = ('Channel %d of f' % channel_num) + error_msg[1:]
        raise TypeError(error_msg)

    # Check dtype
    if not np.issubdtype(item.dtype, parent_class):
        error_msg = 'Field `%s` must have a dtype that subclasses %s' % (field_name, parent_class)
        if channel_num is not None:
            error_msg = ('Channel %d of f' % channel_num) + error_msg[1:]
        raise TypeError(error_msg)
```


Overlapping Code:
```
 check_np_array(item, field_name, ndim, parent_class, channel_num=None):
"""
Check a numpy array's shape and dtype against required
specifications.
Parameters
----------
item : numpy array
The numpy array to check
field_name : str
The name of the field to check
ndim : int
The required number of dimensions
parent_class : type
The parent class of the dtype. ie. np.integer, np.floating.
channel_num : int, optional
If not None, indicates that the item passed in is a subelement
of a list. Indicate this in the error message if triggered.
"""
# Check shape
if item.ndim != ndim:
error_msg = 'Field `%s` must have ndim == %d' % (field_name, ndim)
if channel_num is not None:
error_msg = ('Channel %d of f' % channel_num) + error_msg[1:]
raise TypeError(error_msg)
# Check dtype
if not np.issubdtype(item.dtype, parent_class):
error_msg = 'Field `%s` must have a dtype that subclasses %s' % (field_name, parent_class)
if channel_num is not None:
error_msg = ('Channel %d of f' % channel_num) + error_msg[1:]
raise TypeError(er
```
<Overlap Ratio: 0.9893617021276596>

---

--- 257 --
Question ID: 2f813ea3cdb06fab295cc5987425bc681fbaf551_0
Original Code:
```
def get_products(pclient, **kwargs):
    """Fetch pricing based on filter.
    """
    filters = []
    for k, v in kwargs.items():
        if v is not None:
            filters.append({"Type": "TERM_MATCH", "Field": k, "Value": v})

    res = []
    pager = pclient.get_paginator("get_products").paginate
    for page in pager(FormatVersion="aws_v1", ServiceCode=kwargs.get("ServiceCode"), Filters=filters):
        for rec in page.get("PriceList") or []:
            res.append(json.loads(rec))
    return res
```


Overlapping Code:
```
 **kwargs):
"""Fetch pricing based on filter.
"""
filters = []
for k, v in kwargs.items():
if v is not None:
filters.append({"Type": "TERM_MATCH", "Field": k, "Value": v})
res = []
pager = pclient.get_paginator("get_products").paginate
for page in pager(FormatVersion="aws_v1", ServiceCode=kwargs.get("ServiceCode"), Filters=filters):
for rec in page.get("PriceList") or []:
res.append(json.loads(rec
```
<Overlap Ratio: 0.91324200913242>

---

--- 258 --
Question ID: e64a9f5014b7f60f1d621c753c983b102fbe3148_15
Original Code:
```
def write_handoff_fxn(dispatchable_obj, cfile, local_handles):
   cfile.write('{decl}\n{{\n'.format(**{'decl':_ws_text['handoff_fxn_decl'].format(name=abbr2name(dispatchable_obj.abbreviation))}))
   _local_handles = ['handle_{name}'.format(name = abbr2name(l.abbreviation)) for l in local_handles.values()]
   handles = set()
   joins = [j for j in dispatchable_obj.children if isinstance(j, Register)]
   for j in joins:
      handles.add('handle_{name}'.format(name = abbr2name(j.parent.abbreviation)))
   for h in handles:
      if h not in _local_handles:
         cfile.write('{indent}dissector_handle_t {handle};\n'.format(indent = _ws_text['indent'], handle = h))
   for j in joins:
      if h not in _local_handles:
         cfile.write('{indent}handle_{name} = find_dissector("{name}");\n'.format(indent = _ws_text['indent'], name=abbr2name(j.parent.abbreviation)))
      cfile.write('{indent}dissector_add_uint("{table}", {value}, handle_{name});\n'.format(indent = _ws_text['indent'],
                                                                                            table  = j.table,
                                                                                            value  = j.value,
                                                                                            name   = abbr2name(j.parent.abbreviation)))
   cfile.write('}\n\n')
   if ws_has_section(dispatchable_obj, 'messages'):
      for m in dispatchable_obj.messages.values():
         write_handoff_fxn(m, cfile, local_handles)
```


Overlapping Code:
```
ispatchable_obj, cfile, local_handles):
cfile.write('{decl}\n{{\n'.format(**{'decl':_ws_text['handoff_fxn_decl'].format(name=abbr2name(dispatchable_obj.abbreviation))}))
_local_handles = ['handle_{name}'.format(name = abbr2name(l.abbreviation)) for l in local_handles.values()]
handles = set()
joins = [j for j in dispatchable_obj.children if isinstance(j, Register)]
for j in joins:
handles.add('handle_{name}'.format(name = abbr2name(j.parent.abbreviation)))
for h in handles:
if h not in _local_handles:
cfile.write('{indent}dissector_handle_t {handle};\n'.format(indent = _ws_text['indent'], handle = h))
for j in joins:
if h not in _local_handles:
cfile.write('{indent}handle_{name} = find_dissector("{name}");\n'.format(indent = _ws_text['indent'], name=abbr2name(j.parent.abbreviation)))
cfile.write('{indent}dissector_add_uint("{table}", {value}, handle_{name});\n'.format(indent = _ws_text['indent'],
table = j.table,
value = j.value,
name = abbr2name(j.parent.abbreviation)))
cfile.write('}\n\n')
if ws_has_section(dispatchable_obj, 'messages'):
for m in dispatchable_obj.messages.values():
wr
```
<Overlap Ratio: 0.9459691252144082>

---

--- 259 --
Question ID: 13b1c0172247e26d32cab2292a3168121479e12b_18
Original Code:
```
def _randrange_impl(context, builder, start, stop, step, state):
    state_ptr = get_state_ptr(context, builder, state)
    ty = stop.type
    zero = ir.Constant(ty, 0)
    one = ir.Constant(ty, 1)
    nptr = cgutils.alloca_once(builder, ty, name="n")
    # n = stop - start
    builder.store(builder.sub(stop, start), nptr)

    with builder.if_then(builder.icmp_signed('<', step, zero)):
        # n = (n + step + 1) // step
        w = builder.add(builder.add(builder.load(nptr), step), one)
        n = builder.sdiv(w, step)
        builder.store(n, nptr)
    with builder.if_then(builder.icmp_signed('>', step, one)):
        # n = (n + step - 1) // step
        w = builder.sub(builder.add(builder.load(nptr), step), one)
        n = builder.sdiv(w, step)
        builder.store(n, nptr)

    n = builder.load(nptr)
    with cgutils.if_unlikely(builder, builder.icmp_signed('<=', n, zero)):
        # n <= 0
        msg = "empty range for randrange()"
        context.call_conv.return_user_exc(builder, ValueError, (msg,))

    fnty = ir.FunctionType(ty, [ty, cgutils.true_bit.type])
    fn = builder.function.module.get_or_insert_function(fnty, "llvm.ctlz.%s" % ty)
    # Since the upper bound is exclusive, we need to subtract one before
    # calculating the number of bits. This leads to a special case when
    # n == 1; there's only one possible result, so we don't need bits from
    # the PRNG. This case is handled separately towards the end of this
    # function. CPython's implementation is simpler and just runs another
    # iteration of the while loop when the resulting number is too large
    # instead of subtracting one, to avoid needing to handle a special
    # case. Thus, we only perform this subtraction for the NumPy case.
    nm1 = builder.sub(n, one) if state == "np" else n
    nbits = builder.trunc(builder.call(fn, [nm1, cgutils.true_bit]), int32_t)
    nbits = builder.sub(ir.Constant(int32_t, ty.width), nbits)

    rptr = cgutils.alloca_once(builder, ty, name="r")

    def get_num():
        bbwhile = builder.append_basic_block("while")
        bbend = builder.append_basic_block("while.end")
        builder.branch(bbwhile)

        builder.position_at_end(bbwhile)
        r = get_next_int(context, builder, state_ptr, nbits, state == "np")
        r = builder.trunc(r, ty)
        too_large = builder.icmp_signed('>=', r, n)
        builder.cbranch(too_large, bbwhile, bbend)

        builder.position_at_end(bbend)
        builder.store(r, rptr)

    if state == "np":
        # Handle n == 1 case, per previous comment.
        with builder.if_else(builder.icmp_signed('==', n, one)) as (is_one, is_not_one):
            with is_one:
                builder.store(zero, rptr)
            with is_not_one:
                get_num()
    else:
        get_num()

    return builder.add(start, builder.mul(builder.load(rptr), step))
```


Overlapping Code:
```
ef _randrange_impl(context, builder, start, stop, step, state):
state_ptr = get_state_ptr(context, builder, state)
ty = stop.type
zero = ir.Constant(ty, 0)
one = ir.Constant(ty, 1)
nptr = cgutils.alloca_once(builder, ty, name="n")
# n = stop - start
builder.store(builder.sub(stop, start), nptr)
with builder.if_then(builder.icmp_signed('<', step, zero)):
# n = (n + step + 1) // step
w = builder.add(builder.add(builder.load(nptr), step), one)
n = builder.sdiv(w, step)
builder.store(n, nptr)
with builder.if_then(builder.icmp_signed('>', step, one)):
# n = (n + step - 1) // step
w = builder.sub(builder.add(builder.load(nptr), step), one)
n = builder.sdiv(w, step)
builder.store(n, nptr)
n = builder.load(nptr)
with cgutils.if_unlikely(builder, builder.icmp_signed('<=', n, zero)):
# n <= 0
msg = "empty range for randrange()"
context.call_conv.return_user_exc(builder, ValueError, (msg,))
fnty = ir.FunctionType(ty, [ty, cgutils.true_bit.type])
fn = builder.function.module.get_or_insert_function(fnty, "llvm.ctlz.%s" % ty)
# Since the upper bound is exclusive, we need to subtract one before
# calculating the number of bits. This leads to a special case when
# n == 1; there's only one possible result, so we don't need bits from
# the PRNG. This case is handled separately towards the end of this
# function. CPython's implementation is simpler and just runs another
# iteration of the while loop when the resulting number is too large
# instead of subtracting one, to avoid needing to handle a special
# case. Thus, we only perform this subtraction for the NumPy case.
nm1 = builder.sub(n, one) if state == "np" else n
nbits = builder.trunc(builder.call(fn, [nm1, cgutils.true_bit]), int32_t)
nbits = builder.sub(ir.Constant(int32_t, ty.width), nbits)
rptr = cgutils.alloca_once(builder, ty, name="r")
def get_num():
bbwhile = builder.append_basic_block("while")
bbend = builder.append_basic_block("while.end")
builder.branch(bbwhile)
builder.position_at_end(bbwhile)
r = get_next_int(context, builder, state_ptr, nbits, state == "np")
r = builder.trunc(r, ty)
too_large = builder.icmp_signed('>=', r, n)
builder.cbranch(too_large, bbwhile, bbend)
builder.position_at_end(bbend)
builder.store
```
<Overlap Ratio: 0.9932279909706546>

---

--- 260 --
Question ID: afa3041a17765426e295369c955004ec3b8f9e91_0
Original Code:
```
@pytest.fixture()
def AnsibleDefaults(Ansible):
    """ Load default variables into dictionary.

    Args:
        Ansible - Requires the ansible connection backend.
    """
    return Ansible("include_vars", "./defaults/main.yml")["ansible_facts"]
```


Overlapping Code:
```
ture()
def AnsibleDefaults(Ansible):
""" Load default variables into dictionary.
Args:
Ansible - Requires the ansible connection backend.
"""
return Ansible("include_vars", "./defaults/main.yml")["ansible_facts
```
<Overlap Ratio: 0.9417040358744395>

---

--- 261 --
Question ID: 5d2683984e28f77df8e777a9bf40f8bbd269ddd6_0
Original Code:
```
@main.before_request
def before_request():
    if 'cart' not in session:
        session['cart'] = Cart().to_dict()
```


Overlapping Code:
```
fore_request
def before_request():
if 'cart' not in session:
session['cart'] = Cart().to_dict(
```
<Overlap Ratio: 0.912621359223301>

---

--- 262 --
Question ID: be6f24091f09bd7beb62aa38489c89ecf8b03c6e_0
Original Code:
```
def merge_counts(counts, output, attrs, reduce=False):
    handles = {}
    for sample, path in counts.items():
        handles[sample] = open(path, 'rt')
    with open(output, 'w') as fh:
        samples = list(counts.keys())
        headers = attrs + '\t' + '\t'.join(samples) + '\n'
        fh.write(headers)
        for lines in zip_longest(*[handles[sample] for sample in samples]):
            if lines[0].startswith('__'):
                continue
            values = [line.rstrip().split('\t')[-1] for line in lines]
            gene_annos = '\t'.join(lines[0].rstrip().split('\t')[:-1])
            if reduce:
                if len([v for v in values if int(v) > 0]) < 1:
                    continue
            line = gene_annos + '\t' + '\t'.join(values) + '\n'
            fh.write(line)
    for h in handles.values():
        h.close()
```


Overlapping Code:
```
t, attrs, reduce=False):
handles = {}
for sample, path in counts.items():
handles[sample] = open(path, 'rt')
with open(output, 'w') as fh:
samples = list(counts.keys())
headers = attrs + '\t' + '\t'.join(samples) + '\n'
fh.write(headers)
for lines in zip_longest(*[handles[sample] for sample in samples]):
if lines[0].startswith('__'):
continue
values = [line.rstrip().split('\t')[-1] for line in lines]
gene_annos = '\t'.join(lines[0].rstrip().split('\t')[:-1])
if reduce:
if len([v for v in values if int(v) > 0]) < 1:
continue
line = gene_annos + '\t' + '\t'.join(values) + '\n'
fh.write(line)
for
```
<Overlap Ratio: 0.9049773755656109>

---

--- 263 --
Question ID: 92ff2720f68619c5fab208029a1b917012cc5338_6
Original Code:
```
def is_func_default(node):
    """return true if the given Name node is used in function default argument's
    value
    """
    parent = node.scope()
    if isinstance(parent, astng.Function):
        for default_node in parent.args.defaults:
            for default_name_node in default_node.nodes_of_class(astng.Name):
                if default_name_node is node:
                    return True
    return False
```


Overlapping Code:
```

"""return true if the given Name node is used in function default argument's
value
"""
parent = node.scope()
if isinstance(parent, astng.Function):
for default_node in parent.args.defaults:
for default_name_node in default_node.nodes_of_class(astng.Name):
if default_name_node is node:
return True
r
```
<Overlap Ratio: 0.8902077151335311>

---

--- 264 --
Question ID: 65ddaa4a5feda5c18aaf2891f826b0ac1eef08c4_0
Original Code:
```
def exit_with_error(msg, code=1, exception=None):
    if exception:
        exc_type, exc_value, exc_traceback = sys.exc_info()
        traceback.print_exception(exc_type, exc_value, exc_traceback,
                                limit=2, file=sys.stdout)
        print("Exception:", exception)
    print(msg)
    sys.exit(code)
```


Overlapping Code:
```
_with_error(msg, code=1, exception=None):
if exception:
exc_type, exc_value, exc_traceback = sys.exc_info()
traceback.print_exception(exc_type, exc_value, exc_traceback,
limit=2, file=sys.stdout)
print("Exception:", exception)
print(msg)
sys.exit(cod
```
<Overlap Ratio: 0.9615384615384616>

---

--- 265 --
Question ID: a04d8575f20c529b36ee6618718d2c0cf7dea892_4
Original Code:
```
def upload_file(api_client, id, file_path):
    api = rest.DataApi(api_client)
    upload_info = object_storage.upload_file(api_client, file_path, 'Data')
    model = rest.ComponentsAddFileInputModel(file_name=upload_info.file_name, stored_path=upload_info.stored_path)
    result = api.add_data_file(id, model=model)
    return result
```


Overlapping Code:
```
file(api_client, id, file_path):
api = rest.DataApi(api_client)
upload_info = object_storage.upload_file(api_client, file_path, 'Data')
model = rest.ComponentsAddFileInputModel(file_name=upload_info.file_name, stored_path=upload_info.stored_path)
result = api.add_data_file(id, model=model)
return re
```
<Overlap Ratio: 0.9523809523809523>

---

--- 266 --
Question ID: b3cb7e3ca4f5f8d769af64c0d9923591f0049ff5_1
Original Code:
```
@_register("bool")
def string_boolean(value):
    """Determines the boolean value for a specified string"""
    if value.lower() in ("false", "f", "0", ""):
        return False
    else:
        return True
```


Overlapping Code:
```
ool")
def string_boolean(value):
"""Determines the boolean value for a specified string"""
if value.lower() in ("false", "f", "0", ""):
return False
e
```
<Overlap Ratio: 0.8379888268156425>

---

--- 267 --
Question ID: 836898327106636e7370abe32fcbefa43fbfffd1_2
Original Code:
```
def _get_by_id(t, id_v):
    for id_a in config.id_attributes:
        log.debug("Looking for #%s using id attribute '%s'" % (id_v, id_a))
        elts = t.xpath("//*[@%s='%s']" % (id_a, id_v))
        if elts is not None and len(elts) > 0:
            return elts[0]
    return None
```


Overlapping Code:
```
d_v):
for id_a in config.id_attributes:
log.debug("Looking for #%s using id attribute '%s'" % (id_v, id_a))
elts = t.xpath("//*[@%s='%s']" % (id_a, id_v))
if elts is not None and len(elts) > 0:
return elts[0]
return N
```
<Overlap Ratio: 0.9079497907949791>

---

--- 268 --
Question ID: 703434e34b608837513e9f98daee6a3d5d0ed0b9_15
Original Code:
```
@stub
@pytest.mark.parametrize('stage_attributes', [{'instance_type': 'SOLR_CLOUD'}])
def test_zookeeper_connection_string(sdc_builder, sdc_executor, stage_attributes):
    pass
```


Overlapping Code:
```
@stub
@pytest.mark.parametrize('stage_attributes', [{'instance_type': 'SOLR_CLOUD'}])
def test_zookeeper_connection_string(sdc_builder, sdc_executor, stage_attributes):
pass
```
<Overlap Ratio: 1.0>

---

--- 269 --
Question ID: b993ad5a3a0e8bd45bf6b21962c310b57375d83a_0
Original Code:
```
def solve(masses: List[int]) -> Tuple[int, int]:
    one: int = 0
    for mass in masses:
        fuel = mass // 3 - 2
        one += fuel
        if VERBOSE:
            print(f"{mass} {fuel} {one}")

    two: int = 0
    for mass in masses:
        module_fuel = mass // 3 - 2
        fuel = 0
        while module_fuel > 0:
            fuel += module_fuel
            module_fuel = module_fuel // 3 - 2
        two += fuel
        if VERBOSE:
            print(f"{mass} {fuel} {two}")

    return (one, two)
```


Overlapping Code:
```
Tuple[int, int]:
one: int = 0
for mass in masses:
fuel = mass // 3 - 2
one += fuel
if VERBOSE:
print(f"{mass} {fuel} {one}")
two: int = 0
for mass in masses:
module_fuel = mass // 3 - 2
fuel = 0
while module_fuel > 0:
fuel += module_fuel
module_fuel = module_fuel // 3 - 2
two += fuel
if VERBOSE:
pri
```
<Overlap Ratio: 0.7978723404255319>

---

--- 270 --
Question ID: 5865be0e0b12adc728219da9a099f1f6a15a73ce_3
Original Code:
```
def print_test_accuracy(show_example_errors=False,
                        show_confusion_matrix=False):

    # For all the images in the test-set,
    # calculate the predicted classes and whether they are correct.
    correct, cls_pred = predict_cls_test()

    # Classification accuracy and the number of correct classifications.
    acc, num_correct = cls_accuracy(correct)
    
    # Number of images being classified.
    num_images = len(correct)

    # Print the accuracy.
    msg = "Accuracy on Test-Set: {0:.1%} ({1} / {2})"
    print(msg.format(acc, num_correct, num_images))

    # Plot some examples of mis-classifications, if desired.
    if show_example_errors:
        print("Example errors:")
        plot_example_errors(cls_pred=cls_pred, correct=correct)

    # Plot the confusion matrix, if desired.
    if show_confusion_matrix:
        print("Confusion Matrix:")
        plot_confusion_matrix(cls_pred=cls_pred)
```


Overlapping Code:
```
def print_test_accuracy(show_example_errors=False,
show_confusion_matrix=False):
# For all the images in the test-set,
# calculate the predicted classes and whether they are correct.
correct, cls_pred = predict_cls_test()
# Classification accuracy and the number of correct classifications.
acc, num_correct = cls_accuracy(correct)

# Number of images being classified.
num_images = len(correct)
# Print the accuracy.
msg = "Accuracy on Test-Set: {0:.1%} ({1} / {2})"
print(msg.format(acc, num_correct, num_images))
# Plot some examples of mis-classifications, if desired.
if show_example_errors:
print("Example errors:")
plot_example_errors(cls_pred=cls_pred, correct=correct)
# Plot the confusion matrix, if desired.
if show_confusion_matrix:
print("Confusion Matrix:")
plot_confusion_matrix(cls_pred=cls_pred
```
<Overlap Ratio: 0.9987684729064039>

---

--- 271 --
Question ID: 2d7deba4f204f032e24a74feb1a47e420a420faf_0
Original Code:
```
def obj(beta, lambd = .1, x=X_train, y=y_train, h = .5):
    """
    Function for calculating the objective function for the huberized hinge loss.
    
    Inputs:
        beta: numpy vector
            a vector of length d corresponding to the beta vector
        lambd: int
            lambda, the penalization constant. Default = .1
        x: numpy matrix
            a matrix of size nxd
        y: numpy matrix
            a matrix of size nx1
        h: float
            huberized hinge loss parameter. Default = .5
    
    Returns:
        objective value: float, the objective value.
    """
    n, d = x.shape
    o = np.zeros(n)
    o[y*x.dot(beta) < 1 - h] = (1 - y*x.dot(beta))[y*x.dot(beta) < 1 - h]
    o[abs(1 - y*x.dot(beta)) <= h] = ((1 + h - y*(x.dot(beta)))**2 / (4 * h))[abs(1 - y*x.dot(beta)) <= h]
    return  (1.0/n) * np.sum(o) + lambd * np.sum(beta**2)
```


Overlapping Code:
```
bj(beta, lambd = .1, x=X_train, y=y_train, h = .5):
"""
Function for calculating the objective function for the huberized hinge loss.

Inputs:
beta: numpy vector
a vector of length d corresponding to the beta vector
lambd: int
lambda, the penalization constant. Default = .1
x: numpy matrix
a matrix of size nxd
y: numpy matrix
a matrix of size nx1
h: float
huberized hinge loss parameter. Default = .5

Returns:
objective value: float, the objective value.
"""
n, d = x.shape
o = np.zeros(n)
o[y*x.dot(beta) < 1 - h] = (1 - y*x.dot(beta))[y*x.dot(beta) < 1 - h]
o[abs(1 - y*x.dot(beta)) <= h] = ((1 + h - y*(x.dot(beta)))**2 / (4 * h))[abs(1 - y*x.dot(beta)) <= h]
return (1.0/n) * np.sum(o) + lambd
```
<Overlap Ratio: 0.9681881051175657>

---

--- 272 --
Question ID: bb75d3a23dd736bed84f1c9bc6ca51b10c3a16f6_0
Original Code:
```
def main():
    if sys.argv[1] == 'dev':
        dev()
    else:
        default()
```


Overlapping Code:
```

```
<Overlap Ratio: 0.0>

---

--- 273 --
Question ID: 2c947d5b6e054f7b898a48da0fd8ed4cbc29c190_0
Original Code:
```
def get_sequence_length(fasta_file_path: Path) -> int:
    if fasta_file_path.suffix == ".gz":
        with gzip.open(fasta_file_path, "rt") as fhandle:
            record = next(SeqIO.parse(fhandle, "fasta"))
    else:
        record = next(SeqIO.parse(fasta_file_path, "fasta"))
    return len(record.seq)
```


Overlapping Code:
```
ath: Path) -> int:
if fasta_file_path.suffix == ".gz":
with gzip.open(fasta_file_path, "rt") as fhandle:
record = next(SeqIO.parse(fhandle, "fasta"))
else:
record = next(SeqIO.parse(fasta_file_path, "
```
<Overlap Ratio: 0.7490636704119851>

---

--- 274 --
Question ID: b7e35ffc217f29c99d34b0a4ed5c2765668d4900_3
Original Code:
```
def generateBoundedProxMatrix(agentOpinions, epsilon, proximityLimit):
    
    confidenceMatrix = []
    
    for i in range (len(agentOpinions)):
        
        boundedAgents = np.zeros(len(agentOpinions))
        validAgents = 0
        
        if (i + proximityLimit + 1 >= len(agentOpinions)):
            startIndex = len(agentOpinions) - i - proximityLimit - 1
            endIndex = startIndex + (proximityLimit * 2) + 1

            
        else:
            startIndex = i - proximityLimit
            endIndex = i + proximityLimit + 1
        
        for x in range (startIndex, endIndex):
            if (np.abs(agentOpinions[x] - agentOpinions[i]) <= epsilon):
                boundedAgents[x] = 1
                validAgents += 1
                
        distribution = (np.random.dirichlet(np.ones(validAgents), 1))[0]
        iterator = 0
        
        for n in range (len(boundedAgents)):
            
            if (iterator == validAgents):
                break
            
            elif (boundedAgents[n] == 1):
                boundedAgents[n] = distribution[iterator]
                iterator += 1
    
        confidenceMatrix.append(boundedAgents)
    
    return confidenceMatrix
```


Overlapping Code:
```
Matrix(agentOpinions, epsilon, proximityLimit):

confidenceMatrix = []

for i in range (len(agentOpinions)):

boundedAgents = np.zeros(len(agentOpinions))
validAgents = 0

if (i + proximityLimit + 1 >= len(agentOpinions)):
startIndex = len(agentOpinions) - i - proximityLimit - 1
endIndex = startIndex + (proximityLimit * 2) + 1

else:
startIndex = i - proximityLimit
endIndex = i + proximityLimit + 1

for x in range (startIndex, endIndex):
if (np.abs(agentOpinions[x] - agentOpinions[i]) <= epsilon):
boundedAgents[x] = 1
validAgents += 1

distribution = (np.random.dirichlet(np.ones(validAgents), 1))[0]
iterator = 0

for n in range (len(boundedAgents)):

if (iterator == validAgents):
break

elif (boundedAgents[n] == 1):
boundedAgents[n] = distribution[iterator]
iterator += 1

confidenceMatrix.
```
<Overlap Ratio: 0.9205983889528193>

---

--- 275 --
Question ID: b9249b59dfe9c8d8156dd7a2f2c974cf1978d44e_2
Original Code:
```
@pytest.mark.vcr()
def test_workbench_assets_filter_type_unexpectedvalueerror(api):
    with pytest.raises(UnexpectedValueError):
        api.workbenches.assets(filter_type='NOT')
```


Overlapping Code:
```
est.mark.vcr()
def test_workbench_assets_filter_type_unexpectedvalueerror(api):
with pytest.raises(UnexpectedValueError):
api.workbenches.assets(filter_type='NOT
```
<Overlap Ratio: 0.9640718562874252>

---

--- 276 --
Question ID: e448594db7c73eaa0f2a152566132ac1a2539549_0
Original Code:
```
def intersect(x1, x2, x3, x4):
    if x1 > x3:
        x1, x2, x3, x4 = x3, x4, x1, x2
    if x3 > x2:
        return None, None
    return x3, min(x2, x4)
```


Overlapping Code:
```
):
if x1 > x3:
x1, x2, x3, x4 = x3, x4, x1, x2
if 
```
<Overlap Ratio: 0.3937007874015748>

---

--- 277 --
Question ID: 224e19be46ddf50db6ace667fb06ae8d5525adaa_4
Original Code:
```
def confint(seq):
    """
    Computes 95% confidence intervals.
    :param seq: list or a numpy array with sample measurements
    """
    return np.mean(seq) - (1.96 * np.std(seq)), np.mean(seq) + (1.96 * np.std(seq))
```


Overlapping Code:
```
(seq):
"""
Computes 95% confidence intervals.
:param seq: list or a numpy array with sample measurements
"""
return np.mean(seq) - (1.96 * np.std(seq)), 
```
<Overlap Ratio: 0.7688442211055276>

---

--- 278 --
Question ID: 0dc90991e67373ed00dca475d0349134442fb042_6
Original Code:
```
def set_volume(level):
	command=command_base()
	command[3]=0x06
	command[6]=level
	return command
```


Overlapping Code:
```
et_volume(level):
command=command_base()
command[3
```
<Overlap Ratio: 0.5376344086021505>

---

--- 279 --
Question ID: 878a1f84d31b1cecec2f70bd27005a1a3bb9ce40_3
Original Code:
```
def generate_and_save_lmplot(df, outf):
    """Generate a limplot and save it out."""
    sns_fig = sns.lmplot(data=df, x='sqft_living', y='price', hue='waterfront')
    sns_fig.savefig(outf, dpi=600)
```


Overlapping Code:
```
plot(df, outf):
"""Generate a limplot and save it out."""
sns_fig = sns.lmplot(data=df, x='sqft_living', y='price', hue='waterfront')
sns_fig.savefig(
```
<Overlap Ratio: 0.7978723404255319>

---

--- 280 --
Question ID: 3578a862e1eb29b52b91db967dcaf7d3884d9245_2
Original Code:
```
def test_get_non_existent_value(tracked_db):
    with pytest.raises(KeyError):
        tracked_db.get(b'does-not-exist')
    assert b'does-not-exist' not in tracked_db.access_logs.reads
```


Overlapping Code:
```
xistent_value(tracked_db):
with pytest.raises(KeyError):
tracked_db.get(b'does-not-exist')
assert b'does-not-exist' not in 
```
<Overlap Ratio: 0.727810650887574>

---

--- 281 --
Question ID: 86d955c0aa4609abdac84b46f4da17969c3a904d_1
Original Code:
```
def smart_str(s, encoding='utf8'):
    """ Convert unicode to str. If s is str, return itself.
    >>> smart_str(u'')
    ''
    >>> smart_str(u'abc')
    'abc'
    >>> smart_str(u'\u4f60\u597d') ==  '\xe4\xbd\xa0\xe5\xa5\xbd'
    True
    >>> smart_str('abc')
    'abc'
    >>> smart_str('\xe4\xbd\xa0\xe5\xa5\xbd') == '\xe4\xbd\xa0\xe5\xa5\xbd'
    True
    """
    if isinstance(s, str):
        return s
    return s.encode(encoding)
```


Overlapping Code:
```
rt_str(s, encoding='utf8'):
""" Convert unicode to str. If s is str, return itself.
>>> smart_str(u'')
''
>>> smart_str(u'abc')
'abc'
>>> smart_str(u'\u4f60\u597d') == '\xe4\xbd\xa0\xe5\xa5\xbd'
True
>>> smart_str('abc')
'abc'
>>> smart_str('\xe4\xbd\xa0\xe5\xa5\xbd') == '\xe4\xbd\xa0\xe5\xa5\xbd'
True
"""
if isinstance(s, str):
return s
return s.encode
```
<Overlap Ratio: 0.9543010752688172>

---

--- 282 --
Question ID: 28cf06ec1082d143c6f1b0c746ae4649398a80ae_3
Original Code:
```
def _fileserver_mesh_import(url, filename):
    """Internal function that adds primitive support for DAE files
    to the _mesh_import function of compas.robots."""
    file_extension = _get_file_format(url)

    if file_extension == 'dae':
        # Magic!
        return _dae_mesh_importer(filename)
    else:
        return _mesh_import(url, filename)
```


Overlapping Code:
```
esh_import(url, filename):
"""Internal function that adds primitive support for DAE files
to the _mesh_import function of compas.robots."""
file_extension = _get_file_format(url)
if file_extension == 'dae':
# Magic!
return _dae_mesh_importer(filename
```
<Overlap Ratio: 0.8090614886731392>

---

--- 283 --
Question ID: 181875788a6e9712e36f588155033bf53d309f5a_16
Original Code:
```
@login_in
# 给电影进行评论
def make_comment(request, movie_id):
    user = User.objects.get(id=request.session.get("user_id"))
    movie = Movie.objects.get(id=movie_id)
    comment = request.POST.get("comment")
    Comment.objects.create(user=user, movie=movie, content=comment)
    return redirect(reverse("movie", args=(movie_id,)))
```


Overlapping Code:
```
in_in
# 给电影进行评论
def make_comment(request, movie_id):
user = User.objects.get(id=request.session.get("user_id"))
movie = Movie.objects.get(id=movie_id)
comment = request.POST.get("comment")
Comment.objects.create(user=user, movie=movie, content=comment)
return redirect(reverse("movie", args=(movie_id
```
<Overlap Ratio: 0.974025974025974>

---

--- 284 --
Question ID: ceb56a689e01c2806f579c136ab625f8a9b2546a_0
Original Code:
```
def execute_callback(name, *args):
    """ Execute provided callback """

    callbacks = settings.IPAYMU_CALLBACKS
    callback_string = callbacks.get(name)

    if callback_string and isinstance(callback_string, basestring):
        # Fail silently when callback error
        # Just notify via log console.

        # Split callback namespace to module and its function
        ns = callback_string.split('.')
        callback_func = ns[-1]
        callback_module_str = '.'.join(ns[:-1])

        try:
            callback_module = import_module(callback_module_str)
            getattr(callback_module, callback_func)(*args)
        except ImportError as e:
            raise IpaymuCallbackError('Could not import Ipaymu callback module \'%s\'' % (callback_module_str))
        except AttributeError as e:
            raise IpaymuCallbackError('\'%s\' has no attribute \'%s\'' % (callback_module_str, callback_func))
    return
```


Overlapping Code:
```
ecute provided callback """
callbacks = settings.IPAYMU_CALLBACKS
callback_string = callbacks.get(name)
if callback_string and isinstance(callback_string, basestring):
# Fail silently when callback error
# Just notify via log console.
# Split callback namespace to module and its function
ns = callback_string.split('.')
callback_func = ns[-1]
callback_module_str = '.'.join(ns[:-1])
try:
callback_module = import_module(callback_module_str)
getattr(callback_module, callback_func)(*args)
except ImportError as e:
raise IpaymuCallbackError('Could not import Ipaymu callback module \'%s\'' % (callback_module_str))
except AttributeError as e:
raise IpaymuCallbackError('\'%s\' has no attribute \'%s\''
```
<Overlap Ratio: 0.8883248730964467>

---

--- 285 --
Question ID: c27de865ef89a22739952ae7e78078d815b3e39b_4
Original Code:
```
@patch('fix_rpath_osx.add_loader_path')
@patch('fix_rpath_osx.add_id')
@patch('fix_rpath_osx.get_file_object_from_prefix')
@patch('subprocess.check_call')
def test_main(
        mock_call,
        mock_get_files,
        mock_get_id,
        mock_add_loader_path,
        amber_src, libcpptraj):
    mock_get_files.return_value = [os.path.join(amber_src, libcpptraj)]
    fix_rpath_osx.main([amber_src])
    mock_get_id.assert_called_with(libcpptraj)
    mock_add_loader_path.assert_called_with(libcpptraj, amberhome, 'lib')
```


Overlapping Code:
```
_rpath_osx.add_loader_path')
@patch('fix_rpath_osx.add_id')
@patch('fix_rpath_osx.get_file_object_from_prefix')
@patch('subprocess.check_call')
def test_main(
mock_call,
mock_get_files,
mock_get_id,
mock_add_loader_path,
amber_src, libcpptraj):
mock_get_files.return_value = [os.path.join(amber_src, libcpptraj)]
fix_rpath_osx.main([amber_src])
mock_get_id.assert_called_with(libcpptraj)
mock_add_loader_path.assert_called_with(libcpptraj, amberhome,
```
<Overlap Ratio: 0.9615384615384616>

---

--- 286 --
Question ID: 6404f3d92896c73b18c929d102e95ee8d567e633_0
Original Code:
```
def git_clone_repository(repositoryGit):
    print_split.print_log("gitCloneRepository")
    respositoryDir = None
    try:
        (filepath, tempfilename) = os.path.split(repositoryGit)
        (filename, extension) = os.path.splitext(tempfilename)
        respositoryDir = settings.kAutoArchiveRepositoryRootPath + filename
    except:
        print_split.print_war("未配置git仓库地址")
        return

    if (not os.path.exists(respositoryDir)):
        print_split.print_war('git clone ' + repositoryGit + ' ' + respositoryDir)
        os.system('%s' % 'git clone ' + repositoryGit + ' ' + respositoryDir) 
    else:
        print_split.print_war("检查到本地git仓库已经存在")
```


Overlapping Code:
```
toryGit):
print_split.print_log("gitCloneRepository")
respositoryDir = None
try:
(filepath, tempfilename) = os.path.split(repositoryGit)
(filename, extension) = os.path.splitext(tempfilename)
respositoryDir = settings.kAutoArchiveRepositoryRootPath + filename
except:
print_split.print_war("未配置git仓库地址")
return
if (not os.path.exists(respositoryDir)):
print_split.print_war('git clone ' + repositoryGit + ' ' + respositoryDir)
os.system('%s' % 'git clone ' + repositoryGit + ' ' + respositoryDir) 
el
```
<Overlap Ratio: 0.8710801393728222>

---

--- 287 --
Question ID: a00eac733256a3b6d482971b346cd59ff9fce3d7_3
Original Code:
```
def join_multiline_pairs(text, pair="()"):
    """
    Finds and removes newlines in multiline matching pairs of characters in
    'text'.  For example, "(.*\n.*), {.*\n.*}, or [.*\n.*]".

    By default it joins parens () but it will join any two characters given via
    the 'pair' variable.

    **Note:** Doesnt remove extraneous whitespace that ends up between the pair.
    Use reduce_operators() for that.

    Example:

    .. code-block:: python

        test = (
            "This is inside a multi-line pair of parentheses"
        )

    Will become:

    .. code-block:: python

        test = (         "This is inside a multi-line pair of parentheses"     )
    """
    # Readability variables
    opener = pair[0]
    closer = pair[1]

    # Tracking variables
    inside_pair = False
    inside_quotes = False
    inside_double_quotes = False
    inside_single_quotes = False
    quoted_string = False
    openers = 0
    closers = 0
    linecount = 0  # lint:ok

    # Regular expressions
    opener_regex = re.compile('\%s' % opener)
    closer_regex = re.compile('\%s' % closer)

    output = ""

    for line in text.split('\n'):
        escaped = False
        # First we rule out multi-line strings
        multline_match = multiline_quoted_string.search(line)
        not_quoted_string_match = not_quoted_string.search(line)
        if multline_match and not not_quoted_string_match and not quoted_string:
            if len(line.split('"""')) > 1 or len(line.split("'''")):
                # This is a single line that uses the triple quotes twice
                # Treat it as if it were just a regular line:
                output += line + '\n'
                quoted_string = False
            else:
                output += line + '\n'
                quoted_string = True
        elif quoted_string and multiline_quoted_string.search(line):
            output += line + '\n'
            quoted_string = False
        # Now let's focus on the lines containing our opener and/or closer:
        elif not quoted_string:
            if opener_regex.search(line) \
               or closer_regex.search(line) or inside_pair:
                for character in line:
                    if character == opener:
                        if not escaped and not inside_quotes:
                            openers += 1
                            inside_pair = True
                            output += character
                        else:
                            escaped = False
                            output += character
                    elif character == closer:
                        if not escaped and not inside_quotes:
                            if openers and openers == (closers + 1):
                                closers = 0
                                openers = 0
                                inside_pair = False
                                output += character
                            else:
                                closers += 1
                                output += character
                        else:
                            escaped = False
                            output += character
                    elif character == '\\':
                        if escaped:
                            escaped = False
                            output += character
                        else:
                            escaped = True
                            output += character
                    elif character == '"' and escaped:
                        output += character
                        escaped = False
                    elif character == "'" and escaped:
                        output += character
                        escaped = False
                    elif character == '"' and inside_quotes:
                        if inside_single_quotes:
                            output += character
                        else:
                            inside_quotes = False
                            inside_double_quotes = False
                            output += character
                    elif character == "'" and inside_quotes:
                        if inside_double_quotes:
                            output += character
                        else:
                            inside_quotes = False
                            inside_single_quotes = False
                            output += character
                    elif character == '"' and not inside_quotes:
                        inside_quotes = True
                        inside_double_quotes = True
                        output += character
                    elif character == "'" and not inside_quotes:
                        inside_quotes = True
                        inside_single_quotes = True
                        output += character
                    elif character == ' ' and inside_pair and not inside_quotes:
                        if not output[-1] in [' ', opener]:
                            output += ' '
                    else:
                        if escaped:
                            escaped = False
                        output += character
                if inside_pair is False:
                    output += '\n'
            else:
                output += line + '\n'
        else:
            output += line + '\n'

    # Clean up
    output = trailing_newlines.sub('\n', output)

    return output
```


Overlapping Code:
```
_pairs(text, pair="()"):
"""
Finds and removes newlines in multiline matching pairs of characters in
'text'. For example, "(.*\n.*), {.*\n.*}, or [.*\n.*]".
By default it joins parens () but it will join any two characters given via
the 'pair' variable.
**Note:** Doesnt remove extraneous whitespace that ends up between the pair.
Use reduce_operators() for that.
Example:
.. code-block:: python
test = (
"This is inside a multi-line pair of parentheses"
)
Will become:
.. code-block:: python
test = ( "This is inside a multi-line pair of parentheses" )
"""
# Readability variables
opener = pair[0]
closer = pair[1]
# Tracking variables
inside_pair = False
inside_quotes = False
inside_double_quotes = False
inside_single_quotes = False
quoted_string = False
openers = 0
closers = 0
linecount = 0 # lint:ok
# Regular expressions
opener_regex = re.compile('\%s' % opener)
closer_regex = re.compile('\%s' % closer)
output = ""
for line in text.split('\n'):
escaped = False
# First we rule out multi-line strings
multline_match = multiline_quoted_string.search(line)
not_quoted_string_match = not_quoted_string.search(line)
if multline_match and not not_quoted_string_match and not quoted_string:
if len(line.split('"""')) > 1 or len(line.split("'''")):
# This is a single line that uses the triple quotes twice
# Treat it as if it were just a regular line:
output += line + '\n'
quoted_string = False
else:
output += line + '\n'
quoted_string = True
elif quoted_string and multiline_quoted_string.search(line):
output += line + '\n'
quoted_string = False
# Now let's focus on the lines containing our opener and/or closer:
elif not quoted_string:
if opener_regex.search(line) \
or closer_regex.search(line) or inside_pair:
for character in line:
if character == opener:
if not escaped and not inside_quotes:
openers += 1
inside_pair = True
output += ch
```
<Overlap Ratio: 0.9793541556379036>

---

--- 288 --
Question ID: 2c0bb179f7647e891760dbede059edfc220539dd_5
Original Code:
```
@app.route("/api/group/<group>", methods=["GET"])
@api
@auth
def get_group_keys_view(group):
    name = "funnel:" + group + ":keys"
    key_members = r.smembers(name)
    funnel_list = []
    for key in key_members:
        funnel = r.hgetall(key)
        funnel = {key: float(value) for key, value in funnel.iteritems()}
        funnel["name"] = key
        funnel_list.append(funnel)
    funnel_list.sort(key=lambda x: x["name"])
    data = {
        "funnel_list": funnel_list,
        "total_items": len(funnel_list),
    }
    return data
```


Overlapping Code:
```
pi/group/<group>", methods=["GET"])
@api
@auth
def get_group_keys_view(group):
name = "funnel:" + group + ":keys"
key_members = r.smembers(name)
funnel_list = []
for key in key_members:
funnel = r.hgetall(key)
funnel = {key: float(value) for key, value in funnel.iteritems()}
funnel["name"] = key
funnel_list.append(funnel)
funnel_list.sort(key=lambda x: x["name"])
data = {
"funnel_list": funnel_lis
```
<Overlap Ratio: 0.8639308855291576>

---

--- 289 --
Question ID: e1e4aadfcabe73126029872821aa334d109a995f_5
Original Code:
```
def subplot(times, data, yname="", title="", **kwargs):
  plt.figure(title)

  if len(data.shape) <= 1:
    simpleplot(times, data, yname, title, **kwargs)

  else:
    n_dims = data.shape[1]
    for i in range(n_dims):
      plt.subplot(n_dims * 100 + 11 + i)
      if not i: plt.title(title)
      plt.plot(times, data[:, i], **kwargs)
      ax_id = 'XYZ'[i] if i < 3 else str(i)
      plt.ylabel("%s %s" % (ax_id, yname))

    plt.xlabel("Time (s)")

    if 'label' in kwargs:
      plt.legend()
```


Overlapping Code:
```
="", title="", **kwargs):
plt.figure(title)
if len(data.shape) <= 1:
simpleplot(times, data, yname, title, **kwargs)
else:
n_dims = data.shape[1]
for i in range(n_dims):
plt.subplot(n_dims * 100 + 11 + i)
if not i: plt.title(title)
plt.plot(times, data[:, i], **kwargs)
ax_id = 'XYZ'[i] if i < 3 else str(i)
plt.ylabel("%s %s" % (ax_id, yname))
plt.xlabel("Time (s)")
if 'label' in kwargs:
plt.legend
```
<Overlap Ratio: 0.9259259259259259>

---

--- 290 --
Question ID: f69263d3923b67987b690c6d3a20e27e2a4ab1f8_10
Original Code:
```
def print_corpus_hard_core_stats(name, corpus):
    if corpus:
        print(name + " corpus stats:")
        print("\t#documents: {}".format(len(corpus)))
        print("\t#relations total: {}".format(sum(1 for r in corpus.relations())))
        print("\t#relations prot<-->loc: {}".format(sum(1 for r in corpus.relations() if r.class_id == REL_PRO_LOC_ID)))
        entity_counter = Counter()
        for e in corpus.entities():
            entity_counter.update([e.class_id])
        print("\t#entities: {}".format(entity_counter))

        print_corpus_pipeline_dependent_stats(corpus)
        print()
```


Overlapping Code:
```
s):
if corpus:
print(name + " corpus stats:")
print("\t#documents: {}".format(len(corpus)))
print("\t#relations total: {}".format(sum(1 for r in corpus.relations())))
print("\t#relations prot<-->loc: {}".format(sum(1 for r in corpus.relations() if r.class_id == REL_PRO_LOC_ID)))
entity_counter = Counter()
for e in corpus.entities():
entity_counter.update([e.class_id])
print("\t#entities: {}".format(entity_counter))
print_corpus_pipeline_dependent
```
<Overlap Ratio: 0.872093023255814>

---

--- 291 --
Question ID: be19f4904518e5c80c7c9ea979874478eee09450_1
Original Code:
```
@contextmanager
def tag(name):
    print('<%s>' % name)
    yield
    print('<%s>' % name)
```


Overlapping Code:
```
ontextmanager
def tag(name):
print('<%s>' % name)
yield
print('<%s>' % nam
```
<Overlap Ratio: 0.9487179487179487>

---

--- 292 --
Question ID: 883fd770cf1b721f8587c98d92695243f28f299c_12
Original Code:
```
def print_info(msg):
    """ print an informational message
        msg can contain newlines if needed.
    """
    lines = msg.split("\n")
    click.secho("INFO: " + ("\n      ".join(lines)), fg='white')
```


Overlapping Code:
```
" print an informational message
msg can contain newlines if needed.
"""
lines = msg.split("\n")
click.secho("INFO: " + ("\n ".join(lines)), fg='white
```
<Overlap Ratio: 0.8571428571428571>

---

--- 293 --
Question ID: 50ef350828166416e539b0ff90cc3d638a2d1f7f_1
Original Code:
```
def romanToDecimal(str): 
    res = 0
    i = 0
  
    while (i < len(str)): 
  
        # Getting value of symbol s[i] 
        s1 = value(str[i]) 
  
        if (i+1 < len(str)): 
  
            # Getting value of symbol s[i+1] 
            s2 = value(str[i+1]) 
  
            # Comparing both values 
            if (s1 >= s2): 
  
                # Value of current symbol is greater 
                # or equal to the next symbol 
                res = res + s1 
                i = i + 1
            else: 
  
                # Value of current symbol is greater 
                # or equal to the next symbol 
                res = res + s2 - s1 
                i = i + 2
        else: 
            res = res + s1 
            i = i + 1
  
    return res 
```


Overlapping Code:
```
res = 0
i = 0

while (i < len(str)): 

# Getting value of symbol s[i] 
s1 = value(str[i]) 

if (i+1 < len(str)): 

# Getting value of symbol s[i+1] 
s2 = value(str[i+1]) 

# Comparing both values 
if (s1 >= s2): 

# Value of current symbol is greater 
# or equal to the next symbol 
res = res + s1 
i = i + 1
else: 

# Value of current symbol is greater 
# or equal to the next symbol 
res = res + s2 - s1 
i = i + 2
else: 
res = res + s1 
i = i + 1

```
<Overlap Ratio: 0.9240246406570842>

---

--- 294 --
Question ID: 1d89b6df211725a48f7b96e7298f589dcff16ee0_1
Original Code:
```
def test_hyperparameters():
    hp = hp_module.HyperParameters()
    assert hp.values == {}
    assert hp.space == []
    hp.Choice('choice', [1, 2, 3], default=2)
    assert hp.values == {'choice': 2}
    assert len(hp.space) == 1
    assert hp.space[0].name == 'choice'
    hp.values['choice'] = 3
    assert hp.get('choice') == 3
    hp = hp.copy()
    assert hp.values == {'choice': 3}
    assert len(hp.space) == 1
    assert hp.space[0].name == 'choice'
    with pytest.raises(ValueError, match='Unknown parameter'):
        hp.get('wrong')
```


Overlapping Code:
```
st_hyperparameters():
hp = hp_module.HyperParameters()
assert hp.values == {}
assert hp.space == []
hp.Choice('choice', [1, 2, 3], default=2)
assert hp.values == {'choice': 2}
assert len(hp.space) == 1
assert hp.space[0].name == 'choice'
hp.values['choice'] = 3
assert hp.get('choice') == 3
hp = hp.copy()
assert hp.values == {'choice': 3}
assert len(hp.space) == 1
assert hp.space[0].name == 'choice'
with pytest.raises(ValueError, match='Unknown parameter'):
hp.get('wrong
```
<Overlap Ratio: 0.983402489626556>

---

--- 295 --
Question ID: cce51bea0a99f09e95c89c72fa2f703a2e0a2965_1
Original Code:
```
def lis_size_dp(
        node: Optional[TabulatedNode] = None,
        parent_selected: Optional[bool] = None
) -> int:
    """
    We add extra params to node for tabulation
    """
    if node is None:
        return 0

    if node.left is None and node.right is None:
        if node.max_inc is None:
            node.max_inc = 1
            node.max_exc = 0

        return node.max_exc if parent_selected else node.max_inc

    if not parent_selected:
        if node.max_inc is None:
            node.max_inc = 1 + lis_size_dp(node.left, True) + lis_size_dp(node.right, True)

    if node.max_exc is None:
        node.max_exc = lis_size_dp(node.left, False) + lis_size_dp(node.right, False)

    return max(node.max_inc or 0, node.max_exc or 0)
```


Overlapping Code:
```
al[TabulatedNode] = None,
parent_selected: Optional[bool] = None
) -> int:
"""
We add extra params to node for tabulation
"""
if node is None:
return 0
if node.left is None and node.right is None:
if node.max_inc is None:
node.max_inc = 1
node.max_exc = 0
return node.max_exc if parent_selected else node.max_inc
if not parent_selected:
if node.max_inc is None:
node.max_inc = 1 + lis_size_dp(node.left, True) + lis_size_dp(node.right, True)
if node.max_exc is None:
node.max_exc = lis_size_dp(node.left, False) + lis_size_dp(node.right, False)
retur
```
<Overlap Ratio: 0.8842443729903537>

---

--- 296 --
Question ID: 37ecb653e7dc18e4874f32e50d6088abb2d7098f_0
Original Code:
```
def read_gff(
        file: str,
        as_dict: bool = False) \
        -> Union[List[GffFeature], Dict[str, GffFeature]]:
    """
    Args:
        file: path-like
            The input GFF file

        as_dict:
            If True, returns a dictionary

    Returns: list of GffFeature objects, or dict

        [GffFeature_1, GffFeature_2, ...]

        or

        {
            seqid_1: [GffFeature_1, ...],
            seqid_2: [GffFeature_2, ...], ...
        }
    """
    with GffParser(file) as parser:
        features = [feature for feature in parser]
    if as_dict:
        D = {}
        for f in features:
            D.setdefault(f.seqid, [])
            D[f.seqid].append(f)
        return D
    return features
```


Overlapping Code:
```
f(
file: str,
as_dict: bool = False) \
-> Union[List[GffFeature], Dict[str, GffFeature]]:
"""
Args:
file: path-like
The input GFF file
as_dict:
If True, returns a dictionary
Returns: list of GffFeature objects, or dict
[GffFeature_1, GffFeature_2, ...]
or
{
seqid_1: [GffFeature_1, ...],
seqid_2: [GffFeature_2, ...], ...
}
"""
with GffParser(file) as parser:
features = [feature for feature in parser]
if as_dict:
D = {}
for f in features:
D.setdefault(f.seqid, [])
D[f.seqid].append(f)
return D
ret
```
<Overlap Ratio: 0.9560229445506692>

---

--- 297 --
Question ID: c9ccfa6cc05bdb10070b423d52ff71781850cfa4_2
Original Code:
```
def _get_cdl_info(cdlpoint, vals, names, colors):

    tval = ee.Number(cdlpoint.get('CDL'))
    valindx = vals.indexOf(tval)

    return cdlpoint.set('CDL_NAME', ee.String(names.get(valindx)),
                        'CDL_COLOR', ee.String(colors.get(valindx)))
```


Overlapping Code:
```
ames, colors):
tval = ee.Number(cdlpoint.get('CDL'))
valindx = vals.indexOf(tval)
return cdlpoint.set('CDL_NAME', ee.String(names.get(valindx)),
'CDL_
```
<Overlap Ratio: 0.6696428571428571>

---

--- 298 --
Question ID: 123219954cd02311e9672fcd03228d2819d24348_3
Original Code:
```
def process_doc_file(code_file, add_new_line=True):
    """
    Process given file.

    Args:
        code_file (`str` or `os.PathLike`): The file in which we want to style the docstring.
    """
    with open(code_file, "r", encoding="utf-8", newline="\n") as f:
        code = f.read()

    # fmt: off
    splits = code.split("```")
    splits = [s if i % 2 == 0 else process_code_block(s, add_new_line=add_new_line) for i, s in enumerate(splits)]
    clean_code = "```".join(splits)
    # fmt: on

    diff = clean_code != code
    if diff:
        print(f"Overwriting content of {code_file}.")
        with open(code_file, "w", encoding="utf-8", newline="\n") as f:
            f.write(clean_code)
```


Overlapping Code:
```
de_file, add_new_line=True):
"""
Process given file.
Args:
code_file (`str` or `os.PathLike`): The file in which we want to style the docstring.
"""
with open(code_file, "r", encoding="utf-8", newline="\n") as f:
code = f.read()
# fmt: off
splits = code.split("```")
splits = [s if i % 2 == 0 else process_code_block(s, add_new_line=add_new_line) for i, s in enumerate(splits)]
clean_code = "```".join(splits)
# fmt: on
diff = clean_code != code
if diff:
print(f"Overwriting content of {code_file}.")
with open(code_file, "w", encoding="utf-8", newline="\n") as f:
f.write(c
```
<Overlap Ratio: 0.9456342668863262>

---

--- 299 --
Question ID: 283865c160ca3ad33e48b27b7d1a9bd2f8f0584b_0
Original Code:
```
def vectorize_count(corpus: List[List[str]], labels: List[str] = None):
    """ Met un corpus sous une forme vectorisée. """
    corpus = map(lambda d: " ".join(d), corpus)
    vectorizer = CountVectorizer()
    if labels == []:
        return vectorizer.transform(corpus)
    else:
        return vectorizer.fit_transform(corpus, labels)
```


Overlapping Code:
```
st[str]], labels: List[str] = None):
""" Met un corpus sous une forme vectorisée. """
corpus = map(lambda d: " ".join(d), corpus)
vectorizer = CountVectorizer()
if labels == []:
return vectorizer.transform(corpus)
else:
return vectorizer.fit_transform(corpus, labe
```
<Overlap Ratio: 0.8741721854304636>

---

--- 300 --
Question ID: 93c02bf2c69318452dd7ebff355916cd25c30b4e_3
Original Code:
```
def create_main_window(settings):
    sg.theme(settings['theme'])
    menu_def = [['&Menu', ['&Settings', 'E&xit']],
                ['&Help', '&About...']]

    right_click_menu = ['Unused', ['&Copy', '&Paste','Settings', 'E&xit']]

    layout =  [[sg.Menu(menu_def)],
               [sg.Image('enc.png'),sg.Text('Encrypt and decrypt files', size=[21, 1]), sg.Button('', key='paypal', size=(12,1), font=('Helvetica', 9), button_color=(sg.theme_background_color(), sg.theme_background_color()),
                           image_filename='paypal.png', image_size=(80, 50), image_subsample=2, border_width=0),
                 sg.Button('', key='bitcoin', size=(12,1), font=('Helvetica', 9), button_color=(sg.theme_background_color(), sg.theme_background_color()),
                           image_filename='bitcoin.png', image_size=(80, 60), image_subsample=2, border_width=0)],         
               [sg.Output(size=(60, 20), key='out')],
               [sg.Text('Password',size=(10,1)),sg.In(size=(49,1), key=('pass'))],
               [sg.Text('Select file', size=(10,1)),sg.In(size=(40, 1),key='-in-'), sg.FileBrowse()],
               [sg.Button('Encrypt'), sg.Button('Decrypt')]]

    return sg.Window('Crypter', default_element_size=(11, 2)).Layout(layout)      
```


Overlapping Code:
```
f create_main_window(settings):
sg.theme(settings['theme'])
menu_def = [['&Menu', ['&Settings', 'E&xit']],
['&Help', '&About...']]
right_click_menu = ['Unused', ['&Copy', '&Paste','Settings', 'E&xit']]
layout = [[sg.Menu(menu_def)],
[sg.Image('enc.png'),sg.Text('Encrypt and decrypt files', size=[21, 1]), sg.Button('', key='paypal', size=(12,1), font=('Helvetica', 9), button_color=(sg.theme_background_color(), sg.theme_background_color()),
image_filename='paypal.png', image_size=(80, 50), image_subsample=2, border_width=0),
sg.Button('', key='bitcoin', size=(12,1), font=('Helvetica', 9), button_color=(sg.theme_background_color(), sg.theme_background_color()),
image_filename='bitcoin.png', image_size=(80, 60), image_subsample=2, border_width=0)], 
[sg.Output(size=(60, 20), key='out')],
[sg.Text('Password',size=(10,1)),sg.In(size=(49,1), key=('pass'))],
[sg.Text('Select file', size=(10,1)),sg.In(size=(40, 1),key='-in-'), sg.FileBrowse()],
[sg.Button('Encrypt'), sg.Button('Decrypt')]]
return sg.Window('Crypter', 
```
<Overlap Ratio: 0.9570093457943926>

---

--- 301 --
Question ID: e67257aa98a4bba4ba858bd41a94c1f1d29ccfa2_3
Original Code:
```
def _serialize_allocations_for_resource_provider(allocations,
                                                 resource_provider):
    """Turn a list of allocations into a dict by consumer id.

    {'resource_provider_generation': GENERATION,
     'allocations':
       CONSUMER_ID_1: {
           'resources': {
              'DISK_GB': 4,
              'VCPU': 2
           }
       },
       CONSUMER_ID_2: {
           'resources': {
              'DISK_GB': 6,
              'VCPU': 3
           }
       }
    }
    """
    return _allocations_dict(allocations, lambda x: x.consumer_id,
                             resource_provider=resource_provider)
```


Overlapping Code:
```
e_allocations_for_resource_provider(allocations,
resource_provider):
"""Turn a list of allocations into a dict by consumer id.
{'resource_provider_generation': GENERATION,
'allocations':
CONSUMER_ID_1: {
'resources': {
'DISK_GB': 4,
'VCPU': 2
}
},
CONSUMER_ID_2: {
'resources': {
'DISK_GB': 6,
'VCPU': 3
}
}
}
"""
return _allocations_dict(allocations, lambda x: x.consumer_id,
resource_provider=resource_pro
```
<Overlap Ratio: 0.9553990610328639>

---

--- 302 --
Question ID: f4c3efeb6c030da5e3f6ad1c5681b47b79e8136e_2
Original Code:
```
def check_filter(filt):
    """\
    Check that the low value of the filter is lower than the high.
    If there is to be no filter, return 'None'.

        >>> check_filter(())
        >>> check_filter(False)
        >>> check_filter(None)
        >>> check_filter([(6, 7)])
        [(6.0, 7.0)]
        >>> check_filter([(6, 7), (2, 8)])
        [(6.0, 7.0), (2.0, 8.0)]
        >>> try:
        ...    check_filter([(7, 2)])
        ... except ValueError as e:
        ...    print(e)
        Error in --filter: low >= high

    """
    # Quick return if no filter.
    if not filt:
        return None
    try:
        return [range_check(f[0], f[1]) for f in filt]
    except ValueError as a:
        raise ValueError('Error in --filter: '+py23_str(a))
```


Overlapping Code:
```
low value of the filter is lower than the high.
If there is to be no filter, return 'None'.
>>> check_filter(())
>>> check_filter(False)
>>> check_filter(None)
>>> check_filter([(6, 7)])
[(6.0, 7.0)]
>>> check_filter([(6, 7), (2, 8)])
[(6.0, 7.0), (2.0, 8.0)]
>>> try:
... check_filter([(7, 2)])
... except ValueError as e:
... print(e)
Error in --filter: low >= high
"""
# Quick return if no filter.
if not filt:
return None
try:
return [range_check(f[0], f[1]) for f in filt]
except ValueError as a:
raise ValueError('Error in --filter: '+py23_str(a))
```
<Overlap Ratio: 0.9262981574539364>

---

--- 303 --
Question ID: 83580f3439dcb18afd5e21eaeff7665a7ba78a05_0
Original Code:
```
def into_ranked_dataframe(similar_from_docvec):
	    """ Takes the output of doc2vec most_similar and puts it into
	    a dataframe thats nice to work with """
	    tmp = pd.DataFrame(similar_from_docvec,columns = ['product_label','sim_score'])
	    tmp['rank'] = tmp.index
	    tmp['name'] = tmp['product_label'].apply(lambda r: label_decoder[r])
	    
	    return tmp[['name','rank']].set_index('name')
```


Overlapping Code:
```
ilar_from_docvec):
""" Takes the output of doc2vec most_similar and puts it into
a dataframe thats nice to work with """
tmp = pd.DataFrame(similar_from_docvec,columns = ['product_label','sim_score'])
tmp['rank'] = tmp.index
tmp['name'] = tmp['product_label'].apply(lambda r: label_decoder[r])

return tmp[['name','rank']].set_index('name'
```
<Overlap Ratio: 0.9186991869918699>

---

--- 304 --
Question ID: d3173e58d9c4fc4a3d60c9d3f2b08b6f207ad48b_1
Original Code:
```
def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_project_SNo'), table_name='project')
    op.drop_table('project')
    op.drop_index(op.f('ix_student_SNo'), table_name='student')
    op.drop_index(op.f('ix_student_Avatar'), table_name='student')
    op.drop_table('student')
    op.drop_table('admin')
```


Overlapping Code:
```
def downgrade():
# ### commands auto generated by Alembic - please adjust! ###
op.drop_index(op.f('ix_project_SNo'), table_name='project')
op.drop_table('project')
op.drop_index(op.f('ix_student_SNo'), table_name='student')
op.drop_index(op.f('ix_student_Avatar'), table_name='student')
op.drop_table('student')
op.drop
```
<Overlap Ratio: 0.9550898203592815>

---

--- 305 --
Question ID: 3135c1e1a3915c263f59be5108d17d06e3a4d782_15
Original Code:
```
def main():
    from pprint import pformat
    from textwrap import indent
    for name in globals():
        if name.startswith('somefunc_'):
            print("\n{}():".format(name))
            print(indent(pformat(globals()[name]()), ' '*4))
```


Overlapping Code:
```

from pprint import pformat
from textwrap import indent
for name in globals():
if name.startswith('somefunc_'):
print("\n{}():".format(name))
print(in
```
<Overlap Ratio: 0.746268656716418>

---

--- 306 --
Question ID: 3915d19ecd09e5ec36b6ebd18aaee67a5effccd6_12
Original Code:
```
def rename_pipeline(repo_dir):
    nimbusml_path = os.path.join(repo_dir, 'src', 'python', 'nimbusml')
    os.rename(os.path.join(nimbusml_path, 'pipeline.py'),
              os.path.join(nimbusml_path, '_pipeline.py'))

    replace_file_contents(os.path.join(nimbusml_path, '__init__.py'),
                          'from .pipeline import Pipeline',
                          'from ._pipeline import Pipeline')

    replace_file_contents(os.path.join(nimbusml_path, '__init__.py.in'),
                          'from .pipeline import Pipeline',
                          'from ._pipeline import Pipeline')

    replace_file_contents(os.path.join(repo_dir, 'src', 'python', 'nimbusml.pyproj'),
                          r'nimbusml\pipeline.py',
                          r'nimbusml\_pipeline.py')

    replace_file_contents(os.path.join(nimbusml_path, 'tests', 'test_syntax_expected_failures.py'),
                          'from nimbusml.pipeline import TrainedWarning',
                          'from nimbusml._pipeline import TrainedWarning')
```


Overlapping Code:
```
dir):
nimbusml_path = os.path.join(repo_dir, 'src', 'python', 'nimbusml')
os.rename(os.path.join(nimbusml_path, 'pipeline.py'),
os.path.join(nimbusml_path, '_pipeline.py'))
replace_file_contents(os.path.join(nimbusml_path, '__init__.py'),
'from .pipeline import Pipeline',
'from ._pipeline import Pipeline')
replace_file_contents(os.path.join(nimbusml_path, '__init__.py.in'),
'from .pipeline import Pipeline',
'from ._pipeline import Pipeline')
replace_file_contents(os.path.join(repo_dir, 'src', 'python', 'nimbusml.pyproj'),
r'nimbusml\pipeline.py',
r'nimbusml\_pipeline.py')
replace_file_contents(os.path.join(nimbusml_path, 'tests', 'test_syntax_expected_failures.py'),
'from nimbusml.pipeline import TrainedWarning',
'from nimbusml._pipeline im
```
<Overlap Ratio: 0.9422110552763819>

---

--- 307 --
Question ID: 494506121809d3d96d257bf22d7ebd5a197aa68b_1
Original Code:
```
def first3(set):
    p = newPoint()
    while (p == set[0]):
        p = newPoint()
    set.append(p)
    p = newPoint()
    while(p == set[0] or p == set[1]):
        p = newPoint()
    set.append(p)
    find_max_min(set)
```


Overlapping Code:
```
le (p == set[0]):
p = newPoint()
set.append(p)
p = newPoint()
while(p == set[0] or p == set[1]):
p =
```
<Overlap Ratio: 0.5617977528089888>

---

--- 308 --
Question ID: 1a13cf7618edfa809c49c12f9e0aff8d2793bc88_1
Original Code:
```
def get_mysql_client(cluster, port):
    start_time = time.monotonic()
    while True:
        try:
            return pymysql.connections.Connection(
                host=cluster.get_instance_ip("instance"),
                user="default",
                password="",
                database="default",
                port=port,
            )
        except pymysql.err.OperationalError:
            if time.monotonic() - start_time > 10:
                raise
            time.sleep(0.1)
```


Overlapping Code:
```
lient(cluster, port):
start_time = time.monotonic()
while True:
try:
return pymysql.connections.Connection(
host=cluster.get_instance_ip("instance"),
user="default",
password="",
database="default",
port=port,
)
except pymysql.err.OperationalError:
if time.monotonic() - start_time > 10:
raise
time.s
```
<Overlap Ratio: 0.9259259259259259>

---

--- 309 --
Question ID: ea4c7ee38e4a21fc55b49f9830f4daed3671176e_15
Original Code:
```
@timer
def get_train_ds(batch_size=128,shuffle=True,distort=True,distort_fn=None):
    train_ds = get_tf_dataset_in_batches('train', batch_size, shuffle,distort,distort_fn)
    return train_ds
```


Overlapping Code:
```
imer
def get_train_ds(batch_size=128,shuffle=True,distort=True,distort_fn=None):
train_ds = get_tf_dataset_in_batches('train', batch_size, shuffle,dis
```
<Overlap Ratio: 0.8152173913043478>

---

--- 310 --
Question ID: 82eeed4b8211d175a42bfc7fd9fda14a1a7bf571_2
Original Code:
```
def problemThree():
    '''
    Plot y = x^2 * sin(x) using 1000 data points and x in [0,100]
    '''
    raise NotImplementedError("Problem 3 not implemented.")
```


Overlapping Code:
```
):
'''
Plot y = x^2 * sin(x) using 1000 data points and x in [0,100]
'''
raise NotImplementedError("Problem 3 not impleme
```
<Overlap Ratio: 0.8344827586206897>

---

--- 311 --
Question ID: d4afc171f6f5a693605ad970fb580faa87a94269_4
Original Code:
```
def _tansfocator_guess_focal_position( s_target, p=5960., q=3800.0, sigmaz=6.46e-4, \
                                      alpha=0.66, lens_diameter=0.05, method=2):
    x = 1e15
    if method == 1: # simple sum
        AA = 2.35*sigmaz/p
        BB = -(s_target + alpha * lens_diameter)
        CC = alpha*lens_diameter*q

        cc = numpy.roots([AA,BB,CC])
        x = cc[1]
        return x

    if method == 2: # sum in quadrature
        AA = ( (2.35*sigmaz)**2)/(p**2)
        BB = 0.0
        CC = alpha**2 * lens_diameter**2 - s_target**2
        DD = - 2.0 * alpha**2 * lens_diameter**2 * q
        EE = alpha**2 * lens_diameter**2 * q**2
        cc = numpy.roots([AA,BB,CC,DD,EE])
        for i,cci in enumerate(cc):
            if numpy.imag(cci) == 0:
                return numpy.real(cci)

    return x
```


Overlapping Code:
```
cal_position( s_target, p=5960., q=3800.0, sigmaz=6.46e-4, \
alpha=0.66, lens_diameter=0.05, method=2):
x = 1e15
if method == 1: # simple sum
AA = 2.35*sigmaz/p
BB = -(s_target + alpha * lens_diameter)
CC = alpha*lens_diameter*q
cc = numpy.roots([AA,BB,CC])
x = cc[1]
return x
if method == 2: # sum in quadrature
AA = ( (2.35*sigmaz)**2)/(p**2)
BB = 0.0
CC = alpha**2 * lens_diameter**2 - s_target**2
DD = - 2.0 * alpha**2 * lens_diameter**2 * q
EE = alpha**2 * lens_diameter**2 * q**2
cc = numpy.roots([AA,BB,CC,DD,EE])
for i,cci in enumerate(cc):
if numpy.imag(cci) == 0:
return numpy.real(cci)
ret
```
<Overlap Ratio: 0.9523809523809523>

---

--- 312 --
Question ID: df89b374617f742546d6eb7e0fd0ae663bedfddc_1
Original Code:
```
def load_data(dataset_name, directory_name):
    """
    Load data in JSON format into memory
    :param dataset_name: input dataset name
    :param directory_name: input directory name
    :return:
    """
    filepath = os.path.join(directory_name, 'reviews_%s_5.json' % dataset_name)
    if not os.path.exists(filepath):
        download_data(dataset_name, directory_name)
    data = []
    with open(filepath, 'r') as f:
        for line in f:                            # read file line by line
            item_hash = hash(line)                # we will use this later for partitioning our data
            item = json.loads(line)               # convert JSON string to Python dict
            item['hash'] = item_hash              # add hash for identification purposes
            data.append(item)
    print("Loaded %d data for dataset %s" % (len(data), dataset_name))
    return data
```


Overlapping Code:
```
, directory_name):
"""
Load data in JSON format into memory
:param dataset_name: input dataset name
:param directory_name: input directory name
:return:
"""
filepath = os.path.join(directory_name, 'reviews_%s_5.json' % dataset_name)
if not os.path.exists(filepath):
download_data(dataset_name, directory_name)
data = []
with open(filepath, 'r') as f:
for line in f: # read file line by line
item_hash = hash(line) # we will use this later for partitioning our data
item = json.loads(line) # convert JSON string to Python dict
item['hash'] = item_hash # add hash for identification purposes
data.append(item)
print("Loaded %d data for dataset %s" % (len(data), dataset_name))
return dat
```
<Overlap Ratio: 0.9620786516853933>

---

--- 313 --
Question ID: 82fab4db8212cd5e2b9dea5cb431264ab8ebba9e_1
Original Code:
```
def test_mnist():
    import tensorflow as tf
    import tensorflow.examples.tutorials.mnist.input_data as input_data
    import matplotlib.pyplot as plt

    # %%
    # load MNIST as before
    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)
    mean_img = np.mean(mnist.train.images, axis=0)
    ae = autoencoder(dimensions=[784, 256, 64])

    # %%
    learning_rate = 0.001
    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(ae['cost'])

    # %%
    # We create a session to use the graph
    sess = tf.Session()
    sess.run(tf.initialize_all_variables())

    # %%
    # Fit all training data
    batch_size = 50
    n_epochs = 10
    for epoch_i in range(n_epochs):
        for batch_i in range(mnist.train.num_examples // batch_size):
            batch_xs, _ = mnist.train.next_batch(batch_size)
            train = np.array([img - mean_img for img in batch_xs])
            sess.run(optimizer, feed_dict={
                ae['x']: train, ae['corrupt_prob']: [1.0]})
        print(epoch_i, sess.run(ae['cost'], feed_dict={
            ae['x']: train, ae['corrupt_prob']: [1.0]}))

    # %%
    # Plot example reconstructions
    n_examples = 15
    test_xs, _ = mnist.test.next_batch(n_examples)
    test_xs_norm = np.array([img - mean_img for img in test_xs])
    recon = sess.run(ae['y'], feed_dict={
        ae['x']: test_xs_norm, ae['corrupt_prob']: [0.0]})
    fig, axs = plt.subplots(2, n_examples, figsize=(10, 2))
    for example_i in range(n_examples):
        axs[0][example_i].imshow(
            np.reshape(test_xs[example_i, :], (28, 28)))
        axs[1][example_i].imshow(
            np.reshape([recon[example_i, :] + mean_img], (28, 28)))
    fig.show()
    plt.draw()
    plt.waitforbuttonpress()
```


Overlapping Code:
```
mnist():
import tensorflow as tf
import tensorflow.examples.tutorials.mnist.input_data as input_data
import matplotlib.pyplot as plt
# %%
# load MNIST as before
mnist = input_data.read_data_sets('MNIST_data', one_hot=True)
mean_img = np.mean(mnist.train.images, axis=0)
ae = autoencoder(dimensions=[784, 256, 64])
# %%
learning_rate = 0.001
optimizer = tf.train.AdamOptimizer(learning_rate).minimize(ae['cost'])
# %%
# We create a session to use the graph
sess = tf.Session()
sess.run(tf.initialize_all_variables())
# %%
# Fit all training data
batch_size = 50
n_epochs = 10
for epoch_i in range(n_epochs):
for batch_i in range(mnist.train.num_examples // batch_size):
batch_xs, _ = mnist.train.next_batch(batch_size)
train = np.array([img - mean_img for img in batch_xs])
sess.run(optimizer, feed_dict={
ae['x']: train, ae['corrupt_prob']: [1.0]})
print(epoch_i, sess.run(ae['cost'], feed_dict={
ae['x']: train, ae['corrupt_prob']: [1.0]}))
# %%
# Plot example reconstructions
n_examples = 15
test_xs, _ = mnist.test.next_batch(n_examples)
test_xs_norm = np.array([img - mean_img for img in test_xs])
recon = sess.run(ae['y'], feed_dict={
ae['x']: test_xs_norm, ae['corrupt_prob']: [0.0]})
fig, axs = plt.subplots(2, n_examples, figsize=(10, 2))
for example_i in range(n_examples):
axs[0][example_i].imshow(
np.reshape(test_xs[example_i, :], (28, 28)))
axs[1][example_i].imshow(
np.reshape([recon[example_i, :] + mean_img], (28, 28)))
fig.show()
plt.draw()
plt.waitforbuttonpres
```
<Overlap Ratio: 0.9919517102615694>

---

--- 314 --
Question ID: c7b0744f4bc08d8ca77ed8c47d0ef8df25fa0f57_4
Original Code:
```
def test_get_sorted_primes_list():
    # arrange
    from src.common.primes import get_sorted_primes_list

    # act
    actual_result = get_sorted_primes_list(100)

    # assert
    expected_result = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97]
    assert actual_result == expected_result
```


Overlapping Code:
```
_primes_list():
# arrange
from src.common.primes import get_sorted_primes_list
# act
actual_result = get_sorted_primes_list(100)
# assert
expected_result = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97]
```
<Overlap Ratio: 0.8102893890675241>

---

--- 315 --
Question ID: 8a092e39c20dbb0581f46701185c3e55faf9e460_1
Original Code:
```
@wvtest
def booga2():
    # ensure tests run in the order they were declared
    global last
    WVPASSEQ(last, 'test1')
    last='booga2'
```


Overlapping Code:
```
ure tests run in the order they were declared
global last
WVPASSEQ(la
```
<Overlap Ratio: 0.5655737704918032>

---

--- 316 --
Question ID: a4afb473731ae1947c4e12f7622e1506d4b79c12_1
Original Code:
```
@route('/stop', method='POST')
def stop():
    #global stop_variable
    #stop_variable = request.forms.get('submit')
    #stop_variable = True
    #print(stop_variable)
    button_pressed.put(1)
    print(button_pressed)
    return "stopped"
```


Overlapping Code:
```
l stop_variable
#stop_variable = request.forms.get('submit')
#stop_variable = True
#print(stop_variable)
button_pressed.put(1)
print(button_pressed)
r
```
<Overlap Ratio: 0.7009345794392523>

---

--- 317 --
Question ID: a27b763f8eed3d166bd5de2f343e2225f312b1cc_5
Original Code:
```
def SetClient(ip, port):
	address = (ip, port)
	sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # sock = socket.socket()  
	sock.connect(address) 
	return sock
```


Overlapping Code:
```
 = (ip, port)
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # sock = socket.socket() 
sock.connect(addres
```
<Overlap Ratio: 0.7116564417177914>

---

--- 318 --
Question ID: 5e4b90fe411751f3e5ee9d027575bcbed4bd649d_4
Original Code:
```
def es_cadena_valida(adn):
    """
    (str)-> boolean

    >>> es_cadena_valida("ACT")
    True
    >>> es_cadena_valida("XYZ")
    False
    >>> es_cadena_valida("TSG")
    False

    Valida si una cadena es valida o no

    :param adn: String La cadena ingresada a evaluar
    :return: retorna Boolean TRUE si la cadena es valida o FLASE si es incorrecta
    """
    for caracter in adn:
        if not es_base(caracter):
            return False
    return True
```


Overlapping Code:
```
>>> es_cadena_valida("ACT")
True
>>> es_cadena_valida("XYZ")
False
>>> es_cadena_valida("TSG")
False
Valida si una cadena es valida o no
:param adn: String La cadena ingresada a evaluar
:return: retorna Boolean TRUE si la cadena es valida o FLASE si es incorrecta
"""
for caracter in adn:
if not es_b
```
<Overlap Ratio: 0.7772020725388601>

---

--- 319 --
Question ID: 82fc8a6d44773a0bb7cf9d500ff474d661a9467d_7
Original Code:
```
def get_metrics(run_id):
    with open_connection() as conn:
        with conn.cursor() as cursor:
            cursor.execute(
                f"SELECT win_rate, win_rate_random, win_rate_expert_policy, average_reward FROM \
                cards.metrics \
                WHERE run_id = '{run_id}' \
                ORDER BY id ASC ;"
            )
            result = cursor.fetchall()

    df = pd.DataFrame(result, columns=['win_rate', 'win_rate_random', 'win_rate_expert_policy', 'average_reward'])
    return df
```


Overlapping Code:
```
_id):
with open_connection() as conn:
with conn.cursor() as cursor:
cursor.execute(
f"SELECT win_rate, win_rate_random, win_rate_expert_policy, average_reward FROM \
cards.metrics \
WHERE run_id = '{run_id}' \
ORDER BY id ASC ;"
)
result = cursor.fetchall()
df = pd.DataFrame(result, columns=['win_rate', 'win_rate_random', 'win_rate_expert_policy', 'average_reward'])

```
<Overlap Ratio: 0.929471032745592>

---

--- 320 --
Question ID: ffb730bdd67eaf23b5b0bbb1c04b7882c8c15722_0
Original Code:
```
@pytest.mark.parametrize(
    "vstr,major,minor,pyenv",
    [
        ("3.0", 3, 0, "py30"),
        ("3.6", 3, 6, "py36"),
        ("3.10", 3, 10, "py310"),
    ],
)
def test_pyversion(vstr: str, major: int, minor: int, pyenv: str) -> None:
    v = PyVersion.parse(vstr)
    assert v == vstr
    assert str(v) == vstr
    assert repr(v) == f"PyVersion({vstr!r})"
    assert v.major == major
    assert v.minor == minor
    assert v.pyenv == pyenv
    assert PyVersion.construct(major, minor) == v
    assert json.dumps(v) == f'"{vstr}"'
```


Overlapping Code:
```
r,major,minor,pyenv",
[
("3.0", 3, 0, "py30"),
("3.6", 3, 6, "py36"),
("3.10", 3, 10, "py310"),
],
)
def test_pyversion(vstr: str, major: int, minor: int, pyenv: str) -> None:
v = PyVersion.parse(vstr)
assert v == vstr
assert str(v) == vstr
assert repr(v) == f"PyVersion({vstr!r})"
assert v.major == major
assert v.minor == minor
assert v.pyenv == pyenv
assert PyVersion.construct(major, minor) == v
assert json.dumps(v
```
<Overlap Ratio: 0.9010752688172043>

---

--- 321 --
Question ID: f114f80f70c62e5d9633744cc3ff9756e5ebf407_2
Original Code:
```
def test_modern_signin(user_signin, user_signup, user_create, user_model):

    user = user_create(attributes={'email': 'user@host.com'})
    user.delete()

    # login with wrong credentials
    response = user_signin(user, {'username': 'nobody'})
    assert response.status_code == 200
    assert b'Please enter a correct username and password' in response.content

    # create deactivated test user
    response = user_signup(user)
    assert response['location'].endswith(reverse('ok'))

    # inactive user login
    response = user_signin(user)
    assert (
            b'This account is inactive.' in response.content or
            b'Please enter a correct username and password' in response.content)

    # activate user and try to login again
    assert user_model.objects.count() == 1
    user_model.objects.all().update(is_active=True)
    response = user_signin(user)
    assert response['location'].endswith(reverse('ok'))

    # how about to login when user is already signed in?
    response = user_signin(user, client=response.client)
    assert response['location'].endswith(reverse('fail'))

    response.client.logout()

    # more than one user with this e-mail
    user_create(attributes={'email': user.email})
    # user_model.objects.create(username='dummy', )
    response = user_signin(user)

    assert b'There is more than one user with this e-mail.' in response.content
```


Overlapping Code:
```
est_modern_signin(user_signin, user_signup, user_create, user_model):
user = user_create(attributes=rong credentials
response = user_signin(user, {'username': 'nobody'})
assert response.status_code == 200
assert b'Please enter a correct username and password' in response.content
# create deactivated test user
response = user_signup(user)
assert response['location'].endswith(reverse('ok'))
# inactive user login
response = user_signin(user)
assert (
b'This account is inactive.' in response.content or
b'Please enter a correct username and password' in response.content)
# activate user and try to login again
assert user_model.objects.count() == 1
user_model.objects.all().update(is_active=True)
response = user_signin(user)
assert response['location'].endswith(reverse('ok'))
# how about to login when user is already signed in?
response = user_signin(user, client=response.client)
assert response['location'].endswith(reverse('fail'))
response.client.logout()
# more than one user with this e-mail
user_create(attributes={'email': user.email})
# user_model.objects.create(username='dummy', )
response = user_signin(user)
assert b'There is more than one user with this e-mail.' in response.conten
```
<Overlap Ratio: 0.9508716323296355>

---

--- 322 --
Question ID: 9d4e96a7d1b12e5ef876547dd08f519dc7a09dfb_2
Original Code:
```
@api_blu.route('/user/avatar', methods=['POST'])
@login_required
def set_user_avatar():
    """
    0. 判断用户是否登录
    1. 获取到上传的文件
    2. 再将文件上传到七牛云
    3. 将头像信息更新到当前用户的模型中
    4. 返回上传的结果<avatar_url>
    :return:
    """
    # 0. 判断用户是否登录
    user_id = g.user_id
    user = User.query.get(user_id)
    if not user:
        return jsonify(errno=RET.SESSIONERR, errmsg="用户未登录")

    # 1. 获取到上传的文件
    avatar = request.files.get("avatar")
    if not avatar:
        return jsonify(errno=RET.PARAMERR, errmsg="参数不足")

    # 2. 再将文件上传到七牛云
    try:
        avatar_image = storage_image(avatar.read())
    except Exception as e:
        current_app.logger.error(e)
        return jsonify(errno=RET.THIRDERR, errmsg="第三方系统错误")
    if not avatar_image:
        return jsonify(errno=RET.NODATA, errmsg="无数据")

    # 3. 将头像信息更新到当前用户的模型中
    user.avatar_url = avatar_image
    try:
        db.session.commit()
    except Exception as e:
        current_app.logger.error(e)
        db.session.rollback()
        return jsonify(errno=RET.DBERR, errmsg="数据库提交错误")

    # 4. 返回上传的结果<avatar_url>
    avatar_url = constants.QINIU_DOMIN_PREFIX + avatar_image
    data = {
        "avatar_url": avatar_url
    }
    return jsonify(errno=RET.OK, errmsg="成功", data=data)
```


Overlapping Code:
```
blu.route('/user/avatar', methods=['POST'])
@login_required
def set_user_avatar():
"""
0. 判断用户是否登录
1. 获取到上传的文件
2. 再将文件上传到七牛云
3. 将头像信息更新到当前用户的模型中
4. 返回上传的结果<avatar_url>
:return:
"""
# 0. 判断用户是否登录
user_id = g.user_id
user = User.query.get(user_id)
if not user:
return jsonify(errno=RET.SESSIONERR, errmsg="用户未登录")
# 1. 获取到上传的文件
avatar = request.files.get("avatar")
if not avatar:
return jsonify(errno=RET.PARAMERR, errmsg="参数不足")
# 2. 再将文件上传到七牛云
try:
avatar_image = storage_image(avatar.read())
except Exception as e:
current_app.logger.error(e)
return jsonify(errno=RET.THIRDERR, errmsg="第三方系统错误")
if not avatar_image:
return jsonify(errno=RET.NODATA, errmsg="无数据")
# 3. 将头像信息更新到当前用户的模型中
user.avatar_url = avatar_image
try:
db.session.commit()
except Exception as e:
current_app.logger.error(e)
db.session.rollback()
return jsonify(errno=RET.DBERR, errmsg="数据库提交错误")
# 4. 返回上传的结果<avatar_url>
avatar_url = constants.QINIU_DOMIN_PREFIX + avatar_image
data = {
"avatar_url": avatar_url
}
return jsonify(errno=RET.OK, errmsg="成功",
```
<Overlap Ratio: 0.9846301633045149>

---

--- 323 --
Question ID: 5914558481cf63eb4d1cee362a1a4378ed960409_0
Original Code:
```
def init(config_file_path=None, **kwargs):
    '''Init the storage client. Basically, we set the Redis client and connects it
    to the instance/cluster
    '''
    global redis_connection
    global hosts
    # If config_file_path is None we will assume that we only have localhost
    # as storage node
    if config_file_path is None:
        import StringIO as sio
        config_file_handler = sio.StringIO('localhost\n')
    else:
        config_file_handler = open(config_file_path)
    # As accorded in the API standar, this file must contain all the hosts names
    # with no port, one per line
    hosts = [x.strip() for x in config_file_handler.readlines()]
    config_file_handler.close()
    # If we have more than one host then we will assume that our backend is a Redis
    # cluster. If not, we will assume that we are dealing with a Redis standalone
    # instance
    if len(hosts) > 1:
        # Given that cluster clients are capable to perform master
        # slave hierarchy discovery, we will simply connect to the first
        # node we got
        redis_connection = \
        rediscluster.StrictRedisCluster(host=hosts[0], port=REDIS_PORT)
    else:
        # We are in standalone mode
        redis_connection = \
        redis.StrictRedis(host=hosts[0], port=REDIS_PORT)
    # StrictRedis is not capable to know if we had success when connecting by
    # simply calling the constructor. We need to perform an actual query to
    # the backend
    # If we had no success this first line should crash
    redis_connection.set('PYCOMPSS_TEST', 'OK')
    assert redis_connection.get('PYCOMPSS_TEST') == 'OK'
    redis_connection.delete('PYCOMPSS_TEST')
```


Overlapping Code:
```
it(config_file_path=None, **kwargs):
'''Init the storage client. Basically, we set the Redis client and connects it
to the instance/cluster
'''
global redis_connection
global hosts
# If config_file_path is None we will assume that we only have localhost
# as storage node
if config_file_path is None:
import StringIO as sio
config_file_handler = sio.StringIO('localhost\n')
else:
config_file_handler = open(config_file_path)
# As accorded in the API standar, this file must contain all the hosts names
# with no port, one per line
hosts = [x.strip() for x in config_file_handler.readlines()]
config_file_handler.close()
# If we have more than one host then we will assume that our backend is a Redis
# cluster. If not, we will assume that we are dealing with a Redis standalone
# instance
if len(hosts) > 1:
# Given that cluster clients are capable to perform master
# slave hierarchy discovery, we will simply connect to the first
# node we got
redis_connection = \
rediscluster.StrictRedisCluster(host=hosts[0], port=REDIS_PORT)
else:
# We are in standalone mode
redis_connection = \
redis.StrictRedis(host=hosts[0], port=REDIS_PORT)
# StrictRedis is not capable to know if we had success when connecting by
# simply calling the constructor. We need to perform an actual query to
# the backend
# If we had no success this first line should crash
redis_connection.set('PYCOMPSS_TEST', 'OK')
assert redis_connection.get('PYCOMPSS_TEST') == 'OK'
redis
```
<Overlap Ratio: 0.9725016767270288>

---

--- 324 --
Question ID: 646025c823822ad2539e6196ea53af5a519e26bf_1
Original Code:
```
def printList3(movie_list):
    for each_item in movie_list:
        if isinstance(each_item, list):
            for nested_item in each_item:
                if isinstance(nested_item, list):
                    for deeper_item in nested_item:
                        print(deeper_item)
                else:
                    print(nested_item)
        else:
            print(each_item)
```


Overlapping Code:
```
movie_list):
for each_item in movie_list:
if isinstance(each_item, list):
for nested_item in each_item:
if isinstance(nested_item, list):
for deeper_item in nested_item:
print(deeper_item)
else:
print(nested_item)
else:
print(each_item
```
<Overlap Ratio: 0.9362549800796812>

---

--- 325 --
Question ID: 36ae8ad2dc716541867233bc66cd1b2c94d0b099_4
Original Code:
```
def __return_converted_value(value, std_conv_str, conv_coeffs_list, \
                             std_from_unit, std_to_unit, use_gnu=False, print_result=False, debug=False):

    value_converted = 1.0
    if not use_gnu:
        value_converted = value * conv_coeffs_list[std_conv_str]
    else:
        out_gnu_units = sp.check_output(['units','%s %s' % (value, std_from_unit), '%s' % std_to_unit])
        if debug:
            print(out_gnu_units.split())
            print(flag_from_to_units, std_conv_str, std_from_unit, std_to_unit)
        value_converted = float(out_gnu_units.split()[1])

    if print_result:
        print(" %s %s = %e %s" % \
              (value, std_from_unit, value_converted, std_to_unit) )
    
    return value_converted
```


Overlapping Code:
```
__return_converted_value(value, std_conv_str, conv_coeffs_list, \
std_from_unit, std_to_unit, use_gnu=False, print_result=False, debug=False):
value_converted = 1.0
if not use_gnu:
value_converted = value * conv_coeffs_list[std_conv_str]
else:
out_gnu_units = sp.check_output(['units','%s %s' % (value, std_from_unit), '%s' % std_to_unit])
if debug:
print(out_gnu_units.split())
print(flag_from_to_units, std_conv_str, std_from_unit, std_to_unit)
value_converted = float(out_gnu_units.split()[1])
if print_result:
print(" %s %s = %e %s" % \
(value, std_from_unit, value_converted, std
```
<Overlap Ratio: 0.9373996789727127>

---

--- 326 --
Question ID: 16d5224e9fa82f81b7db23062bd2bd0f7a445c86_0
Original Code:
```
@hookimpl(trylast=True)
def pytest_runtest_setup(item: Item) -> None:
    if not isinstance(item, Function):
        return
    # Don't do nose style setup/teardown on direct unittest style classes.
    if isinstance(item, TestCaseFunction):
        return

    # Capture the narrowed type of item for the teardown closure,
    # see https://github.com/python/mypy/issues/2608
    func = item

    if not call_optional(func.obj, "setup"):
        # Call module level setup if there is no object level one.
        assert func.parent is not None
        call_optional(func.parent.obj, "setup")  # type: ignore[attr-defined]

    def teardown_nose() -> None:
        if not call_optional(func.obj, "teardown"):
            assert func.parent is not None
            call_optional(func.parent.obj, "teardown")  # type: ignore[attr-defined]

    # XXX This implies we only call teardown when setup worked.
    func.addfinalizer(teardown_nose)
```


Overlapping Code:
```
t=True)
def pytest_runtest_setup(item: Item) -> None:
if not isinstance(item, Function):
return
# Don't do nose style setup/teardown on direct unittest style classes.
if isinstance(item, TestCaseFunction):
return
# Capture the narrowed type of item for the teardown closure,
# see https://github.com/python/mypy/issues/2608
func = item
if not call_optional(func.obj, "setup"):
# Call module level setup if there is no object level one.
assert func.parent is not None
call_optional(func.parent.obj, "setup") # type: ignore[attr-defined]
def teardown_nose() -> None:
if not call_optional(func.obj, "teardown"):
assert func.parent is not None
call_optional(func.parent.obj, "teardown") # type: ignore[attr-defined]
# XXX This implies we only call teardown when setup worked.
func.addfinalizer(teardown_n
```
<Overlap Ratio: 0.975609756097561>

---

--- 327 --
Question ID: 933bf7c5c64dd27fc2b55de940ce11ee6953ecdb_0
Original Code:
```
def all_paths():
  """Return all paths which are checked in to git."""
  repo_root = os.path.abspath(os.path.join(INFRABOTS_DIR, os.pardir, os.pardir))
  output = subprocess.check_output(['git', 'ls-files'], cwd=repo_root).rstrip()
  return output.splitlines()
```


Overlapping Code:
```
re checked in to git."""
repo_root = os.path.abspath(os.path.join(INFRABOTS_DIR, os.pardir, os.pardir))
output = subprocess.check_output(['git', 'ls-files'], cwd=repo_root).rstrip()
return output.spli
```
<Overlap Ratio: 0.7936507936507936>

---

--- 328 --
Question ID: a3fe4ca6378c81dc6c16f114a862eea6f04204b0_11
Original Code:
```
def dict_patch(path, value):
    """Return dictionary patch.

    Used for merging.
    """
    if not path:
        return value

    if isinstance(path, str):
        path = path.split(".")

    curr = result = {}
    for k in path[:-1]:
        curr[k] = {}
        curr = curr[k]

    curr[path[-1]] = value
    return result
```


Overlapping Code:
```
"""Return dictionary patch.
Used for merging.
"""
if not path:
return value
if isinstance(path, str):
path = path.split(".")
curr = result = {}
for k in path[:-1]:
curr[k] = {}
curr = curr[k]
curr[pat
```
<Overlap Ratio: 0.7782101167315175>

---

--- 329 --
Question ID: 49b103e10d93f562b298b9c36f1574e96fa2f031_37
Original Code:
```
def msg_list(pkg, search_path, ext):
    dir_list = search_path[pkg]
    files = []
    for d in dir_list:
        files.extend([f for f in os.listdir(d) if f.endswith(ext)])
    return [f[:-len(ext)] for f in files]
```


Overlapping Code:
```
ef msg_list(pkg, search_path, ext):
dir_list = search_path[pkg]
files = []
for d in dir_list:
files.extend([f for f in os.listdir(d) if f.endswith(ext)])
return [f[:-len(ext)] for f in f
```
<Overlap Ratio: 0.96875>

---

--- 330 --
Question ID: 190bbde7328f320d582d24941b053de43c0edeb0_16
Original Code:
```
@app.route('/plot/ph')
def plot_ph():
	times, temps, hums = getHistData(numSamples)
	ys = hums
	fig = Figure()
	axis = fig.add_subplot(1, 1, 1)
	axis.set_title("Humidity Sensor")
	axis.set_xlabel("Samples")
	axis.set_ylabel("Percentage Humidity")
	axis.grid(True)
	xs = range(numSamples)
	axis.plot(xs, ys)
	canvas = FigureCanvas(fig)
	output = io.BytesIO()
	canvas.print_png(output)
	response = make_response(output.getvalue())
	response.mimetype = 'image/png'
	return response
```


Overlapping Code:
```
, temps, hums = getHistData(numSamples)
ys = hums
fig = Figure()
axis = fig.add_subplot(1, 1, 1)
axis.set_title("Humidity Sensor")
axis.set_xlabel("Samples")
axis.set_ylabel("Percentage Humidity")
axis.grid(True)
xs = range(numSamples)
axis.plot(xs, ys)
canvas = FigureCanvas(fig)
output = io.BytesIO()
canvas.print_png(output)
response = make_response(output.getvalue())
response.mimetype = 'image/png'
return respon
```
<Overlap Ratio: 0.9025974025974026>

---

--- 331 --
Question ID: d4ba167c2657e860124f60def9f58fcdbba7c0df_14
Original Code:
```
@fixture
@using(api=api)
def form_view(api: Api):
    @api.route("/form")
    class Form:
        async def on_post(self, req, resp):
            given_form = dict(**(await req.media()))
            assert form_data == given_form

    return Form
```


Overlapping Code:
```
iew(api: Api):
@api.route("/form")
class Form:
async def on_post(self, req, resp):
given_form = dict(**(await req.media()))
assert form_data == given_
```
<Overlap Ratio: 0.746268656716418>

---

--- 332 --
Question ID: ab02dd1295db335ed735a7be6be97ea7212268eb_11
Original Code:
```
def test_parser_service_arguments():
    result = parse('my_service command key:"value"\n')
    args = result.block.service_block.service.service_fragment.arguments
    assert args.child(0) == Token('NAME', 'key')
    entity = get_entity(arith_exp(Tree('an_exp', [args.expression])))
    assert entity.values.string.child(0) == Token('DOUBLE_QUOTED', '"value"')
```


Overlapping Code:
```
result = parse('my_service command key:"value"\n')
args = result.block.service_block.service.service_fragment.arguments
assert args.child(0) == Token('NAME', 'key')
entity = get_entity(arith_exp(Tree('an_exp', [args.expression])))
assert entity.values.string.child(0) == Token('DOUBLE_QUOTED', '"valu
```
<Overlap Ratio: 0.8797653958944281>

---

--- 333 --
Question ID: bcc4525616e57f69b4ac7a064584ea128fdfc351_0
Original Code:
```
async def test_example():
    conn = await aiomysql.connect(

            host=os.environ.get('HOSTNAME'),
            user=os.environ.get('USERNAME'),
            port=int(os.environ.get('PORT')),
            password=os.environ.get('PASSWORD'),
            db=os.environ.get('DATABASE')
    )

    async with conn.cursor() as cur:
        await cur.execute("SELECT * FROM guild_settings")
        print(cur.description)
        r = await cur.fetchall()
        print(r)
    conn.close()
    return r
```


Overlapping Code:
```
sync def test_example():
conn = await aiomysql.connect(
host=os.environ.get('HOSTNAME'),
user=os.environ.get('USERNAME'),
port=int(os.environ.get('PORT')),
password=os.environ.get('PASSWORD'),
db=os.environ.get('DATABASE')
)
async with conn.cursor() as cur:
await cur.execute("SELECT * FROM guild_settings")
print(cur.description)
r = await cur.fetchall()
print(r)
conn.close(
```
<Overlap Ratio: 0.9715762273901809>

---

--- 334 --
Question ID: 827137b7e453645a2d2939d239b6c97417cdd5d8_6
Original Code:
```
def test_cooper_nathans():
    """Test Cooper Nathans method
    """
    R0 = 2117.45739160280
    RMS = np.array([[9154.39386475516, 7.32203491574463e-11, 0, 7.11894676107400e-12],
                    [2.68712790277282e-10, 340628.383580632, 0, -32536.7077302429],
                    [0, 0, 634.724632931705, 0],
                    [2.58004722905037e-11, -32536.7077302429, 0, 3114.58144514260]])
    ResVol0 = (2 * np.pi) ** 2 / np.sqrt(np.linalg.det(RMS)) * 2
    angles0 = np.array([-20.58848852, -41.17697704, -78.6627354, 22.67452921, -20.58848852, -41.17697704])
    BraggWidths0 = np.array(
        [0.0492235489748347, 0.00806951257792662, 0.186936902874783, 1.82137589975272, 0.0843893950600324])

    EXP = EXP_coopernathans
    hkle = [1., 0., 0., 0.]

    EXP.calc_resolution(hkle)

    NP = EXP.RMS
    R = EXP.R0
    BraggWidths = instrument.tools.get_bragg_widths(NP)
    angles = EXP_coopernathans.get_angles_and_Q(hkle)[0]
    ResVol = (2 * np.pi) ** 2 / np.sqrt(np.linalg.det(NP)) * 2

    assert (np.all(np.abs((RMS - NP)) < 100))
    assert (abs(R - R0) < 1e-3)
    assert (abs(ResVol - ResVol0) < 1e-5)
    assert (np.all(np.abs((BraggWidths - BraggWidths0)) < 0.1))
    assert (np.all(np.abs((angles0 - angles)) < 0.1))
```


Overlapping Code:
```
 Cooper Nathans method
"""
R0 = 2117.45739160280
RMS = np.array([[9154.39386475516, 7.32203491574463e-11, 0, 7.11894676107400e-12],
[2.68712790277282e-10, 340628.383580632, 0, -32536.7077302429],
[0, 0, 634.724632931705, 0],
[2.58004722905037e-11, -32536.7077302429, 0, 3114.58144514260]])
ResVol0 = (2 * np.pi) ** 2 / np.sqrt(np.linalg.det(RMS)) * 2
angles0 = np.array([-20.58848852, -41.17697704, -78.6627354, 22.67452921, -20.58848852, -41.17697704])
BraggWidths0 = np.array(
[0.0492235489748347, 0.00806951257792662, 0.186936902874783, 1.82137589975272, 0.0843893950600324])
EXP = EXP_coopernathans
hkle = [1., 0., 0., 0.]
EXP.calc_resolution(hkle)
NP = EXP.RMS
R = EXP.R0
BraggWidths = instrument.tools.get_bragg_widths(NP)
angles = EXP_coopernathans.get_angles_and_Q(hkle)[0]
ResVol = (2 * np.pi) ** 2 / np.sqrt(np.linalg.det(NP)) * 2
assert (np.all(np.abs((RMS - NP)) < 100))
assert (abs(R - R0) < 1e-3)
assert (abs(ResVol - ResVol0) < 1e-5)
assert (np.all(np.abs((BraggWidths - BraggWidths0)) < 0.1))
assert (np.all(np.abs((angles0 - angles))
```
<Overlap Ratio: 0.9615384615384616>

---

--- 335 --
Question ID: b07a8734a34e89e577bd162d0ecf9d465ec717c3_1
Original Code:
```
def load_model(model, filename, device):
    try:
        state = torch.load(filename, map_location=device)
        model.load_state_dict(state['model'], strict=True)
        print(f'Loaded model {filename}.')
    except FileNotFoundError:
        raise Exception(f'The model file {filename} was not found!')
```


Overlapping Code:
```
e):
try:
state = torch.load(filename, map_location=device)
model.load_state_dict(state['model'], strict=True)
print(f'Loaded model {filename}.')
except FileNotFoundError:
raise Exception(f'The model f
```
<Overlap Ratio: 0.746268656716418>

---

--- 336 --
Question ID: 72939b19bd35f96d1f6879c56d8535cbe02db51e_1
Original Code:
```
def add_comment(old_method, self, *args, **kwds):
    """
    for enhence methods

    """
    # print '*** calling: %s%s, kwds=%s' % (old_method.__name__, args, kwds)
    return_value = old_method(self, *args, **kwds)                  # call the original method
    v_number = return_value.get_all_vertexes()
    comment = {
        k:str(k).encode("utf-8").decode("utf-8")  + " is a good place"         # comment
        for k in v_number
    }
    score = {
        k: 5*random.uniform(0, 1) 
        for k in v_number
    }
    return (score, comment)                                 # as the return value of load_csv
```


Overlapping Code:
```
_method, self, *args, **kwds):
"""
for enhence methods
"""
# print '*** calling: %s%s, kwds=%s' % (old_method.__name__, args, kwds)
return_value = old_method(self, *args, **kwds) # call the original method
v_number = return_value.get_all_vertexes()
comment = {
k:str(k).encode("utf-8").decode("utf-8") + " is a good place" # comment
for k in v_number
}
score = {
k: 5*random.uniform(0, 1) 
for k in v_number
}
return (score, comment) # as the return 
```
<Overlap Ratio: 0.9259259259259259>

---

--- 337 --
Question ID: 432a038a49fa76a638f2d1480ac7d18f1f3dd622_10
Original Code:
```
def init_parameters(config):
    version = int(config.version)
    global feature_size, embedding_size, deep_layers, deep_layers_activation, batch_size
    global learning_rate, optimizer_type, batch_norm_Flag, batch_norm_decay, verbose
    global random_seed, l2_reg, epoch_number

    # if version == 1:
    #     batch_norm_Flag = False
    # elif version == 2:
    #     batch_norm_Flag = True

    if str(config.mode) == "test":
        batch_size = 200

    printParameter()
```


Overlapping Code:
```
fig.version)
global feature_size, embedding_size, deep_layers, deep_layers_activation, batch_size
global learning_rate, optimizer_type, batch_norm_Flag, batch_norm_decay, verbose
global random_seed, l2_reg, epoch_number
# if version == 1:
# batch_norm_Flag = False
# elif version == 2:
# batch_norm_Flag = True
if str(config.mode) == "test":
batch_si
```
<Overlap Ratio: 0.831353919239905>

---

--- 338 --
Question ID: 811e07607ad3d7d12ad096319861ae130782bc4f_6
Original Code:
```
def dy(f, x, pcov, jac=None, n_samples=1e6, seed=42):
    """
    Data una variabile aleatoria x, calcola matrice di covarianza della
    variabile aleatoria y=f(x). Nota che la matrice di covarianza corrisponde
    all'errore al quadrato, di conseguenza in caso di funzione da R^n->R
    si deve fare la radice per ottenere l'errore

    Il calcolo di default è fatto probabilisticamente, ovvero non si propaga
    l'errore usando la derivata ma si fa un sampling dalla distribuzione della x,
    poi successivamente si ricostruisce la matrice di convarianza della y.
    Questo metodo è esatto e funziona anche se la funzione f è in presenza di
    un massimo o un minimo, tuttavia in questi casi la distribuzione della y
    non è più gaussiana e vanno trattati con cura, la funzione notifica questo
    con un warning.
    L'unico problema di questo metodo è che potrebbe essere lento, sopratutto
    nel caso di funzioni f molto complicate e/o con output in alta dimensione,
    se la funzione risulta lenta si può abbassare il parametro n_samples, 
    tenendo conto del fatto che l'errore relativo su ciascun elemento della
    matrice di covarianza va come 1/sqrt(n_samples), di default n_samples=1e6 
    cosi' l'errore è sulla terza cifra.

    Se si vuole propagare gli errori col metodo "classico" si può passare
    come argomento in jac una funzione che calcola la jacobiana nel punto x,
    un buon pacchetto per calcolare la jacobiana senza smattare è jax,
    sviluppato da google: https://github.com/google/jax

    Args:
        f(x, y, ...): funzione R^n->R^m che restituisce y=f(x)
        x (tupla, array o numpy array): indica il punto in cui calcolare
            la matrice di covarianza
        pcov (2d array): Matrice di covarianza della variabile aleatoria x
        jac (Callable, optional): Funzione che restituisce la matrice jacobiana
            della funzione f in un punto x. Defaults to None
        n_samples ([int, float], optional): Samples to draw from f. Defaults to 1e6.
        seed (int, optional): seed of the random number generator. Defaults to 42.


    Returns:
        [float, 2d array]: Matrice di covarianza di y=f(x)

    Es: Calcolo dell'errore su y=f(x)=x/(1+x**2) in x=2 +- 0.1
    In questo caso la matrice di covarianza (cov) è uno scalare tale che cov==dx**2
    dove == indica una definizione e dx indica l'errore sulla x, quindi:
    >>> import menzalib as mz
    >>> def f(x):
            return x/(1+x**2)
    >>> mz.dy(f, 2, 0.1**2)
   	0.012000000000000004
    """

    x, pcov = jnp.array(x, ndmin=1, dtype=jnp.float64), jnp.array(pcov, ndmin=2, dtype=jnp.float64)

    # Vedo quanti argomenti ha f e li immetto come vettore x

    
    if x.ndim!=0 and len(signature(f).parameters) == len(x): 
        g = lambda x: f(*x)
    else:
        g = f

    # Calcolo l'errore standard
    if jac is not None:
        J=jac(x)
        return J@pcov@J.T

    # Altrimenti calcolo quello statistico
    key = random.PRNGKey(seed)
    samples = random.multivariate_normal(key, mean=x, cov=pcov, shape=(int(n_samples),))
    y = g(samples.T)

    # Test per vedere se la distribuzione della y è gaussiana
    true_mean = g(x)
    try:
        sample_mean = jnp.mean(y, axis=1)
        std = jnp.std(y, axis=1, ddof=1)/jnp.sqrt(n_samples)
    except IndexError:
        sample_mean = jnp.mean(y)
        std = jnp.std(y, ddof=1)/jnp.sqrt(n_samples)
    
    if (normal_test(true_mean, sample_mean, std) < 1e-5).any():
        message = f"\nThe output distribution of input x: {x} isn't normally distributed anymore\n"
        message += f"A possible cause is that the function f is very close to a maximum/minimum"
        warn(message, RuntimeWarning)

    return np.asarray(jnp.cov(y, ddof=1))
```


Overlapping Code:
```
les=1e6, seed=42):
"""
Data una variabile aleatoria x, calcola matrice di covarianza della
variabile aleatoria y=f(x). Nota che la matrice di covarianza corrisponde
all'errore al quadrato, di conseguenza in caso di funzione da R^n->R
si deve fare la radice per ottenere l'errore
Il calcolo di default è fatto probabilisticamente, ovvero non si propaga
l'errore usando la derivata ma si fa un sampling dalla distribuzione della x,
poi successivamente si ricostruisce la matrice di convarianza della y.
Questo metodo è esatto e funziona anche se la funzione f è in presenza di
un massimo o un minimo, tuttavia in questi casi la distribuzione della y
non è più gaussiana e vanno trattati con cura, la funzione notifica questo
con un warning.
L'unico problema di questo metodo è che potrebbe essere lento, sopratutto
nel caso di funzioni f molto complicate e/o con output in alta dimensione,
se la funzione risulta lenta si può abbassare il parametro n_samples, 
tenendo conto del fatto che l'errore relativo su ciascun elemento della
matrice di covarianza va come 1/sqrt(n_samples), di default n_samples=1e6 
cosi' l'errore è sulla terza cifra.
Se si vuole propagare gli errori col metodo "classico" si può passare
come argomento in jac una funzione che calcola la jacobiana nel punto x,
un buon pacchetto per calcolare la jacobiana senza smattare è jax,
sviluppato da google: https://github.com/google/jax
Args:
f(x, y, ...): funzione R^n->R^m che restituisce y=f(x)
x (tupla, array o numpy array): indica il punto in cui calcolare
la matrice di covarianza
pcov (2d array): Matrice di covarianza della variabile aleatoria x
jac (Callable, optional): Funzione che restituisce la matrice jacobiana
della funzione f in un punto x. Defaults to None
n_samples ([int, float], optional): Samples to draw from f. Defaults to 1e6.
seed (int, optional): seed of the random number generator. Defaults to 42.
Returns:
[float, 2d array]: Matrice di covarianza di y=f(x)
Es: Calcolo dell'errore su y=f(x)=x/(1+x**2) in x=2 +- 0.1
In questo caso la matrice di covarianza (cov) è uno scalare tale che cov==dx**2
dove == indica una definizione e dx indica l'errore sulla x, quindi:
>>> import menzalib as mz
>>> def f(x
```
<Overlap Ratio: 0.9653356735410268>

---

--- 339 --
Question ID: 90f9c7caff3318b20c39749b582ca7eda1c342d1_1
Original Code:
```
def filter_tx_log10(file, library):
	read = pd.read_csv(file,index_col="Barcode")
	tx_log10 = read[read.columns[-1]]
	filter_key = tx_log10.loc[library.index] #filtering library barcodes	
	return filter_key
```


Overlapping Code:
```
ad = pd.read_csv(file,index_col="Barcode")
tx_log10 = read[read.columns[-1]]
filter_key = tx_log10.loc[library.index] #filtering library barcodes 
return
```
<Overlap Ratio: 0.7574257425742574>

---

--- 340 --
Question ID: 61f64fc16f91c22130b6ab3d7970d5bcc070f129_0
Original Code:
```
def create_dataframe(url):
    """ Creates data frame from url """
    data_frame = pd.read_csv(url)
    return data_frame
```


Overlapping Code:
```
ta frame from url """
data_frame = pd.read_csv(url
```
<Overlap Ratio: 0.45454545454545453>

---

--- 341 --
Question ID: 31894a67647dbf5378e4d20ebf5140b8b69d6d6d_5
Original Code:
```
@executer
def delete_groups_dec():
    base_url, headers = get_api_info()
    group_url = "{}/groups".format(base_url)
    group_response = requests.get("{}?limits={}".format(group_url, 200), headers=headers)
    group_details = json.loads(group_response.text)
    groups_id_list = [item['id'] for item in group_details]

    successfully_deleted_groups = []
    failed_groups = []

    for group_id in tqdm(groups_id_list):
        group_response = requests.delete("{}/{}".format(group_url, group_id), headers=headers)
        if group_response:
            successfully_deleted_groups.append(group_id)
        else:
            failed_groups.append(group_id)
    
    if successfully_deleted_groups:
        click.secho("\nList of groups deleted successfully: {}".format(
            successfully_deleted_groups), fg='green')
    if failed_groups:
        click.secho("\nFailed to delete these groups: {}.\n".format(failed_groups), fg='red')
```


Overlapping Code:
```
lete_groups_dec():
base_url, headers = get_api_info()
group_url = "{}/groups".format(base_url)
group_response = requests.get("{}?limits={}".format(group_url, 200), headers=headers)
group_details = json.loads(group_response.text)
groups_id_list = [item['id'] for item in group_details]
successfully_deleted_groups = []
failed_groups = []
for group_id in tqdm(groups_id_list):
group_response = requests.delete("{}/{}".format(group_url, group_id), headers=headers)
if group_response:
successfully_deleted_groups.append(group_id)
else:
failed_groups.append(group_id)

if successfully_deleted_groups:
click.secho("\nList of groups deleted successfully: {}".format(
successfully_deleted_groups), fg='green')
if failed_groups:
click.secho("\nFailed to delete these groups: {}.\n".format(failed_groups), fg='
```
<Overlap Ratio: 0.97442143727162>

---

--- 342 --
Question ID: a1f71f2efd8453668fe2ab6ac11b7f221a77698c_2
Original Code:
```
def compute_tasks(tasks: Iterable[Any], client: Client,
                  max_in_flight: int = 3) -> Iterable[Any]:
    """ Parallel compute stream with back pressure.

        Equivalent to:

        (client.compute(task).result()
          for task in tasks)

        but with up to `max_in_flight` tasks being processed at the same time.
        Input/Output order is preserved, so there is a possibility of head of
        line blocking.

        NOTE: lower limit is 3 concurrent tasks to simplify implementation,
              there is no point calling this function if you want one active
              task and supporting exactly 2 active tasks is not worth the complexity,
              for now. We might special-case `2` at some point.

    """
    # New thread:
    #    1. Take dask task from iterator
    #    2. Submit to client for processing
    #    3. Send it of to wrk_q
    #
    # Calling thread:
    #    1. Pull scheduled future from wrk_q
    #    2. Wait for result of the future
    #    3. yield result to calling code
    from .generic import it2q, qmap

    # (max_in_flight - 2) -- one on each side of queue
    wrk_q = queue.Queue(maxsize=max(1, max_in_flight - 2))  # type: queue.Queue

    # fifo_timeout='0ms' ensures that priority of later tasks is lower
    futures = (client.compute(task, fifo_timeout='0ms') for task in tasks)

    in_thread = threading.Thread(target=it2q, args=(futures, wrk_q))
    in_thread.start()

    yield from qmap(lambda f: f.result(), wrk_q)

    in_thread.join()
```


Overlapping Code:
```
tasks(tasks: Iterable[Any], client: Client,
max_in_flight: int = 3) -> Iterable[Any]:
""" Parallel compute stream with back pressure.
Equivalent to:
(client.compute(task).result()
for task in tasks)
but with up to `max_in_flight` tasks being processed at the same time.
Input/Output order is preserved, so there is a possibility of head of
line blocking.
NOTE: lower limit is 3 concurrent tasks to simplify implementation,
there is no point calling this function if you want one active
task and supporting exactly 2 active tasks is not worth the complexity,
for now. We might special-case `2` at some point.
"""
# New thread:
# 1. Take dask task from iterator
# 2. Submit to client for processing
# 3. Send it of to wrk_q
#
# Calling thread:
# 1. Pull scheduled future from wrk_q
# 2. Wait for result of the future
# 3. yield result to calling code
from .generic import it2q, qmap
# (max_in_flight - 2) -- one on each side of queue
wrk_q = queue.Queue(maxsize=max(1, max_in_flight - 2)) # type: queue.Queue
# fifo_timeout='0ms' ensures that priority of later tasks is lower
futures = (client.compute(task, fifo_timeout='0ms') for task in tasks)
in_thread = threading.Thread(target=it2q, args=(futures, wrk_q))
in_thread.start()
yield from qmap(lambda
```
<Overlap Ratio: 0.9607993850883936>

---

--- 343 --
Question ID: 9fb6e7df49c4e149bd7c60ce791a91ccb54db62a_1
Original Code:
```
def list_folders(vignore, path):
    # get all folders
    folders = [x for x in os.listdir(path) if os.path.isdir(join(path, x))]
    # folders = list(filter(lambda x: False if vignore(join(path, x)) else True, folders))
    folders = list(filter(lambda x: False if x == "src" or x[0] == "." else True, folders))
    return folders
```


Overlapping Code:
```
ers
folders = [x for x in os.listdir(path) if os.path.isdir(join(path, x))]
# folders = list(filter(lambda x: False if vignore(join(path, x)) else True, folders))
folders = list(filter(lambda x: False if x == "src" or x[0] == "." else True, folders))
```
<Overlap Ratio: 0.8012820512820513>

---

--- 344 --
Question ID: ed382011a00d6f83cb0e0ac487b3306b31a6e19c_2
Original Code:
```
def find_typerefs(node, fileName):
    """ Find all references to the type named 'typename'
    """
    #if node.kind == clang.cindex.CursorKind.is_declaration
    #if node.kind.is_definition():
    #if node.is_definition():
        #ref_node = clang.cindex.Cursor_ref(node)
        #ref_node = node
    #if node.kind == clang.cindex.CursorKind.ANNOTATE_ATTR:
    #    print("is_definition", node.spelling, node.location.file, node.kind)
    #if node.location.file and node.location.file.name == fileName:
    #if node.spelling != "":
    #    print("data", node.spelling, node.location.file, node.location.line, node.location.column)
    # Recurse for children of this node
    #for c in node.get_children():
    #    find_typerefs(c, fileName)
    for c in node.get_children():
        if c.location and c.location.file.name == fileName:
            parse_node(c)
```


Overlapping Code:
```
s(node, fileName):
""" Find all references to the type named 'typename'
"""
#if node.kind == clang.cindex.CursorKind.is_declaration
#if node.kind.is_definition():
#if node.is_definition():
#ref_node = clang.cindex.Cursor_ref(node)
#ref_node = node
#if node.kind == clang.cindex.CursorKind.ANNOTATE_ATTR:
# print("is_definition", node.spelling, node.location.file, node.kind)
#if node.location.file and node.location.file.name == fileName:
#if node.spelling != "":
# print("data", node.spelling, node.location.file, node.location.line, node.location.column)
# Recurse for children of this node
#for c in node.get_children():
# find_typerefs(c, fileName)
for c in node.get_children():
if c.location and
```
<Overlap Ratio: 0.9162303664921466>

---

--- 345 --
Question ID: 9f966f81f3e43e23777a3d2f9117cf5f67d333f7_9
Original Code:
```
def _go_ids_accept_single_recursive(a, b, b_parents):
    """
    2 outcomes:

    * a is parent (direct or indirect) of b --> True
    * else --> False
    """

    if a == b:
        return True

    return any(_go_ids_accept_single_recursive(a, pp, GO_TREE.get(pp).parents) for pp in b_parents if pp in GO_TREE)
```


Overlapping Code:
```
(a, b, b_parents):
"""
2 outcomes:
* a is parent (direct or indirect) of b --> True
* else --> False
"""
if a == b:
return True
return any(_go_ids_accept_single_recursive(a, pp, GO_TREE.get(pp).parent
```
<Overlap Ratio: 0.7272727272727273>

---

--- 346 --
Question ID: 988a2a8401c431017a8556ffb7e5c066809f7e37_1
Original Code:
```
@blueprint.route('/<int:poll_id>')
@for_auth
def get_one(poll_id: int):
    logger.info('Poll. Get info %s', poll_id)
    obj = db.session.query(Poll).get_or_404(poll_id)  # type: Poll
    validators.namespace_access(obj.namespace_code)
    return jsonify(dict(results=obj.marshall()))
```


Overlapping Code:
```
poll_id>')
@for_auth
def get_one(poll_id: int):
logger.info('Poll. Get info %s', poll_id)
obj = db.session.query(Poll).get_or_404(poll_id) # type: Poll
validators.namespace_access(obj.namespace_code)
return jsonify(dict(resu
```
<Overlap Ratio: 0.835820895522388>

---

--- 347 --
Question ID: 1840e87be59bd6818b0b1170d5b7b76a9db29ded_1
Original Code:
```
def main():
    glutInit(sys.argv)                              # tells the python we are going to be displaying GLUT style graphics
    glutInitDisplayMode(GLUT_SINGLE | GLUT_RGB)
    glutCreateWindow("Plot Points")
    glutInitWindowSize(400,400)
    glutInitWindowPosition(50,50)
    glutDisplayFunc(plotfunc)
    init()
    glutMainLoop()
```


Overlapping Code:
```
ef main():
glutInit(sys.argv) # tells the python we are going to be displaying GLUT style graphics
glutInitDisplayMode(GLUT_SINGLE | GLUT_RGB)
glutCreateWindow("Plot Points")
glutInitWindowSize(400,400)
glutInitWindowPosition(50,50)
glutDisplayFunc(plotfunc)
i
```
<Overlap Ratio: 0.9252669039145908>

---

--- 348 --
Question ID: f290e9e8755f5bde9581a5b137a4dc4d624fc213_1
Original Code:
```
def valid_local_author(author_host, author_id):
    try:
        tmp = author_id.split("author/")
        author_short_id = tmp[1]
        request_user = AuthorProfile.objects.filter(host=author_host, id=author_short_id)
        if not (request_user.exists()):
            return False
    except:
        return False
    return True
```


Overlapping Code:
```
ef valid_local_author(author_host, author_id):
try:
tmp = author_id.split("author/")
author_short_id = tmp[1]
request_user = AuthorProfile.objects.filter(host=author_host, id=author_short_id)
if not (request_user.exists()):
return False
except:
retur
```
<Overlap Ratio: 0.9259259259259259>

---

--- 349 --
Question ID: 2eb5701c07a0400a66b1bcc8bf35e6b0c13cef54_17
Original Code:
```
def _precision_v_cost():
    import math

    #
    LOOPS = 10**6
    #
    print("time.time_ns(): %s" % time.time_ns())
    print("time.time():    %s\r\n" % time.time())
    #
    starts = time.time_ns()
    min_dt = [abs(time.time_ns() - time.time_ns()) for _ in range(LOOPS)]
    min_dt = min(filter(bool, min_dt))
    print("min delta   time_ns(): %s ns" % min_dt)
    print("duration    time_ns(): %s ns\r\n" % (time.time_ns() - starts))
    #
    starts = time.time_ns()
    min_dt = [abs(time.time() - time.time()) for _ in range(LOOPS)]
    min_dt = min(filter(bool, min_dt))
    print("min delta      time(): %s ns" % math.ceil(min_dt * 1e9))
    print("duration       time(): %s ns\r\n" % (time.time_ns() - starts))
    #
    starts = time.time_ns()
    min_dt = [abs(timestamp() - timestamp()) for _ in range(LOOPS)]
    min_dt = min(filter(bool, min_dt))
    print("min delta timestamp(): %s ns" % math.ceil(min_dt * 1e9))
    print("duration  timestamp(): %s ns\r\n" % (time.time_ns() - starts))
    #
    LOOPS = 10**4
    #
    starts = time.time_ns()
    min_td = [abs(dt.now() - dt.now()) for _ in range(LOOPS)]
    min_td = min(filter(bool, min_td))
    print("min delta dt.now(): %s ns" % math.ceil(min_dt * 1e9))
    print("duration  dt.now(): %s ns\r\n" % (time.time_ns() - starts))
    #
    starts = time.time_ns()
    min_td = [abs(dt_now() - dt_now()) for _ in range(LOOPS)]
    min_td = min(filter(bool, min_td))
    print("min delta dt_now(): %s ns" % math.ceil(min_dt * 1e9))
    print("duration  dt_now(): %s ns\r\n" % (time.time_ns() - starts))
    #
    starts = time.time_ns()
    min_td = [
        abs(
            (dt_now if sys.platform == "win32" else dt.now)()
            - (dt_now if sys.platform == "win32" else dt.now)()
        )
        for _ in range(LOOPS)
    ]
    min_td = min(filter(bool, min_td))
    print("min delta dt_now(): %s ns" % math.ceil(min_dt * 1e9))
    print("duration  dt_now(): %s ns\r\n" % (time.time_ns() - starts))
    #
    dt_nov = dt_now if sys.platform == "win32" else dt.now
    starts = time.time_ns()
    min_td = [abs(dt_nov() - dt_nov()) for _ in range(LOOPS)]
    min_td = min(filter(bool, min_td))
    print("min delta dt_now(): %s ns" % math.ceil(min_dt * 1e9))
    print("duration  dt_now(): %s ns\r\n" % (time.time_ns() - starts))
```


Overlapping Code:
```
port math
#
LOOPS = 10**6
#
print("time.time_ns(): %s" % time.time_ns())
print("time.time(): %s\r\n" % time.time())
#
starts = time.time_ns()
min_dt = [abs(time.time_ns() - time.time_ns()) for _ in range(LOOPS)]
min_dt = min(filter(bool, min_dt))
print("min delta time_ns(): %s ns" % min_dt)
print("duration time_ns(): %s ns\r\n" % (time.time_ns() - starts))
#
starts = time.time_ns()
min_dt = [abs(time.time() - time.time()) for _ in range(LOOPS)]
min_dt = min(filter(bool, min_dt))
print("min delta time(): %s ns" % math.ceil(min_dt * 1e9))
print("duration time(): %s ns\r\n" % (time.time_ns() - starts))
#
starts = time.time_ns()
min_dt = [abs(timestamp() - timestamp()) for _ in range(LOOPS)]
min_dt = min(filter(bool, min_dt))
print("min delta timestamp(): %s ns" % math.ceil(min_dt * 1e9))
print("duration timestamp(): %s ns\r\n" % (time.time_ns() - starts))
#
LOOPS = 10**4
#
starts = time.time_ns()
min_td = [abs(dt.now() - dt.now()) for _ in range(LOOPS)]
min_td = min(filter(bool, min_td))
print("min delta dt.now(): %s ns" % math.ceil(min_dt * 1e9))
print("duration dt.now(): %s ns\r\n" % (time.time_ns() - starts))
#
starts = time.time_ns()
min_td = [abs(dt_now() - dt_now()) for _ in range(LOOPS)]
min_td = min(filter(bool, min_td))
print("min delta dt_now(): %s ns" % math.ceil(min_dt * 1e9))
print("duration dt_now(): %s ns\r\n" % (time.time_ns() - starts))
#
starts = time.time_ns()
min_td = [
abs(
(dt_now if sys.platform == "win32" else dt.now)()
- (dt_now if sys.platform == "win32" else dt.now)()
)
for _ in range(LOOPS)
]
min_td = min(filter(bool, min_td))
print("min delta dt_now(): %s ns" % math.ceil(min_dt * 1e9))
print("duration dt_now(): %s ns\r\n" % (time.time_ns() - starts))
#
dt_nov = dt_now if sys.platform == "win32" else dt.now
starts = time.time_ns()
min_td = [abs(dt_nov() - dt_nov()) for _ in range(LOOPS)]
min_td = min(filter(bool, min_td))
print("min delta dt_now(): %s ns" % math.ceil(min_dt * 1e9))
print("duration dt_now(): %s ns\r\n" % (time.time_ns() - starts))
```
<Overlap Ratio: 0.9867125984251969>

---

--- 350 --
Question ID: 27545099dfad8f6242352652570f4c64b04e62cd_2
Original Code:
```
def arr_to_cla(arr_intensity, str_output_type='full', int_dp=0):
    """
    Takes flux intensity in the xrsb band and returns the classification.
    Note, intensities below 10.0**-8.0 get an empty sting.

    Parameters
    ----------
    arr_intensity : arr
        The float or array of intensity values to find the classification of.

    str_output_type : `str`
        A string to decide the output necessary.
        'full' = the character and number
        'number' = just the number
        'character' = just the character

    int_dp : `int`
        The dataset to look for maxima in.

    Returns
    -------
    result : array
        The list of indices for local maxima.
    """
    lis_results = []

    for i in range(0,len(arr_intensity)):
        lis_results.append(flo_to_cla(arr_intensity[i], str_output_type='full', int_dp=int_dp))

    return np.array(lis_results)
```


Overlapping Code:
```
arr_intensity, str_output_type='full', int_dp=0):
"""
Takes flux intensity in the xrsb band and returns the classification.
Note, intensities below 10.0**-8.0 get an empty sting.
Parameters
----------
arr_intensity : arr
The float or array of intensity values to find the classification of.
str_output_type : `str`
A string to decide the output necessary.
'full' = the character and number
'number' = just the number
'character' = just the character
int_dp : `int`
The dataset to look for maxima in.
Returns
-------
result : array
The list of indices for local maxima.
"""
lis_results = []
for i in range(0,len(arr_intensity)):
lis_results.append(flo_to_cla(arr_intensity[i], str_output_type='full', int_dp=int_dp)
```
<Overlap Ratio: 0.9407114624505929>

---

--- 351 --
Question ID: d9bef0062335735f85138ca286bea734ef9177cd_4
Original Code:
```
def safeMul(*factors):
  if None in factors:
    return None

  factors = [float(x) for x in factors]
  product = reduce(lambda x,y: x*y, factors)
  return product
```


Overlapping Code:
```
afeMul(*factors):
if None in factors:
return None
factors = [float(x) for x in factors]
product = reduce(lambda x,y: x*y, factors)
retur
```
<Overlap Ratio: 0.9066666666666666>

---

--- 352 --
Question ID: 809f2ff93387e4dae6dfe998053f859ab29d43cf_4
Original Code:
```
@app.route('/transaction/<string:transaction_id>', methods=['GET'])
@cors()
@jsonify_exceptions
def transaction_get(transaction_id=None):
    transaction = app.ledger.get_transaction(transaction_id)

    if transaction is None:
        abort(404)

    return jsonify(transaction=transaction)
```


Overlapping Code:
```
oute('/transaction/<string:transaction_id>', methods=['GET'])
@cors()
@jsonify_exceptions
def transaction_get(transaction_id=None):
transaction = app.ledger.get_transaction(transaction_id)
if transaction is None:
abort(404)
return jsonify(transaction
```
<Overlap Ratio: 0.929368029739777>

---

--- 353 --
Question ID: eae5fb61c5fd7fee54c4fdfbe746e2eb690eafd3_1
Original Code:
```
def main():
    # start = (90, 100)
    # goal = (100, 114)
    # Spawn
    start = (29, 65)
    goal = (154, 114)
    # Ramp
    # start = (32, 51)
    # goal = (150, 129)
    # map_grid = np.loadtxt("AutomatonLE.txt", delimiter="").astype(int)
    grid = []
    with open("../AutomatonLE.txt") as f:
        for line in f.readlines():
            values = [int(i) for i in list(line.strip())]
            grid.append(values)
    # print(grid)
    map_grid = np.asarray(grid)
    # print(map_grid)

    path = []
    with open("../path.txt") as f:
        for line in f.readlines():
            x, y = line.split(",")
            path.append((int(x.strip()), int(y.strip())))
    print()
    # print(map_grid.shape)
    plot(map_grid, route=path, start=start, goal=goal)
```


Overlapping Code:
```
# start = (90, 100)
# goal = (100, 114)
# Spawn
start = (29, 65)
goal = (154, 114)
# Ramp
# start = (32, 51)
# goal = (150, 129)
# map_grid = np.loadtxt("AutomatonLE.txt", delimiter="").astype(int)
grid = []
with open("../AutomatonLE.txt") as f:
for line in f.readlines():
values = [int(i) for i in list(line.strip())]
grid.append(values)
# print(grid)
map_grid = np.asarray(grid)
# print(map_grid)
path = []
with open("../path.txt") as f:
for line in f.readlines():
x, y = line.split(",")
path.append((int(x.strip()), int(y.strip())))
print()
# print(map_grid.shape)
plot(map_grid, route=path, start
```
<Overlap Ratio: 0.9523809523809523>

---

--- 354 --
Question ID: 8150fd51bf255683c6fea7c93468cc064a221ee1_0
Original Code:
```
def execute_query_find(query):
    """Search document in mycoll collection using a query.

    Returns a list of documents.
    """
    documents = []
    for document in list(pymodm.connection._get_db().mycoll.find(query)):
        documents.append(document)
    return documents
```


Overlapping Code:
```
ef execute_query_find(query):
"""Search document in mycoll collection using a query.
Returns a list of documents.
"""
documents = []
for document in list(pymodm.connection._get_db().mycoll.find(query)
```
<Overlap Ratio: 0.8097165991902834>

---

--- 355 --
Question ID: 53d78cd74610fa846a4493dddef24c85a7d7fd59_37
Original Code:
```
def getSceneryUnitProductUpdate(projectName, sceneryCategory, sceneryName, sceneryVariant, sceneryStage):
    string = prsOutputs.Util.infoNonExistsLabel
    #
    serverProductFile = scnUnitProductFile(
        prsConfigure.Utility.DEF_value_root_server, projectName, sceneryCategory, sceneryName, sceneryVariant, sceneryStage
    )[1]
    #
    if bscMethods.OsFile.isExist(serverProductFile):
        data = bscMethods.OsFile.mtimeChnPrettify(serverProductFile)
        if data:
            string = data
    return string
```


Overlapping Code:
```
tUpdate(projectName, sceneryCategory, sceneryName, sceneryVariant, sceneryStage):
string = prsOutputs.Util.infoNonExistsLabel
#
serverProductFile = scnUnitProductFile(
prsConfigure.Utility.DEF_value_root_server, projectName, sceneryCategory, sceneryName, sceneryVariant, sceneryStage
)[1]
#
if bscMethods.OsFile.isExist(serverProductFile):
data = bscMethods.OsFile.mtimeChnPrettify(serverProductFile)
```
<Overlap Ratio: 0.8676789587852495>

---

--- 356 --
Question ID: a285eb59aed6f5a7dbd1db185352613e6ab47729_0
Original Code:
```
def duck_duck_goose(lista_nombres,num_elegido):
    while num_elegido > len(lista_nombres):
        num_elegido = num_elegido - 4
    jugador_elegido = lista_nombres[num_elegido - 1]
    return jugador_elegido
```


Overlapping Code:
```
sta_nombres,num_elegido):
while num_elegido > len(lista_nombres):
num_elegido = num_elegido - 4
jugador_elegido = lista_nombres[num_elegido - 1]
retur
```
<Overlap Ratio: 0.7936507936507936>

---

--- 357 --
Question ID: 539b5196056660971e87e7ecd99a26cba405a56a_0
Original Code:
```
async def run_queue_nonblocking_test(dut, queue_type):
    QUEUE_SIZE = 10

    q = queue_type(maxsize=QUEUE_SIZE)

    # queue empty
    assert q.maxsize == QUEUE_SIZE
    assert q.qsize() == 0
    assert q.empty()
    assert not q.full()

    # put one item
    q.put_nowait(0)

    assert q.qsize() == 1
    assert not q.empty()
    assert not q.full()

    # fill queue
    if queue_type is PriorityQueue:
        for k in range(QUEUE_SIZE - 1, 0, -1):
            q.put_nowait(k)
    else:
        for k in range(1, QUEUE_SIZE):
            q.put_nowait(k)

    assert q.qsize() == QUEUE_SIZE
    assert not q.empty()
    assert q.full()

    # overflow
    with pytest.raises(QueueFull):
        q.put_nowait(100)

    # check queue contents
    if queue_type is LifoQueue:
        for k in range(QUEUE_SIZE - 1, -1, -1):
            assert q.get_nowait() == k
    else:
        for k in range(QUEUE_SIZE):
            assert q.get_nowait() == k

    assert q.qsize() == 0
    assert q.empty()
    assert not q.full()

    # underflow
    with pytest.raises(QueueEmpty):
        q.get_nowait()
```


Overlapping Code:
```
t(dut, queue_type):
QUEUE_SIZE = 10
q = queue_type(maxsize=QUEUE_SIZE)
# queue empty
assert q.maxsize == QUEUE_SIZE
assert q.qsize() == 0
assert q.empty()
assert not q.full()
# put one item
q.put_nowait(0)
assert q.qsize() == 1
assert not q.empty()
assert not q.full()
# fill queue
if queue_type is PriorityQueue:
for k in range(QUEUE_SIZE - 1, 0, -1):
q.put_nowait(k)
else:
for k in range(1, QUEUE_SIZE):
q.put_nowait(k)
assert q.qsize() == QUEUE_SIZE
assert not q.empty()
assert q.full()
# overflow
with pytest.raises(QueueFull):
q.put_nowait(100)
# check queue contents
if queue_type is LifoQueue:
for k in range(QUEUE_SIZE - 1, -1, -1):
assert q.get_nowait() == k
else:
for k in range(QUEUE_SIZE):
assert q.get_nowait() == k
assert q.qsize() == 0
assert q.empty()
assert not q.full()
# underflow

```
<Overlap Ratio: 0.9080590238365494>

---

--- 358 --
Question ID: 979feb4188fe880ad26146c97ee90a0b3537c071_1
Original Code:
```
def param_values():
    
    x = [0] * C.NUM

    ## CYCE SYNTHESISx[C.DEGRADATION AND P27 BINDING/DISSOCIATION:
    x[C.kscyce]=0.003
    x[C.kdcyce]=0.001
    x[C.kdcycee]=0.0001
    x[C.kdcycea]=0.03
    x[C.kasse]=1
    x[C.kdise]=0.02
    ## CYCA SYNTHESISx[C.DEGRADATION AND P27 BINDING/DISSOCIATION:
    x[C.kscyca]=0.0025
    x[C.kdcyca]=0.002
    x[C.kdcycac1]=0.4
    x[C.kassa]=1
    x[C.kdisa]=0.02
    ## P27 SYNTHESIS AND DEGRADATION:
    x[C.ks27]=0.008
    x[C.kd27]=0.004
    x[C.kd27e]=2
    x[C.kd27a]=2
    ## EMI1 SYNTHESIS AND DEGRADATION:
    x[C.ksemi1]=0.003
    x[C.kdemi1]=0.001
    ## CDH1 REGULATION:
    x[C.Cdh1T]=1
    x[C.kacdh1]=0.02
    x[C.kicdh1e]=0.07
    x[C.kicdh1a]=0.2
    x[C.kasec]=2
    x[C.kdiec]=0.02
    ## SKP2 SYNTHESIS AND DEGRADATION:
    x[C.ksskp2]=0.004
    x[C.kdskp2]=0.002
    x[C.kdskp2c1]=0.2
    ## CDK INHIBITOR
    x[C.Inhibitor]=0

    return x
```


Overlapping Code:
```
## CYCE SYNTHESISx[C.DEGRADATION AND P27 BINDING/DISSOCIATION:
x[C.kscyce]=0.003
x[C.kdcyce]=0.001
x[C.kdcycee]=0.0001
x[C.kdcycea]=0.03
x[C.kasse]=1
x[C.kdise]=0.02
## CYCA SYNTHESISx[C.DEGRADATION AND P27 BINDING/DISSOCIATION:
x[C.kscyca]=0.0025
x[C.kdcyca]=0.002
x[C.kdcycac1]=0.4
x[C.kassa]=1
x[C.kdisa]=0.02
## P27 SYNTHESIS AND DEGRADATION:
x[C.ks27]=0.008
x[C.kd27]=0.004
x[C.kd27e]=2
x[C.kd27a]=2
## EMI1 SYNTHESIS AND DEGRADATION:
x[C.ksemi1]=0.003
x[C.kdemi1]=0.001
## CDH1 REGULATION:
x[C.Cdh1T]=1
x[C.kacdh1]=0.02
x[C.kicdh1e]=0.07
x[C.kicdh1a]=0.2
x[C.kasec]=2
x[C.kdiec]=0.02
## SKP2 SYNTHESIS AND DEGRADATION:
x[C.ksskp2]=0.004
x[C.kdskp2]=0.002
x[C.kdskp2c1]=0.2
## CDK INHIBITOR
x[C.
```
<Overlap Ratio: 0.9234828496042217>

---

--- 359 --
Question ID: 7cb73d7b4164b49ffab48fc8e065291b135db1c5_11
Original Code:
```
@transactional
def _confirm_payment(payment_record):
    secure_user_id = get_system_account_user_id(SECURE_USER_NAME)
    # 确认金额为订单金额 - 已退款金额
    amount = payment_record.amount - payment_record.refunded_amount
    event_id1 = zyt_bookkeeping(EventType.TRANSFER_OUT_FROZEN, payment_record.sn, secure_user_id, amount)
    event_id2 = zyt_bookkeeping(EventType.TRANSFER_IN, payment_record.sn, payment_record.payee_id, amount)

    transit_transaction_state(payment_record.tx_id, PaymentTxState.SECURED, PaymentTxState.SUCCESS,
                              [event_id1, event_id2])
```


Overlapping Code:
```
d):
secure_user_id = get_system_account_user_id(SECURE_USER_NAME)
# 确认金额为订单金额 - 已退款金额
amount = payment_record.amount - payment_record.refunded_amount
event_id1 = zyt_bookkeeping(EventType.TRANSFER_OUT_FROZEN, payment_record.sn, secure_user_id, amount)
event_id2 = zyt_bookkeeping(EventType.TRANSFER_IN, payment_record.sn, payment_record.payee_id, amount)
transit_transaction_state(payment_record.tx_id, PaymentTxState.SECURED, PaymentTxState.SUCCESS,
```
<Overlap Ratio: 0.8604206500956023>

---

--- 360 --
Question ID: 4a4c360b0c3fea943bf380ae8e14b9e0fc574a7b_16
Original Code:
```
@pytest.mark.usefixtures("job_constants")
def test_check_generation_prereqs_ef_has_errors(database):
    """ Tests a set of conditions that has an error in cross-file, fail the generation check for E/F files. """
    sess = database.session

    sub = SubmissionFactory(submission_id=1, d2_submission=False)
    cross_val = JobFactory(submission_id=sub.submission_id, job_type_id=JOB_TYPE_DICT['validation'], file_type_id=None,
                           job_status_id=JOB_STATUS_DICT['finished'], number_of_errors=1, number_of_warnings=0,
                           error_message=None)
    sess.add_all([sub, cross_val])
    sess.commit()

    can_generate = check_generation_prereqs(sub.submission_id, 'E')
    assert can_generate is False
```


Overlapping Code:
```
@pytest.mark.usefixtures("job_constants")
def test_check_generation_prereqs_ef_has_errors(database):
""" Tests a set of conditions that has an error in cross-file, fail the generation check for E/F files. """
sess = database.session
sub = SubmissionFactory(submission_id=1, d2_submission=False)
cross_val = JobFactory(submission_id=sub.submission_id, job_type_id=JOB_TYPE_DICT['validation'], file_type_id=None,
job_status_id=JOB_STATUS_DICT['finished'], number_of_errors=1, number_of_warnings=0,
error_message=None)
sess.add_all([sub, cross_val])
sess.commit()
can_generate = check_generation_prereqs(sub.submission_id, 'E')
assert can_generate is 
```
<Overlap Ratio: 0.9923430321592649>

---

--- 361 --
Question ID: f016eccb2a8fef9f83541909a8e0e2cb9b757e9b_0
Original Code:
```
def unpickle(file):
    
    with open(file, 'rb') as fo:
        dict = pickle.load(fo,encoding='iso-8859-1')
    return dict
```


Overlapping Code:
```
f unpickle(file):

with open(file, 'rb') as fo:
dict = pickle.load(fo,e
```
<Overlap Ratio: 0.6698113207547169>

---

--- 362 --
Question ID: 397459c21ff9f5f55b327438544d98c86fdd12ea_3
Original Code:
```
def build(capi_home):
    CAPIDependency.set_lib_install_base(capi_home)
    build_libpython(capi_home)
    build_builtin_exts(capi_home)
```


Overlapping Code:
```
PIDependency.set_lib_install_base(capi_home)
build_libpython(capi_home)
build_builtin_exts(capi_home
```
<Overlap Ratio: 0.8>

---

--- 363 --
Question ID: dc1ca5c1a1684ab9b0b714b1f9c92bcaae0dc7ba_13
Original Code:
```
def gen_output_by_receiver(receivers: dict):
    if len(receivers.keys()) == 0:
        return None
    else:
        outputs = []
        for _add in receivers.keys():
            _value = int(receivers[_add])
            _output = t.TxOutput(address=_add, value=_value)
            outputs.append(_output)
        return outputs
```


Overlapping Code:
```
ef gen_output_by_receiver(receivers: dict):
if len(receivers.keys()) == 0:
return None
else:
outputs = []
for _add in receivers.keys():
_value = int(receivers[_add])
_output = t.TxOutput(address=_add, value=_value)
outputs.append(_output)
return outp
```
<Overlap Ratio: 0.984251968503937>

---

--- 364 --
Question ID: 0fff128892f2692e647312f1466281599bd654fd_13
Original Code:
```
def test_lookup_inside_custom_generator():
    values = ['AA', 'BB', 'CC', 'DD', 'EE', 'FF', 'GG', 'HH', 'II', 'JJ']
    mapping = {2 * x.upper(): 2 * x for x in 'abcdefghij'}

    class QuuxGenerator(CustomGenerator):
        aa = SelectOne(values)
        bb = Lookup(aa, mapping)

    g = QuuxGenerator()
    items = list(g.generate(num=50, seed=12345))
    assert all([x.aa == x.bb.upper() for x in items])
```


Overlapping Code:
```
m_generator():
values = ['AA', 'BB', 'CC', 'DD', 'EE', 'FF', 'GG', 'HH', 'II', 'JJ']
mapping = {2 * x.upper(): 2 * x for x in 'abcdefghij'}
class QuuxGenerator(CustomGenerator):
aa = SelectOne(values)
bb = Lookup(aa, mapping)
g = QuuxGenerator()
items = list(g.generate(num=50, seed=12345))
assert al
```
<Overlap Ratio: 0.8152173913043478>

---

--- 365 --
Question ID: 3ca67e9442436a3a4c05f92ccc99c1b4150df427_9
Original Code:
```
def plot_and_get_real_data(row: int) -> (np.ndarray, np.ndarray):
    data = load_data()
    plot_real_data(data, row, row+1)
    return get_x_y(data, row)
```


Overlapping Code:
```
 (np.ndarray, np.ndarray):
data = load_data()
plot_real_data(data, row, row+1)
return get_x_y(data, 
```
<Overlap Ratio: 0.6993006993006993>

---

--- 366 --
Question ID: eba58f8d38f385cdc8f40025b6685d14d849ee19_17
Original Code:
```
def simulate_quantities_of_interest_superoperator2(U_final):
    """
    Calculates the quantities of interest from the propagator U_final

    Args:
        U_final = propagator (either unitary or superoperator)

    Returns
        phi_cond (float):   conditional phase (deg)
        L1      (float):    leakage
        L2      (float):    seepage
        avgatefid (float):  average gate fidelity in full space
        avgatefid_compsubspace (float):  average gate fidelity only in the computational subspace

    """

    phases = phases_from_superoperator(U_final)
    phi_cond = phases[-1]
    L1 = leakage_from_superoperator(U_final)
    L2 = seepage_from_superoperator(U_final)
    avgatefid = pro_avfid_superoperator_phasecorrected(U_final,phases)
    avgatefid_compsubspace = pro_avfid_superoperator_compsubspace_phasecorrected(U_final,L1,phases)     # leakage has to be taken into account, see Woods & Gambetta

    return {'phi_cond': phi_cond, 'L1': L1, 'L2': L2, 'avgatefid_pc': avgatefid, 'avgatefid_compsubspace_pc': avgatefid_compsubspace}
```


Overlapping Code:
```
erator2(U_final):
"""
Calculates the quantities of interest from the propagator U_final
Args:
U_final = propagator (either unitary or superoperator)
Returns
phi_cond (float): conditional phase (deg)
L1 (float): leakage
L2 (float): seepage
avgatefid (float): average gate fidelity in full space
avgatefid_compsubspace (float): average gate fidelity only in the computational subspace
"""
phases = phases_from_superoperator(U_final)
phi_cond = phases[-1]
L1 = leakage_from_superoperator(U_final)
L2 = seepage_from_superoperator(U_final)
avgatefid = pro_avfid_superoperator_phasecorrected(U_final,phases)
avgatefid_compsubspace = pro_avfid_superoperator_compsubspace_phasecorrected(U_final,L1,phases) # leakage has to be taken into account, see Woods & Gambetta
return {'phi_cond': phi_cond, 'L1': L1, 'L2': L2, 'avgatefid_pc': avgatefid, 'avgatefid_compsubspace_pc': avgatefid_compsubsp
```
<Overlap Ratio: 0.949516648764769>

---

--- 367 --
Question ID: d0fc5b2a0582cf1093b38de0c2b95db3cbd5563a_1
Original Code:
```
def run(args):
    if args.layout:
        import json
        args.attributes = True
        # Open the document, read the JSON
        layout = args.layout
        if not ':' in layout:
            layout = 'file:' + layout
        timelineDoc = urllib.request.urlopen(layout)
        timelineData = json.load(timelineDoc)
        # Get all componentIds mentioned in the constraints
        layoutComponentIds = list(map((lambda constraint: constraint['constraintId']), timelineData['constraints']))
        # Store a set of these into the ref-checker class
        RefDelegate2Immerse.constraintIds = set(layoutComponentIds)
    if not args.realtime:
        clock = clocks.CallbackPausableClock(clocks.FastClock())
    else:
        clock = clocks.CallbackPausableClock(clocks.SystemClock())
    
    d = Document(clock, idAttribute=NS_XML("id"))
    if args.tracefile:
        d.setTracefile(args.tracefile)
    if args.attributes:
        d.setDelegateFactory(RefDelegate2Immerse)
    d.setDelegateFactory(UpdateDelegate2Immerse, tag=NS_2IMMERSE("update"))
    try:
        url = args.document
        if not ':' in url:
            # Shortcut to allow specifying local files
            url = 'file:' + url
        d.loadDocument(url)
        d.prepareDocument()
        d.runDocument()
        assert d.isDocumentDone()
    finally:
        if args.dump:
            print('--------------------')
            print(d.dumps())
        if args.dumpfile:
            fp = open(args.dumpfile, 'w')
            fp.write(d.dumps())
            fp.close()
        d.setTracefile(None)
```


Overlapping Code:
```
run(args):
if args.layout:
import json
args.attributes = True
# Open the document, read the JSON
layout = args.layout
if not ':' in layout:
layout = 'file:' + layout
timelineDoc = urllib.request.urlopen(layout)
timelineData = json.load(timelineDoc)
# Get all componentIds mentioned in the constraints
layoutComponentIds = list(map((lambda constraint: constraint['constraintId']), timelineData['constraints']))
# Store a set of these into the ref-checker class
RefDelegate2Immerse.constraintIds = set(layoutComponentIds)
if not args.realtime:
clock = clocks.CallbackPausableClock(clocks.FastClock())
else:
clock = clocks.CallbackPausableClock(clocks.SystemClock())

d = Document(clock, idAttribute=NS_XML("id"))
if args.tracefile:
d.setTracefile(args.tracefile)
if args.attributes:
d.setDelegateFactory(RefDelegate2Immerse)
d.setDelegateFactory(UpdateDelegate2Immerse, tag=NS_2IMMERSE("update"))
try:
url = args.document
if not ':' in url:
# Shortcut to allow specifying local files
url = 'file:' + url
d.loadDocument(url)
d.prepareDocument()
d.runDocument()
assert d.isDocumentDone()
finally:
if args.dump:
print('--------------------')
print(d.dumps())
if args.dumpfile:
fp = open(args.dumpfile, 'w')
fp.write(d.dumps())
fp.close()
d.setTracefile(No
```
<Overlap Ratio: 0.994431185361973>

---

--- 368 --
Question ID: a81fb282ab8af0bfe6f5003c909b9087309fa022_0
Original Code:
```
def run_uvcontsub(args):
    args.outvis = args.uvdata[0]+'.contsub'
    if args.noredo and os.path.isdir(args.outvis):
        casalog.post('Skipping uvcontsub')
    else:
        uvcontsub(vis=args.uvdata[0], fitspw=args.fitspw, want_cont=False, 
                combine='spw', excludechans=True, fitorder=1)
```


Overlapping Code:
```
 = args.uvdata[0]+'.contsub'
if args.noredo and os.path.isdir(args.outvis):
casalog.post('Skipping uvcontsub')
else:
uvcontsub(vis=args.uvdata[0], fitspw=args.fitspw, want_cont=False, 
combine='spw', 
```
<Overlap Ratio: 0.7518796992481203>

---

--- 369 --
Question ID: 6f04f44a681cacfdcd3106446d2eb254f7035e11_3
Original Code:
```
def getDevice(token,serverip,devid):

  authheader = {'Authorization': token}

  url = 'http://'+serverip+'/things/'+devid

  try:
     response = requests.get(url, headers=authheader )
  except ConnectionError as ce:
     return None

  if response.status_code != 200:
     return None
  else:
     data = response.json()
     return data
```


Overlapping Code:
```
etDevice(token,serverip,devid):
authheader = {'Authorization': token}
url = 'http://'+serverip+'/things/'+devid
try:
response = requests.get(url, headers=authheader )
except ConnectionError as ce:
return None
if response.status_code != 200:
return None
else:
d
```
<Overlap Ratio: 0.87248322147651>

---

--- 370 --
Question ID: 711402f2be79eb5c292967d95f900d9626dcdb91_0
Original Code:
```
def jsonToMySQL(host, user, passwd, db_name, table_name):
    json_url = 'https://api.hearthstonejson.com/v1/latest/zhCN/cards.json'
    json_response = requests.get(json_url)
    #print (response.text)
    json_data = json_response.json()

    #link db
    db = MySQLdb.connect(host, user, passwd, db_name, use_unicode=True, charset="utf8")
    cursor = db.cursor()

    #delete already exist table
    cursor.execute("DROP TABLE IF EXISTS " + table_name)

    #create table
    sql_create_table = '''CREATE TABLE ''' + table_name + ''' (
             hs_jsonId INT,
             hs_dbfId INT,
             hs_id VARCHAR(225),
             hs_name VARCHAR(225),
             hs_cost INT,
             hs_rarity VARCHAR(225)) DEFAULT CHARSET=utf8'''

    header_tag_list = ('dbfId','id','name','cost','rarity')
    char_type_tags = ('id', 'name', 'rarity')

    cursor.execute(sql_create_table)

    #with open(json_file, 'r', encoding='UTF-8') as f:
    #    json_data = json.load(f)

    print (len(json_data))

    for i in range(0, len(json_data), 1):
    #for i in range(0, 10, 1):
        '''
        if 'dbfId' not in json_data[i] or 'name' not in json_data[i] or 'id' not in json_data[i]:
            print("data missing: jsonId="+str(i))
            continue
        '''
        data = {'id': i}
        for header_tag in header_tag_list:
            if header_tag in json_data[i]:
                data[header_tag] = str(json_data[i][header_tag])

        sql_pre_key = '(hs_jsonId'
        sql_pre_value = '(' + str(i)
        for key, value in data.items():
            sql_pre_key = sql_pre_key + ', hs_' + key
            if key in char_type_tags:
                sql_pre_value = sql_pre_value + ', "' + value + '"'
            else:
                sql_pre_value = sql_pre_value + ', ' + value
        sql_pre_key = sql_pre_key + ')'
        sql_pre_value = sql_pre_value + ')'

        '''
        data_jsonId = str(i)
        data_dbfId = str(json_data[i]['dbfId']) # 2539
        data_id = json_data[i]['id']            # AT_001
        data_name = json_data[i]['name']        # 炎枪术
        '''
        sql_insert = '''INSERT INTO ''' + table_name + sql_pre_key + ''' VALUES ''' + sql_pre_value
        print (sql_insert)

        try:
           # 执行sql语句
           cursor.execute(sql_insert)
           # 提交到数据库执行
           db.commit()
           print('ok')
        except:
           # Rollback in case there is any error
           db.rollback()
           print('err: jsonId=' + str(i))
           print (sql_insert)

    #disconnect db
    db.close()

    print('Done.')
```


Overlapping Code:
```
le_name):
json_url = 'https://api.hearthstonejson.com/v1/latest/zhCN/cards.json'
json_response = requests.get(json_url)
#print (response.text)
json_data = json_response.json()
#link db
db = MySQLdb.connect(host, user, passwd, db_name, use_unicode=True, charset="utf8")
cursor = db.cursor()
#delete already exist table
cursor.execute("DROP TABLE IF EXISTS " + table_name)
#create table
sql_create_table = '''CREATE TABLE ''' + table_name + ''' (
hs_jsonId INT,
hs_dbfId INT,
hs_id VARCHAR(225),
hs_name VARCHAR(225),
hs_cost INT,
hs_rarity VARCHAR(225)) DEFAULT CHARSET=utf8'''
header_tag_list = ('dbfId','id','name','cost','rarity')
char_type_tags = ('id', 'name', 'rarity')
cursor.execute(sql_create_table)
#with open(json_file, 'r', encoding='UTF-8') as f:
# json_data = json.load(f)
print (len(json_data))
for i in range(0, len(json_data), 1):
#for i in range(0, 10, 1):
'''
if 'dbfId' not in json_data[i] or 'name' not in json_data[i] or 'id' not in json_data[i]:
print("data missing: jsonId="+str(i))
continue
'''
data = {'id': i}
for header_tag in header_tag_list:
if header_tag in json_data[i]:
data[header_tag] = str(json_data[i][header_tag])i)
for key, value in data.items():
sql_pre_key = sql_pre_key + ', hs_' + key
if key in char_type_tags:
sql_pre_value = sql_pre_value + ', "' + value + '"'
else:
sql_pre_value = sql_pre_value + ', ' + value
sql_pre_key = sql_pre_key + ')'
sql_pre_value = sql_pre_value + ')'
'''
data_jsonId = str(i)
data_dbfId = str(json_data[i]['dbfId']) # 2539
data_id = json_data[i]['id'] # AT_001
data_name = json_data[i]['name'] # 炎枪术
'''
sql_insert = '''INSERT INTO ''' + table_name + sql_pre_key + ''' VALUES ''' + sql_pre_value
print (sql_insert)
try:
# 执行sql语句
cursor.execute(sql_insert)
# 提交到数据库执行
db.commit()
print('ok')
except:
# Rollback in case there is any error
db.rollback()
prin
```
<Overlap Ratio: 0.9403598971722366>

---

--- 371 --
Question ID: ccdf401e1a4453f505cfc4bbb99545ffdce75458_2
Original Code:
```
def filter_created_range(qs, _, value):
    gte, lte = value.get("gte"), value.get("lte")
    if gte:
        qs = qs.filter(created__date__gte=gte)
    if lte:
        qs = qs.filter(created__date__lte=lte)
    return qs
```


Overlapping Code:
```
ter_created_range(qs, _, value):
gte, lte = value.get("gte"), value.get("lte")
if gte:
qs = qs.filter(created__date__gte=gte)
if lte:
qs = qs.filter(c
```
<Overlap Ratio: 0.7936507936507936>

---

--- 372 --
Question ID: 7f29bffc7ead33753995a53e50a51fd006db7d57_0
Original Code:
```
def solve():
    part_one = True
    for n in numbers:
        for b in boards:
            if b.active and b.mark(n) and b.check_win():
                if part_one:
                    print(f"The following board won:{b}")
                    print(f"The last drawn number was {n}")
                    print(f"Sum of unmarked numbers on board: {(sum := b.sum())}")
                    print(f"The answer to part one: {sum}")
                    part_one = False
                if active_boards() > 1:
                    b.active = False
                    print(
                        f"A board was eliminated. Remaining boards: {active_boards()}"
                    )
                else:
                    print(f"The following was the last board:{b}")
                    print(f"The last drawn number was {n}")
                    print(f"Sum of unmarked numbers on board: {(sum := b.sum())}")
                    print(f"The answer to part two: {n*sum}")
                    return
```


Overlapping Code:
```
 in numbers:
for b in boards:
if b.active and b.mark(n) and b.check_win():
if part_one:
print(f"The following board won:{b}")
print(f"The last drawn number was {n}")
print(f"Sum of unmarked numbers on board: {(sum := b.sum())}")
print(f"The answer to part one: {sum}")
part_one = False
if active_boards() > 1:
b.active = False
print(
f"A board was eliminated. Remaining boards: {active_boards()}"
)
else:
print(f"The following was the last board:{b}")
print(f"The last drawn number was {n}")
print(f"Sum of unmarked numbers on board: {(sum := b.sum())}")
print(f"The answer to part two: {n*sum}")
ret
```
<Overlap Ratio: 0.9419152276295133>

---

--- 373 --
Question ID: 735e4ce2966a57519a06731bb9fa8b1621e352e4_8
Original Code:
```
def multipolygons(geometries):
    """Create multipolygons from arrays of polygons

    Parameters
    ----------
    geometries : array_like
        An array of polygons or coordinates (see polygons).
    """
    geometries = np.asarray(geometries)
    if not isinstance(geometries, Geometry) and np.issubdtype(
        geometries.dtype, np.number
    ):
        geometries = polygons(geometries)
    return lib.create_collection(geometries, GeometryType.MULTIPOLYGON)
```


Overlapping Code:
```
e multipolygons from arrays of polygons
Parameters
----------
geometries : array_like
An array of polygons or coordinates (see polygons).
"""
geometries = np.asarray(geometries)
if not isinstance(geometries, Geometry) and np.issubdtype(
geometries.dtype, np.number
):
geometries = polygons(geometries)
return lib.create_collection(geometries, GeometryType.MULT
```
<Overlap Ratio: 0.8823529411764706>

---

--- 374 --
Question ID: 60857cf700bb64c9c1be37fa96c09b36a657003c_0
Original Code:
```
def setup():
    pygame.init()
    viewport = (1024,768)
    pygame.display.set_mode(viewport, OPENGL | DOUBLEBUF)
    glLightfv(GL_LIGHT0, GL_POSITION,   (viewport[0]/2, 0, viewport[1]/2, 0.0))
    glLightfv(GL_LIGHT0, GL_AMBIENT,    (0.2, 0.2, 0.2, 1.0))
    glLightfv(GL_LIGHT0, GL_DIFFUSE,    (0.5, 0.5, 0.5, 1.0))
    glEnable(GL_LIGHT0)
    glEnable(GL_LIGHTING)
    glEnable(GL_COLOR_MATERIAL)
    glEnable(GL_DEPTH_TEST)
    glShadeModel(GL_SMOOTH)
    glEnable(GL_BLEND)
    glBlendFunc(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA)

    global clock
    clock   = pygame.time.Clock()
    
    global player
    player  = Player(0., 0.)
    
    global enemy
    enemy = Player(200., 0.)

    global trailMatrix
    trailMatrix	= {}
    
    global floor
    floor   = Floor(size=20, tileSize=10)
    
    global camera
    camera  = Camera(viewport, (floor.size*floor.tileSize, floor.size*floor.tileSize))
    camera.bindToPlayer(player)
    
    global playerEnabled
    playerEnabled = True
```


Overlapping Code:
```

pygame.display.set_mode(viewport, OPENGL | DOUBLEBUF)
glLightfv(GL_LIGHT0, GL_POSITION, (viewport[0]/2, 0, viewport[1]/2, 0.0))
glLightfv(GL_LIGHT0, GL_AMBIENT, (0.2, 0.2, 0.2, 1.0))
glLightfv(GL_LIGHT0, GL_DIFFUSE, (0.5, 0.5, 0.5, 1.0))
glEnable(GL_LIGHT0)
glEnable(GL_LIGHTING)
glEnable(GL_COLOR_MATERIAL)
glEnable(GL_DEPTH_TEST)
glShadeModel(GL_SMOOTH)
glEnable(GL_BLEND)
glBlendFunc(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA)
global clock
clock = pygame.time.Clock()

global player
player = Player(0., 0.)

global enemy
enemy = Player(200., 0.)
global trailMatrix
trailMatrix = {}

global floor
floor = Floor(size=20, tileSize=10)

global camera
camera = Camera(viewport, (floor.size*floor.tileSize, floor.size*floor.tileSize))
camera.bindToPlayer(pl
```
<Overlap Ratio: 0.8865248226950354>

---

--- 375 --
Question ID: 76059e04225efb2185b89c25bc99860d1bb2401d_1
Original Code:
```
def validate_tenant(cmd, namespace):
    """
    Make sure tenant is a GUID. If domain name is provided, resolve to GUID.
    https://docs.microsoft.com/en-us/azure/active-directory/develop/v2-protocols-oidc#fetch-the-openid-connect-metadata-document
    """
    if namespace.tenant is not None and not _is_guid(namespace.tenant):
        import requests
        active_directory_endpoint = cmd.cli_ctx.cloud.endpoints.active_directory
        url = '{}/{}/.well-known/openid-configuration'.format(active_directory_endpoint, namespace.tenant)
        metadata = requests.get(url, verify=not should_disable_connection_verify()).json()

        # Example issuer: https://sts.windows.net/72f988bf-86f1-41af-91ab-2d7cd011db47/
        tenant_id = metadata['issuer'].split("/")[3]

        logger.debug('Resolve tenant domain name %s to GUID %s', namespace.tenant, tenant_id)
        namespace.tenant = tenant_id
```


Overlapping Code:
```
mespace):
"""
Make sure tenant is a GUID. If domain name is provided, resolve to GUID.
https://docs.microsoft.com/en-us/azure/active-directory/develop/v2-protocols-oidc#fetch-the-openid-connect-metadata-document
"""
if namespace.tenant is not None and not _is_guid(namespace.tenant):
import requests
active_directory_endpoint = cmd.cli_ctx.cloud.endpoints.active_directory
url = '{}/{}/.well-known/openid-configuration'.format(active_directory_endpoint, namespace.tenant)
metadata = requests.get(url, verify=not should_disable_connection_verify()).json()
# Example issuer: https://sts.windows.net/72f988bf-86f1-41af-91ab-2d7cd011db47/
tenant_id = metadata['issuer'].split("/")[3]
logger.debug('Resolve tenant domain name %s to GUID %s', namespace.tenant, tenant_id)
namespace.tenant = te
```
<Overlap Ratio: 0.9585870889159561>

---

--- 376 --
Question ID: dabd40c6bbf7161f44be3e67813ac8040a7cc8bd_6
Original Code:
```
def test_content_type():
    r = Response()
    # default ctype and charset
    eq_(r.content_type, 'text/html')
    eq_(r.charset, 'UTF-8')
    # setting to none, removes the header
    r.content_type = None
    eq_(r.content_type, None)
    eq_(r.charset, None)
    # can set missing ctype
    r.content_type = None
    eq_(r.content_type, None)
```


Overlapping Code:
```
t_type():
r = Response()
# default ctype and charset
eq_(r.content_type, 'text/html')
eq_(r.charset, 'UTF-8')
# setting to none, removes the header
r.content_type = None
eq_(r.content_type, None)
eq_(r.charset, None)
# can set missing ctype
r.content_typ
```
<Overlap Ratio: 0.8382838283828383>

---

--- 377 --
Question ID: 6b1566af0a9718133065c11ba289daa58900898d_21
Original Code:
```
def test_reg_user_cannot_get_another_org_id_quota(reg_user_headers):
    """ regular users cannot see an organization's cve id quota they don't belong to """
    org = str(uuid.uuid4())
    user = str(uuid.uuid4())
    create_new_user_with_new_org_by_shortname(org, user)
    res = requests.get(
        f'{env.AWG_BASE_URL}{ORG_URL}/{org}/id_quota',
        headers=reg_user_headers
    )
    assert res.status_code == 403
    response_contains_json(res, 'error', 'NOT_SAME_ORG_OR_SECRETARIAT')
```


Overlapping Code:
```
nother_org_id_quota(reg_user_headers):
""" regular users cannot see an organization's cve id quota they don't belong to """
org = str(uuid.uuid4())
user = str(uuid.uuid4())
create_new_user_with_new_org_by_shortname(org, user)
res = requests.get(
f'{env.AWG_BASE_URL}{ORG_URL}/{org}/id_quota',
headers=reg_user_headers
)
assert res.status_code == 403
response_contains_json(res, 'error', 'NOT_SAME_ORG_OR_SECRETARIAT'
```
<Overlap Ratio: 0.930648769574944>

---

--- 378 --
Question ID: 19849eb0845aa6a14f76fdb2455c1645b497a337_3
Original Code:
```
def analyze_swaps(data):
    swaps = defaultdict(lambda: 0)
    frequency = defaultdict(lambda: 0)
    frequency_count = 0
    for elem in data:
        orig_labels = elem['groundtruth']
        reco_labels = elem['recognized']
        for i in xrange(len(orig_labels)):
            frequency[orig_labels[i]] += 1
            frequency_count += 1
            if orig_labels[i] != reco_labels[i]:
                swaps[(orig_labels[i], reco_labels[i])] += 1
    print("Frequency:")
    frequency = sorted(frequency.items(), key=operator.itemgetter(1), reverse=True)
    for (label,count) in frequency:
        print("\t{}: {:.3f}".format(label, count / float(frequency_count)))

    print("Swaps:")
    swaps = sorted(swaps.items(), key=operator.itemgetter(1), reverse=True)
    for swap in swaps:
        print("\t{} -> {} : {}".format(swap[0][0], swap[0][1], swap[1]))
```


Overlapping Code:
```
def analyze_swaps(data):
swaps = defaultdict(lambda: 0)
frequency = defaultdict(lambda: 0)
frequency_count = 0
for elem in data:
orig_labels = elem['groundtruth']
reco_labels = elem['recognized']
for i in xrange(len(orig_labels)):
frequency[orig_labels[i]] += 1
frequency_count += 1
if orig_labels[i] != reco_labels[i]:
swaps[(orig_labels[i], reco_labels[i])] += 1
print("Frequency:")
frequency = sorted(frequency.items(), key=operator.itemgetter(1), reverse=True)
for (label,count) in frequency:
print("\t{}: {:.3f}".format(label, count / float(frequency_count)))
print("Swaps:")
swaps = sorted(swaps.items(), key=operator.itemgetter(1), reverse=True)
for swap in swaps:
print("\t{} -> {} : {}".form
```
<Overlap Ratio: 0.9510869565217391>

---

--- 379 --
Question ID: 6b9c14472495851ac67e4282969ef3aee4d1ddcb_0
Original Code:
```
def chanceX(dice, x):
    # first, set up base cases
    # account for only one die passed
    # also accounts for recursive base
    if isinstance(dice, tuple):
        dice = list(dice)
    if not isinstance(dice, list):
        dice = [dice]

    # each die can be at the minimum 1, so the sum cannot be less than the number of dice
    if x < len(dice):
        return 0

    # is it possible for the dice to sum up to x?
    max = 0
    for die in dice:
        max += die
    if max < x:
        return 0

    if len(dice) == 1:
        if dice[0] < x:
            return 0 # cannot roll x, as dice has no side for it
        else:
            return 1 / dice[0] # one side has x
    """
    For multiple dice,
    compute the chance recursively.
    There may be a way to do this
    iteratively, or with a basic formula,
    but I'm not sure how I would do that.
    I assume the chance corresponds to the surface area of a plane,
    as when the rolls required are graphed in cartesian coordinates,
    the points form a slanted plane.
    """
    chance = 0
    otherDice = dice.copy()
    lockedIn = otherDice.pop() # removes last die

    # vary the value of the die removed
    for i in range(1, lockedIn + 1):
        # compute the probability that the other dice can sum to the x after the locked in value is added
        chanceOthers = chanceX(otherDice, x - i)
        #print("The chance of rolling {} using {}, given {} is {}".format(x, otherDice, i, chanceOthers / lockedIn))
        chance += chanceOthers / lockedIn # || to chances together
        # chance to roll (x -i) times the chance to roll with the other dice, times the chance to roll i with this die

    return chance
```


Overlapping Code:
```
base cases
# account for only one die passed
# also accounts for recursive base
if isinstance(dice, tuple):
dice = list(dice)
if not isinstance(dice, list):
dice = [dice]
# each die can be at the minimum 1, so the sum cannot be less than the number of dice
if x < len(dice):
return 0
# is it possible for the dice to sum up to x?
max = 0
for die in dice:
max += die
if max < x:
return 0
if len(dice) == 1:
if dice[0] < x:
return 0 # cannot roll x, as dice has no side for it
else:
return 1 / dice[0] # one side has x
"""
For multiple dice,
compute the chance recursively.
There may be a way to do this
iteratively, or with a basic formula,
but I'm not sure how I would do that.
I assume the chance corresponds to the surface area of a plane,
as when the rolls required are graphed in cartesian coordinates,
the points form a slanted plane.
"""
chance = 0
otherDice = dice.copy()
lockedIn = otherDice.pop() # removes last die
# vary the value of the die removed
for i in range(1, lockedIn + 1):
# compute the probability that the other dice can sum to the x after the locked in value is added
chanceOthers = chanceX(otherDice, x - i)
#print("The chance of rolling {} using {}, given {} is {}".format(x, otherDice, i, chanceOthers / lockedIn))
chance += chanceOthers / lockedIn # || to chances together
# chance to roll (x -i) times the chance to roll with the other dice, times the chance to roll i wi
```
<Overlap Ratio: 0.9569377990430622>

---

--- 380 --
Question ID: d44e1dfa133bbb79f09ce7d952a2b5ba90ccb66a_2
Original Code:
```
def test_commmit_requires_project_id(test_db):
    commit_id = get_dummy_hash()

    try:
        commit = Commit(id=commit_id, filename='model.onnx')
        test_db.session.add(commit)
        test_db.session.commit()
    except exc.IntegrityError:
        pass  # This exception should be thrown
```


Overlapping Code:
```
(test_db):
commit_id = get_dummy_hash()
try:
commit = Commit(id=commit_id, filename='model.onnx')
test_db.session.add(commit)
test_db.session.commit()
except exc.IntegrityError:
pass # This exception 
```
<Overlap Ratio: 0.7936507936507936>

---

--- 381 --
Question ID: bcf257a1f3e9e47e79f5adccc4cb7718c993bdb6_3
Original Code:
```
def _insert_widget_or_layout(layout: QLayout, item: WidgetOrLayout, *args, **kwargs):
    if isinstance(item, QWidget):
        layout.addWidget(item, *args, **kwargs)
    elif isinstance(item, QLayout):
        # QLayout and some subclasses (like QFormLayout) omit this method,
        # and will crash at runtime.
        layout.addLayout(item, *args, **kwargs)
    else:
        raise TypeError(item)
```


Overlapping Code:
```
 QLayout, item: WidgetOrLayout, *args, **kwargs):
if isinstance(item, QWidget):
layout.addWidget(item, *args, **kwargs)
elif isinstance(item, QLayout):
# QLayout and some subclasses (like QFormLayout) omit this method,
# and will crash at runtime.
layout.addLayout(item, *args, **kwargs)
else:
raise 
```
<Overlap Ratio: 0.8547008547008547>

---

--- 382 --
Question ID: a2c535b27a5ceabf9aa8b2875dae0c423b1a2c13_1
Original Code:
```
def deploy():
    regex = re.compile('^\w+$')
    apps = sorted(file for file in os.listdir(apath(r=request)) if regex.match(file))
    form = SQLFORM.factory(
        Field('appcfg',default=GAE_APPCFG,label='Path to appcfg.py',
              requires=EXISTS(error_message=T('file not found'))),
        Field('google_application_id',requires=IS_ALPHANUMERIC()),
        Field('applications','list:string',
              requires=IS_IN_SET(apps,multiple=True),
              label=T('web2py apps to deploy')),
        Field('email',requires=IS_EMAIL(),label=T('GAE Email')),
        Field('password','password',requires=IS_NOT_EMPTY(),label=T('GAE Password')))
    cmd = output = errors= ""
    if form.accepts(request,session):
        try:
            kill()
        except:
            pass
        ignore_apps = [item for item in apps \
                           if not item in form.vars.applications]
        regex = re.compile('\(applications/\(.*')
        yaml = apath('../app.yaml', r=request)
        if not os.path.exists(yaml):
            example = apath('../app.example.yaml', r=request)
            shutil.copyfile(example,yaml)
        data = read_file(yaml)
        data = re.sub('application:.*','application: %s' % form.vars.google_application_id,data)
        data = regex.sub('(applications/(%s)/.*)|' % '|'.join(ignore_apps),data)
        write_file(yaml, data)

        path = request.env.applications_parent
        cmd = '%s --email=%s --passin update %s' % \
            (form.vars.appcfg, form.vars.email, path)
        p = cache.ram('gae_upload',
                      lambda s=subprocess,c=cmd:s.Popen(c, shell=True,
                                                        stdin=s.PIPE,
                                                        stdout=s.PIPE,
                                                        stderr=s.PIPE, close_fds=True),-1)
        p.stdin.write(form.vars.password+'\n')
        fcntl.fcntl(p.stdout.fileno(), fcntl.F_SETFL, os.O_NONBLOCK)
        fcntl.fcntl(p.stderr.fileno(), fcntl.F_SETFL, os.O_NONBLOCK)
    return dict(form=form,command=cmd)
```


Overlapping Code:
```
sorted(file for file in os.listdir(apath(r=request)) if regex.match(file))
form = SQLFORM.factory(
Field('appcfg',default=GAE_APPCFG,label='Path to appcfg.py',
requires=EXISTS(error_message=T('file not found'))),
Field('google_application_id',requires=IS_ALPHANUMERIC()),
Field('applications','list:string',
requires=IS_IN_SET(apps,multiple=True),
label=T('web2py apps to deploy')),
Field('email',requires=IS_EMAIL(),label=T('GAE Email')),
Field('password','password',requires=IS_NOT_EMPTY(),label=T('GAE Password')))
cmd = output = errors= ""
if form.accepts(request,session):
try:
kill()
except:
pass
ignore_apps = [item for item in apps \
if not item in form.vars.applications]
regex = re.compile('\(applications/\(.*')
yaml = apath('../app.yaml', r=request)
if not os.path.exists(yaml):
example = apath('../app.example.yaml', r=request)
shutil.copyfile(example,yaml)
data = read_file(yaml)
data = re.sub('application:.*','application: %s' % form.vars.google_application_id,data)
data = regex.sub('(applications/(%s)/.*)|' % '|'.join(ignore_apps),data)
write_file(yaml, data)
path = request.env.applications_parent
cmd = '%s --email=%s --passin update %s' % \
(form.vars.appcfg, form.vars.email, path)
p = cache.ram('gae_upload',
lambda s=subprocess,c=cmd:s.Popen(c, shell=True,
stdin=s.PIPE,
stdout=s.PIPE,
stderr=s.PIPE, close_fds=True),-1)
p.stdin.write(form.vars.password+'\n')
fcntl.fcntl(p.stdout.fileno(), fcntl.F_SETFL, os.O_NONBLOCK)
fcntl.fcntl(p.stderr.fileno(), fcntl.F_SETFL, os.O_NON
```
<Overlap Ratio: 0.9433962264150944>

---

--- 383 --
Question ID: 132e8b8b3fa5163f9210a6d1adca8aa2555545a6_38
Original Code:
```
def test_bind2():
    s = tir.Schedule(element_wise_compute_at_split, debug_mask="all")
    _, j0 = s.get_loops(s.get_block("B"))
    _, j1o, _ = s.get_loops(s.get_block("C"))
    s.bind(j0, "threadIdx.x")
    s.bind(j1o, "threadIdx.x")
    tvm.ir.assert_structural_equal(s.mod["main"], element_wise_compute_at_split_j0_j1o_bound)
    verify_trace_roundtrip(s, mod=element_wise_compute_at_split)
```


Overlapping Code:
```
 tir.Schedule(element_wise_compute_at_split, debug_mask="all")
_, j0 = s.get_loops(s.get_block("B"))
_, j1o, _ = s.get_loops(s.get_block("C"))
s.bind(j0, "threadIdx.x")
s.bind(j1o, "threadIdx.x")
tvm.ir.assert_structural_equal(s.mod["main"], element_wise_compute_at_split_j0_j1o_bound)
verify_trace_roundtrip(s
```
<Overlap Ratio: 0.8446866485013624>

---

