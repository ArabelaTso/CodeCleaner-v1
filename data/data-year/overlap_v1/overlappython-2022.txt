--- 0 --
Question ID: 6744c5a8846b111b0170e462d02bdfc5ecf29425_0
Original Code:
```
def get_sub_package(packages_path: str) -> str:
    package_cmd = "--package"
    packages = os.listdir(packages_path)
    available_packages = ", ".join(packages)

    if package_cmd not in sys.argv:
        raise RuntimeError(
            f"Specify which package to build with '{package_cmd} <PACKAGE NAME>'. "
            f"Available packages are: {available_packages}"
        )

    index = sys.argv.index(package_cmd)
    sys.argv.pop(index)  # Removes the switch
    package = sys.argv.pop(index)  # Returns the element after the switch
    if package not in packages:
        raise RuntimeError(
            f"Unknown package '{package}'. Available packages are: {available_packages}"
        )
    return package
```


Overlapping Code:
```
get_sub_package(packages_path: str) -> str:
package_cmd = "--package"
packages = os.listdir(packages_path)
available_packages = ", ".join(packages)
if package_cmd not in sys.argv:
raise RuntimeError(
f"Specify which package to build with '{package_cmd} <PACKAGE NAME>'. "
f"Available packages are: {available_packages}"
)
index = sys.argv.index(package_cmd)
sys.argv.pop(index) # Removes the switch
package = sys.argv.pop(index) # Returns the element after the switch
if package not in packages:
raise RuntimeError(
f"Unknown package '{package}'. Available packages are: {available_packages}"
)
retur
```
<Overlap Ratio: 0.9787928221859706>

---

--- 1 --
Question ID: 75f79ea2cbdc8f137ac84d9a747dff9ee3623a4d_2
Original Code:
```
def _extract_nth_band(subdataset, xy_bbox, rad_coefs):
    x0, y0, x1, y1 = xy_bbox
    row_start, col_start = subdataset.index(x0, y0)
    row_stop, col_stop = subdataset.index(x1, y1)
    arr = subdataset.read(
        1,
        window=Window.from_slices(
            (row_start, row_stop + 1),
            (col_start, col_stop + 1)
        )
    )
    # Turn DNs into TOA reflectances
    band_array = _digital_number_to_reflectance(arr, *rad_coefs)
    return band_array
```


Overlapping Code:
```
ract_nth_band(subdataset, xy_bbox, rad_coefs):
x0, y0, x1, y1 = xy_bbox
row_start, col_start = subdataset.index(x0, y0)
row_stop, col_stop = subdataset.index(x1, y1)
arr = subdataset.read(
1,
window=Window.from_slices(
(row_start, row_stop + 1),
(col_start, col_stop + 1)
)
)
# Turn DNs into TOA reflectances
band_array = _digital_number_to_reflectance(arr, *r
```
<Overlap Ratio: 0.9113924050632911>

---

--- 2 --
Question ID: 893e690ec93465ad034d4affcca8275c09a0ee45_2
Original Code:
```
def find_files(src, src_ext_name, use_start=False):
    """
    Method to find files with given extension
    """
    result = []
    for root, dirs, files in os.walk(src):
        for file in files:
            if file == src_ext_name or file.endswith(src_ext_name):
                result.append(os.path.join(root, file))
            elif use_start and file.startswith(src_ext_name):
                result.append(os.path.join(root, file))
    return result
```


Overlapping Code:
```
lse):
"""
Method to find files with given extension
"""
result = []
for root, dirs, files in os.walk(src):
for file in files:
if file == src_ext_name or file.endswith(src_ext_name):
result.append(os.path.join(root, file))
elif use_start and file.startswith(src_ext_name):
result.append(os.path.join(root, file))
return result
```
<Overlap Ratio: 0.876010781671159>

---

--- 3 --
Question ID: 69e8820ba11c4ccbf5c86951577451bb4f76b037_0
Original Code:
```
def replace_class(full_path: str, new_module):
    def replace_class_instance(func):
        @functools.wraps(func)
        async def with_replaced_class(*args, **kwargs):
            class_name = full_path.split(".")[-1]
            module_name = ".".join(full_path.split(".")[:-1])
            replaced_class = getattr(sys.modules[module_name], class_name)
            setattr(sys.modules[module_name], class_name, new_module)

            try:
                if inspect.iscoroutinefunction(func):
                    result = await func(*args, **kwargs)
                else:
                    result = func(*args, **kwargs)
            finally:
                setattr(sys.modules[module_name], class_name, replaced_class)

            return result

        return with_replaced_class

    return replace_class_instance
```


Overlapping Code:
```
lace_class(full_path: str, new_module):
def replace_class_instance(func):
@functools.wraps(func)
async def with_replaced_class(*args, **kwargs):
class_name = full_path.split(".")[-1]
module_name = ".".join(full_path.split(".")[:-1])
replaced_class = getattr(sys.modules[module_name], class_name)
setattr(sys.modules[module_name], class_name, new_module)
try:
if inspect.iscoroutinefunction(func):
result = await func(*args, **kwargs)
else:
result = func(*args, **kwargs)
finally:
setattr(sys.modules[module_name], class_name, replaced_class)
return result
return with_replaced_class
return replace_cl
```
<Overlap Ratio: 0.9693053311793215>

---

--- 4 --
Question ID: 65fba4fa18d8eb795a7a89ab2d5dde09b9ca051b_0
Original Code:
```
def main():
    if len(sys.argv) == 1:
        raise ValueError("Specify csv files to include as command line arguments.")

    csvs = []
    for path in sys.argv[1:]:
        p = pathlib.Path(path)
        if p.is_dir():
            csvs.extend(p.glob("*.csv"))
        else:
            csvs.append(p)

    all_data = MultiStats.from_recorded_data(*csvs)

    fig = plot_detection_fraction(all_data)
    fig.set_size_inches(15, 5)
    fig.savefig(OUT_DIR / "grouped_detection_fractions.png", bbox_inches='tight', dpi=200)

    plt.show()
```


Overlapping Code:
```
in():
if len(sys.argv) == 1:
raise ValueError("Specify csv files to include as command line arguments.")
csvs = []
for path in sys.argv[1:]:
p = pathlib.Path(path)
if p.is_dir():
csvs.extend(p.glob("*.csv"))
else:
csvs.append(p)
all_data = MultiStats.from_recorded_data(*csvs)
fig = plot_detection_fraction(all_data)
fig.set_size_inches(15, 5)
fig.savefig(OUT_DIR / "grouped_detection_fractions.png", bbox_inch
```
<Overlap Ratio: 0.9172259507829977>

---

--- 5 --
Question ID: 2618c160604c668f1d27543cfcb9010f90910789_0
Original Code:
```
def get_coordinates_key_for_expression(
        *,
        x: Union[int, Int],
        y: Union[int, Int]) -> ExpressionString:
    """
    Get a key string for the expression from the x and y coordinates.

    Parameters
    ----------
    x : int or Int
        X-coordinate.
    y : int or Int
        Y-coordinate.

    Returns
    -------
    key_exp_str : ExpressionString
        Key expression string.
    """
    from apysc._type.variable_name_interface import VariableNameInterface
    if isinstance(x, VariableNameInterface):
        x_str: str = x.variable_name
    else:
        x_str = str(x)
    if isinstance(y, VariableNameInterface):
        y_str: str = y.variable_name
    else:
        y_str = str(y)
    key_exp_str: ExpressionString = ExpressionString(
        value=f'String({x_str}) + "_" + String({y_str})')
    return key_exp_str
```


Overlapping Code:
```
es_key_for_expression(
*,
x: Union[int, Int],
y: Union[int, Int]) -> ExpressionString:
"""
Get a key string for the expression from the x and y coordinates.
Parameters
----------
x : int or Int
X-coordinate.
y : int or Int
Y-coordinate.
Returns
-------
key_exp_str : ExpressionString
Key expression string.
"""
from apysc._type.variable_name_interface import VariableNameInterface
if isinstance(x, VariableNameInterface):
x_str: str = x.variable_name
else:
x_str = str(x)
if isinstance(y, VariableNameInterface):
y_str: str = y.variable_name
else:
y_str = str(y)
key_exp_str: ExpressionString = ExpressionString(
value=f'String({x_str}) + "_" + Strin
```
<Overlap Ratio: 0.9312320916905444>

---

--- 6 --
Question ID: 5394a76ea2a59c9e92e104f1f4a85cc147468ebc_18
Original Code:
```
def compute_precision_recall(cm: np.ndarray) -> Tuple[float, float]:
    """ computes precision and recall from a confusion matrix """
    tn = cm[0, 0]
    tp = cm[1, 1]
    fp = cm[0, 1]
    fn = cm[1, 0]

    precision = tp / get_denominator(tp + fp)
    recall = tp / get_denominator(tp + fn)
    return precision, recall
```


Overlapping Code:
```
_precision_recall(cm: np.ndarray) -> Tuple[float, float]:
""" computes precision and recall from a confusion matrix """
tn = cm[0, 0]
tp = cm[1, 1]
fp = cm[0, 1]
fn = cm[1, 0]
precision = tp / get_denominator(tp + fp)
recall = tp / get_denominator(tp 
```
<Overlap Ratio: 0.8595890410958904>

---

--- 7 --
Question ID: fee5495bb5c9ee33876aa22c6a6e792cb935d8d8_0
Original Code:
```
def handle_csar(path, parsed_params):
    """Handles CSAR (multi-file) ADTs and returns any errors caught
    :params: path, parsed_params
    :type: string, dictionary
    :return: template

    | parsed_params: dictionary containing the input to change
    | path: local or remote path to the file to parse
    """
    errors = csar_validation(path, parsed_params)
    if errors:
        raise MultiError(errors, "Cannot parse CSAR, issues in templates...")
        
    template = parser.get_template(path, parsed_params)

    template.nodetemplates = get_concrete_nodes(template)

    return template
```


Overlapping Code:
```

"""Handles CSAR (multi-file) ADTs and returns any errors caught
:params: path, parsed_params
:type: string, dictionary
:return: template
| parsed_params: dictionary containing the input to change
| path: local or remote path to the file to parse
"""
errors = csar_validation(path, parsed_params)
if errors:
raise MultiError(errors, "Cannot parse CSAR, issues in templates...")

template = parser.get_template(path, parsed_params)
template.nodetemplates = get_concrete_nodes(template)
return template
```
<Overlap Ratio: 0.931098696461825>

---

--- 8 --
Question ID: 6cd976e98f8d397ebdfa4e36ed9da1883d4db478_1
Original Code:
```
def average_gradients(tower_grads):
    average_grads = []
    for grad_and_vars in zip(*tower_grads):
        grads = []
        for g, _ in grad_and_vars:
            expanded_g = tf.expand_dims(g, 0)
            grads.append(expanded_g)
        grad = tf.concat(grads, 0)
        grad = tf.reduce_mean(grad, 0)
        v = grad_and_vars[0][1]
        grad_and_var = (grad, v)
        average_grads.append(grad_and_var)
    return average_grads
```


Overlapping Code:
```
def average_gradients(tower_grads):
average_grads = []
for grad_and_vars in zip(*tower_grads):
grads = []
for g, _ in grad_and_vars:
expanded_g = tf.expand_dims(g, 0)
grads.append(expanded_g)
grad = tf.concat(grads, 0)
grad = tf.reduce_mean(grad, 0)
v = grad_and_vars[0][1]
grad_and_var = (grad, v)
average_grads.append(grad_and_var)
return average_grads
```
<Overlap Ratio: 1.0>

---

--- 9 --
Question ID: f571a3dc1cc6295799a0201b4c2ed4bebb3357b5_2
Original Code:
```
def build_linux(workingPath):
    arch = 'x86_64'
    build_one_arch(workingPath, 'Debug', arch)
    
    build_one_arch(workingPath, 'Release', arch)
```


Overlapping Code:
```

arch = 'x86_64'
build_one_arch(workingPath, 'Debug', arch)

build_one_arch(workingPath, 'Release', 
```
<Overlap Ratio: 0.746268656716418>

---

--- 10 --
Question ID: 7e17cd30c7fdc3f405c26cbaec248033cac05183_1
Original Code:
```
def __test_epoch(student_net, testloader, device, criterion):
    student_net.eval()
    test_loss = 0
    correct = 0
    total = 0
    with torch.no_grad():
        for batch_idx, (inputs, targets) in enumerate(testloader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = student_net(inputs)
            # loss = criterion(outputs, targets)

            # test_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

            progress_bar(batch_idx,
                         len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)' %
                         (test_loss / (batch_idx + 1), 100. * correct / total,
                          correct, total))

    # Save checkpoint.
    acc = 100. * correct / total
```


Overlapping Code:
```
och(student_net, testloader, device, criterion):
student_net.eval()
test_loss = 0
correct = 0
total = 0
with torch.no_grad():
for batch_idx, (inputs, targets) in enumerate(testloader):
inputs, targets = inputs.to(device), targets.to(device)
outputs = student_net(inputs)
# loss = criterion(outputs, targets)
# test_loss += loss.item()
_, predicted = outputs.max(1)
total += targets.size(0)
correct += predicted.eq(targets).sum().item()
progress_bar(batch_idx,
len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)' %
(test_loss / (batch_idx + 1), 100. * correct / total,
correct, total))
# Save checkpoint.
acc = 100. * correct / to
```
<Overlap Ratio: 0.9751937984496124>

---

--- 11 --
Question ID: 525b8ac86d181a78d28a50cd33cd89141aeb42c8_5
Original Code:
```
@pytest.mark.asyncio
async def test_command_pdelhook(tile38):
    response = (
        await tile38.setchan(name).within(key).circle(52.25, 13.37, 100).activate()
    )
    assert response.ok

    response = await tile38.chans()
    assert response.ok
    assert len(response.chans) == 1

    response = await tile38.pdelchan("*")
    assert response.ok

    response = await tile38.chans()
    assert response.ok
    assert len(response.chans) == 0
```


Overlapping Code:
```
 test_command_pdelhook(tile38):
response = (
await tile38.setchan(name).within(key).circle(52.25, 13.37, 100).activate()
)
assert response.ok
response = await tile38.chans()
assert response.ok
assert len(response.chans) == 1
response = await tile38.pdelchan("*")
assert response.ok
response = await tile38.chans()
assert response.ok
assert len(response.chans
```
<Overlap Ratio: 0.9086294416243654>

---

--- 12 --
Question ID: f2796ea144ad193df317596da903d1ebea84da24_12
Original Code:
```
@pytest.mark.parametrize('contour_plot_2d', [kde_contour_plot_2d,
                                             fastkde_contour_plot_2d])
@pytest.mark.parametrize('levels', [[0.9],
                                    [0.9, 0.6],
                                    [0.9, 0.6, 0.3],
                                    [0.9, 0.7, 0.5, 0.3]])
def test_contour_plot_2d_levels(contour_plot_2d, levels):
    try:
        np.random.seed(42)
        x = np.random.randn(1000)
        y = np.random.randn(1000)
        cmap = plt.cm.viridis

        ax1 = plt.subplot(211)
        contour_plot_2d(ax1, x, y, levels=levels, cmap=cmap)
        ax2 = plt.subplot(212)
        contour_plot_2d(ax2, x, y, levels=levels, cmap=cmap, fc=None)

        # assert that color between filled and unfilled contours matches
        # first level
        color1 = ax1.get_children()[0].get_facecolor()  # filled face color
        color2 = ax2.get_children()[0].get_edgecolor()  # unfilled line color
        assert_array_equal(color1, color2)
        # last level
        color1 = ax1.get_children()[len(levels)-1].get_facecolor()
        color2 = ax2.get_children()[len(levels)-1].get_edgecolor()
        assert_array_equal(color1, color2)

        plt.close("all")

    except ImportError:
        if 'fastkde' not in sys.modules:
            pass
```


Overlapping Code:
```
pytest.mark.parametrize('contour_plot_2d', [kde_contour_plot_2d,
fastkde_contour_plot_2d])
@pytest.mark.parametrize('levels', [[0.9],
[0.9, 0.6],
[0.9, 0.6, 0.3],
[0.9, 0.7, 0.5, 0.3]])
def test_contour_plot_2d_levels(contour_plot_2d, levels):
try:
np.random.seed(42)
x = np.random.randn(1000)
y = np.random.randn(1000)
cmap = plt.cm.viridis
ax1 = plt.subplot(211)
contour_plot_2d(ax1, x, y, levels=levels, cmap=cmap)
ax2 = plt.subplot(212)
contour_plot_2d(ax2, x, y, levels=levels, cmap=cmap, fc=None)
# assert that color between filled and unfilled contours matches
# first level
color1 = ax1.get_children()[0].get_facecolor() # filled face color
color2 = ax2.get_children()[0].get_edgecolor() # unfilled line color
assert_array_equal(color1, color2)
# last level
color1 = ax1.get_children()[len(levels)-1].get_facecolor()
color2 = ax2.get_children()[len(levels)-1].get_edgecolor()
assert_array_equal(color1, color2)
plt.close("all")
except ImportError:
if 'fastkde' not in sys.modules:
pa
```
<Overlap Ratio: 0.9969818913480886>

---

--- 13 --
Question ID: 107b1786a4aef1e85b9f701b0d28b1fe33f5ad08_0
Original Code:
```
@contextmanager
def timing():
    t0 = time.time()
    yield lambda: (t1 - t0)
    t1 = time.time()
```


Overlapping Code:
```
@contextmanager
def timing():
t0 = time.time()
yield lambda: (t1 - t
```
<Overlap Ratio: 0.7816091954022989>

---

--- 14 --
Question ID: fa07c76034d9f89dd6b8009b47bc725883385a56_7
Original Code:
```
def test_list_with_registry(baz):
    data = get_data(baz, bar=True)
    hp = ParentListHP.create(data={'foos': data})
    assert isinstance(hp.foos, list)
    assert len(hp.foos) == 2
    foo = hp.foos[0]
    assert isinstance(foo, Foo)
    assert foo.baz == baz

    bar = hp.foos[1]
    assert isinstance(bar, Bar)
    assert bar.baz == baz
```


Overlapping Code:
```
data = get_data(baz, bar=True)
hp = ParentListHP.create(data={'foos': data})
assert isinstance(hp.foos, list)
assert len(hp.foos) == 2
foo = hp.foos[0]
assert isinstance(foo, Foo)
assert foo.baz == baz
bar = hp.foos[1]
assert isinstance(bar, Bar)
assert bar.baz 
```
<Overlap Ratio: 0.8675496688741722>

---

--- 15 --
Question ID: ac89e0990ef502ce2032982496fc9481e356bb33_6
Original Code:
```
@pytest.mark.django_db(transaction=True)
def test_author_insert_notify_in_transaction(pg_connection):
    with atomic():
        author = Author.objects.create(name='Billy')
    pg_connection.poll()
    assert 1 == len(pg_connection.notifies)
    assert not Post.objects.exists()
    process_notifications(pg_connection)
    assert 1 == Post.objects.count()
    post = Post.objects.last()
    assert post.author == author
```


Overlapping Code:
```
@pytest.mark.django_db(transaction=True)
def test_author_insert_notify_in_transaction(pg_connection):
with atomic():
author = Author.objects.create(name='Billy')
pg_connection.poll()
assert 1 == len(pg_connection.notifies)
assert not Post.objects.exists()
process_notifications(pg_connection)
assert 1 == Post.objects.count()
post = Post.objects.last()
assert post.author == autho
```
<Overlap Ratio: 0.9973753280839895>

---

--- 16 --
Question ID: 36b03bf2c2032a87bbc96e3c4f9fd883ffc4b08c_0
Original Code:
```
def events(request, response=None):
    """
    Returns a list of events in the CLA system.
    if parameters are passed returns filtered lists

    :return: List of events in dict format
    """

    event = get_event_instance()
    events = [event.to_dict() for event in event.all()]
    if request.params:
        results = event.search_events(**request.params)
        if results:
            events = [ev.to_dict() for ev in results]
        else:
            # return empty list if search fails
            response.status = HTTP_404
            return {"events": []}

    return {"events": events}
```


Overlapping Code:
```
(request, response=None):
"""
Returns a list of events in the CLA system.
if parameters are passed returns filtered lists
:return: List of events in dict format
"""
event = get_event_instance()
events = [event.to_dict() for event in event.all()]
if request.params:
results = event.search_events(**request.params)
if results:
events = [ev.to_dict() for ev in results]
else:
# return empty list if search fails
response.status = HTTP_404
return {"events": []}
return {"events": ev
```
<Overlap Ratio: 0.9695740365111561>

---

--- 17 --
Question ID: afe9e99123973660bf5b7382f0c67bbc34cc5637_1
Original Code:
```
def _parse_model(mod, item=None):
    if isinstance(mod, str):
        dfs = Dfs0(mod)
        if (len(dfs.items) > 1) and (item is None):
            raise ValueError("Model ambiguous - please provide item")
        mod = dfs.read(items=item).to_dataframe()
    elif isinstance(mod, pd.DataFrame):
        mod = DataFramePointModelResultItem(mod, item=item).df
    elif isinstance(mod, pd.Series):
        mod = mod.to_frame()
    elif isinstance(mod, DfsModelResultItem):
        if not mod.is_dfs0:
            raise ValueError("Only dfs0 ModelResults are supported")
        mod = mod._extract_point_dfs0(mod.item).to_dataframe()
    elif isinstance(mod, DfsModelResult):
        if not mod.is_dfs0:
            raise ValueError("Only dfs0 ModelResults are supported")
        if mod.item is None:
            raise ValueError("Model ambiguous - please provide item")
        mod = mod._extract_point_dfs0(mod.item).to_dataframe()

    assert mod.shape[1] == 1  # A single item

    mod.columns = ["Model"]

    return mod
```


Overlapping Code:
```
d, item=None):
if isinstance(mod, str):
dfs = Dfs0(mod)
if (len(dfs.items) > 1) and (item is None):
raise ValueError("Model ambiguous - please provide item")
mod = dfs.read(items=item).to_dataframe()
elif isinstance(mod, pd.DataFrame):
mod = DataFramePointModelResultItem(mod, item=item).df
elif isinstance(mod, pd.Series):
mod = mod.to_frame()
elif isinstance(mod, DfsModelResultItem):
if not mod.is_dfs0:
raise ValueError("Only dfs0 ModelResults are supported")
mod = mod._extract_point_dfs0(mod.item).to_dataframe()
elif isinstance(mod, DfsModelResult):
if not mod.is_dfs0:
raise ValueError("Only dfs0 ModelResults are supported")
if mod.item is None:
raise ValueError("Model ambiguous - please provide item")
mod = mod._extract_point_dfs0(mod.item).to_dataframe()
assert mod.shape[1] == 1 # A sin
```
<Overlap Ratio: 0.9280742459396751>

---

--- 18 --
Question ID: 4615a7bb2082ea09229eed4fac215fecde9fb19c_0
Original Code:
```
def get_model(args, criterion):
    """Construct model from main args"""
    kwargs = dict(num_classes=args.classes,
                  num_layers=args.num_layers,
                  kernel_size=args.kernel_size,
                  num_filters=args.num_filters,
                  imsize=args.imsize,
                  padding=args.padding,
                  batch_norm=args.batch_norm,
                  multi_head=args.multi_head)
    if "warp" in args.meta_model.lower():
        model = WarpedOmniConv(warp_num_layers=args.warp_num_layers,
                               warp_num_filters=args.warp_num_filters,
                               warp_residual_connection=args.warp_residual,
                               warp_act_fun=args.warp_act_fun,
                               warp_batch_norm=args.warp_batch_norm,
                               warp_final_head=args.warp_final_head,
                               **kwargs)
    else:
        model = OmniConv(**kwargs)

    if args.cuda:
        model = model.cuda()

    if args.log_ival > 0:
        print(model)

    if "warp" in args.meta_model.lower():
        return WarpGradWrapper(
            model,
            args.inner_opt,
            args.outer_opt,
            args.inner_kwargs,
            args.outer_kwargs,
            args.meta_kwargs,
            criterion)

    if args.meta_model.lower() == 'leap':
        return LeapWrapper(
            model,
            args.inner_opt,
            args.outer_opt,
            args.inner_kwargs,
            args.outer_kwargs,
            args.meta_kwargs,
            criterion,
        )

    if args.meta_model.lower() == 'no':
        return NoWrapper(
            model,
            args.inner_opt,
            args.inner_kwargs,
            criterion,
        )

    if args.meta_model.lower() == 'ft':
        return FtWrapper(
            model,
            args.inner_opt,
            args.inner_kwargs,
            criterion,
        )

    if args.meta_model.lower() == 'fomaml':
        return FOMAMLWrapper(
            model,
            args.inner_opt,
            args.outer_opt,
            args.inner_kwargs,
            args.outer_kwargs,
            criterion,
        )

    if args.meta_model.lower() == 'reptile':
        return ReptileWrapper(
            model,
            args.inner_opt,
            args.outer_opt,
            args.inner_kwargs,
            args.outer_kwargs,
            criterion,
        )

    if args.meta_model.lower() == 'maml':
        return MAMLWrapper(
            model,
            args.inner_opt,
            args.outer_opt,
            args.inner_kwargs,
            args.outer_kwargs,
            criterion,
        )
    raise NotImplementedError('Meta-learner {} unknown.'.format(
        args.meta_model.lower()))
```


Overlapping Code:
```
"""Construct model from main args"""
kwargs = dict(num_classes=args.classes,
num_layers=args.num_layers,
kernel_size=args.kernel_size,
num_filters=args.num_filters,
imsize=args.imsize,
padding=args.padding,
batch_norm=args.batch_norm,
multi_head=args.multi_head)
if "warp" in args.meta_model.lower():
model = WarpedOmniConv(warp_num_layers=args.warp_num_layers,
warp_num_filters=args.warp_num_filters,
warp_residual_connection=args.warp_residual,
warp_act_fun=args.warp_act_fun,
warp_batch_norm=args.warp_batch_norm,
warp_final_head=args.warp_final_head,
**kwargs)
else:
model = OmniConv(**kwargs)
if args.cuda:
model = model.cuda()
if args.log_ival > 0:
print(model)
if "warp" in args.meta_model.lower():
return WarpGradWrapper(
model,
args.inner_opt,
args.outer_opt,
args.inner_kwargs,
args.outer_kwargs,
args.meta_kwargs,
criterion)
if args.meta_model.lower() == 'leap':
return LeapWrapper(
model,
args.inner_opt,
args.outer_opt,
args.inner_kwargs,
args.outer_kwargs,
args.meta_kwargs,
criterion,
)
if args.meta_model.lower() == 'no':
return NoWrapper(
model,
args.inner_opt,
args.inner_kwargs,
criterion,
)
if args.meta_model.lower() == 'ft':
return FtWrapper(
model,
args.inner_opt,
args.inner_kwargs,
criterion,
)
if args.meta_model.lower() == 'fomaml':
return FOMAMLWrapper(
model,
args.inner_opt,
args.outer_opt,
args.inner_kwargs,
args.outer_kwargs,
criterion,
)
if args.meta_model.lower() == 'reptile':
return ReptileWrapper(
model,
args.inner_opt,
args.outer_opt,
args.inner_kwargs,
args.outer_kwargs,
criterion,
)
if args.meta_model.lower() == 
```
<Overlap Ratio: 0.9755485893416928>

---

--- 19 --
Question ID: 3305c03ee328b6073934665c8c1bf2a4353f7017_2
Original Code:
```
def test_linecomp_by_sorting():
    unsorted = [
        '\t'.join(line)
        for line in [
            [r'\N', r'\N', r'\N'],
            [r'\N', '', r'\N'],
            [r'\N', r'\N', ''],
            ['', r'\N', r'\N'],
            [r'\N', '-.52', 'baz'],
            [r'\N', '42', r'\N'],
            [r'\N', '.42', 'bar'],
            [r'\N', '-.4', 'foo'],
            [r'\N', 'foo', '.42'],
        ]
    ]
    sorted_lines = unsorted[:]
    sorted_lines.sort(key=cmp_to_key(linecomp))
    result = [s.split('\t') for s in sorted_lines]
    assert result == [
        ['', r'\N', r'\N'],
        [r'\N', '', r'\N'],
        [r'\N', '-.52', 'baz'],
        [r'\N', '-.4', 'foo'],
        [r'\N', '.42', 'bar'],
        [r'\N', '42', r'\N'],
        [r'\N', r'\N', ''],
        [r'\N', r'\N', r'\N'],
        [r'\N', 'foo', '.42'],
    ]
```


Overlapping Code:
```
ting():
unsorted = [
'\t'.join(line)
for line in [
[r'\N', r'\N', r'\N'],
[r'\N', '', r'\N'],
[r'\N', r'\N', ''],
['', r'\N', r'\N'],
[r'\N', '-.52', 'baz'],
[r'\N', '42', r'\N'],
[r'\N', '.42', 'bar'],
[r'\N', '-.4', 'foo'],
[r'\N', 'foo', '.42'],
]
]
sorted_lines = unsorted[:]
sorted_lines.sort(key=cmp_to_key(linecomp))
result = [s.split('\t') for s in sorted_lines]
assert result == [
['', r'\N', r'\N'],
[r'\N', '', r'\N'],
[r'\N', '-.52', 'baz'],
[r'\N', '-.4', 'foo'],
[r'\N', '.42', 'bar'],
[r'\N', '42', r'\N'],
[r'\N', r'\N', ''],
[r'\N', 
```
<Overlap Ratio: 0.8972267536704731>

---

--- 20 --
Question ID: 930ab783927cac539ff32ddba9d858892d12dbea_29
Original Code:
```
def test_get_preceding_sibling_by_svg_tag(html_doc):
    rect_path = xh.get_element_by_svg_tag("path", filter.attribute_contains("d", "m423")).get_preceding_sibling_by_svg_tag(
    "rect",
    filter
      .attribute_less_than("width", 640)
      .and_operator(filter.attribute_greater_than_or_equal_to("width", 620))
     )
    elements = html_doc.xpath(str(rect_path))
    assert len(elements) != 0
```


Overlapping Code:
```
doc):
rect_path = xh.get_element_by_svg_tag("path", filter.attribute_contains("d", "m423")).get_preceding_sibling_by_svg_tag(
"rect",
filter
.attribute_less_than("width", 640)
.and_operator(filter.attribute_greater_than_or_equal_to("width", 620))
)
elements = html_doc.xpath(str(rect_path))
assert len(el
```
<Overlap Ratio: 0.837465564738292>

---

--- 21 --
Question ID: a9090642e298505642306c029da34d2eaad075f0_1
Original Code:
```
def mock_layout_get(*args, **kwargs):
    """ Mocks the BIDSLayout.get method to get the files
    It returns a list of MockBidsFiles
    """
    # We add one extra file ("N_RUNS + 1") so that we can have a BIDS
    # file that doesn't exist in the "scan_df" dataframe and test a
    # special case in "determine_scan_durations"
    return [MockBidsFile(path='scan_{}'.format(i)) for i in range(N_RUNS + 1)]
```


Overlapping Code:
```
yout_get(*args, **kwargs):
""" Mocks the BIDSLayout.get method to get the files
It returns a list of MockBidsFiles
"""
# We add one extra file ("N_RUNS + 1") so that we can have a BIDS
# file that doesn't exist in the "scan_df" dataframe and test a
# special case in "determine_scan_durations"
return [MockBidsFile(path='scan_{}'.format(i)) for i in 
```
<Overlap Ratio: 0.9234828496042217>

---

--- 22 --
Question ID: c5bb99c3d18fd816302c58d233ef02f81c46252c_0
Original Code:
```
def close_env(env_process):
    process = psutil.Process(env_process.pid)
    for proc in process.children(recursive=True):
        proc.kill()
    process.kill()
```


Overlapping Code:
```
:
process = psutil.Process(env_process.pid)
for proc in process.children(recursive=True):
proc.kill()
process.kill()
```
<Overlap Ratio: 0.8169014084507042>

---

--- 23 --
Question ID: 8a4601b74a5208edccea033c3d2c445a7a94f1dd_3
Original Code:
```
def check_password(token, password):
    cache_key = token + hashlib.sha256(password.encode("utf-8")).hexdigest()
    if cache_key in _pw_auth_validator:
        return _pw_auth_validator[cache_key]
    split = token.split(":")
    if len(split) != 3:
        return False
    algorithm = split[0]
    check_func = query_utility(IPasswordChecker, name=algorithm)
    if check_func is None:
        logger.warning(f"Could not find password checker for {algorithm}")
        return False
    decision = check_func(token, password)
    _pw_auth_validator[cache_key] = decision
    return decision
```


Overlapping Code:
```
ssword(token, password):
cache_key = token + hashlib.sha256(password.encode("utf-8")).hexdigest()
if cache_key in _pw_auth_validator:
return _pw_auth_validator[cache_key]
split = token.split(":")
if len(split) != 3:
return False
algorithm = split[0]
check_func = query_utility(IPasswordChecker, name=algorithm)
if check_func is None:
logger.warning(f"Could not find password checker for {algorithm}")
return False
decision = check_func(token, password)
_pw_auth_validator[cache_key] = decision
return
```
<Overlap Ratio: 0.9596928982725528>

---

--- 24 --
Question ID: 0c255072b2541bb77d68beebe77203131f1c812a_0
Original Code:
```
def slave_loop(communicator,
               logger=None,
               epd_to_deploy=None,
               untar_directory='/tmp'):
    status = MPI.Status()
    rank = communicator.Get_rank()

    if not logger:
        logger = logging.getLogger("testMPI.slave")
    commands = {}

    if epd_to_deploy != None:
        lock_file_path = os.path.join(untar_directory, "sw_deploy_lock")
        if not os.path.isfile(lock_file_path):
            try:
                lock_file = open(lock_file_path, "w")
                lock_file.write("locked \n")
                lock_file.close()
                epd_tar = tarfile.open(epd_to_deploy)
                epd_tar.extractall(path=untar_directory)
                # logger.debug('extract %s' %(epd_to_deploy))
            except IOError as e:
                logger.error("Could not deploy epd: %s" % (e))
                pass

    max_nb_jobs = 1

    ret_value = 0
    slave_on_hold = False
    while True:
        ended_jobs_info = {}  # job_id -> (job_status, job_exit_status)
        t = None
        if len(commands) < max_nb_jobs:
            communicator.send('Requesting a job',
                              dest=0,
                              tag=MPIScheduler.JOB_REQUEST)

            # logger.debug("Slave " + repr(rank) + " job request")
            communicator.Probe(source=0,
                               tag=MPI.ANY_TAG, status=status)
            # logger.debug("Slave " + repr(rank) + " job request answered")
            t = status.Get_tag()
        elif communicator.Iprobe(source=0,
                                 tag=MPI.ANY_TAG, status=status):
            t = status.Get_tag()
        if t != None:

            if t == MPIScheduler.JOB_SENDING:
                # logger.debug("Slave " + repr(rank) + " receiving job")
                job_list = communicator.recv(source=0, tag=t)
                # logger.debug("Slave " + repr(rank) + " job list received")
                for j in job_list:
                    # process = scheduler.LocalScheduler.create_process(j)
                    separator = " "
                    if not j.command:  # barrier job
                        command = None
                    else:
                        # command = ""
                        # for command_el in j.plain_command():
                            # command = command + "\'" + command_el + "\' "
                        command = (j.plain_command(),
                                   j.plain_stdout(),
                                   j.plain_stderr())
                    # command = separator.join(j.plain_command())
                    # logger.debug("[host: " + socket.gethostname() + "] "
                             #+ "Slave " + repr(rank) + " RUNS JOB"
                             #+ repr(j.job_id) + " " + str(command))
                    commands[j.job_id] = (command, j.env)
            elif t == MPIScheduler.NO_JOB:
                communicator.recv(source=0, tag=t)
                # logger.debug("Slave " + repr(rank) + " "
                #             "received no job " + repr(commands))
                # time.sleep(1)
            elif t == MPIScheduler.EXIT_SIGNAL:
                communicator.send('STOP', dest=0, tag=MPIScheduler.EXIT_SIGNAL)
                logger.debug("[host: " + socket.gethostname() + "] "
                             + "Slave " + repr(rank) + " STOP !!!!! received")
                break
            elif t == MPIScheduler.JOB_KILL:
                job_ids = communicator.recv(source=0, tag=t)
                for job_id in job_ids:
                    if job_id in commands.keys():
                        # TO DO: relevant exception type and message
                        raise Exception(
                            "The job " + repr(job_id) + " can not be killed")

            else:
                raise Exception('Unknown tag')
        for job_id, command_def in six.iteritems(commands):
            command, env = command_def
            if command == None:
                # ended_jobs_info[job_id] = (constants.FAILED,
                                           #(constants.EXIT_ABORTED, None,
                                            # None, None))
                # normally a barrier job
                ended_jobs_info[job_id] = (constants.DONE,
                                           (constants.FINISHED_REGULARLY, 0,
                                            None, None))
            else:

                # if j.plain_stderr():
                    # command = command + " >> " + \
                        # j.plain_stdout() + " 2>> " + j.plain_stderr()
                # else:
                    # command = command + " >> " + j.plain_stdout()

                # ret_value = os.system(command)
                plain_command, plain_stdout, plain_stderr = command
                cmd_stdout, cmd_stderr = (None, None)

                if plain_stdout:
                    cmd_stdout = open(plain_stdout, 'w+')

                if plain_stderr:
                    cmd_stderr = open(plain_stderr, 'w+')

                logger.debug("[host: " + socket.gethostname() + "] "
                             + "Slave %s JOB%s STARTING SUBPROCESS COMMAND %s, "
                             "stdout: %s, stderr: %s"
                             % (repr(rank), repr(job_id), plain_command,
                                plain_stdout, plain_stderr))

                if env is not None:
                    env2 = dict(os.environ)
                    env2.update(env)
                    env = env2

                try:
                    ret_value = subprocess.call(plain_command,
                                                stdout=cmd_stdout,
                                                stderr=cmd_stderr,
                                                env=env)
                    # ret_value = subprocess.call(plain_command)
                    logger.debug("[host: " + socket.gethostname() + "] "
                                 + "Slave %s JOB%s ENDED REGULARLY "
                                 "(ret value %d), stdout: %s, stderr: %s"
                                 % (repr(rank), repr(job_id), ret_value,
                                    plain_stdout, plain_stderr))

                except Exception as e:
                    ret_value = None
                    # import traceback
                    # exc_type, exc_value, exc_traceback = sys.exc_info()
                    # if hasattr(e, 'child_traceback'):
                        # logger.debug(
                        # traceback.print_tb(e.child_traceback)
                    logger.debug("[host: " + socket.gethostname() + "] "
                                 + "Slave %s JOB%s RAISED ERROR, "
                                 "stdout: %s, stderr: %s"
                                 % (repr(rank), repr(job_id),
                                    plain_stdout, plain_stderr),
                                 exc_info=True)
                    ended_jobs_info[job_id] = (constants.FAILED,
                                               (constants.EXIT_ABORTED,
                                                None, None, None))
                    # traceback.format_exception(exc_type, exc_value,
                    # exc_traceback)

                finally:
                    if cmd_stdout:
                        cmd_stdout.close()

                    if cmd_stderr:
                        cmd_stderr.close()

                if ret_value != None:
                    ended_jobs_info[job_id] = (constants.DONE,
                                               (constants.FINISHED_REGULARLY,
                                                ret_value, None, None))

        if ended_jobs_info:
            for job_id in six.iterkeys(ended_jobs_info):
                del commands[job_id]
            logger.debug("[host: " + socket.gethostname() + "] "
                         + "Slave " + repr(rank) + " send JOB_RESULT")
            communicator.send(ended_jobs_info, dest=0,
                              tag=MPIScheduler.JOB_RESULT)
        else:
            pass
            # TO DO send Slave is alive
        if slave_on_hold:
            logger.debug("[host: " + socket.gethostname() + "] "
                         + "Slave %d was punished !!!" % (rank))
            # time.sleep(1200) #20 mins
            break
        else:
            time.sleep(1)

    if epd_to_deploy != None:
        logger.debug("[host: " + socket.gethostname() + "] "
                     + "Slave %d cleaning ... \n" % (rank))
        if os.path.isfile(lock_file_path):
            try:
                os.remove(lock_file_path)
                archive_dir_path = os.path.join(untar_directory, 'epd')
                if os.path.isdir(archive_dir_path):
                    shutil.rmtree(archive_dir_path)
                    logger.debug("remove %s" % (archive_dir_path))
            except Exception as e:
                pass
        logger.debug("[host: " + socket.gethostname() + "] "
                     + "Slave %d: end of cleaning! \n" % (rank))
    logger.debug("[host: " + socket.gethostname() + "] "
                 + "Slave %d END!!! \n" % (rank))
```


Overlapping Code:
```
,
epd_to_deploy=None,
untar_directory='/tmp'):
status = MPI.Status()
rank = communicator.Get_rank()
if not logger:
logger = logging.getLogger("testMPI.slave")
commands = {}
if epd_to_deploy != None:
lock_file_path = os.path.join(untar_directory, "sw_deploy_lock")
if not os.path.isfile(lock_file_path):
try:
lock_file = open(lock_file_path, "w")
lock_file.write("locked \n")
lock_file.close()
epd_tar = tarfile.open(epd_to_deploy)
epd_tar.extractall(path=untar_directory)
# logger.debug('extract %s' %(epd_to_deploy))
except IOError as e:
logger.error("Could not deploy epd: %s" % (e))
pass
max_nb_jobs = 1
ret_value = 0
slave_on_hold = False
while True:
ended_jobs_info = {} # job_id -> (job_status, job_exit_status)
t = None
if len(commands) < max_nb_jobs:
communicator.send('Requesting a job',
dest=0,
tag=MPIScheduler.JOB_REQUEST)
# logger.debug("Slave " + repr(rank) + " job request")
communicator.Probe(source=0,
tag=MPI.ANY_TAG, status=status)
# logger.debug("Slave " + repr(rank) + " job request answered")
t = status.Get_tag()
elif communicator.Iprobe(source=0,
tag=MPI.ANY_TAG, status=status):
t = status.Get_tag()
if t != None:
if t == MPIScheduler.JOB_SENDING:
# logger.debug("Slave " + repr(rank) + " receiving job")
job_list = communicator.recv(source=0, tag=t)
# logger.debug("Slave " + repr(rank) + " job list received")
for j in job_list:
# process = scheduler.LocalScheduler.create_process(j)
separator = " "
if not j.command: # barrier job
command = None
else:
# command = ""
# for command_el in j.plain_command():
# command = command + "\'" + command_el + "\' "
command = (j.plain
```
<Overlap Ratio: 0.9586578789694428>

---

--- 25 --
Question ID: 740cf5cf9297cfbc6cc70e0490f10c2adbc22a4c_0
Original Code:
```
def get_info(package):
    """process the request of getting user's info
    """
    params = package.get('params')
    username = params.get(ParamType.UsernameWithDefault)
    if username is None:
        user = package.get('user')
    else:
        user = UserHelper.get_user_by_username(username)
    if user is None:
        return Response.error_response("No User")

    user = UserHelper.user_filter(user)
    permission_public = user.get('permission')
    user_id = user.get('id')
    school_id = PermissionHelper.get_user_school(user_id)
    if school_id == 0:
        if permission_public >= 8:
            permission_private = permission_public
        else:
            permission_private = -1
        schoolname = 'public area'
    else:
        permission_private = PermissionHelper.get_permission(user_id, school_id)
        school = SchoolHelper.get_school(school_id)
        if school is None:
            schoolname = '-'
        else:
            schoolname = school.get('schoolname')

    download = ProgramHelper.count_user_downloadlog(user_id)

    del user['permission']
    user.update({
        'school_name' : schoolname,
        'permission_public' : permission_public,
        'permission_private' : permission_private,
        'download' : download
    })
    return Response.success_response({'user' : user})
```


Overlapping Code:
```
""process the request of getting user's info
"""
params = package.get('params')
username = params.get(ParamType.UsernameWithDefault)
if username is None:
user = package.get('user')
else:
user = UserHelper.get_user_by_username(username)
if user is None:
return Response.error_response("No User")
user = UserHelper.user_filter(user)
permission_public = user.get('permission')
user_id = user.get('id')
school_id = PermissionHelper.get_user_school(user_id)
if school_id == 0:
if permission_public >= 8:
permission_private = permission_public
else:
permission_private = -1
schoolname = 'public area'
else:
permission_private = PermissionHelper.get_permission(user_id, school_id)
school = SchoolHelper.get_school(school_id)
if school is None:
schoolname = '-'
else:
schoolname = school.get('schoolname')
download = ProgramHelper.count_user_downloadlog(user_id)
del user['permission']
user.update({
'school_name' : schoolname,
'permission_public' : permission_public,
'permission_private' : permission_private,
'download' : download
})
return Response.success_re
```
<Overlap Ratio: 0.957350272232305>

---

--- 26 --
Question ID: 77d4bc8a68803f698f17bde6b1f272f41a1e3c25_5
Original Code:
```
def train_kmeans(x, num_clusters=10, num_gpus=1):
    """
    Runs k-means clustering on one or several GPUs
    """
    d = x.shape[1]
    kmeans = faiss.Clustering(d, num_clusters)
    kmeans.verbose = True
    kmeans.niter = 20

    kmeans.max_points_per_centroid = 100000

    res = [faiss.StandardGpuResources() for i in range(num_gpus)]

    flat_config = []
    for i in range(num_gpus):
        cfg = faiss.GpuIndexFlatConfig()
        cfg.useFloat16 = False
        cfg.device = i
        flat_config.append(cfg)

    if num_gpus == 1:
        index = faiss.GpuIndexFlatL2(res[0], d, flat_config[0])
    else:
        indexes = [faiss.GpuIndexFlatL2(res[i], d, flat_config[i])
                   for i in range(num_gpus)]
        index = faiss.IndexProxy()
        for sub_index in indexes:
            index.addIndex(sub_index)

    # perform the training
    kmeans.train(x, index)
    centroids = faiss.vector_float_to_array(kmeans.centroids)

    stats = kmeans.iteration_stats
    objective = np.array([
        stats.at(i).obj for i in range(stats.size())
    ])

    print(("Final objective: %.4g" % objective[-1]))

    return centroids.reshape(num_clusters, d)
```


Overlapping Code:
```
ef train_kmeans(x, num_clusters=10, num_gpus=1):
"""
Runs k-means clustering on one or several GPUs
"""
d = x.shape[1]
kmeans = faiss.Clustering(d, num_clusters)
kmeans.verbose = True
kmeans.niter = 20
kmeans.max_points_per_centroid = 100000
res = [faiss.StandardGpuResources() for i in range(num_gpus)]
flat_config = []
for i in range(num_gpus):
cfg = faiss.GpuIndexFlatConfig()
cfg.useFloat16 = False
cfg.device = i
flat_config.append(cfg)
if num_gpus == 1:
index = faiss.GpuIndexFlatL2(res[0], d, flat_config[0])
else:
indexes = [faiss.GpuIndexFlatL2(res[i], d, flat_config[i])
for i in range(num_gpus)]
index = faiss.IndexProxy()
for sub_index in indexes:
index.addIndex(sub_index)
# perform the training
kmeans.train(x, index)
centroids = faiss.vector_float_to_array(kmeans.centroids)
stats = kmeans.iteration_stats
objective = np.array([
stats.at(i).obj for i in range(stats.size())
])
print(("Final objective: %.4g" % objective[-1]))
return ce
```
<Overlap Ratio: 0.9664292980671414>

---

--- 27 --
Question ID: 0ee471e238a34a202c3e1ef0b95db0b3d6eb1afd_12
Original Code:
```
def create_custom_mesh2(objname, x0, x1, y0, y1, z0, z1, data):
 
    # Define arrays for holding data    
    myvertex = []
    myfaces = []
    
    # Create all Vertices

    # vertex 0
    mypoint = [(x0, y0, z0)]
    myvertex.extend(mypoint)

    # vertex 1
    mypoint = [(x1, y0, z0)]
    myvertex.extend(mypoint)

    # vertex 2
    mypoint = [(x0, y1, z1)]
    myvertex.extend(mypoint)

    # vertex 3
    mypoint = [(x1, y1, z1)]
    myvertex.extend(mypoint)

    # -------------------------------------
    # Create all Faces
    # -------------------------------------
    myface = [(0, 1, 3, 2)]
    myfaces.extend(myface)

    print("A", objname)
    mymesh = bpy.data.meshes.new(objname)
    print("B")
    myobject = bpy.data.objects.new(objname, mymesh)
    print("C")
    bpy.context.scene.collection.objects.link(myobject)
    print("D")
    # Generate mesh data
    mymesh.from_pydata(myvertex, [], myfaces)
    # Calculate the edges
    print("E")
    mymesh.update(calc_edges=True)

    # Set Location
    #myobject.location.x = px
    #myobject.location.y = py
    #myobject.location.z = pz
    print("F")
    myobject.location.x = 0
    myobject.location.y = 0
    myobject.location.z = 0
    
    tex = bpy.data.textures.new('%s-TEXTURE'%(objname), 'IMAGE')
    print(data.shape)
    mn = np.nanmin(data)
    mx = np.nanmax(data)
    d = (data - mn)/(mx - mn)
    d2 = np.zeros((d.shape[0], d.shape[1], 4))
    d2[:, :, 0] = d
    d2[:, :, 1] = d
    d2[:, :, 2] = d
    d2[:, :, 3] = 1
    print(d2.shape, d2.flatten().shape)
    
    image = bpy.data.images.new("%s-IMAGE"%(objname), width=d.shape[0], height=d.shape[1])
    image.pixels = d2.flatten()
    tex.image = image
    
    mat = bpy.data.materials.new('%s-DATA'%(objname))
    mat.texture_paint_images = [image]
    #mat.texture_slots.add()
    #ts = mat.texture_slots[0]
    #ts.texture = tex
    #ts.texture_coords = 'UV'
    #ts.uv_layer = 'default'
    #mtex.texture_coords = 'UV'
    
    myobject.data.materials = mat
    

    return myobject
```


Overlapping Code:
```
name, x0, x1, y0, y1, z0, z1, data):

# Define arrays for holding data 
myvertex = []
myfaces = []

# Create all Vertices
# vertex 0
mypoint = [(x0, y0, z0)]
myvertex.extend(mypoint)
# vertex 1
mypoint = [(x1, y0, z0)]
myvertex.extend(mypoint)
# vertex 2
mypoint = [(x0, y1, z1)]
myvertex.extend(mypoint)
# vertex 3
mypoint = [(x1, y1, z1)]
myvertex.extend(mypoint)
# -------------------------------------
# Create all Faces
# -------------------------------------
myface = [(0, 1, 3, 2)]
myfaces.extend(myface)
print("A", objname)
mymesh = bpy.data.meshes.new(objname)
print("B")
myobject = bpy.data.objects.new(objname, mymesh)
print("C")
bpy.context.scene.collection.objects.link(myobject)
print("D")
# Generate mesh data
mymesh.from_pydata(myvertex, [], myfaces)
# Calculate the edges
print("E")
mymesh.update(calc_edges=True)
# Set Location
#myobject.location.x = px
#myobject.location.y = py
#myobject.location.z = pz
print("F")
myobject.location.x = 0
myobject.location.y = 0
myobject.location.z = 0

tex = bpy.data.textures.new('%s-TEXTURE'%(objname), 'IMAGE')
print(data.shape)
mn = np.nanmin(data)
mx = np.nanmax(data)
d = (data - mn)/(mx - mn)
d2 = np.zeros((d.shape[0], d.shape[1], 4))
d2[:, :, 0] = d
d2[:, :, 1] = d
d2[:, :, 2] = d
d2[:, :, 3] = 1
print(d2.shape, d2.flatten().shape)

image = bpy.data.images.new("%s-IMAGE"%(objname), width=d.shape[0], height=d.shape[1])
image.pixels = d2.flatten()
tex.image = image

mat = bpy.data.materials.new('%s-DATA'%(objname))
mat.texture_paint_images = [image]
#mat.texture_slots.add()
#ts = mat.texture_slots[0]
#ts.texture = tex
#ts.texture_coords = 'UV'
#ts.uv_layer = 'default'
#mtex.texture_coords = 'UV'

myobject.data.materials = mat

r
```
<Overlap Ratio: 0.9764503159103963>

---

--- 28 --
Question ID: f6d9ab3a6727f742bb4331e1814521fcb0ddcb0b_5
Original Code:
```
def ecdf(data):
	""" Compute eCDF
	data : List of values
	Returns:
	Tuple of x and y values for eCDF plot
	"""
	x = np.sort(data)
	n = len(x)
	y = np.arange(n) / float(n)


	return(x,y)
```


Overlapping Code:
```
data):
""" Compute eCDF
data : List of values
Returns:
Tuple of x and y values for eCDF plot
"""
x = np.sort(data)
n = len(x)
y = np.arange(n) / float
```
<Overlap Ratio: 0.8620689655172413>

---

--- 29 --
Question ID: 0657de93d1e5b30e794f21550ae68d6cc11d1a46_12
Original Code:
```
def ask():
  options = ['Add User To The Spammer','Remove User From Spammer','Remove User From All Groupchats','Delete Groupchats','Rename Groupchats','Spam User','Change group icon','Help']
  print("\033[H\033[J", end="")
  print('[ ', end='', flush=True)
  cprint('1', 'green', end='', flush=True)
  print(' ] ', end='', flush=True)
  print('Create Groupchats', end='', flush=True)
  for x, i in enumerate(options):
    print()
    print()
    print('[ ', end='', flush=True)
    cprint(x + 2, 'green', end='', flush=True)
    print(' ] ', end='', flush=True)
    print(i, end='', flush=True)
  print()
  print()
  choice = input("> ")
  try:
    if int(choice) == 1:
      cprint('Creating Groupchats...', 'green')
      create()
      time.sleep(1)
      ask()
    elif int(choice) == 2:
      cprint('Enter user id below', 'yellow')
      id = input("")
      addUser(id)
      cprint('Added user!', 'green')
      time.sleep(1)
      ask()
    elif int(choice) == 3:
      cprint('Enter user id below', 'yellow')
      id = input("")
      removeUser(id)
      time.sleep(1)
      ask()
    elif int(choice) == 4:
      cprint('Enter user id below', 'yellow')
      id = input("")
      remove(id)
      cprint('Removed from all groupchats', 'green')
      time.sleep(1)
      ask()
    elif int(choice) == 5:
      delete()
      cprint('Deleted all groupchats', 'green')
      time.sleep(1)
      ask()
    elif int(choice) == 6:
      cprint('Enter group chat names below', 'yellow')
      name = input("")
      rename(str(name))
      time.sleep(1)
      ask()
    elif int(choice) == 7:
      cprint('Enter user id below', 'yellow')
      id = input("")
      spam(id)
      for char in 'Done spamming':
        time.sleep(0.1)
        cprint(char, 'magenta', end='', flush=True)
      time.sleep(5)
      ask()
    elif int(choice) == 8:
      cprint('Enter url to image below', 'yellow')
      url = input("")
      try:
        base64.b64encode(requests.get(url).content)
      except:
        cprint('Invalid Url', 'red')
        time.sleep(1.5)
        ask()
      url = str(base64.b64encode(requests.get(url).content)).replace("b'", '')
      changeImg(f'data:image/png;base64,{url}')
      ask()
    elif int(choice) == 9:
      cprint("1.)To create groupchats is to prepare groupchats to add them to. The more groupchats the more pings for them. \n\n2.)To add someone to the spammer is to add them to the list of people who get removed and added to increase the amount of pings. MAKE SURE YOU HAVE THEM ADDED And to remove them is vice versa. You don't need to have them added to remove them.\n\n3.)To delete the group chats is self explanatory. To remove someone from all the groupchats is just to kick them from the groups you just added them to. To spam them is to start the spammer.", 'green')
      input("Press Enter To Exit")
      ask()
    else:
      ask()
  except:
    ask()
```


Overlapping Code:
```
ptions = ['Add User To The Spammer','Remove User From Spammer','Remove User From All Groupchats','Delete Groupchats','Rename Groupchats','Spam User','Change group icon','Help']
print("\033[H\033[J", end="")
print('[ ', end='', flush=True)
cprint('1', 'green', end='', flush=True)
print(' ] ', end='', flush=True)
print('Create Groupchats', end='', flush=True)
for x, i in enumerate(options):
print()
print()
print('[ ', end='', flush=True)
cprint(x + 2, 'green', end='', flush=True)
print(' ] ', end='', flush=True)
print(i, end='', flush=True)
print()
print()
choice = input("> ")
try:
if int(choice) == 1:
cprint('Creating Groupchats...', 'green')
create()
time.sleep(1)
ask()
elif int(choice) == 2:
cprint('Enter user id below', 'yellow')
id = input("")
addUser(id)
cprint('Added user!', 'green')
time.sleep(1)
ask()
elif int(choice) == 3:
cprint('Enter user id below', 'yellow')
id = input("")
removeUser(id)
time.sleep(1)
ask()
elif int(choice) == 4:
cprint('Enter user id below', 'yellow')
id = input("")
remove(id)
cprint('Removed from all groupchats', 'green')
time.sleep(1)
ask()
elif int(choice) == 5:
delete()
cprint('Deleted all groupchats', 'green')
time.sleep(1)
ask()
elif int(choice) == 6:
cprint('Enter group chat names below', 'yellow')
name = input("")
rename(str(name))
time.sleep(1)
ask()
elif int(choice) == 7:
cprint('Enter user id below', 'yellow')
id = input("")
spam(id)
for char in 'Done spamming':
time.sleep(0.1)
cprint(char, 'magenta', end='', flush=True)
time.sleep(5)
ask()
elif int(choice) == 8:
cprint('Enter url to image below', 'yellow')
url = input("")
try:
base64.b64encode(requests.get(url).content)
except:
cprint('Invalid Url', 'red')
time.sleep(1.5)
ask()
url = str(base64.b64encode(requests.get(url).content)).replace("b'", '')
changeImg(f'data:image/png;base64,{url}')
ask()
elif int(choice) == 9:
cprint("1.)To create groupchats is to prepare groupchats to add them to. The more groupchats the more pings for them. \n\n2.)To add someone to the spammer is to add them to the list of people who get removed and added to increase t
```
<Overlap Ratio: 0.9852661596958175>

---

--- 30 --
Question ID: c3f2179f4bca2e52365357a7b8f67a9e86f4593b_5
Original Code:
```
def gen_embeddings(word_dict, dim, in_file=None,
                   init=lasagne.init.Uniform()):
    """
        Generate an initial embedding matrix for `word_dict`.
        If an embedding file is not given or a word is not in the embedding file,
        a randomly initialized vector will be used.
    """

    num_words = max(word_dict.values()) + 1
    embeddings = init((num_words, dim))
    logging.info('Embeddings: %d x %d' % (num_words, dim))

    if in_file is not None:
        logging.info('Loading embedding file: %s' % in_file)
        pre_trained = 0
        for line in open(in_file).readlines():
            sp = line.split()
            assert len(sp) == dim + 1
            if sp[0] in word_dict:
                pre_trained += 1
                embeddings[word_dict[sp[0]]] = [float(x) for x in sp[1:]]
        logging.info('Pre-trained: %d (%.2f%%)' %
                     (pre_trained, pre_trained * 100.0 / num_words))
    return embeddings
```


Overlapping Code:
```
_file=None,
init=lasagne.init.Uniform()):
"""
Generate an initial embedding matrix for `word_dict`.
If an embedding file is not given or a word is not in the embedding file,
a randomly initialized vector will be used.
"""
num_words = max(word_dict.values()) + 1
embeddings = init((num_words, dim))
logging.info('Embeddings: %d x %d' % (num_words, dim))
if in_file is not None:
logging.info('Loading embedding file: %s' % in_file)
pre_trained = 0
for line in open(in_file).readlines():
sp = line.split()
assert len(sp) == dim + 1
if sp[0] in word_dict:
pre_trained += 1
embeddings[word_dict[sp[0]]] = [float(x) for x in sp[1:]]
logging.info('Pre-trained: %d (%.2f%%)' %
(pre_trained, pre_trained * 100.0 / num_words))
return embeddin
```
<Overlap Ratio: 0.9494163424124513>

---

--- 31 --
Question ID: c8baad290f4cb949388236761be605e642ed2d6f_0
Original Code:
```
def delete_job(room_lifetime):
    """
    A background job (runs every hour) that deletes expired rooms
    :param room_lifetime: room expiry (in seconds)
    """
    for room in os.listdir('r'):
        if time.time() - os.path.getmtime(f'r{os.path.sep}{room}') > room_lifetime:
            os.remove(f'r{os.path.sep}{room}')
```


Overlapping Code:
```
om_lifetime):
"""
A background job (runs every hour) that deletes expired rooms
:param room_lifetime: room expiry (in seconds)
"""
for room in os.listdir('r'):
if time.time() - os.path.getmtime(f'r{os.path.sep}{room}') > room_lifetime:
os.remove(f'r{
```
<Overlap Ratio: 0.8710801393728222>

---

--- 32 --
Question ID: 7c077bf44e87cb409658d98030a2b416d9b98dbc_5
Original Code:
```
def do_std(df, group_cols, counted, agg_name):
    """Add the standard deviation for each group for a given feature.

    Arguments:
        df: DataFrame to group and add the standard deviation feature.
        group_cols: List with column or columns names to group by.
        counted: Feature name to get the standard deviation (string).
        agg_name: New feature name (string)

    Returns:
        df: Same DataFrame with the new feature
    """
    gp = df[group_cols + [counted]].groupby(group_cols)[counted].std().reset_index().rename(
        columns={counted: agg_name})
    df = df.merge(gp, on=group_cols, how='left')
    del gp
    gc.collect()
    return df
```


Overlapping Code:
```
do_std(df, group_cols, counted, agg_name):
"""Add the standard deviation for each group for a given feature.
Arguments:
df: DataFrame to group and add the standard deviation feature.
group_cols: List with column or columns names to group by.
counted: Feature name to get the standard deviation (string).
agg_name: New feature name (string)
Returns:
df: Same DataFrame with the new feature
"""
gp = df[group_cols + [counted]].groupby(group_cols)[counted].std().reset_index().rename(
columns={counted: agg_name})
df = df.merge(gp, on=group_cols, how='left')
del gp
gc.collect()
return df
```
<Overlap Ratio: 0.9932088285229203>

---

--- 33 --
Question ID: c520b2a3a969577ea7836ad808a35f9fad24f71d_3
Original Code:
```
def prompt_user(prompt, default=False, autoconfirm=False):
    if autoconfirm:
        return True

    if default:
        query = "[Y/n]"
    else:
        query = "[y/N]"
    prompt = f"{prompt} {query} "

    while True:
        out = input(prompt).strip().lower()

        if not out:
            return default

        if out.startswith("y"):
            return True
        if out.startswith("n"):
            return False
```


Overlapping Code:
```
ault=False, autoconfirm=False):
if autoconfirm:
return True
if default:
query = "[Y/n]"
else:
query = "[y/N]"
prompt = f"{prompt} {query} "
while True:
out = input(prompt).strip().lower()
if not out:
return default
if out.startswith("y"):
return True
```
<Overlap Ratio: 0.7961783439490446>

---

--- 34 --
Question ID: 666112bbb218859cb0654924f3b4ecab8f38180a_3
Original Code:
```
def find_specific_class(specific_class, labels):
    
    img_ind = -1
    
    for img_ind in range(labels.shape[0]):
        if labels[img_ind] == specific_class:
            break
    
    return img_ind
```


Overlapping Code:
```
 find_specific_class(specific_class, labels):

img_ind = -1

for img_ind in range(labels.shape[0]):
if labels[img_ind] == specific_class:
break

retur
```
<Overlap Ratio: 0.9259259259259259>

---

--- 35 --
Question ID: fc9ed8e057689b4236908e0a26a6917db08253e9_12
Original Code:
```
@pytest.mark.parametrize('per_test_flask_app', ['dirbs_poweruser_login', 'dirbs_api_user', 'dirbs_catalog_user'],
                         indirect=True)
def test_imei_api(per_test_flask_app, per_test_postgres, logger, mocked_statsd, tmpdir, request, mocked_config,
                  api_version):
    """Test IMEI API call works with the security role created based on abstract role."""
    dsn = per_test_postgres.dsn()
    db_config = DBConfig(ignore_env=True, **dsn)
    with create_db_connection(db_config) as conn, \
            create_db_connection(db_config, autocommit=True) as metadata_conn:
        with get_importer(OperatorDataImporter,
                          conn,
                          metadata_conn,
                          db_config,
                          tmpdir,
                          logger,
                          mocked_statsd,
                          OperatorDataParams(
                              filename='testData1-operator-operator1-anonymized_20161101_20161130.csv',
                              operator='operator1',
                              perform_unclean_checks=False,
                              extract=False)) as imp:
            imp.import_data()

    current_user = request.node.callspec.params['per_test_flask_app']

    if api_version == 'v1':
        if current_user in ['dirbs_poweruser_login', 'dirbs_api_user']:
            rv = per_test_flask_app.get(url_for('{0}.imei_api'.format(api_version),
                                                imei='388260336982806', include_seen_with=1))
            assert rv.status_code == 200
            assert json.loads(rv.data.decode('utf-8'))['seen_with'] == \
                                                      [{'imsi': '11101400135251', 'msisdn': '22300825684694'},
                                                       {'imsi': '11101400135252', 'msisdn': '22300825684692'}]
            assert json.loads(rv.data.decode('utf-8'))['realtime_checks']['ever_observed_on_network'] is True

        else:
            with pytest.raises(DatabaseRoleCheckException):
                per_test_flask_app.get(url_for('{0}.imei_api'.format(api_version),
                                               imei='388260336982806', include_seen_with=1))
    else:  # api version 2.0
        if current_user in ['dirbs_poweruser_login', 'dirbs_api_user']:
            rv = per_test_flask_app.get(url_for('{0}.imei_get_subscribers_api'.format(api_version),
                                                imei='388260336982806'))
            assert rv.status_code == 200
            data = json.loads(rv.data.decode('utf-8'))
            assert len(data['subscribers']) is not 0
            assert data['subscribers'] == [
                {
                    'imsi': '11101400135251',
                    'last_seen': '2016-11-01',
                    'msisdn': '22300825684694'
                },
                {
                    'imsi': '11101400135252',
                    'last_seen': '2016-11-02',
                    'msisdn': '22300825684692'
                }]
        else:
            with pytest.raises(DatabaseRoleCheckException):
                per_test_flask_app.get(url_for('{0}.imei_get_subscribers_api'.format(api_version),
                                               imei='388260336982806'))
```


Overlapping Code:
```
est.mark.parametrize('per_test_flask_app', ['dirbs_poweruser_login', 'dirbs_api_user', 'dirbs_catalog_user'],
indirect=True)
def test_imei_api(per_test_flask_app, per_test_postgres, logger, mocked_statsd, tmpdir, request, mocked_config,
api_version):
"""Test IMEI API call works with the security role created based on abstract role."""
dsn = per_test_postgres.dsn()
db_config = DBConfig(ignore_env=True, **dsn)
with create_db_connection(db_config) as conn, \
create_db_connection(db_config, autocommit=True) as metadata_conn:
with get_importer(OperatorDataImporter,
conn,
metadata_conn,
db_config,
tmpdir,
logger,
mocked_statsd,
OperatorDataParams(
filename='testData1-operator-operator1-anonymized_20161101_20161130.csv',
operator='operator1',
perform_unclean_checks=False,
extract=False)) as imp:
imp.import_data()
current_user = request.node.callspec.params['per_test_flask_app']
if api_version == 'v1':
if current_user in ['dirbs_poweruser_login', 'dirbs_api_user']:
rv = per_test_flask_app.get(url_for('{0}.imei_api'.format(api_version),
imei='388260336982806', include_seen_with=1))
assert rv.status_code == 200
assert json.loads(rv.data.decode('utf-8'))['seen_with'] == \
[{'imsi': '11101400135251', 'msisdn': '22300825684694'},
{'imsi': '11101400135252', 'msisdn': '22300825684692'}]
assert json.loads(rv.data.decode('utf-8'))['realtime_checks']['ever_observed_on_network'] is True
else:
with pytest.raises(DatabaseRoleCheckException):
per_test_flask_app.get(url_for('{0}.imei_api'.format(api_version),
imei='388260336982806', include_seen_with=1))
else: # api version 2.0
if current_user in ['dirbs_poweruser_login', 'dirbs_api_user']:
rv = per_test_flask_app.get(url_for('{0}.imei_get_subscribers_api'.format(api_vers
```
<Overlap Ratio: 0.9948186528497409>

---

--- 36 --
Question ID: 226880a1a12ca4045e6a898d3a66784484b667fd_0
Original Code:
```
def load_args():
    parser = argparse.ArgumentParser(description = "Pipeline runner")
    
    parser.add_argument(
        'target_repo',
        action = 'store',
        help = "the type of object to generate jsons for",
    )

    parser.add_argument(
        'problem_type',
        action = 'store',
        help = 'the d3m problem type to check'
    )
    # parser.add_argument(
    #     'primitives_or_pipelines',
    #     action = 'store',
    #     help = "the type of object to generate jsons for",
    # )
    arguments = parser.parse_args()
    return [arguments.target_repo, arguments.problem_type]
```


Overlapping Code:
```
def load_args():
parser = argparse.ArgumentParser(description = "Pipeline runner")

parser.add_argument(
'target_repo',
action = 'store',
help = "the type of object to generate jsons for",
)
parser.add_argument(
'problem_type',
action = 'store',
help = 'the d3m problem type to check'
)
# parser.add_argument(
# 'primitives_or_pipelines',
# action = 'store',
# help = "the type of object to generate jsons for",
# )
arguments = parser.parse_args()
return [arguments.target_repo, ar
```
<Overlap Ratio: 0.9581673306772909>

---

--- 37 --
Question ID: ae8ce29f43055862d58a694a64553975ee0298b6_25
Original Code:
```
def cmp(a, b):
    if a == b:
        return 0
    elif a < b:
        return -1
    else:
        return 1
```


Overlapping Code:
```
== b:
return 0
elif a < b:
return -1
else:
return 
```
<Overlap Ratio: 0.704225352112676>

---

--- 38 --
Question ID: 676b8b8fa9edb2e0448a867726f93705fda631cd_0
Original Code:
```
@auth.route('/login', methods=['POST'])
def login():
    post_data = request.get_json()
    username = post_data.get('username')
    secret = post_data.get('secret')

    regx = re.compile('^{}$'.format(username), re.IGNORECASE)
    user_dict = mongo.db.users.find_one({'username': regx})
    user_secret = secret

    if is_authenticated(user_dict, user_secret):
        user = User(user_dict['username'], user_secret)
        flask_login.login_user(user)
        resp = {
            'status': 0,
            'authenticated': True,
            'message': 'Successfully logged in.',
            'user': {
                'username': user.username,
            }
        }
        return jsonify(resp), 200

    resp = {
        'status': 'fail',
        'authenticated': False,
        'message': 'Bad login'
    }
    return jsonify(resp), 401
```


Overlapping Code:
```
uth.route('/login', methods=['POST'])
def login():
post_data = request.get_json()
username = post_data.get('username')
secret = post_data.get('secret')
regx = re.compile('^{}$'.format(username), re.IGNORECASE)
user_dict = mongo.db.users.find_one({'username': regx})
user_secret = secret
if is_authenticated(user_dict, user_secret):
user = User(user_dict['username'], user_secret)
flask_login.login_user(user)
resp = {
'status': 0,
'authenticated': True,
'message': 'Successfully logged in.',
'user': {
'username': user.username,
}
}
return jsonify(resp), 200
resp = {
'status': 'fail',
'authenticated': False,
'message': 'Bad login'
}
ret
```
<Overlap Ratio: 0.9637462235649547>

---

--- 39 --
Question ID: 5f4c2151b453c39162249241cade10ded72b6d5a_8
Original Code:
```
def span_str(start = None, end = None):
  assert(start is not None or end is not None)
  if start is None:
    return ' '  + str(end) + ')'
  elif end is None:
    return '(' + str(start) + ' '
  else:
    return ' (' + str(start) + ' ' + str(end) + ') '    
```


Overlapping Code:
```
def span_str(start = None, end = None):
assert(start is not None or end is not None)
if start is None:
return ' ' + str(end) + ')'
elif end is None:
return '(' + str(start) + ' '
else:
return ' (' + str(s
```
<Overlap Ratio: 0.8755364806866953>

---

--- 40 --
Question ID: 723de0a5bbd627b16d9141116cd0d4472294a554_4
Original Code:
```
def test_function(test_case):
    output = rearrange_digits(test_case[0])
    solution = test_case[1]
    if sum(output) == sum(solution):
        print("Pass")
    else:
        print("Fail")
```


Overlapping Code:
```
def test_function(test_case):
output = rearrange_digits(test_case[0])
solution = test_case[1]
if sum(output) == sum(solution):
print("Pass")
else:
print("Fail")
```
<Overlap Ratio: 1.0>

---

--- 41 --
Question ID: 3da6d404c3beb0b79e4ede613b6f84739f6231c5_0
Original Code:
```
def test_set_vars():
    candidate = CXStandardProfile()

    with pytest.raises(TypeError):
        candidate.vars = 123

    candidate.vars = ["a", "b", "c"]
    assert candidate.vars == ["a", "b", "c"]
    assert candidate.y[VARS] == ["a", "b", "c"]

    candidate.vars = None
    assert candidate.vars == []
    assert candidate.y[VARS] == []
```


Overlapping Code:
```
= CXStandardProfile()
with pytest.raises(TypeError):
candidate.vars = 123
candidate.vars = ["a", "b", "c"]
assert candidate.vars == ["a", "b", "c"]
assert candidate.y[VARS] == ["a", "b", "c"]
candidate.vars = None
assert candidate.vars == []
assert candidate.y[VARS]
```
<Overlap Ratio: 0.8778877887788779>

---

--- 42 --
Question ID: 28bb563d4e77c050ad414be9642fbea72b74da7d_2
Original Code:
```
def ConvergenceKTest(CorrectA, J, Laplacian, k_vals, n):
    # Make space for the result to be saved
    Values = np.empty(len(k_vals))
    
    # Loop through all values of n
    for i, k in enumerate(k_vals):
        # Create the initial conditions
        A = np.zeros_like(J)
    
        print(i)
        # Solve the system
        A = EM.solve_approx(J, Laplacian, 1, A, n, k)
        
        # Find the error
        Values[i] = np.sum((A - CorrectA) ** 2)
        
    return Values
```


Overlapping Code:
```
rrectA, J, Laplacian, k_vals, n):
# Make space for the result to be saved
Values = np.empty(len(k_vals))

# Loop through all values of n
for i, k in enumerate(k_vals):
# Create the initial conditions
A = np.zeros_like(J)

print(i)
# Solve the system
A = EM.solve_approx(J, Laplacian, 1, A, n, k)

# Find the error
Values[i] = np.sum((A - CorrectA) ** 2)

return
```
<Overlap Ratio: 0.9232736572890026>

---

--- 43 --
Question ID: 9b51df0f8e67c8296dac3ab781a3f6fcb65d76ed_12
Original Code:
```
@Function
def check_pending_async(args):
    if globals.pendingAsync is None or not len(globals.pendingAsync): return Object.fromBoolean(False)
    return Object.fromBoolean(True)
```


Overlapping Code:
```
sync(args):
if globals.pendingAsync is None or not len(globals.pendingAsync): return Object.fromBool
```
<Overlap Ratio: 0.5847953216374269>

---

--- 44 --
Question ID: 4fccc1adaaa4e4ef0dee8bf26d632b6021c2780b_1
Original Code:
```
@app.route("/<string:path>/", methods = ['POST', 'GET'])
def path(path):
	lang = request.accept_languages.best_match(supported_languages)
	ret = copy.deepcopy(page)
	rtbdy = copy.deepcopy(body)
	status = rtbdy.add_MD("md/"+path+"."+lang+".md")
	ret.add_body(str(rtbdy))
	return str(ret), status
```


Overlapping Code:
```
p.route("/<string:path>/", methods = ['POST', 'GET'])
def path(path):
lang = request.accept_languages.best_match(supported_languages)
ret = copy.deepcopy(page)
rtbdy = copy.deepcopy(body)
status = rtbdy.add_MD("md/"+path+"."+lang+".md")
ret.add_body(
```
<Overlap Ratio: 0.8680555555555556>

---

--- 45 --
Question ID: 88ebf18f6afffd8fd603b85146cbf14f21d977a4_5
Original Code:
```
@login_required
def events_list_mine(request):
    context = {"events_shown": "mine"}
    query = Q(bookings__person=request.user, bookings__cancelledOn=None)
    query = query | Q(organisers=request.user)
    query = query | Q(owner=request.user)
    events = Event.objects.filter(query).distinct()
    if events.count() > 0:
        return events_list(request, events, context)
    else:
        messages.debug(request, "You have no event yet")
        return redirect("events_list_all")
```


Overlapping Code:
```
t_mine(request):
context = {"events_shown": "mine"}
query = Q(bookings__person=request.user, bookings__cancelledOn=None)
query = query | Q(organisers=request.user)
query = query | Q(owner=request.user)
events = Event.objects.filter(query).distinct()
if events.count() > 0:
return events_list(request, events, context)
else:
messages.debug(request, "You have no event yet")
return redirect("events_lis
```
<Overlap Ratio: 0.9153318077803204>

---

--- 46 --
Question ID: 6b37f9565f143bb7d21132b392f07cc3ab7c806b_0
Original Code:
```
def intersect(box_a, box_b):
    n = box_a.size(0)
    A = box_a.size(1)
    B = box_b.size(1)
    max_xy = torch.min(box_a[:, :, 2:].unsqueeze(2).expand(n, A, B, 2),
                       box_b[:, :, 2:].unsqueeze(1).expand(n, A, B, 2))
    min_xy = torch.max(box_a[:, :, :2].unsqueeze(2).expand(n, A, B, 2),
                       box_b[:, :, :2].unsqueeze(1).expand(n, A, B, 2))
    return torch.clamp(max_xy - min_xy, min=0).prod(3)
```


Overlapping Code:
```
t(box_a, box_b):
n = box_a.size(0)
A = box_a.size(1)
B = box_b.size(1)
max_xy = torch.min(box_a[:, :, 2:].unsqueeze(2).expand(n, A, B, 2),
box_b[:, :, 2:].unsqueeze(1).expand(n, A, B, 2))
min_xy = torch.max(box_a[:, :, :2].unsqueeze(2).expand(n, A, B, 2),
box_b[:, :, :2].unsqueeze(1).expand(n, A, B, 2))
return torch.clamp(max_xy - min_xy, min=0).pr
```
<Overlap Ratio: 0.9536784741144414>

---

--- 47 --
Question ID: f8ab3865cbf8288a67f7508e2e4ba99bb11a4feb_1
Original Code:
```
def get_reward(state):
    """randomly select an action, return next state and reward"""
    rand = random.randint(0, 3)
    action = actions[rand]

    x = state[0] + action[0]
    y = state[1] + action[1]

    if x < 0 or x >= size or y < 0 or y >= size:  # out of gridworld
        next_state = state  # state unchanged
    else:
        next_state = [x, y]
    reward = -1

    return next_state, reward
```


Overlapping Code:
```
state):
"""randomly select an action, return next state and reward"""
rand = random.randint(0, 3)
action = actions[rand]
x = state[0] + action[0]
y = state[1] + action[1]
if x < 0 or x >= size or y < 0 or y >= size: # out of gridworld
next_state = state # state unchanged
else:
next_state = [x, y]
reward = -1
return
```
<Overlap Ratio: 0.9028571428571428>

---

--- 48 --
Question ID: 4905fd63189ce58f29c2f6fd68b1a3742beff180_3
Original Code:
```
def test_full_write_access(path):
    try:
        testdir = os.path.join(path, "test_write_access")
        os.mkdir(testdir)
        os.rmdir(testdir)
        return True
    except PermissionError:
        # There is no access to create folders in path:
        return False
```


Overlapping Code:
```
estdir = os.path.join(path, "test_write_access")
os.mkdir(testdir)
os.rmdir(testdir)
return True
except PermissionError:
# There is no access to creat
```
<Overlap Ratio: 0.6787330316742082>

---

--- 49 --
Question ID: 0afcd498a3e7bb94a538760ebf1ce831ce104976_34
Original Code:
```
def tensors_to_vols(input_vols_th):
    vols_np = [vol_unnormalize(input_vols_th[i].cpu().data.numpy()) for i in range(len(input_vols_th))]
    vols_np = np.stack(vols_np, 0)
    return vols_np
```


Overlapping Code:
```

vols_np = [vol_unnormalize(input_vols_th[i].cpu().data.numpy()) for i in range(len(input_vols_th))]
```
<Overlap Ratio: 0.5524861878453039>

---

--- 50 --
Question ID: 577ebd038b06483a51fc1759c7dbed2554343823_0
Original Code:
```
def readData(filename, NumDataSet):
    ### Read CSV into raw_data dataframe ###
    input_data = pd.read_csv(filename)
    raw_data_header = input_data.columns[1:NumDataSet+1].tolist()
    

    ### Print Data headers
    print('Input Data File Header:', raw_data_header)

    ### number of columns and rows in raw_data (shape only for dataframe)
    input_data_numrows = input_data.shape[0]
    
    input_data_numcols = input_data.shape[1]- NumDataSet #minus off the std deviation data
    print('Input Data: Rows -', input_data_numrows, ', Columns -', input_data_numcols)

    ### Saving raw_data columns into individual list (rows) in rfp_data numpy
    # Flip row and col from raw_data
    rfp_data = np.zeros((input_data_numcols,input_data_numrows))

    for i in range(0, input_data_numcols): # Iterate through all columns
        rfp_data[i, :] = input_data.iloc[:, i]
    # print(rfp_data)

    # Time + All Inducers
    rfp_data_numrows = rfp_data.shape[0] # or = np.size(rfp_data,0)
    # Number of RFP Data Per Inducer
    rfp_data_numcols = rfp_data.shape[1]

    ### Convert RFP/OD into (mol/OD) ###
    # Starts from 1 because Row 0 is time
    for i in range (1, rfp_data_numrows):
        for j in range (0, rfp_data_numcols):
            rfp_data[i][j] = ODconv(rfp_data[i][j])

    #store standard deviation data
    stddev_data = np.zeros((NumDataSet, input_data_numrows))

    for i in range(input_data_numcols, input_data_numcols + NumDataSet): # Iterate through all columns
        stddev_data[i-input_data_numcols, :] = input_data.iloc[:, i]

    stddev_data_numrows = stddev_data.shape[0]
    stddev_data_numcols = stddev_data.shape[1]

    # convert RFP/OD into Molar/OD
    for i in range(0, stddev_data_numrows):
        for j in range(0, stddev_data_numcols):
            stddev_data[i][j] = ODconv(stddev_data[i][j])

    return raw_data_header, rfp_data, stddev_data
```


Overlapping Code:
```
:
### Read CSV into raw_data dataframe ###
input_data = pd.read_csv(filename)
raw_data_header = input_data.columns[1:NumDataSet+1].tolist()

### Print Data headers
print('Input Data File Header:', raw_data_header)
### number of columns and rows in raw_data (shape only for dataframe)
input_data_numrows = input_data.shape[0]

input_data_numcols = input_data.shape[1]- NumDataSet #minus off the std deviation data
print('Input Data: Rows -', input_data_numrows, ', Columns -', input_data_numcols)
### Saving raw_data columns into individual list (rows) in rfp_data numpy
# Flip row and col from raw_data
rfp_data = np.zeros((input_data_numcols,input_data_numrows))
for i in range(0, input_data_numcols): # Iterate through all columns
rfp_data[i, :] = input_data.iloc[:, i]
# print(rfp_data)
# Time + All Inducers
rfp_data_numrows = rfp_data.shape[0] # or = np.size(rfp_data,0)
# Number of RFP Data Per Inducer
rfp_data_numcols = rfp_data.shape[1]
### Convert RFP/OD into (mol/OD) ###
# Starts from 1 because Row 0 is time
for i in range (1, rfp_data_numrows):
for j in range (0, rfp_data_numcols):
rfp_data[i][j] = ODconv(rfp_data[i][j])
#store standard deviation data
stddev_data = np.zeros((NumDataSet, input_data_numrows))
for i in range(input_data_numcols, input_data_numcols + NumDataSet): # Iterate through all columns
stddev_data[i-input_data_numcols, :] = input_data.iloc[:, i]
stddev_data_numrows = stddev_data.shape[0]
stddev_data_numcols = stddev_data.shape[1]
# convert RFP/OD into Molar/OD
for i in range(0, stddev_data_numrows):
for j in range(0, stddev_data_numcols):
stddev_data[i][j] = ODconv(stddev_data[i][j])
return raw_data_header
```
<Overlap Ratio: 0.9666080843585237>

---

--- 51 --
Question ID: 6f47eee79a702f7d677979c76cfa7e6c0f56a14e_2
Original Code:
```
def get_num_from_precision(precision: int) -> decimal.Decimal:
    """
    :param precision:  0
    :return:  precision 
    """
    if precision < 0:
        raise ValueError('precision  0')
    return decimal.Decimal('1e{}'.format(-precision))
```


Overlapping Code:
```
om_precision(precision: int) -> decimal.Decimal:
"""
:param precision:  0
:return:  precision 
"""
if precision < 0:
raise ValueError('precision  0')
return decimal.Decimal('1e{}'.
```
<Overlap Ratio: 0.8583690987124464>

---

--- 52 --
Question ID: 04e31660902b5e889bb5392c7f71a26c9cce503f_4
Original Code:
```
def fetch_disk_by_id(id, devices):
    for d in devices:
        if d['RaidDevice'] == id:
            return d
    return []
```


Overlapping Code:
```
evices):
for d in devices:
if d['RaidDevice'] == i
```
<Overlap Ratio: 0.5154639175257731>

---

--- 53 --
Question ID: 43efbd89d4e9b634fa74a76111bf547e2652f26f_18
Original Code:
```
def OLS_prepare_data(df, model, metric='pagerank', grouped=False):
    data = df.query("kind == @model & metric == @metric").copy()
    if grouped:
        data = data.groupby(['fm','hmm','hMM','kind','metric']).mean().reset_index()
    #data.loc[:,'pw'] = data.apply(lambda row: int(row.metric=='pagerank'), axis=1)
    #data.loc[:,'hMM-hmm'] = data.apply(lambda row: row.hMM-row.hmm, axis=1)
    #data.loc[:,'abs(hMM-hmm)'] = data.apply(lambda row: abs(row.hMM-row.hmm), axis=1)
    data.loc[:,'Intercept'] = 1
    return data
```


Overlapping Code:
```
metric='pagerank', grouped=False):
data = df.query("kind == @model & metric == @metric").copy()
if grouped:
data = data.groupby(['fm','hmm','hMM','kind','metric']).mean().reset_index()
#data.loc[:,'pw'] = data.apply(lambda row: int(row.metric=='pagerank'), axis=1)
#data.loc[:,'hMM-hmm'] = data.apply(lambda row: row.hMM-row.hmm, axis=1)
#data.loc[:,'abs(hMM-hmm)'] = data.apply(lambda row: abs(row.hMM-row.hmm), axis=1)
data.loc[:,'Intercept'] = 1
r
```
<Overlap Ratio: 0.9146341463414634>

---

--- 54 --
Question ID: f11ca4d13cb39dfc5e8be3003105ccf6e96296bd_10
Original Code:
```
def predict_mpan512(subdir, model,conf_thres=0.95):
    mx, my = get_overlap_poly()
    patch_creator = p512
    keep_all = []
    tifimages_pan = glob.glob(''.join([subdir, 'PAN/', '*.tif']))
    tifimages_ms = [''.join([subdir, 'MS/', item.split('/')[-1].replace('PAN', 'MS')]) for item in tifimages_pan]
    for ms, pan in list(zip(tifimages_ms, tifimages_pan)):
        anns = {}
        image_id = ms.split('/')[-1].replace('.tif', '').replace('MS_', '')
        img_patches,img = get_mpan_image_patches(ms,pan,patch_creator)
        if img is None:
            keep_all.extend([[image_id,-1,'POLYGON EMPTY','POLYGON EMPTY']])
            continue
        shifts = {}
        for k in patch_creator.coords.keys():
            shifts[k] = (patch_creator.coords[k][2], patch_creator.coords[k][0])
        spacenet_predctions_default = get_predictions_spacenet(image_id, img_patches, model, shifts,conf_thres=conf_thres)
        anns[0] = spacenet_predctions_default
        xx = [[0, 512, 256, 768],[388,900,256,768]]
        yy = [[256, 768, 0, 512],[256,768,388,900]]
        shift_x = {0: (0, 256), 1: (388, 256)}
        shift_y = {k: (v[1], v[0]) for k, v in shift_x.items()}
        img_patches = []
        for ix in yy:
            img_patches.append(img[ix[0]:ix[1], ix[2]:ix[3], :])
        img_patches = np.asarray(img_patches)
        spacenet_predctions_x = get_predictions_spacenet(image_id, img_patches, model, shift_x,conf_thres=conf_thres)
        anns[1] = spacenet_predctions_x
        img_patches = []
        for ix in xx:
            img_patches.append(img[ix[0]:ix[1], ix[2]:ix[3], :])
        img_patches = np.asarray(img_patches)
        spacenet_predctions_y = get_predictions_spacenet(image_id, img_patches, model, shift_y,conf_thres=conf_thres)
        anns[2] = spacenet_predctions_y
        keep = get_final_annotations(image_id,anns,mx,my)
        if keep == []:
            keep = [[image_id, -1, 'POLYGON EMPTY', "POLYGON EMPTY"]]
        keep_all.extend(keep)
    return keep_all
```


Overlapping Code:
```
el,conf_thres=0.95):
mx, my = get_overlap_poly()
patch_creator = p512
keep_all = []
tifimages_pan = glob.glob(''.join([subdir, 'PAN/', '*.tif']))
tifimages_ms = [''.join([subdir, 'MS/', item.split('/')[-1].replace('PAN', 'MS')]) for item in tifimages_pan]
for ms, pan in list(zip(tifimages_ms, tifimages_pan)):
anns = {}
image_id = ms.split('/')[-1].replace('.tif', '').replace('MS_', '')
img_patches,img = get_mpan_image_patches(ms,pan,patch_creator)
if img is None:
keep_all.extend([[image_id,-1,'POLYGON EMPTY','POLYGON EMPTY']])
continue
shifts = {}
for k in patch_creator.coords.keys():
shifts[k] = (patch_creator.coords[k][2], patch_creator.coords[k][0])
spacenet_predctions_default = get_predictions_spacenet(image_id, img_patches, model, shifts,conf_thres=conf_thres)
anns[0] = spacenet_predctions_default
xx = [[0, 512, 256, 768],[388,900,256,768]]
yy = [[256, 768, 0, 512],[256,768,388,900]]
shift_x = {0: (0, 256), 1: (388, 256)}
shift_y = {k: (v[1], v[0]) for k, v in shift_x.items()}
img_patches = []
for ix in yy:
img_patches.append(img[ix[0]:ix[1], ix[2]:ix[3], :])
img_patches = np.asarray(img_patches)
spacenet_predctions_x = get_predictions_spacenet(image_id, img_patches, model, shift_x,conf_thres=conf_thres)
anns[1] = spacenet_predctions_x
img_patches = []
for ix in xx:
img_patches.append(img[ix[0]:ix[1], ix[2]:ix[3], :])
img_patches = np.asarray(img_patches)
spacenet_predctions_y = get_predictions_spacenet(image_id, img_patches, model, shift_y,conf_thres=conf_thres)
anns[2] = spacenet_predctions_y
keep = get_final_annotations(image_id,anns,mx,my)
if keep == []:
keep = [[image_id, -1, 'POLYGON EMPTY', "POLYGON EMPTY"]]
ke
```
<Overlap Ratio: 0.9615384615384616>

---

--- 55 --
Question ID: 104ab3347ad29648ea47da6ffbc0282f1f77a64e_12
Original Code:
```
def load_snap_patents_mat(nclass=5):
    fulldata = scipy.io.loadmat(f'{DATAPATH}/snap_patents.mat')

    dataset = NCDataset('snap_patents')
    edge_index = torch.tensor(fulldata['edge_index'], dtype=torch.long)
    node_feat = torch.tensor(
        fulldata['node_feat'].todense(), dtype=torch.float)
    num_nodes = int(fulldata['num_nodes'])
    dataset.graph = {'edge_index': edge_index,
                     'edge_feat': None,
                     'node_feat': node_feat,
                     'num_nodes': num_nodes}

    years = fulldata['years'].flatten()
    label = even_quantile_labels(years, nclass, verbose=False)
    dataset.label = torch.tensor(label, dtype=torch.long)

    return dataset
```


Overlapping Code:
```
lldata = scipy.io.loadmat(f'{DATAPATH}/snap_patents.mat')
dataset = NCDataset('snap_patents')
edge_index = torch.tensor(fulldata['edge_index'], dtype=torch.long)
node_feat = torch.tensor(
fulldata['node_feat'].todense(), dtype=torch.float)
num_nodes = int(fulldata['num_nodes'])
dataset.graph = {'edge_index': edge_index,
'edge_feat': None,
'node_feat': node_feat,
'num_nodes': num_nodes}
years = fulldata['years'].flatten()
label = even_quantile_labels(years, nclass, verbose=False)
dataset.label = torch.tensor(label, dtype=torch.long)
return datase
```
<Overlap Ratio: 0.9323181049069373>

---

--- 56 --
Question ID: a8b74ddcfc45ab2071f7d384beebc4e9c5b43638_1
Original Code:
```
def test_fetch_incidents(requests_mock):
    mock_data = load_mock_response('fetch_incidents_info.json')
    fetch_incidents_response = mock_data.get('FETCH_INCIDENTS_RESPONSE', {})
    fetch_incidents_params = mock_data.get('FETCH_INCIDENTS_PARAMS', {})
    fetch_incidents_results = mock_data.get('FETCH_INCIDENTS_RESULTS', {})

    api = integration.FETCH_INCIDENTS_API.format(
        MONITOR_ID=MONITOR_ID,
        API_KEY=API_KEY,
        max_results=fetch_incidents_params.get('max_results', 0))

    url = f'{integration.BASE_URL}/{api}'
    requests_mock.post(url, json=fetch_incidents_response)
    next_run, incidents = integration.fetch_incidents(
        CLIENT,
        max_results=fetch_incidents_params.get('max_results', 0),
        last_run=fetch_incidents_params.get('last_run', {}),
        first_fetch_time=fetch_incidents_params.get('first_fetch_time', 0),
        incident_types=fetch_incidents_params.get('incident_types', []))

    assert next_run == fetch_incidents_results.get('next_run')
    assert len(incidents) == len(fetch_incidents_results.get('incidents', [])) == 1
    assert isinstance(incidents, list) == isinstance(fetch_incidents_results.get('incidents', []), list)
    assert incidents[0]["name"] == fetch_incidents_results.get('incidents', [])[0]["name"]
    assert incidents[0]["occurred"] == fetch_incidents_results.get('incidents', [])[0]["occurred"]
    assert json.loads(incidents[0]["rawJSON"]) == fetch_incidents_results.get('incidents', [])[0]["rawJSON"]
```


Overlapping Code:
```
st_fetch_incidents(requests_mock):
mock_data = load_mock_response('fetch_incidents_info.json')
fetch_incidents_response = mock_data.get('FETCH_INCIDENTS_RESPONSE', {})
fetch_incidents_params = mock_data.get('FETCH_INCIDENTS_PARAMS', {})
fetch_incidents_results = mock_data.get('FETCH_INCIDENTS_RESULTS', {})
api = integration.FETCH_INCIDENTS_API.format(
MONITOR_ID=MONITOR_ID,
API_KEY=API_KEY,
max_results=fetch_incidents_params.get('max_results', 0))
url = f'{integration.BASE_URL}/{api}'
requests_mock.post(url, json=fetch_incidents_response)
next_run, incidents = integration.fetch_incidents(
CLIENT,
max_results=fetch_incidents_params.get('max_results', 0),
last_run=fetch_incidents_params.get('last_run', {}),
first_fetch_time=fetch_incidents_params.get('first_fetch_time', 0),
incident_types=fetch_incidents_params.get('incident_types', []))
assert next_run == fetch_incidents_results.get('next_run')
assert len(incidents) == len(fetch_incidents_results.get('incidents', [])) == 1
assert isinstance(incidents, list) == isinstance(fetch_incidents_results.get('incidents', []), list)
assert incidents[0]["name"] == fetch_incidents_results.get('incidents', [])[0]["name"]
assert incidents[0]["occurred"] == fetch_incidents_results.get('incidents', [])[0]["occurred"]
assert json.loads(incidents[0]["rawJSON"]) == fetch_incidents_results.get('incid
```
<Overlap Ratio: 0.9782608695652174>

---

--- 57 --
Question ID: 4c73435f64aa998e77846a2f2119fef0969e7063_2
Original Code:
```
def ensure_ordering(
    expression: Expression,
    *,
    ordering: OrderingHint = None,
) -> Sequence[Variable]:
    """Get a canonical ordering of the variables in the expression, or pass one through.

    The canonical ordering of the variables in a given expression is based on the alphabetical
    sort order of the variables based on their names.

    :param expression: The expression to get a canonical ordering from.
    :param ordering: A given ordering to pass through if not none, otherwise calculate it.
    :returns: The ordering
    """
    if ordering is not None:
        return _upgrade_ordering(ordering)
    # use alphabetical ordering
    return _sorted_variables(expression.get_variables())
```


Overlapping Code:
```
: Expression,
*,
ordering: OrderingHint = None,
) -> Sequence[Variable]:
"""Get a canonical ordering of the variables in the expression, or pass one through.
The canonical ordering of the variables in a given expression is based on the alphabetical
sort order of the variables based on their names.
:param expression: The expression to get a canonical ordering from.
:param ordering: A given ordering to pass through if not none, otherwise calculate it.
:returns: The ordering
"""
if ordering is not None:
return _upgrade_ordering(ordering)
# use alphabetical ordering
return _sorted_variables(expres
```
<Overlap Ratio: 0.9202453987730062>

---

--- 58 --
Question ID: a16e14e1249d975ce0be4d15725ae70a8d3a8290_2
Original Code:
```
@xfail_incompatible
def test_hash_invalid_algorithm():
    with pytest.raises(pip_api.exceptions.InvalidArguments):
        pip_api.hash("whatever", "invalid")
```


Overlapping Code:
```
d_algorithm():
with pytest.raises(pip_api.exceptions.InvalidArguments):
pip_api.hash("whatever", "in
```
<Overlap Ratio: 0.6802721088435374>

---

--- 59 --
Question ID: 0a0f367c1c51a056826cfa4caa983d4254925a8b_31
Original Code:
```
def sh_chebyt(n, monic=False):
    r"""Shifted Chebyshev polynomial of the first kind.

    Defined as :math:`T^*_n(x) = T_n(2x - 1)` for :math:`T_n` the nth
    Chebyshev polynomial of the first kind.

    Parameters
    ----------
    n : int
        Degree of the polynomial.
    monic : bool, optional
        If `True`, scale the leading coefficient to be 1. Default is
        `False`.

    Returns
    -------
    T : orthopoly1d
        Shifted Chebyshev polynomial of the first kind.

    Notes
    -----
    The polynomials :math:`T^*_n` are orthogonal over :math:`[0, 1]`
    with weight function :math:`(x - x^2)^{-1/2}`.

    """
    base = sh_jacobi(n, 0.0, 0.5, monic=monic)
    if monic:
        return base
    if n > 0:
        factor = 4**n / 2.0
    else:
        factor = 1.0
    base._scale(factor)
    return base
```


Overlapping Code:
```
nic=False):
r"""Shifted Chebyshev polynomial of the first kind.
Defined as :math:`T^*_n(x) = T_n(2x - 1)` for :math:`T_n` the nth
Chebyshev polynomial of the first kind.
Parameters
----------
n : int
Degree of the polynomial.
monic : bool, optional
If `True`, scale the leading coefficient to be 1. Default is
`False`.
Returns
-------
T : orthopoly1d
Shifted Chebyshev polynomial of the first kind.
Notes
-----
The polynomials :math:`T^*_n` are orthogonal over :math:`[0, 1]`
with weight function :math:`(x - x^2)^{-1/2}`.
"""
base = sh_jacobi(n, 0.0, 0.5, monic=monic)
if monic:
return base
if n > 0:
factor = 4**n / 2.0
else:
factor = 1.0
base._scale(factor)
re
```
<Overlap Ratio: 0.959479015918958>

---

--- 60 --
Question ID: f51b1c7f0c17fcfb1632176cae5ed2d15d54f5a6_5
Original Code:
```
def _handle_login_response(request):
    """ This function is used to get the login response of authorization request from microsoft login page.

    :param request: Data given to REST endpoint
    :return: HttpResponse. The response displayed on authorization URL page
    """

    asset_id = request.GET.get('state')
    if not asset_id:
        return HttpResponse('ERROR: Asset ID not found in URL\n{}'.format(json.dumps(request.GET)), content_type="text/plain", status=400)

    # Check for error in URL
    error = request.GET.get('error')
    error_description = request.GET.get('error_description')

    # If there is an error in response
    if error:
        message = 'Error: {0}'.format(error)
        if error_description:
            message = '{0} Details: {1}'.format(message, error_description)
        return HttpResponse('Server returned {0}'.format(message), content_type="text/plain", status=400)

    code = request.GET.get('code')
    admin_consent = request.GET.get('admin_consent')

    # If none of the code or admin_consent is available
    if not (code or admin_consent):
        return HttpResponse('Error while authenticating\n{0}'.format(json.dumps(request.GET)), content_type="text/plain", status=400)

    state = _load_app_state(asset_id)

    # If value of admin_consent is available
    if admin_consent:
        if admin_consent == 'True':
            admin_consent = True
        else:
            admin_consent = False

        state['admin_consent'] = admin_consent
        _save_app_state(state, asset_id, None)

        # If admin_consent is True
        if admin_consent:
            return HttpResponse('Admin Consent received. Please close this window.', content_type="text/plain")
        return HttpResponse('Admin Consent declined. Please close this window and try again later.', content_type="text/plain", status=400)

    # If value of admin_consent is not available, value of code is available
    state['code'] = code
    try:
        state['code'] = MicrosoftTeamConnector().encrypt_state(code, "code")
        state[MSTEAMS_STATE_IS_ENCRYPTED] = True
    except Exception as e:
        return HttpResponse("{}: {}".format(MSTEAMS_ENCRYPTION_ERR, str(e)), content_type="text/plain", status=400)
    _save_app_state(state, asset_id, None)

    return HttpResponse('Code received. Please close this window, the action will continue to get new token.', content_type="text/plain")
```


Overlapping Code:
```
def _handle_login_response(request):
""" This function is used to get the login response of authorization request from microsoft login page.
:param request: Data given to REST endpoint
:return: HttpResponse. The response displayed on authorization URL page
"""
asset_id = request.GET.get('state')
if not asset_id:
return HttpResponse('ERROR: Asset ID not found in URL\n{}'.format(json.dumps(request.GET)), content_type="text/plain", status=400)
# Check for error in URL
error = request.GET.get('error')
error_description = request.GET.get('error_description')
# If there is an error in response
if error:
message = 'Error: {0}'.format(error)
if error_description:
message = '{0} Details: {1}'.format(message, error_description)
return HttpResponse('Server returned {0}'.format(message), content_type="text/plain", status=400)
code = request.GET.get('code')
admin_consent = request.GET.get('admin_consent')
# If none of the code or admin_consent is available
if not (code or admin_consent):
return HttpResponse('Error while authenticating\n{0}'.format(json.dumps(request.GET)), content_type="text/plain", status=400)
state = _load_app_state(asset_id)
# If value of admin_consent is available
if admin_consent:
if admin_consent == 'True':
admin_consent = True
else:
admin_consent = False
state['admin_consent'] = admin_consent
_save_app_state(state, asset_id, None)
# If admin_consent is True
if admin_consent:
return HttpResponse('Admin Consent received. Please close this window.', content_type="text/plain")
return HttpResponse('Admin Consent declined. Please close this window and try again later.', content_type="text/plain", status=400)
# If value of admin_consent is not available, value of code is available
state['code'] = code
try:
state['code'] = MicrosoftTeamConnector().encrypt_state(code, "code")
state[MSTEAMS_STATE_IS_ENCRYPTED] = True
except Exception as e:
return HttpResponse("{}: {}".format(MSTEAMS_ENCRYPTION_ERR, str(e)), content_type="text/plain", status=400)
_save_app_state(state, asset_id, None)
return HttpResponse('Code received. Please close this window, the action will continue to get new token.', content_type="text/
```
<Overlap Ratio: 0.9967487227124942>

---

--- 61 --
Question ID: 6a8f6859f816b4625cf3dab39935f25bd872f783_1
Original Code:
```
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('input_file_name')
    parser.add_argument('temp_file_name')

    args, extra_args = parser.parse_known_args()
    run_test_once(args, extra_args)
```


Overlapping Code:
```
def main():
parser = argparse.ArgumentParser()
parser.add_argument('input_file_name')
parser.add_argument('temp_file_name')
args, extra_args = parser.parse_known_args()
run_test_onc
```
<Overlap Ratio: 0.905>

---

--- 62 --
Question ID: 54c77769f977a7f078c48115055697d6b756a565_2
Original Code:
```
def merge_and_filter(peaks, args):
    rep_peaks = get_replicating_peaks( peaks )
    fil_peaks = filter_by_guide_coverage( rep_peaks, 
                                          pd.read_table( args.casa_guide_file, sep='\t', header=0 )['Coordinates'],
                                          min_coverage=args.min_guide_coverage
                                        )
    return fil_peaks
```


Overlapping Code:
```
ilter(peaks, args):
rep_peaks = get_replicating_peaks( peaks )
fil_peaks = filter_by_guide_coverage( rep_peaks, 
pd.read_table( args.casa_guide_file, sep='\t', header=0 )['Coordinates'],
min_coverage=
```
<Overlap Ratio: 0.7782101167315175>

---

--- 63 --
Question ID: a0d20afe0549e14c55c4ce0b0a5034b779526488_6
Original Code:
```
def sweep_render_dir(render_dir: str):
    """Checks to see if the rendering directory exists. If it does, it removes
    it and recreates a new rendering directory.
    """
    if os.path.exists(render_dir):
        shutil.rmtree(render_dir)
    os.mkdir(render_dir)
```


Overlapping Code:
```
"Checks to see if the rendering directory exists. If it does, it removes
it and recreates a new rendering directory.
"""
if os.path.exists(render_dir)
```
<Overlap Ratio: 0.6276150627615062>

---

--- 64 --
Question ID: 87d69495cb6e86db0b07fa1502909e7e45ef8903_2
Original Code:
```
@app.route('/mongodb/phone/<phone>/<sum>')
def send_data(phone, sum):
	try:
		r = requests.get(URL + '/send_data/'+phone+'/'+sum)
		if(r.text == 'nice'):
			user = users.find_one({'phone': phone, "onTelegram": False})
			print(user)
			if(user != None):
				send_to_whatsapp(phone, sum)
			return 'good'
		elif(r.text == 'bad'):
			return 'bad'
	except:	
		return 'server error'
```


Overlapping Code:
```
.route('/mongodb/phone/<phone>/<sum>')
def send_data(phone, sum):
try:
r = requests.get(URL + '/send_data/'+phone+'/'+sum)
if(r.text == 'nice'):
user = users.find_one({'phone': phone, "onTelegram": False})
print(user)
if(user != None):
send_to_whatsapp(phone, sum)
return 'good'
elif(r.text == 'bad')
```
<Overlap Ratio: 0.8595988538681948>

---

--- 65 --
Question ID: c65ed685f87e62d0f2de0d657da543ea6bdb99eb_11
Original Code:
```
def prod(val, axis=-1, keepdims=False):
    """The product."""
    if get_backend() == "pytorch":
        import torch

        return torch.prod(val, dim=axis, keepdim=keepdims)
    else:
        import tensorflow as tf

        return tf.reduce_prod(val, axis=axis, keepdims=keepdims)
```


Overlapping Code:
```
he product."""
if get_backend() == "pytorch":
import torch
return torch.prod(val, dim=axis, keepdim=keepdims)
else:
import tensorflow as tf
return tf.
```
<Overlap Ratio: 0.625>

---

--- 66 --
Question ID: 7f0f344eccafaa0e224e4249c0f028bd8d1ed2a6_4
Original Code:
```
def test_is_excluded_record():
    # file
    assert ExcludeSearch.is_excluded_record(
        rec_file_name="chapter_exclude_all/",
        rec_header_name=None,
        to_exclude=[("chapter_exclude_all.md", None)],
    )
    # file with multiple excluded
    assert not ExcludeSearch.is_excluded_record(
        rec_file_name="chapter_exclude_all/",
        rec_header_name=None,
        to_exclude=[("chapter_exclude_all.md", "something.md")],
    )
    # file + header (not specifically excluded)
    assert ExcludeSearch.is_excluded_record(
        rec_file_name="chapter_exclude_all/",
        rec_header_name="header-chapter_exclude_all-aex",
        to_exclude=[("chapter_exclude_all.md", None)],
    )
    # file + header (specifically excluded)
    assert ExcludeSearch.is_excluded_record(
        rec_file_name="chapter_exclude_all/",
        rec_header_name="header-chapter_exclude_all-aex",
        to_exclude=[("chapter_exclude_all.md", "header-chapter_exclude_all-aex")],
    )
    # file in dir
    assert ExcludeSearch.is_excluded_record(
        rec_file_name="dir/dir_chapter_exclude_all/",
        rec_header_name=None,
        to_exclude=[("dir/dir_chapter_exclude_all.md", None)],
    )
    # all dir
    assert ExcludeSearch.is_excluded_record(
        rec_file_name="all_dir/some-chapter/",
        rec_header_name=None,
        to_exclude=[("all_dir/*", None)],
    )
    assert ExcludeSearch.is_excluded_record(
        rec_file_name="all_dir/some-chapter/",
        rec_header_name=None,
        to_exclude=[("all_dir/*", None)],
    )
    # all dir + header
    assert ExcludeSearch.is_excluded_record(
        rec_file_name="all_dir/some-chapter/",
        rec_header_name="all_dir/some-chapter-aex",
        to_exclude=[("all_dir/*", None)],
    )
    # all subdir
    assert ExcludeSearch.is_excluded_record(
        rec_file_name="all_dir_sub/all_dir_sub2/some-chapter/",
        rec_header_name=None,
        to_exclude=[("all_dir_sub/all_dir_sub2/*", None)],
    )
    # all subdir + header
    assert ExcludeSearch.is_excluded_record(
        rec_file_name="all_dir_sub/all_dir_sub2/some-chapter/",
        rec_header_name="alldir-header-all_dir_sub2-aex",
        to_exclude=[("all_dir_sub/all_dir_sub2/*", None)],
    )
    # file within subdir wildcard
    assert ExcludeSearch.is_excluded_record(
        rec_file_name="all_dir_sub/all_dir_sub2/all_dir_sub2_1/",
        rec_header_name=None,
        to_exclude=[("all_dir_sub/*/all_dir_sub2_1.md", None)],
    )
    # file within multiple subdir wildcard
    assert ExcludeSearch.is_excluded_record(
        rec_file_name="all_dir_sub/all_dir_sub2/all_dir_sub2_again/all_dir_sub2_1/",
        rec_header_name=None,
        to_exclude=[("all_dir_sub/*/all_dir_sub2_1.md", None)],
    )
    # file within multiple subdir wildcard + header
    assert ExcludeSearch.is_excluded_record(
        rec_file_name="all_dir_sub/all_dir_sub2/all_dir_sub2_again/all_dir_sub2_1/",
        rec_header_name="alldir-header-all_dir_sub2-aex",
        to_exclude=[
            ("all_dir_sub/*/all_dir_sub2_1.md", "alldir-header-all_dir_sub2-aex")
        ],
    )
```


Overlapping Code:
```
):
# file
assert ExcludeSearch.is_excluded_record(
rec_file_name="chapter_exclude_all/",
rec_header_name=None,
to_exclude=[("chapter_exclude_all.md", None)],
)
# file with multiple excluded
assert not ExcludeSearch.is_excluded_record(
rec_file_name="chapter_exclude_all/",
rec_header_name=None,
to_exclude=[("chapter_exclude_all.md", "something.md")],
)
# file + header (not specifically excluded)
assert ExcludeSearch.is_excluded_record(
rec_file_name="chapter_exclude_all/",
rec_header_name="header-chapter_exclude_all-aex",
to_exclude=[("chapter_exclude_all.md", None)],
)
# file + header (specifically excluded)
assert ExcludeSearch.is_excluded_record(
rec_file_name="chapter_exclude_all/",
rec_header_name="header-chapter_exclude_all-aex",
to_exclude=[("chapter_exclude_all.md", "header-chapter_exclude_all-aex")],
)
# file in dir
assert ExcludeSearch.is_excluded_record(
rec_file_name="dir/dir_chapter_exclude_all/",
rec_header_name=None,
to_exclude=[("dir/dir_chapter_exclude_all.md", None)],
)
# all dir
assert ExcludeSearch.is_excluded_record(
rec_file_name="all_dir/some-chapter/",
rec_header_name=None,
to_exclude=[("all_dir/*", None)],
)
assert ExcludeSearch.is_excluded_record(
rec_file_name="all_dir/some-chapter/",
rec_header_name=None,
to_exclude=[("all_dir/*", None)],
)
# all dir + header
assert ExcludeSearch.is_excluded_record(
rec_file_name="all_dir/some-chapter/",
rec_header_name="all_dir/some-chapter-aex",
to_exclude=[("all_dir/*", None)],
)
# all subdir
assert ExcludeSearch.is_excluded_record(
rec_file_name="all_dir_sub/all_dir_sub2/some-chapter/",
rec_header_name=None,
to_exclude=[("all_dir_sub/all_dir_sub2/*", None)],
)
# all subdir + header
assert ExcludeSearch.is_excluded_record(
rec_file_name="all_dir_sub/all_dir_sub2/some-chapter/",
rec_header_name="alldir-header-all_dir_sub2-aex",
to_exclude=[("all_dir_sub/all_dir_sub2/*", None)],
)
# file within subdir wildcard
assert ExcludeSearch.is_excluded_record(
rec_file_name="all_dir_sub/all_dir_sub2/all_dir_sub2_1/",
rec_header_name=None,
to_exclude=[("all_dir_sub/*/all_dir_su
```
<Overlap Ratio: 0.9786527514231499>

---

--- 67 --
Question ID: d879d766d4f7534558bd009e0e7f419ae03a5ea6_0
Original Code:
```
def rstjinja(app, docname, source):
    """
    Render our pages as a jinja template for fancy templating goodness.
    """
    # Make sure we're outputting HTML
    if app.builder.format != "html":
        return
    src = source[0]
    rendered = app.builder.templates.render_string(src, app.config.html_context)
    source[0] = rendered
```


Overlapping Code:
```
ef rstjinja(app, docname, source):
"""
Render our pages as a jinja template for fancy templating goodness.
"""
# Make sure we're outputting HTML
if app.builder.format != "html":
return
src = source[0]
rendered = app.builder.templates.render_string(src, app.config.html_context)
source[0] = rende
```
<Overlap Ratio: 0.9866220735785953>

---

--- 68 --
Question ID: c0ad2b0d7ce7ffcea0faf8560c9928107a634ddd_1
Original Code:
```
def build_matrix(variants: Manager) -> list:
    variant_colors = variants.filter().distinct('color').values('color')
    sorted_colors = get_sorted_values(
        Color,
        variant_colors
    )

    variant_sizes = variants.filter().distinct('size').values('size')
    sorted_sizes = get_sorted_values(
        Size,
        variant_sizes
    )

    matrix = build_structure(sorted_sizes.count(), sorted_colors.count())

    matrix = place_variants_into_matrix(
        matrix,
        variants,
        list(sorted_colors.values_list('id', flat=True)),
        list(sorted_sizes.values_list('id', flat=True))
    )

    return matrix
```


Overlapping Code:
```
) -> list:
variant_colors = variants.filter().distinct('color').values('color')
sorted_colors = get_sorted_values(
Color,
variant_colors
)
variant_sizes = variants.filter().distinct('size').values('size')
sorted_sizes = get_sorted_values(
Size,
variant_sizes
)
matrix = build_structure(sorted_sizes.count(), sorted_colors.count())
matrix = place_variants_into_matrix(
matrix,
variants,
list(sorted_colors.values_list('id', flat=True)),
list(sorted_si
```
<Overlap Ratio: 0.8442776735459663>

---

--- 69 --
Question ID: ca1ace6fee57dd9d4e4378b1a46a68e1094fe02c_17
Original Code:
```
def presidual_layer(tparams, state_below, options, prefix='presidual', mask=None,
                    one_step=False, init_state=None, **kwargs):
    '''
    parametric residual layer (recurrent depth adjustable)
    parametric vector on identity connection
    '''
    if one_step:
        assert init_state, 'previous state must be provided'

    # here state_below in x_emb
    nsteps = state_below.shape[0]
    depth = options['unit_depth']
    dim = options['dim_proj']
    if state_below.ndim == 3:
        n_samples = state_below.shape[1]
    else:
        n_samples = 1

    if mask is None:
        mask = tensor.alloc(1., state_below.shape[0], 1)

    def _slice(_x, n, dim):
        if _x.ndim == 3:
            return _x[:, :, n * dim:(n + 1) * dim]
        return _x[:, n * dim:(n + 1) * dim]

    # input mask, x(t), h(t-1)
    def _presblock(m_, x_, h_):
        y = h_
        for idx in xrange(depth):
            hy = tensor.dot(y, tparams[_p(prefix, 'U'+str(idx+1))])
            y = tensor.nnet.sigmoid(_slice(x_, idx, dim) + hy)
        # p = 2*sigmoid(wh(t-1)+b)-1
        p = 2 * tensor.nnet.sigmoid(tensor.dot(h_, tparams[_p(prefix, 'w_res')]) + tparams[_p(prefix, 'b_res')]) - 1
        p_vec = p.reshape(p.shape[0], 1)
        # h(t) = tanh(ph(t-1)+y)
        h = tensor.tanh(tensor.dot(tensor.nlinalg.alloc_diag(p_vec), h_) + y)
        h = m_[:, None] * h + (1. - m_)[:, None] * h_
        return h

    # state_below = W*x(t)+b (for all inter_state y)
    state_below = (tensor.dot(state_below, tparams[_p(prefix, 'W')]) +
                   tparams[_p(prefix, 'b')])

    if init_state is None:
        init_state = tensor.alloc(numpy_floatX(0.), n_samples, dim)

    if one_step:
        rval = _presblock(mask, state_below, init_state)
    else:
        rval, updates = theano.scan(_presblock,
                                    sequences=[mask, state_below],
                                    outputs_info=[init_state],
                                    name=_p(prefix, 'layers'),
                                    n_steps=nsteps)
    # rval = [rval] # note: for consistency among model layers
    return rval
```


Overlapping Code:
```
ptions, prefix='presidual', mask=None,
one_step=False, init_state=None, **kwargs):
'''
parametric residual layer (recurrent depth adjustable)
parametric vector on identity connection
'''
if one_step:
assert init_state, 'previous state must be provided'
# here state_below in x_emb
nsteps = state_below.shape[0]
depth = options['unit_depth']
dim = options['dim_proj']
if state_below.ndim == 3:
n_samples = state_below.shape[1]
else:
n_samples = 1
if mask is None:
mask = tensor.alloc(1., state_below.shape[0], 1)
def _slice(_x, n, dim):
if _x.ndim == 3:
return _x[:, :, n * dim:(n + 1) * dim]
return _x[:, n * dim:(n + 1) * dim]
# input mask, x(t), h(t-1)
def _presblock(m_, x_, h_):
y = h_
for idx in xrange(depth):
hy = tensor.dot(y, tparams[_p(prefix, 'U'+str(idx+1))])
y = tensor.nnet.sigmoid(_slice(x_, idx, dim) + hy)
# p = 2*sigmoid(wh(t-1)+b)-1
p = 2 * tensor.nnet.sigmoid(tensor.dot(h_, tparams[_p(prefix, 'w_res')]) + tparams[_p(prefix, 'b_res')]) - 1
p_vec = p.reshape(p.shape[0], 1)
# h(t) = tanh(ph(t-1)+y)
h = tensor.tanh(tensor.dot(tensor.nlinalg.alloc_diag(p_vec), h_) + y)
h = m_[:, None] * h + (1. - m_)[:, None] * h_
return h
# state_below = W*x(t)+b (for all inter_state y)
state_below = (tensor.dot(state_below, tparams[_p(prefix, 'W')]) +
tparams[_p(prefix, 'b')])
if init_state is None:
init_state = tensor.alloc(numpy_floatX(0.), n_samples, dim)
if one_step:
rval = _presblock(mask, state_below, init_state)
else:
rval, updates = theano.scan(_presblock,
sequences=[mask, state_below],
outputs_info=[init_state],
name=_p(prefix, 'layers'),
n_steps=nsteps)
# rval = [rval] # note: for
```
<Overlap Ratio: 0.9491425192193969>

---

--- 70 --
Question ID: d4b6194eda92abd0e3e181ef505f7919702f6e19_4
Original Code:
```
def one_cone(blue, yellow):
    if len(blue)>0:
        angle = STEER_MIN
    elif len(yellow)>0:
        angle = STEER_MAX
    return angle
```


Overlapping Code:
```
e_cone(blue, yellow):
if len(blue)>0:
angle = STEER_MIN
elif len(yellow)>0:
angle = STEER_MAX
return
```
<Overlap Ratio: 0.8928571428571429>

---

--- 71 --
Question ID: 69d07fdea709287a39e1d335373a3ae770c37c00_2
Original Code:
```
def ghostSlider(ghostControls, surface, sliderParent):
    """Modify the ghost control behaviour to slide on top of a surface

    Args:
        ghostControls (dagNode): The ghost control
        surface (Surface): The NURBS surface
        sliderParent (dagNode): The parent for the slider.
    """
    if not isinstance(ghostControls, list):
        ghostControls = [ghostControls]

    # Seleccionamos los controles Ghost que queremos mover sobre el surface

    surfaceShape = surface.getShape()

    for ctlGhost in ghostControls:
        ctl = pm.listConnections(ctlGhost, t="transform")[-1]
        t = ctl.getMatrix(worldSpace=True)

        gDriver = primitive.addTransform(ctlGhost.getParent(),
                                         ctl.name() + "_slideDriver",
                                         t)

        try:
            pm.connectAttr(ctl + ".translate", gDriver + ".translate")
            pm.disconnectAttr(ctl + ".translate", ctlGhost + ".translate")
        except RuntimeError:
            pass

        try:
            pm.connectAttr(ctl + ".scale", gDriver + ".scale")
            pm.disconnectAttr(ctl + ".scale", ctlGhost + ".scale")
        except RuntimeError:
            pass

        try:
            pm.connectAttr(ctl + ".rotate", gDriver + ".rotate")
            pm.disconnectAttr(ctl + ".rotate", ctlGhost + ".rotate")
        except RuntimeError:
            pass

        oParent = ctlGhost.getParent()
        npoName = "_".join(ctlGhost.name().split("_")[:-1]) + "_npo"
        oTra = pm.PyNode(pm.createNode("transform",
                                       n=npoName,
                                       p=oParent,
                                       ss=True))
        oTra.setTransformation(ctlGhost.getMatrix())
        pm.parent(ctlGhost, oTra)

        slider = primitive.addTransform(sliderParent,
                                        ctl.name() + "_slideDriven",
                                        t)

        # connexion

        dm_node = node.createDecomposeMatrixNode(
            gDriver.attr("worldMatrix[0]"))
        cps_node = pm.createNode("closestPointOnSurface")
        dm_node.attr("outputTranslate") >> cps_node.attr("inPosition")
        surfaceShape.attr("worldSpace[0]") >> cps_node.attr("inputSurface")
        cps_node.attr("position") >> slider.attr("translate")

        pm.normalConstraint(surfaceShape,
                            slider,
                            aimVector=[0, 0, 1],
                            upVector=[0, 1, 0],
                            worldUpType="objectrotation",
                            worldUpVector=[0, 1, 0],
                            worldUpObject=gDriver)

        pm.parent(ctlGhost.getParent(), slider)
```


Overlapping Code:
```
ntrols, surface, sliderParent):
"""Modify the ghost control behaviour to slide on top of a surface
Args:
ghostControls (dagNode): The ghost control
surface (Surface): The NURBS surface
sliderParent (dagNode): The parent for the slider.
"""
if not isinstance(ghostControls, list):
ghostControls = [ghostControls]
# Seleccionamos los controles Ghost que queremos mover sobre el surface
surfaceShape = surface.getShape()
for ctlGhost in ghostControls:
ctl = pm.listConnections(ctlGhost, t="transform")[-1]
t = ctl.getMatrix(worldSpace=True)
gDriver = primitive.addTransform(ctlGhost.getParent(),
ctl.name() + "_slideDriver",
t)
try:
pm.connectAttr(ctl + ".translate", gDriver + ".translate")
pm.disconnectAttr(ctl + ".translate", ctlGhost + ".translate")
except RuntimeError:
pass
try:
pm.connectAttr(ctl + ".scale", gDriver + ".scale")
pm.disconnectAttr(ctl + ".scale", ctlGhost + ".scale")
except RuntimeError:
pass
try:
pm.connectAttr(ctl + ".rotate", gDriver + ".rotate")
pm.disconnectAttr(ctl + ".rotate", ctlGhost + ".rotate")
except RuntimeError:
pass
oParent = ctlGhost.getParent()
npoName = "_".join(ctlGhost.name().split("_")[:-1]) + "_npo"
oTra = pm.PyNode(pm.createNode("transform",
n=npoName,
p=oParent,
ss=True))
oTra.setTransformation(ctlGhost.getMatrix())
pm.parent(ctlGhost, oTra)
slider = primitive.addTransform(sliderParent,
ctl.name() + "_slideDriven",
t)
# connexion
dm_node = node.createDecomposeMatrixNode(
gDriver.attr("worldMatrix[0]"))
cps_node = pm.createNode("closestPointOnSurface")
dm_node.attr("outputTranslate") >> cps_node.attr("inPosition")
surfaceShape.attr("worldSpace[0]") >> cps_node.attr("inputSurface")
cps_node.attr("position") >> slider.attr("translate")
pm.normalConstraint(surfaceShape,
slider,
aimVector=[0, 
```
<Overlap Ratio: 0.983698707138842>

---

--- 72 --
Question ID: a6c79024ada304313c6b02d3d173236690737192_0
Original Code:
```
def has_wireshark_env():
    """Test if wireshark GUI can run.

    Returns:
      (True, "") if wireshark can run in the environment.
      (False, Error_String) otherwise.
    """
    platform = os.uname()
    print(platform)
    if not platform:
        return False, u"Failed to get uname"
    if platform[0].lower() != u"linux":
        return False, u"Supported only on Linux"

    if not has_cmd(LINUX_BIN_WIRESHARK):
        return False, u"can\'t find %s" % LINUX_BIN_WIRESHARK

    # All look good.
    return True, u""
```


Overlapping Code:
```
has_wireshark_env():
"""Test if wireshark GUI can run.
Returns:
(True, "") if wireshark can run in the environment.
(False, Error_String) otherwise.
"""
platform = os.uname()
print(platform)
if not platform:
return False, u"Failed to get uname"
if platform[0].lower() != u"linux":
return False, u"Supported only on Linux"
if not has_cmd(LINUX_BIN_WIRESHARK):
return False, u"can\'t find %s" % LINUX_BIN_W
```
<Overlap Ratio: 0.8977777777777778>

---

--- 73 --
Question ID: 0caeb81d302573fdde3e70660b676ceddefc8756_4
Original Code:
```
def one_nash_filter(solver, threshold=0.001):
    num_players = solver._num_players
    filtered_idx_list = []
    len_filtered_strategies = []

    meta_games = solver.get_meta_game()
    policies = solver.get_policies()
    num_str, _ = np.shape(meta_games[0])
    if num_str <= solver.strategy_set_size:
        return meta_games, policies

    solver.update_meta_strategies()
    nash = solver.get_meta_strategies()

    for player in range(num_players):
        zero_pos = np.where(nash[player] <= threshold)[0]
        filtered_idx_list.append(zero_pos)
        len_filtered_strategies.append(len(zero_pos))

    if np.sum(len_filtered_strategies) == 0:
        return solver._meta_games, solver._policies

    for player in range(num_players):
        # filter meta_games.
        for dim in range(num_players):
            filtered_idx = filtered_idx_list[dim]
            meta_games[player] = np.delete(meta_games[player], filtered_idx, axis=dim)
        # filter policies.
        policies[player] = np.delete(policies[player], filtered_idx_list[player])
        policies[player] = list(policies[player])

    print("Strategies filtered:")
    num_str_players = []
    for player in range(num_players):
        print("Player " + str(player) + ":", filtered_idx_list[player])
        num_str_players.append(len(policies[player]))
    print("Number of strategies after filtering:", num_str_players)

    return meta_games, policies
```


Overlapping Code:
```
filter(solver, threshold=0.001):
num_players = solver._num_players
filtered_idx_list = []
len_filtered_strategies = []
meta_games = solver.get_meta_game()
policies = solver.get_policies()
num_str, _ = np.shape(meta_games[0])
if num_str <= solver.strategy_set_size:
return meta_games, policies
solver.update_meta_strategies()
nash = solver.get_meta_strategies()
for player in range(num_players):
zero_pos = np.where(nash[player] <= threshold)[0]
filtered_idx_list.append(zero_pos)
len_filtered_strategies.append(len(zero_pos))
if np.sum(len_filtered_strategies) == 0:
return solver._meta_games, solver._policies
for player in range(num_players):
# filter meta_games.
for dim in range(num_players):
filtered_idx = filtered_idx_list[dim]
meta_games[player] = np.delete(meta_games[player], filtered_idx, axis=dim)
# filter policies.
policies[player] = np.delete(policies[player], filtered_idx_list[player])
policies[player] = list(policies[player])
print("Strategies filtered:")
num_str_players = []
for player in range(num_players):
print("Player " + str(player) + ":", filtered_idx_list[player])
num_str_players.append(len(policies[player]))
print("Number of strategies after filtering:", num_str_players)
retu
```
<Overlap Ratio: 0.9710610932475884>

---

--- 74 --
Question ID: 962cfe04a5d241bac7617ae5d86a5dc593741238_15
Original Code:
```
def getItemsForPicsDownloading( iLimit = 50, iTooOldDays = 95 ):
    #
    # bGetPictures = True, not implemented yet
    #
    tTooOld = timezone.now() - timezone.timedelta( iTooOldDays )
    #
    qsGetPics = Keeper.objects.filter(
                    tGotPictures__isnull = True,
                    tTimeEnd__gt         = tTooOld,
                    iBidCount__gt        = 0,
                ).order_by( 'tTimeEnd'
                ).values_list( 'iItemNumb', flat = True
                )[ : iLimit ]
    #
    iWantPics = iLimit / 10
    #
    if iLimit > len( qsGetPics ):
        #
        iWantPics = iLimit - len( qsGetPics )
        #
    #
    # qsZeroBids = Keeper.objects.filter(
    #                 tGotPictures__isnull = True, iBidCount = 0
    #                 ).values_list( 'iItemNumb', flat = True )
    #
    qsZeroBids = Keeper.objects.filter(
                        iBidCount           = 0,
                        tTimeEnd__gt        = tTooOld,
                        cListingType        = 'FixedPriceItem',
                        tGotPictures__isnull= True
                    ).values_list( 'iItemNumb', flat = True
                    )[ : iWantPics ]
    #
    return qsGetPics.union( qsZeroBids )
```


Overlapping Code:
```
mit = 50, iTooOldDays = 95 ):
#
# bGetPictures = True, not implemented yet
#
tTooOld = timezone.now() - timezone.timedelta( iTooOldDays )
#
qsGetPics = Keeper.objects.filter(
tGotPictures__isnull = True,
tTimeEnd__gt = tTooOld,
iBidCount__gt = 0,
).order_by( 'tTimeEnd'
).values_list( 'iItemNumb', flat = True
)[ : iLimit ]
#
iWantPics = iLimit / 10
#
if iLimit > len( qsGetPics ):
#
iWantPics = iLimit - len( qsGetPics )
#
#
# qsZeroBids = Keeper.objects.filter(
# tGotPictures__isnull = True, iBidCount = 0
# ).values_list( 'iItemNumb', flat = True )
#
qsZeroBids = Keeper.objects.filter(
iBidCount = 0,
tTimeEnd__gt = tTooOld,
cListingType = 'FixedPriceItem',
tGotPictures__isnull= True
).values_list( 'iItemNumb', flat = True
)[ : iWantPics ]
#
r
```
<Overlap Ratio: 0.9146341463414634>

---

--- 75 --
Question ID: 568f18ef03007c0e220a26096430842fb006cf0f_0
Original Code:
```
def _parse_single_line(line: str):
    possible_separators = (":", "_", "-", "\t", " ", ";", ",", ".")
    idx = 0
    parsed_line = (line,)
    while idx < len(possible_separators):
        res = line.split(possible_separators[idx])
        if len(res) == 2:
            parsed_line = res
            break
        idx += 1

    # if we fail with the possible separators, let's see if
    # we can split up on contiguous whitespace to two pieces.

    if len(parsed_line) == 1:
        ln = re.split(r'\s+', *parsed_line)
        if len(ln) == 2:
            parsed_line = ln
    rx = '[' + re.escape(''.join(possible_separators[2:-4])) + ']'

    # remove the obvious unwanted chars
    parsed_line = [element.strip("\n").strip("\x00") for element in parsed_line]

    # remove the separator-like chars
    parsed_line = [re.sub(rx, "", el) for el in parsed_line]

    # remove whitespace around elements
    parsed_line = [element.strip(" ") for element in parsed_line]

    return parsed_line
```


Overlapping Code:
```
 str):
possible_separators = (":", "_", "-", "\t", " ", ";", ",", ".")
idx = 0
parsed_line = (line,)
while idx < len(possible_separators):
res = line.split(possible_separators[idx])
if len(res) == 2:
parsed_line = res
break
idx += 1
# if we fail with the possible separators, let's see if
# we can split up on contiguous whitespace to two pieces.
if len(parsed_line) == 1:
ln = re.split(r'\s+', *parsed_line)
if len(ln) == 2:
parsed_line = ln
rx = '[' + re.escape(''.join(possible_separators[2:-4])) + ']'
# remove the obvious unwanted chars
parsed_line = [element.strip("\n").strip("\x00") for element in parsed_line]
# remove the separator-like chars
parsed_line = [re.sub(rx, "", el) for el in parsed_line]
# remove whitespace around elements
parsed_line = [element.strip(" ") for element in parse
```
<Overlap Ratio: 0.936768149882904>

---

--- 76 --
Question ID: 7e4f941d449ba5ee070ac7ec9133e403949f6fe6_0
Original Code:
```
@mock.patch('pyecoregen.cli.EcoreGenerator')
def test__generate_from_cli(generator_mock, cwd_module_dir):
    mock_generator = generator_mock()
    mock_generator.generate = mock.MagicMock()

    generate_from_cli(['-e', 'input/library.ecore', '-o', 'some/folder'])

    # look at arguments of generate call:
    mock_generate = generator_mock().generate
    model = mock_generator.generate.call_args[0][0]
    path = mock_generator.generate.call_args[0][1]

    assert isinstance(model, pyecore.ecore.EPackage)
    assert model.name == 'library'
    assert path == 'some/folder'
```


Overlapping Code:
```
ch('pyecoregen.cli.EcoreGenerator')
def test__generate_from_cli(generator_mock, cwd_module_dir):
mock_generator = generator_mock()
mock_generator.generate = mock.MagicMock()
generate_from_cli(['-e', 'input/library.ecore', '-o', 'some/folder'])
# look at arguments of generate call:
mock_generate = generator_mock().generate
model = mock_generator.generate.call_args[0][0]
path = mock_generator.generate.call_args[0][1]
assert isinstance(model, pyecore.ecore.EPackage)
assert model.name =
```
<Overlap Ratio: 0.9085820895522388>

---

--- 77 --
Question ID: 953c1fb47142b706eed2dd69679c70b988f63382_1
Original Code:
```
def setup_relu1():
    # Construct a simple ReLU model with 2 hidden layers
    dtype = torch.float64
    relu_param = torch.tensor([
        -1, 0.5, -0.3, 0.74, -2, 1.5, -0.5, 0.2, -1, -0.5, 1.5, 1.2, 2, -1.5,
        2.6, 0.3, -2, -0.3, -.4, -0.1, 0.2, -0.5, 1.2, 1.3, -.4, .5, -.6, 0.3
    ],
                              dtype=dtype)
    return setup_relu((2, 4, 4), relu_param, negative_gradient=0.1, bias=False)
```


Overlapping Code:
```
le ReLU model with 2 hidden layers
dtype = torch.float64
relu_param = torch.tensor([
-1, 0.5, -0.3, 0.74, -2, 1.5, -0.5, 0.2, -1, -0.5, 1.5, 1.2, 2, -1.5,
2.6, 0.3, -2, -0.3, -.4, -0.1, 0.2, -0.5, 1.2, 1.3, -.4, .5, -.6, 0.3
],
dtype=dtype)
return setup_relu((2, 4, 4), relu_param, negative_gradient=
```
<Overlap Ratio: 0.8498583569405099>

---

--- 78 --
Question ID: 317e1c038ee3059652d5db98ce6cf7cc29317e97_3
Original Code:
```
def create_get_directory(parent: Path, child: str) -> Path:
    '''
    A helper function that automatically creates a directory if it doesn't exist.
    '''
    path = parent / child
    if not path.exists():
        path.mkdir(parents=True)

    return path
```


Overlapping Code:
```
: str) -> Path:
'''
A helper function that automatically creates a directory if it doesn't exist.
'''
path = parent / child
if not path.exists():
path.mkdir(parents=True)
return path
```
<Overlap Ratio: 0.8053097345132744>

---

--- 79 --
Question ID: 5dfae507c252975a6115736efcc167381500c9f5_2
Original Code:
```
def check_status(url: str) -> List[Result]:
    results: List[Result] = []
    search = ["status/", "stats/"]

    for path in search:
        target = urljoin(url, path)

        res = network.http_get(target, False)
        body = res.text

        if res.status_code == 200 and "Active connections:" in body:
            results.append(
                Result(
                    f"Nginx status page found: {target}",
                    Vulnerabilities.SERVER_NGINX_STATUS_EXPOSED,
                    target,
                    [
                        network.http_build_raw_request(res.request),
                        network.http_build_raw_response(res),
                    ],
                )
            )

        results += response_scanner.check_response(target, res)

    return results
```


Overlapping Code:
```
(url: str) -> List[Result]:
results: List[Result] = []
search = ["status/", "stats/"]
for path in search:
target = urljoin(url, path)
res = network.http_get(target, False)
body = res.text
if res.status_code == 200 and "Active connections:" in body:
results.append(
Result(
f"Nginx status page found: {target}",
Vulnerabilities.SERVER_NGINX_STATUS_EXPOSED,
target,
[
network.http_build_raw_request(res.request),
network.http_build_raw_response(res),
],
)
)
results += response_scanner.check_response(target, res)
return resu
```
<Overlap Ratio: 0.9649446494464945>

---

--- 80 --
Question ID: 1b301db7d9722f350f904e1d5905599acdb5b466_7
Original Code:
```
def calculate_blkio_bytes(d):
    """

    :param d:
    :return: (read_bytes, wrote_bytes), ints
    """
    bytes_stats = graceful_chain_get(d, "blkio_stats", "io_service_bytes_recursive")
    if not bytes_stats:
        return 0, 0
    r = 0
    w = 0
    for s in bytes_stats:
        if s["op"] == "Read":
            r += s["value"]
        elif s["op"] == "Write":
            w += s["value"]
    return r, w
```


Overlapping Code:
```
late_blkio_bytes(d):
"""
:param d:
:return: (read_bytes, wrote_bytes), ints
"""
bytes_stats = graceful_chain_get(d, "blkio_stats", "io_service_bytes_recursive")
if not bytes_stats:
return 0, 0
r = 0
w = 0
for s in bytes_stats:
if s["op"] == "Read":
r += s["value"]
elif s["op"] == "Write":
w += s["valu
```
<Overlap Ratio: 0.9263803680981595>

---

--- 81 --
Question ID: 24ce4af8344af3405e9520095667560f594757a5_0
Original Code:
```
def check_valid_value(value, valid_values):
    """ Returns None if the received `value`
    is not contained in the received `valid_values`
    """
    if value in valid_values:
        return value
    return None
```


Overlapping Code:
```
" Returns None if the received `value`
is not contained in the received `valid_values`
"""
if value 
```
<Overlap Ratio: 0.5347593582887701>

---

--- 82 --
Question ID: 64f0ef89b41246b45a0f27b2b98de5e0ee60111f_1
Original Code:
```
def test_fits2radec():
    scale = ael.fits2radec(fitsfn)

    assert scale["ra"].values[[32, 51, 98], [28, 92, 156]] == approx(
        [152.313342, 157.988921, 165.012208]
    )
    assert scale["dec"].values[[32, 51, 98], [28, 92, 156]] == approx(
        [59.982123, 59.182819, 59.149952]
    )
```


Overlapping Code:
```
.fits2radec(fitsfn)
assert scale["ra"].values[[32, 51, 98], [28, 92, 156]] == approx(
[152.313342, 157.988921, 165.012208]
)
assert scale["dec"].values[[32, 51, 98], [28, 92, 156]] == approx(
[59.9821
```
<Overlap Ratio: 0.7662835249042146>

---

--- 83 --
Question ID: 0803d9380edff055d884703703cd7ded33c22cb8_1
Original Code:
```
def sfm_loop(sfm_images, features_dir, baseline, wpSet, K, dist):
    """
    Main Structure From Motion loop.
    
    :param sfm_images: Text file of image paths.
    :param features_dir: Path of features directory.
    :param baseline: baseline of first two views.
    :param wpSet: World points data from the baseline.
    :param K: Camera intrinsic matrix.
    :param dist: Camera distortion parameters.
    """

    # Get new view. Perform linear PnP on new view to get pose information.
    view1 = baseline.view1
    view2 = baseline.view2
    completed_views = [view1, view2]

    def update_3d_points(view, completed_views, K):
        """
        Updates 3D points with the current view.
        :param view: View with which to update world 3D coordinates.
        :param completed_views: Views from which 3D points have been triangulated.
        :param K: Camera intrinsic matrix
        """
        view.rotation, view.translation = compute_pose(view, completed_views, K, img_matches)

        for view_n in completed_views:
            if view_n.id in view.tracked_pts:
                # Before triangulating, outliers should be removed using F matrix/RANSAC between x1 and x2.
                x1, x2 = remove_outliers(view, view_n)
                print("Number of points to triangulate:", x1.shape[0])
                X = triangulate_points(K, t1=view.translation, R1=view.rotation,
                                       t2=view_n.translation, R2=view_n.rotation, x1=x1, x2=x2,
                                       print_error=True)
                # add correspondences to world coordinates only if reproj errors are low for img pair
                if X is not None:
                    X = store_3Dpoints_to_views(X, view_n, view, K, error_threshold=2.0)
                    print(f"Found {len(X)} 3D points between image{view_n.name} and image{view.name}.")
                    view.reproject_view(K, print_error=True)
                    wpSet.add_correspondences(X, view, view_n)
        print(f"Found {len(view.world_points)} 3D points for new image{view.name}.")

    for i, image in enumerate(sfm_images[2:]):
        # extract features of a view
        view = ImageView(image, features_dir)
        view.read_features()
        if view.descriptors is None:
            view.extract_features(write_to_file=True)
        if view not in completed_views:
            update_3d_points(view, completed_views, K, dist)
            completed_views.append(view)
        
        # Perform bundle adjustment on new view and existing views -> Update 3D points dictionary
        wpSet.correspondences.to_csv(f'points\\point_correspondences_{i + 1}.csv')
        ba = BundleAdjustment(wpSet, K, dist, completed_views)
        poses, wpSet.world_points = ba.optimize()
        for j, view in enumerate(completed_views):
            rot_mat = (poses[j, :9]).reshape(3, 3)
            t_vec = poses[j, 9:].reshape(3, 1)
            view.rotation = rot_mat
            view.translation = t_vec
            view.update_world_points(wpSet)
            view.reproject_view(K, print_error=True)
        np.savez(f'points\\points3d_{i}', point_cloud=wpSet.world_points)

    wpSet.correspondences.to_csv('\\point_correspondences.csv')
    np.savetxt("points_3d.csv", wpSet.world_points, delimiter=",")
    return wpSet.world_points
```


Overlapping Code:
```
 baseline, wpSet, K, dist):
"""
Main Structure From Motion loop.

:param sfm_images: Text file of image paths.
:param features_dir: Path of features directory.
:param baseline: baseline of first two views.
:param wpSet: World points data from the baseline.
:param K: Camera intrinsic matrix.
:param dist: Camera distortion parameters.
"""
# Get new view. Perform linear PnP on new view to get pose information.
view1 = baseline.view1
view2 = baseline.view2
completed_views = [view1, view2]
def update_3d_points(view, completed_views, K):
"""
Updates 3D points with the current view.
:param view: View with which to update world 3D coordinates.
:param completed_views: Views from which 3D points have been triangulated.
:param K: Camera intrinsic matrix
"""
view.rotation, view.translation = compute_pose(view, completed_views, K, img_matches)
for view_n in completed_views:
if view_n.id in view.tracked_pts:
# Before triangulating, outliers should be removed using F matrix/RANSAC between x1 and x2.
x1, x2 = remove_outliers(view, view_n)
print("Number of points to triangulate:", x1.shape[0])
X = triangulate_points(K, t1=view.translation, R1=view.rotation,
t2=view_n.translation, R2=view_n.rotation, x1=x1, x2=x2,
print_error=True)
# add correspondences to world coordinates only if reproj errors are low for img pair
if X is not None:
X = store_3Dpoints_to_views(X, view_n, view, K, error_threshold=2.0)
print(f"Found {len(X)} 3D points between image{view_n.name} and image{view.name}.")
view.reproject_view(K, print_error=True)
wpSet.add_correspondences(X, view, view_n)
print(f"Found {len(view.world_points)} 3D points for new image{view.name}.")
for i, image in enumerate(sfm_images[2:]):
# extract features of a view
view = ImageView(image, features_dir)
view.read_features()
if view.descriptors is None:
view.extract_features(write_to_file=True)
if view not in completed_views:
update_3d_points(view, completed_views, K, dist)
completed_views
```
<Overlap Ratio: 0.974512743628186>

---

--- 84 --
Question ID: d91f10e4333abe30ae20c29c7c6ad3bcd4a827c6_0
Original Code:
```
def test_init(ws):
    """
    Test that :meth:`.Connection.__init__` draws attributes from the passed session and websocket handler.

    """
    assert ws.user_id == "test"
    assert ws.groups == ["admin", "test"]
    assert ws.permissions == ["create_sample"]
```


Overlapping Code:
```
:
"""
Test that :meth:`.Connection.__init__` draws attributes from the passed session and websocket handler.
"""
assert ws.user_id == "test"
assert ws.groups == ["admin", "test"]
assert ws.permissions == ["cre
```
<Overlap Ratio: 0.8781512605042017>

---

--- 85 --
Question ID: 15706a072451c3500888d62350c61f355113ef36_6
Original Code:
```
def union_bb(a,b):
    if a is None:
        return b
    elif b is None:
        return a
    elif isinstance(b,list):
        return union_bb(a,(b,b))
    else:
        return ([min(c[0],c[1]) for c in zip(a[0],b[0])],   \
                [max(c[0],c[1]) for c in zip(a[1],b[1])])
```


Overlapping Code:
```

if a is None:
return b
elif b is None:
return a
elif isinstance(b,list):
return union_bb(a,(b,b))
else:
return ([min(c[0],c[1]) for c in zip(a[0],b[0])], \
[max(c[0],
```
<Overlap Ratio: 0.7731481481481481>

---

--- 86 --
Question ID: 45108f55a094d4a955636f59156d6d792cd2f0df_1
Original Code:
```
def _find_thread_stack(thread_id):
    """Returns a stack object that can be used to dump a stack trace for
    the given thread id (or None if the id is not found).
    """
    for tid, stack in sys._current_frames().items():
        if tid == thread_id:
            return stack
    return None
```


Overlapping Code:
```
_id):
"""Returns a stack object that can be used to dump a stack trace for
the given thread id (or None if the id is not found).
"""
for tid, stack in sys._current_frames().items():
if tid == thread_i
```
<Overlap Ratio: 0.78125>

---

--- 87 --
Question ID: 4df44fc48f24e819a79de1bd3d4e9fcb8d990874_13
Original Code:
```
async def _assert_postconditions_async(postconditions: List[Contract],
                                       resolved_kwargs: Mapping[str, Any]) -> Optional[BaseException]:
    """Assert that the postconditions of an async function hold."""
    assert 'result' in resolved_kwargs, \
        "Expected 'result' to be already set in resolved kwargs before calling this function."

    for contract in postconditions:
        condition_kwargs = select_condition_kwargs(contract=contract, resolved_kwargs=resolved_kwargs)

        if inspect.iscoroutinefunction(contract.condition):
            check = await contract.condition(**condition_kwargs)
        else:
            check_or_coroutine = contract.condition(**condition_kwargs)
            if inspect.iscoroutine(check_or_coroutine):
                check = await check_or_coroutine
            else:
                check = check_or_coroutine

        if not_check(check=check, contract=contract):
            exception = _create_violation_error(contract=contract, resolved_kwargs=resolved_kwargs)

            return exception

    return None
```


Overlapping Code:
```
def _assert_postconditions_async(postconditions: List[Contract],
resolved_kwargs: Mapping[str, Any]) -> Optional[BaseException]:
"""Assert that the postconditions of an async function hold."""
assert 'result' in resolved_kwargs, \
"Expected 'result' to be already set in resolved kwargs before calling this function."
for contract in postconditions:
condition_kwargs = select_condition_kwargs(contract=contract, resolved_kwargs=resolved_kwargs)
if inspect.iscoroutinefunction(contract.condition):
check = await contract.condition(**condition_kwargs)
else:
check_or_coroutine = contract.condition(**condition_kwargs)
if inspect.iscoroutine(check_or_coroutine):
check = await check_or_coroutine
else:
check = check_or_coroutine
if not_check(check=check, contract=contract):
exception = _create_violation_error(contract=contract, resolved_kwargs=resolved_
```
<Overlap Ratio: 0.9530201342281879>

---

--- 88 --
Question ID: 51abb3f92ca204e4930864bed6c039caaf5485a1_1
Original Code:
```
def load_summarized_table(
    args: argparse.Namespace
) -> pd.DataFrame:
    """Load the DataFrame and keep only columns according to the selected metrics.

    Parameters
    ----------
    args : argparse.Namespace
        Arguments to control the loading.

    Returns
    -------
    pd.DataFrame
        The summarized DataFrame.
    """
    df = pd.read_csv(args.metrics_path)
    keep_cols = list(df.columns)[:2]
    for col in df.columns[2:]:
        for cmet in args.chosen_metrics:
            if col.endswith(cmet):
                keep_cols.append(col)
    summ_df = df[keep_cols]
    summ_df = summ_df.sort_values(args.sort_by)
    summ_df = summ_df.round(3)
    return summ_df
```


Overlapping Code:
```

args: argparse.Namespace
) -> pd.DataFrame:
"""Load the DataFrame and keep only columns according to the selected metrics.
Parameters
----------
args : argparse.Namespace
Arguments to control the loading.
Returns
-------
pd.DataFrame
The summarized DataFrame.
"""
df = pd.read_csv(args.metrics_path)
keep_cols = list(df.columns)[:2]
for col in df.columns[2:]:
for cmet in args.chosen_metrics:
if col.endswith(cmet):
keep_cols.append(col)
summ_df = df[keep_cols]
summ_df = summ_df.sort_values(args.so
```
<Overlap Ratio: 0.8710801393728222>

---

--- 89 --
Question ID: 9c3e946512f4af0c18b57892638f2c5ee3b757eb_18
Original Code:
```
@app.route("/progress") #Do Discovery
def progress():


    global username, password, ip_network, ssh_enabled_ips
    content=get_status()
    render_template("/progress.html", ip_network=ip_network, title="TCP Scan", hosts=ssh_enabled_ips,status=content)
    ssh_enabled_ips=[]
    #form = DeviceDiscoveryForm()
    ssh_enabled_ips=tcpscan(ip_network)
    unique_ips = list(set(ssh_enabled_ips))
    if len(unique_ips) == 0:
        flash('No Devices to login via SSH', 'danger')
        content=get_status()
        return redirect(url_for('device_discovery'))
    try_logon(unique_ips)
    content=get_status()
    return render_template("/progress_logon.html",status=content)
```


Overlapping Code:
```
rogress():
global username, password, ip_network, ssh_enabled_ips
content=get_status()
render_template("/progress.html", ip_network=ip_network, title="TCP Scan", hosts=ssh_enabled_ips,status=content)
ssh_enabled_ips=[]
#form = DeviceDiscoveryForm()
ssh_enabled_ips=tcpscan(ip_network)
unique_ips = list(set(ssh_enabled_ips))
if len(unique_ips) == 0:
flash('No Devices to login via SSH', 'danger')
content=get_status()
return redirect(url_for('device_discovery'))
try_logon(unique_ips)
content=get_status()
return render_template("/progress_logon.html
```
<Overlap Ratio: 0.9016393442622951>

---

--- 90 --
Question ID: 3f2c2e3a271362a615460cd3772d1b00e4fa9480_5
Original Code:
```
def testKeyConversionFromEd25519ToCurve25519():
    signer = Signer()
    sk = signer.keyraw
    vk = signer.verraw
    # Check when keys are passed as raw bytes
    secretKey = ed25519SkToCurve25519(sk)
    publicKey = ed25519PkToCurve25519(vk)
    assert PrivateKey(secretKey).public_key.__bytes__() == publicKey
    assert ed25519PkToCurve25519(vk, toHex=True) == \
           hexlify(PrivateKey(secretKey).public_key.__bytes__())

    # Check when keys are passed as hex
    secretKey = ed25519SkToCurve25519(hexlify(sk))
    publicKey = ed25519PkToCurve25519(hexlify(vk))
    assert PrivateKey(secretKey).public_key.__bytes__() == publicKey
```


Overlapping Code:
```
KeyConversionFromEd25519ToCurve25519():
signer = Signer()
sk = signer.keyraw
vk = signer.verraw
# Check when keys are passed as raw bytes
secretKey = ed25519SkToCurve25519(sk)
publicKey = ed25519PkToCurve25519(vk)
assert PrivateKey(secretKey).public_key.__bytes__() == publicKey
assert ed25519PkToCurve25519(vk, toHex=True) == \
hexlify(PrivateKey(secretKey).public_key.__bytes__())
# Check when keys are passed as hex
secretKey = ed25519SkToCurve25519(hexlify(sk))
publicKey = ed25519PkToCurve25519(hexlify(vk))
assert PrivateKey(secretKey).public_k
```
<Overlap Ratio: 0.9401709401709402>

---

--- 91 --
Question ID: 44fd15d47121bfeb9c407bcc6477125e774a2345_76
Original Code:
```
@cpython_api([PyObject, PyObject, Py_ssize_t, Py_ssize_t], Py_ssize_t, error=-1)
def PyUnicode_Count(space, w_str, w_substr, start, end):
    """Return the number of non-overlapping occurrences of substr in
    str[start:end].  Return -1 if an error occurred."""
    w_count = space.call_method(w_str, "count", w_substr,
                                space.newint(start), space.newint(end))
    return space.int_w(w_count)
```


Overlapping Code:
```
size_t, Py_ssize_t], Py_ssize_t, error=-1)
def PyUnicode_Count(space, w_str, w_substr, start, end):
"""Return the number of non-overlapping occurrences of substr in
str[start:end]. Return -1 if an error occurred."""
w_count = space.call_method(w_str, "count", w_substr,
space.newint(start), space.newint(end))
return space.i
```
<Overlap Ratio: 0.864>

---

--- 92 --
Question ID: 3eeafb978c60879f7eee0dda34c20d1f046224cd_2
Original Code:
```
def entities_recognition(dataset_id, domain_id, correspondances, fields, api_key, language):
    records = records_v2(domain_id, dataset_id, rows=ROWS_NUMBER, api_key=api_key)
    for name in fields:
        class_correspondance = get_field_class(records['records'], fields[name], language)
        if class_correspondance:
            correspondances['classes'].append(class_correspondance)
            update_field_class(fields, name, class_correspondance)
```


Overlapping Code:
```
ities_recognition(dataset_id, domain_id, correspondances, fields, api_key, language):
records = records_v2(domain_id, dataset_id, rows=ROWS_NUMBER, api_key=api_key)
for name in fields:
class_correspondance = get_field_class(records['records'], fields[name], language)
if class_correspondance:
correspondances['classes'].append(class_correspondance)
update_field_class(fields, name, class_correspondan
```
<Overlap Ratio: 0.975609756097561>

---

--- 93 --
Question ID: 7cb3cf244a9104c3b80b10eee5a24952750d6153_0
Original Code:
```
def download_dikhololo_night():  # pragma: no cover
    """Download and read the dikholo night hdr texture example.

    Files hosted at https://polyhaven.com/

    Returns
    -------
    pyvista.texture
        HDR Texture.

    Examples
    --------
    >>> import pyvista
    >>> from pyvista import examples    # doctest:+SKIP
    >>> gltf_file = examples.gltf.download_damaged_helmet()  # doctest:+SKIP
    >>> texture = examples.hdr.download_dikhololo_night()  # doctest:+SKIP
    >>> pl = pyvista.Plotter()  # doctest:+SKIP
    >>> pl.import_gltf(gltf_file)  # doctest:+SKIP
    >>> pl.set_environment_texture(texture)  # doctest:+SKIP
    >>> pl.show()  # doctest:+SKIP

    """
    texture = _download_and_read('dikhololo_night_4k.hdr', texture=True)
    texture.SetColorModeToDirectScalars()
    texture.SetMipmap(True)
    texture.SetInterpolate(True)
    return texture
```


Overlapping Code:
```
nload_dikhololo_night(): # pragma: no cover
"""Download and read the dikholo night hdr texture example.
Files hosted at https://polyhaven.com/
Returns
-------
pyvista.texture
HDR Texture.
Examples
--------
>>> import pyvista
>>> from pyvista import examples # doctest:+SKIP
>>> gltf_file = examples.gltf.download_damaged_helmet() # doctest:+SKIP
>>> texture = examples.hdr.download_dikhololo_night() # doctest:+SKIP
>>> pl = pyvista.Plotter() # doctest:+SKIP
>>> pl.import_gltf(gltf_file) # doctest:+SKIP
>>> pl.set_environment_texture(texture) # doctest:+SKIP
>>> pl.show() # doctest:+SKIP
"""
texture = _download_and_read('dikhololo_night_4k.hdr', texture=True)
texture.SetColorModeToDirectScalars()
texture.SetMipmap(True)
texture.SetInterpolate(T
```
<Overlap Ratio: 0.9664948453608248>

---

--- 94 --
Question ID: 0aa4930e4d04e7af8a581272b2d5b47e2e5ed098_0
Original Code:
```
def get_tests(config={}):
    from common import make_hash_tests

    tests = []

    test_vectors = load_tests(("Cryptodome", "SelfTest", "Hash", "test_vectors", "SHA3"),
                                "ShortMsgKAT_SHA3-512.txt",
                                "KAT SHA-3 512",
                                { "len" : lambda x: int(x) } )

    test_data = []
    for tv in test_vectors:
        if tv.len == 0:
            tv.msg = b("")
        test_data.append((hexlify(tv.md), tv.msg, tv.desc))

    tests += make_hash_tests(SHA3, "SHA3_512", test_data,
                             digest_size=SHA3.digest_size,
                             oid="2.16.840.1.101.3.4.2.10")
    tests += list_test_cases(APITest)
    return tests
```


Overlapping Code:
```
ake_hash_tests
tests = []
test_vectors = load_tests(("Cryptodome", "SelfTest", "Hash", "test_vectors", "SHA3"),
"ShortMsgKAT_SHA3-512.txt",
"KAT SHA-3 512",
{ "len" : lambda x: int(x) } )
test_data = []
for tv in test_vectors:
if tv.len == 0:
tv.msg = b("")
test_data.append((hexlify(tv.md), tv.msg, tv.desc))
tests += make_hash_tests(SHA3, "SHA3_512", test_data,
digest_size=SHA3.digest_size,
oid="2
```
<Overlap Ratio: 0.7736943907156673>

---

--- 95 --
Question ID: a723b9d16a072991826384f423eea3831e428ea6_0
Original Code:
```
def delete_toolbox(self):
    """OptiGenAlgNsga2Deap method to delete DEAP toolbox
    Parameters
    ----------
    self : OptiGenAlgNsga2Deap
    """

    # Delete toolbox
    self.toolbox = None

    # Delete creator classes
    del creator.FitnessMin
    del creator.Individual
```


Overlapping Code:
```
def delete_toolbox(self):
"""OptiGenAlgNsga2Deap method to delete DEAP toolbox
Parameters
----------
self : OptiGenAlgNsga2Deap
"""
# Delete toolbox
self.toolbox = None
# Delete creator classes
del creator.FitnessMin
del creator.Indivi
```
<Overlap Ratio: 0.9832635983263598>

---

--- 96 --
Question ID: 20f0862385b561d54b6eece64aaa00c25f04d309_1
Original Code:
```
@pytest.fixture(scope='session')
def variables_datacenter():
    variables = {}
    variables['observation'] = DEFAULT_DATACENTER_OBSERVATION_VARIABLES
    variables['action'] = DEFAULT_DATACENTER_ACTION_VARIABLES
    return variables
```


Overlapping Code:
```
re(scope='session')
def variables_datacenter():
variables = {}
variables['observation'] = DEFAULT_DATACENTER_OBSERVATION_VARIABLES
variables['action'] = DEFAULT_DATACENTER_ACTION_VARIABLES
return vari
```
<Overlap Ratio: 0.9174311926605505>

---

--- 97 --
Question ID: e13713df839db72fe116f231b7c8f845532df4f9_8
Original Code:
```
def find_object_name(scene, name):
    if scene.name == name:
        return scene

    for child in scene.children:
        result = find_object_name(child, name)
        if result is not None:
            return result

    return None
```


Overlapping Code:
```
 == name:
return scene
for child in scene.children:
result = find_object_name(child, name)
if result is not None:
return result
return None
```
<Overlap Ratio: 0.7433155080213903>

---

--- 98 --
Question ID: b6a018eb47eec9d761a97a29fdd12239167c8579_6
Original Code:
```
def get_eta_A_C_f_i(m_C_f_i, A_env_f_i):
    """fi(W/m)/(W/m2) (%) (6a)

    Args:
      m_C_f_i(float): fiW/(W/m2)(6b)/get_m_C_f_i
      A_env_f_i(Decimal): fi(7)/get_A_env_f_i

    Returns:
      Decimal: fi(W/m)/(W/m2)

    """

    # Decimal10
    eta_A_C_f_i = Decimal((m_C_f_i / float(A_env_f_i)) * 100).quantize(Decimal(str(10**(-10))), rounding=ROUND_HALF_UP)
    # 
    eta_A_C_f_i = eta_A_C_f_i.quantize(Decimal('0.1'), rounding=ROUND_CEILING)

    return eta_A_C_f_i
```


Overlapping Code:
```
_C_f_i(m_C_f_i, A_env_f_i):
"""fi(W/m)/(W/m2) (%) (6a)
Args:
m_C_f_i(float): fiW/(W/m2)(6b)/get_m_C_f_i
A_env_f_i(Decimal): fi(7)/get_A_env_f_i
Returns:
Decimal: fi(W/m)/(W/m2)
"""
# Decimal10
eta_A_C_f_i = Decimal((m_C_f_i / float(A_env_f_i)) * 100).quantize(Decimal(str(10**(-10))), rounding=ROUND_HALF_UP)
# 
eta_A_C_f_i = eta_A_C_f_i.quantize(Decimal('0.1'), rounding=ROUND_CEILING)
return eta_A
```
<Overlap Ratio: 0.9666080843585237>

---

--- 99 --
Question ID: 33069b4b218765c48b7eae2dc4eb5eefaa9db130_13
Original Code:
```
def test_RealtimeProvider_free_bus_1(server):
    provider = Provider.from_context(server)
    seconds = time.time()
    with server.osc_protocol.capture() as transcript:
        with provider.at(seconds):
            audio_bus = provider.add_bus(calculation_rate=CalculationRate.AUDIO)
            control_bus_a = provider.add_bus()
            control_bus_b = provider.add_bus()
            control_bus_c = provider.add_bus()
        with provider.at(seconds + 0.01):
            audio_bus.free()
            control_bus_a.free()
            control_bus_d = provider.add_bus()
    assert audio_bus.identifier == 16
    assert control_bus_a.identifier == 0
    assert control_bus_b.identifier == 1
    assert control_bus_c.identifier == 2
    assert control_bus_d.identifier == 0
    assert [entry.message for entry in transcript] == []
```


Overlapping Code:
```
 test_RealtimeProvider_free_bus_1(server):
provider = Provider.from_context(server)
seconds = time.time()
with server.osc_protocol.capture() as transcript:
with provider.at(seconds):
audio_bus = provider.add_bus(calculation_rate=CalculationRate.AUDIO)
control_bus_a = provider.add_bus()
control_bus_b = provider.add_bus()
control_bus_c = provider.add_bus()
with provider.at(seconds + 0.01):
audio_bus.free()
control_bus_a.free()
control_bus_d = provider.add_bus()
assert audio_bus.identifier == 16
assert control_bus_a.identifier == 0
assert control_bus_b.identifier == 1
assert control_bus_c.identifier == 2
assert control_bus_d.identifier == 0
asse
```
<Overlap Ratio: 0.927246790299572>

---

--- 100 --
Question ID: 02c97ec5f60a2d69124d3e37bf0c239a96883532_1
Original Code:
```
def build_vocab(path, raw_vocab, config, trans='transE'):

    print("Creating word vocabulary...")
    vocab_list = ['_PAD','_GO', '_EOS', '_UNK', ] + sorted(raw_vocab, key=raw_vocab.get, reverse=True)
    if len(vocab_list) > config.symbols:
        vocab_list = vocab_list[:config.symbols]
    
    print("Creating entity vocabulary...")
    entity_list = ['_NONE', '_PAD_H', '_PAD_R', '_PAD_T', '_NAF_H', '_NAF_R', '_NAF_T'] 
    with open('%s/entity.txt' % path) as f:
        for i, line in enumerate(f):
            e = line.strip()
            entity_list.append(e)
    
    print("Creating relation vocabulary...")
    relation_list = []
    with open('%s/relation.txt' % path) as f:
        for i, line in enumerate(f):
            r = line.strip()
            relation_list.append(r)

    print("Loading word vectors...")
    vectors = {}
    with open('%s/glove.840B.300d.txt' % path) as f:
        for i, line in enumerate(f):
            if i % 100000 == 0:
                print("    processing line %d" % i)
            s = line.strip()
            word = s[:s.find(' ')]
            vector = s[s.find(' ')+1:]
            vectors[word] = vector
    
    embed = []
    for word in vocab_list:
        if word in vectors:
            #vector = map(float, vectors[word].split())
            vector = vectors[word].split()
        else:
            vector = np.zeros((config.embed_units), dtype=np.float32) 
        embed.append(vector)
    embed = np.array(embed, dtype=np.float32)
            
    print("Loading entity vectors...")
    entity_embed = []
    with open('%s/entity_%s.txt' % (path, trans)) as f:
        for i, line in enumerate(f):
            s = line.strip().split('\t')
            #entity_embed.append(map(float, s))
            entity_embed.append(s)

    print("Loading relation vectors...")
    relation_embed = []
    with open('%s/relation_%s.txt' % (path, trans)) as f:
        for i, line in enumerate(f):
            s = line.strip().split('\t')
            relation_embed.append(s)

    entity_relation_embed = np.array(entity_embed+relation_embed, dtype=np.float32)
    entity_embed = np.array(entity_embed, dtype=np.float32)
    relation_embed = np.array(relation_embed, dtype=np.float32)

    word2id = dict()
    entity2id = dict()
    for word in vocab_list:
        word2id[word] = len(word2id)
    for entity in entity_list + relation_list:
        entity2id[entity] = len(entity2id)

    return word2id, entity2id, vocab_list, embed, entity_list, entity_embed, relation_list, relation_embed, entity_relation_embed
```


Overlapping Code:
```
ans='transE'):
print("Creating word vocabulary...")
vocab_list = ['_PAD','_GO', '_EOS', '_UNK', ] + sorted(raw_vocab, key=raw_vocab.get, reverse=True)
if len(vocab_list) > config.symbols:
vocab_list = vocab_list[:config.symbols]

print("Creating entity vocabulary...")
entity_list = ['_NONE', '_PAD_H', '_PAD_R', '_PAD_T', '_NAF_H', '_NAF_R', '_NAF_T'] 
with open('%s/entity.txt' % path) as f:
for i, line in enumerate(f):
e = line.strip()
entity_list.append(e)

print("Creating relation vocabulary...")
relation_list = []
with open('%s/relation.txt' % path) as f:
for i, line in enumerate(f):
r = line.strip()
relation_list.append(r)
print("Loading word vectors...")
vectors = {}
with open('%s/glove.840B.300d.txt' % path) as f:
for i, line in enumerate(f):
if i % 100000 == 0:
print(" processing line %d" % i)
s = line.strip()
word = s[:s.find(' ')]
vector = s[s.find(' ')+1:]
vectors[word] = vector

embed = []
for word in vocab_list:
if word in vectors:
#vector = map(float, vectors[word].split())
vector = vectors[word].split()
else:
vector = np.zeros((config.embed_units), dtype=np.float32) 
embed.append(vector)
embed = np.array(embed, dtype=np.float32)

print("Loading entity vectors...")
entity_embed = []
with open('%s/entity_%s.txt' % (path, trans)) as f:
for i, line in enumerate(f):
s = line.strip().split('\t')
#entity_embed.append(map(float, s))
entity_embed.append(s)
print("Loading relation vectors...")
relation_embed = []
with open('%s/relation_%s.txt' % (path, trans)) as f:
for i, line in enumerate(f):
s = line.strip().split('\t')
relation_embed.append(s)
entity_relation_embed = np.array(entity_embed+relation_embed, dtype=np.float32)
entity_embed = np.array(entity_embed, dtype=np.float32)
relation_embed = np.array(relation_embed, dtype=np.float32)
word2id = dict()
entity2id = dict()
for word in vocab_list:
word2id[word] = len(word2id)
for entity in entity_list + relation_list:
entity2id[entity] = len(entity2id)
return wo
```
<Overlap Ratio: 0.9549461312438785>

---

--- 101 --
Question ID: c48dff6a289dd41de899395a7cc61ec7422f5c44_0
Original Code:
```
@command('generate-config', 'license_key [output_file]',
"""Generates a sample agent configuration file for <license_key>.""")
def generate_config(args):
    import os
    import sys

    if len(args) == 0:
        usage('generate-config')
        sys.exit(1)

    from newrelic import __file__ as package_root
    package_root = os.path.dirname(package_root)

    config_file = os.path.join(package_root, 'newrelic.ini')

    content = open(config_file, 'r').read()

    if len(args) >= 1:
        content = content.replace('*** REPLACE ME ***', args[0])

    if len(args) >= 2 and args[1] != '-':
        output_file = open(args[1], 'w')
        output_file.write(content)
        output_file.close()
    else:
        print(content)
```


Overlapping Code:
```
onfig', 'license_key [output_file]',
"""Generates a sample agent configuration file for <license_key>.""")
def generate_config(args):
import os
import sys
if len(args) == 0:
usage('generate-config')
sys.exit(1)
from newrelic import __file__ as package_root
package_root = os.path.dirname(package_root)
config_file = os.path.join(package_root, 'newrelic.ini')
content = open(config_file, 'r').read()
if len(args) >= 1:
content = content.replace('*** REPLACE ME ***', args[0])
if len(args) >= 2 and args[1] != '-':
output_file = open(args[1], 'w')
output_file.write(content)
output_file.close()
else:
p
```
<Overlap Ratio: 0.9478672985781991>

---

--- 102 --
Question ID: 21d09c9139681e7abbce341d69f350ac83fe9e2e_0
Original Code:
```
def infer_ros(input_cloud, model, corr2soft):
    query = load_pc_infer(input_cloud)
    query = np.array(query, dtype=np.float32)

    out, _, _, _ = infer_model(model, corr2soft, query)
    out_show = out.reshape(1, 32, 32) # size is related to the disco dimension
    return out
```


Overlapping Code:
```
d, model, corr2soft):
query = load_pc_infer(input_cloud)
query = np.array(query, dtype=np.float32)
out, _, _, _ = infer_model(model, corr2soft, query)
out_show = out.reshape(1, 32, 32) # size is relat
```
<Overlap Ratio: 0.7692307692307693>

---

--- 103 --
Question ID: 7c4c68cf052509418e7f0b77bb3fbc0bc66ae006_3
Original Code:
```
def query_SRS_for_program_list(url, inventory, lists_of_interest):
    try:
        chemicallistresponse = requests.get(url)
        chemicallistjson = json.loads(chemicallistresponse.text)
    except:
        return "Error:404"
    all_chemicals_list = []
    for chemical in chemicallistjson:
       #get cas
       chemicaldict = {}
       chemicaldict['SRS_CAS'] = chemical['currentCasNumber']
       chemicaldict['SRS_ID'] = chemical['subsKey']
       #get synonyms
       #extract from the json
       synonyms = chemical['synonyms']
       #ids are deeply embedded in this list. Go get ids relevant to these lists of interest
       alternateids = []
       for i in synonyms:
           if i['listName'] in lists_of_interest:
               # print('True for' + i['listName'])
               #chem_alt_id_info = {}
               for l in i['alternateIds']:
                   #chem_alt_id_info['alternateId'] = l['alternateId']
                   #chem_alt_id_info['alternateIdTypeName']
                   alternateids.append(l['alternateId'])

       #make list of alt ids unique by converting to a set, then back to a list
       alternateids = list(set(alternateids))

       if len(alternateids) > 0:
           for id in range(0, len(alternateids)):
               chemicaldict['PGM_ID'] = alternateids[id]
               all_chemicals_list.append(chemicaldict.copy())
       else:
           all_chemicals_list.append(chemicaldict)
    #Write it into a df
    all_inventory_chemicals = pd.DataFrame(all_chemicals_list)
    return all_inventory_chemicals
```


Overlapping Code:
```
_SRS_for_program_list(url, inventory, lists_of_interest):
try:
chemicallistresponse = requests.get(url)
chemicallistjson = json.loads(chemicallistresponse.text)
except:
return "Error:404"
all_chemicals_list = []
for chemical in chemicallistjson:
#get cas
chemicaldict = {}
chemicaldict['SRS_CAS'] = chemical['currentCasNumber']
chemicaldict['SRS_ID'] = chemical['subsKey']
#get synonyms
#extract from the json
synonyms = chemical['synonyms']
#ids are deeply embedded in this list. Go get ids relevant to these lists of interest
alternateids = []
for i in synonyms:
if i['listName'] in lists_of_interest:
# print('True for' + i['listName'])
#chem_alt_id_info = {}
for l in i['alternateIds']:
#chem_alt_id_info['alternateId'] = l['alternateId']
#chem_alt_id_info['alternateIdTypeName']
alternateids.append(l['alternateId'])
#make list of alt ids unique by converting to a set, then back to a list
alternateids = list(set(alternateids))
if len(alternateids) > 0:
for id in range(0, len(alternateids)):
chemicaldict['PGM_ID'] = alternateids[id]
all_chemicals_list.append(chemicaldict.copy())
else:
all_chemicals_list.append(chemicaldict)
#Write it into a df
all_inventory_chemicals = pd.DataFrame(all_chemicals_list)
return
```
<Overlap Ratio: 0.9736421725239617>

---

--- 104 --
Question ID: 7d4ec3b2ea9b93799340426971898142d97d90f5_3
Original Code:
```
def verify_data(img1, img2, intrinsics1, extrinsics1, intrinsics2, extrinsics2):
    img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)

    E, F, relative_pose = two_view_geometry(intrinsics1, extrinsics1,
                                            intrinsics2, extrinsics2)

    # sift = cv2.xfeatures2d.SIFT_create(nfeatures=20)
    # kp1 = sift.detect(img1, mask=None)
    # coord1 = np.array([[kp.pt[0], kp.pt[1]] for kp in kp1]).T

    # Initiate ORB detector
    orb = cv2.ORB_create()
    # find the keypoints with ORB
    kp1 = orb.detect(img1, None)
    coord1 = np.array([[kp.pt[0], kp.pt[1]] for kp in kp1[:20]]).T
    return epipolar(coord1, F, img1, img2)
```


Overlapping Code:
```
, img2, intrinsics1, extrinsics1, intrinsics2, extrinsics2):
img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
E, F, relative_pose = two_view_geometry(intrinsics1, extrinsics1,
intrinsics2, extrinsics2)
# sift = cv2.xfeatures2d.SIFT_create(nfeatures=20)
# kp1 = sift.detect(img1, mask=None)
# coord1 = np.array([[kp.pt[0], kp.pt[1]] for kp in kp1]).T
# Initiate ORB detector
orb = cv2.ORB_create()
# find the keypoints with ORB
kp1 = orb.detect(img1, None)
coord1 = np.array([[kp.pt[0], kp.pt[1]] for kp in kp1[:20]]).T
return epipolar(coord1, F, img1, img2)
```
<Overlap Ratio: 0.967741935483871>

---

--- 105 --
Question ID: 12d317512cab1bead5d5cb8fdd36a466e600ab0f_2
Original Code:
```
@patch("services.health_checker.CosmosClient")
@patch("services.health_checker.get_store_key")
def test_get_state_store_status_other_exception(cosmos_client_mock, get_store_key_mock) -> None:
    get_store_key_mock.return_value = None
    cosmos_client_mock.return_value = None
    cosmos_client_mock.side_effect = Exception()

    status, message = health_checker.create_state_store_status()

    assert status == StatusEnum.not_ok
    assert message == strings.UNSPECIFIED_ERROR
```


Overlapping Code:
```
ces.health_checker.CosmosClient")
@patch("services.health_checker.get_store_key")
def test_get_state_store_status_other_exception(cosmos_client_mock, get_store_key_mock) -> None:
get_store_key_mock.return_value = None
cosmos_client_mock.return_value = None
cosmos_client_mock.side_effect = Exception()
status, message = health_checker.create_state_store_status()
assert status == StatusEnum.not_ok
assert message == strings.UNSPECIFIED_
```
<Overlap Ratio: 0.960352422907489>

---

--- 106 --
Question ID: 208bcd5d140a584e923bfcd44ee06fbcd1bdb71e_2
Original Code:
```
def encode_numpy_slice(ndarray, convert_float=True):
    ndarray = ndarray.copy(order='C')
    dtype = np.dtype(ndarray.dtype).name
    output = io.BytesIO()
    if convert_float:
        with Image.fromarray(img_as_ubyte(ndarray)) as im:   
            im.save(output, format="JPEG")
    else:
        with Image.fromarray(ndarray) as im:   
            im.save(output, format="JPEG")
    output.seek(0)
    #data = base64.b64encode(output.read()) 
    data = output.read()
    data = base64.b64encode(data)
    return dict(data=data, dtype=dtype, shape=ndarray.shape)
```


Overlapping Code:
```
ue):
ndarray = ndarray.copy(order='C')
dtype = np.dtype(ndarray.dtype).name
output = io.BytesIO()
if convert_float:
with Image.fromarray(img_as_ubyte(ndarray)) as im: 
im.save(output, format="JPEG")
else:
with Image.fromarray(ndarray) as im: 
im.save(output, format="JPEG")
output.seek(0)
#data = base64.b64encode(output.read()) 
data = output.read()
data = base64.b64encode(data)
return dict(data=da
```
<Overlap Ratio: 0.8247422680412371>

---

--- 107 --
Question ID: 658b591953d33b3309b05337ed6f4ca65eca6141_1
Original Code:
```
def mass_plot_io():
    
    m1 = np.sqrt(m0**2 + big_dm)
    m2 = np.sqrt(m1**2 + small_dm)
    
    with quantity_support():

        plt.loglog(m0, m0)
        plt.loglog(m0, m1)
        plt.loglog(m0, m2)
        plt.loglog(m0, np.sqrt(.7 * m1**2 + .3 * m2**2 + .02 * m0**2))
```


Overlapping Code:
```
ss_plot_io():

m1 = np.sqrt(m0**2 + big_dm)
m2 = np.sqrt(m1**2 + small_dm)

with quantity_support():
plt.loglog(m0, m0)
plt.loglog(m0, m1)
plt.loglog(m0, m2)
plt.loglog(m0, np.sqrt(.7 * m1**2 + .3 * m
```
<Overlap Ratio: 0.8849557522123894>

---

--- 108 --
Question ID: 625f5558fec6561ccce643c9dcca356d9fd867f3_13
Original Code:
```
def initialize_variables(): # pragma: no cover
    """This function initializes the values for the rocket that will be used in the
    simulation. Specifics are given alongside the value.
    """
    STANDARD_GRAVITY = 9.80665
    #current values for falcon 9 booster
    thrust = float(
        490000)  # Motor thrust in Newtons
    motor_isp = float(
        335)  # Motor ISP
    mass_flow = thrust / (motor_isp * STANDARD_GRAVITY)
    print(mass_flow)

    dry_mass = float(
        10000
           )  # Dry mass in kg
    wet_mass = float(
        40000
    )  # Wet mass in kg

    reference_area = 3.14159 * 3**2  # This is the cross sectional profile of the rocket
    return dry_mass, wet_mass, mass_flow, thrust, motor_isp, reference_area
```


Overlapping Code:
```
ze_variables(): # pragma: no cover
"""This function initializes the values for the rocket that will be used in the
simulation. Specifics are given alongside the value.
"""
STANDARD_GRAVITY = 9.80665
#current values for falcon 9 booster
thrust = float(
490000) # Motor thrust in Newtons
motor_isp = float(
335) # Motor ISP
mass_flow = thrust / (motor_isp * STANDARD_GRAVITY)
print(mass_flow)
dry_mass = float(
10000
) # Dry mass in kg
wet_mass = float(
40000
) # Wet mass in kg
reference_area = 3.14159 * 3**2 # This is the cross sectional profile of the rocket
return dry_mass, wet_mass, mass_flow, t
```
<Overlap Ratio: 0.9316770186335404>

---

--- 109 --
Question ID: 9e6c24499a4baf2892321a7a09ed7821d8536c60_0
Original Code:
```
def create_follicle_on_selection():
    sel = pm.ls(os = True)
    if len(sel) > 1:
        src_obj = sel[0]
        trgt_objs = sel[1:]
        follicle_list = fmc.create_follicle_object_position(src_obj, trgt_objs)

        for f, t in zip(follicle_list, trgt_objs):
            f.rename('{}_foll'.format(t.nodeName()))
            res = pm.parentConstraint(f, t, mo = True)
            res.setParent(world = True)
```


Overlapping Code:
```
on():
sel = pm.ls(os = True)
if len(sel) > 1:
src_obj = sel[0]
trgt_objs = sel[1:]
follicle_list = fmc.create_follicle_object_position(src_obj, trgt_objs)
for f, t in zip(follicle_list, trgt_objs):
f.rename('{}_foll'.format(t.nodeName()))
res = pm.parentConstraint(f, t, mo = True)
res.setParent(worl
```
<Overlap Ratio: 0.8849557522123894>

---

--- 110 --
Question ID: 16397b7afcef9d29b49b3213a411a6900817bbae_3
Original Code:
```
@pytest.mark.parametrize(
    "offset,expected",
    [
        ((24 * 60 * 60), {"id": "test"}),
        (-(24 * 60 * 60), None),
    ],
)
def test_actor_cookie_that_expires(app_client, offset, expected):
    expires_at = int(time.time()) + offset
    cookie = app_client.ds.sign(
        {"a": {"id": "test"}, "e": baseconv.base62.encode(expires_at)}, "actor"
    )
    response = app_client.get("/", cookies={"ds_actor": cookie})
    assert expected == app_client.ds._last_request.scope["actor"]
```


Overlapping Code:
```
est.mark.parametrize(
"offset,expected",
[
((24 * 60 * 60), {"id": "test"}),
(-(24 * 60 * 60), None),
],
)
def test_actor_cookie_that_expires(app_client, offset, expected):
expires_at = int(time.time()) + offset
cookie = app_client.ds.sign(
{"a": {"id": "test"}, "e": baseconv.base62.encode(expires_at)}, "actor"
)
response = app_client.get("/", cookies={"ds_actor": cookie})
assert expected == app_c
```
<Overlap Ratio: 0.9070294784580499>

---

--- 111 --
Question ID: 20aae0fcd0a8197d27c13553f3036d33b61e9213_4
Original Code:
```
def _run_task(task):
    """Free function wrapping the Task runner.

    It needs to be free because bound instancemethods can't be pickled for multiprocessing.
    """
    task._run()
```


Overlapping Code:
```
ing the Task runner.
It needs to be free because bound instancemethods can't be pickled for multipro
```
<Overlap Ratio: 0.5988023952095808>

---

--- 112 --
Question ID: 82f76c0e9dc96c7d6f44e0739c0cbe4a767ef48d_1
Original Code:
```
def sonde5(isTest=False):
    TILE_ID = 'sp_ex'
    print(f'{getTimeStr()} (+) Starting sensors 5', flush=True)
    start_time = time.time()
    data = executeScriptToGetData()
    tipboardAnswer = sendDataToTipboard(tile_id=TILE_ID, data=data, tile_template='simple_percentage', isTest=isTest)
    fade = False if not random.randrange(0, 1) else True
    sendBVColor(tile_id=TILE_ID, color=BACKGROUND_TAB[random.randrange(0, 3)], fading=fade)
    end(title=f'sensors5 -> {TILE_ID}', start_time=start_time, tipboardAnswer=tipboardAnswer, TILE_ID=TILE_ID)
```


Overlapping Code:
```
'
print(f'{getTimeStr()} (+) Starting sensors 5', flush=True)
start_time = time.time()
data = executeScriptToGetData()
tipboardAnswer = sendDataToTipboard(tile_id=TILE_ID, data=data, tile_template='simple_percentage', isTest=isTest)
fade = False if not random.randrange(0, 1) else True
sendBVColor(tile_id=TILE_ID, color=BACKGROUND_TAB[random.randrange(0, 3)], fading=fade)
end(title=f'sensors5 -> {TILE_ID}', start_time=start_time, tipboardAnswer=tipboardAnswer, TILE_ID=TILE_ID
```
<Overlap Ratio: 0.9176245210727969>

---

--- 113 --
Question ID: 30f2b10652770dd23cf3be8e57fb27b746721c50_546
Original Code:
```
def AOCDEFACEE():
	print(w+"AOCDEFACE"+g+" is Installing.....\n"+g)
	os.system("apt-get update -y;apt-get upgrade -y;apt-get install git -y;git clone https://github.com/Amriez/AOCDEFACE.git/;mv AOCDEFACE $HOME")
	print(w+"\nAOCDEFACE"+g+" is Installed and saved in"+w+" home "+g+"directory")
	input(b+"\npress ENTER to continue")
	os.system("clear;python hacked.py")
```


Overlapping Code:
```
E"+g+" is Installing.....\n"+g)
os.system("apt-get update -y;apt-get upgrade -y;apt-get install git -y;git clone https://github.com/Amriez/AOCDEFACE.git/;mv AOCDEFACE $HOME")
print(w+"\nAOCDEFACE"+g+" is Installed and saved in"+w+" home "+g+"directory")
input(b+"\npress ENTER to continue")
os.system("clear;python hacked.py")
```
<Overlap Ratio: 0.9030470914127424>

---

--- 114 --
Question ID: ffa6de6d762ee4a605a4e2e3dd37330e1a623ba6_1
Original Code:
```
def test_dot_real(data_dict):
    def get_iter(path, data_shape, batch_size):
        data_train = mx.io.LibSVMIter(data_libsvm=path,
                                      data_shape=data_shape,
                                      batch_size=batch_size)
        data_iter = iter(data_train)
        return data_iter

    data_dir = os.path.join(os.getcwd(), 'data')

    path = os.path.join(data_dir, data_dict['data_name'])
    if not os.path.exists(path):
        get_bz2_data(
            data_dir,
            data_dict['data_name'],
            data_dict['url'],
            data_dict['data_origin_name']
        )
        assert os.path.exists(path)

    k = data_dict['feature_dim']
    m = data_dict['m']
    density = estimate_density(path, data_dict['feature_dim'])

    mini_path = os.path.join(data_dir, data_dict['data_mini'])
    if not os.path.exists(mini_path):
        os.system("head -n 2000 %r > %r" % (path, mini_path))
        assert os.path.exists(mini_path)

    print("Running Benchmarking on %r data" % data_dict['data_mini'])
    for batch_size in data_dict['batch_size']:  # iterator through different batch size of choice
        print("batch_size is %d" % batch_size)
        # model
        data_shape = (k, )
        train_iter = get_iter(mini_path, data_shape, batch_size)
        weight = mx.nd.random.uniform(low=0, high=1, shape=(k, m))

        csr_data = []
        dns_data = []
        num_batch = 0
        for batch in train_iter:
            data = train_iter.getdata()
            csr_data.append(data)
            dns_data.append(data.tostype('default'))
            num_batch += 1
        bag_of_data = [csr_data, dns_data]
        num_repeat = 5
        costs = []
        for d in bag_of_data:
            weight.wait_to_read()
            cost = 0.
            count = 0
            for d_batch in d:
                d_batch.wait_to_read()
                cost += measure_cost(num_repeat, mx.nd.dot, d_batch, weight)
                count += 1
            costs.append(cost/count)
        t_sparse = costs[0]
        t_dense = costs[1]
        ratio = t_dense / t_sparse
        print('density(%)\tn\tm\tk\tt_dense/t_sparse\tt_dense\tt_sparse')
        fmt = "%0.4f\t\t%d\t%d\t%d\t%0.2f\t\t\t%0.4f\t%0.6f"
        print(fmt % (density * 100, batch_size, m, k, ratio, t_dense, t_sparse))
```


Overlapping Code:
```
ta_dict):
def get_iter(path, data_shape, batch_size):
data_train = mx.io.LibSVMIter(data_libsvm=path,
data_shape=data_shape,
batch_size=batch_size)
data_iter = iter(data_train)
return data_iter
data_dir = os.path.join(os.getcwd(), 'data')
path = os.path.join(data_dir, data_dict['data_name'])
if not os.path.exists(path):
get_bz2_data(
data_dir,
data_dict['data_name'],
data_dict['url'],
data_dict['data_origin_name']
)
assert os.path.exists(path)
k = data_dict['feature_dim']
m = data_dict['m']
density = estimate_density(path, data_dict['feature_dim'])
mini_path = os.path.join(data_dir, data_dict['data_mini'])
if not os.path.exists(mini_path):
os.system("head -n 2000 %r > %r" % (path, mini_path))
assert os.path.exists(mini_path)
print("Running Benchmarking on %r data" % data_dict['data_mini'])
for batch_size in data_dict['batch_size']: # iterator through different batch size of choice
print("batch_size is %d" % batch_size)
# model
data_shape = (k, )
train_iter = get_iter(mini_path, data_shape, batch_size)
weight = mx.nd.random.uniform(low=0, high=1, shape=(k, m))
csr_data = []
dns_data = []
num_batch = 0
for batch in train_iter:
data = train_iter.getdata()
csr_data.append(data)
dns_data.append(data.tostype('default'))
num_batch += 1
bag_of_data = [csr_data, dns_data]
num_repeat = 5
costs = []
for d in bag_of_data:
weight.wait_to_read()
cost = 0.
count = 0
for d_batch in d:
d_batch.wait_to_read()
cost += measure_cost(num_repeat, mx.nd.dot, d_batch, weight)
count += 1
costs.append(cost/count)
t_sparse = costs[0]
t_dense = costs[1]
ratio = t_dense / t_sparse
print('density(%)\tn\tm\tk\tt_dense/t_sparse\tt_dense\tt_sparse')
fmt = "%0.4f\t\t%d\t%d\t%d\t%0.2f\t\t\t%0.4f\t%0.6f"
print(fmt % (density * 100, batch_size, m, k, ratio, 
```
<Overlap Ratio: 0.9782001117942984>

---

--- 115 --
Question ID: f9adde7ecc876c2f551a9cf339a755bdb78d4250_5
Original Code:
```
def make_cursor(widget, iconpath, x, y):
    image = Gtk.Image()
    image.set_from_file(iconpath)
    pixbuf = image.get_pixbuf()
    screen = widget.get_screen()
    display = screen.get_display()
    return Gdk.Cursor(display, pixbuf, x, y)
```


Overlapping Code:
```
cursor(widget, iconpath, x, y):
image = Gtk.Image()
image.set_from_file(iconpath)
pixbuf = image.get_pixbuf()
screen = widget.get_screen()
display = screen.get_display()
return Gdk.Cursor(display, pix
```
<Overlap Ratio: 0.91324200913242>

---

--- 116 --
Question ID: 6a6ef29e9b45131efc43836479e4b4cc7e490cca_7
Original Code:
```
@user_pait(
    status=PaitStatus.release,
    tag=("mock",),
    response_model_list=[UserSuccessRespModel2, FailRespModel],
    enable_mock_response=True,
)
def mock_route(
    uid: int = Query.i(description="user id", gt=10, lt=1000),
    user_name: str = Query.i(description="user name", min_length=2, max_length=4),
    email: Optional[str] = Query.i(default="example@xxx.com", description="user email"),
    multi_user_name: List[str] = MultiQuery.i(description="user name", min_length=2, max_length=4),
    age: int = Path.i(description="age", gt=1, lt=100),
    sex: SexEnum = Query.i(description="sex"),
) -> dict:
    """Test gen mock response"""
    return {
        "code": 0,
        "msg": "",
        "data": {
            "uid": uid,
            "user_name": user_name,
            "email": email,
            "age": age,
            "sex": sex.value,
            "multi_user_name": multi_user_name,
        },
    }
```


Overlapping Code:
```
pait(
status=PaitStatus.release,
tag=("mock",),
response_model_list=[UserSuccessRespModel2, FailRespModel],
enable_mock_response=True,
)
def mock_route(
uid: int = Query.i(description="user id", gt=10, lt=1000),
user_name: str = Query.i(description="user name", min_length=2, max_length=4),
email: Optional[str] = Query.i(default=cription="user email"),
multi_user_name: List[str] = MultiQuery.i(description="user name", min_length=2, max_length=4),
age: int = Path.i(description="age", gt=1, lt=100),
sex: SexEnum = Query.i(description="sex"),
) -> dict:
"""Test gen mock response"""
return {
"code": 0,
"msg": "",
"data": {
"uid": uid,
"user_name": user_name,
"email": email,
"age": age,
"sex": sex.value,
"multi_user_name": multi_user_name,
},
}
```
<Overlap Ratio: 0.9639175257731959>

---

--- 117 --
Question ID: 283f09dc637fa965bc8af894b623a1eca1b570f5_2
Original Code:
```
def get_rgrids(max_value, rgrid_count):
    """Calculate radial grid steps and return it as a list"""

    import math

    digits = math.floor(math.log(max_value, 10))
    scale = max_value / (10**digits)

    ubound = math.ceil(scale) * (10**digits)
    step = ubound / (rgrid_count+1)

    return list(step * i for i in range(1, rgrid_count+1))
```


Overlapping Code:
```
ue, rgrid_count):
"""Calculate radial grid steps and return it as a list"""
import math
digits = math.floor(math.log(max_value, 10))
scale = max_value / (10**digits)
ubound = math.ceil(scale) * (10**digits)
step = ubound / (rgrid_count+1)
return list
```
<Overlap Ratio: 0.7936507936507936>

---

--- 118 --
Question ID: 7ba7f87405482d6f2c4422d0b47f18f89b626bdb_0
Original Code:
```
def getSettings():
    if not os.path.isfile(settingsfile):
        settings = {
            'connections': {},
            'max_history': 200000,
            'max_scroll': 200000,
            'smooth_scroll': True
        }
        saveSettings(settings)
        return settings
    with open(settingsfile, 'r') as f:
        settings = yaml.load(f)
    return settings
```


Overlapping Code:
```
 not os.path.isfile(settingsfile):
settings = {
'connections': {},
'max_history': 200000,
'max_scroll': 200000,
'smooth_scroll': True
}
saveSettings(settings)
return settings
with open(settingsfile, '
```
<Overlap Ratio: 0.7407407407407407>

---

--- 119 --
Question ID: 857eca2a556951ee9bddd2597f5c81031f266fe2_0
Original Code:
```
def clickable(widget):
    """
    Makes widget to be clickable.

    :param widget: QLabel to receive clicks
    :return: clickable widget
    """

    class Filter(QObject):
        clicked = pyqtSignal()

        def eventFilter(self, obj, event):
            if obj == widget:
                if event.type() == QEvent.MouseButtonRelease:
                    if obj.rect().contains(event.pos()):
                        self.clicked.emit()
                        return True
            return False

    filter = Filter(widget)
    widget.installEventFilter(filter)
    return filter.clicked
```


Overlapping Code:
```
lickable.
:param widget: QLabel to receive clicks
:return: clickable widget
"""
class Filter(QObject):
clicked = pyqtSignal()
def eventFilter(self, obj, event):
if obj == widget:
if event.type() == QEvent.MouseButtonRelease:
if obj.rect().contains(event.pos()):
self.clicked.emit()
return True
return False
filter = Filter(widget)
widget.installEventFilter(filter)
return filter.clicked
```
<Overlap Ratio: 0.8914549653579676>

---

--- 120 --
Question ID: 4b4111b001af98a8f5dfe2337470efc36e0f5491_3
Original Code:
```
def compute_weights(samples):
    mu, std = norm.fit(samples)
    std_vec = std * torch.ones_like(samples)
    mu_vec  = mu  * torch.ones_like(samples)
    pi_vec  = np.pi    * torch.ones_like(samples)

    weights = ((std_vec*torch.sqrt(2.0*pi_vec)) *
               torch.exp(0.5*torch.square((samples-mu_vec)/std_vec)))

    if rank==0:
        print(f'min weight: {torch.min(weights)}, max weight: {torch.max(weights)}')
    #weights = torch.clamp(weights, 0, weight_cap)

    return weights
```


Overlapping Code:
```
s):
mu, std = norm.fit(samples)
std_vec = std * torch.ones_like(samples)
mu_vec = mu * torch.ones_like(samples)
pi_vec = np.pi * torch.ones_like(samples)
weights = ((std_vec*torch.sqrt(2.0*pi_vec)) *
torch.exp(0.5*torch.square((samples-mu_vec)/std_vec)))
if rank==0:
print(f'min weight: {torch.min(weights)}, max weight: {torch.max(weights)}')
#weights = torch.clamp(weights, 0, weight_cap)
return we
```
<Overlap Ratio: 0.9280742459396751>

---

--- 121 --
Question ID: b8ac2fe73d1edfb866a8f3034f337623ee0df724_1
Original Code:
```
def test_pairwise_dist():
    emb_anc = tf.random.uniform((8,64))
    emb_pos = tf.random.uniform((32,64))
    emb_anc = tf.math.l2_normalize(emb_anc, axis=1)
    emb_pos = tf.math.l2_normalize(emb_pos, axis=1)
    
    loss_obj = OnlineTripletLoss(bsz=40, n_anchor=8, n_pos_per_anchor=4, use_anc_as_pos=True)
    dist1 = loss_obj._pairwise_distances_v2(emb_anc, emb_pos, use_anc_as_pos=True, squared=True) 
    dist2 = 2 * (1 - loss_obj._pairwise_dotprod(emb_anc, emb_pos, use_anc_as_pos=True))
    dist3 = loss_obj._pairwise_distances_v2_fast(emb_anc, emb_pos, use_anc_as_pos=True, squared=True)  
    
    assert(tf.reduce_sum(dist1-dist2) < 0.0000001)
    assert(tf.reduce_sum(dist1-dist3) < 0.0000001)
    return       
```


Overlapping Code:
```
ist():
emb_anc = tf.random.uniform((8,64))
emb_pos = tf.random.uniform((32,64))
emb_anc = tf.math.l2_normalize(emb_anc, axis=1)
emb_pos = tf.math.l2_normalize(emb_pos, axis=1)

loss_obj = OnlineTripletLoss(bsz=40, n_anchor=8, n_pos_per_anchor=4, use_anc_as_pos=True)
dist1 = loss_obj._pairwise_distances_v2(emb_anc, emb_pos, use_anc_as_pos=True, squared=True) 
dist2 = 2 * (1 - loss_obj._pairwise_dotprod(emb_anc, emb_pos, use_anc_as_pos=True))
dist3 = loss_obj._pairwise_distances_v2_fast(emb_anc, emb_pos, use_anc_as_pos=True, squared=True) 

assert(tf.reduce_sum(dist1-dist2) < 0.0000001)
assert(t
```
<Overlap Ratio: 0.9036144578313253>

---

--- 122 --
Question ID: e92683def66cbbc9c194341d353b0acb592142f9_0
Original Code:
```
def initialize(seed=-1):
    """
    Reinitalize the library with a seed. If seed is -1 then system time is
    used to create the seed.
    """

    global lib, ctxt_obj, ELEM_INSTALLED, KDT_INSTALLED
    
    #
    # Load C-API library and set return types
    #
    lib = cdll.LoadLibrary('libcskylark.so')
    lib.sl_create_context.restype              = c_int
    lib.sl_create_default_context.restype      = c_int
    lib.sl_free_context.restype                = c_int
    lib.sl_create_sketch_transform.restype     = c_int
    lib.sl_serialize_sketch_transform.restype  = c_int
    lib.sl_deserialize_sketch_transform.restype = c_int
    lib.sl_wrap_raw_matrix.restype             = c_int
    lib.sl_free_raw_matrix_wrap.restype        = c_int
    lib.sl_wrap_raw_sp_matrix.restype          = c_int
    lib.sl_free_raw_sp_matrix_wrap.restype     = c_int
    lib.sl_raw_sp_matrix_nnz.restype           = c_int
    lib.sl_raw_sp_matrix_height.restype           = c_int
    lib.sl_raw_sp_matrix_width.restype           = c_int
    lib.sl_raw_sp_matrix_struct_updated.restype = c_int
    lib.sl_raw_sp_matrix_reset_update_flag.restype = c_int
    lib.sl_raw_sp_matrix_data.restype          = c_int
    lib.sl_strerror.restype                    = c_char_p
    lib.sl_supported_sketch_transforms.restype = c_char_p
    lib.sl_has_elemental.restype               = c_bool
    lib.sl_has_combblas.restype                = c_bool
    lib.sl_get_exception_info.restype          = None
    lib.sl_print_exception_trace               = None
    
    ELEM_INSTALLED = lib.sl_has_elemental()
    KDT_INSTALLED  = lib.sl_has_combblas()

    if seed == -1:
        seed = int(time.time())

    if 'ctxt_obj' in globals():
        lib.sl_free_context(ctxt_obj)
            
    ctxt_obj = c_void_p()
    lib.sl_create_default_context(seed, byref(ctxt_obj))
```


Overlapping Code:
```
lize(seed=-1):
"""
Reinitalize the library with a seed. If seed is -1 then system time is
used to create the seed.
"""
global lib, ctxt_obj, ELEM_INSTALLED, KDT_INSTALLED

#
# Load C-API library and set return types
#
lib = cdll.LoadLibrary('libcskylark.so')
lib.sl_create_context.restype = c_int
lib.sl_create_default_context.restype = c_int
lib.sl_free_context.restype = c_int
lib.sl_create_sketch_transform.restype = c_int
lib.sl_serialize_sketch_transform.restype = c_int
lib.sl_deserialize_sketch_transform.restype = c_int
lib.sl_wrap_raw_matrix.restype = c_int
lib.sl_free_raw_matrix_wrap.restype = c_int
lib.sl_wrap_raw_sp_matrix.restype = c_int
lib.sl_free_raw_sp_matrix_wrap.restype = c_int
lib.sl_raw_sp_matrix_nnz.restype = c_int
lib.sl_raw_sp_matrix_height.restype = c_int
lib.sl_raw_sp_matrix_width.restype = c_int
lib.sl_raw_sp_matrix_struct_updated.restype = c_int
lib.sl_raw_sp_matrix_reset_update_flag.restype = c_int
lib.sl_raw_sp_matrix_data.restype = c_int
lib.sl_strerror.restype = c_char_p
lib.sl_supported_sketch_transforms.restype = c_char_p
lib.sl_has_elemental.restype = c_bool
lib.sl_has_combblas.restype = c_bool
lib.sl_get_exception_info.restype = None
lib.sl_print_exception_trace = None

ELEM_INSTALLED = lib.sl_has_elemental()
KDT_INSTALLED = lib.sl_has_combblas()
if seed == -1:
seed = int(time.time())
if 'ctxt_obj' in globals():
lib.sl_free_context(ctxt_obj)

ctxt_obj = c_void_p()
lib.sl_create_default_context(see
```
<Overlap Ratio: 0.9803921568627451>

---

--- 123 --
Question ID: 4a5ff1646cdadb2db61f0ae2c348e0c1114c7fb2_0
Original Code:
```
def euler_from_quaternion(x, y, z, w):
        
     t3 = +2.0 * (w * z + x * y)
     t4 = +1.0 - 2.0 * (y * y + z * z)
     yaw_z = math.atan2(t3, t4)
     
     return yaw_z # in radians
```


Overlapping Code:
```
ion(x, y, z, w):

t3 = +2.0 * (w * z + x * y)
t4 = +1.0 - 2.0 * (y * y + z * z)
yaw_z = math.atan2(t3, t4)

return
```
<Overlap Ratio: 0.7354838709677419>

---

--- 124 --
Question ID: 906f2f0971cacd8845d8c8eaa239106deda3912d_30
Original Code:
```
def checkInteger(s):
    try:
        int(s)
        return True
    except ValueError:
        return False
```


Overlapping Code:
```
ckInteger(s):
try:
int(s)
return True
except ValueError:
return False
```
<Overlap Ratio: 0.9078947368421053>

---

--- 125 --
Question ID: 5e611139ab530bcf30171430af22d7d1c538a2b8_1
Original Code:
```
def _read_image(img_path, normalize=False, dtype=np.float32):
  img = np.array(Image.open(img_path))
  if normalize:
    img = img.astype(np.float32) * 2. / 255. - 1
  if dtype is not None:
    img = img.astype(dtype)
  return img
```


Overlapping Code:
```
mage(img_path, normalize=False, dtype=np.float32):
img = np.array(Image.open(img_path))
if normalize:
img = img.astype(np.float32) * 2. / 255. - 1
if dtype is not None:
img = img.astype(dtype)
return 
```
<Overlap Ratio: 0.9345794392523364>

---

--- 126 --
Question ID: 198ca08eaa928b53fdcdc57c8503851d20d28c99_0
Original Code:
```
def logistic(x, L, k, x0):
    """
    Logistic function

    .. math::
       L/(1+exp(-k(x-x0)))

    Parameters
    ----------
    x : array_like
        Independent variable to evalute logistic function
    L : float
        Maximum of logistic function
    k : float
        Steepness of logistic function
    x0 : float
        Inflection point of logistic function

    Returns
    -------
    float or ndarray
        Logistic function at *x* with maximum *L*, steepness *k* and inflection
        point *x0*

    """
    return L * sp.expit(k * (x - x0))
```


Overlapping Code:
```
L, k, x0):
"""
Logistic function
.. math::
L/(1+exp(-k(x-x0)))
Parameters
----------
x : array_like
Independent variable to evalute logistic function
L : float
Maximum of logistic function
k : float
Steepness of logistic function
x0 : float
Inflection point of logistic function
Returns
-------
float or ndarray
Logistic function at *x* with maximum *L*, steepness *k* and inflection
point *x0*
"""
r
```
<Overlap Ratio: 0.8928571428571429>

---

--- 127 --
Question ID: 001f8cd2f55ca8406127d6220844b96209a6b15a_48
Original Code:
```
def get_offsets(dtype, interleave, band, width, length, num_bands=1):
    """
    From ISCE Image.py
    """
    bytes_per_pix = np.dtype(dtype).itemsize
    # In this single-band case, all choices are the same
    if band == 0 and num_bands == 1:
        return (
            width * bytes_per_pix,  # ImageOffset
            bytes_per_pix,  # PixelOffset
            width * bytes_per_pix,  # LineOffset
        )
    # otherwise, get the specific interleave options
    if interleave == "BIL":
        return (
            band * width * bytes_per_pix,  # ImageOffset
            bytes_per_pix,  # PixelOffset
            num_bands * width * bytes_per_pix,  # LineOffset
        )
    elif interleave == "BIP":
        return (
            band * bytes_per_pix,
            num_bands * bytes_per_pix,
            num_bands * width * bytes_per_pix,
        )
    elif interleave == "BSQ":
        return (
            band * width * length * bytes_per_pix,
            bytes_per_pix,
            width * bytes_per_pix,
        )
    else:
        raise ValueError("Unknown interleave: %s" % interleave)
```


Overlapping Code:
```
d, width, length, num_bands=1):
"""
From ISCE Image.py
"""
bytes_per_pix = np.dtype(dtype).itemsize
# In this single-band case, all choices are the same
if band == 0 and num_bands == 1:
return (
width * bytes_per_pix, # ImageOffset
bytes_per_pix, # PixelOffset
width * bytes_per_pix, # LineOffset
)
# otherwise, get the specific interleave options
if interleave == "BIL":
return (
band * width * bytes_per_pix, # ImageOffset
bytes_per_pix, # PixelOffset
num_bands * width * bytes_per_pix, # LineOffset
)
elif interleave == "BIP":
return (
band * bytes_per_pix,
num_bands * bytes_per_pix,
num_bands * width * bytes_per_pix,
)
elif interleave == "BSQ":
return (
band * width * length * bytes_per_pix,
bytes_per_pix,
width * bytes_per_pix,
)
else:
raise ValueError("Unknown interleave: %s" % interleave)
```
<Overlap Ratio: 0.954653937947494>

---

--- 128 --
Question ID: 391280629f45849718bf50a45a483389e94997dc_2
Original Code:
```
def doConvertRc(oMgr, fromVersion):
    if fromVersion < 210:
        globs.log.write(globs.SEV_NOTICE, function='Convert', action='doConvertRc', msg='Updating .rc file from version {} to version 210.'.format(fromVersion))
        # Start adding back in secitons
        if oMgr.parser.has_section('main') is False:
            globs.log.write(globs.SEV_DEBUG, function='Convert', action='convertRc', msg='Adding [main] section.')
            oMgr.addRcSection('main')

        if oMgr.parser.has_section('incoming') is False:
            globs.log.write(globs.SEV_DEBUG, function='Convert', action='convertRc', msg='Adding [incoming] section.')
            oMgr.addRcSection('incoming')

        if oMgr.parser.has_section('outgoing') is False:
            globs.log.write(globs.SEV_DEBUG, function='Convert', action='convertRc', msg='Adding [outgoing] section.')
            oMgr.addRcSection('outgoing')

        if oMgr.parser.has_section('report') is False:
            globs.log.write(globs.SEV_DEBUG, function='Convert', action='convertRc', msg='Adding [report] section.')
            oMgr.addRcSection('report')

        if oMgr.parser.has_section('headings') is False:
            globs.log.write(globs.SEV_DEBUG, function='Convert', action='convertRc', msg='Adding [headings] section.')
            oMgr.addRcSection('headings')

        for fromsection, fromoption, tosection, tooption in optList210:
            moveOption(oMgr, fromsection, fromoption, tosection, tooption)

        # Adjusted format of sizeDisplay in version 2.1
        szDisp = oMgr.getRcOption('report', 'sizedisplay')
        if szDisp == 'none':
            oMgr.setRcOption('report', 'sizedisplay', 'byte')
        oMgr.setRcOption('report', 'showsizedisplay', 'true')

        oMgr.updateRc()
        doConvertRc(oMgr, 210)
    elif fromVersion < 300:
        globs.log.write(globs.SEV_NOTICE, function='Convert', action='doConvertRc', msg='Updating .rc file from version {} to version 300.'.format(fromVersion))
        # Remove deprecated options
        if oMgr.parser.has_option('report', 'noactivitybg') == True:    # Deprecated in version 2.2.0
            oMgr.clearRcOption('report', 'noactivitybg')

        if oMgr.parser.has_option('main', 'version') == True:    # Deprecated in version 2.2.7 (renamed to 'rcversion')
            oMgr.clearRcOption('main', 'version')

        oMgr.updateRc()
        doConvertRc(oMgr, 300)
    elif fromVersion < 310:
        globs.log.write(globs.SEV_NOTICE, function='Convert', action='doConvertRc', msg='Updating .rc file from version {} to version 310.'.format(fromVersion))
        # Adjust size display option
        value1 = oMgr.getRcOption('report', 'sizedisplay')
        value2 = oMgr.getRcOption('report', 'showsizedisplay')
        if value2.lower() == 'false':
            value1 = 'none'
        value1 = sizeTranslate[value1]
        oMgr.setRcOption('report', 'sizedisplay', value1)
        oMgr.clearRcOption('report', 'showsizedisplay')

        # Change basic report options
        reportTitle = oMgr.getRcOption('report', 'reporttitle')
        oMgr.setRcOption('report', 'title', 'Duplicati Backup Summary Report')
        oMgr.clearRcOption('report', 'reporttitle')
        oMgr.setRcOption('report', 'columns', 'source:Source, destination:Destination, date: Date, time: Time, dupversion:Version, duration:Duration, examinedFiles:Files, examinedFilesDelta:+/-, sizeOfExaminedFiles:Size, fileSizeDelta:+/-, addedFiles:Added, deletedFiles:Deleted, modifiedFiles:Modified, filesWithError:Errors, parsedResult:Result, messages:Messages, warnings:Warnings, errors:Errors, logdata:Log Data')
        oMgr.setRcOption('report', 'weminline', 'false')
        moveOption(oMgr, 'report', 'subheadbg', 'report', 'groupheadingbg')
       
        # Set up report sections
        mainReport = oMgr.getRcOption('report', 'style')    # This is the main report run
        oMgr.clearRcOption('report', 'style')

        # Add new sections using pre-defined defaults
        oMgr.addRcSection('srcdest')
        oMgr.addRcSection('bysrc')
        oMgr.addRcSection('bydest')
        oMgr.addRcSection('bydate')
        oMgr.addRcSection('noactivity')
        oMgr.addRcSection('lastseen')
        for section, option, default, cancontinue in options.rcParts:
            if section in ['srcdest','bysrc','bydest','bydate','noactivity','lastseen']:
                oMgr.setRcOption(section, option, default)
       
        # Now, set the default report to mimic what was in the old format
        oMgr.setRcOption(mainReport, 'title', reportTitle)
        oMgr.setRcOption('report', 'layout', mainReport + ', noactivity')

        # Update 'last seen' settings
        value1 = oMgr.getRcOption('report', 'lastseensummary')
        value2 = oMgr.getRcOption('report', 'lastseensummarytitle')
        if value1.lower() != 'none':
            oMgr.setRcOption('lastseen', 'title', value2)
            value3 = oMgr.getRcOption('report', 'layout')
            if value1.lower() == 'top':
                oMgr.setRcOption('report', 'layout', 'lastseen, ' + value3)
            else:
                oMgr.setRcOption('report', 'layout', value3 + ', lastseen')
        oMgr.clearRcOption('report', 'lastseensummary')
        oMgr.clearRcOption('report', 'lastseensummarytitle')
        
        # Adjust field background colors
        moveOption(oMgr, 'report', 'lastseenlow', 'report', 'normaldays')
        moveOption(oMgr, 'report', 'lastseenlowcolor', 'report', 'normalbg')
        moveOption(oMgr, 'report', 'lastseenmed', 'report', 'warningdays')
        moveOption(oMgr, 'report', 'lastseenmedcolor', 'report', 'warningbg')
        moveOption(oMgr, 'report', 'lastseenhighcolor', 'report', 'errorbg')

        # Convert headings to new 'columns' format
        headings = oMgr.getRcSection('headings')
        columns = ''
        colIndex = -1
        for columnName in headings:
            colIndex += 1
            if headings[columnName] != '':
                columns += v310Translate[columnName] + ':' + headings[columnName]
                if colIndex < len(headings)-1:
                    columns += ', '
        if columns[-2:] == ', ':
            columns = columns[:len(columns)-2:]
        oMgr.setRcOption(mainReport, 'columns', columns)
        oMgr.clearRcSection('headings')

        # Change to new email server format
        # Set [main]emailservers= option
        oMgr.setRcOption('main', 'emailservers', 'incoming, outgoing')

        # Move 'in*' to just '*'
        protocol = oMgr.getRcOption('incoming', 'intransport')
        oMgr.setRcOption('incoming', 'protocol', protocol)
        oMgr.clearRcOption('incoming', 'intransport')        
        oMgr.setRcOption('outgoing', 'protocol', 'smtp')

        for option in ['inserver', 'inport', 'inencryption', 'inaccount', 'inpassword', 'infolder', 'inkeepalive']:
            optVal = oMgr.getRcOption('incoming', option)
            oMgr.setRcOption('incoming', option[2:], optVal)
            oMgr.clearRcOption('incoming', option)
        for option in ['outserver', 'outport', 'outencryption', 'outaccount', 'outpassword', 'outsender', 'outsendername', 'outreceiver', 'outkeepalive']:
            optVal = oMgr.getRcOption('outgoing', option)
            if optVal == None:
                optVal = ''
            oMgr.setRcOption('outgoing', option[3:], optVal)
            oMgr.clearRcOption('outgoing', option)

        # Move 'markread' to incoming
        markread = oMgr.getRcOption('main', 'markread')
        oMgr.setRcOption('incoming', 'markread', markread)
        oMgr.clearRcOption('main', 'markread')

        # Move logging levels
        verbose = oMgr.getRcOption('main', 'verbose')
        if verbose in ['1','2']:
            verbose = '5'
        elif verbose == '3':
            verbose = '7'
        oMgr.setRcOption('main', 'verbose', verbose)

        # Add authentication methods
        oMgr.setRcOption('incoming', 'authentication', 'basic')
        oMgr.setRcOption('outgoing', 'authentication', 'basic')

        # Update [apprise] section, if it exists. If it doesn't, default .rc routine will take care of it.
        if oMgr.hasSection('apprise'):
            oMgr.setRcOption('apprise', 'enabled', 'true')

        oMgr.updateRc()
        doConvertRc(oMgr, 310)
    else:
        pass

    return None;
```


Overlapping Code:
```
ConvertRc(oMgr, fromVersion):
if fromVersion < 210:
globs.log.write(globs.SEV_NOTICE, function='Convert', action='doConvertRc', msg='Updating .rc file from version {} to version 210.'.format(fromVersion))
# Start adding back in secitons
if oMgr.parser.has_section('main') is False:
globs.log.write(globs.SEV_DEBUG, function='Convert', action='convertRc', msg='Adding [main] section.')
oMgr.addRcSection('main')
if oMgr.parser.has_section('incoming') is False:
globs.log.write(globs.SEV_DEBUG, function='Convert', action='convertRc', msg='Adding [incoming] section.')
oMgr.addRcSection('incoming')
if oMgr.parser.has_section('outgoing') is False:
globs.log.write(globs.SEV_DEBUG, function='Convert', action='convertRc', msg='Adding [outgoing] section.')
oMgr.addRcSection('outgoing')
if oMgr.parser.has_section('report') is False:
globs.log.write(globs.SEV_DEBUG, function='Convert', action='convertRc', msg='Adding [report] section.')
oMgr.addRcSection('report')
if oMgr.parser.has_section('headings') is False:
globs.log.write(globs.SEV_DEBUG, function='Convert', action='convertRc', msg='Adding [headings] section.')
oMgr.addRcSection('headings')
for fromsection, fromoption, tosection, tooption in optList210:
moveOption(oMgr, fromsection, fromoption, tosection, tooption)
# Adjusted format of sizeDisplay in version 2.1
szDisp = oMgr.getRcOption('report', 'sizedisplay')
if szDisp == 'none':
oMgr.setRcOption('report', 'sizedisplay', 'byte')
oMgr.setRcOption('report', 'showsizedisplay', 'true')
oMgr.updateRc()
doConvertRc(oMgr, 210)
elif fromVersion < 300:
globs.log.write(globs.SEV_NOTICE, function='Convert', action='doConvertRc', msg='Updating .rc file from version {} to version 300.'.format(fromVersion))
# Remove deprecated options
if oMgr.parser.has_option('report', 'noactivitybg') == True: # Deprecated in version 2.2.0
oMgr.clearRcOption('report', 'noactivitybg')
if oMgr.parser.has_option('main', 'version') == True: # Deprecated in version 2.2.7 (renamed to 'rcversion')
oMgr.clearRcOption('main', 'version')
oMgr.updateRc()
doConvertRc(oMgr, 300)
elif fromVersion < 310:
globs.log.
```
<Overlap Ratio: 0.9831460674157303>

---

--- 129 --
Question ID: 8566a374e758f9f41eac095d5697b11bfd12d607_0
Original Code:
```
def makepacket(number):

    
    numberstring = str(number)
    while len(numberstring)  < 4:
        numberstring = "0" + numberstring
    
    passcode = binascii.hexlify(numberstring.encode()).decode()
    packet = "45454d5030313030455bc678040000004a00000001000000001c00000000000000ffffff00455bc6640201030005200320200001ff00ff00ff00000810000000010c00000026ab9ffbdf" + passcode + "000000000000000000000000ac15c508"
    #packet = "45454d50303130300a9c1178040000005f00000001010000001c00000000000000ffffe0000a9c00010201030005200320200001ff00ff00ff00000810000000010c0000b0e892ecf8bc" + passcode + "0000000000000000000000000a9c221b1100000011000000000000000e0000000100000007"
    return binascii.unhexlify(packet)
```


Overlapping Code:
```
ef makepacket(number):

numberstring = str(number)
while len(numberstring) < 4:
numberstring = "0" + numberstring

passcode = binascii.hexlify(numberstring.encode()).decode()
packet = "45454d5030313030455bc678040000004a00000001000000001c00000000000000ffffff00455bc6640201030005200320200001ff00ff00ff00000810000000010c00000026ab9ffbdf" + passcode + "000000000000000000000000ac15c508"
#packet = "45454d50303130300a9c1178040000005f00000001010000001c00000000000000ffffe0000a9c00010201030005200320200001ff00ff00ff00000810000000010c0000b0e892ecf8bc" + passcode + "0000000000000000000000000a9c221b1100000011000000000000000e000
```
<Overlap Ratio: 0.9266467065868264>

---

--- 130 --
Question ID: 86adb472c4f6dc145f0669ea4b05c823e270f608_1
Original Code:
```
def _python_exit():
    global _global_shutdown
    _global_shutdown = True
    items = list(_threads_wakeups.items())
    mp.util.debug("Interpreter shutting down. Waking up queue_manager_threads "
                  "{}".format(items))
    for thread, thread_wakeup in items:
        if thread.is_alive():
            thread_wakeup.wakeup()
    for thread, _ in items:
        thread.join()
```


Overlapping Code:
```
on_exit():
global _global_shutdown
_global_shutdown = True
items = list(_threads_wakeups.items())
mp.util.debug("Interpreter shutting down. Waking up queue_manager_threads "
"{}".format(items))
for thread, thread_wakeup in items:
if thread.is_alive():
thread_wakeup.wakeup()
for threa
```
<Overlap Ratio: 0.8847352024922118>

---

--- 131 --
Question ID: df1839168cc2107280bf8d58317bbcc5371a2473_7
Original Code:
```
def _reload_model(ts_experiment, eval_conf, idx, use_best=False):
    '''
    load model into ts_experiment
    '''
    fn = eval_conf.df_results.iloc[idx]['model_fn']
    # print('fn')
    arch = eval_conf.df_results.iloc[idx]['arch']
    print(arch)
    ts_experiment.learn = _get_mock_learner(ts_experiment, arch)
    if not use_best:
        ts_experiment.learn.load(eval_conf.model_dir/Path(fn).stem)
    else:
        ts_experiment.learn.load(eval_conf.model_dir/(Path(fn).stem+'_best_val'))
    return

    if not test:
        fn = eval_conf.preds_dir/eval_conf.df_results.iloc[idx]['val_preds'] 
    else:
        fn=eval_conf.preds_dir/eval_conf.df_results.iloc[idx]['test_preds']
    return torch.load(fn)
```


Overlapping Code:
```
d_model(ts_experiment, eval_conf, idx, use_best=False):
'''
load model into ts_experiment
'''
fn = eval_conf.df_results.iloc[idx]['model_fn']
# print('fn')
arch = eval_conf.df_results.iloc[idx]['arch']
print(arch)
ts_experiment.learn = _get_mock_learner(ts_experiment, arch)
if not use_best:
ts_experiment.learn.load(eval_conf.model_dir/Path(fn).stem)
else:
ts_experiment.learn.load(eval_conf.model_dir/(Path(fn).stem+'_best_val'))
return
if not test:
fn = eval_conf.preds_dir/eval_conf.df_results.iloc[idx]['val_preds'] 
else:
fn=eval_conf.preds_dir/eval_conf.df_results.iloc[idx]['test_preds']
retu
```
<Overlap Ratio: 0.9569377990430622>

---

--- 132 --
Question ID: 462e824aef2fd6c7e8d0d652b701f74c797eef13_4
Original Code:
```
def write_smiles(dataset: Iterable[str], filename: str):
    """
    Dumps a list of SMILES into a file, one per line
    """
    n_lines = 0
    with open(filename, 'w') as out:
        for smiles_str in dataset:
            out.write('%s\n' % smiles_str)
            n_lines += 1
    print(f'{filename} contains {n_lines} molecules')
```


Overlapping Code:
```
ename: str):
"""
Dumps a list of SMILES into a file, one per line
"""
n_lines = 0
with open(filename, 'w') as out:
for smiles_str in dataset:
out.write('%s\n' % smiles_str)
n_lines += 1
print(f'{filen
```
<Overlap Ratio: 0.7168458781362007>

---

--- 133 --
Question ID: 10b4ae8337b708cdd45772874ffd6a861ff36fa5_7
Original Code:
```
def _prepare_cleanup(
    training: MappedTriples,
    testing: MappedTriples,
    max_ids: Optional[Tuple[int, int]] = None,
) -> torch.BoolTensor:
    """
    Calculate a mask for the test triples with triples containing test-only entities or relations.

    :param training: shape: (n, 3)
        The training triples.
    :param testing: shape: (m, 3)
        The testing triples.

    :return: shape: (m,)
        The move mask.
    """
    # base cases
    if len(testing) == 0:
        return torch.empty(0, dtype=torch.bool)
    if len(training) == 0:
        return torch.ones(testing.shape[0], dtype=torch.bool)

    columns = [[0, 2], [1]]
    to_move_mask = torch.zeros(1, dtype=torch.bool)
    if max_ids is None:
        max_ids = typing.cast(
            Tuple[int, int],
            tuple(max(training[:, col].max().item(), testing[:, col].max().item()) + 1 for col in columns),
        )
    for col, max_id in zip(columns, max_ids):
        # IDs not in training
        not_in_training_mask = torch.ones(max_id, dtype=torch.bool)
        not_in_training_mask[training[:, col].view(-1)] = False

        # triples with exclusive test IDs
        exclusive_triples = not_in_training_mask[testing[:, col].view(-1)].view(-1, len(col)).any(dim=-1)
        to_move_mask = to_move_mask | exclusive_triples
    return to_move_mask
```


Overlapping Code:
```
g: MappedTriples,
testing: MappedTriples,
max_ids: Optional[Tuple[int, int]] = None,
) -> torch.BoolTensor:
"""
Calculate a mask for the test triples with triples containing test-only entities or relations.
:param training: shape: (n, 3)
The training triples.
:param testing: shape: (m, 3)
The testing triples.
:return: shape: (m,)
The move mask.
"""
# base cases
if len(testing) == 0:
return torch.empty(0, dtype=torch.bool)
if len(training) == 0:
return torch.ones(testing.shape[0], dtype=torch.bool)
columns = [[0, 2], [1]]
to_move_mask = torch.zeros(1, dtype=torch.bool)
if max_ids is None:
max_ids = typing.cast(
Tuple[int, int],
tuple(max(training[:, col].max().item(), testing[:, col].max().item()) + 1 for col in columns),
)
for col, max_id in zip(columns, max_ids):
# IDs not in training
not_in_training_mask = torch.ones(max_id, dtype=torch.bool)
not_in_training_mask[training[:, col].view(-1)] = False
# triples with exclusive test IDs
exclusive_triples = not_in_training_mask[testing[:, col].view(-1)].view(-1, len(col)).any(dim=-1)
to_move_mask = to_move_mask | exclusive_triples
return to_m
```
<Overlap Ratio: 0.9675723049956179>

---

--- 134 --
Question ID: bf6c7a3e1fd05895289e7302d31c3ba8727dd474_5
Original Code:
```
@click.command()
@click.pass_context
@click.option('--model', 'model', help='which type of raster')
@click.option('--forecast_hours_', 'forecast_hours_',
              help='Forecast hours to extract from')
@click.option('--model_run', 'model_run',
              help='model run to use for the time series')
@click.option('--input_geojson', 'input_geojson', help='shape to clip by')
def extract_raster(ctx, model, forecast_hours_, model_run, input_geojson):
    output_geojson = extract_raster_main(
        model, forecast_hours_, model_run, input_geojson)

    return output_geojson

    if output_geojson is not None:
        click.echo(json.dumps(output_geojson))
```


Overlapping Code:
```
@click.command()
@click.pass_context
@click.option('--model', 'model', help='which type of raster')
@click.option('--forecast_hours_', 'forecast_hours_',
help='Forecast hours to extract from')
@click.option('--model_run', 'model_run',
help='model run to use for the time series')
@click.option('--input_geojson', 'input_geojson', help='shape to clip by')
def extract_raster(ctx, model, forecast_hours_, model_run, input_geojson):
output_geojson = extract_raster_main(
model, forecast_hours_, model_run, input_geojson)
return output_geojson
if output_geojson is not None:
click.echo(json.dumps(ou
```
<Overlap Ratio: 0.9770114942528736>

---

--- 135 --
Question ID: 11abc820cdfc2d5d2bc77037fe9672da5768605c_11
Original Code:
```
def convert_tokens(eval_dict, qa_id, y_start_list, y_end_list):
    """Convert predictions to tokens from the context.

    Args:
        eval_dict (dict): Dictionary with eval info for the dataset. This is
            used to perform the mapping from IDs and indices to actual text.
        qa_id (int): List of QA example IDs.
        y_start_list (list): List of start predictions.
        y_end_list (list): List of end predictions.
        no_answer (bool): Questions can have no answer. E.g., SQuAD 2.0.

    Returns:
        pred_dict (dict): Dictionary index IDs -> predicted answer text.
        sub_dict (dict): Dictionary UUIDs -> predicted answer text (submission).
    """
    pred_dict = {}
    sub_dict = {}
    for qid, y_start, y_end in zip(qa_id, y_start_list, y_end_list):
        context = eval_dict[str(qid)]["context"]
        spans = eval_dict[str(qid)]["spans"]
        uuid = eval_dict[str(qid)]["uuid"]
        start_idx = spans[y_start][0]
        end_idx = spans[y_end][1]
        pred_dict[str(qid)] = context[start_idx: end_idx]
        sub_dict[uuid] = context[start_idx: end_idx]
    return pred_dict, sub_dict
```


Overlapping Code:
```
nvert_tokens(eval_dict, qa_id, y_start_list, y_end_list):
"""Convert predictions to tokens from the context.
Args:
eval_dict (dict): Dictionary with eval info for the dataset. This is
used to perform the mapping from IDs and indices to actual text.
qa_id (int): List of QA example IDs.
y_start_list (list): List of start predictions.
y_end_list (list): List of end predictions.
no_answer (bool): Questions can have no answer. E.g., SQuAD 2.0.
Returns:
pred_dict (dict): Dictionary index IDs -> predicted answer text.
sub_dict (dict): Dictionary UUIDs -> predicted answer text (submission).
"""
pred_dict = {}
sub_dict = {}
for qid, y_start, y_end in zip(qa_id, y_start_list, y_end_list):
context = eval_dict[str(qid)]["context"]
spans = eval_dict[str(qid)]["spans"]
uuid = eval_dict[str(qid)]["uuid"]
start_idx = spans[y_start][0]
end_idx = spans[y_end][1]
pred_dict[str(qid)] = context[start_idx: end_idx]
sub_dict[uuid] = context[start_idx: end_idx]
return p
```
<Overlap Ratio: 0.975609756097561>

---

--- 136 --
Question ID: 0a3845708a2f673a61b329be3525c6a6cb0e6529_2
Original Code:
```
def discover_benchmarks(module_name, type_=BenchmarksType.TIME.value, repeat=10, number=1):
    """
    Discover benchmarks in the module

    :param module_name: benchmarks module
    :param type_: benchmark type
    :return: time benchmarks
    """
    for module in discover_modules(module_name):
        for attr_name, module_attr in module.__dict__.items():
            if attr_name.startswith('_'):
                # skip attributes which start with underscore
                continue

            if inspect.isclass(module_attr):
                for name, class_attr in inspect.getmembers(module_attr):
                    if not name.startswith(f'{type_}_'):
                        continue

                    name_parts = module.__name__.split('.', 1)[1:] + [module_attr.__name__, name]
                    benchmark_name = '.'.join(name_parts)
                    func = inspect.getattr_static(module_attr, name)
                    params = inspect.getattr_static(module_attr, 'params', [[]])
                    for param in itertools.product(*params):
                        yield TimeBenchmark(benchmark_name, func, param, module_attr, repeat=repeat, number=number)
```


Overlapping Code:
```
, type_=BenchmarksType.TIME.value, repeat=10, number=1):
"""
Discover benchmarks in the module
:param module_name: benchmarks module
:param type_: benchmark type
:return: time benchmarks
"""
for module in discover_modules(module_name):
for attr_name, module_attr in module.__dict__.items():
if attr_name.startswith('_'):
# skip attributes which start with underscore
continue
if inspect.isclass(module_attr):
for name, class_attr in inspect.getmembers(module_attr):
if not name.startswith(f'{type_}_'):
continue
name_parts = module.__name__.split('.', 1)[1:] + [module_attr.__name__, name]
benchmark_name = '.'.join(name_parts)
func = inspect.getattr_static(module_attr, name)
params = inspect.getattr_static(module_attr, 'params', [[]])
for param in itertools.product(*params):
yield TimeBenchmark(benchmark_name, func, param, module_attr, repeat=re
```
<Overlap Ratio: 0.9392265193370166>

---

--- 137 --
Question ID: 9a22132332a06af7c2d99cddd9964d8a5efbd6ca_32
Original Code:
```
def get_playable_podcast11(soup12):
    subjects = []
    for content in soup12.find_all('item'):
        try:        
            link = content.find('enclosure')
            link = link.get('url')
            print("\n\nLink: ", link)
            title = content.find('title')
            title = title.get_text()
        except AttributeError:
            continue
        item = {
                'url': link,
                'title': title,
                'thumbnail': "https://cdn3.img.sputniknews.com/images/105617/96/1056179634.png",
        }
        subjects.append(item)
    return subjects
```


Overlapping Code:
```
def get_playable_podcast11(soup12):
subjects = []
for content in soup12.find_all('item'):
try: 
link = content.find('enclosure')
link = link.get('url')
print("\n\nLink: ", link)
title = content.find('title')
title = title.get_text()
except AttributeError:
continue
item = {
'url': link,
'title': title,
'thumbnail': "https://cdn3.img.sputniknews.com/images/105617/96/1056179634.png",
}
subjects.appen
```
<Overlap Ratio: 0.9456264775413712>

---

--- 138 --
Question ID: b7d8aba58c8896f79e236018db55298dd7d93010_2
Original Code:
```
def compute_timestep(u, current_delta_t):
    """Return the timestep, based upon the CFL criterion"""

    ref_vel.interpolate(dot(JacobianInverse(mesh), u))
    ts_min = 1. / mesh.comm.allreduce(ref_vel.dat.data.max(), MPI.MAX)
    # Grab (smallest) maximum permitted on all cores:
    ts_max = min(float(current_delta_t)*increase_tolerance, maximum_timestep)
    # Compute timestep:
    tstep = min(ts_min*target_cfl_no, ts_max)
    return tstep
```


Overlapping Code:
```
ef compute_timestep(u, current_delta_t):
"""Return the timestep, based upon the CFL criterion"""
ref_vel.interpolate(dot(JacobianInverse(mesh), u))
ts_min = 1. / mesh.comm.allreduce(ref_vel.dat.data.max(), MPI.MAX)
# Grab (smallest) maximum permitted on all cores:
ts_max = min(float(current_delta_t)*increase_tolerance, maximum_timestep)
# Compute timestep:
tstep = min(ts_min*target_cfl_no, ts_max)
ret
```
<Overlap Ratio: 0.9758454106280193>

---

--- 139 --
Question ID: dbd2459f38ac87dc671cbf3243129d7877741767_6
Original Code:
```
def post_net(inputs, is_train):

    inputs = tf.reshape(inputs, [config.batch_size, config.max_phr_len , 1, -1])

    conv_1 = tf.nn.tanh(tf.layers.batch_normalization(tf.layers.conv2d(inputs, 512, (5,1), name = "post_conv_1",padding='same'), training = is_train, name = "post_conv_1_BN"))

    conv_2 = tf.nn.tanh(tf.layers.batch_normalization(tf.layers.conv2d(conv_1, 512, (5,1), name = "post_conv_2",padding='same'), training = is_train, name = "post_conv_2_BN"))

    conv_3 = tf.nn.tanh(tf.layers.batch_normalization(tf.layers.conv2d(conv_2, 512, (5,1), name = "post_conv_3",padding='same'), training = is_train, name = "post_conv_3_BN"))   

    conv_4 = tf.nn.tanh(tf.layers.batch_normalization(tf.layers.conv2d(conv_3, 512, (5,1), name = "post_conv_4",padding='same'), training = is_train, name = "post_conv_4_BN"))

    output = tf.layers.conv2d(conv_4, config.num_features, (5,1), name = "post_conv_5",padding='same')

    return tf.squeeze(output)
```


Overlapping Code:
```
ts, is_train):
inputs = tf.reshape(inputs, [config.batch_size, config.max_phr_len , 1, -1])
conv_1 = tf.nn.tanh(tf.layers.batch_normalization(tf.layers.conv2d(inputs, 512, (5,1), name = "post_conv_1",padding='same'), training = is_train, name = "post_conv_1_BN"))
conv_2 = tf.nn.tanh(tf.layers.batch_normalization(tf.layers.conv2d(conv_1, 512, (5,1), name = "post_conv_2",padding='same'), training = is_train, name = "post_conv_2_BN"))
conv_3 = tf.nn.tanh(tf.layers.batch_normalization(tf.layers.conv2d(conv_2, 512, (5,1), name = "post_conv_3",padding='same'), training = is_train, name = "post_conv_3_BN")) 
conv_4 = tf.nn.tanh(tf.layers.batch_normalization(tf.layers.conv2d(conv_3, 512, (5,1), name = "post_conv_4",padding='same'), training = is_train, name = "post_conv_4_BN"))
output = tf.layers.conv2d(conv_4, config.num_features, (5,1), name = "post_conv_5",padding='same')
return tf.squeeze(ou
```
<Overlap Ratio: 0.9761388286334056>

---

--- 140 --
Question ID: 18ea7a4669d744d3db26b2a27f5324cb846eec65_0
Original Code:
```
def test_workchain_build(sphinx_build_factory, xml_equal, reference_result):
    """Test building sphinx documentation for WorkChain.

    Builds Sphinx documentation for workchain and compares against expected XML result.
    """
    sphinx_build = sphinx_build_factory('workchain', buildername='xml')
    sphinx_build.build(assert_pass=True)

    index_file = sphinx_build.outdir / 'index.xml'
    xml_equal(index_file, reference_result('workchain.xml'))
```


Overlapping Code:
```
phinx_build_factory, xml_equal, reference_result):
"""Test building sphinx documentation for WorkChain.
Builds Sphinx documentation for workchain and compares against expected XML result.
"""
sphinx_build = sphinx_build_factory('workchain', buildername='xml')
sphinx_build.build(assert_pass=True)
index_file = sphinx_build.outdir / 'index.xml'
xml_equal(index_file, reference_result('workchain.xml'))
```
<Overlap Ratio: 0.9389671361502347>

---

--- 141 --
Question ID: ebec4e65e2536c8030d90c981434c0ab7bd826f4_4
Original Code:
```
def get(PATH, mask=None, bg=False, cb=None):
    if bg:
        _thread.start_new_thread(
            INTERNAL.get, [PATH, cb, mask])
    else:
        return INTERNAL.get(PATH, cb, mask)
```


Overlapping Code:
```
, mask=None, bg=False, cb=None):
if bg:
_thread.start_new_thread(
INTERNAL.get, [PATH, cb, mask])
else:
return INTER
```
<Overlap Ratio: 0.7682119205298014>

---

--- 142 --
Question ID: a4dfca8c84da006ebe66c8c1a14942cc8058e5f2_2
Original Code:
```
def test_gzip():
    mock = MagicMock(return_value="salt")
    with patch.dict(archive.__salt__, {"cmd.run": mock}):
        with patch("salt.utils.path.which", lambda exe: exe):
            ret = archive.gzip("/tmp/something-to-compress")
            assert ["salt"] == ret
            mock.assert_called_once_with(
                ["gzip", "/tmp/something-to-compress"],
                runas=None,
                python_shell=False,
                template=None,
            )
```


Overlapping Code:
```
f test_gzip():
mock = MagicMock(return_value="salt")
with patch.dict(archive.__salt__, {"cmd.run": mock}):
with patch("salt.utils.path.which", lambda exe: exe):
ret = archive.gzip("/tmp/something-to-compress")
assert ["salt"] == ret
mock.assert_called_once_with(
["gzip", "/tmp/something-to-compress"],
runas=None,
python_shell=False,
template=None,

```
<Overlap Ratio: 0.9915014164305949>

---

--- 143 --
Question ID: d1ead9ab375e92b80456d2755130fc686af9747a_1
Original Code:
```
def run_main():

    ap = argparse.ArgumentParser()
    ap.add_argument('-d', '--dataset',    type=str, default='./dataset', help='root folder of dataset')
    ap.add_argument('-g', '--graph',      type=str, default='./freeze/frozen_graph.pb', help='graph file (.pb) to be evaluated.')
    ap.add_argument('-i', '--input_node', type=str, default='input_1', help='input node.')
    ap.add_argument('-o', '--output_node',type=str, default='flatten_1/Reshape', help='output node.') 
    ap.add_argument('-b', '--batchsize',  type=int, default=1, help='Evaluation batchsize. Default is 1.') 
    args = ap.parse_args()

    print('\n'+DIVIDER)
    print('Keras version      : ',tf.keras.__version__)
    print('TensorFlow version : ',tf.__version__)
    print(sys.version)
    print(DIVIDER)
    print(' Command line options:')
    print ('--dataset     : ',args.dataset)
    print ('--graph       : ',args.graph)
    print ('--input_node  : ',args.input_node)
    print ('--output_node : ',args.output_node)
    print ('--batchsize   : ',args.batchsize)
    print(DIVIDER)

    input_graph_def = tf.Graph().as_graph_def()
    input_graph_def.ParseFromString(tf.io.gfile.GFile(args.graph, "rb").read())

    graph_eval(input_graph_def, args.input_node, args.output_node, args.dataset, args.batchsize)
```


Overlapping Code:
```
main():
ap = argparse.ArgumentParser()
ap.add_argument('-d', '--dataset', type=str, default='./dataset', help='root folder of dataset')
ap.add_argument('-g', '--graph', type=str, default='./freeze/frozen_graph.pb', help='graph file (.pb) to be evaluated.')
ap.add_argument('-i', '--input_node', type=str, default='input_1', help='input node.')
ap.add_argument('-o', '--output_node',type=str, default='flatten_1/Reshape', help='output node.') 
ap.add_argument('-b', '--batchsize', type=int, default=1, help='Evaluation batchsize. Default is 1.') 
args = ap.parse_args()
print('\n'+DIVIDER)
print('Keras version : ',tf.keras.__version__)
print('TensorFlow version : ',tf.__version__)
print(sys.version)
print(DIVIDER)
print(' Command line options:')
print ('--dataset : ',args.dataset)
print ('--graph : ',args.graph)
print ('--input_node : ',args.input_node)
print ('--output_node : ',args.output_node)
print ('--batchsize : ',args.batchsize)
print(DIVIDER)
input_graph_def = tf.Graph().as_graph_def()
input_graph_def.ParseFromString(tf.io.gfile.GFile(args.graph, "rb").read())
graph_eval(input_graph_def, args.input_node, args.output_node, args.dataset, 
```
<Overlap Ratio: 0.9804587935429057>

---

--- 144 --
Question ID: 76db2bb47977d65d349e1e37bef2d5fbf3bbd87a_0
Original Code:
```
@router.get("/status", tags=["status"])
def serverStatus():
    cP = ConfigProvider.ConfigProvider()
    psU = ProcessStatusUtil()
    psD = psU.getInfo()
    return {"msg": "Status is nominal!", "version": cP.getVersion(), "status": psD}
```


Overlapping Code:
```
s"])
def serverStatus():
cP = ConfigProvider.ConfigProvider()
psU = ProcessStatusUtil()
psD = psU.getInfo()
return {"msg": "Status is nominal!", "vers
```
<Overlap Ratio: 0.6756756756756757>

---

--- 145 --
Question ID: 8b4276cf467857883740cd00e1930987bd949c60_2
Original Code:
```
def test_ModeId():

    # read dict
    with open("./tests/test_data/ModeId_results_dict.json") as json_file:
        api_results = json.load(json_file)

    feat = parse_results(api_results, t_zone=TZ, t_unit=None)
    # Check dataframe conversion
    df_df = pd.read_csv("./tests/test_data/ModeId_df.csv")
    pd.testing.assert_frame_equal(
        feat.to_df().drop("datetime", axis=1), df_df, check_less_precise=True
    )

    # Summary
    res = feat.summary()
    assert res[0]["portion"][0] == 84
    assert res[0]["counts"][1] == 8
    assert (res[1]["counts"][1] == 8).any()
    assert (res[1]["portion"][0] == 84).any()

    # Mode table (+wallclock times)
    feat = parse_results(api_results, t_zone=TZ, t_unit="s")
    mt_df = feat.mode_table().reset_index(drop=True)
    mt_correct_df = pd.read_pickle("./tests/test_data/mode_table_wc.pkl")
    mt_correct_df = mt_correct_df.reset_index(drop=True)
    assert mt_correct_df.equals(mt_df.reset_index(drop=True))
```


Overlapping Code:
```
f test_ModeId():
# read dict
with open("./tests/test_data/ModeId_results_dict.json") as json_file:
api_results = json.load(json_file)
feat = parse_results(api_results, t_zone=TZ, t_unit=None)
# Check dataframe conversion
df_df = pd.read_csv("./tests/test_data/ModeId_df.csv")
pd.testing.assert_frame_equal(
feat.to_df().drop("datetime", axis=1), df_df, check_less_precise=True
)
# Summary
res = feat.summary()
assert res[0]["portion"][0] == 84
assert res[0]["counts"][1] == 8
assert (res[1]["counts"][1] == 8).any()
assert (res[1]["portion"][0] == 84).any()
# Mode table (+wallclock times)
feat = parse_results(api_results, t_zone=TZ, t_unit="s")
mt_df = feat.mode_table().reset_index(drop=True)
mt_correct_df = pd.read_pickle("./tests/test_data/mode_table_wc.pkl")
mt_correct_df = mt_correct_df.reset_index(drop=True)
assert mt_correct_df.equals(mt_
```
<Overlap Ratio: 0.9681093394077449>

---

--- 146 --
Question ID: cd4e26fb528c0876b343d67b094aa0385193bb64_3
Original Code:
```
def test_calling_at_cmd_raises_CommandFailure_when_NO_CARRIER_in_at_cmd_output_occurred(buffer_connection, at_cmd_test_class):
    from moler.exceptions import CommandFailure
    buffer_connection.remote_inject_response(["AT+CMD\ndata\nNO CARRIER\n"])
    at_cmd = at_cmd_test_class("AT+CMD", connection=buffer_connection.moler_connection)
    with pytest.raises(CommandFailure) as error:
        at_cmd()
    assert 'AT+CMD' in str(error.value)
    assert "failed with >>NO CARRIER<<" in str(error.value)
```


Overlapping Code:
```
ises_CommandFailure_when_NO_CARRIER_in_at_cmd_output_occurred(buffer_connection, at_cmd_test_class):
from moler.exceptions import CommandFailure
buffer_connection.remote_inject_response(["AT+CMD\ndata\nNO CARRIER\n"])
at_cmd = at_cmd_test_class("AT+CMD", connection=buffer_connection.moler_connection)
with pytest.raises(CommandFailure) as error:
at_cmd()
assert 'AT+CMD' in str(error.value)
assert "
```
<Overlap Ratio: 0.8456659619450317>

---

--- 147 --
Question ID: 586610cb5605426f59bec3ab33221fad88788b12_0
Original Code:
```
def dice_game():

    high_score = 0
    
    print("Current high score is: ", high_score)

    print("1) Roll Dice")
    print("2) Leave Game")

    choice = input("Enter your choice: ")

    if choice == "1":
        dice_roll1 = random.randint(1,6)
        print("you rolled a: ", dice_roll1)
        dice_roll2 = random.randint(1,6)
        print("You rolled a: ", dice_roll2)

        total = dice_roll1 + dice_roll2

        print("You rolled a total of: ", total)

        if total > high_score:
            print("New high score!\n")
            high_score = total

    elif choice == "2":
        print("Thank you for playing")
    else:
        print("Enter a valid choice!")
        dice_game()
```


Overlapping Code:
```
"Current high score is: ", high_score)
print("1) Roll Dice")
print("2) Leave Game")
choice = input("Enter your choice: ")
if choice == "1":
dice_roll1 = random.randint(1,6)
print("you rolled a: ", dice_roll1)
dice_roll2 = random.randint(1,6)
print("You rolled a: ", dice_roll2)
total = dice_roll1 + dice_roll2
print("You rolled a total of: ", total)
if total > high_score:
print("New high score!\n")
high_score = total
elif choice == "2":
print("Thank you for playing")
else:
print("Enter a valid cho
```
<Overlap Ratio: 0.8976660682226212>

---

--- 148 --
Question ID: 0a110d4a8b8a71da2af25b88982c93be862843a2_155
Original Code:
```
def lisp_send_map_request ( lisp_sockets , lisp_ephem_port , seid , deid , rloc ,
 pubsub = False ) :
 global lisp_last_map_request_sent
 if 7 - 7: i1IIi . I1IiiI
 if 68 - 68: OoooooooOO
 if 91 - 91: IiII . ooOoO0o * I11i
 if 39 - 39: o0oOOo0O0Ooo + i11iIiiIii
 if 69 - 69: iIii1I11I1II1 . II111iiii
 if 36 - 36: I1IiiI * i1IIi + OoOoOO00
 oO000oo0 = OOoO0ooo0ooo0 = None
 if ( rloc ) :
  oO000oo0 = rloc . rloc
  OOoO0ooo0ooo0 = rloc . translated_port if lisp_i_am_rtr else LISP_DATA_PORT
  if 51 - 51: iIii1I11I1II1 % Ii1I + iIii1I11I1II1 + oO0o - IiII * o0oOOo0O0Ooo
  if 13 - 13: iIii1I11I1II1
  if 10 - 10: I1IiiI * iII111i * ooOoO0o . IiII
  if 7 - 7: iIii1I11I1II1
  if 60 - 60: OOooOOo . Ii1I . Ii1I % II111iiii + OoO0O00
 ooOoOoOo , OOOOO0 , OoO = lisp_myrlocs
 if ( ooOoOoOo == None ) :
  lprint ( "Suppress sending Map-Request, IPv4 RLOC not found" )
  return
  if 49 - 49: I1IiiI . I1ii11iIi11i / Oo0Ooo
 if ( OOOOO0 == None and oO000oo0 != None and oO000oo0 . is_ipv6 ( ) ) :
  lprint ( "Suppress sending Map-Request, IPv6 RLOC not found" )
  return
  if 24 - 24: II111iiii
  if 40 - 40: o0oOOo0O0Ooo . I1IiiI - o0oOOo0O0Ooo
 i1i = lisp_map_request ( )
 i1i . record_count = 1
 i1i . nonce = lisp_get_control_nonce ( )
 i1i . rloc_probe = ( oO000oo0 != None )
 i1i . subscribe_bit = pubsub
 i1i . xtr_id_present = pubsub
 if 62 - 62: oO0o
 if 71 - 71: i1IIi . I1ii11iIi11i / i11iIiiIii + II111iiii
 if 14 - 14: iII111i
 if 35 - 35: Ii1I
 if 54 - 54: OOooOOo
 if 83 - 83: i1IIi / II111iiii - I1IiiI + I1ii11iIi11i . IiII * oO0o
 if 92 - 92: OoOoOO00 + oO0o % Ii1I / Ii1I - iII111i
 if ( rloc ) : rloc . last_rloc_probe_nonce = i1i . nonce
 if 11 - 11: Oo0Ooo % II111iiii * Ii1I + II111iiii
 I1IIiIiIIiIiI = deid . is_multicast_address ( )
 if ( I1IIiIiIIiIiI ) :
  i1i . target_eid = seid
  i1i . target_group = deid
 else :
  i1i . target_eid = deid
  if 9 - 9: I1Ii111
  if 69 - 69: i1IIi + ooOoO0o + Ii1I
  if 88 - 88: OoOoOO00 + iII111i % O0 + OOooOOo / OoooooooOO / OOooOOo
  if 95 - 95: ooOoO0o . Oo0Ooo % IiII + iII111i
  if 16 - 16: I11i * OoO0O00 % o0oOOo0O0Ooo - O0 % II111iiii - I1IiiI
  if 72 - 72: OoooooooOO * OoOoOO00 . OOooOOo + Ii1I . OOooOOo / II111iiii
  if 8 - 8: i1IIi
  if 1 - 1: OoOoOO00 . OoO0O00 . OoO0O00 * O0
  if 97 - 97: OoooooooOO % ooOoO0o . I1Ii111 / iII111i
 if ( i1i . rloc_probe == False ) :
  oooOOoO0oo0 = lisp_get_signature_eid ( )
  if ( oooOOoO0oo0 ) :
   i1i . signature_eid . copy_address ( oooOOoO0oo0 . eid )
   i1i . privkey_filename = "./lisp-sig.pem"
   if 59 - 59: II111iiii + O0 . I1ii11iIi11i . Oo0Ooo * OoO0O00
   if 35 - 35: oO0o / I1Ii111 * OOooOOo + OoooooooOO . IiII
   if 1 - 1: I1IiiI + I1Ii111 / OOooOOo . Ii1I . oO0o / I1ii11iIi11i
   if 54 - 54: OOooOOo
   if 86 - 86: oO0o * Oo0Ooo / OOooOOo
   if 18 - 18: II111iiii - I1Ii111
 if ( seid == None or I1IIiIiIIiIiI ) :
  i1i . source_eid . afi = LISP_AFI_NONE
 else :
  i1i . source_eid = seid
  if 13 - 13: i11iIiiIii - O0 % OoOoOO00 + OOooOOo * ooOoO0o
  if 55 - 55: i1IIi - OOooOOo / I11i * Ii1I
  if 20 - 20: OoOoOO00 * iIii1I11I1II1 % O0 - i1IIi
  if 51 - 51: I1ii11iIi11i * Ii1I - oO0o / O0 * OoooooooOO
  if 12 - 12: i1IIi / iIii1I11I1II1 / O0 * OoO0O00
  if 15 - 15: i11iIiiIii / IiII + Ii1I % OOooOOo % I1ii11iIi11i * oO0o
  if 24 - 24: OOooOOo / OOooOOo + I11i / iII111i . oO0o - iII111i
  if 59 - 59: I1ii11iIi11i % II111iiii - i11iIiiIii - I1Ii111
  if 34 - 34: II111iiii + iII111i / IiII
  if 47 - 47: OoO0O00
  if 40 - 40: o0oOOo0O0Ooo / iII111i . o0oOOo0O0Ooo
  if 63 - 63: o0oOOo0O0Ooo * iIii1I11I1II1 * II111iiii . OoO0O00 - oO0o / OoOoOO00
 if ( oO000oo0 != None and lisp_nat_traversal and lisp_i_am_rtr == False ) :
  if ( oO000oo0 . is_private_address ( ) == False ) :
   ooOoOoOo = lisp_get_any_translated_rloc ( )
   if 78 - 78: i11iIiiIii / OoO0O00 / i1IIi . i11iIiiIii
  if ( ooOoOoOo == None ) :
   lprint ( "Suppress sending Map-Request, translated RLOC not found" )
   return
   if 100 - 100: II111iiii . IiII . I11i
   if 60 - 60: OoOoOO00 % OOooOOo * i1IIi
   if 3 - 3: OoooooooOO
   if 75 - 75: OoooooooOO * I1Ii111 * o0oOOo0O0Ooo + I1ii11iIi11i . iIii1I11I1II1 / O0
   if 23 - 23: oO0o - O0 * IiII + i11iIiiIii * Ii1I
   if 8 - 8: ooOoO0o / II111iiii . I1ii11iIi11i * ooOoO0o % oO0o
   if 36 - 36: I1ii11iIi11i % OOooOOo - ooOoO0o - I11i + I1IiiI
   if 37 - 37: I1ii11iIi11i * IiII
 if ( oO000oo0 == None or oO000oo0 . is_ipv4 ( ) ) :
  if ( lisp_nat_traversal and oO000oo0 == None ) :
   O0ooOoOO0OoO0O0 = lisp_get_any_translated_rloc ( )
   if ( O0ooOoOO0OoO0O0 != None ) : ooOoOoOo = O0ooOoOO0OoO0O0
   if 86 - 86: I11i * iIii1I11I1II1 - I1ii11iIi11i % IiII . OOooOOo * I1Ii111
  i1i . itr_rlocs . append ( ooOoOoOo )
  if 49 - 49: OoOoOO00 * OoOoOO00
 if ( oO000oo0 == None or oO000oo0 . is_ipv6 ( ) ) :
  if ( OOOOO0 == None or OOOOO0 . is_ipv6_link_local ( ) ) :
   OOOOO0 = None
  else :
   i1i . itr_rloc_count = 1 if ( oO000oo0 == None ) else 0
   i1i . itr_rlocs . append ( OOOOO0 )
   if 86 - 86: iIii1I11I1II1
   if 42 - 42: ooOoO0o * ooOoO0o . I1ii11iIi11i . ooOoO0o / I1IiiI * iIii1I11I1II1
   if 50 - 50: Ii1I
   if 16 - 16: OoooooooOO / oO0o + I1IiiI / O0
   if 12 - 12: ooOoO0o / I1IiiI % Oo0Ooo - II111iiii / i11iIiiIii
   if 33 - 33: o0oOOo0O0Ooo + IiII / OoOoOO00 / ooOoO0o
   if 9 - 9: OoOoOO00
   if 44 - 44: Oo0Ooo . i11iIiiIii % OOooOOo
   if 87 - 87: o0oOOo0O0Ooo
 if ( oO000oo0 != None and i1i . itr_rlocs != [ ] ) :
  oO0o0o00O = i1i . itr_rlocs [ 0 ]
 else :
  if ( deid . is_ipv4 ( ) ) :
   oO0o0o00O = ooOoOoOo
  elif ( deid . is_ipv6 ( ) ) :
   oO0o0o00O = OOOOO0
  else :
   oO0o0o00O = ooOoOoOo
   if 41 - 41: OoooooooOO . iII111i / oO0o
   if 16 - 16: iII111i + o0oOOo0O0Ooo / II111iiii * i11iIiiIii * OoO0O00 . iIii1I11I1II1
   if 34 - 34: I11i / o0oOOo0O0Ooo * OOooOOo * OOooOOo
   if 89 - 89: I1ii11iIi11i . OoooooooOO
   if 61 - 61: i1IIi + i11iIiiIii
   if 59 - 59: i11iIiiIii * OOooOOo + i1IIi * iIii1I11I1II1 + I11i
 o0o0ooOOo0oO = i1i . encode ( oO000oo0 , OOoO0ooo0ooo0 )
 i1i . print_map_request ( )
 if 97 - 97: OoO0O00 - I11i . OoooooooOO
 if 58 - 58: I1ii11iIi11i / II111iiii / i11iIiiIii
 if 27 - 27: iIii1I11I1II1 - O0 + OoOoOO00
 if 28 - 28: oO0o . IiII * iII111i % Oo0Ooo - OoO0O00 / I11i
 if 67 - 67: i11iIiiIii + i11iIiiIii / ooOoO0o - o0oOOo0O0Ooo
 if 94 - 94: O0 + OoO0O00 / I1IiiI * II111iiii * i11iIiiIii
 if ( oO000oo0 != None ) :
  if ( rloc . is_rloc_translated ( ) ) :
   I1OOoO0OoOOo0 = lisp_get_nat_info ( oO000oo0 , rloc . rloc_name )
   if 55 - 55: OoooooooOO * O0 + i1IIi % I1IiiI
   if 10 - 10: II111iiii - Ii1I . I11i . O0 + Ii1I
   if 50 - 50: iIii1I11I1II1 / Ii1I . ooOoO0o / ooOoO0o * OoOoOO00 * iII111i
   if 15 - 15: o0oOOo0O0Ooo % II111iiii + I1IiiI
   if ( I1OOoO0OoOOo0 == None ) :
    iiiI1I = rloc . rloc . print_address_no_iid ( )
    OoIi1I1I = "gleaned-{}" . format ( iiiI1I )
    IIIiIIi111 = rloc . translated_port
    I1OOoO0OoOOo0 = lisp_nat_info ( iiiI1I , OoIi1I1I , IIIiIIi111 )
    if 21 - 21: I1ii11iIi11i - ooOoO0o
   lisp_encapsulate_rloc_probe ( lisp_sockets , oO000oo0 , I1OOoO0OoOOo0 ,
 o0o0ooOOo0oO )
   return
   if 81 - 81: iII111i / i11iIiiIii / I1Ii111
   if 70 - 70: I1ii11iIi11i / i11iIiiIii
  O0O0 = oO000oo0 . print_address_no_iid ( )
  OO0oooOO = lisp_convert_4to6 ( O0O0 )
  lisp_send ( lisp_sockets , OO0oooOO , LISP_CTRL_PORT , o0o0ooOOo0oO )
  return
  if 90 - 90: II111iiii / OoOoOO00 . Ii1I . OoooooooOO
  if 76 - 76: OoooooooOO
  if 78 - 78: IiII % i11iIiiIii
  if 23 - 23: iIii1I11I1II1 - o0oOOo0O0Ooo - Ii1I % OOooOOo
  if 100 - 100: oO0o . OoO0O00 . i11iIiiIii % II111iiii * IiII
  if 81 - 81: OOooOOo - OOooOOo + OoOoOO00
 iiII11iI = None if lisp_i_am_rtr else seid
 if ( lisp_decent_pull_xtr_configured ( ) ) :
  oooO = lisp_get_decent_map_resolver ( deid )
 else :
  oooO = lisp_get_map_resolver ( None , iiII11iI )
  if 34 - 34: OoOoOO00 * o0oOOo0O0Ooo * i11iIiiIii - I11i % oO0o / OoO0O00
 if ( oooO == None ) :
  lprint ( "Cannot find Map-Resolver for source-EID {}" . format ( green ( seid . print_address ( ) , False ) ) )
  if 75 - 75: i1IIi / Ii1I * OoO0O00 - I1ii11iIi11i * O0 . IiII
  return
  if 11 - 11: I11i / Ii1I % oO0o
 oooO . last_used = lisp_get_timestamp ( )
 oooO . map_requests_sent += 1
 if ( oooO . last_nonce == 0 ) : oooO . last_nonce = i1i . nonce
 if 50 - 50: i11iIiiIii
 if 93 - 93: i1IIi / Ii1I * II111iiii - Oo0Ooo . OoOoOO00 - OOooOOo
 if 25 - 25: I11i / ooOoO0o % ooOoO0o - OOooOOo
 if 59 - 59: I1IiiI + o0oOOo0O0Ooo . iIii1I11I1II1 - O0 - i11iIiiIii
 if ( seid == None ) : seid = oO0o0o00O
 lisp_send_ecm ( lisp_sockets , o0o0ooOOo0oO , seid , lisp_ephem_port , deid ,
 oooO . map_resolver )
 if 4 - 4: I1IiiI
 if 36 - 36: Ii1I
 if 76 - 76: i11iIiiIii + i1IIi
 if 56 - 56: OoOoOO00 + II111iiii / i11iIiiIii * OoOoOO00 * OoooooooOO
 lisp_last_map_request_sent = lisp_get_timestamp ( )
 if 15 - 15: OoOoOO00 / OoooooooOO + OOooOOo
 if 76 - 76: Ii1I * iII111i . OoooooooOO
 if 92 - 92: iIii1I11I1II1 - Oo0Ooo - I1IiiI - OOooOOo * I1Ii111
 if 44 - 44: I1Ii111 - II111iiii / OOooOOo
 oooO . resolve_dns_name ( )
 return
 if 50 - 50: I11i / I1ii11iIi11i
 if 60 - 60: II111iiii / Ii1I + OoO0O00 % I1IiiI * i1IIi / II111iiii
 if 91 - 91: I1IiiI * I1Ii111 * i11iIiiIii - oO0o - IiII + I1ii11iIi11i
 if 99 - 99: OoO0O00 % o0oOOo0O0Ooo
 if 3 - 3: OOooOOo / OoOoOO00 % iIii1I11I1II1
 if 47 - 47: ooOoO0o . i11iIiiIii / OoO0O00
 if 48 - 48: O0
 if 89 - 89: i11iIiiIii % OoO0O00 . OoOoOO00 + Oo0Ooo + OoOoOO00
```


Overlapping Code:
```
lisp_send_map_request ( lisp_sockets , lisp_ephem_port , seid , deid , rloc ,
pubsub = False ) :
global lisp_last_map_request_sent
if 7 - 7: i1IIi . I1IiiI
if 68 - 68: OoooooooOO
if 91 - 91: IiII . ooOoO0o * I11i
if 39 - 39: o0oOOo0O0Ooo + i11iIiiIii
if 69 - 69: iIii1I11I1II1 . II111iiii
if 36 - 36: I1IiiI * i1IIi + OoOoOO00
oO000oo0 = OOoO0ooo0ooo0 = None
if ( rloc ) :
oO000oo0 = rloc . rloc
OOoO0ooo0ooo0 = rloc . translated_port if lisp_i_am_rtr else LISP_DATA_PORT
if 51 - 51: iIii1I11I1II1 % Ii1I + iIii1I11I1II1 + oO0o - IiII * o0oOOo0O0Ooo
if 13 - 13: iIii1I11I1II1
if 10 - 10: I1IiiI * iII111i * ooOoO0o . IiII
if 7 - 7: iIii1I11I1II1
if 60 - 60: OOooOOo . Ii1I . Ii1I % II111iiii + OoO0O00
ooOoOoOo , OOOOO0 , OoO = lisp_myrlocs
if ( ooOoOoOo == None ) :
lprint ( "Suppress sending Map-Request, IPv4 RLOC not found" )
return
if 49 - 49: I1IiiI . I1ii11iIi11i / Oo0Ooo
if ( OOOOO0 == None and oO000oo0 != None and oO000oo0 . is_ipv6 ( ) ) :
lprint ( "Suppress sending Map-Request, IPv6 RLOC not found" )
return
if 24 - 24: II111iiii
if 40 - 40: o0oOOo0O0Ooo . I1IiiI - o0oOOo0O0Ooo
i1i = lisp_map_request ( )
i1i . record_count = 1
i1i . nonce = lisp_get_control_nonce ( )
i1i . rloc_probe = ( oO000oo0 != None )
i1i . subscribe_bit = pubsub
i1i . xtr_id_present = pubsub
if 62 - 62: oO0o
if 71 - 71: i1IIi . I1ii11iIi11i / i11iIiiIii + II111iiii
if 14 - 14: iII111i
if 35 - 35: Ii1I
if 54 - 54: OOooOOo
if 83 - 83: i1IIi / II111iiii - I1IiiI + I1ii11iIi11i . IiII * oO0o
if 92 - 92: OoOoOO00 + oO0o % Ii1I / Ii1I - iII111i
if ( rloc ) : rloc . last_rloc_probe_nonce = i1i . nonce
if 11 - 11: Oo0Ooo % II111iiii * Ii1I + II111iiii
I1IIiIiIIiIiI = deid . is_multicast_address ( )
if ( I1IIiIiIIiIiI ) :
i1i . target_eid = seid
i1i . target_group = deid
else :
i1i . target_eid = deid
if 9 - 9: I1Ii111
if 69 - 69: i1IIi + ooOoO0o + Ii1I
if 88 - 88: OoOoOO00 + iII111i % O0 + OOooOOo / OoooooooOO / OOooOOo
if 95 - 95: ooOoO0o . Oo0Ooo % IiII + iII111i
if 16 - 16: I11i * OoO0O00 % o0oOOo0O0Ooo - O0 % II111iiii - I1IiiI
if 72 - 72: OoooooooOO * OoOoOO00 . OOooOOo + Ii1I . OOooOOo / II111iiii
if 8 - 8: i1IIi
if 1 - 1: OoOoOO00 . OoO0O00 . OoO0O00 * O0
if 97 - 97: OoooooooOO % ooOoO0o . I1Ii111 / iII111i
if ( i1i . rloc_probe == False ) :
oooOOoO0oo0 = lisp_get_signature_eid ( )
if ( oooOOoO0oo0 ) :
i1i . signature_eid . copy_address ( oooOOoO0oo0 . eid )
i1i . privke
```
<Overlap Ratio: 0.9904365904365905>

---

--- 149 --
Question ID: 8237e4a161d5e86e67c21247d893006918d78aa7_2
Original Code:
```
def test_log_info(caplog):
    # Arrange
    test_df = pd.DataFrame({
        'name': ['fault1', 'fault2'],
        'i1': [720, 305],
        'i2': [875, 342],
        'j1': [311, 32],
        'j2': [103, 800],
        'k1': [791, 847],
        'k2': [994, 494],
        'face': ['I+', 'I+']
    })

    # Act
    wf.write_faults_nexus('test', test_df)

    # Assert
    for record in caplog.records:
        assert record.levelname == "INFO"
    assert 'writing FNAME data in Nexus format to file: test' in caplog.text
```


Overlapping Code:
```
t_log_info(caplog):
# Arrange
test_df = pd.DataFrame({
'name': ['fault1', 'fault2'],
'i1': [720, 305],
'i2': [875, 342],
'j1': [311, 32],
'j2': [103, 800],
'k1': [791, 847],
'k2': [994, 494],
'face': ['I+', 'I+']
})
# Act
wf.write_faults_nexus('test', test_df)
# Assert
for record in caplog.records:
assert record.levelname == "INFO"
assert 'writing FNAME data in Nexus format to file: test' in caplo
```
<Overlap Ratio: 0.9685230024213075>

---

--- 150 --
Question ID: ae17e648fb3d9947d40e78d6b219151b1ed85fab_33
Original Code:
```
@app.callback(
	[Output('AlphasGraph', 'figure'),Output("AlphasAlphasDataSummary","children")],
	[Input('AlphasData','children')],
	[State('AlphasRawData','children'), State('AlphasDirect','children'), State("AlphasSigNum","value")],
	)
def update_graph(jsonified_dataAlphas, jsonified_data, AlphaDir, sig):	
	'''
    Update Alpha Raw graph

            Parameters:
                    jsonified_dataAlphas (json): Jsonified Alpha data 
					jsonified_data (json): Jsonified data
					AlphaDir (str): Alpha data directory
					sig (float): Error scaling factor

            Returns:
					Fig (dcc.Graph) : Figure element 
					JSON (json) : jsonified summary data for display
                    
    '''
	if jsonified_data not in [0,"0", None, "None"] and jsonified_dataAlphas not in [0,"0", None, "None"]:
		#Un json data
		data = pd.read_json(jsonified_data, orient='split')
		data.index = data.index.tz_localize(None)
		Data_i_Name = data.columns[0]
		# Statistics of interest
		WindowParameters = CalcStats.CalcStats(data[Data_i_Name])
		Alphasdf = pd.read_json(jsonified_dataAlphas, orient='split')
		Alphasdf.index = Alphasdf.index.tz_localize(None) 		
		Fig = DashPlots.CreateAlphasFig(Alphasdf, WindowParameters, sig, FigHeightPX/2, Data_i_Name)
	
		if SaveFigs == 1:
			XRange = [data.index[0],data.index[-1]]
			NameDate =  "_%s_%s" % (XRange[0].strftime("%d%m%Y"),XRange[1].strftime("%d%m%Y"))
			p1 = Process(target=Graphing.plotMATPLOTLIBAlpha, args=[data,Alphasdf,XRange,[None,None],"cachefiles"+os.sep+"Alpha",Data_i_Name+NameDate,True])
			p1.start()
			p1.join()

		return Fig, json.dumps(CalcStats.CalcAlphaStats(Alphasdf[Data_i_Name]))
	else:
		return DashPlots.EmptyFig(FigHeightPX/2), json.dumps(CalcStats.CalcAlphaStatsEmpty())
```


Overlapping Code:
```
Output("AlphasAlphasDataSummary","children")],
[Input('AlphasData','children')],
[State('AlphasRawData','children'), State('AlphasDirect','children'), State("AlphasSigNum","value")],
)
def update_graph(jsonified_dataAlphas, jsonified_data, AlphaDir, sig): 
'''
Update Alpha Raw graph
Parameters:
jsonified_dataAlphas (json): Jsonified Alpha data 
jsonified_data (json): Jsonified data
AlphaDir (str): Alpha data directory
sig (float): Error scaling factor
Returns:
Fig (dcc.Graph) : Figure element 
JSON (json) : jsonified summary data for display

'''
if jsonified_data not in [0,"0", None, "None"] and jsonified_dataAlphas not in [0,"0", None, "None"]:
#Un json data
data = pd.read_json(jsonified_data, orient='split')
data.index = data.index.tz_localize(None)
Data_i_Name = data.columns[0]
# Statistics of interest
WindowParameters = CalcStats.CalcStats(data[Data_i_Name])
Alphasdf = pd.read_json(jsonified_dataAlphas, orient='split')
Alphasdf.index = Alphasdf.index.tz_localize(None) 
Fig = DashPlots.CreateAlphasFig(Alphasdf, WindowParameters, sig, FigHeightPX/2, Data_i_Name)

if SaveFigs == 1:
XRange = [data.index[0],data.index[-1]]
NameDate = "_%s_%s" % (XRange[0].strftime("%d%m%Y"),XRange[1].strftime("%d%m%Y"))
p1 = Process(target=Graphing.plotMATPLOTLIBAlpha, args=[data,Alphasdf,XRange,[None,None],"cachefiles"+os.sep+"Alpha",Data_i_Name+NameDate,True])
p1.start()
p1.join()
return Fig, json.dumps(CalcStats.CalcAlphaStats(Alphasdf[Data_i_Name]))
else:
return DashPlots.EmptyFig(FigHeightPX/2), json.dumps(CalcStats.CalcAlphaStatsEmpty(
```
<Overlap Ratio: 0.96875>

---

--- 151 --
Question ID: 7fe0c12974fbed692742cf84672db6512533e42f_1
Original Code:
```
def to_a1_range(start_row_index: int, start_col_index: int, end_row_index: int, end_col_index: int) -> str:
    """\
    2 "A1:B2" 
    (end_row_index, end_col_index) 
    """
    return "{}:{}".format(to_a1_cell(start_row_index, start_col_index),
                          to_a1_cell(end_row_index, end_col_index))
```


Overlapping Code:
```
row_index: int, start_col_index: int, end_row_index: int, end_col_index: int) -> str:
"""\
2 "A1:B2" 
(end_row_index, end_col_index) 
"""
return "{}:{}".format(to_a1_cell(start_row_index, start_col_index
```
<Overlap Ratio: 0.7911392405063291>

---

--- 152 --
Question ID: bdda29eae654a32b64034abe00e31a7c5d9698a3_2
Original Code:
```
def main(root, target, part_two=False):
    """Orchestrate the BFS returning steps taken when target is reached."""
    prev = set()
    prev.add(root)

    to_process = collections.deque(possible_moves(root))
    [prev.add(node) for node in to_process]

    steps = 1

    while True:
        children = []
        while to_process:
            [children.append(child) for child in possible_moves(to_process.pop())
                if child not in prev]

        steps += 1

        for child in children:
            if child == target and not part_two:
                return steps

            prev.add(child)

        if part_two and steps == 50:
            return len(prev)

        to_process = collections.deque(children)
```


Overlapping Code:
```
chestrate the BFS returning steps taken when target is reached."""
prev = set()
prev.add(root)
to_process = collections.deque(possible_moves(root))
[prev.add(node) for node in to_process]
steps = 1
while True:
children = []
while to_process:
[children.append(child) for child in possible_moves(to_process.pop())
if child not in prev]
steps += 1
for child in children:
if child == target and not part_two:
return steps
prev.add(child)
if part_two and steps == 50:
return len(prev)
to_process = collect
```
<Overlap Ratio: 0.8849557522123894>

---

--- 153 --
Question ID: 45eecb320480f8f962379b706f6ae923faad9d9b_1
Original Code:
```
def make_positive(datalist):
    MIN = 1
    m = min(datalist)
    if m>=MIN:
        shift = 0
    else:
        shift = MIN-m
    shifted_data = [d+shift for d in datalist]
    return shift,shifted_data
```


Overlapping Code:
```
m = min(datalist)
if m>=MIN:
shift = 0
else:
shift = MIN-m
shifted_data = [d+shift for d in datalist
```
<Overlap Ratio: 0.6097560975609756>

---

--- 154 --
Question ID: b752c168ea08dcf89e18dfa775764df3a73f31cf_15
Original Code:
```
def update_inter_deployment_dependencies(sm):
    dependencies_list = sm.list(models.InterDeploymentDependencies)
    for dependency in dependencies_list:
        if (dependency.target_deployment_func and
                not dependency.external_target):
            _update_dependency_target_deployment(sm, dependency)
```


Overlapping Code:
```
r_deployment_dependencies(sm):
dependencies_list = sm.list(models.InterDeploymentDependencies)
for dependency in dependencies_list:
if (dependency.target_deployment_func and
not dependency.external_target):
_update_dependency_target_deployment(sm, de
```
<Overlap Ratio: 0.9124087591240876>

---

--- 155 --
Question ID: fbfd24dcc59d1c71738c36857773857b2f53912d_5
Original Code:
```
@pytest.mark.real_data
@pytest.mark.regression
def test_legacy_sample_qc_table(real_data_cache):
    comparison.assert_legacy_dev_sample_qc_equal(
        real_data_cache / "legacy_outputs/all_sample_qc.csv",
        real_data_cache / "dev_outputs/sample_level/sample_qc.csv",
    )
```


Overlapping Code:
```
est.mark.real_data
@pytest.mark.regression
def test_legacy_sample_qc_table(real_data_cache):
comparison.assert_legacy_dev_sample_qc_equal(
real_data_cache / "legacy_outputs/all_sample_qc.csv",
real_data_cache / "dev_outputs/sample_level/sample_q
```
<Overlap Ratio: 0.9496124031007752>

---

--- 156 --
Question ID: 2f05ce920449b8ef9c0cc2a907d37b060f0acb6d_1
Original Code:
```
def get_score(fname):
    print(f'start processing {fname}', flush=True)
    offset, size, nk = parse_retrieve_fname(fname)
    print(f'offset: {offset}, size{size}, k{nk}', flush=True)
    scores = np.zeros(args.dstore_size, dtype=np.float32)

    ret = np.memmap(os.path.join(args.retrieval_dir, fname), dtype=np.int32, mode='r', shape=(size, nk))

    # import pdb; pdb.set_trace()
    for i, row in enumerate(ret):
        if i % 100000 == 0:
            print(f'processing {i} rows', flush=True)
            # break
        scores[row] = scores[row] + 1. / (np.arange(len(row)) + 1)
        # if i == 50000:
        #     break

    return scores
```


Overlapping Code:
```
ame):
print(f'start processing {fname}', flush=True)
offset, size, nk = parse_retrieve_fname(fname)
print(f'offset: {offset}, size{size}, k{nk}', flush=True)
scores = np.zeros(args.dstore_size, dtype=np.float32)
ret = np.memmap(os.path.join(args.retrieval_dir, fname), dtype=np.int32, mode='r', shape=(size, nk))
# import pdb; pdb.set_trace()
for i, row in enumerate(ret):
if i % 100000 == 0:
print(f'processing {i} rows', flush=True)
# break
scores[row] = scores[row] + 1. / (np.arange(len(row)) + 1
```
<Overlap Ratio: 0.8992805755395683>

---

--- 157 --
Question ID: efd9f141956a681544d2a8c593883fc80424006a_19
Original Code:
```
async def test_connect_error_second_attempt(hostname, unused_tcp_port):
    client = SMTP(hostname=hostname, port=unused_tcp_port, timeout=1.0)

    with pytest.raises(SMTPConnectError):
        await client.connect()

    with pytest.raises(SMTPConnectError):
        await client.connect()
```


Overlapping Code:
```
ond_attempt(hostname, unused_tcp_port):
client = SMTP(hostname=hostname, port=unused_tcp_port, timeout=1.0)
with pytest.raises(SMTPConnectError):
await client.connect()
with pytest.raises(SMTPConnectE
```
<Overlap Ratio: 0.7662835249042146>

---

--- 158 --
Question ID: ba9a89a20a5246b3dd730505a5077464e9b4eaae_2
Original Code:
```
def save_all_datasets(args):
    # logger.info('*' * 100)
    # logger.info('Pre-training dataset')
    # _ = init_dataset(args=args,
    #                  mode=enums.TRAINING_MODE_PRE_TRAIN,
    #                  load_if_saved=False)
    # summarization
    for lang in [enums.LANG_JAVA, enums.LANG_GO, enums.LANG_PHP, enums.LANG_PYTHON, enums.LANG_RUBY,
                 enums.LANG_JAVASCRIPT]:
        for split in ['train', 'valid', 'test']:
            logger.info('*' * 100)
            logger.info(f'Summarization - {lang} - {split}')
            _ = init_dataset(args=args,
                             mode=enums.TRAINING_MODE_FINE_TUNE,
                             task=enums.TASK_SUMMARIZATION,
                             language=lang,
                             split=split,
                             load_if_saved=False)
```


Overlapping Code:
```
 save_all_datasets(args):
# logger.info('*' * 100)
# logger.info('Pre-training dataset')
# _ = init_dataset(args=args,
# mode=enums.TRAINING_MODE_PRE_TRAIN,
# load_if_saved=False)
# summarization
for lang in [enums.LANG_JAVA, enums.LANG_GO, enums.LANG_PHP, enums.LANG_PYTHON, enums.LANG_RUBY,
enums.LANG_JAVASCRIPT]:
for split in ['train', 'valid', 'test']:
logger.info('*' * 100)
logger.info(f'Summarization - {lang} - {split}')
_ = init_dataset(args=args,
mode=enums.TRAINING_MODE_FINE_TUNE,
task=enums.TASK_SUMMARIZATION,
language=lang,
split=spli
```
<Overlap Ratio: 0.9548611111111112>

---

--- 159 --
Question ID: 85adfc253bb4c960061f784c6672a7d58767047a_1
Original Code:
```
@login_required
@permission_required('students.delete_student', raise_exception=True)
def debug_delete_students(request: HttpRequest):
    Student.objects.all().delete()
    return redirect("core:debug")
```


Overlapping Code:
```
required
@permission_required('students.delete_student', raise_exception=True)
def debug_delete_students(request: HttpRequest):
Student.objects.all().
```
<Overlap Ratio: 0.7692307692307693>

---

--- 160 --
Question ID: d27a7cd8fb1a33aefe639f54dcde93489cfbe955_3
Original Code:
```
def import_stock_daily():
    w = WindRest(WIND_REST_URL)
    engine = get_db_engine()
    with get_db_session(engine) as session:
        # 
        sql_str = 'select wind_code, max(Trade_date) from wind_stock_daily group by wind_code'
        table = session.execute(sql_str)
        stock_trade_date_latest_dic = dict(table.fetchall())
        # 
        sql_str = "select trade_date from wind_trade_date where trade_date > '2005-1-1'"
        table = session.execute(sql_str)
        trade_date_sorted_list = [t[0] for t in table.fetchall()]
        trade_date_sorted_list.sort()
        # 
        table = session.execute('SELECT wind_code, ipo_date, delist_date FROM wind_stock_info')
        stock_date_dic = {wind_code: (ipo_date, delist_date if delist_date is None or delist_date > UN_AVAILABLE_DATE else None) for
                          wind_code, ipo_date, delist_date in table.fetchall()}
    today_t_1 = date.today() - ONE_DAY
    data_df_list = []

    try:
        for wind_code, date_pair in stock_date_dic.items():
            date_ipo, date_delist = date_pair
            #  date_from
            if wind_code in stock_trade_date_latest_dic:
                date_latest_t1 = stock_trade_date_latest_dic[wind_code] + ONE_DAY
                date_from = max([date_latest_t1, DATE_BASE, date_ipo])
            else:
                date_from = max([DATE_BASE, date_ipo])
            date_from = get_first(trade_date_sorted_list, lambda x: x >= date_from)
            #  date_to
            if date_delist is None:
                date_to = today_t_1
            else:
                date_to = min([date_delist, today_t_1])
            date_to = get_last(trade_date_sorted_list, lambda x: x <= date_to)
            if date_from is None or date_to is None or date_from > date_to:
                continue
            # 
            wind_indictor_str = "open,high,low,close,adjfactor,volume,amt,pct_chg,maxupordown," + \
                                "swing,turn,free_turn,trade_status,susp_days"
            data_df = w.wsd(wind_code, wind_indictor_str, date_from, date_to)
            if data_df is None:
                logging.warning('%s has no data during %s %s', wind_code, date_from, date_to)
                continue
            logging.info('%d data of %s', data_df.shape[0], wind_code)
            data_df['wind_code'] = wind_code
            data_df_list.append(data_df)
    finally:
        # 
        if len(data_df_list) > 0:
            data_df_all = pd.concat(data_df_list)
            data_df_all.index.rename('trade_date', inplace=True)
            data_df_all.reset_index(inplace=True)
            data_df_all.set_index(['wind_code', 'trade_date'], inplace=True)
            data_df_all.to_sql('wind_stock_daily', engine, if_exists='append',
                               dtype={
                                   'wind_code': String(20),
                                   'trade_date': Date,
                                   'open': Float,
                                   'high': Float,
                                   'low': Float,
                                   'close': Float,
                                   'adjfactor': Float,
                                   'volume': Float,
                                   'amt': Float,
                                   'pct_chg': Float,
                                   'maxupordown': Integer,
                                   'swing': Float,
                                   'turn': Float,
                                   'free_turn': Float,
                                   'trade_status': String(20),
                                   'susp_days': Integer,
                               }
                               )
            logging.info('%d data imported', data_df_all.shape[0])
```


Overlapping Code:
```
k_daily():
w = WindRest(WIND_REST_URL)
engine = get_db_engine()
with get_db_session(engine) as session:
# 
sql_str = 'select wind_code, max(Trade_date) from wind_stock_daily group by wind_code'
table = session.execute(sql_str)
stock_trade_date_latest_dic = dict(table.fetchall())
# 
sql_str = "select trade_date from wind_trade_date where trade_date > '2005-1-1'"
table = session.execute(sql_str)
trade_date_sorted_list = [t[0] for t in table.fetchall()]
trade_date_sorted_list.sort()
# 
table = session.execute('SELECT wind_code, ipo_date, delist_date FROM wind_stock_info')
stock_date_dic = {wind_code: (ipo_date, delist_date if delist_date is None or delist_date > UN_AVAILABLE_DATE else None) for
wind_code, ipo_date, delist_date in table.fetchall()}
today_t_1 = date.today() - ONE_DAY
data_df_list = []
try:
for wind_code, date_pair in stock_date_dic.items():
date_ipo, date_delist = date_pair
#  date_from
if wind_code in stock_trade_date_latest_dic:
date_latest_t1 = stock_trade_date_latest_dic[wind_code] + ONE_DAY
date_from = max([date_latest_t1, DATE_BASE, date_ipo])
else:
date_from = max([DATE_BASE, date_ipo])
date_from = get_first(trade_date_sorted_list, lambda x: x >= date_from)
#  date_to
if date_delist is None:
date_to = today_t_1
else:
date_to = min([date_delist, today_t_1])
date_to = get_last(trade_date_sorted_list, lambda x: x <= date_to)
if date_from is None or date_to is None or date_from > date_to:
continue
# 
wind_indictor_str = "open,high,low,close,adjfactor,volume,amt,pct_chg,maxupordown," + \
"swing,turn,free_turn,trade_status,susp_days"
data_df = w.wsd(wind_code, wind_indictor_str, date_from, date_to)
if data_df is None:
logging.warning('%s has no data during %s %s', wind_code, date_from, date_to)
continue
logging.info('%d data of %s', data_df.shape[0], wind_code)
data_df['wind_code'] = wind_code
data_df_list.append(data_df
```
<Overlap Ratio: 0.9790816326530613>

---

--- 161 --
Question ID: 0701be6728fd240c75a3fa2b0538b52e286bb1f8_0
Original Code:
```
def stripes(num_images_per_class=100, img_shape=(16, 16), num_classes=4,
            class_type=('vertical', 'horizontal', 'main_diagonal', 'off_diagonal')):

    if num_classes > 4 or num_classes < 2:
        raise ValueError('stripes data has minimum of 2 classes and maximum of 4 classes')

    data = np.zeros([*img_shape, num_classes * num_images_per_class])

    for i in range(num_images_per_class):

        for j in range(num_classes):
            if class_type[j] == 'vertical':
                data[:, :, i + j * num_images_per_class] = np.kron(np.ones([img_shape[0], 1]), randn(1, img_shape[1]))

            elif class_type[j] == 'horizontal':
                data[:, :, i + j * num_images_per_class] = np.kron(np.ones([1, img_shape[0]]), randn(img_shape[1], 1))

            elif class_type[j] == 'main_diagonal':
                # diagonal (top left to bottom right)
                data[:, :, i + j * num_images_per_class] = toeplitz(randn(img_shape[0]), randn(img_shape[1]))

            elif class_type[j] == 'off_diagonal':
                # diagonal (top right to bottom left)
                data[:, :, i + j * num_images_per_class] = np.rot90(toeplitz(randn(img_shape[0]), randn(img_shape[1])),
                                                                    1)

    data = rescale(data)
    labels = np.kron(np.arange(num_classes), np.ones([num_images_per_class]))

    return data, labels
```


Overlapping Code:
```
e=(16, 16), num_classes=4,
class_type=('vertical', 'horizontal', 'main_diagonal', 'off_diagonal')):
if num_classes > 4 or num_classes < 2:
raise ValueError('stripes data has minimum of 2 classes and maximum of 4 classes')
data = np.zeros([*img_shape, num_classes * num_images_per_class])
for i in range(num_images_per_class):
for j in range(num_classes):
if class_type[j] == 'vertical':
data[:, :, i + j * num_images_per_class] = np.kron(np.ones([img_shape[0], 1]), randn(1, img_shape[1]))
elif class_type[j] == 'horizontal':
data[:, :, i + j * num_images_per_class] = np.kron(np.ones([1, img_shape[0]]), randn(img_shape[1], 1))
elif class_type[j] == 'main_diagonal':
# diagonal (top left to bottom right)
data[:, :, i + j * num_images_per_class] = toeplitz(randn(img_shape[0]), randn(img_shape[1]))
elif class_type[j] == 'off_diagonal':
# diagonal (top right to bottom left)
data[:, :, i + j * num_images_per_class] = np.rot90(toeplitz(randn(img_shape[0]), randn(img_shape[1])),
1)
data = rescale(data)
labels = np.kron(np.arange(num_classes), np.on
```
<Overlap Ratio: 0.9186351706036745>

---

--- 162 --
Question ID: bdc9a66b8f4282a6afe68d2be2e3f041955203ab_1
Original Code:
```
def test_pupfile():
    with http_server(directory=CWD):
        # with nullcontext():
        url = "http://localhost:38080/ps3updat-cex-3.55.pup"
        fh = HTTPFile(url)
        # pup_path = importlib.resources.files(__package__) / "ps3updat-cex-3.55.pup"
        # fh = open(pup_path, 'rb')
        pupf = PUPFile(fh)
        pupf.rootfs.dump()
```


Overlapping Code:
```
(directory=CWD):
# with nullcontext():
url = "http://localhost:38080/ps3updat-cex-3.55.pup"
fh = HTTPFile(url)
# pup_path = importlib.resources.files(__package__) / "ps3updat-cex-3.55.pup"
# fh = open(pup_path, 'rb')
pupf = PUPFile(fh)
pupf.rootfs.du
```
<Overlap Ratio: 0.8620689655172413>

---

--- 163 --
Question ID: 20395cd788c5cd7b10e4f9c757c29fb21de0c88c_0
Original Code:
```
def extract_all_links(site):
    html = requests.get(site).text
    soup = BeautifulSoup(html, "html.parser").find_all("a")
    links = [link.get("href") for link in soup]
    return links
```


Overlapping Code:
```
extract_all_links(site):
html = requests.get(site).text
soup = BeautifulSoup(html, "html.parser").find_all("a")
links = [link.get("href") for link in 
```
<Overlap Ratio: 0.872093023255814>

---

--- 164 --
Question ID: e0f87cbc7956af9fc25348670e5b24203e4404ca_31
Original Code:
```
@Ghost.command(name="help", description="The help command.", usage="help (command)", aliases=["cmds", "commands"])
async def help(ctx, *, command = None):
    totalcmds = len(Ghost.commands)-len(scriptsList)
    if command is None:
        if __embedmode__:
            embed = discord.Embed(title=f"{__embedemoji__} **{__embedtitle__}** {__embedemoji__}", color=__embedcolour__, description=f"""
Arguments in `[]` are required, arguments in `()` are optional.

`{Ghost.command_prefix}`**text (page 1/2)**  Text commands.
`{Ghost.command_prefix}`**fun (page 1)**  Fun commands.
`{Ghost.command_prefix}`**image (page 1)**  Image commands.
`{Ghost.command_prefix}`**moderation (page 1)**  Moderation commands.
`{Ghost.command_prefix}`**info (page 1)**  Info commands.
`{Ghost.command_prefix}`**user (page 1)**  User commands.
`{Ghost.command_prefix}`**selfbot (page 1)**  Selfbot commands.
`{Ghost.command_prefix}`**webhook (page 1)**  Webhook commands.
`{Ghost.command_prefix}`**abuse (page 1)**  Abuse commands.
`{Ghost.command_prefix}`**themes (page 1)**  Theme commands.
`{Ghost.command_prefix}`**giveaway (page 1)**  Giveaway commands.
`{Ghost.command_prefix}`**nsfw (page 1)**  NSFW commands.
`{Ghost.command_prefix}`**proxy (page 1)**  Proxy commands.
`{Ghost.command_prefix}`**tools (page 1)**  Discord and other tools.
`{Ghost.command_prefix}`**customcommands**  Your custom commands.
`{Ghost.command_prefix}`**customscripts**  Your scripts.

`{Ghost.command_prefix}`**search [term]**  Search for a command.
`{Ghost.command_prefix}`**help (command)**  Help for a specific command.

There is a total of `{totalcmds}` commands.
        """)
            embed.set_author(name="All Commands")
            embed.set_image(url=__embedlargeimage__)
            embed.set_thumbnail(url=__embedimage__)
            embed.set_footer(text=__embedfooter__, icon_url=__embedfooterimage__)
            embed.timestamp = datetime.now()
            await ctx.send(embed=embed, delete_after=__deletetimeout__)
        else:
            await ctx.send(f"""```ini
[ {__embedtitle__} ]

Arguments in [] are required, arguments in () are optional.

{Ghost.command_prefix}text (page 1/2)  Text commands.
{Ghost.command_prefix}fun (page 1)  Fun commands.
{Ghost.command_prefix}image (page 1)  Image commands.
{Ghost.command_prefix}moderation (page 1)  Moderation commands.
{Ghost.command_prefix}info (page 1)  Info commands.
{Ghost.command_prefix}user (page 1)  User commands.
{Ghost.command_prefix}selfbot (page 1)  Selfbot commands.
{Ghost.command_prefix}webhook (page 1)  Webhook commands.
{Ghost.command_prefix}abuse (page 1)  Abuse commands.
{Ghost.command_prefix}themes (page 1)  Theme commands.
{Ghost.command_prefix}giveaway (page 1)  Giveaway commands.
{Ghost.command_prefix}nsfw (page 1)  NSFW commands.
{Ghost.command_prefix}proxy (page 1)  Proxy commands.
{Ghost.command_prefix}tools (page 1)  Discord and other tools.
{Ghost.command_prefix}customcommands  Your custom commands.
{Ghost.command_prefix}customscripts  Your scripts.

{Ghost.command_prefix}search [term]  Search for a command.
{Ghost.command_prefix}help (command)  Help for a specific command.

There is a total of {totalcmds} commands.

# {__embedfooter__}```""", delete_after=__deletetimeout__)

    else:
        for cmd in Ghost.commands:
            if command == cmd.name or command in cmd.aliases:
                if not cmd.aliases:
                    cmd.aliases.append("No aliases")
                if __embedmode__:
                    embed = discord.Embed(title=f"{cmd.name}", color=__embedcolour__)
                    embed.add_field(name="Usage", value=f"{cmd.usage}", inline=False)
                    embed.add_field(name="Description", value=f"{cmd.description}", inline=False)
                    embed.add_field(name="Aliases", value=', '.join(cmd.aliases))
                    embed.set_thumbnail(url=__embedimage__)
                    embed.set_image(url=__embedlargeimage__)
                    embed.set_footer(text=__embedfooter__, icon_url=__embedfooterimage__)
                    embed.timestamp = datetime.now()
                    await ctx.send(embed=embed, delete_after=__deletetimeout__)
                else:
                    await ctx.send(f"""```ini
[ {cmd.name} ]

Usage: {cmd.usage}
Description: {cmd.description}


# {__embedfooter__}```""", delete_after=__deletetimeout__)

```


Overlapping Code:
```
estamp = datetime.now()
await ctx.send(embed=embed
```
<Overlap Ratio: 0.021132713440405747>

---

--- 165 --
Question ID: 954dab58aee4ed757042fcd517d36b4da488ef9a_3
Original Code:
```
def placebo_plot(g,placebo_groups,diff_data_0):
    """
    Generates Figure 8: Observed treatment effect for Apulia and Basilicata and placebo units
    """
    
    diff_list = []
    diff_list = Parallel(n_jobs=-1)(delayed(g)(pair) for pair in placebo_groups)

    # Auxiliary
    fig, axes = plt.subplots(1, 2,figsize=(13,4))
    ax1 = axes[0]
    ax2 = axes[1]
    year = diff_data_0.index.values

    for i in range(len(diff_list)):

        ax1.plot(diff_list[i]['GDP Gap'],color='gray',label = 'Placebos' if i == 1 else "")
        ax2.plot(diff_list[i]['Murder Gap'],color='gray',label = 'Placebos' if i == 1 else "")


    ax1.plot(diff_data_0['GDP Gap'],color='black',label = 'Treated Region')
    ax2.plot(diff_data_0['Murder Gap'],color='black',label = 'Treated Region')

    ax1.set_xlabel('Year')
    ax1.set_ylabel('GDP per capita, % Gap')
    ax1.tick_params(axis='y')
    ax1.set_ylim(-30,30)    
    ax1.title.set_text('Fig 8(a) GDP per capita')
    ax1.axhline(0)

    ax1.set_xlabel('Year')
    ax2.set_ylabel('Murder Rate, Difference')
    ax2.tick_params(axis='y')
    ax2.set_ylim(-4,4)
    ax2.title.set_text('Fig 8(b) Murder Rate')
    ax2.axhline(0)

    ax1.axvspan(1975, 1980, color='y', alpha=0.5, lw=0,label='Mafia Outbreak')
    ax2.axvspan(1975, 1980, color='y', alpha=0.5, lw=0,label='Mafia Outbreak')

    ax1.legend(loc = 'upper center', bbox_to_anchor = (0.5, -0.22), shadow = True, ncol = 2)
    ax2.legend(loc = 'upper center', bbox_to_anchor = (0.5, -0.22), shadow = True, ncol = 2)

    plt.show()
```


Overlapping Code:
```
):
"""
Generates Figure 8: Observed treatment effect for Apulia and Basilicata and placebo units
"""

diff_list = []
diff_list = Parallel(n_jobs=-1)(delayed(g)(pair) for pair in placebo_groups)
# Auxiliary
fig, axes = plt.subplots(1, 2,figsize=(13,4))
ax1 = axes[0]
ax2 = axes[1]
year = diff_data_0.index.values
for i in range(len(diff_list)):
ax1.plot(diff_list[i]['GDP Gap'],color='gray',label = 'Placebos' if i == 1 else "")
ax2.plot(diff_list[i]['Murder Gap'],color='gray',label = 'Placebos' if i == 1 else "")
ax1.plot(diff_data_0['GDP Gap'],color='black',label = 'Treated Region')
ax2.plot(diff_data_0['Murder Gap'],color='black',label = 'Treated Region')
ax1.set_xlabel('Year')
ax1.set_ylabel('GDP per capita, % Gap')
ax1.tick_params(axis='y')
ax1.set_ylim(-30,30) 
ax1.title.set_text('Fig 8(a) GDP per capita')
ax1.axhline(0)
ax1.set_xlabel('Year')
ax2.set_ylabel('Murder Rate, Difference')
ax2.tick_params(axis='y')
ax2.set_ylim(-4,4)
ax2.title.set_text('Fig 8(b) Murder Rate')
ax2.axhline(0)
ax1.axvspan(1975, 1980, color='y', alpha=0.5, lw=0,label='Mafia Outbreak')
ax2.axvspan(1975, 1980, color='y', alpha=0.5, lw=0,label='Mafia Outbreak')
ax1.legend(loc = 'upper center', bbox_to_anchor = (0.5, -0.22), shadow = True, ncol = 2)
ax2.legend(loc = 'upper center', bbox_to_anchor = (0.5, -0.22), shadow = True, ncol =
```
<Overlap Ratio: 0.9574007220216606>

---

--- 166 --
Question ID: 4c7b73d5f42124d0da837b2071791b3974ff48c0_0
Original Code:
```
@pytest.mark.parametrize(
    'status',
    [
        'released',
        'in progress',
        'deleted',
    ]
)
def test_analysis_step_run_valid_statuses(status, testapp, analysis_step_run):
    testapp.patch_json(analysis_step_run['@id'], {'status': status})
    res = testapp.get(analysis_step_run['@id'] + '@@embedded').json
    assert res['status'] == status
```


Overlapping Code:
```
ark.parametrize(
'status',
[
'released',
'in progress',
'deleted',
]
)
def test_analysis_step_run_valid_statuses(status, testapp, analysis_step_run):
testapp.patch_json(analysis_step_run['@id'], {'status': status})
res = testapp.get(analysis_step_run['@id'] + '@@embedded').json
assert res['status'] ==
```
<Overlap Ratio: 0.949685534591195>

---

--- 167 --
Question ID: 870830ac6d3ca665607fc2adaf7f3480b48a6334_2
Original Code:
```
def hash_to_point(*data):
	result = ''
	for datum in data:
		if datum is None:
			raise TypeError
		result += blake2s(str(datum).encode('utf-8')).hexdigest()

	# Continue hashing until we get a valid Point
	while True:
		result = blake2s(result.encode('utf-8')).hexdigest()
		if make_point(int(result,16)) is not None:
			return make_point(int(result,16))*Scalar(cofactor)
```


Overlapping Code:
```
def hash_to_point(*data):
result = ''
for datum in data:
if datum is None:
raise TypeError
result += blake2s(str(datum).encode('utf-8')).hexdigest()
# Continue hashing until we get a valid Point
while True:
result = blake2s(result.encode('utf-8')).hexdigest()
if make_point(int(result,16)) is not None:
return make_point(int(result,16))*Scalar(cofact
```
<Overlap Ratio: 0.9915014164305949>

---

--- 168 --
Question ID: b29bc073733fd123dee5e41aad50f80c19be76ea_9
Original Code:
```
def get_base_renderers(dataset_name: str,
                       label: str = 'color',
                       property_label: str = 'shape'
                       ) -> ml_collections.ConfigDict:
  """Get base config for the given dataset, label and property value."""
  data = get_data_config(dataset_name, label, property_label)
  data.train_kwargs.load_kwargs.filter_fns = 'True'
  data.train_kwargs.load_kwargs.num_samples = '0'
  data.train_kwargs.load_kwargs.weights = [1.]
  return data
```


Overlapping Code:
```
derers(dataset_name: str,
label: str = 'color',
property_label: str = 'shape'
) -> ml_collections.ConfigDict:
"""Get base config for the given dataset, label and property value."""
data = get_data_config(dataset_name, label, property_label)
data.train_kwargs.load_kwargs.filter_fns = 'True'
data.train_kwargs.load_kwargs.num_samples = '0'
data.train_kwargs.load
```
<Overlap Ratio: 0.878345498783455>

---

--- 169 --
Question ID: b6134939f533fdcb5ebdd86fc6456217d08305b0_2
Original Code:
```
@connection_status
@bot_admin
@user_admin
@loggable
def unmute(update: Update, context: CallbackContext) -> str:
    bot, args = context.bot, context.args
    chat = update.effective_chat
    user = update.effective_user
    message = update.effective_message

    user_id, reason = extract_user_and_text(message, args)
    if not user_id:
        message.reply_text(
            "You'll need to either give me a username to unmute, or reply to someone to be unmuted."
        )
        return ""

    member = chat.get_member(int(user_id))

    if member.status in ("kicked", "left"):
        message.reply_text(
            "This user isn't even in the chat, unmuting them won't make them talk more than they "
            "already do!",
        )

    elif (
        member.can_send_messages
        and member.can_send_media_messages
        and member.can_send_other_messages
        and member.can_add_web_page_previews
    ):
        message.reply_text("This user already has the right to speak.")
    else:
        chat_permissions = ChatPermissions(
            can_send_messages=True,
            can_invite_users=True,
            can_pin_messages=True,
            can_send_polls=True,
            can_change_info=True,
            can_send_media_messages=True,
            can_send_other_messages=True,
            can_add_web_page_previews=True,
        )
        try:
            bot.restrict_chat_member(chat.id, int(user_id), chat_permissions)
        except BadRequest:
            pass
        bot.sendMessage(
            chat.id,
            "{} [<code>{}</code>] Was Unmuted.".format(
                mention_html(member.user.id, member.user.first_name), member.user.id
            ),
            parse_mode=ParseMode.HTML,
        )
        return (
            f"<b>{html.escape(chat.title)}:</b>\n"
            f"#UNMUTE\n"
            f"<b>Admin:</b> {mention_html(user.id, user.first_name)}\n"
            f"<b>User:</b> {mention_html(member.user.id, member.user.first_name)}"
        )
    return ""
```


Overlapping Code:
```
connection_status
@bot_admin
@user_admin
@loggable
def unmute(update: Update, context: CallbackContext) -> str:
bot, args = context.bot, context.args
chat = update.effective_chat
user = update.effective_user
message = update.effective_message
user_id, reason = extract_user_and_text(message, args)
if not user_id:
message.reply_text(
"You'll need to either give me a username to unmute, or reply to someone to be unmuted."
)
return ""
member = chat.get_member(int(user_id))
if member.status in ("kicked", "left"):
message.reply_text(
"This user isn't even in the chat, unmuting them won't make them talk more than they "
"already do!",
)
elif (
member.can_send_messages
and member.can_send_media_messages
and member.can_send_other_messages
and member.can_add_web_page_previews
):
message.reply_text("This user already has the right to speak.")
else:
chat_permissions = ChatPermissions(
can_send_messages=True,
can_invite_users=True,
can_pin_messages=True,
can_send_polls=True,
can_change_info=True,
can_send_media_messages=True,
can_send_other_messages=True,
can_add_web_page_previews=True,
)
try:
bot.restrict_chat_member(chat.id, int(user_id), chat_permissions)
except BadRequest:
pass
bot.sendMessage(
chat.id,
"{} [<code>{}</code>] Was Unmuted.".format(
mention_html(member.user.id, member.user.first_name), member.user.id
),
parse_mode=ParseMode.HTML,
)
return (
f"<b>{html.escape(chat.title)}:</b>\n"
f"#UNMUTE\n"
f"<b>Admin:</b> {mention_html(user.id, user.first_name)}\n"
f"<b>User:</b> {mention_html(member.user.id, member.user.first_name)}"

```
<Overlap Ratio: 0.9923224568138196>

---

--- 170 --
Question ID: 40e73ecf9cce1253294d0ab103fc9130c0e9b2fc_1
Original Code:
```
def plant(q, dq, u, f_ext, prior=prior):
    """TODO: docstring."""
    H, C, g, B = prior(q, dq)
    ddq = jax.scipy.linalg.solve(H, f_ext + B@u - C@dq - g, sym_pos=True)
    return ddq
```


Overlapping Code:
```
:
"""TODO: docstring."""
H, C, g, B = prior(q, dq)
ddq = jax.scipy.linalg.solve(H, f_ext + B@u - C@d
```
<Overlap Ratio: 0.5882352941176471>

---

--- 171 --
Question ID: 2299be24ed211bc0d95a878bff661c9590388b84_8
Original Code:
```
def longest_match_size(str1, str2):
    sq = SequenceMatcher(lambda x: x == " ", str1, str2)
    match = sq.find_longest_match(0, len(str1), 0, len(str2))
    return match.size
```


Overlapping Code:
```
size(str1, str2):
sq = SequenceMatcher(lambda x: x == " ", str1, str2)
match = sq.find_longest_match(0, len(str1), 0, len(str2))
return match.size
```
<Overlap Ratio: 0.8902439024390244>

---

--- 172 --
Question ID: 324ac65784fbe6385a130a28d05fe4f86fa50f06_72
Original Code:
```
def test_ode_coupled_mNone_generator():
    # coupled equations
    m = None
    k = np.array([0.0, 6.0e5, 6.0e5, 6.0e5])  # diagonal of stiffness
    zeta = np.array([0.0, 0.05, 1.0, 2.0])  # percent damping
    b = 2.0 * zeta * np.sqrt(k)  # diagonal of damping
    k = np.diag(k)
    b = np.diag(b)

    k[1:, 1:] += np.random.randn(3, 3) * 1000
    b[1:, 1:] += np.random.randn(3, 3)

    h = 0.001  # time step
    t = np.arange(0, 0.3001, h)  # time vector
    c = 2 * np.pi
    f = (
        np.vstack(
            (
                3 * (1 - np.cos(c * 2 * t)),  # forcing function
                4 * (np.cos(np.sqrt(6e5 / 30) * t)),
                5 * (np.cos(np.sqrt(6e5 / 30) * t)),
                6 * (np.cos(np.sqrt(6e5 / 30) * t)),
            )
        )
        * 1.0e4
    )

    for order in (0, 1):
        for rf in (None, 3, np.array([1, 2, 3])):
            for static_ic in (0, 1):
                # su
                tsu = ode.SolveUnc(m, b, k, h, order=order, rf=rf)
                solu = tsu.tsolve(f, static_ic=static_ic)

                nt = f.shape[1]
                gen, d, v = tsu.generator(nt, f[:, 0], static_ic=static_ic)
                for i in range(1, nt):
                    gen.send((i, f[:, i]))
                solu2 = tsu.finalize()

                tsu0 = ode.SolveUnc(m, b, k, h=None, order=order, rf=rf)
                solu0 = tsu0.tsolve(f[:, :1], static_ic=static_ic)
                gen, d, v = tsu0.generator(1, f[:, 0], static_ic=static_ic)
                solu20 = tsu0.finalize()

                assert np.allclose(solu2.a, solu.a)
                assert np.allclose(solu2.v, solu.v)
                assert np.allclose(solu2.d, solu.d)

                assert np.allclose(solu0.a, solu.a[:, :1])
                assert np.allclose(solu0.v, solu.v[:, :1])
                assert np.allclose(solu0.d, solu.d[:, :1])

                assert np.allclose(solu20.a, solu2.a[:, :1])
                assert np.allclose(solu20.v, solu2.v[:, :1])
                assert np.allclose(solu20.d, solu2.d[:, :1])

                # test the generator solver w/ partial update:
                nt = f.shape[1]
                gen, d, v = tsu.generator(nt, f[:, 0], static_ic=static_ic)
                for i in range(1, nt):
                    fi = f[:, i] / 2
                    gen.send((i, fi))
                    gen.send((-1, fi))
                solu2 = tsu.finalize()

                assert np.allclose(solu2.a, solu.a)
                assert np.allclose(solu2.v, solu.v)
                assert np.allclose(solu2.d, solu.d)

                # se
                tse = ode.SolveExp2(m, b, k, h, order=order, rf=rf)
                sole = tse.tsolve(f, static_ic=static_ic)

                nt = f.shape[1]
                gen, d, v = tse.generator(nt, f[:, 0], static_ic=static_ic)
                for i in range(1, nt):
                    gen.send((i, f[:, i]))
                sole2 = tse.finalize()

                tse0 = ode.SolveExp2(m, b, k, h=None, order=order, rf=rf)
                sole0 = tse0.tsolve(f[:, :1], static_ic=static_ic)
                gen, d, v = tse0.generator(1, f[:, 0], static_ic=static_ic)
                sole20 = tse0.finalize()

                assert np.allclose(sole2.a, sole.a)
                assert np.allclose(sole2.v, sole.v)
                assert np.allclose(sole2.d, sole.d)

                assert np.allclose(solu.a, sole.a)
                assert np.allclose(solu.v, sole.v)
                assert np.allclose(solu.d, sole.d)

                assert np.allclose(sole0.a, sole.a[:, :1])
                assert np.allclose(sole0.v, sole.v[:, :1])
                assert np.allclose(sole0.d, sole.d[:, :1])

                assert np.allclose(sole20.a, sole2.a[:, :1])
                assert np.allclose(sole20.v, sole2.v[:, :1])
                assert np.allclose(sole20.d, sole2.d[:, :1])

                # test the generator solver w/ partial update:
                nt = f.shape[1]
                gen, d, v = tse.generator(nt, f[:, 0], static_ic=static_ic)
                for i in range(1, nt):
                    fi = f[:, i] / 2
                    gen.send((i, fi))
                    gen.send((-1, fi))
                sole2 = tse.finalize()

                assert np.allclose(sole2.a, sole.a)
                assert np.allclose(sole2.v, sole.v)
                assert np.allclose(sole2.d, sole.d)
```


Overlapping Code:
```
nerator():
# coupled equations
m = None
k = np.array([0.0, 6.0e5, 6.0e5, 6.0e5]) # diagonal of stiffness
zeta = np.array([0.0, 0.05, 1.0, 2.0]) # percent damping
b = 2.0 * zeta * np.sqrt(k) # diagonal of damping
k = np.diag(k)
b = np.diag(b)
k[1:, 1:] += np.random.randn(3, 3) * 1000
b[1:, 1:] += np.random.randn(3, 3)
h = 0.001 # time step
t = np.arange(0, 0.3001, h) # time vector
c = 2 * np.pi
f = (
np.vstack(
(
3 * (1 - np.cos(c * 2 * t)), # forcing function
4 * (np.cos(np.sqrt(6e5 / 30) * t)),
5 * (np.cos(np.sqrt(6e5 / 30) * t)),
6 * (np.cos(np.sqrt(6e5 / 30) * t)),
)
)
* 1.0e4
)
for order in (0, 1):
for rf in (None, 3, np.array([1, 2, 3])):
for static_ic in (0, 1):
# su
tsu = ode.SolveUnc(m, b, k, h, order=order, rf=rf)
solu = tsu.tsolve(f, static_ic=static_ic)
nt = f.shape[1]
gen, d, v = tsu.generator(nt, f[:, 0], static_ic=static_ic)
for i in range(1, nt):
gen.send((i, f[:, i]))
solu2 = tsu.finalize()
tsu0 = ode.SolveUnc(m, b, k, h=None, order=order, rf=rf)
solu0 = tsu0.tsolve(f[:, :1], static_ic=static_ic)
gen, d, v = tsu0.generator(1, f[:, 0], static_ic=static_ic)
solu20 = tsu0.finalize()
assert np.allclose(solu2.a, solu.a)
assert np.allclose(solu2.v, solu.v)
assert np.allclose(solu2.d, solu.d)
assert np.allclose(solu0.a, solu.a[:, :1])
assert np.allclose(solu0.v, solu.v[:, :1])
assert np.allclose(solu0.d, solu.d[:, :1])
assert np.allclose(solu20.a, solu2.a[:, :1])
assert np.allclose(solu20.v, solu2.v[:, :1])
assert np.allclose(solu20.d, solu2.d[:, :1])
# test the generator solver w/ partial update:
nt = f.shape[1]
gen, d, v = tsu.generator(nt, f[:, 0], static_ic=static_ic)
for i in range(1, nt):
fi = f[:, i] / 2
gen.send((i, fi))
gen.send((-1, fi))
solu2 = tsu.finalize()
assert np.allclose(solu2.a, solu.a)
assert
```
<Overlap Ratio: 0.983698707138842>

---

--- 173 --
Question ID: df21fb9ee1f9f03ad1344e0bb4c6d7fd1dee98e3_9
Original Code:
```
def set_votes(user, category, winner, loser):
    query = '''
        INSERT INTO cafe.votes (user_id, category_id, winner_baker_id,
                    loser_baker_id)
             VALUES (%(user_id)s, %(category_id)s, %(winner_id)s, %(loser_id)s)
    '''
    params = {
        'user_id': user.id,
        'category_id': category['id'],
        'winner_id': winner['baker_id'],
        'loser_id': loser['baker_id'],
    }
    conn = connection()
    cursor = conn.cursor()
    cursor.execute(query, params)
    conn.commit()
    conn.close()
```


Overlapping Code:
```
ner, loser):
query = '''
INSERT INTO cafe.votes (user_id, category_id, winner_baker_id,
loser_baker_id)
VALUES (%(user_id)s, %(category_id)s, %(winner_id)s, %(loser_id)s)
'''
params = {
'user_id': user.id,
'category_id': category['id'],
'winner_id': winner['baker_id'],
'loser_id': loser['baker_id'],
}
conn = connection()
cursor = conn.cursor()
cursor.execute(query, params)
conn.commit()
conn.close()
```
<Overlap Ratio: 0.9241379310344827>

---

--- 174 --
Question ID: 0af95f25fd9bf6e9d668ff3d159566e805dc121f_2
Original Code:
```
def get_teamocil_dir():
    """
    Return teamocil configuration directory.

    Returns
    -------
    str :
        absolute path to teamocil config directory

    See Also
    --------
    :meth:`tmuxp.config.import_teamocil`
    """
    return os.path.expanduser('~/.teamocil/')
```


Overlapping Code:
```
t_teamocil_dir():
"""
Return teamocil configuration directory.
Returns
-------
str :
absolute path to teamocil config directory
See Also
--------
:meth:`tmuxp.config.import_teamocil`
"""
return os.pat
```
<Overlap Ratio: 0.8547008547008547>

---

--- 175 --
Question ID: 7c32fc45129013b747e35793bb7d424a1908b65c_12
Original Code:
```
def createMeetCloseHelper(pollType):
    
    jsonData =json.loads(request.get_data())
    #GET DATA FROM FRONT END#
    groupName = jsonData["groupName"]
    pollData = {}
    pollData["pollCreator"] = jsonData["pollCreator"]
    pollData["pollTitle"] = jsonData["pollTitle"]
    pollData["pollPrompt"] = jsonData["pollPrompt"]
    pollData["pollType"] = pollType
    pollData["uuid"] = str(uuid.uuid4())
    pollData["pollStatus"] = "ACTIVE"
    pollData["pollVoteOptionsList"] = jsonData["pollVoteOptions"]
    pollVoteOptions = {}
    for option in jsonData["pollVoteOptions"]:
        pollVoteOptions[option] = 0
    pollData["pollVoteOptions"] = pollVoteOptions
    pollData["voters"] = []
    pollData["result"] = None
    #

    #SQL CONNECTION
    connection = sqlite3.connect(r"./database.db")
    cursor = connection.cursor()

    cursor.execute("SELECT * FROM  groups WHERE [groupName] = ?",(groupName,))
    groupData = list(cursor.fetchone())

    groupPolls = json.loads(groupData[4])
    groupPolls.append(pollData)
    groupPolls = json.dumps(groupPolls)
    groupData[4] = groupPolls

    cursor.execute("DELETE FROM groups WHERE [groupName] = ?",(groupName,))
    cursor.execute("INSERT INTO groups (groupName,status,posts,memberpolls,groupPolls,members) VALUES(?,?,?,?,?,?)",tuple(groupData))
    connection.commit()
    connection.close()
```


Overlapping Code:
```
tCloseHelper(pollType):

jsonData =json.loads(request.get_data())
#GET DATA FROM FRONT END#
groupName = jsonData["groupName"]
pollData = {}
pollData["pollCreator"] = jsonData["pollCreator"]
pollData["pollTitle"] = jsonData["pollTitle"]
pollData["pollPrompt"] = jsonData["pollPrompt"]
pollData["pollType"] = pollType
pollData["uuid"] = str(uuid.uuid4())
pollData["pollStatus"] = "ACTIVE"
pollData["pollVoteOptionsList"] = jsonData["pollVoteOptions"]
pollVoteOptions = {}
for option in jsonData["pollVoteOptions"]:
pollVoteOptions[option] = 0
pollData["pollVoteOptions"] = pollVoteOptions
pollData["voters"] = []
pollData["result"] = None
#
#SQL CONNECTION
connection = sqlite3.connect(r"./database.db")
cursor = connection.cursor()
cursor.execute("SELECT * FROM groups WHERE [groupName] = ?",(groupName,))
groupData = list(cursor.fetchone())
groupPolls = json.loads(groupData[4])
groupPolls.append(pollData)
groupPolls = json.dumps(groupPolls)
groupData[4] = groupPolls
cursor.execute("DELETE FROM groups WHERE [groupName] = ?",(groupName,))
cursor.execute("INSERT INTO groups (groupName,status,posts,memberpolls,groupPolls,members) VALUES(?,?,?,?,?,?)",tuple(groupData))
connection.commit()
connection.clo
```
<Overlap Ratio: 0.986088379705401>

---

--- 176 --
Question ID: 9556a52a27831318174d1ec6ce8484e380df9eb4_0
Original Code:
```
def train_model_lenet(num_convs, num_linear, l_rate, batch_size, device):
    transform_train = transforms.Compose([transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])

    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)

    net = LeNetFamily(num_convs, num_linear)
    net = net.to(device)
    criterion = nn.CrossEntropyLoss()

    optimizer = optim.SGD(net.parameters(), lr=l_rate, momentum=0.9)
    
    model_name = "nc_{}__nl_{}__bs_{}__lr_{}".format(num_convs, num_linear, batch_size, l_rate)
    path = "{}{}".format("./models/", model_name)
    
    
    EITER = 500
    for epoch in range(51):
        model_path = "{}__epoch_{}.pth".format(path, epoch)
        running_loss = 0.0
        for i,data in enumerate(trainloader, 0):
            inputs, labels = data[0].to(device), data[1].to(device)
            optimizer.zero_grad()
            outputs = net(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            last_path = "{}__last_epoch__step_{}".format(path, i)
            if i % EITER == 1:
                print("Loss @ [Epoch:{} Inter:{}] is {}".format(epoch, i, running_loss/EITER))
                running_loss = 0.0
            if epoch > 49:
                torch.save(net.state_dict(), last_path)
        if epoch % 5 == 0:
            torch.save(net.state_dict(), model_path)
```


Overlapping Code:
```
in_model_lenet(num_convs, num_linear, l_rate, batch_size, device):
transform_train = transforms.Compose([transforms.ToTensor(),
transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)
net = LeNetFamily(num_convs, num_linear)
net = net.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=l_rate, momentum=0.9)

model_name = "nc_{}__nl_{}__bs_{}__lr_{}".format(num_convs, num_linear, batch_size, l_rate)
path = "{}{}".format("./models/", model_name)


EITER = 500
for epoch in range(51):
model_path = "{}__epoch_{}.pth".format(path, epoch)
running_loss = 0.0
for i,data in enumerate(trainloader, 0):
inputs, labels = data[0].to(device), data[1].to(device)
optimizer.zero_grad()
outputs = net(inputs)
loss = criterion(outputs, labels)
loss.backward()
optimizer.step()
running_loss += loss.item()
last_path = "{}__last_epoch__step_{}".format(path, i)
if i % EITER == 1:
print("Loss @ [Epoch:{} Inter:{}] is {}".format(epoch, i, running_loss/EITER))
running_loss = 0.0
if epoch > 49:
torch.save(net.state_dict(), last_path)
if epoch % 5 == 0:
torch.save(net.state_dict()
```
<Overlap Ratio: 0.9852180339985218>

---

--- 177 --
Question ID: d9bebef25663f593d56227239c5a3902d9ba6932_2
Original Code:
```
def convert_norm_act(norm_layer, act_layer):
    assert isinstance(norm_layer, (type, str,  types.FunctionType, functools.partial))
    assert act_layer is None or isinstance(act_layer, (type, str, types.FunctionType, functools.partial))
    norm_act_kwargs = {}

    # unbind partial fn, so args can be rebound later
    if isinstance(norm_layer, functools.partial):
        norm_act_kwargs.update(norm_layer.keywords)
        norm_layer = norm_layer.func

    if isinstance(norm_layer, str):
        norm_act_layer = get_norm_act_layer(norm_layer)
    elif norm_layer in _NORM_ACT_TYPES:
        norm_act_layer = norm_layer
    elif isinstance(norm_layer,  types.FunctionType):
        # if function type, must be a lambda/fn that creates a norm_act layer
        norm_act_layer = norm_layer
    else:
        type_name = norm_layer.__name__.lower()
        if type_name.startswith('batchnorm'):
            norm_act_layer = BatchNormAct2d
        elif type_name.startswith('groupnorm'):
            norm_act_layer = GroupNormAct
        else:
            assert False, f"No equivalent norm_act layer for {type_name}"

    if norm_act_layer in _NORM_ACT_REQUIRES_ARG:
        # pass `act_layer` through for backwards compat where `act_layer=None` implies no activation.
        # In the future, may force use of `apply_act` with `act_layer` arg bound to relevant NormAct types
        norm_act_kwargs.setdefault('act_layer', act_layer)
    if norm_act_kwargs:
        norm_act_layer = functools.partial(norm_act_layer, **norm_act_kwargs)  # bind/rebind args
    return norm_act_layer
```


Overlapping Code:
```
m_act(norm_layer, act_layer):
assert isinstance(norm_layer, (type, str, types.FunctionType, functools.partial))
assert act_layer is None or isinstance(act_layer, (type, str, types.FunctionType, functools.partial))
norm_act_kwargs = {}
# unbind partial fn, so args can be rebound later
if isinstance(norm_layer, functools.partial):
norm_act_kwargs.update(norm_layer.keywords)
norm_layer = norm_layer.func
if isinstance(norm_layer, str):
norm_act_layer = get_norm_act_layer(norm_layer)
elif norm_layer in _NORM_ACT_TYPES:
norm_act_layer = norm_layer
elif isinstance(norm_layer, types.FunctionType):
# if function type, must be a lambda/fn that creates a norm_act layer
norm_act_layer = norm_layer
else:
type_name = norm_layer.__name__.lower()
if type_name.startswith('batchnorm'):
norm_act_layer = BatchNormAct2d
elif type_name.startswith('groupnorm'):
norm_act_layer = GroupNormAct
else:
assert False, f"No equivalent norm_act layer for {type_name}"
if norm_act_layer in _NORM_ACT_REQUIRES_ARG:
# pass `act_layer` through for backwards compat where `act_layer=None` implies no activation.
# In the future, may force use of `apply_act` with `act_layer` arg bound to relevant NormAct types
norm_act_kwargs.setdefault('act_layer', act_layer)
if norm_act_kwargs:
norm_act_layer = functools.partial(norm_act_layer, **norm_act_kwargs) # bind/rebind args
ret
```
<Overlap Ratio: 0.9761388286334056>

---

--- 178 --
Question ID: 69e1416f770975500d2de2c84833e658c2dcc755_0
Original Code:
```
def create_pipeline(**kwargs):

    unimp_full_pipeline = Pipeline(
        [
            node(
                func=init_mlflow,
                inputs="params:unimp_full_model_params",
                outputs="experiment_id",
            ),
            node(
                func=init_mlflow_run,
                inputs=[
                    "params:unimp_full_model_params",
                    "experiment_id",
                ],
                outputs="active_run_id",
            ),
            node(
                func=define_unimp_full_model,
                inputs=[
                    "data_engred_unimp_full",
                    "params:unimp_full_model_params",
                    "params:globals",
                    "params:RANDOM_SEED",
                ],
                outputs="untrained_unimp_full_model_pipeline"
            ),
            node(
                func=optimize_unimp_full_model,
                inputs=[
                    "data_engred_unimp_full",
                    "params:unimp_full_model_params",
                    "params:globals",
                    "active_run_id",
                    "params:RANDOM_SEED",
                    "params:hypertune",
                    "untrained_unimp_full_model_pipeline"
                ],
                outputs=[
                    "best_model_params",
                    "best_untrained_unimp_full_model_pipeline",
                ]
                ),
            node(
                func=train_unimp_full_model,
                inputs=[
                    "data_engred_unimp_full",
                    "best_model_params",
                    "params:globals",
                    "active_run_id",
                    "params:RANDOM_SEED",
                    "best_untrained_unimp_full_model_pipeline"
                ],
                outputs="unimp_full_model_pipeline",
                ),
            node(
                func=predict,
                inputs=[
                    "unimp_full_model_pipeline",
                    "data_engred_unimp_full",
                    "params:unimp_full_model_params",
                ],
                outputs="data_predicted_full_taxi",
            ),
            node(
                func=train_unimp_full_baseline,
                inputs=[
                    "data_engred_unimp_full",
                    "params:unimp_full_model_params",
                    "params:globals",
                    "active_run_id",
                ],
                outputs="baseline_pipeline",
            ),
            node(
                func=predict_baseline,
                inputs=[
                    "baseline_pipeline",
                    "data_predicted_full_taxi", # full_taxi because we want to add more preds to the dataframe
                    "params:unimp_full_model_params",
                ],
                outputs="data_predicted_full_baseline",
            ),
            node(
                func=report_performance_metrics,
                inputs=[
                    "data_predicted_full_baseline",
                    "params:unimp_full_model_params",
                    "active_run_id",
                ],
                outputs=None,
            ),
            node(
                func=visualization_caller,
                inputs=[
                    "data_predicted_full_baseline",
                    "baseline_pipeline",
                    "params:unimp_full_model_params",
                    "params:globals",
                    "active_run_id",
                ],
                outputs="artifacts_ready",
            )
            ,
            node(
                func=copy_artifacts_to_ntx,
                inputs=[
                    "experiment_id",
                    "active_run_id",
                    "params:ntx_connection",
                    "artifacts_ready",
                ],
                outputs=None,
            )
        ]
    )

    unimp_ama_pipeline = Pipeline(
        [
            node(
                func=init_mlflow,
                inputs="params:unimp_ama_model_params",
                outputs="experiment_id",
            ),
            node(
                func=init_mlflow_run,
                inputs=[
                    "params:unimp_ama_model_params",
                    "experiment_id",
                ],
                outputs="active_run_id",
            ),
            node(
                func=define_unimp_ama_model,
                inputs=[
                    "data_engred_unimp_ama",
                    "params:unimp_ama_model_params",
                    "params:globals",
                    "params:RANDOM_SEED",
                ],
                outputs="untrained_unimp_ama_model_pipeline"
            ),
            node(
                func=optimize_unimp_ama_model,
                inputs=[
                    "data_engred_unimp_ama",
                    "params:unimp_ama_model_params",
                    "params:globals",
                    "active_run_id",
                    "params:RANDOM_SEED",
                    "params:hypertune",
                    "untrained_unimp_ama_model_pipeline"
                ],
                outputs=[
                    "best_model_params",
                    "best_untrained_unimp_ama_model_pipeline",
                ]
            ),
            node(
                func=train_unimp_ama_model,
                inputs=[
                    "data_engred_unimp_ama",
                    "best_model_params",
                    "params:globals",
                    "active_run_id",
                    "params:RANDOM_SEED",
                    "best_untrained_unimp_ama_model_pipeline"
                ],
                outputs="unimp_ama_model_pipeline",
            ),
            node(
                func=predict,
                inputs=[
                    "unimp_ama_model_pipeline",
                    "data_engred_unimp_ama",
                    "params:unimp_ama_model_params",
                ],
                outputs="data_predicted_ama_taxi",
            ),
            node(
                func=train_unimp_ama_baseline,
                inputs=[
                    "data_engred_unimp_ama",
                    "params:unimp_ama_model_params",
                    "params:globals",
                    "active_run_id",
                ],
                outputs="baseline_pipeline",
            ),
            node(
                func=predict_baseline,
                inputs=[
                    "baseline_pipeline",
                    "data_predicted_ama_taxi", 
                    "params:unimp_ama_model_params",
                ],
                outputs="data_predicted_ama_baseline",
            ),
            node(
                func=report_performance_metrics,
                inputs=[
                    "data_predicted_ama_baseline",
                    "params:unimp_ama_model_params",
                    "active_run_id",
                ],
                outputs=None,
            ),
            node(
                func=visualization_caller,
                inputs=[
                    "data_predicted_ama_baseline",
                    "baseline_pipeline",
                    "params:unimp_ama_model_params",
                    "params:globals",
                    "active_run_id",
                ],
                outputs="artifacts_ready",
            )
            ,
            node(
                func=copy_artifacts_to_ntx,
                inputs=[
                    "experiment_id",
                    "active_run_id",
                    "params:ntx_connection",
                    "artifacts_ready",
                ],
                outputs=None,
            )
             
        ]
    )


    unimp_ramp_pipeline = Pipeline(
        [
            node(
                func=init_mlflow,
                inputs="params:unimp_ramp_model_params",
                outputs="experiment_id",
            ),
            node(
                func=init_mlflow_run,
                inputs=[
                    "params:unimp_ramp_model_params",
                    "experiment_id",
                ],
                outputs="active_run_id",
            ),
            node(
                func=define_unimp_ramp_model,
                inputs=[
                    "data_engred_unimp_ramp",
                    "params:unimp_ramp_model_params",
                    "params:globals",
                    "params:RANDOM_SEED",
                ],
                outputs="untrained_unimp_ramp_model_pipeline"
            ),
            node(
                func=optimize_unimp_ramp_model,
                inputs=[
                    "data_engred_unimp_ramp",
                    "params:unimp_ramp_model_params",
                    "params:globals",
                    "active_run_id",
                    "params:RANDOM_SEED",
                    "params:hypertune",
                    "untrained_unimp_ramp_model_pipeline"
                ],
                outputs=[
                    "best_model_params",
                    "best_untrained_unimp_ramp_model_pipeline",
                ]
            ),
            node(
                func=train_unimp_ramp_model,
                inputs=[
                    "data_engred_unimp_ramp",
                    "best_model_params",
                    "params:globals",
                    "active_run_id",
                    "params:RANDOM_SEED",
                    "best_untrained_unimp_ramp_model_pipeline"
                ],
                outputs="unimp_ramp_model_pipeline",
            ),
            node(
                func=predict,
                inputs=[
                    "unimp_ramp_model_pipeline",
                    "data_engred_unimp_ramp",
                    "params:unimp_ramp_model_params",
                ],
                outputs="data_predicted_ramp_taxi",
            ),
            node(
                func=train_unimp_ramp_baseline,
                inputs=[
                    "data_engred_unimp_ramp",
                    "params:unimp_ramp_model_params",
                    "params:globals",
                    "active_run_id",
                ],
                outputs="baseline_pipeline",
            ),
            node(
                func=predict_baseline,
                inputs=[
                    "baseline_pipeline",
                    "data_predicted_ramp_taxi", 
                    "params:unimp_ramp_model_params",
                ],
                outputs="data_predicted_ramp_baseline",
            ),
            node(
                func=report_performance_metrics,
                inputs=[
                    "data_predicted_ramp_baseline",
                    "params:unimp_ramp_model_params",
                    "active_run_id",
                ],
                outputs=None,
            ),
            node(
                func=visualization_caller,
                inputs=[
                    "data_predicted_ramp_baseline",
                    "baseline_pipeline",
                    "params:unimp_ramp_model_params",
                    "params:globals",
                    "active_run_id",
                ],
                outputs="artifacts_ready",
            )
            ,
            node(
                func=copy_artifacts_to_ntx,
                inputs=[
                    "experiment_id",
                    "active_run_id",
                    "params:ntx_connection",
                    "artifacts_ready",
                ],
                outputs=None,
            )             
        ]
    )

    
    return {
        'unimp_full': unimp_full_pipeline,
        'unimp_ama': unimp_ama_pipeline,
        'unimp_ramp': unimp_ramp_pipeline        
    }
```


Overlapping Code:
```
s):
unimp_full_pipeline = Pipeline(
[
node(
func=init_mlflow,
inputs="params:unimp_full_model_params",
outputs="experiment_id",
),
node(
func=init_mlflow_run,
inputs=[
"params:unimp_full_model_params",
"experiment_id",
],
outputs="active_run_id",
),
node(
func=define_unimp_full_model,
inputs=[
"data_engred_unimp_full",
"params:unimp_full_model_params",
"params:globals",
"params:RANDOM_SEED",
],
outputs="untrained_unimp_full_model_pipeline"
),
node(
func=optimize_unimp_full_model,
inputs=[
"data_engred_unimp_full",
"params:unimp_full_model_params",
"params:globals",
"active_run_id",
"params:RANDOM_SEED",
"params:hypertune",
"untrained_unimp_full_model_pipeline"
],
outputs=[
"best_model_params",
"best_untrained_unimp_full_model_pipeline",
]
),
node(
func=train_unimp_full_model,
inputs=[
"data_engred_unimp_full",
"best_model_params",
"params:globals",
"active_run_id",
"params:RANDOM_SEED",
"best_untrained_unimp_full_model_pipeline"
],
outputs="unimp_full_model_pipeline",
),
node(
func=predict,
inputs=[
"unimp_full_model_pipeline",
"data_engred_unimp_full",
"params:unimp_full_model_params",
],
outputs="data_predicted_full_taxi",
),
node(
func=train_unimp_full_baseline,
inputs=[
"data_engred_unimp_full",
"params:unimp_full_model_params",
"params:globals",
"active_run_id",
]
```
<Overlap Ratio: 0.9787395596051632>

---

--- 179 --
Question ID: 07fb98a321250e0bee2d22c3cdc80755cc9567f4_0
Original Code:
```
def train(opt):
    print("Training model with the following parameters:")
    print("\t number of stages: {}".format(opt.train_stages))
    print("\t number of concurrently trained stages: {}".format(opt.train_depth))
    print("\t learning rate scaling: {}".format(opt.lr_scale))
    print("\t non-linearity: {}".format(opt.activation))

    real = functions.read_image(opt)
    real = functions.adjust_scales2image(real, opt)
    reals = functions.create_reals_pyramid(real, opt)
    print("Training on image pyramid: {}".format([r.shape for r in reals]))
    print("")

    if opt.naive_img != "":
        naive_img = functions.read_image_dir(opt.naive_img, opt)
        naive_img_large = imresize_to_shape(naive_img, reals[-1].shape[2:], opt)
        naive_img = imresize_to_shape(naive_img, reals[0].shape[2:], opt)
        naive_img = functions.convert_image_np(naive_img)*255.0
    else:
        naive_img = None
        naive_img_large = None

    if opt.fine_tune:
        img_to_augment = naive_img
    else:
        img_to_augment = functions.convert_image_np(reals[0])*255.0

    if opt.train_mode == "editing":
        opt.noise_scaling = 0.1

    generator = init_G(opt)
    if opt.fine_tune:
        for _ in range(opt.train_stages-1):
            generator.init_next_stage()
        generator.load_state_dict(torch.load('{}/{}/netG.pth'.format(opt.model_dir, opt.train_stages-1),
                                             map_location="cuda:{}".format(torch.cuda.current_device())))


    fixed_noise = []
    noise_amp = []

    for scale_num in range(opt.start_scale, opt.train_stages):
        opt.out_ = functions.generate_dir2save(opt)
        opt.outf = '%s/%d' % (opt.out_,scale_num)
        try:
            os.makedirs(opt.outf)
        except OSError:
                print(OSError)
                pass
        functions.save_image('{}/real_scale.jpg'.format(opt.outf), reals[scale_num])

        d_curr = init_D(opt)
        if opt.fine_tune:
            d_curr.load_state_dict(torch.load('{}/{}/netD.pth'.format(opt.model_dir, opt.train_stages-1),
                                              map_location="cuda:{}".format(torch.cuda.current_device())))
        elif scale_num > 0:
            d_curr.load_state_dict(torch.load('%s/%d/netD.pth' % (opt.out_, scale_num - 1)))
            generator.init_next_stage()

        writer = SummaryWriter(log_dir=opt.outf)
        fixed_noise, noise_amp, generator, d_curr = train_single_scale(d_curr, generator, reals, img_to_augment,
                                                                       naive_img, naive_img_large, fixed_noise,
                                                                       noise_amp, opt, scale_num, writer)

        torch.save(fixed_noise, '%s/fixed_noise.pth' % (opt.out_))
        torch.save(generator, '%s/G.pth' % (opt.out_))
        torch.save(reals, '%s/reals.pth' % (opt.out_))
        torch.save(noise_amp, '%s/noise_amp.pth' % (opt.out_))
        del d_curr
    writer.close()
    return
```


Overlapping Code:
```
t("Training model with the following parameters:")
print("\t number of stages: {}".format(opt.train_stages))
print("\t number of concurrently trained stages: {}".format(opt.train_depth))
print("\t learning rate scaling: {}".format(opt.lr_scale))
print("\t non-linearity: {}".format(opt.activation))
real = functions.read_image(opt)
real = functions.adjust_scales2image(real, opt)
reals = functions.create_reals_pyramid(real, opt)
print("Training on image pyramid: {}".format([r.shape for r in reals]))
print("")
if opt.naive_img != "":
naive_img = functions.read_image_dir(opt.naive_img, opt)
naive_img_large = imresize_to_shape(naive_img, reals[-1].shape[2:], opt)
naive_img = imresize_to_shape(naive_img, reals[0].shape[2:], opt)
naive_img = functions.convert_image_np(naive_img)*255.0
else:
naive_img = None
naive_img_large = None
if opt.fine_tune:
img_to_augment = naive_img
else:
img_to_augment = functions.convert_image_np(reals[0])*255.0
if opt.train_mode == "editing":
opt.noise_scaling = 0.1
generator = init_G(opt)
if opt.fine_tune:
for _ in range(opt.train_stages-1):
generator.init_next_stage()
generator.load_state_dict(torch.load('{}/{}/netG.pth'.format(opt.model_dir, opt.train_stages-1),
map_location="cuda:{}".format(torch.cuda.current_device())))
fixed_noise = []
noise_amp = []
for scale_num in range(opt.start_scale, opt.train_stages):
opt.out_ = functions.generate_dir2save(opt)
opt.outf = '%s/%d' % (opt.out_,scale_num)
try:
os.makedirs(opt.outf)
except OSError:
print(OSError)
pass
functions.save_image('{}/real_scale.jpg'.format(opt.outf), reals[scale_num])
d_curr = init_D(opt)
if opt.fine_tune:
d_curr.load_state_dict(torch.load('{}/{}/netD.pth'.format(opt.model_dir, opt.train_stages-1),
map_location="cuda:{}".format(torch.cuda.current_device())))
elif scale_num > 0:
d_curr.load_state_dict(torch.load('%s/%d/netD.pth' % (opt.out_, scale_num - 1)))
generator.init_next_stage()
writer = SummaryWriter(log_dir=opt.outf)
fixed_noise, noise_amp, generator, d_curr = train_single_scale(d_curr, generator, reals, 
```
<Overlap Ratio: 0.988824101068999>

---

--- 180 --
Question ID: 6ad4f70bf2fa6bc397cf8233ae6d66df5f1c9a9c_8
Original Code:
```
def test_check_restore_session_check_search_path(run_reframe, tmp_path):
    run_reframe(
        checkpath=['unittests/resources/checks_unlisted/deps_complex.py']
    )
    returncode, stdout, _ = run_reframe(
        checkpath=[f'{tmp_path}/foo'],
        more_options=[
            f'--restore-session={tmp_path}/report.json', '-n', 'T1', '-R'
        ],
        action='list'
    )
    assert returncode == 0
    assert 'Found 0 check(s)' in stdout
```


Overlapping Code:
```
h_path(run_reframe, tmp_path):
run_reframe(
checkpath=['unittests/resources/checks_unlisted/deps_complex.py']
)
returncode, stdout, _ = run_reframe(
checkpath=[f'{tmp_path}/foo'],
more_options=[
f'--restore-session={tmp_path}/report.json', '-n', 'T1', '-R'
],
action='list'
)
assert returncode == 0
a
```
<Overlap Ratio: 0.7978723404255319>

---

--- 181 --
Question ID: 0681ba6de6bfed398e974cebe20d735df21c208b_0
Original Code:
```
def test_parse_kpoints(vasp_kpoints):
    """
    Parse a reference KPOINTS file.

    Using the KpointsParser and compare the result to a reference
    kpoints-node.

    """

    kpoints, _ = vasp_kpoints

    try:
        _ = kpoints.get_attribute('mesh')
        file_path = data_path('kpoints', 'KPOINTS_mesh')
        method = 'get_kpoints_mesh'
        param = 'mesh'
    except AttributeError:
        pass

    try:
        _ = kpoints.get_attribute('array|kpoints')
        file_path = data_path('kpoints', 'KPOINTS_list')
        method = 'get_kpoints'
        param = 'list'
    except AttributeError:
        pass

    parser = KpointsParser(file_path=file_path)
    result = parser.kpoints
    if param == 'list':
        assert getattr(result, method)().all() == getattr(kpoints, method)().all()
    if param == 'mesh':
        assert getattr(result, method)() == getattr(kpoints, method)()
```


Overlapping Code:
```
_parse_kpoints(vasp_kpoints):
"""
Parse a reference KPOINTS file.
Using the KpointsParser and compare the result to a reference
kpoints-node.
"""
kpoints, _ = vasp_kpoints
try:
_ = kpoints.get_attribute('mesh')
file_path = data_path('kpoints', 'KPOINTS_mesh')
method = 'get_kpoints_mesh'
param = 'mesh'
except AttributeError:
pass
try:
_ = kpoints.get_attribute('array|kpoints')
file_path = data_path('kpoints', 'KPOINTS_list')
method = 'get_kpoints'
param = 'list'
except AttributeError:
pass
parser = KpointsParser(file_path=file_path)
result = parser.kpoints
if param == 'list':
assert getattr(result, method)().all() == getattr(kpoints, method)().all()
if param == 'mesh':
assert getattr(result, method)()
```
<Overlap Ratio: 0.9491298527443106>

---

--- 182 --
Question ID: 312cf973c05f33f5b578e08da41d5d751803fb35_1
Original Code:
```
def clear_mpls_counters(device):
    """ Config ldp on Device

        Args:
            device (`obj`): Device object
        Return:
            None
        Raise:
            SubCommandFailure: Failed configuring interface
    """
    log.info("clear mpls counters on {device}".format(device=device.name))

    try:
        device.execute("clear mpls counters")
    except SubCommandFailure as e:
        raise SubCommandFailure(
            'Could not clear mpls counters on {device}, Error: {error}'.format(
                device=device.name, error=e
            )
        )       
```


Overlapping Code:
```
g ldp on Device
Args:
device (`obj`): Device object
Return:
None
Raise:
SubCommandFailure: Failed configuring interface
"""
log.info("clear mpls counters on {device}".format(device=device.name))
try:
device.execute("clear mpls counters")
except SubCommandFailure as e:
raise SubCommandFailure(
'Could not clear mpls counters on {device}, Error: {error}'.format(
device=device.name, error=
```
<Overlap Ratio: 0.8919540229885058>

---

--- 183 --
Question ID: 74ff59c439b5efe8f7e48ad718d5d621828d65a7_4
Original Code:
```
def sep_knowns(cycles):
    unknowns = []
    knowns = []

    i = 0
    while i < len(cycles):
        if i + 1 < len(cycles) and len(cycles[i]) == len(cycles[i + 1]):
            unknowns.append(cycles[i])
            unknowns.append(cycles[i + 1])
            i += 2
        else:
            knowns.append(cycles[i])
            i += 1

    return knowns, unknowns
```


Overlapping Code:
```

knowns = []
i = 0
while i < len(cycles):
if i + 1 < len(cycles) and len(cycles[i]) == len(cycles[i + 1]):
unknowns.append(cycles[i])
unknowns.append(cycles[i + 1])
i += 2
else:
knowns.append(cycles[i
```
<Overlap Ratio: 0.7407407407407407>

---

--- 184 --
Question ID: 99075f5a3278dc85eb59aab0c4c4a6c15d2f5e94_2
Original Code:
```
def test_lease_keep(client):
    ID = random.randint(10000, 100000)
    TTL = 5  # min is 2sec
    keep_cb = mock.Mock()
    cancel_cb = mock.Mock()

    lease = client.Lease(ttl=TTL, ID=ID)
    lease.grant()
    lease.keepalive(keep_cb=keep_cb, cancel_cb=cancel_cb)
    with pytest.raises(RuntimeError):
        lease.keepalive()
    time.sleep(1)
    lease.cancel_keepalive()
    assert keep_cb.called
    assert keep_cb.call_count < 2  # or it keep too fast
    assert cancel_cb.called

    lease.keepalive_once()
    lease = client.Lease(ttl=TTL, ID=ID, new=False)
    lease.grant()
    assert lease.alive()
    lease.revoke()

    lease = client.Lease(ttl=TTL)
    lease.grant()
    assert lease.alive()
    lease.revoke()
```


Overlapping Code:
```
ent):
ID = random.randint(10000, 100000)
TTL = 5 # min is 2sec
keep_cb = mock.Mock()
cancel_cb = mock.Mock()
lease = client.Lease(ttl=TTL, ID=ID)
lease.grant()
lease.keepalive(keep_cb=keep_cb, cancel_cb=cancel_cb)
with pytest.raises(RuntimeError):
lease.keepalive()
time.sleep(1)
lease.cancel_keepalive()
assert keep_cb.called
assert keep_cb.call_count < 2 # or it keep too fast
assert cancel_cb.called
lease.keepalive_once()
lease = client.Lease(ttl=TTL, ID=ID, new=False)
lease.grant()
assert lease.alive()
lease.revoke()
lease = client.Lease(ttl=TTL)
lease.grant()
assert lease.alive()
lease.revok
```
<Overlap Ratio: 0.9584664536741214>

---

--- 185 --
Question ID: c2f82c3ffffd49ff0339318dc03aa161f0e37a1e_0
Original Code:
```
def main():
    import os

    import requests
    import datetime as dt

    t = dt.datetime.now()
    today = t.strftime("%d/%m/%Y")
    today_time = t.strftime("%H:%M:%S")

    APP_ID = os.environ["APP_ID"]
    API_KEY = os.environ["API_KEY"]
    USERNAME = os.environ["USERNAME"]
    PROJECT_NAME = "exerciseTracking"
    SHEET_NAME = "workouts"
    GENDER = "male"
    WEIGHT_KG = 80
    HEIGHT_CM = 157
    AGE = 27
    headers = {
        "x-app-id": APP_ID,
        "x-app-key": API_KEY,
    }

    request_body = {
        "query": input("Tell me which exercises you did: "),
        "gender": GENDER,
        "weight_kg": WEIGHT_KG,
        "height_cm": HEIGHT_CM,
        "age": AGE
    }

    auth = (os.environ["UNAME"], os.environ["PWD"])
    nutritionix_endpoint = "https://trackapi.nutritionix.com/v2/natural/exercise"
    sheety_endpoint = f"https://api.sheety.co/{USERNAME}/{PROJECT_NAME}/{SHEET_NAME}"

    nutritionix_data = requests.post(url=nutritionix_endpoint, json=request_body, headers=headers)
    n = nutritionix_data.json()

    for exercise in n["exercises"]:
        msg_body = {
            "workout": {
                "date": today,
                "time": today_time,
                "exercise": exercise["name"].title(),
                "duration": exercise["duration_min"],
                "calories": exercise["nf_calories"]
            }
        }
        sheety_data = requests.post(url=sheety_endpoint, json=msg_body, auth=auth)
        print(sheety_data.text)
```


Overlapping Code:
```
quests
import datetime as dt
t = dt.datetime.now()
today = t.strftime("%d/%m/%Y")
today_time = t.strftime("%H:%M:%S")
APP_ID = os.environ["APP_ID"]
API_KEY = os.environ["API_KEY"]
USERNAME = os.environ["USERNAME"]
PROJECT_NAME = "exerciseTracking"
SHEET_NAME = "workouts"
GENDER = "male"
WEIGHT_KG = 80
HEIGHT_CM = 157
AGE = 27
headers = {
"x-app-id": APP_ID,
"x-app-key": API_KEY,
}
request_body = {
"query": input("Tell me which exercises you did: "),
"gender": GENDER,
"weight_kg": WEIGHT_KG,
"height_cm": HEIGHT_CM,
"age": AGE
}
auth = (os.environ["UNAME"], os.environ["PWD"])
nutritionix_endpoint = "https://trackapi.nutritionix.com/v2/natural/exercise"
sheety_endpoint = f"https://api.sheety.co/{USERNAME}/{PROJECT_NAME}/{SHEET_NAME}"
nutritionix_data = requests.post(url=nutritionix_endpoint, json=request_body, headers=headers)
n = nutritionix_data.json()
for exercise in n["exercises"]:
msg_body = {
"workout": {
"date": today,
"time": today_time,
"exercise": exercise["name"].title(),
"duration": exercise["duration_min"],
"calories": exercise["nf_calories"]
}
}
sheety_data = requests.post(url=sheety_endpoint, json=msg_body, auth=auth)
pr
```
<Overlap Ratio: 0.956738768718802>

---

--- 186 --
Question ID: e6e52b062ce90dce00f33a01a55d2781d6d9a952_0
Original Code:
```
def get_mkl_lib(device_id=None, verbose=False):
    if sys.platform == 'win32':
        # find *.dll
        current_path = os.path.dirname(os.path.realpath(__file__))
        mkl_engine_path = os.path.join(current_path, os.pardir, 'mklEngine', 'mklml.dll')
        if not os.path.isfile(mkl_engine_path):
            neon_logger.display("mklml.dll not found")
            return 0

        mkl_engine_path = os.path.join(current_path, os.pardir, 'mklEngine', 'mklEngine.dll')
        if not os.path.isfile(mkl_engine_path):
            neon_logger.display("mklEngine.dll not found")
            return 0

        math_engine_path = os.path.join(current_path, os.pardir, 'mklEngine', 'cmath.dll')
        if not os.path.isfile(math_engine_path):
            neon_logger.display("cmath.dll not found")
            return 0

        header_path = os.path.join(os.path.dirname(__file__), 'mklEngine',
                                   'src', 'math_cpu.header')
        if os.path.isfile(header_path):
            neon_logger.display("math_cpu.header not found")
            return 0
        return 1

    elif sys.platform == 'darwin':
        # find *.dylib
        current_path = os.path.dirname(os.path.realpath(__file__))
        mkl_engine_path = os.path.join(current_path, os.pardir, 'mklEngine', 'mklEngine.dylib')
        if not os.path.isfile(mkl_engine_path):
            neon_logger.display("mklEngine.dylib not found")
            return 0

        math_engine_path = os.path.join(current_path, os.pardir, 'mklEngine', 'cmath.dylib')
        if not os.path.isfile(math_engine_path):
            neon_logger.display("cmath.dylib not found")
            return 0

        header_path = os.path.join(os.path.dirname(__file__), 'mklEngine',
                                   'src', 'math_cpu.header')
        if os.path.isfile(header_path):
            neon_logger.display("math_cpu.header not found")
            return 0
        return 1

    else:
        # find *.so
        current_path = os.path.dirname(os.path.realpath(__file__))
        mkl_engine_path = os.path.join(current_path, os.pardir, 'mklEngine', 'mklEngine.so')
        if not os.path.isfile(mkl_engine_path):
            neon_logger.display("mklEngine.so not found")
            return 0

        math_engine_path = os.path.join(current_path, os.pardir, 'mklEngine', 'cmath.so')
        if not os.path.isfile(math_engine_path):
            neon_logger.display("cmath.so not found")
            return 0

        header_path = os.path.join(os.path.dirname(__file__), 'mklEngine',
                                   'src', 'math_cpu.header')
        if os.path.isfile(header_path):
            neon_logger.display("math_cpu.header not found")
            return 0
        return 1
```


Overlapping Code:
```
lib(device_id=None, verbose=False):
if sys.platform == 'win32':
# find *.dll
current_path = os.path.dirname(os.path.realpath(__file__))
mkl_engine_path = os.path.join(current_path, os.pardir, 'mklEngine', 'mklml.dll')
if not os.path.isfile(mkl_engine_path):
neon_logger.display("mklml.dll not found")
return 0
mkl_engine_path = os.path.join(current_path, os.pardir, 'mklEngine', 'mklEngine.dll')
if not os.path.isfile(mkl_engine_path):
neon_logger.display("mklEngine.dll not found")
return 0
math_engine_path = os.path.join(current_path, os.pardir, 'mklEngine', 'cmath.dll')
if not os.path.isfile(math_engine_path):
neon_logger.display("cmath.dll not found")
return 0
header_path = os.path.join(os.path.dirname(__file__), 'mklEngine',
'src', 'math_cpu.header')
if os.path.isfile(header_path):
neon_logger.display("math_cpu.header not found")
return 0
return 1
elif sys.platform == 'darwin':
# find *.dylib
current_path = os.path.dirname(os.path.realpath(__file__))
mkl_engine_path = os.path.join(current_path, os.pardir, 'mklEngine', 'mklEngine.dylib')
if not os.path.isfile(mkl_engine_path):
neon_logger.display("mklEngine.dylib not found")
return 0
math_engine_path = os.path.join(current_path, os.pardir, 'mklEngine', 'cmath.dylib')
if not os.path.isfile(math_engine_path):
neon_logger.display("cmath.dylib not found")
return 0
header_path = os.path.join(os.path.dirname(__file__), 'mklEngine',
'src', 'math_cpu.header')
if os.path.isfile(header_path):
neon_logger.display("math_cpu.header not found")
return 0
return 1
else:
# find *.so
current_path = os.path.dirname(os.path.realpath(__file__))
mkl_engine_path = os.path.join(current_path, os.pardir, 'mklEngine', 'mklEngine.so')
if not os.path.isfile(mkl_engine_path):
neon_logger.display("mklEngine.so not found")
return 0
math_engine_path = os.path.join(current_path, os.pardir, 'mklEngine', 'cmath.so')
if not os.path.isfile(math_engine_path):
neon_logger.display("cmath.so not found")
return 0
header_p
```
<Overlap Ratio: 0.992914979757085>

---

--- 187 --
Question ID: 38d2ea165569269c1c07b37f25b8bec40d353124_2
Original Code:
```
def train(epoch, iter_no, df_iter, batch_multiplier=10, print_freq=100, scheduler=None):  
    
    print('\nEpoch: %d' % epoch)
    if args.cyclic==False and scheduler is None:
        adjust_learning_rate(optimizer, epoch)
    train_loss = AverageMeter()
    data_time = AverageMeter()
    batch_time = AverageMeter()
    correct = 0
    total = 0

    # switch to train mode
    net.train()

    end = time.time()
    for batch_idx, (inputs, targets, indexes) in enumerate(trainloader):
        if args.cyclic: scheduler.step()
        iter_no += 1
        data_time.update(time.time() - end)
        inputs, targets, indexes = inputs.to(device), targets.to(device), indexes.to(device)
        
        if batch_idx % batch_multiplier == 0:
            optimizer.step()
            optimizer.zero_grad()
            
        features = net(inputs)
        outputs = lemniscate(features, indexes)
        loss = criterion(outputs, indexes) / float(batch_multiplier)

        loss.backward()

        train_loss.update(loss.item(), inputs.size(0))

        # measure elapsed time
        batch_time.update(time.time() - end)
        end = time.time()

        if batch_idx % print_freq == 0 or batch_idx == len(trainloader):
            print('Epoch: [{}][{}/{}]'
                  'Time: {batch_time.val:.3f} ({batch_time.avg:.3f}) '
                  'Data: {data_time.val:.3f} ({data_time.avg:.3f}) '
                  'Loss: {train_loss.val:.4f} ({train_loss.avg:.4f}) '
                  'LR: {lr}'.format(
                  epoch, batch_idx, len(trainloader), batch_time=batch_time, data_time=data_time, train_loss=train_loss, lr=optimizer.param_groups[0]['lr']))

        df_iter = df_iter.append({
            "epoch": epoch, 
            "iteration": iter_no, 
            "learning_rate": optimizer.param_groups[0]['lr'], 
            "loss": train_loss.val, 
        }, ignore_index=True)  

        if scheduler is not None: scheduler.on_batch_end(True)
                    
    return iter_no, train_loss.avg, df_iter
```


Overlapping Code:
```
poch, iter_no, df_iter, batch_multiplier=10, print_freq=100, scheduler=None): 

print('\nEpoch: %d' % epoch)
if args.cyclic==False and scheduler is None:
adjust_learning_rate(optimizer, epoch)
train_loss = AverageMeter()
data_time = AverageMeter()
batch_time = AverageMeter()
correct = 0
total = 0
# switch to train mode
net.train()
end = time.time()
for batch_idx, (inputs, targets, indexes) in enumerate(trainloader):
if args.cyclic: scheduler.step()
iter_no += 1
data_time.update(time.time() - end)
inputs, targets, indexes = inputs.to(device), targets.to(device), indexes.to(device)

if batch_idx % batch_multiplier == 0:
optimizer.step()
optimizer.zero_grad()

features = net(inputs)
outputs = lemniscate(features, indexes)
loss = criterion(outputs, indexes) / float(batch_multiplier)
loss.backward()
train_loss.update(loss.item(), inputs.size(0))
# measure elapsed time
batch_time.update(time.time() - end)
end = time.time()
if batch_idx % print_freq == 0 or batch_idx == len(trainloader):
print('Epoch: [{}][{}/{}]'
'Time: {batch_time.val:.3f} ({batch_time.avg:.3f}) '
'Data: {data_time.val:.3f} ({data_time.avg:.3f}) '
'Loss: {train_loss.val:.4f} ({train_loss.avg:.4f}) '
'LR: {lr}'.format(
epoch, batch_idx, len(trainloader), batch_time=batch_time, data_time=data_time, train_loss=train_loss, lr=optimizer.param_groups[0]['lr']))
df_iter = df_iter.append({
"epoch": epoch, 
"iteration": iter_no, 
"learning_rate": optimizer.param_groups[0]['lr'], 
"loss": train_loss.val, 
}, ignore_index=True) 
if scheduler is not None: scheduler.on_batch_end(True)

return iter_no, train_loss.avg, df_iter
```
<Overlap Ratio: 0.9931719428926132>

---

--- 188 --
Question ID: 2ed480cdcfa28dd007f6db7b0731c529c83f70f0_4
Original Code:
```
def test():
    url = APP_URL_DATA + "/dumps/unpaywall/?where={\"doi\":\""
    url += "10.4000/rechercheformation.2839\",\"treated\":false}"
    try:
        test_json = requests.get(url, headers=header).json()['data'][0]
        print(test_json)
    except Exception:
        print("The test element is not in the unpaywall dump collection \
                or it has already be processed")
        return
    process_doi_unpaywall(test_json)
```


Overlapping Code:
```
TA + "/dumps/unpaywall/?where={\"doi\":\""
url += "10.4000/rechercheformation.2839\",\"treated\":false}"
try:
test_json = requests.get(url, headers=header).json()['data'][0]
print(test_json)
except Exception:
print("The test element is not in the unpaywall dump collection \
or it has already be proc
```
<Overlap Ratio: 0.8>

---

--- 189 --
Question ID: 467ae70af6eefaf632ced2f238a3bcb8b79bcbae_0
Original Code:
```
def create_canonical_request_string(method,
                                    uri,
                                    headers,
                                    auth_method):
    """
    Create a canonical request string from aspects of the request.
    """
    headers_of_interest = []
    for header_name in ['content-type', 'x-altus-date']:
        found = False
        for key in headers:
            key_lc = key.lower()
            if headers[key] is not None and key_lc == header_name:
                headers_of_interest.append(headers[key].strip())
                found = True
        if not found:
            headers_of_interest.append('')

    # Our signature verification with treat a query with no = as part of the
    # path, so we do as well. It appears to be a behavior left to the server
    # implementation, and python and our java servlet implementation disagree.
    uri_components = urlparse(uri)
    path = uri_components.path
    if not path:
        path = '/'
    if uri_components.query and '=' not in uri_components.query:
        path += '?' + uri_components.query

    canonical_string = method.upper() + '\n'
    canonical_string += '\n'.join(headers_of_interest) + '\n'
    canonical_string += path + '\n'
    canonical_string += auth_method

    return canonical_string
```


Overlapping Code:
```
t_string(method,
uri,
headers,
auth_method):
"""
Create a canonical request string from aspects of the request.
"""
headers_of_interest = []
for header_name in ['content-type', 'x-altus-date']:
found = False
for key in headers:
key_lc = key.lower()
if headers[key] is not None and key_lc == header_name:
headers_of_interest.append(headers[key].strip())
found = True
if not found:
headers_of_interest.append('')
# Our signature verification with treat a query with no = as part of the
# path, so we do as well. It appears to be a behavior left to the server
# implementation, and python and our java servlet implementation disagree.
uri_components = urlparse(uri)
path = uri_components.path
if not path:
path = '/'
if uri_components.query and '=' not in uri_components.query:
path += '?' + uri_components.query
canonical_string = method.upper() + '\n'
canonical_string += '\n'.join(headers_of_interest) + '\n'
canonical_string += path + '\n'
canonical
```
<Overlap Ratio: 0.9286412512218963>

---

--- 190 --
Question ID: 6a0e03795a8c2b6bc0e5a0259453faf1fc5beb60_0
Original Code:
```
def _get_step_number(method_name):
    match = re.match(LAB_METHOD_NAME_REGEX, method_name)
    if match is None:
        return None
    return int(match.groups()[0])
```


Overlapping Code:
```
name):
match = re.match(LAB_METHOD_NAME_REGEX, method_name)
if match is None:
return None
return int(match.groups()[0]
```
<Overlap Ratio: 0.8027210884353742>

---

--- 191 --
Question ID: d7a784e0be831f66b1bde2a4611d4ad199cc4143_2
Original Code:
```
def showcreds():
    """Load and show credentials from db"""

    conn = sqlite3.connect(dbfile)
    with conn:
        cur = conn.cursor()
        cur.execute('SELECT * FROM Credentials ORDER BY url')
        data = from_db_cursor(cur)

    print()
    print(colored(data, 'magenta'))
    print()

    cur.close()

    while True:
        response = input(colored(" Back to menu or exit [menu/exit] ", 'yellow'))
        if not response.isalpha():
            continue
        if response == 'menu' or response == 'exit':
            break

    if response == 'menu':
        # Back to menu
        os.system("clear")
        main()
    else:
        # Exit
        os.system("clear")
        exit(0)
```


Overlapping Code:
```
nd show credentials from db"""
conn = sqlite3.connect(dbfile)
with conn:
cur = conn.cursor()
cur.execute('SELECT * FROM Credentials ORDER BY url')
data = from_db_cursor(cur)
print()
print(colored(data, 'magenta'))
print()
cur.close()
while True:
response = input(colored(" Back to menu or exit [menu/exit] ", 'yellow'))
if not response.isalpha():
continue
if response == 'menu' or response == 'exit':
break
if response == 'menu':
# Back to menu
os.system("clear")
main()
else:
# Exit
os.system("clear
```
<Overlap Ratio: 0.9328358208955224>

---

--- 192 --
Question ID: 0f205ff8b8cc8ce39ca7af0ebd51f8180a7e8acd_5
Original Code:
```
def plot_1D_pics(k, est_csd, est_pots, tp, Fs, cut=9):
    plt.figure(figsize=(12, 8))
    # plt.suptitle('plane: '+str(k.estm_x[cut,0])+' $\mu$m '+' $\lambda$ : '+str(k.lambd)+
                 # '  R: '+ str(k.R))
    ax1 = plt.subplot(122)
    set_axis(ax1, -0.05, 1.05, letter= 'D')
    make_plot_spacetime(ax1, k.estm_x, k.estm_y, est_csd[cut,:,:], Fs,
              title='Estimated CSD', cmap='bwr')
    for lvl, name in zip([-500,-850,-2000], ['II/III', 'IV', 'V/VI']):
        plt.axhline(lvl, ls='--', color='grey')
        plt.text(340, lvl+20, name)
    plt.xlim(250, 400)
    plt.xticks([250, 300, 350, 400], [-50, 0, 50, 100])
    ax2 = plt.subplot(121)
    set_axis(ax2, -0.05, 1.05, letter= 'C')
    make_plot_spacetime(ax2, k.estm_x, k.estm_y, est_pots[cut,:,:],
              title='Estimated LFP', cmap='PRGn')
    plt.axvline(tp/Fs*1000, ls='--', color ='grey', lw=2)
    plt.xlim(250, 400)
    plt.xticks([250, 300, 350, 400], [-50, 0, 50, 100])
    plt.tight_layout()
    plt.savefig('figure_1D_pics', dpi=300)
```


Overlapping Code:
```
Fs, cut=9):
plt.figure(figsize=(12, 8))
# plt.suptitle('plane: '+str(k.estm_x[cut,0])+' $\mu$m '+' $\lambda$ : '+str(k.lambd)+
# ' R: '+ str(k.R))
ax1 = plt.subplot(122)
set_axis(ax1, -0.05, 1.05, letter= 'D')
make_plot_spacetime(ax1, k.estm_x, k.estm_y, est_csd[cut,:,:], Fs,
title='Estimated CSD', cmap='bwr')
for lvl, name in zip([-500,-850,-2000], ['II/III', 'IV', 'V/VI']):
plt.axhline(lvl, ls='--', color='grey')
plt.text(340, lvl+20, name)
plt.xlim(250, 400)
plt.xticks([250, 300, 350, 400], [-50, 0, 50, 100])
ax2 = plt.subplot(121)
set_axis(ax2, -0.05, 1.05, letter= 'C')
make_plot_spacetime(ax2, k.estm_x, k.estm_y, est_pots[cut,:,:],
title='Estimated LFP', cmap='PRGn')
plt.axvline(tp/Fs*1000, ls='--', color ='grey', lw=2)
plt.xlim(250, 400)
plt.xticks([250, 300, 350, 400], [-50, 0, 50, 100])
plt.tight_layout()
plt.savefig('figure_1D_pi
```
<Overlap Ratio: 0.9381898454746137>

---

--- 193 --
Question ID: 598b6316452b8a7d926bbe53385d206a9cdc900d_3
Original Code:
```
def initialize(model: nn.Layer, init: str):
    """Initialize weights of a neural network module.

    Parameters are initialized using the given method or distribution.

    Custom initialization routines can be implemented into submodules

    Args:
        model (nn.Layer): Target.
        init (str): Method of initialization.
    """
    assert check_argument_types()

    if init == "xavier_uniform":
        nn.initializer.set_global_initializer(nn.initializer.XavierUniform(),
                                              nn.initializer.Constant())
    elif init == "xavier_normal":
        nn.initializer.set_global_initializer(nn.initializer.XavierNormal(),
                                              nn.initializer.Constant())
    elif init == "kaiming_uniform":
        nn.initializer.set_global_initializer(nn.initializer.KaimingUniform(),
                                              nn.initializer.Constant())
    elif init == "kaiming_normal":
        nn.initializer.set_global_initializer(nn.initializer.KaimingNormal(),
                                              nn.initializer.Constant())
    else:
        raise ValueError("Unknown initialization: " + init)
```


Overlapping Code:
```
 nn.Layer, init: str):
"""Initialize weights of a neural network module.
Parameters are initialized using the given method or distribution.
Custom initialization routines can be implemented into submodules
Args:
model (nn.Layer): Target.
init (str): Method of initialization.
"""
assert check_argument_types()
if init == "xavier_uniform":
nn.initializer.set_global_initializer(nn.initializer.XavierUniform(),
nn.initializer.Constant())
elif init == "xavier_normal":
nn.initializer.set_global_initializer(nn.initializer.XavierNormal(),
nn.initializer.Constant())
elif init == "kaiming_uniform":
nn.initializer.set_global_initializer(nn.initializer.KaimingUniform(),
nn.initializer.Constant())
elif init == "kaiming_normal":
nn.initializer.set_global_initializer(nn.initializer.KaimingNormal(),
nn.initializer.Constant())
else:
raise ValueError("Unknown initialization: " + init
```
<Overlap Ratio: 0.9755011135857461>

---

--- 194 --
Question ID: 1617669b70e1b30ab3c168158648e2ae751fb4e7_3
Original Code:
```
def logout(driver):
    mf_logout_url = "https://moneyforward.com/sign_out"
    driver.get(mf_logout_url)
    time.sleep(2)
```


Overlapping Code:
```
f_logout_url = "https://moneyforward.com/sign_out"
```
<Overlap Ratio: 0.45045045045045046>

---

--- 195 --
Question ID: ad475283b62d067b315d2540f0db797993998a45_0
Original Code:
```
def write(path: Path) -> None:
    # read methods up to start of tag enum values
    lines: List[str] = []
    with open(path, "r") as f:
        for line in f.readlines():
            lines.append(line)
            if line.strip() == MARKER:
                break

    # write tag enum values
    with open(path, "w") as f:
        f.writelines(lines)
        for tag, v in DicomDictionary.items():
            keyword = v[-1]
            if keyword:
                f.write(f"    {keyword} = {tag}\n")
```


Overlapping Code:
```
 Path) -> None:
# read methods up to start of tag enum values
lines: List[str] = []
with open(path, "r") as f:
for line in f.readlines():
lines.append(line)
if line.strip() == MARKER:
break
# write tag enum values
with open(path, "w") as f:
f.writelines(lines)
for tag, v in DicomDictionary.items():
keyword = v[-1]
if keyword:
f.write(f" {keyword} =
```
<Overlap Ratio: 0.9333333333333333>

---

--- 196 --
Question ID: 729c032a9d3db74487cfa10763d9949a1ed755e6_7
Original Code:
```
def chkfflotrs(bbarr):
    bubbleList = [col for col in range(len(bbarr[0]))
                  if bbarr[0][col] != blank]

    newbbList = []

    for i in range(len(bubbleList)):
        if i == 0:
            newbbList.append(bubbleList[i])
        elif bubbleList[i] > bubbleList[i - 1] + 1:
            newbbList.append(bubbleList[i])

    cpyofbrd = copy.deepcopy(bbarr)

    for row in range(len(bbarr)):
        for col in range(len(bbarr[0])):
            bbarr[row][col] = blank

    for col in newbbList:
        popflotrs(bbarr, cpyofbrd, col)
```


Overlapping Code:
```
chkfflotrs(bbarr):
bubbleList = [col for col in range(len(bbarr[0]))
if bbarr[0][col] != blank]
newbbList = []
for i in range(len(bubbleList)):
if i == 0:
newbbList.append(bubbleList[i])
elif bubbleList[i] > bubbleList[i - 1] + 1:
newbbList.append(bubbleList[i])
cpyofbrd = copy.deepcopy(bbarr)
for row in range(len(bbarr)):
for col in range(len(bbarr[0])):
bbarr[row][col] = blank
for col in newbbLi
```
<Overlap Ratio: 0.9111617312072893>

---

--- 197 --
Question ID: 88c9e3af4411569791cf77ecc1a737d4c4eee95d_1
Original Code:
```
def load_yaml(stream):
    """load yaml from a file-like object; used to make it easier to cater to
    API changes in ruamel.yaml
    """
    from ruamel.yaml import YAML

    yaml = YAML(typ="safe", pure=True)
    return yaml.load(stream)
```


Overlapping Code:
```
eam):
"""load yaml from a file-like object; used to make it easier to cater to
API changes in ruamel.yaml
"""
from ruamel.yaml import YAML
yaml = YAML(typ="safe", pure=Tru
```
<Overlap Ratio: 0.7953488372093023>

---

--- 198 --
Question ID: 51e25329c7334ff7517cd47e4485b252f4feee9d_0
Original Code:
```
def make_encryptor(plaintext_type, pk_rcv_type, sk_snd_type):
  @tff.tf_computation(plaintext_type, pk_rcv_type, sk_snd_type)
  def encrypt_tensor(plaintext, pk_rcv, sk_snd):
    pk_rcv = easy_box.PublicKey(pk_rcv)
    sk_snd = easy_box.SecretKey(sk_snd)
    nonce = easy_box.gen_nonce()
    ciphertext, mac = easy_box.seal_detached(plaintext, nonce, pk_rcv, sk_snd)
    return ciphertext.raw, mac.raw, nonce.raw

  return encrypt_tensor
```


Overlapping Code:
```
, sk_snd_type):
@tff.tf_computation(plaintext_type, pk_rcv_type, sk_snd_type)
def encrypt_tensor(plaintext, pk_rcv, sk_snd):
pk_rcv = easy_box.PublicKey(pk_rcv)
sk_snd = easy_box.SecretKey(sk_snd)
nonce = easy_box.gen_nonce()
ciphertext, mac = easy_box.seal_detached(plaintext, nonce, pk_rcv, sk_snd)
return ciphertext.raw, mac.raw, nonce.raw
return 
```
<Overlap Ratio: 0.8536585365853658>

---

--- 199 --
Question ID: 21ff7f47cbd4b6369c570afb17c5e9d9fc010ab4_11
Original Code:
```
def heapSort(arr):  # in-place | not-stable
    # Time Complexity O(nlogn) | Space Complexity O(1)

    def heapify(arr, n, i):  # Max Heap
        largest = i  #     
        l = 2 * i + 1  # Left Node
        r = 2 * i + 2  # Right Node

        if l < n and arr[largest] < arr[l]:
            largest = l

        if r < n and arr[largest] < arr[r]:
            largest = r

        # root  
        #   ,  heapify
        if largest != i:
            arr[i], arr[largest] = arr[largest], arr[i]
            heapify(arr, n, largest)

    n = len(arr)

    for i in range(n // 2, -1, -1):
        heapify(arr, n, i)

    for i in range(n - 1, 0, -1):
        arr[i], arr[0] = arr[0], arr[i]
        # Heapify root element
        heapify(arr, i, 0)

    return arr
```


Overlapping Code:
```
: # in-place | not-stable
# Time Complexity O(nlogn) | Space Complexity O(1)
def heapify(arr, n, i): # Max Heap
largest = i #     
l = 2 * i + 1 # Left Node
r = 2 * i + 2 # Right Node
if l < n and arr[largest] < arr[l]:
largest = l
if r < n and arr[largest] < arr[r]:
largest = r
# root  
#   ,  heapify
if largest != i:
arr[i], arr[largest] = arr[largest], arr[i]
heapify(arr, n, largest)
n = len(arr)
for i in range(n // 2, -1, -1):
heapify(arr, n, i)
for i in range(n - 1, 0, -1):
arr[i], arr[0] = arr[0], arr[i]
# Heapify root element
hea
```
<Overlap Ratio: 0.9296235679214403>

---

--- 200 --
Question ID: ddb1981b4c8e7bc5d1904a336ef584dc10f249a3_0
Original Code:
```
def calculate_errors(out_dir, data, name, naieve_model=True):
  """
  Advanced plotting function for validation of refugee registration numbers in camps.
  """
  plt.clf()

  # data.loc[:,["%s sim" % name,"%s data" % name]]).as_matrix()
  y1 = data["%s sim" % name].as_matrix()

  y2 = data["%s data" % name].as_matrix()
  days = np.arange(len(y1))

  naieve_early_day = 7
  naieve_training_day = 30

  # Rescaled values
  plt.clf()

  plt.xlabel("Days elapsed")
  plt.ylabel("Number of refugees")

  simtot = data["refugees in camps (simulation)"].as_matrix().flatten()
  untot = data["refugees in camps (UNHCR)"].as_matrix().flatten()

  y1_rescaled = np.zeros(len(y1))
  for i in range(0, len(y1_rescaled)):
    # Only rescale if simtot > 0
    if simtot[i] > 0:
      y1_rescaled[i] = y1[i] * untot[i] / simtot[i]

  """
  Error quantification phase:
  - Quantify the errors and mismatches for this camp.
  """

  lerr = dd.LocationErrors()

  # absolute difference
  lerr.errors["absolute difference"] = a.abs_diffs(y1, y2)

  # absolute difference (rescaled)
  lerr.errors["absolute difference rescaled"] = a.abs_diffs(y1_rescaled, y2)

  # ratio difference
  lerr.errors["ratio difference"] = a.abs_diffs(y1, y2) / (np.maximum(untot, np.ones(len(untot))))

  """ Errors of which I'm usure whether to report:
   - accuracy ratio (forecast / true value), because it crashes if denominator is 0.
   - ln(accuracy ratio).
  """

  # We can only calculate the Mean Absolute Scaled Error if we have a naieve model in our plot.
  if naieve_model:

    # Number of observations (aggrgate refugee days in UNHCR data set for this location)
    lerr.errors["N"] = np.sum(y2)

    # flat naieve model (7 day)
    lerr.errors["MASE7"] = a.calculate_MASE(y1_rescaled, y2, n1, naieve_early_day)
    lerr.errors["MASE7-sloped"] = a.calculate_MASE(y1_rescaled, y2, n3, naieve_early_day)
    lerr.errors["MASE7-ratio"] = a.calculate_MASE(y1_rescaled, y2, n5, naieve_early_day)

    # flat naieve model (30 day)
    lerr.errors["MASE30"] = a.calculate_MASE(y1_rescaled, y2, n2, naieve_training_day)
    lerr.errors["MASE30-sloped"] = a.calculate_MASE(y1_rescaled, y2, n4, naieve_training_day)
    lerr.errors["MASE30-ratio"] = a.calculate_MASE(y1_rescaled, y2, n6, naieve_training_day)


    # Accuracy ratio doesn't work because of 0 values in the data.
    print("%s,%s,%s,%s,%s,%s,%s,%s,%s" % (out_dir, name, lerr.errors["MASE7"],lerr.errors["MASE7-sloped"], lerr.errors["MASE7-ratio"],lerr.errors["MASE30"],lerr.errors["MASE30-sloped"],lerr.errors["MASE30-ratio"],lerr.errors["N"]))

  return lerr
```


Overlapping Code:
```
data, name, naieve_model=True):
"""
Advanced plotting function for validation of refugee registration numbers in camps.
"""
plt.clf()
# data.loc[:,["%s sim" % name,"%s data" % name]]).as_matrix()
y1 = data["%s sim" % name].as_matrix()
y2 = data["%s data" % name].as_matrix()
days = np.arange(len(y1))
naieve_early_day = 7
naieve_training_day = 30
# Rescaled values
plt.clf()
plt.xlabel("Days elapsed")
plt.ylabel("Number of refugees")
simtot = data["refugees in camps (simulation)"].as_matrix().flatten()
untot = data["refugees in camps (UNHCR)"].as_matrix().flatten()
y1_rescaled = np.zeros(len(y1))
for i in range(0, len(y1_rescaled)):
# Only rescale if simtot > 0
if simtot[i] > 0:
y1_rescaled[i] = y1[i] * untot[i] / simtot[i]
"""
Error quantification phase:
- Quantify the errors and mismatches for this camp.
"""
lerr = dd.LocationErrors()
# absolute difference
lerr.errors["absolute difference"] = a.abs_diffs(y1, y2)
# absolute difference (rescaled)
lerr.errors["absolute difference rescaled"] = a.abs_diffs(y1_rescaled, y2)
# ratio difference
lerr.errors["ratio difference"] = a.abs_diffs(y1, y2) / (np.maximum(untot, np.ones(len(untot))))
""" Errors of which I'm usure whether to report:
- accuracy ratio (forecast / true value), because it crashes if denominator is 0.
- ln(accuracy ratio).
"""
# We can only calculate the Mean Absolute Scaled Error if we have a naieve model in our plot.
if naieve_model:
# Number of observations (aggrgate refugee days in UNHCR data set for this location)
lerr.errors["N"] = np.sum(y2)
# flat naieve model (7 day)
lerr.errors["MASE7"] = a.calculate_MASE(y1_rescaled, y2, n1, naieve_early_day)
lerr.errors["MASE7-sloped"] = a.calculate_MASE(y1_rescaled, y2, n3, naieve_early_day)
lerr.errors["MASE7-ratio"] = a.calculate_MASE(y1_rescaled, y2, n5, naieve_early_day)
# flat naieve model (30 day)
lerr.errors["MASE30"] = a.calculate_MASE(y1_rescaled, y2, n2, naieve_training_day)
lerr.errors["MASE30-sloped"] = a.calculate_MASE(y1_rescaled, y2, n4, naieve_training_day)
lerr.errors["MASE30-ratio"] = a.calculate_MASE(y1_rescaled, y2, n6, naieve_training_day)
# Accuracy ratio doesn't work because of 0 values in the data.
print("%s,%s,%s,%s,%s,%s,%s,%s,%s" % (out_dir, name, lerr.errors["MASE7"],lerr.errors["MASE7-sloped"], lerr.errors["MASE7-ratio"],lerr.erro
```
<Overlap Ratio: 0.9816709292412618>

---

--- 201 --
Question ID: 01fbb7f8ba1c0a0deed7c2153d9f65d39c329d54_3
Original Code:
```
@forge.copy(request, exclude='method')
def get(url: str, **kwargs) -> Response:
    """Wrapper around :py:func:`requests.get` with additional options specific to iNat API requests"""
    return request('GET', url, **kwargs)
```


Overlapping Code:
```
est, exclude='method')
def get(url: str, **kwargs) -> Response:
"""Wrapper around :py:func:`requests.get` with additional options specific to iNat API requests"""
return
```
<Overlap Ratio: 0.786046511627907>

---

--- 202 --
Question ID: 22e6d0f2b2f477b57e84f0fd4e65d192146364a6_2
Original Code:
```
def test_output_module():
    # pylint: disable=no-value-for-parameter

    @module()
    def o1(wf: FugueWorkflow, df: WorkflowDataFrame) -> None:
        pass

    @module()
    def o2(wf: FugueWorkflow, df: WorkflowDataFrame):
        pass

    @module()
    def o3(df: WorkflowDataFrame):
        pass

    assert o1.has_input
    assert o1.has_no_output
    assert o2.has_no_output
    assert o3.has_no_output

    with FugueWorkflow() as dag:
        df = dag.df([[0]], "a:int")
        o1(df)
        o1(dag, df)
        o2(df=df)
        o2(df=df, wf=dag)
        o3(df)
```


Overlapping Code:
```
_module():
# pylint: disable=no-value-for-parameter
@module()
def o1(wf: FugueWorkflow, df: WorkflowDataFrame) -> None:
pass
@module()
def o2(wf: FugueWorkflow, df: WorkflowDataFrame):
pass
@module()
def o3(df: WorkflowDataFrame):
pass
assert o1.has_input
assert o1.has_no_output
assert o2.has_no_output
assert o3.has_no_output
with FugueWorkflow() as dag:
df = dag.df([[0]], "a:int")
o1(df)
o1(dag, df)
o2(df=df)
o2(df=df, wf=dag)

```
<Overlap Ratio: 0.9536423841059603>

---

--- 203 --
Question ID: 84f8fc5c7345ece989d9ee94ac87753dd2301118_3
Original Code:
```
def test_name_error():
    with pytest.raises(NameError):
        iceberg(2, 3)
    with pytest.raises(NameError):
        chocolat()
    with pytest.raises(NameError):
        wishful_thinking()
```


Overlapping Code:
```
pytest.raises(NameError):
iceberg(2, 3)
with pytest.raises(NameError):
chocolat()
with pytest.raises
```
<Overlap Ratio: 0.6289308176100629>

---

--- 204 --
Question ID: 77323326a3a05ef5b71a17f3de780ad88fadd947_6
Original Code:
```
def createPlugMatrixFromCells( cellPlugs ) :

	if not cellPlugs :
		return []

	rowsPlug = next( iter( cellPlugs ) ).ancestor( Gaffer.Spreadsheet.RowsPlug )
	assert( rowsPlug is not None )

	# Build a matrix of rows/columns in ascending order. We don't actually
	# care what the original row/column indices were, we just need them
	# to be ascending so the matrix represents the logical order of the cells.

	matrix = []

	# First, group cells by row
	rows = {}
	for cell in cellPlugs :
		rowPlug = cell.ancestor( Gaffer.Spreadsheet.RowPlug )
		rows.setdefault( rowPlug, [] ).append( cell )

	# Then sort the rows, and their cells
	spreadsheetRows = rowsPlug.children()
	for rowPlug, cells in sorted( rows.items(), key = lambda item : spreadsheetRows.index( item[0] ) ) :
		rowCells = rowPlug["cells"].children()
		matrix.append( sorted( cells, key = rowCells.index ) )

	return matrix
```


Overlapping Code:
```
ls( cellPlugs ) :
if not cellPlugs :
return []
rowsPlug = next( iter( cellPlugs ) ).ancestor( Gaffer.Spreadsheet.RowsPlug )
assert( rowsPlug is not None )
# Build a matrix of rows/columns in ascending order. We don't actually
# care what the original row/column indices were, we just need them
# to be ascending so the matrix represents the logical order of the cells.
matrix = []
# First, group cells by row
rows = {}
for cell in cellPlugs :
rowPlug = cell.ancestor( Gaffer.Spreadsheet.RowPlug )
rows.setdefault( rowPlug, [] ).append( cell )
# Then sort the rows, and their cells
spreadsheetRows = rowsPlug.children()
for rowPlug, cells in sorted( rows.items(), key = lambda item : spreadsheetRows.index( item[0] ) ) :
rowCells = rowPlug["cells"].children()
matrix.append( sorted( cells, key = rowCe
```
<Overlap Ratio: 0.936768149882904>

---

--- 205 --
Question ID: e380ab1cf72d434e091b2184598c6076464be8c6_2
Original Code:
```
def process_docs(obj):
    term_set = set()
    for doc in obj:
        if doc['fields']['title'] and doc['fields']['content']:
            for term in clean_text(doc['fields']['title']):
                term_set.add(term)
            for term in clean_text(doc['fields']['content']):
                term_set.add(term)
    return term_set
```


Overlapping Code:
```
c in obj:
if doc['fields']['title'] and doc['fields']['content']:
for term in clean_text(doc['fields']['title']):
term_set.add(term)
for term in clean_text(doc['fields']['content']):
term_set.add(term
```
<Overlap Ratio: 0.7604562737642585>

---

--- 206 --
Question ID: 0293e80c48b061bbfb371c95ece0b2a540942771_0
Original Code:
```
def getSSIM(X, Y):
    """
       Computes the mean structural similarity between two images.
    """
    assert (X.shape == Y.shape), "Image-patche provided have different dimensions"
    nch = 1 if X.ndim==2 else X.shape[-1]
    mssim = []
    for ch in xrange(nch):
        Xc, Yc = X[...,ch].astype(np.float64), Y[...,ch].astype(np.float64)
        mssim.append(compute_ssim(Xc, Yc))
    return np.mean(mssim)
```


Overlapping Code:
```
"
Computes the mean structural similarity between two images.
"""
assert (X.shape == Y.shape), "Image-patche provided have different dimensions"
nch = 1 if X.ndim==2 else X.shape[-1]
mssim = []
for ch in xrange(nch):
Xc, Yc = X[...,ch].astype(np.float64), Y[...,ch].astype(np.float64)
mssim.append(compute_ssim(Xc, Yc
```
<Overlap Ratio: 0.8756906077348067>

---

--- 207 --
Question ID: 90fef6f12ab0bafddd9352b19305a81838bbe3af_11
Original Code:
```
def setsUsed():
    low_estimate = {
        'non_crit_care': 6,
        'crit_care': 12,
        'crit_care_vent': 12
        }
    
    high_estimate = {
        'non_crit_care': 30,
        'crit_care': 50,
        'crit_care_vent': 50,
        }
    
    mean_estimate = {}
    for key in low_estimate:
        mean_estimate[key] = (low_estimate[key] + high_estimate[key])/2
    
    output = {
        'low_estimate': low_estimate,
        'mean_estimate': mean_estimate,
        'high_estimate': high_estimate
        }
    return(output)
```


Overlapping Code:
```
def setsUsed():
low_estimate = {
'non_crit_care': 6,
'crit_care': 12,
'crit_care_vent': 12
}

high_estimate = {
'non_crit_care': 30,
'crit_care': 50,
'crit_care_vent': 50,
}

mean_estimate = {}
for key in low_estimate:
mean_estimate[key] = (low_estimate[key] + high_estimate[key])/2

output = {
'low_estimate': low_estimate,
'mean_estimate': mean_estimate,
'high_estimate': high_estimate
}
return(out
```
<Overlap Ratio: 0.9900990099009901>

---

--- 208 --
Question ID: dfbcde33b8f8a4375d2b0ef35d57cd76d7507544_7
Original Code:
```
def is_request_correct(url: str,
                       p_count: int,
                       **kwargs) -> Tuple[str, str]:
    """
    Check:
         is the HTTP request correct (means there are no exceptions catch).

         has there been any result.

         does a page at the number exist (
        means RNC doesn't redirect to the first page).

    :return: first and last pages if everything's OK.

    :exception WrongHTTPRequest: HTTP request is wrong.
    :exception NoResultFound: no result found.
    :exception LastPageDoesntExist: the last page doesn't exist.
    """
    logger.debug("Validating that everything is OK")
    try:
        # to reduce the number of requests
        # the two checks are combined into one.
        # coro writes logs by itself
        first_page = whether_result_found(url, **kwargs)
    except ValueError:
        logger.error("HTTP request is OK, but no result found")
        raise NoResultFound(f"{kwargs}")
    except RuntimeError:
        logger.error("HTTP request is wrong")
        raise WrongHTTPRequest(f"{kwargs}")
    logger.debug("HTTP request is correct, result found")

    logger.debug("Validating that the last page exists")
    try:
        last_page = does_page_exist(url, p_count - 1, first_page, **kwargs)
    except ValueError:
        logger.error("Everything is OK, but last page doesn't exist")
        raise LastPageDoesntExist(f"{kwargs}")
    logger.debug("The last page exists")

    logger.debug("Validated successfully")
    return first_page, last_page
```


Overlapping Code:
```
s_request_correct(url: str,
p_count: int,
**kwargs) -> Tuple[str, str]:
"""
Check:
 is the HTTP request correct (means there are no exceptions catch).
 has there been any result.
 does a page at the number exist (
means RNC doesn't redirect to the first page).
:return: first and last pages if everything's OK.
:exception WrongHTTPRequest: HTTP request is wrong.
:exception NoResultFound: no result found.
:exception LastPageDoesntExist: the last page doesn't exist.
"""
logger.debug("Validating that everything is OK")
try:
# to reduce the number of requests
# the two checks are combined into one.
# coro writes logs by itself
first_page = whether_result_found(url, **kwargs)
except ValueError:
logger.error("HTTP request is OK, but no result found")
raise NoResultFound(f"{kwargs}")
except RuntimeError:
logger.error("HTTP request is wrong")
raise WrongHTTPRequest(f"{kwargs}")
logger.debug("HTTP request is correct, result found")
logger.debug("Validating that the last page exists")
try:
last_page = does_page_exist(url, p_count - 1, first_page, **kwargs)
except ValueError:
logger.error("Everything is OK, but last page doesn't exist")
raise LastPageDoesntExist(f"{kwargs}")
logger.debug("The last page exists")
logger.debug("Validated succe
```
<Overlap Ratio: 0.9667440061871616>

---

--- 209 --
Question ID: 13090ccb72c3bc99b86692ede57bce6f59e560d8_18
Original Code:
```
def test_disjuncts():
    assert disjuncts(A | B | C) == {A, B, C}
    assert disjuncts((A | B) & C) == {(A | B) & C}
    assert disjuncts(A) == {A}
    assert disjuncts(True) == {True}
    assert disjuncts(False) == {False}
```


Overlapping Code:
```
_disjuncts():
assert disjuncts(A | B | C) == {A, B, C}
assert disjuncts((A | B) & C) == {(A | B) & C}
assert disjuncts(A) == {A}
assert disjuncts(True
```
<Overlap Ratio: 0.7352941176470589>

---

--- 210 --
Question ID: c7b5f06e69efa7b2fbbec77ca3b81d61b34645a9_20
Original Code:
```
@lower_builtin("set.difference_update", types.Set, types.IterableType)
def set_difference_update(context, builder, sig, args):
    inst = SetInstance(context, builder, sig.args[0], args[0])
    other = SetInstance(context, builder, sig.args[1], args[1])

    inst.difference(other)

    return context.get_dummy_value()
```


Overlapping Code:
```
.Set, types.IterableType)
def set_difference_update(context, builder, sig, args):
inst = SetInstance(context, builder, sig.args[0], args[0])
other = SetInstance(context, builder, sig.args[1], args[1])
inst.difference(other)
return context.get_dummy_v
```
<Overlap Ratio: 0.8305647840531561>

---

--- 211 --
Question ID: 52394c2d903832ac2b591631e658422fa845379a_0
Original Code:
```
@pytest.fixture(autouse=True)
def mocked_logger(logger):
    with patch.object(default_network, 'getLogger') as get_logger:
        get_logger.return_value = logger
        yield
```


Overlapping Code:
```
(autouse=True)
def mocked_logger(logger):
with patch.object(default_network, 'getLogger') as get_log
```
<Overlap Ratio: 0.6329113924050633>

---

--- 212 --
Question ID: 56786380a0d7d8275e172fb97f1f3f9d7e83b7a6_4
Original Code:
```
def mapping_match_logical():
    """ Test matching of mapping type"""
    boats = [
        {"": 1, },
        {"": 1, "": 1},
        {"": 1, "": 1},
        {"": 1, "": 1},
    ]
    problems = 0
    valid_boats = 0
    for _ in range(100_000):
        for boat in boats:
            if isinstance(boat, Mapping):
                if "" in boat and "" in boat: 
                    problems += 1
                elif "" in boat and "" in boat: 
                    problems += 1
                else:
                    valid_boats += 1
                    
    
    assert valid_boats == 200_000
    assert problems == 200_000
```


Overlapping Code:
```
 of mapping type"""
boats = [
{"": 1, },
{"": 1, "": 1},
{"": 1, "": 1},
{"": 1, "": 1},
]
problems = 0
valid_boats = 0
for _ in range(100_000):
for boat in boats:
if isinstance(boat, Mapping):
if "" in boat and "" in boat: 
problems += 1
elif "" in boat and "" in boat: 
problems += 1
else:
valid_boats += 1


assert valid_boats == 200_00
```
<Overlap Ratio: 0.8254716981132075>

---

--- 213 --
Question ID: 7b183455173c94b859ab17b3874decf7cbfd4efd_0
Original Code:
```
def test_run_fixed_height(monkeypatch):
    monkeypatch.setattr(SymbolsTable, "__len__", lambda _: 80)
    model = run(
        syms=None,
        fixed_input_height=128,
        save_model=False,
        crnn=CreateCRNNArgs(
            cnn_num_features=[16, 32, 48, 64, 80],
            cnn_kernel_size=[3] * 5,
            cnn_stride=[1] * 5,
            cnn_dilation=[1] * 5,
            cnn_activation=["LeakyReLU"] * 5,
            cnn_poolsize=[2] * 3 + [0] * 2,
            cnn_dropout=[0] * 5,
            cnn_batchnorm=[False] * 5,
            rnn_layers=5,
        ),
    )
    assert isinstance(model, LaiaCRNN)
    assert sum(param.numel() for param in model.parameters()) == 9591248
```


Overlapping Code:
```
ight(monkeypatch):
monkeypatch.setattr(SymbolsTable, "__len__", lambda _: 80)
model = run(
syms=None,
fixed_input_height=128,
save_model=False,
crnn=CreateCRNNArgs(
cnn_num_features=[16, 32, 48, 64, 80],
cnn_kernel_size=[3] * 5,
cnn_stride=[1] * 5,
cnn_dilation=[1] * 5,
cnn_activation=["LeakyReLU"] * 5,
cnn_poolsize=[2] * 3 + [0] * 2,
cnn_dropout=[0] * 5,
cnn_batchnorm=[False] * 5,
rnn_layers=5,
),
)
assert isinstance(model, LaiaCRNN)
assert sum(param.numel() for param in model.parameters()) == 
```
<Overlap Ratio: 0.946969696969697>

---

--- 214 --
Question ID: aa0b4ad8a7193b7baa10b68fef04ad9e37be1322_1
Original Code:
```
def run():
    pi = PI()
    checks = {}
    for x, y in zip(range(1000), pi):
        #print y,
        if x in tests:
            checks[x] = pi.a1
    if tests != checks:
        raise RuntimeError
```


Overlapping Code:
```

```
<Overlap Ratio: 0.0>

---

--- 215 --
Question ID: 5606c775e10a113b5417ebfffdb1eb92ea97e92f_0
Original Code:
```
def make_deck(model, feature, words):
    deckid = int(hashlib.sha256(feature.title.encode('utf-8')).hexdigest(), 16) % 10**8
    deck = genanki.Deck(deckid, feature.title)

    for key, g in itertools.groupby(sorted(words, key=feature.key), key=feature.key):
        similar = list(g)
        if len(similar) == 1:
            continue

        print(key)
        similar = sorted(similar, key=lambda w:w['text'])
        print(similar)

        extra = '<br>'.join([f'''
<div style="vertical-align: middle; font-size: 1em; font-family: Arial">
    [{s["text"]}]&nbsp;
    <audio style="vertical-align: middle;" src="{s["audio"]}" controls></audio>
</div>
        ''' for s in similar])

        for s in similar:
            note = MinimalPairNote(model=model, fields=[s['text'], s['audio'], extra])
            deck.add_note(note)

    return deck
```


Overlapping Code:
```
eck(model, feature, words):
deckid = int(hashlib.sha256(feature.title.encode('utf-8')).hexdigest(), 16) % 10**8
deck = genanki.Deck(deckid, feature.title)
for key, g in itertools.groupby(sorted(words, key=feature.key), key=feature.key):
similar = list(g)
if len(similar) == 1:
continue
print(key)
similar = sorted(similar, key=lambda w:w['text'])
print(similar)
extra = '<br>'.join([f'''
<div style="vertical-align: middle; font-size: 1em; font-family: Arial">
[{s["text"]}]&nbsp;
<audio style="vertical-align: middle;" src="{s["audio"]}" controls></audio>
</div>
''' for s in similar])
for s in similar:
note = MinimalPairNote(model=model, fields=[s['text'], s['audio'], extra])
deck.add_note(note)

```
<Overlap Ratio: 0.970873786407767>

---

--- 216 --
Question ID: be5edd2ed3399ba1a7d889c69adee44b2d7cae6e_1
Original Code:
```
def submit(args):
    """Submission script with MPI."""
    def mpi_submit(nworker, nserver, pass_envs):
        """Internal closure for job submission."""
        def run(prog):
            """run the program"""
            subprocess.check_call(prog, shell=True)

        cmd = ''
        if args.host_file is not None:
            cmd = '--hostfile %s ' % (args.host_file)
        cmd += ' ' + ' '.join(args.command)

        pass_envs['DMLC_JOB_CLUSTER'] = 'mpi'

        # start workers
        if nworker > 0:
            logging.info('Start %d workers by mpirun' % nworker)
            pass_envs['DMLC_ROLE'] = 'worker'
            prog = 'mpirun -n %d %s %s' % (nworker, get_mpi_env(pass_envs), cmd)
            thread = Thread(target=run, args=(prog,))
            thread.setDaemon(True)
            thread.start()


        # start servers
        if nserver > 0:
            logging.info('Start %d servers by mpirun' % nserver)
            pass_envs['DMLC_ROLE'] = 'server'
            prog = 'mpirun -n %d %s %s' % (nserver, get_mpi_env(pass_envs), cmd)
            thread = Thread(target=run, args=(prog,))
            thread.setDaemon(True)
            thread.start()


    tracker.submit(args.num_workers, args.num_servers,
                   fun_submit=mpi_submit,
                   pscmd=(' '.join(args.command)))
```


Overlapping Code:
```
 MPI."""
def mpi_submit(nworker, nserver, pass_envs):
"""Internal closure for job submission."""
def run(prog):
"""run the program"""
subprocess.check_call(prog, shell=True)
cmd = ''
if args.host_file is not None:
cmd = '--hostfile %s ' % (args.host_file)
cmd += ' ' + ' '.join(args.command)
pass_envs['DMLC_JOB_CLUSTER'] = 'mpi'
# start workers
if nworker > 0:
logging.info('Start %d workers by mpirun' % nworker)
pass_envs['DMLC_ROLE'] = 'worker'
prog = 'mpirun -n %d %s %s' % (nworker, get_mpi_env(pass_envs), cmd)
thread = Thread(target=run, args=(prog,))
thread.setDaemon(True)
thread.start()
# start servers
if nserver > 0:
logging.info('Start %d servers by mpirun' % nserver)
pass_envs['DMLC_ROLE'] = 'server'
prog = 'mpirun -n %d %s %s' % (nserver, get_mpi_env(pass_envs), cmd)
thread = Thread(target=run, args=(prog,))
thread.setDaemon(True)
thread.start()
tracker.submit(args.num_workers, args.num_servers,
fun_submit=mpi_submit,
pscmd=(' '
```
<Overlap Ratio: 0.9368836291913215>

---

--- 217 --
Question ID: 544e6f379b865573cbab1bed2ad04c56669e1ffb_0
Original Code:
```
def source(*functions):
    """ source a script as if we have written the script in jupyter notebook and executed it """
    source_code = '\n\n'.join(getsource(fn) for fn in functions)        
    display(HTML(highlight(source_code, PythonLexer(), HtmlFormatter(full=True))))
```


Overlapping Code:
```
e(*functions):
""" source a script as if we have written the script in jupyter notebook and executed it """
source_code = '\n\n'.join(getsource(fn) for fn in functions) 
display(HTML(highlight(source_code, PythonLexer(), HtmlFormatter(full=True)))
```
<Overlap Ratio: 0.9610894941634242>

---

--- 218 --
Question ID: 54de69c10ff19fc60274fe2184fd43c2dc2dcc57_13
Original Code:
```
def test_band_edge_w_options():
    parsed_args = parse_args(["be",
                              "--vasprun", "vasprun_1",
                              "--outcar", "OUTCAR_1",
                              ])

    expected = Namespace(
        vasprun=Path("vasprun_1"),
        outcar=Path("OUTCAR_1"),
        func=parsed_args.func,
    )

    assert parsed_args == expected
```


Overlapping Code:
```
_options():
parsed_args = parse_args(["be",
"--vasprun", "vasprun_1",
"--outcar", "OUTCAR_1",
])
expected = Namespace(
vasprun=Path("vasprun_1"),
outcar=Path("OUTCAR_1"),
func=parsed_args.func,
)
assert parsed_args == expect
```
<Overlap Ratio: 0.9105691056910569>

---

--- 219 --
Question ID: 179976f93f8ed949a4c2f33e9d7f71db73794fa5_3
Original Code:
```
@main.command()
@click.argument("name")
def create_queue(name):
    """Create queue with NAME supplied as argument"""
    queue = create(name)
    logger.info(queue.url)
```


Overlapping Code:
```
and()
@click.argument("name")
def create_queue(name):
"""Create queue with NAME supplied as argument
```
<Overlap Ratio: 0.6369426751592356>

---

--- 220 --
Question ID: 444ebb538831c94b107893d873af3b0de5c75481_0
Original Code:
```
def parse_tree_string(parsetree, indent=None, b64_source=True, indent_level=0, debug=False):
    indent_str = (' ' * indent * indent_level) if indent else ''
    if isinstance(parsetree, ParseTree):
        children = [parse_tree_string(child, indent, b64_source, indent_level+1, debug) for child in parsetree.children]
        debug_str = parsetree.debug_str() if debug else ''
        if indent is None or len(children) == 0:
            return '{0}({1}: {2}{3})'.format(indent_str, parsetree.nonterminal, debug_str, ', '.join(children))
        else:
            return '{0}({1}:{2}\n{3}\n{4})'.format(
                indent_str,
                parsetree.nonterminal,
                debug_str,
                ',\n'.join(children),
                indent_str
            )
    elif isinstance(parsetree, Terminal):
        return indent_str + parsetree.dumps(b64_source=b64_source)
```


Overlapping Code:
```
ef parse_tree_string(parsetree, indent=None, b64_source=True, indent_level=0, debug=False):
indent_str = (' ' * indent * indent_level) if indent else ''
if isinstance(parsetree, ParseTree):
children = [parse_tree_string(child, indent, b64_source, indent_level+1, debug) for child in parsetree.children]
debug_str = parsetree.debug_str() if debug else ''
if indent is None or len(children) == 0:
return '{0}({1}: {2}{3})'.format(indent_str, parsetree.nonterminal, debug_str, ', '.join(children))
else:
return '{0}({1}:{2}\n{3}\n{4})'.format(
indent_str,
parsetree.nonterminal,
debug_str,
',\n'.join(children),
indent_str
)
elif isinstance(parsetree, Terminal):
return indent_str + parsetree.dumps(b64_so
```
<Overlap Ratio: 0.9763560500695411>

---

--- 221 --
Question ID: 8389609a0770baef5ec3de86e8b1a0f846cd6521_0
Original Code:
```
def random_shuffle(a):
    keys = list(a.keys())
    values = list(a.values())
    random.shuffle(values)
    return dict(zip(keys, values))
```


Overlapping Code:
```
= list(a.keys())
values = list(a.values())
random.shuffle(valu
```
<Overlap Ratio: 0.5>

---

--- 222 --
Question ID: 22cb200f94f200cb58be445266a937b6c09f6a50_8
Original Code:
```
@pytest.mark.parametrize(
    "command",
    [
        "iothub setup --update-dotenv",
        ""
    ]
)
def test_is_terse_command_true(command):
    envvars = EnvVars(Output())
    assert envvars.is_terse_command(command)
```


Overlapping Code:
```
ize(
"command",
[
"iothub setup --update-dotenv",
""
]
)
def test_is_terse_command_true(command):
envvars = EnvVars(Output())
assert envvars.is_terse_
```
<Overlap Ratio: 0.8021390374331551>

---

--- 223 --
Question ID: d24cef7ccf5f7221c75cc27b06e15f148aa63ee8_3
Original Code:
```
def fetchable_genetics(projects: bool = False) -> List[str]:
    """
    Lists genetics data available to download from the PPMI

    Parameters
    ----------
    projects : bool, optional
        List available projects instead of individual data files available for
        download. Due to the size of genetic data, many datasets are split up
        into multiple files associated with a single project or analysis; you
        can specify these projects when downloading data with
        :py:func:`pypmi.datasets.fetch_genetics` and all associated files
        will be fetched.

    Returns
    -------
    available : list
        List of available data files

    See Also
    --------
    pypmi.fetch_genetics
    """

    if projects:
        return ['project {}'.format(project)
                for project in [107, 108, 115, 116, 118, 120, 133]]
    else:
        return list(_GENETICS.keys())
```


Overlapping Code:
```
bool = False) -> List[str]:
"""
Lists genetics data available to download from the PPMI
Parameters
----------
projects : bool, optional
List available projects instead of individual data files available for
download. Due to the size of genetic data, many datasets are split up
into multiple files associated with a single project or analysis; you
can specify these projects when downloading data with
:py:func:`pypmi.datasets.fetch_genetics` and all associated files
will be fetched.
Returns
-------
available : list
List of available data files
See Also
--------
pypmi.fetch_genetics
"""
if projects:
return ['project {}'.format(project)
for project in [107, 108, 115, 116, 118, 120, 133]]
else:
ret
```
<Overlap Ratio: 0.922266139657444>

---

--- 224 --
Question ID: efd9f141956a681544d2a8c593883fc80424006a_22
Original Code:
```
async def test_connect_via_socket(smtp_client, hostname, smtpd_server_port):
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
        sock.connect((hostname, smtpd_server_port))

        await smtp_client.connect(hostname=None, port=None, sock=sock)
        response = await smtp_client.ehlo()

    assert response.code == SMTPStatus.completed
```


Overlapping Code:
```
smtp_client, hostname, smtpd_server_port):
with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
sock.connect((hostname, smtpd_server_port))
await smtp_client.connect(hostname=None, port=None, sock=sock)
response = await smtp_client.ehlo()
assert response.code == SMTPStatus.completed
```
<Overlap Ratio: 0.8963414634146342>

---

--- 225 --
Question ID: 60be9dffe436cdf54010f0d4755f320c0cdfc886_7
Original Code:
```
def create_model_optimizer_autoencoder(args, dataset_class):
    model = ResnetAutoencoder(z_dim=args.autoencoder_z_dim, num_classes=dataset_class.num_classes,
                              drop_rate=args.drop_rate, input_size=dataset_class.input_size)

    model = model.cuda()

    if args.autoencoder_resume:
        model, _, _ = resume_model(args, model)
        args.start_epoch = args.autoencoder_train_epochs

    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)

    return model, optimizer, args
```


Overlapping Code:
```
izer_autoencoder(args, dataset_class):
model = ResnetAutoencoder(z_dim=args.autoencoder_z_dim, num_classes=dataset_class.num_classes,
drop_rate=args.drop_rate, input_size=dataset_class.input_size)
model = model.cuda()
if args.autoencoder_resume:
model, _, _ = resume_model(args, model)
args.start_epoch = args.autoencoder_train_epochs
optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)
retu
```
<Overlap Ratio: 0.8948545861297539>

---

--- 226 --
Question ID: b7cb1896adbb88a7924c3d4e797379a7c6fc0e14_0
Original Code:
```
def wait_for(success, timeout=TIMEOUT):
    start_time = time.time()
    interval = 0.25
    while not success() and time.time() < start_time + timeout:
        time.sleep(interval)
        interval *= 2
        if interval > 5:
            interval = 5
    if time.time() > start_time + timeout:
        raise ValueError("Timeout waiting for {}", success)
```


Overlapping Code:
```
f wait_for(success, timeout=TIMEOUT):
start_time = time.time()
interval = 0.25
while not success() and time.time() < start_time + timeout:
time.sleep(interval)
interval *= 2
if interval > 5:
interval = 5
if time.time() > start_time + timeout:
raise ValueError("Tim
```
<Overlap Ratio: 0.8918918918918919>

---

--- 227 --
Question ID: 35a867bf320b7148d51ea802a41172abbd344eef_0
Original Code:
```
def start(run_type, n_runs=1, n_cores=-2, **kwargs):
    """run the simulation as a subprocess,
    which makes it easier to manage"""

    if is_running():
        raise Exception('Simulation is already running.')

    if run_type not in RUN_TYPES:
        raise Exception('Not a valid run type: "{}".'.format(run_type))

    if run_type == 'sensitivity':
        params = [s.strip() for s in kwargs['sensitivity_params'].split('\n') if s.strip()]
    else:
        params = []

    cmd = [
        'python',
        'main.py',
        '-n', str(n_runs),
        '-c', str(n_cores),
        '-p', kwargs['params'],
        '-r', kwargs['config'],
        run_type
    ]
    cmd.extend(params)
    with open(LOG_FILE, 'w+') as f:
        kwargs = {
            'stdout': f,
            'stderr': subprocess.STDOUT,
        }
        if WINDOWS:
            kwargs['creationflags'] = subprocess.CREATE_NEW_PROCESS_GROUP
        else:
            kwargs['preexec_fn'] = os.setsid
        ps = subprocess.Popen(cmd, **kwargs)
    with open(PID_FILE, 'w') as f:
        f.write(str(ps.pid))
```


Overlapping Code:
```
, n_runs=1, n_cores=-2, **kwargs):
"""run the simulation as a subprocess,
which makes it easier to manage"""
if is_running():
raise Exception('Simulation is already running.')
if run_type not in RUN_TYPES:
raise Exception('Not a valid run type: "{}".'.format(run_type))
if run_type == 'sensitivity':
params = [s.strip() for s in kwargs['sensitivity_params'].split('\n') if s.strip()]
else:
params = []
cmd = [
'python',
'main.py',
'-n', str(n_runs),
'-c', str(n_cores),
'-p', kwargs['params'],
'-r', kwargs['config'],
run_type
]
cmd.extend(params)
with open(LOG_FILE, 'w+') as f:
kwargs = {
'stdout': f,
'stderr': subprocess.STDOUT,
}
if WINDOWS:
kwargs['creationflags'] = subprocess.CREATE_NEW_PROCESS_GROUP
else:
kwargs['preexec_fn'] = os.setsid
ps = subprocess.Popen(cmd, **kwargs)
with open(PID_F
```
<Overlap Ratio: 0.936768149882904>

---

--- 228 --
Question ID: b53e5b32b9de322459deba00499085812a761241_6
Original Code:
```
def create_library_changelog():
    log('CHANGELOG')
    log('-----------------------------------------------------------------------', True)
    initialize_global_params_from_config_file()
    if current_export_file:
        previous_song_rows = []
        current_song_rows = []
        if previous_export_file:
            log('Previous export file: ')
            log(os.path.abspath(previous_export_file))
            previous_song_rows.extend(import_track_records_from_csv_file(previous_export_file))
        log('\nCurrent export file: ')
        log(os.path.abspath(current_export_file))
        current_song_rows.extend(import_track_records_from_csv_file(current_export_file))
        log('\nFiles loaded successfully, Creating changelog...', True)

        track_matches = create_match_results(previous_song_rows, current_song_rows)
        duplicates = create_duplicates_results(current_song_rows)

        changelog_results = track_matches + duplicates
        # setup the output directory, create it if needed
        create_dir_if_not_exist(output_dir)
        filename = export_track_matches_to_csv_file(changelog_results)
        log('Changelog has been created. File with results has been saved in:')
        log(filename, True)
    else:
        log('Changelog cannot be created. Previous and Current Export files not found.', True)
```


Overlapping Code:
```
log('CHANGELOG')
log('-----------------------------------------------------------------------', True)
initialize_global_params_from_config_file()
if current_export_file:
previous_song_rows = []
current_song_rows = []
if previous_export_file:
log('Previous export file: ')
log(os.path.abspath(previous_export_file))
previous_song_rows.extend(import_track_records_from_csv_file(previous_export_file))
log('\nCurrent export file: ')
log(os.path.abspath(current_export_file))
current_song_rows.extend(import_track_records_from_csv_file(current_export_file))
log('\nFiles loaded successfully, Creating changelog...', True)
track_matches = create_match_results(previous_song_rows, current_song_rows)
duplicates = create_duplicates_results(current_song_rows)
changelog_results = track_matches + duplicates
# setup the output directory, create it if needed
create_dir_if_not_exist(output_dir)
filename = export_track_matches_to_csv_file(changelog_results)
log('Changelog has been created. File with results has been saved in:')
log(filename, True)
else:
log('Changelog cannot be created. Previous and Current
```
<Overlap Ratio: 0.9450171821305842>

---

--- 229 --
Question ID: 5379a06205929b39569693f7b2e2e97805dedd9b_1
Original Code:
```
def get_class_property_groups(df):
    """
    :param df:
    :return: d, Counter
        d: {
            "<concept> <property>": "<concept>/<property_fname>",
        },
        Counter: number of rows for each concept/property combination
            of "<concept>/<property_fname>"
    """
    d = dict()
    counts = []
    for idx, row in df.iterrows():
        c = row["concept"]
        ps = row["property"].split(';')
        prev_identified = None
        v = "%s/%s" % (c, uri_to_fname(ps[0]).replace('-', ':'))
        for p in ps:
            k = c + " " + p
            if k in d:
                prev_identified = d[k]
                break
            d[k] = v

        if prev_identified:
            # print("picking a prev-identified\t%s\t%d" % (prev_identified, idx))
            v = prev_identified
            for p in ps:
                k = c + " " + p
                d[k] = prev_identified
        counts.append(v)
    return d, Counter(counts)
```


Overlapping Code:
```
f get_class_property_groups(df):
"""
:param df:
:return: d, Counter
d: {
"<concept> <property>": "<concept>/<property_fname>",
},
Counter: number of rows for each concept/property combination
of "<concept>/<property_fname>"
"""
d = dict()
counts = []
for idx, row in df.iterrows():
c = row["concept"]
ps = row["property"].split(';')
prev_identified = None
v = "%s/%s" % (c, uri_to_fname(ps[0]).replace('-', ':'))
for p in ps:
k = c + " " + p
if k in d:
prev_identified = d[k]
break
d[k] = v
if prev_identified:
# print("picking a prev-identified\t%s\t%d" % (prev_identified, idx))
v = prev_identified
for p in ps:
k = c + " " + p
d[k] = prev_identifi
```
<Overlap Ratio: 0.9325681492109039>

---

--- 230 --
Question ID: 43ecd69050205d1c564f3004cec59babbcd04602_0
Original Code:
```
def wrapper_render_one_anno(dir_prefix, gameid, anno_id):
    print('Running Scripts::Make_One_Annotation:wrapper_render_one_anno')
    ### Load game
    print ('Loading')
    game_basename = gameid+'.pkl'

    game_pkl = os.path.join(game_dir, game_basename)
    with open(game_pkl,'rb') as f:
        raw_data = pd.read_pickle(f)
    game_str = "{visitor}@{home}, on {date}".format(
        visitor=raw_data['events'][0]['visitor']['abbreviation'],
        home=raw_data['events'][0]['home']['abbreviation'],
        date=raw_data['gamedate']
    )
    print (game_str)


    ### Create a new directory for videos
    vid_dir =os.path.join(game_dir, 'video') # base dir that holds all the videos
    if not os.path.exists(vid_dir):
        os.makedirs(vid_dir)

    new_dir = os.path.join(vid_dir, '{prefix}-{game_id}'.format(
        prefix=dir_prefix,
        game_id=game_basename.split('.')[0]
    ))
    previous_rendered_events = []
    if not os.path.exists(new_dir):
        os.makedirs(new_dir)
    else: # already a directory exists, likely we've tried to do the same thing
        print(new_dir)
        print('Already exists, not rerunning events rendered and saved previously')

    render_one_anno(
        raw_data,
        new_dir,
        anno_id
    )
```


Overlapping Code:
```
no(dir_prefix, gameid, anno_id):
print('Running Scripts::Make_One_Annotation:wrapper_render_one_anno')
### Load game
print ('Loading')
game_basename = gameid+'.pkl'
game_pkl = os.path.join(game_dir, game_basename)
with open(game_pkl,'rb') as f:
raw_data = pd.read_pickle(f)
game_str = "{visitor}@{home}, on {date}".format(
visitor=raw_data['events'][0]['visitor']['abbreviation'],
home=raw_data['events'][0]['home']['abbreviation'],
date=raw_data['gamedate']
)
print (game_str)
### Create a new directory for videos
vid_dir =os.path.join(game_dir, 'video') # base dir that holds all the videos
if not os.path.exists(vid_dir):
os.makedirs(vid_dir)
new_dir = os.path.join(vid_dir, '{prefix}-{game_id}'.format(
prefix=dir_prefix,
game_id=game_basename.split('.')[0]
))
previous_rendered_events = []
if not os.path.exists(new_dir):
os.makedirs(new_dir)
else: # already a directory exists, likely we've tried to do the same thing
print(new_dir)
print('Already exists, not rerunning events rendered and saved previously')
render_one_anno(
raw_data,
new_dir
```
<Overlap Ratio: 0.9668508287292817>

---

--- 231 --
Question ID: 069480b4526cb83e33845af661111e3bb7696a46_5
Original Code:
```
def list_services(conn):
    print("List Services:")

    for service in conn.identity.services():
        print(service)
```


Overlapping Code:
```
st_services(conn):
print("List Services:")
for ser
```
<Overlap Ratio: 0.4807692307692308>

---

--- 232 --
Question ID: 5eaa1bfa518d7c8c59715f469c49473f89282dc4_4
Original Code:
```
def eq(args):
    args = valueify(args)
    if len(args) != 2: raise MethodInputError("Incorrect number of inputs, should be 2, %s were given" % len(args))
    return tokenz.Token("bool", args[0].val == args[1].val)
```


Overlapping Code:
```
gs):
args = valueify(args)
if len(args) != 2: raise MethodInputError("Incorrect number of inputs, should be 2, %s were given" % len(args))
return tokenz.Token("bool"
```
<Overlap Ratio: 0.812807881773399>

---

--- 233 --
Question ID: 8ed3f82bfc69879bbbfe3dc14099027b64445975_0
Original Code:
```
@contextmanager
def session_scope():
    """Provide a transactional scope around a series of operations."""
    session = Session()
    try:
        yield session
        session.commit()
    except SQLAlchemyError:
        session.rollback()
        raise
    finally:
        session.close()
```


Overlapping Code:
```
@contextmanager
def session_scope():
"""Provide a transactional scope around a series of operations."""
session = Session()
try:
yield session
session.commit()
except SQLAlchemyError:
session.rollback()
raise
finally:
session.close()
```
<Overlap Ratio: 1.0>

---

--- 234 --
Question ID: 2c2fdc20708a2da8654abb2a61d2e64bc88dbe1b_2
Original Code:
```
@patch('logging.Logger.info')
@patch('requests.post')
def test_rocket_chat_success(mock_request, mock_logger, mock_url, mock_messages):
    Messages.send_rocketchat_message(mock_messages, mock_url)

    mock_request.assert_called_once_with(mock_url, json={'text': mock_messages[0]})
    mock_logger.assert_called_once_with('Rocket Chat message sent!')
```


Overlapping Code:
```
patch('logging.Logger.info')
@patch('requests.post')
def test_rocket_chat_success(mock_request, mock_logger, mock_url, mock_messages):
Messages.send_rocketchat_message(mock_messages, mock_url)
mock_request.assert_called_once_with(mock_url, json={'text': mock_messages[0]})
mock_logger.assert_called_once_with('R
```
<Overlap Ratio: 0.9201183431952663>

---

--- 235 --
Question ID: c705f112ed561835325a2e14c85ecd8321f2a466_8
Original Code:
```
def _clenshaw_curtis_weights(n):
    """
    Computes the Clenshaw-Curtis quadrature using a fast FFT method.

    This is a 'brainless' port of MATLAB code found in:
    Fast Construction of the Fejer and Clenshaw-Curtis Quadrature Rules
    Jorg Waldvogel, 2005
    http://www.sam.math.ethz.ch/~joergw/Papers/fejer.pdf

    :param n:
    :return:
    """
    from scipy.fftpack import ifft, fft, fftshift

    # TODO python3 handles division differently from python2. Check how MATLAB interprets /, and if this code is still correct for python3

    # function [wf1,wf2,wcc] = fejer(n)
    # Weights of the Fejer2, Clenshaw-Curtis and Fejer1 quadratures by DFTs
    # n>1. Nodes: x_k = cos(k*pi/n)
    # N = [1:2:n-1]'; l=length(N); m=n-l; K=[0:m-1]';
    N = np.arange(start=1, stop=n, step=2)[:, None]
    l = N.size
    m = n - l
    K = np.arange(start=0, stop=m)[:, None]

    # Fejer2 nodes: k=0,1,...,n; weights: wf2, wf2_n=wf2_0=0
    # v0 = [2./N./(N-2); 1/N(end); zeros(m,1)];
    v0 = np.vstack([2. / N / (N-2), 1. / N[-1]] + [0] * m)

    # v2 = -v0(1:end-1) - v0(end:-1:2);
    # wf2 = ifft(v2);
    v2 = -v0[:-1] - v0[:0:-1]

    # Clenshaw-Curtis nodes: k=0,1,...,n; weights: wcc, wcc_n=wcc_0
    # g0 = -ones(n,1);
    g0 = -np.ones((n, 1))

    # g0(1 + l) = g0(1 + l) + n;
    g0[l] = g0[l] + n

    # g0(1+m) = g0(1 + m) + n;
    g0[m] = g0[m] + n

    # g = g0/(n^2-1+mod(n,2));
    g = g0 / (n ** 2 - 1 + n % 2)

    # wcc=ifft(v2 + g);
    wcc = ifft((v2 + g).flatten()).real
    wcc = np.hstack([wcc, wcc[0]])

    # Fejer1 nodes: k=1/2,3/2,...,n-1/2; vector of weights: wf1
    # v0=[2*exp(i*pi*K/n)./(1-4*K.^2); zeros(l+1,1)];
    # v1=v0(1:end-1)+conj(v0(end:-1:2)); wf1=ifft(v1);
    # don't need these

    return wcc * np.pi / (n / 2 + 1)  # adjust for different scaling of python vs MATLAB fft
```


Overlapping Code:
```
lenshaw_curtis_weights(n):
"""
Computes the Clenshaw-Curtis quadrature using a fast FFT method.
This is a 'brainless' port of MATLAB code found in:
Fast Construction of the Fejer and Clenshaw-Curtis Quadraturethz.ch/~joergw/Papers/fejer.pdf
:param n:
:return:
"""
from scipy.fftpack import ifft, fft, fftshift
# TODO python3 handles division differently from python2. Check how MATLAB interprets /, and if this code is still correct for python3
# function [wf1,wf2,wcc] = fejer(n)
# Weights of the Fejer2, Clenshaw-Curtis and Fejer1 quadratures by DFTs
# n>1. Nodes: x_k = cos(k*pi/n)
# N = [1:2:n-1]'; l=length(N); m=n-l; K=[0:m-1]';
N = np.arange(start=1, stop=n, step=2)[:, None]
l = N.size
m = n - l
K = np.arange(start=0, stop=m)[:, None]
# Fejer2 nodes: k=0,1,...,n; weights: wf2, wf2_n=wf2_0=0
# v0 = [2./N./(N-2); 1/N(end); zeros(m,1)];
v0 = np.vstack([2. / N / (N-2), 1. / N[-1]] + [0] * m)
# v2 = -v0(1:end-1) - v0(end:-1:2);
# wf2 = ifft(v2);
v2 = -v0[:-1] - v0[:0:-1]
# Clenshaw-Curtis nodes: k=0,1,...,n; weights: wcc, wcc_n=wcc_0
# g0 = -ones(n,1);
g0 = -np.ones((n, 1))
# g0(1 + l) = g0(1 + l) + n;
g0[l] = g0[l] + n
# g0(1+m) = g0(1 + m) + n;
g0[m] = g0[m] + n
# g = g0/(n^2-1+mod(n,2));
g = g0 / (n ** 2 - 1 + n % 2)
# wcc=ifft(v2 + g);
wcc = ifft((v2 + g).flatten()).real
wcc = np.hstack([wcc, wcc[0]])
# Fejer1 nodes: k=1/2,3/2,...,n-1/2; vector of weights: wf1
# v0=[2*exp(i*pi*K/n)./(1-4*K.^2); zeros(l+1,1)];
# v1=v0(1:end-1)+conj(v0(end:-1:2)); wf1=ifft(v1);
# don't need these
return wcc * np.pi / (n / 2 + 1) # adjust for different sc
```
<Overlap Ratio: 0.9488740109555691>

---

--- 236 --
Question ID: dbf75775d7ccd7ae4436bc3c80eba63e41331ec2_1
Original Code:
```
@public
def negative_start() -> range:
    a = range(6)
    return a[-6:5:2]
```


Overlapping Code:
```

```
<Overlap Ratio: 0.0>

---

--- 237 --
Question ID: d229cb0ad6444d38ae49dd9f9a95dd6134cf4c89_1
Original Code:
```
def save(queue):
    # type: (Queue) -> None

    number = 0
    output = "screenshots/file_{}.png"
    to_png = mss.tools.to_png

    while "there are screenshots":
        img = queue.get()
        if img is None:
            break

        to_png(img.rgb, img.size, output=output.format(number))
        number += 1
```


Overlapping Code:
```
ber = 0
output = "screenshots/file_{}.png"
to_png = mss.tools.to_png
while "there are screenshots":
img = queue.get()
if img is None:
break
to_png(img.rgb, img.size, output=output.format(number))
numb
```
<Overlap Ratio: 0.796812749003984>

---

--- 238 --
Question ID: f6c78b9e1e685bcb9be5316b826a143242b8699c_4
Original Code:
```
def train(graph, model):
  tfg.conf.training = True
  query_train = query(graph, gl.Mask.TRAIN)
  dataset = tfg.Dataset(query_train, window=5)
  data_dict = dataset.get_data_dict()
  feature_handler = tfg.FeatureHandler('feature_handler',
    query_train.get_node("train").decoder.feature_spec)

  x_list = reformat_node_feature(data_dict, query_train.list_alias(), feature_handler)
  train_embeddings = model.forward(x_list, nbrs_num)
  loss = supervised_loss(train_embeddings, data_dict['train'].labels)
  return dataset.iterator, loss
```


Overlapping Code:
```
el):
tfg.conf.training = True
query_train = query(graph, gl.Mask.TRAIN)
dataset = tfg.Dataset(query_train, window=5)
data_dict = dataset.get_data_dict()
feature_handler = tfg.FeatureHandler('feature_handler',
query_train.get_node("train").decoder.feature_spec)
x_list = reformat_node_feature(data_dict, query_train.list_alias(), feature_handler)
train_embeddings = model.forward(x_list, nbrs_num)
loss = supervised_loss(train_embeddings, data_dict['t
```
<Overlap Ratio: 0.8754863813229572>

---

--- 239 --
Question ID: 5850bb624fc311e1b4624e5a4555703ac8613620_0
Original Code:
```
@pytest.mark.parametrize(
    "start_block,end_block,batch_size,resource_group,web3_provider_type",
    [
        (10324748, 10324748, 1, "version_01a_block", "mock"),
        (12640760, 12640760, 1, "version_03_block", "mock"),
        (14473621, 14473621, 1, "version_04_block", "mock"),
        (14473622, 14473622, 1, "version_05_block", "mock"),
        skip_if_slow_tests_disabled(
            (10324748, 10324748, 1, "version_01a_block", "public_endpoint")
        ),
        skip_if_slow_tests_disabled(
            (12640760, 12640760, 1, "version_03_block", "public_endpoint")
        ),
        skip_if_slow_tests_disabled(
            (14473621, 14473621, 1, "version_04_block", "public_endpoint")
        ),
        skip_if_slow_tests_disabled(
            (14473622, 14473622, 1, "version_05_block", "public_endpoint")
        ),
    ],
)
def test_export_blocks_job(
    tmpdir, start_block, end_block, batch_size, resource_group, web3_provider_type
):
    blocks_output_file = str(tmpdir.join("actual_blocks.csv"))
    transactions_output_file = str(tmpdir.join("actual_transactions.csv"))

    job = ExportBlocksJob(
        start_block=start_block,
        end_block=end_block,
        batch_size=batch_size,
        batch_web3_provider=ThreadLocalProxy(
            lambda: get_web3_provider(
                web3_provider_type,
                lambda file: read_resource(resource_group, file),
                batch=True,
            )
        ),
        max_workers=5,
        item_exporter=blocks_and_transactions_item_exporter(
            blocks_output_file, transactions_output_file
        ),
        export_blocks=blocks_output_file is not None,
        export_transactions=transactions_output_file is not None,
    )
    job.run()

    compare_lines_ignore_order(
        read_resource(resource_group, "expected_blocks.csv"),
        read_file(blocks_output_file),
    )

    compare_lines_ignore_order(
        read_resource(resource_group, "expected_transactions.csv"),
        read_file(transactions_output_file),
    )
```


Overlapping Code:
```
.parametrize(
"start_block,end_block,batch_size,resource_group,web3_provider_type",
[
(10324748, 10324748, 1, "version_01a_block", "mock"),
(12640760, 12640760, 1, "version_03_block", "mock"),
(14473621, 14473621, 1, "version_04_block", "mock"),
(14473622, 14473622, 1, "version_05_block", "mock"),
skip_if_slow_tests_disabled(
(10324748, 10324748, 1, "version_01a_block", "public_endpoint")
),
skip_if_slow_tests_disabled(
(12640760, 12640760, 1, "version_03_block", "public_endpoint")
),
skip_if_slow_tests_disabled(
(14473621, 14473621, 1, "version_04_block", "public_endpoint")
),
skip_if_slow_tests_disabled(
(14473622, 14473622, 1, "version_05_block", "public_endpoint")
),
],
)
def test_export_blocks_job(
tmpdir, start_block, end_block, batch_size, resource_group, web3_provider_type
):
blocks_output_file = str(tmpdir.join("actual_blocks.csv"))
transactions_output_file = str(tmpdir.join("actual_transactions.csv"))
job = ExportBlocksJob(
start_block=start_block,
end_block=end_block,
batch_size=batch_size,
batch_web3_provider=ThreadLocalProxy(
lambda: get_web3_provider(
web3_provider_type,
lambda file: read_resource(resource_group, file),
batch=True,
)
),
max_workers=5,
item_exporter=blocks_and_transactions_item_exporter(
blocks_output_file, transactions_output_file
),
export_blocks=blocks_output_file is not None,
export_transactions=transactions_output_file is not None,
)
job.run()
compare_lines_ignore_order(
read_resource(resource_group, "expected_blocks.csv"),
read_file(blocks_output_file),
)
compare_lines_ignore_order(
read_resource(resource_group, "expected_transactions.csv
```
<Overlap Ratio: 0.9673518742442564>

---

--- 240 --
Question ID: 5f6bf97eb78b58ba7ed24d4217d65453b5da2324_4
Original Code:
```
def _print_diff_cycle_list(cycles1: Set[count_cycles.Cycle],
                           cycles2: Set[count_cycles.Cycle], label: str):
    before_cycles: Set[str] = set(_cycle_str(cycle) for cycle in cycles1)
    after_cycles: Set[str] = set(_cycle_str(cycle) for cycle in cycles2)
    _print_set_diff(before_cycles, after_cycles, label)
```


Overlapping Code:
```
ycles1: Set[count_cycles.Cycle],
cycles2: Set[count_cycles.Cycle], label: str):
before_cycles: Set[str] = set(_cycle_str(cycle) for cycle in cycles1)
after_cycles: Set[str] = set(_cycle_str(cycle) for cycle in cycles2)
_print_set_diff(before_cycles, 
```
<Overlap Ratio: 0.8389261744966443>

---

--- 241 --
Question ID: 53e07e5c0b5e8eafa9b65a5cfecd85383fd56e1e_3
Original Code:
```
def test_crosscorr_similarity_batchsize(random_seed=0):
    rng = np.random.RandomState(random_seed)
    X = rng.rand(100, 128)

    results = [crosscorr_similarity(X, X, batch_size=batch_size)
               for batch_size in [None, 50, 2500, 3000]]

    for r1, r2 in zip(results, results[1:]):
        assert_allclose(r1, r2)
```


Overlapping Code:
```
similarity_batchsize(random_seed=0):
rng = np.random.RandomState(random_seed)
X = rng.rand(100, 128)
results = [crosscorr_similarity(X, X, batch_size=batch_size)
for batch_size in [None, 50, 2500, 3000]]
for r1, r2 in zip(results, results[1:]):
asser
```
<Overlap Ratio: 0.8710801393728222>

---

--- 242 --
Question ID: e1b31044e433b2058dc06849f93ff064a71f0653_6
Original Code:
```
def serial_triple_dot_coulomb_symmetry_spin():
    # Coulomb matrix elements
    # Intradot terms: u, uex
    # Interdot terms: un, udc, usc
    u, uex, un, udc, usc = 10., 2., 3., -0.5, -0.2

    # ----------- Spinless -----------
    nsingle = 5
    dotindex = [0, 0, 1, 1, 2]
    # m, n, k, l
    coulomb = []
    for m, n, k, l in itertools.product(range(nsingle), repeat=4):
        if m == n == k == l:
            coulomb.append([m,m,m,m,u/2]) # Direct
        if dotindex[m] == dotindex[k]:
            if m == n and k == l and m != k:
                coulomb.append([m,m,k,k,uex/2]) # Exchange
        if m != n and k != l:
            # Intradot
            if dotindex[m] == dotindex[n]:
                if m == l and n == k: coulomb.append([m,n,n,m,u/2])   # Direct
                if m == k and n == l: coulomb.append([m,n,m,n,uex/2]) # Exchange
            # Interdot
            # Note that the pairs (n,k) and (m,l) are located at different dots
            if (dotindex[m] == dotindex[l] and
                dotindex[n] == dotindex[k] and
                abs(dotindex[m]-dotindex[n]) == 1):
                if m == l and n == k:
                    coulomb.append([m,n,n,m,un/2])   # Direct
                if n == k and m != l:
                    sgn = dotindex[m]-dotindex[n]
                    coulomb.append([m,n,n,l,udc/2*sgn])  # Charge-dipole
                if n != k and m == l:
                    sgn = dotindex[n]-dotindex[m]
                    coulomb.append([m,n,k,m,udc/2*sgn])  # Charge-dipole
                if n != k and m != l:
                    coulomb.append([m,n,k,l,usc/2])  # Charge-quadrupole
    coulomb0 = coulomb

    coulomb1 = {(0,0,0,0):u, (1,1,1,1):u, (2,2,2,2):u, (3,3,3,3):u, (4,4,4,4):u,
                (0,1,1,0):u, (2,3,3,2):u,
                #
                (0,0,1,1):uex, (2,2,3,3):uex,
                (0,1,0,1):uex, (2,3,2,3):uex,
                #
                (0,2,2,0):un, (0,3,3,0):un,
                (1,2,2,1):un, (1,3,3,1):un,
                (2,4,4,2):un, (3,4,4,3):un,
                #
                (0,2,2,1):-udc, (0,3,3,1):-udc, (2,4,4,3):-udc,
                (0,2,3,0):+udc, (1,2,3,1):+udc,
                #
                (0,2,3,1):usc, (0,3,2,1):usc,
                # Conjugated terms
                (1,1,0,0):uex, (3,3,2,2):uex,
                #
                (1,2,2,0):-udc, (1,3,3,0):-udc, (3,4,4,2):-udc,
                (0,3,2,0):+udc, (1,3,2,1):+udc,
                #
                (1,3,2,0):usc, (1,2,3,0):usc
                }

    coulomb2 = {(0,0,0,0):u, (1,1,1,1):u, (2,2,2,2):u, (3,3,3,3):u, (4,4,4,4):u,
                (0,1,1,0):u, (2,3,3,2):u,
                #
                (0,0,1,1):uex, (2,2,3,3):uex,
                (0,1,0,1):uex, (2,3,2,3):uex,
                #
                (0,2,2,0):un, (0,3,3,0):un,
                (1,2,2,1):un, (1,3,3,1):un,
                (2,4,4,2):un, (3,4,4,3):un,
                #
                (0,2,2,1):-udc, (0,3,3,1):-udc, (2,4,4,3):-udc,
                (0,2,3,0):+udc, (1,2,3,1):+udc,
                #
                (0,2,3,1):usc, (0,3,2,1):usc
                }

    sys0_spinless = qmeq.Builder(nsingle=5, coulomb=coulomb0, symmetry=None, m_less_n=False, herm_c=False)
    sys0_spinless.solve(masterq=False)
    sys1_spinless = qmeq.Builder(nsingle=5, coulomb=coulomb1, symmetry=None, m_less_n=True, herm_c=False)
    sys1_spinless.solve(masterq=False)
    sys2_spinless = qmeq.Builder(nsingle=5, coulomb=coulomb2, symmetry=None, m_less_n=True, herm_c=True)
    sys2_spinless.solve(masterq=False)

    assert sum(abs(sys1_spinless.Ea-sys0_spinless.Ea)) < EPS
    assert sum(abs(sys2_spinless.Ea-sys0_spinless.Ea)) < EPS

    # ----------- Spinful -----------
    nsingle = 10
    nssl = nsingle//2
    dotindex = [0, 0, 1, 1, 2, 0, 0, 1, 1, 2]
    # m, n, k, l
    coulomb = []
    for m, n, k, l in itertools.product(range(nsingle), repeat=4):
        if m != n and k != l and m//nssl == l//nssl and n//nssl == k//nssl:
            # Intradot
            if dotindex[m] == dotindex[n]:
                if m == l and n == k: coulomb.append([m,n,n,m,u/2]) # Direct
                if m == k and n == l:
                    coulomb.append([m,n,m,n,uex/2]) # Exchange
                    if m+nssl < nsingle:
                        coulomb.append([m,n+nssl,m+nssl,n,uex/2])
                        coulomb.append([m+nssl,n,m,n+nssl,uex/2])
                        coulomb.append([m,m+nssl,n+nssl,n,uex/2])
                        coulomb.append([m+nssl,m,n,n+nssl,uex/2])
            # Interdot
            # Note that the pairs (n,k) and (m,l) are located at different dots
            if (dotindex[m] == dotindex[l] and
                dotindex[n] == dotindex[k] and
                abs(dotindex[m]-dotindex[n]) == 1):
                if m == l and n == k:
                    coulomb.append([m,n,n,m,un/2])   # Direct
                if n == k and m != l:
                    sgn = dotindex[m]-dotindex[n]
                    coulomb.append([m,n,n,l,udc/2*sgn])  # Charge-dipole
                if n != k and m == l:
                    sgn = dotindex[n]-dotindex[m]
                    coulomb.append([m,n,k,m,udc/2*sgn])  # Charge-dipole
                if n != k and m != l:
                    coulomb.append([m,n,k,l,usc/2])  # Charge-quadrupole

    indexing='ssq'
    sys_ref_spinful = qmeq.Builder(nsingle=10, coulomb=coulomb, indexing=indexing)
    sys_ref_spinful.solve(masterq=False)
    sys0_spinful = qmeq.Builder(nsingle=10, coulomb=coulomb0, symmetry='spin', m_less_n=False, indexing=indexing)
    sys0_spinful.solve(masterq=False)
    sys1_spinful = qmeq.Builder(nsingle=10, coulomb=coulomb1, symmetry='spin', m_less_n=True, herm_c=False, indexing=indexing)
    sys1_spinful.solve(masterq=False)
    sys2_spinful = qmeq.Builder(nsingle=10, coulomb=coulomb2, symmetry='spin', m_less_n=True, herm_c=True, indexing=indexing)
    sys2_spinful.solve(masterq=False)

    assert sum(abs(sys0_spinful.Ea-sys_ref_spinful.Ea)) < 10*EPS
    assert sum(abs(sys1_spinful.Ea-sys_ref_spinful.Ea)) < 10*EPS
    assert sum(abs(sys2_spinful.Ea-sys_ref_spinful.Ea)) < 10*EPS
```


Overlapping Code:
```
t_coulomb_symmetry_spin():
# Coulomb matrix elements
# Intradot terms: u, uex
# Interdot terms: un, udc, usc
u, uex, un, udc, usc = 10., 2., 3., -0.5, -0.2
# ----------- Spinless -----------
nsingle = 5
dotindex = [0, 0, 1, 1, 2]
# m, n, k, l
coulomb = []
for m, n, k, l in itertools.product(range(nsingle), repeat=4):
if m == n == k == l:
coulomb.append([m,m,m,m,u/2]) # Direct
if dotindex[m] == dotindex[k]:
if m == n and k == l and m != k:
coulomb.append([m,m,k,k,uex/2]) # Exchange
if m != n and k != l:
# Intradot
if dotindex[m] == dotindex[n]:
if m == l and n == k: coulomb.append([m,n,n,m,u/2]) # Direct
if m == k and n == l: coulomb.append([m,n,m,n,uex/2]) # Exchange
# Interdot
# Note that the pairs (n,k) and (m,l) are located at different dots
if (dotindex[m] == dotindex[l] and
dotindex[n] == dotindex[k] and
abs(dotindex[m]-dotindex[n]) == 1):
if m == l and n == k:
coulomb.append([m,n,n,m,un/2]) # Direct
if n == k and m != l:
sgn = dotindex[m]-dotindex[n]
coulomb.append([m,n,n,l,udc/2*sgn]) # Charge-dipole
if n != k and m == l:
sgn = dotindex[n]-dotindex[m]
coulomb.append([m,n,k,m,udc/2*sgn]) # Charge-dipole
if n != k and m != l:
coulomb.append([m,n,k,l,usc/2]) # Charge-quadrupole
coulomb0 = coulomb
coulomb1 = {(0,0,0,0):u, (1,1,1,1):u, (2,2,2,2):u, (3,3,3,3):u, (4,4,4,4):u,
(0,1,1,0):u, (2,3,3,2):u,
#
(0,0,1,1):uex, (2,2,3,3):uex,
(0,1,0,1):uex, (2,3,2,3):uex,
#
(0,2,2,0):un, (0,3,3,0):un,
(1,2,2,1):un, (1,3,3,1):un,
(2,4,4,2):un, (3,4,4,3):un,
#
(0,2,2,1):-udc, (0,3,3,1):-udc, (2,4,4,3):-udc,
(0,2,3,0):+udc, (1,2,3,1):+udc,
#
(0,2,3,1):usc, (0,3,2,1):usc,
# Conjugated terms
(1,1,0,0):uex, (3,3,2,2):uex,
#
(1,2,2,0):-udc, (1,3,3,0):-udc, (3,4,4,2):-udc,
(0,3,2,0):+udc, 
```
<Overlap Ratio: 0.9714285714285714>

---

--- 243 --
Question ID: 3f141512af9c79b9eb075660aeccebb06b995877_8
Original Code:
```
def main():
    global DWH_CLUSTER_IDENTIFIER, DWH_IAM_ROLE_NAME
    global DWH_DB_USER, DWH_DB_PASSWORD, DWH_PORT
    config_parser()

    ec2 = aws_resource('ec2', "us-west-2")
    s3 = aws_resource('s3', "us-west-2")
    iam = aws_client('iam', "us-west-2")
    redshift = aws_client('redshift', "us-west-2")

    roleArn = iam_create_role(iam)

    clusterCreationStarted = init_cluster_creation(redshift, roleArn)

    if clusterCreationStarted:
        print("The cluster is being created.")

        while True:
            print("Checking if the cluster is created...")

            if redshift_cluster_status(redshift) == 'available':
                config_update_cluster(redshift)
                aws_open_redshift_port(ec2, redshift)
                break
            else:
                print("Cluster is still being created. Please wait.")

            time.sleep(30)
        print("Cluster creation successful.\n")

        # Add Redshift to Airflow connections
        myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]
        DWH_ENDPOINT = myClusterProps['Endpoint']['Address']

        conn = Connection(
            conn_id='redshift',
            conn_type='Postgres',
            host=DWH_ENDPOINT,
            login=DWH_DB_USER,
            password=DWH_DB_PASSWORD,
            port=DWH_PORT
        )

        session = settings.Session()
        session.add(conn)
        session.commit()

        # Add role to Variables
        Variable.set("aws_iam_role", DWH_IAM_ROLE_NAME)
```


Overlapping Code:
```
ER, DWH_IAM_ROLE_NAME
global DWH_DB_USER, DWH_DB_PASSWORD, DWH_PORT
config_parser()
ec2 = aws_resource('ec2', "us-west-2")
s3 = aws_resource('s3', "us-west-2")
iam = aws_client('iam', "us-west-2")
redshift = aws_client('redshift', "us-west-2")
roleArn = iam_create_role(iam)
clusterCreationStarted = init_cluster_creation(redshift, roleArn)
if clusterCreationStarted:
print("The cluster is being created.")
while True:
print("Checking if the cluster is created...")
if redshift_cluster_status(redshift) == 'available':
config_update_cluster(redshift)
aws_open_redshift_port(ec2, redshift)
break
else:
print("Cluster is still being created. Please wait.")
time.sleep(30)
print("Cluster creation successful.\n")
# Add Redshift to Airflow connections
myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]
DWH_ENDPOINT = myClusterProps['Endpoint']['Address']
conn = Connection(
conn_id='redshift',
conn_type='Postgres',
host=DWH_ENDPOINT,
login=DWH_DB_USER,ttings.Session()
session.add(conn)
session.commit()
# Add role to Variables
Variable.set("aws_iam_ro
```
<Overlap Ratio: 0.903861955628595>

---

--- 244 --
Question ID: 3ae144074b21550c77cdd8b0c2475e1b752ee01e_3
Original Code:
```
def os_path_nextname(basename):
    """Pick the next Filename not already existing in the Cwd"""

    pattern = basename + "*"

    paths = list(glob.glob(pattern))

    last_path = basename
    if not paths:

        return basename

    paths.sort(key=os_path_intrev)
    last_path = paths[-1]

    (base, ext, _) = os_path_partition(last_path)
    last_intrev = os_path_intrev(last_path)
    next_intrev = last_intrev + 1

    next_path = "{}{}~".format(base, ext)
    if next_intrev != 1:
        next_path = "{}{}~{}~".format(base, ext, next_intrev)

    return next_path
```


Overlapping Code:
```
name):
"""Pick the next Filename not already existing in the Cwd"""
pattern = basename + "*"
paths = list(glob.glob(pattern))
last_path = basename
if not paths:
return basename
paths.sort(key=os_path_intrev)
last_path = paths[-1]
(base, ext, _) = os_path_partition(last_path)
last_intrev = os_path_intrev(last_path)
next_intrev = last_intrev + 1
next_path = "{}{}~".format(base, ext)
if next_intrev != 1:
next_path = "{}{}~{}~".format(base, ext, next
```
<Overlap Ratio: 0.9>

---

--- 245 --
Question ID: f4f61dcbba1bd6942e5b9556d0cca3e69f34e044_1
Original Code:
```
def main(argv=None):
    if argv is None:
        argv = sys.argv

    # defaults
    osc_freq = 16000 # kHz
    baud = 115200
    cpu = "autodetect"
    flash_addr_base = 0
    erase_all = False
    erase_only = False
    verify = False
    verify_only = False
    blank_check = False
    xonxoff = False
    start = False
    control = False
    select_bank = False
    read = False
    readlen = 0
    get_serial_number = False
    udp = False
    port = -1
    mac = "" # "0C-1D-12-E0-1F-10"

    optlist, args = getopt.getopt(argv[1:], '',
            ['cpu=', 'oscfreq=', 'baud=', 'addr=', 'start=',
                'filetype=', 'bank=', 'read=', 'len=', 'serialnumber',
                'udp', 'port=', 'mac=', 'verify', 'verifyonly', 'blankcheck',
                'xonxoff', 'eraseall', 'eraseonly', 'list', 'control'])

    for o, a in optlist:
        if o == "--list":
            log("Supported cpus:")
            for val in sorted(cpu_parms.keys()):
                log(" %s" % val)
            sys.exit(0)
        if o == "--cpu":
            cpu = a
        elif o == "--xonxoff":
            xonxoff = True
        elif o == "--oscfreq":
            osc_freq = int(a)
        elif o == "--addr":
            flash_addr_base = int(a, 0)
        elif o == "--baud":
            baud = int(a)
        elif o == "--eraseall":
            erase_all = True
        elif o == "--eraseonly":
            erase_only = True
        elif o == "--verify":
            verify = True
        elif o == "--verifyonly":
            verify = True
            verify_only = True
        elif o == "--blankcheck":
            verify = True
            blank_check = True
        elif o == "--control":
            control = True
        elif o == "--start":
            start = True
            if a:
                startaddr = int(a, 0)
            else:
                startaddr = 0
        elif o == "--bank":
            select_bank = True
            bank = int(a)
        elif o == "--read":
            read = True
            readfile = a
        elif o == "--serialnumber":
            get_serial_number = True
        elif o == "--len":
            readlen = int(a)
        elif o == "--udp":
            udp = True
        elif o == "--port":
            port = int(a)
        elif o == "--mac":
            mac = a
        else:
            panic("Unhandled option: %s" % o)

    if cpu != "autodetect" and not cpu in cpu_parms:
        panic("Unsupported cpu %s" % cpu)

    if len(args) == 0:
        syntax()

    device = args[0]

    if udp:
        if '.' in device:
            if ':' in device:
                device, port = tuple(device.split(':'))
                port = int(port)
                if port<0 or port>65535:
                    panic("Bad port number: %d" % port)
            parts = [int(x) for x in device.split('.')]
            if len(parts)!=4 or min(parts)<0 or max(parts)>255:
                panic("Bad IPv4-address: %s" % device)
            device = '.'.join([str(x) for x in parts])
        elif ':' in device:
            # panic("Bad IPv6-address: %s" % device)
            pass
        else:
            panic("Bad IP-address: %s" % device)
        if port < 0:
            port = 41825
        if mac:
            parts = [int(x, 16) for x in mac.split('-')]
            if len(parts)!=6 or min(parts)<0 or max(parts)>255:
                panic("Bad MAC-address: %s" % mac)
            mac = '-'.join(['%02x'%x for x in parts])
            log("cpu=%s ip=%s:%d mac=%s" % (cpu, device, port, mac))
        else:
            log("cpu=%s ip=%s:%d" % (cpu, device, port))
    else:
        log("cpu=%s oscfreq=%d device=%s baud=%d" % (cpu, osc_freq, device, baud))

    prog = nxpprog(cpu, device, baud, osc_freq, xonxoff, control, (device, port, mac) if udp else None, verify)

    if erase_only:
        prog.erase_all(verify)
    elif blank_check:
        prog.blank_check_all()
    elif start:
        prog.start(startaddr)
    elif select_bank:
        prog.select_bank(bank)
    elif get_serial_number:
        sn = prog.get_serial_number()
        sys.stdout.write(sn)
    elif read:
        if not readlen:
            panic("Read length is 0")
        fd = open(readfile, "w")
        prog.read_block(flash_addr_base, readlen, fd)
        fd.close()
    else:
        if len(args) != 2:
            syntax()

        filename = args[1]

        image = open(filename, "rb").read()

        if not verify_only:
            start = time.time()
            success = prog.prog_image(image, flash_addr_base, erase_all, verify)
            stop = time.time()
            elapsed = stop - start
            log("Programmed %s in %.1f seconds" % ("successfully" if success else "with errors", elapsed))

        if verify:
            start = time.time()
            success = prog.verify_image(flash_addr_base, image)
            stop = time.time()
            elapsed = stop - start
            log("Verified %s in %.1f seconds" % ("successfully" if success else "with errors", elapsed))

        if not verify_only:
            prog.start(flash_addr_base)
```


Overlapping Code:
```
def main(argv=None):
if argv is None:
argv = sys.argv
# defaults
osc_freq = 16000 # kHz
baud = 115200
cpu = "autodetect"
flash_addr_base = 0
erase_all = False
erase_only = False
verify = False
verify_only = False
blank_check = False
xonxoff = False
start = False
control = False
select_bank = False
read = False
readlen = 0
get_serial_number = False
udp = False
port = -1
mac = "" # "0C-1D-12-E0-1F-10"
optlist, args = getopt.getopt(argv[1:], '',
['cpu=', 'oscfreq=', 'baud=', 'addr=', 'start=',
'filetype=', 'bank=', 'read=', 'len=', 'serialnumber',
'udp', 'port=', 'mac=', 'verify', 'verifyonly', 'blankcheck',
'xonxoff', 'eraseall', 'eraseonly', 'list', 'control'])
for o, a in optlist:
if o == "--list":
log("Supported cpus:")
for val in sorted(cpu_parms.keys()):
log(" %s" % val)
sys.exit(0)
if o == "--cpu":
cpu = a
elif o == "--xonxoff":
xonxoff = True
elif o == "--oscfreq":
osc_freq = int(a)
elif o == "--addr":
flash_addr_base = int(a, 0)
elif o == "--baud":
baud = int(a)
elif o == "--eraseall":
erase_all = True
elif o == "--eraseonly":
erase_only = True
elif o == "--verify":
verify = True
elif o == "--verifyonly":
verify = True
verify_only = True
elif o == "--blankcheck":
verify = True
blank_check = True
elif o == "--control":
control = True
elif o == "--start":
start = True
if a:
startaddr = int(a, 0)
else:
startaddr = 0
elif o == "--bank":
select_bank = True
bank = int(a)
elif o == "--read":
read = True
readfile = a
elif o == "--serialnumber":
get_serial_number = True
elif o == "--len":
readlen = int(a)
elif o == "--udp":
udp = True
elif o == "--port":
port = int(a)
elif o == "--mac":
mac = a
else:
panic("Unhandled option: %s" % o)
if cpu != "autodetect" and not cpu in cpu_parms:
panic("Unsupported cpu %s" % cpu)
if
```
<Overlap Ratio: 0.9942987457240593>

---

--- 246 --
Question ID: 68289cf64967e043e55f53a151dfe72ffd61f91e_13
Original Code:
```
@skip_unless_linux
def test_return_event_set(test_dir: Path, time_taken):
    watcher = RustNotify([str(test_dir)], False, False, 0)

    with time_taken(0, 20):
        assert watcher.watch(100, 1, 500, AbstractEvent(True)) == 'stop'
```


Overlapping Code:
```
n_event_set(test_dir: Path, time_taken):
watcher = RustNotify([str(test_dir)], False, False, 0)
with time_taken(0, 20):
assert watcher.watch(100, 1, 5
```
<Overlap Ratio: 0.6912442396313364>

---

--- 247 --
Question ID: d240999b626a346aa9ec07fef8022c82d7a2029d_4
Original Code:
```
def _ensure_dict(item):
    if type(item) == str:
        return ast.literal_eval(item)
    else:
        return item
```


Overlapping Code:
```

if type(item) == str:
return ast.literal_eval(ite
```
<Overlap Ratio: 0.5376344086021505>

---

--- 248 --
Question ID: b0f4372f914769547fb942b23ae25089ee51ebf0_3
Original Code:
```
def PR_curve(precisions: np.ndarray, label: list, title: str, x=None):
    # bit = precisions.shape[1]
    from matplotlib import pyplot as plt
    # min_presion = np.min([np.min(l) for l in precisions])
    # max_presion = np.max([np.max(l) for l in precisions])
    min_presion = 0.5
    max_presion = 1
    plt.title(title)
    plt.xticks(np.arange(0.1, 1.1, 0.1))
    plt.xlabel("recall")
    plt.yticks(np.arange(round(min_presion * 10 - 1) * 0.1, (round(max_presion * 10)+1) * 0.1, 0.1))
    plt.ylabel("precision")
    if x is None:
        x = np.arange(0.02, 1.02, 0.02)
        # x = np.expand_dims(x, precisions.shape)
    colors = ['red', 'blue', 'c', 'green', 'yellow', 'black', 'lime', 'grey', 'pink', 'navy']
    markets = ['o', 'v', '^', '>', '<', '+', 'x', '*', 'd', 'D']
    for i in range(precisions.shape[0]):
        # plt.plot(x[i], precisions[i, :], marker=markets[i % 10], color=colors[i % 10], label=label[i])
        plt.plot(x[i], precisions[i], color=colors[i % 10], label=label[i])
        # plt.plot(x, precisions[i, :], color=colors[i % 10], label=label[i])
    plt.grid()
    ax = plt.axes()
    ax.set(xlim=(0, 1), ylim=(round(min_presion * 10 - 1) * 0.1, (round(max_presion * 10)) * 0.1))
    plt.legend()
    # plt.axes('tight')
    plt.show()
```


Overlapping Code:
```
ve(precisions: np.ndarray, label: list, title: str, x=None):
# bit = precisions.shape[1]
from matplotlib import pyplot as plt
# min_presion = np.min([np.min(l) for l in precisions])
# max_presion = np.max([np.max(l) for l in precisions])
min_presion = 0.5
max_presion = 1
plt.title(title)
plt.xticks(np.arange(0.1, 1.1, 0.1))
plt.xlabel("recall")
plt.yticks(np.arange(round(min_presion * 10 - 1) * 0.1, (round(max_presion * 10)+1) * 0.1, 0.1))
plt.ylabel("precision")
if x is None:
x = np.arange(0.02, 1.02, 0.02)
# x = np.expand_dims(x, precisions.shape)
colors = ['red', 'blue', 'c', 'green', 'yellow', 'black', 'lime', 'grey', 'pink', 'navy']
markets = ['o', 'v', '^', '>', '<', '+', 'x', '*', 'd', 'D']
for i in range(precisions.shape[0]):
# plt.plot(x[i], precisions[i, :], marker=markets[i % 10], color=colors[i % 10], label=label[i])
plt.plot(x[i], precisions[i], color=colors[i % 10], label=label[i])
# plt.plot(x, precisions[i, :], color=colors[i % 10], label=label[i])
plt.grid()
ax = plt.axes()
ax.set(xlim=(0, 1), ylim=(round(min_presion * 10 - 1) * 0.1, (round(max_presion * 10)) * 0.1))
plt.legend(
```
<Overlap Ratio: 0.9636048526863085>

---

--- 249 --
Question ID: 86145ce6242f96d8541d77e28d22d17b889db316_0
Original Code:
```
def profile_function(mod, dev, collectors, func_name="main", warmup_iters=10):
    """Collect performance information of a function execution. Usually used with
    a compiled PrimFunc.

    This information can include performance counters like cache hits and FLOPs
    that are useful in debugging performance issues of individual PrimFuncs.
    Different metrics can be collected depending on which MetricCollector is
    used.

    Example
    -------

    .. code-block: python
        f = tvm.build(my_func, target="llvm", name="my_func")
        prof = tvm.runtime.profiling.profile_function(
            f,
            tvm.cpu(),
            [tvm.runtime.profiling.PAPIMetricCollector({tvm.cpu(): ["PAPI_FP_OPS"]}),
        )
        counters = prof(*args)
        print(counters)

    Parameters
    ----------
    mod: Module
        Module containing the function to profile.
    dev: Device
        Device to run the function on.

    collectors: List[MetricCollector]
        :py:class:`MetricCollector`s which will collect performance information.
    func_name: str
        Name of the function in `mod` to profile. Defaults to "main".
    warmup_iters: int
        Number of iterations to run the function before collecting performance
        information. Recommended to set this larger than 0 for consistent cache
        effects. Defaults to 10.

    Returns
    -------
    prof: PackedFunc[args, Dict[str, ObjectRef]]
        PackedFunc which takes the same arguments as the `mod[func_name]` and
        returns performance metrics as a `Dict[str, ObjectRef]` where values
        can be `CountNode`, `DurationNode`, `PercentNode`.
    """
    return _ffi_api.ProfileFunction(
        mod, func_name, dev.device_type, dev.device_id, warmup_iters, collectors
    )
```


Overlapping Code:
```
c_name="main", warmup_iters=10):
"""Collect performance information of a function execution. Usually used with
a compiled PrimFunc.
This information can include performance counters like cache hits and FLOPs
that are useful in debugging performance issues of individual PrimFuncs.
Different metrics can be collected depending on which MetricCollector is
used.
Example
-------
.. code-block: python
f = tvm.build(my_func, target="llvm", name="my_func")
prof = tvm.runtime.profiling.profile_function(
f,
tvm.cpu(),
[tvm.runtime.profiling.PAPIMetricCollector({tvm.cpu(): ["PAPI_FP_OPS"]}),
)
counters = prof(*args)
print(counters)
Parameters
----------
mod: Module
Module containing the function to profile.
dev: Device
Device to run the function on.
collectors: List[MetricCollector]
:py:class:`MetricCollector`s which will collect performance information.
func_name: str
Name of the function in `mod` to profile. Defaults to "main".
warmup_iters: int
Number of iterations to run the function before collecting performance
information. Recommended to set this larger than 0 for consistent cache
effects. Defaults to 10.
Returns
-------
prof: PackedFunc[args, Dict[str, ObjectRef]]
PackedFunc which takes the same arguments as the `mod[func_name]` and
returns performance metrics as a `Dict[str, ObjectRef]` where values
can be `CountNode`, `DurationNode`, `PercentNode`.
"""
return _ffi_api.ProfileFunction(
mod, func_name, dev.device_type, dev.device_
```
<Overlap Ratio: 0.9501965923984272>

---

--- 250 --
Question ID: c765f106244ed67362c7c994dfe96cabfd5ecfe7_3
Original Code:
```
def save_model(step, saver, sess):
	print('Saving the model at step-%d'%step)

	saved_model_path = saver.save(sess, FLAGS.model_dir+'model', global_step=step)

	print('have saved model to ', saved_model_path)
	print("rewriting the number of model to config.py")

	#write the best checkpoint number back to the config.py file
	configFile=open(FLAGS.config_dir, "r")
	content=[line.strip("\n") for line in configFile]
	configFile.close()

	for i in range(len(content)):
		if ("checkpoint_path" in content[i]):
			content[i]="tf.app.flags.DEFINE_string('checkpoint_path', './model/model-%d','The path to a checkpoint from which to fine-tune.')"%step
	
	configFile=open(FLAGS.config_dir, "w")
	for line in content:
		configFile.write(line+"\n")
	configFile.close()
```


Overlapping Code:
```
el(step, saver, sess):
print('Saving the model at step-%d'%step)
saved_model_path = saver.save(sess, FLAGS.model_dir+'model', global_step=step)
print('have saved model to ', saved_model_path)
print("rewriting the number of model to config.py")
#write the best checkpoint number back to the config.py file
configFile=open(FLAGS.config_dir, "r")
content=[line.strip("\n") for line in configFile]
configFile.close()
for i in range(len(content)):
if ("checkpoint_path" in content[i]):
content[i]="tf.app.flags.DEFINE_string('checkpoint_path', './model/model-%d','The path to a checkpoint from which to fine-tune.')"%step

configFile=open(FLAGS.config_dir, "w")
for line in content:
configFile.write(line+"\n")
configFile
```
<Overlap Ratio: 0.9728260869565217>

---

--- 251 --
Question ID: d5a168a7ac63614a45963af3a2360ac1f8fa11b1_1
Original Code:
```
def showblock(bx, by, shape, c):
  for y in range(0, 4):
    for x in range(0, 4):
      if shape & (1<<(y*4+x)):
        map[bx+x][by+y] = c
```


Overlapping Code:
```
ange(0, 4):
for x in range(0, 4):
if shape & (1<<(
```
<Overlap Ratio: 0.4132231404958678>

---

--- 252 --
Question ID: ffe89aee829efc4f673ecb63fcd56a9a2fe4a41e_1
Original Code:
```
def get_play(game_id, options, fight_id, status, client_state, version):
    "botfights get_play function for countdown"
    if None == client_state:
        return None
    plays = {}
    for round_id, round_data in client_state['rounds'].items():
        target = round_data[0]
        operands = round_data[1]
        code = get_play_adder(target, operands)
        plays[round_id] = code
    return plays
```


Overlapping Code:
```
 client_state, version):
"botfights get_play function for countdown"
if None == client_state:
return None
plays = {}
for round_id, round_data in client_state['rounds'].items():
target = round_data[0]
operands = round_data[1]
code = get_play_adder(target, operands)
plays[round_id] = code
return plays
```
<Overlap Ratio: 0.8620689655172413>

---

--- 253 --
Question ID: 492b01d0a2ff285db1f00f3fd18128d140552b31_1
Original Code:
```
def main(args):
    """ Transforms the problem file streamed in through the standard input using JSON the data file passed via command-line argument. """
    if len(args) < 1:
        eprint("Usage: {0} <data.json>".format(os.path.basename(sys.argv[0])))
        exit(-1)

    data_path = args[0]
    # with open(data_path, mode='r', encoding="utf-8") as fp:
    with io.open(data_path, mode='r', encoding="utf-8") as fp:
        input_data = json.load(fp)

    template = Template(template_text)
    template.environment.filters['tif'] = tif_filter
    template.environment.filters['mapattr'] = map_filter

    rendered = template.render(data=input_data)

    # output the rednered template to the standard output
    print(rendered)
    print("; This PDDL problem file was generated using Jinja2 template")
    print(";    Python: " + sys.version)
    print(";    Data: " + data_path)
    print(";    Time: " + str(datetime.datetime.now()))
```


Overlapping Code:
```
gs):
""" Transforms the problem file streamed in through the standard input using JSON the data file passed via command-line argument. """
if len(args) < 1:
eprint("Usage: {0} <data.json>".format(os.path.basename(sys.argv[0])))
exit(-1)
data_path = args[0]
# with open(data_path, mode='r', encoding="utf-8") as fp:
with io.open(data_path, mode='r', encoding="utf-8") as fp:
input_data = json.load(fp)
template = Template(template_text)
template.environment.filters['tif'] = tif_filter
template.environment.filters['mapattr'] = map_filter
rendered = template.render(data=input_data)
# output the rednered template to the standard output
print(rendered)
print("; This PDDL problem file was generated using Jinja2 template")
print("; Python: " + sys.version)
print("; Data: " + data_path)
print("; Time: " + str(datetime.datetime.now()))
```
<Overlap Ratio: 0.98698224852071>

---

--- 254 --
Question ID: 099625f87b0b4ac8aab4aca696b8c929a6e85cb8_1
Original Code:
```
def _validate_stream_header(file: File):
    try:
        header = parser.cparser_be.stream_header_t(file)
    except EOFError:
        return False

    return (
        header.magic == STREAM_MAGIC
        and header.version == HUFFMAN_VERSION
        and HUNDRED_K_BLOCK_MIN <= header.hundred_k_blocksize <= HUNDRED_K_BLOCK_MAX
    )
```


Overlapping Code:
```
idate_stream_header(file: File):
try:
header = parser.cparser_be.stream_header_t(file)
except EOFError:
return False
return (
header.magic == STREAM_MAGIC
and header.version == HUFFMAN_VERSION
and HUNDRED_K_BLOCK_MIN <= header.hundred_k_blocksize <= 
```
<Overlap Ratio: 0.8960573476702509>

---

--- 255 --
Question ID: 485df8d752e40e82b5d4887a67e26061574addfb_7
Original Code:
```
def write_to_string(
    input_otio,
    adapter_name='otio_json',
    **adapter_argument_map
):
    """Return input_otio written to a string using adapter_name.

    Example:
        raw_text = otio.adapters.write_to_string(my_timeline, "otio_json")
    """

    adapter = plugins.ActiveManifest().from_name(adapter_name)
    return adapter.write_to_string(
        input_otio=input_otio,
        **adapter_argument_map
    )
```


Overlapping Code:
```
otio,
adapter_name='otio_json',
**adapter_argument_map
):
"""Return input_otio written to a string using adapter_name.
Example:
raw_text = otio.adapters.write_to_string(my_timeline, "otio_json")
"""
adapter = plugins.ActiveManifest().from_name(adapter_name)
return adapter.write_to_string(
input_otio
```
<Overlap Ratio: 0.8241758241758241>

---

--- 256 --
Question ID: 738741668e4fc286aa3d5766559b5f3eb6297a80_0
Original Code:
```
def assert_poly_almost_equal(p1, p2, msg=""):
    try:
        assert_(np.all(p1.domain == p2.domain))
        assert_(np.all(p1.window == p2.window))
        assert_almost_equal(p1.coef, p2.coef)
    except AssertionError:
        msg = "Result: %s\nTarget: %s", (p1, p2)
        raise AssertionError(msg)
```


Overlapping Code:
```
ef assert_poly_almost_equal(p1, p2, msg=""):
try:
assert_(np.all(p1.domain == p2.domain))
assert_(np.all(p1.window == p2.window))
assert_almost_equal(p1.coef, p2.coef)
except AssertionError:
msg = "Result: %s\nTarget: %s", (p1, p2)
raise AssertionErr
```
<Overlap Ratio: 0.9689922480620154>

---

--- 257 --
Question ID: 0a5ee5468122bdbb8d95274ef795ea8e50563a93_5
Original Code:
```
def branch_tica(centers, bandwidth, fusing_tolerance=1, logweights=None):
    inf, sup = np.min(centers), np.max(centers)
    padding = 1.1
    init_points = np.arange(inf*padding, sup*padding, bandwidth)[:, np.newaxis]
    fixed_points, kde = find_fes_fixed_points(centers[:, np.newaxis], bandwidth, init_points, return_kde = True, logweights=logweights)
    state_bounds = get_state_bounds(fixed_points, kde, [inf, sup])
    state_bounds = fuse_bounds(state_bounds, tol = fusing_tolerance)
    _fes = -kde.logpdf(kde.dataset)
    for d in state_bounds:
        inf = d['bounds'][0]
        sup = d['bounds'][1]
        d['fes'] = _fes
        d['mask'] = np.logical_and(centers >= inf, centers <= sup)
    return state_bounds
```


Overlapping Code:
```
ters, bandwidth, fusing_tolerance=1, logweights=None):
inf, sup = np.min(centers), np.max(centers)
padding = 1.1
init_points = np.arange(inf*padding, sup*padding, bandwidth)[:, np.newaxis]
fixed_points, kde = find_fes_fixed_points(centers[:, np.newaxis], bandwidth, init_points, return_kde = True, logweights=logweights)
state_bounds = get_state_bounds(fixed_points, kde, [inf, sup])
state_bounds = fuse_bounds(state_bounds, tol = fusing_tolerance)
_fes = -kde.logpdf(kde.dataset)
for d in state_bounds:
inf = d['bounds'][0]
sup = d['bounds'][1]
d['fes'] = _fes
d['mask'] = np.logical_and(centers >= 
```
<Overlap Ratio: 0.9104704097116844>

---

--- 258 --
Question ID: 8db74457f0fea727e6021840d686343cb3d258f2_7
Original Code:
```
def pam_waveform2(ak, TS,  
                 samples = 10, tinitial = 0, tguard = 0.0):
    
    Dt = TS / samples                                # sampling period    
    Nguard = np.round(tguard / Dt)                   # guard points                         
    Ntot = 2 * Nguard + samples * ak.size            # total number of points   
    
    x = np.zeros( Ntot.astype(int) )
    t = np.arange( tinitial, tinitial + Ntot * Dt, Dt )

    i = np.floor( (t - tinitial) / TS).astype(int)
    j = np.where( np.logical_and(i >= 0, i < ak.size ) )

    x[j] = ak[ i[j] ]
    return t, x
```


Overlapping Code:
```
S, 
samples = 10, tinitial = 0, tguard = 0.0):

Dt = TS / samples # sampling period 
Nguard = np.round(tguard / Dt) # guard points 
Ntot = 2 * Nguard + samples * ak.size # total number of points 

x = np.zeros( Ntot.astype(int) )
t = np.arange( tinitial, tinitial + Ntot * Dt, Dt )
i = np.floor( (t - tinitial) / TS).astype(int)
j = np.where( np.logical_and(i >= 0, i < ak.size ) )
x[j] = ak[ i[j] ]
r
```
<Overlap Ratio: 0.923963133640553>

---

--- 259 --
Question ID: 7668d492e756b0a06bc64af07dea863e5e516702_2
Original Code:
```
@pytest.mark.parametrize(
    "discovery,username",
    [
        (TEST_DISCOVERY, TEST_USERNAME),
        (TEST_DISCOVERY2, TEST_USERNAME2),
    ],
)
async def test_zeroconf_flow(
    hass: HomeAssistant,
    mock_setup_entry: AsyncMock,
    mock_smile_config_flow: MagicMock,
    discovery: ZeroconfServiceInfo,
    username: str,
) -> None:
    """Test config flow for smile devices."""
    result = await hass.config_entries.flow.async_init(
        DOMAIN,
        context={CONF_SOURCE: SOURCE_ZEROCONF},
        data=discovery,
    )
    assert result.get("type") == RESULT_TYPE_FORM
    assert result.get("errors") == {}
    assert result.get("step_id") == "user"
    assert "flow_id" in result

    result2 = await hass.config_entries.flow.async_configure(
        result["flow_id"],
        user_input={CONF_PASSWORD: TEST_PASSWORD},
    )
    await hass.async_block_till_done()

    assert result2.get("type") == RESULT_TYPE_CREATE_ENTRY
    assert result2.get("title") == "Test Smile Name"
    assert result2.get("data") == {
        CONF_HOST: TEST_HOST,
        CONF_PASSWORD: TEST_PASSWORD,
        CONF_PORT: DEFAULT_PORT,
        CONF_USERNAME: username,
        PW_TYPE: API,
    }

    assert len(mock_setup_entry.mock_calls) == 1
    assert len(mock_smile_config_flow.connect.mock_calls) == 1
```


Overlapping Code:
```
.mark.parametrize(
"discovery,username",
[
(TEST_DISCOVERY, TEST_USERNAME),
(TEST_DISCOVERY2, TEST_USERNAME2),
],
)
async def test_zeroconf_flow(
hass: HomeAssistant,
mock_setup_entry: AsyncMock,
mock_smile_config_flow: MagicMock,
discovery: ZeroconfServiceInfo,
username: str,
) -> None:
"""Test config flow for smile devices."""
result = await hass.config_entries.flow.async_init(
DOMAIN,
context={CONF_SOURCE: SOURCE_ZEROCONF},
data=discovery,
)
assert result.get("type") == RESULT_TYPE_FORM
assert result.get("errors") == {}
assert result.get("step_id") == "user"
assert "flow_id" in result
result2 = await hass.config_entries.flow.async_configure(
result["flow_id"],
user_input={CONF_PASSWORD: TEST_PASSWORD},
)
await hass.async_block_till_done()
assert result2.get("type") == RESULT_TYPE_CREATE_ENTRY
assert result2.get("title") == "Test Smile Name"
assert result2.get("data") == {
CONF_HOST: TEST_HOST,
CONF_PASSLT_PORT,
CONF_USERNAME: username,
PW_TYPE: API,
}
assert len(mock_setup_entry.mock_calls) == 1
assert len(mock_smile_config_flow.connect.mock_calls) =
```
<Overlap Ratio: 0.9578853046594982>

---

--- 260 --
Question ID: 5cd1dea68f2e347491dee7a10cd364506c37c0c3_3
Original Code:
```
def testUserInput():
    fileName = QtGui.QFileDialog.getOpenFileName(getMainWindow(), 'Open file',)
    if fileName:
        smp.OpenDataFile(fileName, guiName=os.path.basename(fileName))
        smp.Show()
        smp.ResetCamera()
        smp.Render()
```


Overlapping Code:
```
ef testUserInput():
fileName = QtGui.QFileDialog.getOpenFileName(getMainWindow(), 'Open file',)
if fileName:
smp.OpenDataFile(fileName, guiName=os.path.basename(fileName))
smp.Show()
smp.ResetCamera()
```
<Overlap Ratio: 0.9345794392523364>

---

--- 261 --
Question ID: 607414f84dd65ce953b25da5fd2f17868e0ddf93_0
Original Code:
```
def post_indexing_handler(program_enrollments):
    """
    Do the work which happens after a profile is reindexed

    Args:
        program_enrollments (list of ProgramEnrollment): A list of ProgramEnrollments
    """
    feature_sync_user = settings.FEATURES.get('OPEN_DISCUSSIONS_USER_SYNC', False)

    if not feature_sync_user:
        log.debug('OPEN_DISCUSSIONS_USER_SYNC is set to False (so disabled) in the settings')

    _refresh_all_default_indices()
    for program_enrollment in program_enrollments:
        try:
            _send_automatic_emails(program_enrollment)
        except:  # pylint: disable=bare-except
            log.exception("Error sending automatic email for enrollment %s", program_enrollment)

        # only update for discussion queries for now
        try:
            _update_percolate_memberships(program_enrollment.user, PercolateQuery.DISCUSSION_CHANNEL_TYPE)
        except:  # pylint: disable=bare-except
            log.exception("Error syncing %s to channels", program_enrollment.user)
```


Overlapping Code:
```
ng_handler(program_enrollments):
"""
Do the work which happens after a profile is reindexed
Args:
program_enrollments (list of ProgramEnrollment): A list of ProgramEnrollments
"""
feature_sync_user = settings.FEATURES.get('OPEN_DISCUSSIONS_USER_SYNC', False)
if not feature_sync_user:
log.debug('OPEN_DISCUSSIONS_USER_SYNC is set to False (so disabled) in the settings')
_refresh_all_default_indices()
for program_enrollment in program_enrollments:
try:
_send_automatic_emails(program_enrollment)
except: # pylint: disable=bare-except
log.exception("Error sending automatic email for enrollment %s", program_enrollment)
# only update for discussion queries for now
try:
_update_percolate_memberships(program_enrollment.user, PercolateQuery.DISCUSSION_CHANNEL_TYPE)
except: # pylint: disable=bare-except
log.exception("Error syncing %s to channels", program_enr
```
<Overlap Ratio: 0.9684684684684685>

---

--- 262 --
Question ID: 0c7590281c52f053295c7c2733b2977deee1453a_1
Original Code:
```
def logout(request):
    if request.method == 'POST' or not request.user.is_authenticated():
        auth.logout(request)
        return redirect('static:landing')

    return render(request, 'account/logout.html')
```


Overlapping Code:
```
):
if request.method == 'POST' or not request.user.is_authenticated():
auth.logout(request)
return redirect('static:landing')
return render(request, '
```
<Overlap Ratio: 0.7936507936507936>

---

--- 263 --
Question ID: 74c00a0741d0c6dfe09a522e6c2038e228996ef2_1
Original Code:
```
def _conv_bn_relu(**conv_params):
  """Helper to build a conv -> BN -> relu block."""
  filters = conv_params["filters"]
  kernel_size = conv_params["kernel_size"]
  strides = conv_params.setdefault("strides", (1, 1))
  kernel_initializer = conv_params.setdefault("kernel_initializer", "he_normal")
  padding = conv_params.setdefault("padding", "same")
  kernel_regularizer = conv_params.setdefault("kernel_regularizer", l2(1.e-4))

  def f(inpt):
    conv = Conv2D(
        filters=filters,
        kernel_size=kernel_size,
        strides=strides,
        padding=padding,
        kernel_initializer=kernel_initializer,
        kernel_regularizer=kernel_regularizer)(
            inpt)
    return _bn_relu(conv)

  return f
```


Overlapping Code:
```
_conv_bn_relu(**conv_params):
"""Helper to build a conv -> BN -> relu block."""
filters = conv_params["filters"]
kernel_size = conv_params["kernel_size"]
strides = conv_params.setdefault("strides", (1, 1))
kernel_initializer = conv_params.setdefault("kernel_initializer", "he_normal")
padding = conv_params.setdefault("padding", "same")
kernel_regularizer = conv_params.setdefault("kernel_regularizer", l2(1.e-4))
def f(inpt):
conv = Conv2D(
filters=filters,
kernel_size=kernel_size,
strides=strides,
padding=padding,
kernel_initializer=kernel_initializer,
kernel_regularizer=kernel_regularizer)(

```
<Overlap Ratio: 0.9372056514913658>

---

--- 264 --
Question ID: 3d242408af15e8590789d85d9b83bfbf77b90b2c_3
Original Code:
```
@pytest.mark.usefixtures("dummyG")
@pytest.mark.parametrize("sort_by", ("value", None))
@pytest.mark.parametrize("group_by", ("group", None))
def test_arc(dummyG, group_by, sort_by):
    """Test for arc layout.

    Checks:

    1. X-axis minimum is 0.
    2. X-axis maximum is 2 * (num_nodes - 1)
    3. Y-axis remains at 0 all the time.
    """

    pos, nt = get_pos_df(dummyG, layouts.arc, group_by=group_by, sort_by=sort_by)
    assert pos["x"].min() == 0
    assert pos["x"].max() == 2 * (len(nt) - 1)
    assert all(pos["y"] == 0.0)
```


Overlapping Code:
```
.mark.usefixtures("dummyG")
@pytest.mark.parametrize("sort_by", ("value", None))
@pytest.mark.parametrize("group_by", ("group", None))
def test_arc(dummyG, group_by, sort_by):
"""Test for arc layout.
Checks:
1. X-axis minimum is 0.
2. X-axis maximum is 2 * (num_nodes - 1)
3. Y-axis remains at 0 all the time.
"""
pos, nt = get_pos_df(dummyG, layouts.arc, group_by=group_by, sort_by=sort_by)
assert pos["x"].min() == 0
assert pos["x"].max() == 2 * (len(n
```
<Overlap Ratio: 0.9153225806451613>

---

--- 265 --
Question ID: 16ab4d78e447e1448969cfed303856d05bbd1f00_18
Original Code:
```
def grouping_assign_net(message, f):
	@wraps(f)
	def decorated(*args, **kwargs):
		result = f(*args, **kwargs)
		net_id = -1
		if kwargs.get("net") is None:
			if kwargs.get("net_id") is None:
				net_id = args[1].id if isinstance(args[1], hal_py.Net) else args[1]
			else:
				net_id = kwargs.get("net_id")
		else:
			net_id = kwargs.get("net").id
		log_string = "Function: {}, Grouping-ID: {}, Net-ID: {}".format(message, args[0].id, net_id)
		hal_py.log_info(log_string)
		return result
	return decorated
```


Overlapping Code:
```
(message, f):
@wraps(f)
def decorated(*args, **kwargs):
result = f(*args, **kwargs)
net_id = -1
if kwargs.get("net") is None:
if kwargs.get("net_id") is None:
net_id = args[1].id if isinstance(args[1], hal_py.Net) else args[1]
else:
net_id = kwargs.get("net_id")
else:
net_id = kwargs.get("net").id
log_string = "Function: {}, Grouping-ID: {}, Net-ID: {}".format(message, args[0].id, net_id)
hal_py.log_info(log_
```
<Overlap Ratio: 0.8710359408033826>

---

--- 266 --
Question ID: a648b495b9d5ba66f2c643fd68483de1a1c9691e_0
Original Code:
```
def beta_posteriors_all(
    totals: List[int],
    positives: List[int],
    sim_count: int,
    a_priors_beta: List[Union[float, int]],
    b_priors_beta: List[Union[float, int]],
    seed: Union[int, np.random.bit_generator.SeedSequence] = None,
) -> np.ndarray:
    """
    Draw from beta posterior distributions for all variants at once.

    Parameters
    ----------
    totals : List of numbers of experiment observations (e.g. number of sessions) for each variant.
    positives : List of numbers of ones (e.g. number of conversions) for each variant.
    sim_count : Number of simulations to be used for probability estimation.
    a_priors_beta : List of prior alpha parameters for Beta distributions for each variant.
    b_priors_beta : List of prior beta parameters for Beta distributions for each variant.
    seed : Random seed.

    Returns
    -------
    beta_samples : List of lists of beta distribution samples for all variants.
    """
    rng = np.random.default_rng(seed)

    beta_samples = np.array(
        [
            rng.beta(
                positives[i] + a_priors_beta[i],
                totals[i] - positives[i] + b_priors_beta[i],
                sim_count,
            )
            for i in range(len(totals))
        ]
    )
    return beta_samples
```


Overlapping Code:
```

positives: List[int],
sim_count: int,
a_priors_beta: List[Union[float, int]],
b_priors_beta: List[Union[float, int]],
seed: Union[int, np.random.bit_generator.SeedSequence] = None,
) -> np.ndarray:
"""
Draw from beta posterior distributions for all variants at once.
Parameters
----------
totals : List of numbers of experiment observations (e.g. number of sessions) for each variant.
positives : List of numbers of ones (e.g. number of conversions) for each variant.
sim_count : Number of simulations to be used for probability estimation.
a_priors_beta : List of prior alpha parameters for Beta distributions for each variant.
b_priors_beta : List of prior beta parameters for Beta distributions for each variant.
seed : Random seed.
Returns
-------
beta_samples : List of lists of beta distribution samples for all variants.
"""
rng = np.random.default_rng(seed)
beta_samples = np.array(
[
rng.beta(
positives[i] + a_priors_beta[i],
totals[i] - positives[i] + b_priors_beta[i],
sim_count,
)
for i
```
<Overlap Ratio: 0.9182736455463728>

---

--- 267 --
Question ID: 149b81015b3e5cf297b77c6df214ea8f24d3192e_1
Original Code:
```
def test_stream_forms_configured(requests_mock, config, form_response):
    requests_mock.register_uri("GET", TYPEFORM_BASE_URL + "forms/u6nXL7", form_response)
    requests_mock.register_uri("GET", TYPEFORM_BASE_URL + "forms/k9xNV4", form_response)

    stream = Forms(authenticator=MagicMock(), **config)

    merged_records = merge_records(stream, SyncMode.full_refresh)

    assert len(merged_records) == 2
```


Overlapping Code:
```
est_stream_forms_configured(requests_mock, config, form_response):
requests_mock.register_uri("GET", TYPEFORM_BASE_URL + "forms/u6nXL7", form_response)
requests_mock.register_uri("GET", TYPEFORM_BASE_URL + "forms/k9xNV4", form_response)
stream = Forms(authenticator=MagicMock(), **config)
merged_records = merge_records(stream, SyncMode.full_refresh)
assert len(merged_records) ==
```
<Overlap Ratio: 0.9819121447028424>

---

--- 268 --
Question ID: 0c34c74254adca1ea72841213ddd4c11d1ac144a_0
Original Code:
```
def profile_cpu_bound_program():
    real_dog = DogStatsApi()
    real_dog.reporter = NullReporter()
    fake_dog = NullDogStatsApi()
    for type_, dog in [('real', real_dog), ('fake', fake_dog)]:
        print('\n\n\nTESTING %s\n\n' % type_)
        dog.start()
        program = CPUBoundProgram(dog)
        yappi.start()
        program.run()
        yappi.print_stats(sort_type=yappi.SORTTYPE_TSUB, sort_order=yappi.SORTORDER_DESC)
        yappi.stop()
        yappi.clear_stats()
```


Overlapping Code:
```
ofile_cpu_bound_program():
real_dog = DogStatsApi()
real_dog.reporter = NullReporter()
fake_dog = NullDogStatsApi()
for type_, dog in [('real', real_dog), ('fake', fake_dog)]:
print('\n\n\nTESTING %s\n\n' % type_)
dog.start()
program = CPUBoundProgram(dog)
yappi.start()
program.run()
yappi.print_stats(sort_type=yappi.SORTTYPE_TSUB, sort_order=yappi.SORTORDER_DESC
```
<Overlap Ratio: 0.9012345679012346>

---

--- 269 --
Question ID: 8043c1fe3256d03debb92099ce4c83c33572d279_2
Original Code:
```
def saved_example(filename):
    n, w = example(filename)

    soln = activelo.solve(n, w)

    activelo.plot(soln)

    return soln
```


Overlapping Code:
```
example(filename):
n, w = example(filename)
soln = activelo.solve(n, w)
activelo.plot(soln)
return s
```
<Overlap Ratio: 0.8849557522123894>

---

--- 270 --
Question ID: e6f6035a38d2a762a1a22dcfebc8a53bf471da7c_0
Original Code:
```
def main(word):
    word_mat = generate_sparse_mat(word.upper())
    counter = 0
    # Change date to first pixel of contribution chart
    for row in word_mat:
        row_str = ""
        for val in row:
            commit_date = FIRST_CONTRIB_DATE + datetime.timedelta(days=counter)
            row_str = f"{row_str} {commit_date}---{val}"
            execute_cmd(f"""git commit --allow-empty -m "EMPTY COMMIT" --date="{commit_date}" """, val)
            counter = counter + 1
```


Overlapping Code:
```
(word):
word_mat = generate_sparse_mat(word.upper())
counter = 0
# Change date to first pixel of contribution chart
for row in word_mat:
row_str = ""
for val in row:
commit_date = FIRST_CONTRIB_DATE + datetime.timedelta(days=counter)
row_str = f"{row_str} {commit_date}---{val}"
execute_cmd(f"""git commit --allow-empty -m "EMPTY COMMIT" --date="{com
```
<Overlap Ratio: 0.875>

---

--- 271 --
Question ID: c9e0eae1777a2c1aae0ba0fda714b5777f97799c_4
Original Code:
```
def Init():
    
    """
   

    Returns
    -------
    edelta : TYPE
        DESCRIPTION.
    comspace : TYPE
        DESCRIPTION.
    cna_sigs : TYPE
        DESCRIPTION.
    adj : TYPE
        DESCRIPTION.
    agcn : TYPE
        DESCRIPTION.
    com : TYPE
        DESCRIPTION.
    comdist : TYPE
        DESCRIPTION.
    surf_atoms : TYPE
        DESCRIPTION.
    comAu : TYPE
        DESCRIPTION.
    comPt : TYPE
        DESCRIPTION.
    hoadjAu : TYPE
        DESCRIPTION.
    hoadjPt : TYPE
        DESCRIPTION.
    comdistAu : TYPE
        DESCRIPTION.
    comdistPt : TYPE
        DESCRIPTION.
    midcomdistAu : TYPE
        DESCRIPTION.
    midcomdistPt : TYPE
        DESCRIPTION.
    surf_atomsPt : TYPE
        DESCRIPTION.
    headj : TYPE
        DESCRIPTION.
    mix : TYPE
        DESCRIPTION.

    """
    
    edelta = {}; comspace = {}; cna_sigs = {}
    com = {}; comdist = {}; surf_atoms = {} 
    comAu = {}; comPt = {}; hoadjAu = {}; hoadjPt = {} 
    comdistAu = {}; comdistPt = {}; midcomdistPt = {} ; nn = {}
    midcomdistAu = {}; surf_atomsPt = {}; headj = {}; mix = {}
    PtAu = {}; PtOnly = {}; AvgCoPt = {}; GyrationPt = {}; Gyration = {}
    return (edelta, comspace, cna_sigs, com, comdist, 
            surf_atoms, comAu, comPt, hoadjAu, hoadjPt, comdistAu, 
            comdistPt, midcomdistAu, midcomdistPt, surf_atomsPt, 
            headj, mix, nn, PtAu, PtOnly, AvgCoPt, Gyration, GyrationPt)
```


Overlapping Code:
```
():

"""

Returns
-------
edelta : TYPE
DESCRIPTION.
comspace : TYPE
DESCRIPTION.
cna_sigs : TYPE
DESCRIPTION.
adj : TYPE
DESCRIPTION.
agcn : TYPE
DESCRIPTION.
com : TYPE
DESCRIPTION.
comdist : TYPE
DESCRIPTION.
surf_atoms : TYPE
DESCRIPTION.
comAu : TYPE
DESCRIPTION.
comPt : TYPE
DESCRIPTION.
hoadjAu : TYPE
DESCRIPTION.
hoadjPt : TYPE
DESCRIPTION.
comdistAu : TYPE
DESCRIPTION.
comdistPt : TYPE
DESCRIPTION.
midcomdistAu : TYPE
DESCRIPTION.
midcomdistPt : TYPE
DESCRIPTION.
surf_atomsPt : TYPE
DESCRIPTION.
headj : TYPE
DESCRIPTION.
mix : TYPE
DESCRIPTION.
"""

edelta = {}; comspace = {}; cna_sigs = {}
com = {}; comdist = {}; surf_atoms = {} 
comAu = {}; comPt = {}; hoadjAu = {}; hoadjPt = {} 
comdistAu = {}; comdistPt = {}; midcomdistPt = {} ; nn = {}
midcomdistAu = {}; surf_atomsPt = {}; headj = {}; mix = {}
PtAu = {}; PtOnly = {}; AvgCoPt = {}; GyrationPt = {}; Gyration = {}
return (edelta, comspace, cna_sigs, com, comdist, 
surf_atoms, comAu, comPt, hoadjAu, hoadjPt, comdistAu, 
comdistPt, midcomdistAu, midcomdistPt, surf_atomsPt, 
headj, mix, nn, PtAu, PtOnly, AvgCoPt, Gyration, Gy
```
<Overlap Ratio: 0.9847806624888094>

---

--- 272 --
Question ID: 6cadce240fbf8b19411c5a0ff75b5b3799d0bbfa_1
Original Code:
```
def _resnet(rng, arch, block, layers, pretrained, **kwargs):
  resnet = ResNet(block=block, layers=layers, **kwargs)

  if pretrained:
    torch_params = utils.load_torch_params(model_urls[arch])
    flax_params = FrozenDict(utils.torch_to_linen(torch_params, _get_flax_keys))
  else:
    init_batch = jnp.ones((1, 224, 224, 3), jnp.float32)
    flax_params = ResNet(block=block, layers=layers, **kwargs).init(rng, init_batch)

  return resnet, flax_params
```


Overlapping Code:
```
ers, pretrained, **kwargs):
resnet = ResNet(block=block, layers=layers, **kwargs)
if pretrained:
torch_params = utils.load_torch_params(model_urls[arch])
flax_params = FrozenDict(utils.torch_to_linen(torch_params, _get_flax_keys))
else:
init_batch = jnp.ones((1, 224, 224, 3), jnp.float32)
flax_params = ResNet(block=block, layers=layers, **kwargs).i
```
<Overlap Ratio: 0.813953488372093>

---

--- 273 --
Question ID: 4426a623f623fd1623255345c1f28dec064b7fcd_0
Original Code:
```
def spider(url) -> Tuple[List[str], List[Result]]:
    global _links, _insecure, _tasks, _lock

    results: List[Result] = []

    # create processing pool
    pool = Pool()
    mgr = Manager()
    queue = mgr.Queue()

    asy = pool.apply_async(_get_links, (url, [url], queue, pool))

    with _lock:
        _tasks.append(asy)

    while True:
        if all(t is None or t.ready() for t in _tasks):
            break
        else:
            count_none = 0
            count_ready = 0
            count_not_ready = 0

            for t in _tasks:
                if t is None:
                    count_none += 1
                elif t.ready():
                    count_ready += 1
                else:
                    count_not_ready += 1

            output.debug(
                f"Spider Task Status: None: {count_none}, Ready: {count_ready}, Not Ready: {count_not_ready}"
            )

        time.sleep(3)

    pool.close()

    for t in _tasks:
        try:
            t.get()
        except Exception:
            output.debug_exception()

    while not queue.empty():
        res = queue.get()

        if len(res) > 0:
            for re in res:
                if re not in results:
                    results.append(re)

    # copy data and reset
    links = _links[:]
    _links = []
    _insecure = []
    _tasks = []

    return links, results
```


Overlapping Code:
```
:
global _links, _insecure, _tasks, _lock
results: List[Result] = []
# create processing pool
pool = Pool()
mgr = Manager()
queue = mgr.Queue()
asy = pool.apply_async(_get_links, (url, [url], queue, pool))
with _lock:
_tasks.append(asy)
while True:
if all(t is None or t.ready() for t in _tasks):
break
else:
count_none = 0
count_ready = 0
count_not_ready = 0
for t in _tasks:
if t is None:
count_none += 1
elif t.ready():
count_ready += 1
else:
count_not_ready += 1
output.debug(
f"Spider Task Status: None: {count_none}, Ready: {count_ready}, Not Ready: {count_not_ready}"
)
time.sleep(3)
pool.close()
for t in _tasks:
try:
t.get()
except Exception:
output.debug_exception()
while not queue.empty():
res = queue.get()
if len(res) > 0:
for re in res:
if re not in results:
results.append(re)
# copy data and reset
links = _links[:]
_links = []
_inse
```
<Overlap Ratio: 0.9023354564755839>

---

--- 274 --
Question ID: abedbb71dc900007c5b4a1250241071aab24da8c_1
Original Code:
```
@make_symbolic
def str_locate(string, pattern):
    """
    Find the indices of all pattern matches.
    """
    try:
        if isinstance(string, str):
            raise TypeError
        return Series([[m.start(0) for m in re.finditer(pattern, s)] for s in string])

    except TypeError:
        return [m.start(0) for m in re.finditer(pattern, string)]
```


Overlapping Code:
```
ic
def str_locate(string, pattern):
"""
Find the indices of all pattern matches.
"""
try:
if isinstance(string, str):
raise TypeError
return Series([[m.start(0) for m in re.finditer(pattern, s)] for s in string])
except TypeError:
return [m.start(0) for m in re.finditer(pattern, stri
```
<Overlap Ratio: 0.9466666666666667>

---

--- 275 --
Question ID: 885cd0f4c410108e3f69319f24eaa06c4e0d9ec6_1
Original Code:
```
def run(args=None):
    """ The main routine. """
    cfg = Config()
    cfg.configure_logger()
    devices = {device.name: device for device in [create_device(c) for c in cfg.config['accelerometers']]}
    endpoint = TCP4ServerEndpoint(reactor, cfg.port)
    logger.info(f"Listening on port {cfg.port}")
    endpoint.listen(CommandFactory(devices))
    reactor.run()
```


Overlapping Code:
```
" The main routine. """
cfg = Config()
cfg.configure_logger()
devices = {device.name: device for device in [create_device(c) for c in cfg.config['accelerometers']]}
endpoint = TCP4ServerEndpoint(reactor, cfg.port)
logger.info(f"Listening on port {cfg.port}")
endpoint.listen(CommandFactory(devices))
reactor.run()
```
<Overlap Ratio: 0.9343283582089552>

---

--- 276 --
Question ID: 6f5814fe8730e00029487817530c9bc70c2de895_11
Original Code:
```
def test_represent():
    represent(sx) == Matrix([[0, 1], [1, 0]])
    represent(sy) == Matrix([[0, -I], [I, 0]])
    represent(sz) == Matrix([[1, 0], [0, -1]])
    represent(sm) == Matrix([[0, 0], [1, 0]])
    represent(sp) == Matrix([[0, 1], [0, 0]])
```


Overlapping Code:
```
= Matrix([[0, 1], [1, 0]])
represent(sy) == Matrix([[0, -I], [I, 0]])
represent(sz) == Matrix([[1, 0], [0, -1]])
represent(sm) == Matrix([[0, 0], [1, 
```
<Overlap Ratio: 0.6437768240343348>

---

--- 277 --
Question ID: 31b1d4edbe65d07219fd1e69499b5abc84f7382e_12
Original Code:
```
def test_UI_GIVEN_user_selects_entire_shape_WHEN_choosing_pixel_layout_THEN_pixel_mapping_becomes_visible(
    qtbot, template, pixel_options
):
    # Press the entire shape button under pixel layout
    systematic_button_press(qtbot, template, pixel_options.entire_shape_radio_button)

    # Check that the pixel mapping items are visible
    assert pixel_options.pixel_options_stack.isVisible()
    assert pixel_options.pixel_options_stack.currentIndex() == 1
```


Overlapping Code:
```
ape_WHEN_choosing_pixel_layout_THEN_pixel_mapping_becomes_visible(
qtbot, template, pixel_options
):
# Press the entire shape button under pixel layout
systematic_button_press(qtbot, template, pixel_options.entire_shape_radio_button)
# Check that the pixel mapping items are visible
assert pixel_options.pixel_options_stack.isVisible()
assert pixel_options.pixel_options_stack.currentInd
```
<Overlap Ratio: 0.8876146788990825>

---

--- 278 --
Question ID: 42e138c39602d365305963c0c6bd5d5d912f7af5_0
Original Code:
```
@click.command()
@click.argument('in_file', type=click.File(encoding='utf-8'))
@click.option('--out_dir', '-o', default=os.getcwd(), type=click.Path())
def openiti2txt(in_file, out_dir):
    """Remove metadata from a text in OpenITI format.
    """
    create_dirs(out_dir)

    text = []
    for line in in_file:
        # Ignore metadata in the file and openITI header
        if not line.startswith('#META#') and line != '######OpenITI#\n':
            text.append(line)

    # TODO: optionally remove other openITI tags

    text = u''.join(text)
    fname = out_file_name(out_dir, in_file.name, ext='txt')
    with codecs.open(fname, 'wb', encoding='utf-8') as f:
        f.write(text)
```


Overlapping Code:
```
ck.command()
@click.argument('in_file', type=click.File(encoding='utf-8'))
@click.option('--out_dir', '-o', default=os.getcwd(), type=click.Path())
def openiti2txt(in_file, out_dir):
"""Remove metadata from a text in OpenITI format.
"""
create_dirs(out_dir)
text = []
for line in in_file:
# Ignore metadata in the file and openITI header
if not line.startswith('#META#') and line != '######OpenITI#\n':
text.append(line)
# TODO: optionally remove other openITI tags
text = u''.join(text)
fname = out_file_name(out_dir, in_file.name, ext='txt')
with codecs.open(fname, 'wb', encoding='utf-8') as f:
f.write(tex
```
<Overlap Ratio: 0.9902439024390244>

---

--- 279 --
Question ID: 1415bdc005a082993a894bb214799989f44df486_3
Original Code:
```
def main():
    args = parse_args()
    # init models
    modelA = init_model(args.modelA, checkpoint=None, device=args.device)\
        .eval()
    modelB = init_model(args.modelB, checkpoint=None, device=args.device)\
        .eval()

    src_img = load_image(args.source_path).to(args.device)
    codes = modelA.encoder(src_img)
    latents = get_latent(modelA.decoder, codes)

    _, save_swap_layer = modelA.decoder.swap_forward(
        [latents],
        input_is_latent=True,
        swap=True, swap_layer_num=args.swap_layer,
    )

    image, _ = modelB.decoder.swap_forward(
        [latents],
        input_is_latent=True,
        swap=True, swap_layer_num=args.swap_layer,
        swap_layer_tensor=save_swap_layer,
    )
    # our generator's default output channel order is bgr
    image = image[:, [2, 1, 0], ...]

    mmcv.mkdir_or_exist(os.path.dirname(args.save_path))
    utils.save_image(image, args.save_path, normalize=True)
```


Overlapping Code:
```
()
# init models
modelA = init_model(args.modelA, checkpoint=None, device=args.device)\
.eval()
modelB = init_model(args.modelB, checkpoint=None, device=args.device)\
.eval()
src_img = load_image(args.source_path).to(args.device)
codes = modelA.encoder(src_img)
latents = get_latent(modelA.decoder, codes)
_, save_swap_layer = modelA.decoder.swap_forward(
[latents],
input_is_latent=True,
swap=True, swap_layer_num=args.swap_layer,
)
image, _ = modelB.decoder.swap_forward(
[latents],
input_is_latent=True,
swap=True, swap_layer_num=args.swap_layer,
swap_layer_tensor=save_swap_layer,
)
# our generator's default output channel order is bgr
image = image[:, [2, 1, 0], ...]
mmcv.mkdir_or_exist(os.path.dirname(args.save_path))
utils.save_image(image, args.
```
<Overlap Ratio: 0.9321824907521579>

---

--- 280 --
Question ID: 40c1efb9d0a40c79ea15e03a04a04e5ab8913a90_11
Original Code:
```
def get_mirror_offset_spots_dw():
    """
    Mirror shenanigans placing a mirror portal with a broken camera
    """
    yield ('Dark Death Mountain Offset Mirror', 'West Dark Death Mountain (Bottom)', 'Pyramid Area')
```


Overlapping Code:
```
offset_spots_dw():
"""
Mirror shenanigans placing a mirror portal with a broken camera
"""
yield ('Dark Death Mountain Offset Mirror', 'West Dark Death Mounta
```
<Overlap Ratio: 0.7821782178217822>

---

--- 281 --
Question ID: d1cf99c651cf0ffca23a43424ee2897df98d37ab_0
Original Code:
```
def drawDetection(image,detections,colors=None,cost=None):
    if image is None:
        return image
    for item in detections:
        xmin = item[3]
        ymin = item[4]
        xmax = item[5]
        ymax = item[6]
        label = str(int(item[1]))
        if colors is None:
            cv2.putText(image,label,(xmin,ymin), 3,1,(255,0,255))
            cv2.rectangle(image,(xmin,ymin),(xmax,ymax),(255,0,0))
        else:
            color=colors[int(round(item[1]))]
            color=[c *256 for c in color]
            cv2.putText(image,label,(xmin,ymin), 3,1,color)
            cv2.rectangle(image,(xmin,ymin),(xmax,ymax),color)

    if not cost is None:
        cv2.putText(image,cost,(0,40),3,1,(0,0,255))

    return image
```


Overlapping Code:
```
tion(image,detections,colors=None,cost=None):
if image is None:
return image
for item in detections:
xmin = item[3]
ymin = item[4]
xmax = item[5]
ymax = item[6]
label = str(int(item[1]))
if colors is None:
cv2.putText(image,label,(xmin,ymin), 3,1,(255,0,255))
cv2.rectangle(image,(xmin,ymin),(xmax,ymax),(255,0,0))
else:
color=colors[int(round(item[1]))]
color=[c *256 for c in color]
cv2.putText(image,label,(xmin,ymin), 3,1,color)
cv2.rectangle(image,(xmin,ymin),(xmax,ymax),color)
if not cost is None:
cv2.putText(image,cost,(0,40),3,1,(0,0,255))
ret
```
<Overlap Ratio: 0.9617391304347827>

---

--- 282 --
Question ID: 7e804b969e5bdce2e4c58f80048e6012e996d170_1
Original Code:
```
def update_s3_dir(audio_url, orca, validation):
    calls_path = 'calls' if orca else 'nocalls'
    validation_path = 'validation' if validation else 'train'
    filename = audio_url.split('/')[-1].split('.')[0]
    subprocess.run([
        'aws', 's3', 'mv', f'{s3_unlabeled_path}spectrograms/{filename}.png',
        f'{s3_labeled_path}{validation_path}/{calls_path}/'
    ])
    subprocess.run([
        'aws', 's3', 'mv', f'{s3_unlabeled_path}mp3/{filename}.mp3',
        f'{s3_labeled_path}mp3/{calls_path}/'
    ])
    return f'{s3_url}/mp3/{calls_path}/{filename}.mp3'
```


Overlapping Code:
```
, orca, validation):
calls_path = 'calls' if orca else 'nocalls'
validation_path = 'validation' if validation else 'train'
filename = audio_url.split('/')[-1].split('.')[0]
subprocess.run([
'aws', 's3', 'mv', f'{s3_unlabeled_path}spectrograms/{filename}.png',
f'{s3_labeled_path}{validation_path}/{calls_path}/'
])
subprocess.run([
'aws', 's3', 'mv', f'{s3_unlabeled_path}mp3/{filename}.mp3',
f'{s3_labeled_path}mp3/{calls_path}/'
])
return f'{s3_url
```
<Overlap Ratio: 0.8806262230919765>

---

--- 283 --
Question ID: 92fa0e2d3e968b63fba36a494cc3712bc8d88307_1
Original Code:
```
def is_real(val: (int, float)) -> bool:
    """
    Check if the provided argument is real

    :param val: value to check
    :return: boolean indicating value is real
    """
    return False if isinstance(val, complex) else True
```


Overlapping Code:
```
int, float)) -> bool:
"""
Check if the provided argument is real
:param val: value to check
:return: boolean indicating value is real
"""
return False
```
<Overlap Ratio: 0.7281553398058253>

---

--- 284 --
Question ID: c41a47e6b90f9ec11a16c23788a2988a40e6c2b6_4
Original Code:
```
def rawmoment(slc, sqc, scp, vm, k):
    """
    This is where the resultant distribution moments are calculated. MODIFY 
    THIS CODE AT YOUR OWN RISK. These equations have been verified with
    published equations and example problems by N.D. Cox.
    
    Each of the derivative components need to be standardized prior to input
    to this function. This means multiplying them by their respective
    standard deviations, depending on the order of the derivative. Helper
    functions have been defined for this purpose (standard_lc, standard_qc,
    and standard_cp). However, this is only necessary if manually calling this
    function rather than using soerp_numeric below.
    
    Parameters
    ----------
    slc : array
        The standardized first derivative terms.
    sqc : array
        The standardized pure second derivative terms
    scp : 2d-array
        The standardized cross-product second derivative terms
    vm : 2d-array
        The first 9 (starting at 0) standardized distribution moments (one 
        row for each input variable, corresponding to the derivative array 
        order). See the documentation for ``soerp_numeric`` for more details.
    k : int
        The kth distribution moment to calculate.
    
    Returns
    -------
    rm : scalar
        The kth raw distribution moment
    """
    lc = copy(slc)
    qc = copy(sqc)
    cp = copy(scp)
    n = len(lc)
    
    if assume_linear:
        qc[:] = 0.0
        cp[:,:] = 0.0
        
    ans = 0.0
        
    ############################
    # The 0th raw moment
    
    if k==0:
        ans = 1
        
    ############################
    # The 1st raw moment
    
    elif k==1:
        for i in range(n):
            ans += qc[i]*vm[i,2]
    
    ############################
    # The 2nd raw moment
    
    elif k==2:
        for i in range(n):
            ans += lc[i]**2*vm[i,2] + 2*lc[i]*qc[i]*vm[i,3] + qc[i]**2*vm[i,4]
        
        if n>=2:
            for i in range(n-1):
                for j in range(i+1, n):
                    ans += (2*qc[i]*qc[j] + cp[i,j]**2)*vm[i,2]*vm[j,2]
    
    ############################
    # The 3rd raw moment
    
    elif k==3:
        for i in range(n):
            ans += lc[i]**3*vm[i,3] + qc[i]**3*vm[i,6] + \
                   3*lc[i]**2*qc[i]*vm[i,4] + 3*lc[i]*qc[i]**2*vm[i,5]
        
        if n>=2:
            for i in range(n-1):
                for j in range(i+1, n):
                    ans += cp[i,j]**3*vm[i,3]*vm[j,3] + \
                           6*lc[i]*lc[j]*cp[i,j]*vm[i,2]*vm[j,2] + \
                           6*qc[i]*qc[j]*cp[i,j]*vm[i,3]*vm[j,3]
            for i in range(n):
                for j in range(n):
                    if j!=i:
                        ans += 3*qc[i]**2*vm[i,4]*qc[j]*vm[j,2] + \
                               6*lc[i]*qc[j]*cp[i,j]*vm[i,2]*vm[j,3] +\
                               3*qc[i]*lc[j]**2*vm[i,2]*vm[j,2] + \
                               6*lc[i]*qc[i]*qc[j]*vm[i,3]*vm[j,2] + \
                               3*lc[i]*cp[i,j]**2*vm[i,3]*vm[j,2] + \
                               3*qc[i]*cp[i,j]**2*vm[i,4]*vm[j,2]
        
        if n>=3:
            for i in range(n-2):
                for j in range(i+1, n-1):
                    for k in range(j+1, n):
                        ans += (6*qc[i]*qc[j]*qc[k] + \
                                6*cp[i,j]*cp[i,k]*cp[j,k] + 
                                3*(qc[i]*cp[j,k]**2 + \
                                qc[j]*cp[i,k]**2 + \
                                qc[k]*cp[i,j]**2))*vm[i,2]*vm[j,2]*vm[k,1]
    
    ############################
    # The 4th raw moment
    
    elif k==4:
        for i in range(n):
            ans += lc[i]**4*vm[i,4] + qc[i]**4*vm[i,8] + \
                   4*lc[i]**3*qc[i]*vm[i,5] + 4*lc[i]*qc[i]**3*vm[i,7] + \
                   6*lc[i]**2*qc[i]**2*vm[i,6]
        
        if n>=2:
            for i in range(n-1):
                for j in range(i+1, n):
                    ans += 6*lc[i]**2*lc[j]**2*vm[i,2]*vm[j,2] + \
                           6*qc[i]**2*qc[j]**2*vm[i,4]*vm[j,4] + \
                           cp[i,j]**4*vm[i,4]*vm[j,4] + \
                           12*cp[i,j]*(lc[i]**2*lc[j]*vm[i,3]*vm[j,2] + \
                                       lc[i]*lc[j]**2*vm[i,2]*vm[j,3]) + \
                           12*cp[i,j]*qc[i]*qc[j]*(qc[i]*vm[i,5]*vm[j,3] + \
                                                   qc[j]*vm[i,3]*vm[j,6]) + \
                           12*qc[i]*qc[j]*(lc[i]**2*vm[i,4]*vm[j,2] + \
                                           lc[j]**2*vm[i,2]*vm[j,4] + \
                                           2*lc[i]*lc[j]*vm[i,3]*vm[j,3]) + \
                           6*cp[i,j]**2*(lc[i]**2*vm[i,4]*vm[j,2] + \
                                         lc[j]**2*vm[i,2]*vm[j,4] + \
                                         2*lc[i]*lc[j]*vm[i,3]*vm[j,3]) + \
                           6*cp[i,j]**2*(qc[i]**2*vm[i,6]*vm[j,2] + \
                                         qc[j]**2*vm[i,2]*vm[j,6] + \
                                         2*qc[i]*qc[j]*vm[i,4]*vm[j,4]) + \
                           12*cp[i,j]*(lc[j]*qc[i]*(lc[j]*vm[i,3]*vm[j,3] + \
                                                    2*lc[i]*vm[i,4]*vm[j,2]) + \
                                       lc[i]*qc[j]*(lc[i]*vm[i,3]*vm[j,3] + \
                                                    2*lc[j]*vm[i,2]*vm[j,4])) +\
                           12*cp[i,j]*(lc[i]*qc[j]*(qc[j]*vm[i,2]*vm[j,5] + \
                                                    2*qc[i]*vm[i,4]*vm[j,3]) + \
                                       lc[j]*qc[i]*(qc[i]*vm[i,5]*vm[j,2] + \
                                                    2*qc[j]*vm[i,3]*vm[j,4])) +\
                           12*cp[i,j]**2*(qc[i]*(lc[i]*vm[i,5]*vm[i,2] + \
                                                 lc[j]*vm[i,4]*vm[j,3]) + \
                                          qc[j]*(lc[i]*vm[i,3]*vm[j,4] + \
                                                 lc[j]*vm[i,2]*vm[j,5]))
            for i in range(n):
                for j in range(n):
                    if i!=j:
                        ans += 4*qc[i]**3*qc[j]*vm[i,6]*vm[j,2] + \
                               4*qc[i]*lc[j]**3*vm[i,2]*vm[j,3] + \
                               12*lc[i]*qc[i]*lc[j]**2*vm[i,3]*vm[i,2] + \
                               12*lc[i]*qc[i]**2*qc[j]*vm[i,5]*vm[i,2] + \
                               12*lc[i]*qc[i]*qc[j]**2*vm[i,3]*vm[j,4] + \
                               4*lc[i]*cp[i,j]**3*vm[i,4]*vm[j,3] + \
                               4*qc[i]*cp[i,j]**3*vm[i,5]*vm[j,3] + \
                               6*qc[i]**2*lc[j]**2*vm[i,4]*vm[j,2]
            
        if n>=3:
            for i in range(n-2):
                for j in range(i+1, n-1):
                    for k in range(j+1, n):
                        ans += (12*qc[i]**2*qc[j]*qc[k] + \
                               6*cp[i,j]**2*cp[i,k]**2 + \
                               12*qc[i]*(qc[k]*cp[i,j]**2 + qc[j]*cp[i,k]**2) + \
                               6*qc[i]**2*cp[j,k])*vm[i,4]*vm[j,2]*vm[k,2]
                        ans += (12*qc[i]*qc[j]**2*qc[k] + \
                               6*cp[i,j]**2*cp[j,k]**2 + \
                               12*qc[j]*(qc[k]*cp[i,j]**2 + qc[i]*cp[j,k]**2) + \
                               6*qc[j]**2*cp[i,k]**2)*vm[i,2]*vm[j,4]*vm[k,2]
                        ans += (12*qc[i]*qc[j]*qc[k]**2 + \
                               6*cp[i,k]**2*cp[j,k]**2 + \
                               12*qc[k]*(qc[i]*cp[j,k]**2 + qc[j]*cp[i,k]**2) + \
                               6*qc[k]**2*cp[i,j]**2)*vm[i,2]*vm[j,2]*vm[k,4]
                        ans += (12*cp[i,j]**2*cp[i,k]*cp[j,k] + \
                               24*qc[i]*qc[j]*qc[k]*cp[i,j] + \
                               4*qc[k]*cp[i,j]**3 + \
                               24*qc[i]*qc[k]*cp[i,k]*cp[j,k])*vm[i,3]*vm[j,3]*vm[k,2]
                        ans += (12*cp[i,j]*cp[i,k]**2*cp[j,k] + \
                               24*qc[i]*qc[j]*qc[k]*cp[i,k] + \
                               4*qc[j]*cp[i,k]**3 + \
                               24*qc[i]*qc[k]*cp[i,j]*cp[j,k])*vm[i,3]*vm[j,2]*vm[k,3]
                        ans += (12*cp[i,j]*cp[i,k]*cp[j,k]**2 + \
                               24*qc[i]*qc[j]*qc[k]*cp[j,k] + \
                               4*qc[i]*cp[j,k]**3 + \
                               24*qc[j]*qc[j]*cp[i,j]*cp[i,k])*vm[i,2]*vm[j,3]*vm[k,3]
                        ans += (12*cp[i,j]*cp[i,k]*cp[j,k] + \
                               24*qc[i]*qc[j]*qc[k]*cp[j,k] + \
                               4*qc[i]*cp[j,k]**3 + \
                               24*qc[j]*qc[k]*cp[i,j]*cp[i,k])*vm[i,2]*vm[j,3]*vm[k,3]
                        ans += 24*(qc[i]*qc[j]*qc[k] + \
                               cp[i,j]*cp[i,k]*cp[j,k])*(lc[i]*vm[i,3]*vm[j,2]*vm[k,2] + \
                                                         lc[j]*vm[i,2]*vm[j,3]*vm[k,2] + \
                                                         lc[k]*vm[i,2]*vm[j,2]*vm[k,3])
                        ans += 12*(lc[i]*cp[j,k]**2*vm[i,2]*(cp[i,j]*vm[j,3]*vm[k,2] + \
                               cp[i,k]*vm[j,2]*vm[k,3]) + lc[j]*cp[i,k]**2*vm[j,2]*(cp[i,j]*vm[i,3]*vm[k,2] + \
                               cp[j,k]*vm[i,2]*vm[k,3]) + \
                               lc[k]*cp[i,j]**2*vm[k,2]*(cp[i,k]*vm[i,3]*vm[j,2] + \
                               cp[j,k]*vm[i,2]*vm[j,3]))
                        ans += 12*(qc[i]*cp[j,k]**2*vm[i,3]*(cp[i,j]*vm[j,3]*vm[k,2] + \
                               cp[i,k]*vm[j,2]*vm[k,3]) + qc[j]*cp[i,k]**2*vm[j,3]*(cp[i,j]*vm[i,3]*vm[k,2] + \
                               cp[j,k]*vm[i,2]*vm[k,3]) + \
                               qc[k]*cp[i,j]**2*vm[k,3]*(cp[i,k]*vm[i,3]*vm[j,2] + \
                               cp[j,k]*vm[i,2]*vm[j,3]))
                        ans += 24*cp[i,j]*cp[i,k]*cp[j,k]*(qc[i]*vm[i,4]*vm[j,2]*vm[k,2] + \
                               qc[j]*vm[i,2]*vm[j,4]*vm[k,2] + qc[k]*vm[i,2]*vm[j,2]*vm[k,4])
                        ans += vm[i,2]*vm[j,2]*vm[k,2]*(12*(qc[i]*qc[j]*lc[k]**2 + \
                               qc[i]*qc[k]*lc[j]**2 + qc[j]*qc[k]*lc[i]**2) + \
                               6*(lc[i]**2*cp[j,k]**2 + lc[j]**2*cp[i,k]**2 + \
                               lc[k]**2*cp[i,j]**2) + \
                               24*(cp[i,j]*cp[i,k]*lc[j]*lc[k] + \
                                   cp[i,j]*cp[j,k]*lc[i]*lc[k] + \
                                   cp[i,k]*cp[j,k]*lc[i]*lc[j]) + \
                               24*(lc[i]*lc[j]*qc[k]*cp[i,j] + \
                                   lc[i]*lc[k]*qc[j]*cp[i,k] + \
                                   lc[j]*lc[k]*qc[i]*cp[j,k]))
                        ans += vm[i,3]*vm[j,2]*vm[k,2]*(24*lc[j]*cp[i,j]*qc[i]*qc[k] + \
                               24*lc[k]*cp[i,k]*qc[i]*qc[j] + \
                               12*lc[i]*cp[j,k]**2*qc[i] + \
                               24*lc[j]*cp[i,k]*cp[j,k]*qc[i] + \
                               24*lc[k]*cp[i,j]*cp[j,k]*qc[i] + \
                               12*lc[i]*cp[i,k]**2*qc[j] + \
                               12*lc[i]*cp[i,j]**2*qc[k])
                        ans += vm[i,2]*vm[j,3]*vm[k,2]*(24*lc[i]*cp[i,j]*qc[j]*qc[k] + \
                               24*lc[k]*cp[j,k]*qc[i]*qc[j] + \
                               12*lc[j]*cp[i,k]**2*qc[j] + \
                               24*lc[i]*cp[i,k]*cp[j,k]*qc[j] + \
                               24*lc[k]*cp[i,j]*cp[i,k]*qc[j] + \
                               12*lc[j]*cp[j,k]**2*qc[i] + \
                               12*lc[j]*cp[i,j]**2*qc[k])
                        ans += vm[i,2]*vm[j,2]*vm[k,3]*(24*lc[i]*cp[i,k]*qc[j]*qc[k] + \
                               24*lc[j]*cp[j,k]*qc[i]*qc[k] + \
                               12*lc[k]*cp[i,j]**2*qc[k] + \
                               24*lc[i]*cp[i,j]*cp[j,k]*qc[k] + \
                               24*lc[j]*cp[i,j]*cp[i,k]*qc[k] + \
                               12*lc[k]*cp[j,k]**2*qc[i] + \
                               12*lc[k]*cp[i,k]**2*qc[j])
        
        if n>=4:
            for i in range(n-3):
                for j in range(i+1, n-2):
                    for k in range(j+1, n-1):
                        for m in range(k+1, n):
                            ans += vm[i,2]*vm[j,2]*vm[k,2]*vm[m,2]*(24*(qc[i]*qc[j]*qc[k]*qc[m] +\
                                   cp[i,j]*cp[i,k]*cp[j,m]*cp[k,m] + \
                                   cp[i,j]*cp[i,m]*cp[j,k]*cp[k,m] + \
                                   cp[i,k]*cp[i,m]*cp[j,k]*cp[j,m] + \
                                   qc[i]*cp[j,k]*cp[j,m]*cp[k,m] + \
                                   qc[j]*cp[i,k]*cp[i,m]*cp[i,m] + \
                                   qc[k]*cp[i,j]*cp[i,m]*cp[j,m] + \
                                   qc[m]*cp[i,j]*cp[i,k]*cp[j,k]) + \
                                   12*(qc[i]*qc[j]*cp[k,m]**2 + \
                                       qc[i]*qc[k]*cp[j,m]**2 + \
                                       qc[i]*qc[m]*cp[j,k]**2 + \
                                       qc[j]*qc[k]*cp[i,m]**2 + \
                                       qc[j]*qc[m]*cp[i,k]**2 + \
                                       qc[k]*qc[m]*cp[i,j]**2) + \
                                   6*(cp[i,j]**2*cp[k,m]**2 + \
                                      cp[i,k]**2*cp[j,m]**2 + \
                                      cp[i,m]**2*cp[j,k]**2))
    
    ############################
    
    else:
        print('Can only calculate raw moments k = 0 to 4. Sorry.')
        ans = None
    
    return ans
```


Overlapping Code:
```
ent(slc, sqc, scp, vm, k):
"""
This is where the resultant distribution moments are calculated. MODIFY 
THIS CODE AT YOUR OWN RISK. These equations have been verified with
published equations and exammponents need to be standardized prior to input
to this function. This means multiplying them by their respective
standard deviations, depending on the order of the derivative. Helper
functions have been defined for this purpose (standard_lc, standard_qc,
and standard_cp). However, this is only necessary if manually calling this
function rather than using soerp_numeric below.

Parameters
----------
slc : array
The standardized first derivative terms.
sqc : array
The standardized pure second derivative terms
scp : 2d-array
The standardized cross-product second derivative terms
vm : 2d-array
The first 9 (starting at 0) standardized distribution moments (one 
row for each input variable, corresponding to the derivative array 
order). See the documentation for ``soerp_numeric`` for more details.
k : int
The kth distribution moment to calculate.

Returns
-------
rm : scalar
The kth raw distribution moment
"""
lc = copy(slc)
qc = copy(sqc)
cp = copy(scp)
n = len(lc)

if assume_linear:
qc[:] = 0.0
cp[:,:] = 0.0

ans = 0.0

############################
# The 0th raw moment

if k==0:
ans = 1

############################
# The 1st raw moment

elif k==1:
for i in range(n):
ans += qc[i]*vm[i,2]

############################
# The 2nd raw moment

elif k==2:
for i in range(n):
ans += lc[i]**2*vm[i,2] + 2*lc[i]*qc[i]*vm[i,3] + qc[i]**2*vm[i,4]

if n>=2:
for i in range(n-1):
for j in range(i+1, n):
ans += (2*qc[i]*qc[j] + cp[i,j]**2)*vm[i,2]*vm[j,2]

############################
# The 3rd raw moment

elif k==3:
for i in range(n):
ans += lc[i]**3*vm[i,3] + qc[i]**3*vm[i,6] + \
3*lc[i]**2*qc[i]*vm[i,4] + 3*lc[i]*qc[i]**2*vm[i,5]

if n>=2:
for i in range(n-1):
for j in range(i+1, n):
ans +=
```
<Overlap Ratio: 0.9581653225806451>

---

--- 285 --
Question ID: 09ab624fd34b487ce702e3a1bc93be04c9a92db1_6
Original Code:
```
def list_rankings(wf):
    # type: (Workflow3) -> ()

    fiat = wf.settings.get('currency')

    def _get():
        api = CryptoCompareClient()
        return api.get_top_market_cap(fiat, 10)

    add_ticks_to_workflow(
        wf,
        wf.cached_data(
            'market_cap_rankings_10', _get, max_age=3, session=True
        ),
    )
```


Overlapping Code:
```
kflow3) -> ()
fiat = wf.settings.get('currency')
def _get():
api = CryptoCompareClient()
return api.get_top_market_cap(fiat, 10)
add_ticks_to_workflow(
wf,
wf.cached_data(
'market_cap_rankings_10', _g
```
<Overlap Ratio: 0.7490636704119851>

---

--- 286 --
Question ID: cea9ae69659ebfb8a8404af6f11de3d5ed1fc82d_4
Original Code:
```
def post_data_helper(grant_type=None, code=None, refresh_token=None):
    data = {
        "client_id": os.environ.get('STRAVA_CLIENT_ID'),
        "client_secret": os.environ.get('STRAVA_CLIENT_SECRET')
    }

    if grant_type:
        data['grant_type'] = grant_type

    if refresh_token:
        data['refresh_token'] = refresh_token

    if code:
        data['code'] = code

    return data
```


Overlapping Code:
```
 code=None, refresh_token=None):
data = {
"client_id": os.environ.get('STRAVA_CLIENT_ID'),
"client_secret": os.environ.get('STRAVA_CLIENT_SECRET')
}
if grant_type:
data['grant_type'] = grant_type
if refresh_token:
data['refresh_token'] = refresh_toke
```
<Overlap Ratio: 0.7598784194528876>

---

--- 287 --
Question ID: 9c42751e8cb69669028dbe7b3c60f5a852b9760e_29
Original Code:
```
def test_parse_empty_background_with_short_description(parser):
    """The parser should parse an empty Background with a short description"""
    # given
    feature_file = """
        Feature: My Feature

            Background: My Background
    """

    # when
    ast = parser.parse_contents(None, feature_file)

    # then
    assert ast.background.short_description == "My Background"
```


Overlapping Code:
```
test_parse_empty_background_with_short_description(parser):
"""The parser should parse an empty Background with a short description"""
# given
feature_file = """
Feature: My Feature
Background: My Background
"""
# when
ast = parser.parse_contents(None, feature_file)
# then
assert ast.background.shor
```
<Overlap Ratio: 0.8928571428571429>

---

--- 288 --
Question ID: 5377d2b13a0b95a52bd8837d251fe769cd9ece23_36
Original Code:
```
def bc_python_premise(rule, arg_patterns, arg_context):
  engine = rule.rule_base.engine
  patterns = rule.goal_arg_patterns()
  if len(arg_patterns) == len(patterns):
    context = contexts.bc_context(rule)
    try:
      if all(map(lambda pat, arg:
                   pat.match_pattern(context, context,
                                     arg, arg_context),
                 patterns,
                 arg_patterns)):
        rule.rule_base.num_bc_rules_matched += 1
        mark1 = context.mark(True)
        if rule.pattern(0).match_data(context, context,
                context.lookup_data('clause_num') + 1):
          context.end_save_all_undo()
          with engine.prove(rule.rule_base.root_name, 'python_premise', context,
                            (rule.pattern(1),
                             rule.pattern(2),
                             rule.pattern(3),
                             rule.pattern(4),
                             rule.pattern(5),
                             rule.pattern(6),
                             rule.pattern(7),)) \
            as gen_2:
            for x_2 in gen_2:
              assert x_2 is None, \
                "compiler.bc_python_premise: got unexpected plan from when clause 2"
              rule.rule_base.num_bc_rule_successes += 1
              yield
        else: context.end_save_all_undo()
        context.undo_to_mark(mark1)
        rule.rule_base.num_bc_rule_failures += 1
    finally:
      context.done()
```


Overlapping Code:
```
on_premise(rule, arg_patterns, arg_context):
engine = rule.rule_base.engine
patterns = rule.goal_arg_patterns()
if len(arg_patterns) == len(patterns):
context = contexts.bc_context(rule)
try:
if all(map(lambda pat, arg:
pat.match_pattern(context, context,
arg, arg_context),
patterns,
arg_patterns)):
rule.rule_base.num_bc_rules_matched += 1
mark1 = context.mark(True)
if rule.pattern(0).match_data(context, context,
context.lookup_data('clause_num') + 1):
context.end_save_all_undo()
with engine.prove(rule.rule_base.root_name, 'python_premise', context,
(rule.pattern(1),
rule.pattern(2),
rule.pattern(3),
rule.pattern(4),
rule.pattern(5),
rule.pattern(6),
rule.pattern(7),)) \
as gen_2:
for x_2 in gen_2:
assert x_2 is None, \
"compiler.bc_python_premise: got unexpected plan from when clause 2"
rule.rule_base.num_bc_rule_successes += 1
yield
else: context.end_save_all_undo()
context.undo_to_mark(mark1)
rule.rule_base.num_bc_rule_failures += 1
finally:
context.done(
```
<Overlap Ratio: 0.9878048780487805>

---

--- 289 --
Question ID: 802d3137f1544c142a8c64ecc7a5d9eb56025a11_1
Original Code:
```
def rsync(ctx, *args, **kwargs):  # type: ignore
    """Ugly workaround for https://github.com/fabric/patchwork/issues/16."""
    ssh_agent = os.environ.get('SSH_AUTH_SOCK', None)
    if ssh_agent:
        ctx.config['run']['env']['SSH_AUTH_SOCK'] = ssh_agent
    return rsync_(ctx, *args, **kwargs)
```


Overlapping Code:
```
: ignore
"""Ugly workaround for https://github.com/fabric/patchwork/issues/16."""
ssh_agent = os.environ.get('SSH_AUTH_SOCK', None)
if ssh_agent:
ctx.config['run']['env']['SSH_AUTH_SOCK'] = ssh_agent

```
<Overlap Ratio: 0.7299270072992701>

---

--- 290 --
Question ID: ede59415b222058bdfb718d056a94fa5e203948f_11
Original Code:
```
@pytest.mark.asyncio
async def test_sound_volume(bleak_client, client):
    bleak_client.read_gatt_char.return_value = b"a" * 32
    await client.get_sound_volume()
```


Overlapping Code:
```
mark.asyncio
async def test_sound_volume(bleak_client, client):
bleak_client.read_gatt_char.return_value = b"a" * 32

```
<Overlap Ratio: 0.75>

---

--- 291 --
Question ID: 53b8bd173fccd280bd430a9e0f66641a1e2f1f50_18
Original Code:
```
def port(valobj):
    val = valobj.unsigned
    if (val & 0xF) == 0x7:
        target = valobj.target
        if etp_arch_bits(target) == 64 and not etp_halfword(target):
            if etp_big_endian(target):
                data = (val >> 36) & 0x0FFFFFFF
            else:
                data = (val >> 4) & 0x0FFFFFFF
        else:
            data = pixdata2data(valobj)
        return '#Port<0.%u>' % data
    else:
        return '#NotPort<%#x>' % val
```


Overlapping Code:
```
f port(valobj):
val = valobj.unsigned
if (val & 0xF) == 0x7:
target = valobj.target
if etp_arch_bits(target) == 64 and not etp_halfword(target):
if etp_big_endian(target):
data = (val >> 36) & 0x0FFFFFFF
else:
data = (val >> 4) & 0x0FFFFFFF
else:
data = pixdata2data(valobj)
return '#Port<0.%u>' % data
else:
return '#NotPort<%#x>' % va
```
<Overlap Ratio: 0.9911504424778761>

---

--- 292 --
Question ID: cbaf932aeb1cfe564a60a48222ac4dcaa380d543_1
Original Code:
```
def read_scanline(band, yoff):
    """ Read a band scanline (up to the y-offset), returning an array of values.

    A raster (image) may consist of multiple bands (e.g. for a colour image, one may have a band for
    red, green, blue, and alpha).
    A scanline, is a single row of a band.

    band, definition: https://gdal.org/user/raster_data_model.html#raster-band
    fetching a raster band: https://gdal.org/tutorials/raster_api_tut.html#fetching-a-raster-band
    """
    scanline = band.ReadRaster(xoff=0, yoff=yoff,
                               xsize=band.XSize, ysize=1,
                               buf_xsize=band.XSize, buf_ysize=1,
                               buf_type=gdal.GDT_Float32)
    return struct.unpack('f' * band.XSize, scanline)
```


Overlapping Code:
```
nd scanline (up to the y-offset), returning an array of values.
A raster (image) may consist of multiple bands (e.g. for a colour image, one may have a band for
red, green, blue, and alpha).
A scanline, is a single row of a band.
band, definition: https://gdal.org/user/raster_data_model.html#raster-band
fetching a raster band: https://gdal.org/tutorials/raster_api_tut.html#fetching-a-raster-band
"""
scanline = band.ReadRaster(xoff=0, yoff=yoff,
xsize=band.XSize, ysize=1,
buf_xsize=band.XSize, buf_ysize=1,
buf_type=gdal.GDT_Float32)
return struc
```
<Overlap Ratio: 0.873015873015873>

---

--- 293 --
Question ID: 566b774d62472aa1932501a18ec7cae80e02726b_6
Original Code:
```
def lowpass(data, f, fs):
    wn = 2*f/fs
    b, a = signal.butter(8, wn, 'lowpass')
    filtedData = signal.filtfilt(b, a, data)
    return filtedData
```


Overlapping Code:
```
ata, f, fs):
wn = 2*f/fs
b, a = signal.butter(8, wn, 'lowpass')
filtedData = signal.filtfilt(b, a, data)
return filtedDa
```
<Overlap Ratio: 0.8888888888888888>

---

--- 294 --
Question ID: b1683a8f02e1062c2e4756dfeabfe6c3f6a90f46_5
Original Code:
```
def get_icc_profile(decoded_data):
    """
    Returns ICC image profile (if it exists and was correctly decoded)
    """
    # fixme: move this function somewhere?
    icc_profiles = [res.data for res in decoded_data.image_resource_blocks
                   if res.resource_id == ImageResourceID.ICC_PROFILE]

    if not icc_profiles:
        return None

    icc_profile = icc_profiles[0]

    if isinstance(icc_profile, bytes): # profile was not decoded
        return None

    return icc_profile
```


Overlapping Code:
```
def get_icc_profile(decoded_data):
"""
Returns ICC image profile (if it exists and was correctly decoded)
"""
# fixme: move this function somewhere?
icc_profiles = [res.data for res in decoded_data.image_resource_blocks
if res.resource_id == ImageResourceID.ICC_PROFILE]
if not icc_profiles:
return None
icc_profile = icc_profiles[0]
if isinstance(icc_profile, bytes): # profile was not decoded
return None
return icc_pr
```
<Overlap Ratio: 0.9882352941176471>

---

--- 295 --
Question ID: 3458b57ed9315b3d9e28a0f1274cb6b63edb9b4d_0
Original Code:
```
def lev_dist(first, second):
    """Find the Levenshtein distance between two strings."""
    if len(first) > len(second):
        first, second = second, first
    if len(second) == 0:
        return len(first)
    first_length = len(first) + 1
    second_length = len(second) + 1
    distance_matrix = [[0] * second_length for x in range(first_length)]
    for i in range(first_length):
       distance_matrix[i][0] = i
    for j in range(second_length):
       distance_matrix[0][j]=j
    for i in xrange(1, first_length):
        for j in range(1, second_length):
            deletion = distance_matrix[i-1][j] + 1
            insertion = distance_matrix[i][j-1] + 1
            substitution = distance_matrix[i-1][j-1]
            if first[i-1] != second[j-1]:
                substitution += 1
            distance_matrix[i][j] = min(insertion, deletion, substitution)
    return distance_matrix[first_length-1][second_length-1]
```


Overlapping Code:
```
def lev_dist(first, second):
"""Find the Levenshtein distance between two strings."""
if len(first) > len(second):
first, second = second, first
if len(second) == 0:
return len(first)
first_length = len(first) + 1
second_length = len(second) + 1
distance_matrix = [[0] * second_length for x in range(first_length)]
for i in range(first_length):
distance_matrix[i][0] = i
for j in range(second_length):
distance_matrix[0][j]=j
for i in xrange(1, first_length):
for j in range(1, second_length):
deletion = distance_matrix[i-1][j] + 1
insertion = distance_matrix[i][j-1] + 1
substitution = distance_matrix[i-1][j-1]
if first[i-1] != second[j-1]:
substitution += 1
distance_matrix[i][j] = min(insertion, deletion, substitution)
return distance_matrix[first_length-1][second_le
```
<Overlap Ratio: 0.9910256410256411>

---

--- 296 --
Question ID: f7d87fe1f5a2211e35a8b08f549a4c14b2b9f335_0
Original Code:
```
def tune(device_name, strategy="bayes_opt_GPyTorch_lean", strategy_options=None, verbose=True, quiet=False, simulation_mode=True):

    #input dimensions and data
    image_width = 4096
    image_height = 4096
    filter_width = 15
    filter_height = 15
    problem_size = (image_width, image_height)
    size = numpy.prod(problem_size)

    args = []

    metrics = OrderedDict()
    metrics["GFLOP/s"] = lambda p: (image_width * image_height * filter_width * filter_height * 2 / 1e9) / (p["time"] / 1e3)

    #setup tunable parameters
    tune_params = OrderedDict()
    tune_params["filter_width"] = [filter_width]
    tune_params["filter_height"] = [filter_height]
    tune_params["block_size_x"] = [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 112, 128]
    tune_params["block_size_y"] = [1, 2, 4, 8, 16, 32]
    tune_params["tile_size_x"] = [1, 2, 3, 4, 5, 6, 7, 8]
    tune_params["tile_size_y"] = [1, 2, 3, 4, 5, 6, 7, 8]
    tune_params["use_padding"] = [0, 1]
    tune_params["read_only"] = [0, 1]

    restrict = ["block_size_x*block_size_y>=64", "tile_size_x*tile_size_y<30"]

    grid_div_x = ["block_size_x", "tile_size_x"]
    grid_div_y = ["block_size_y", "tile_size_y"]

    #start tuning
    results, env = kernel_tuner.tune_kernel("convolution_kernel", "convolution.cu", problem_size, args, tune_params, grid_div_y=grid_div_y,
                                            grid_div_x=grid_div_x, metrics=metrics, verbose=verbose, quiet=quiet, restrictions=restrict,
                                            cache="cache_files/convolution_" + device_name, strategy=strategy, strategy_options=strategy_options,
                                            simulation_mode=simulation_mode)

    # print(len(results))

    return results, env
```


Overlapping Code:
```
ame, strategy="bayes_opt_GPyTorch_lean", strategy_options=None, verbose=True, quiet=False, simulation_mode=True):
#input dimensions and data
image_width = 4096
image_height = 4096
filter_width = 15
filter_height = 15
problem_size = (image_width, image_height)
size = numpy.prod(problem_size)
args = []
metrics = OrderedDict()
metrics["GFLOP/s"] = lambda p: (image_width * image_height * filter_width * filter_height * 2 / 1e9) / (p["time"] / 1e3)
#setup tunable parameters
tune_params = OrderedDict()
tune_params["filter_width"] = [filter_width]
tune_params["filter_height"] = [filter_height]
tune_params["block_size_x"] = [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 112, 128]
tune_params["block_size_y"] = [1, 2, 4, 8, 16, 32]
tune_params["tile_size_x"] = [1, 2, 3, 4, 5, 6, 7, 8]
tune_params["tile_size_y"] = [1, 2, 3, 4, 5, 6, 7, 8]
tune_params["use_padding"] = [0, 1]
tune_params["read_only"] = [0, 1]
restrict = ["block_size_x*block_size_y>=64", "tile_size_x*tile_size_y<30"]
grid_div_x = ["block_size_x", "tile_size_x"]
grid_div_y = ["block_size_y", "tile_size_y"]
#start tuning
results, env = kernel_tuner.tune_kernel("convolution_kernel", "convolution.cu", problem_size, args, tune_params, grid_div_y=grid_div_y,
grid_div_x=grid_div_x, metrics=metrics, verbose=verbose, quiet=quiet, restrictions=restrict,
cache="cache_files/convolution_" + device_name, strategy=strategy, strategy_options=strategy_options,
simulation_mode=simulation_mode)
# print(len(results))
return results,
```
<Overlap Ratio: 0.986>

---

--- 297 --
Question ID: d0872b6e45a853008bfc2cecec2b19fb4751243d_0
Original Code:
```
def _grid(centroid, radius, step):
    """
    Generates a list of points that will be used as probes to test coordination.

    A spherical grid of equiseparated points (i.e. probes) is constructed aimed
    to contain the whole biological system (or a zone of it in case of user
    request). The `centroid` and `radius` parameters of the method are obtained
    either when parsing the input `.pdb` file (grid containing the whole
    molecule) or entered by the user with `--center` and `--radius` parameters
    of the program (only this zone of the molecule will be explored). The `step`
    parameter determines the distance between points of the grid.

    Parameters
    ----------
    centroid : array_like
        Array of 3 floats defining the center of the sphere
    radius : float
        Radius of the sphere used to construct the grid
    step : float
        Distance, in Angstroms, between two consecutive probes

    Returns
    -------
    list of array_like
        list of 3-float arrays containing the points (i.e. probes) of the grid
    """
    #1. Two points at the ends of a cube of l=2*radius are obtained
    xmi, ymi, zmi = centroid - radius
    xma, yma, zma = centroid + radius

    #2. Each axis x, y and z is splitted at every step distance
    numx = int((xma - xmi) / step) + 1
    numy = int((yma - ymi) / step) + 1
    numz = int((zma - zmi) / step) + 1
    x = np.linspace(xmi, xma, numx)
    y = np.linspace(ymi, yma, numy)
    z = np.linspace(zmi, zma, numz)

    #3. A cubic grid is generated by iterating over the 3 axes
    grid = []
    for i in range(len(x)):
        for j in range(len(y)):
            for k in range(len(z)):
                grid.append([x[i], y[j], z[k]])
    points = np.array(grid) #Cube embedding the protein

    #4. Points out of the sphere are discarded
    is_in_sphere = np.linalg.norm(points - centroid, axis=1) <= radius
    points = points[is_in_sphere, :]

    return points
```


Overlapping Code:
```
us, step):
"""
Generates a list of points that will be used as probes to test coordination.
A spherical grid of equiseparated points (i.e. probes) is constructed aimed
to contain the whole biological system (or a zone of it in case of user
request). The `centroid` and `radius` parameters of the method are obtained
either when parsing the input `.pdb` file (grid containing the whole
molecule) or entered by the user with `--center` and `--radius` parameters
of the program (only this zone of the molecule will be explored). The `step`
parameter determines the distance between points of the grid.
Parameters
----------
centroid : array_like
Array of 3 floats defining the center of the sphere
radius : float
Radius of the sphere used to construct the grid
step : float
Distance, in Angstroms, between two consecutive probes
Returns
-------
list of array_like
list of 3-float arrays containing the points (i.e. probes) of the grid
"""
#1. Two points at the ends of a cube of l=2*radius are obtained
xmi, ymi, zmi = centroid - radius
xma, yma, zma = centroid + radius
#2. Each axis x, y and z is splitted at every step distance
numx = int((xma - xmi) / step) + 1
numy = int((yma - ymi) / step) + 1
numz = int((zma - zmi) / step) + 1
x = np.linspace(xmi, xma, numx)
y = np.linspace(ymi, yma, numy)
z = np.linspace(zmi, zma, numz)
#3. A cubic grid is generated by iterating over the 3 axes
grid = []
for i in range(len(x)):
for j in range(len(y)):
for k in range(len(z)):
grid.append([x[i], y[j], z[k]])
points = np.array(grid) #Cube embedding the protein
#4. Points out of the sphere are discarded
is_in_sphere = np.linalg.norm(points - centroid, axis=1) <= radius
points = points[is_in_sphere, :]
ret
```
<Overlap Ratio: 0.9803921568627451>

---

--- 298 --
Question ID: 6997961e6b821ca491045838b32c2410bcbe738d_3
Original Code:
```
@pytest.fixture
def get_include_paths():
    with mock.patch.object(factory, 'get_include_paths') as patch:
        patch.return_value = []
        yield patch
```


Overlapping Code:
```
 get_include_paths():
with mock.patch.object(factory, 'get_include_paths') as patch:
patch.return_va
```
<Overlap Ratio: 0.7194244604316546>

---

--- 299 --
Question ID: 58b4da35f8bd638742d8006dae70304e228a4c07_3
Original Code:
```
@borg.on(events.NewMessage(pattern=r"\.(.*)", outgoing=True))
async def _(event):

    if event.fwd_from:

        return

    input_str = event.pattern_match.group(1)

    if input_str == "round":

        await event.edit(input_str)

        animation_chars = ["", "", "", "" ""]

        animation_interval = 0.1

        animation_ttl = range(100)

        for i in animation_ttl:

            await asyncio.sleep(animation_interval)

            await event.edit(animation_chars[i % 4])

```


Overlapping Code:
```
@borg.on(events.NewMessage(pattern=r"\.(.*)", outgoing=True))
async def _(event):
if event.fwd_from:
return
input_str = event.pattern_match.group(1)
if input_str == "round":
await event.edit(input_str)
animation_chars = ["", "", "", "" ""]
animation_interval = 0.1
animation_ttl = range(100)
for i in animation_ttl:
await asyncio.sleep(animation_interval)
await event.edit(animation_chars[i % 4])
```
<Overlap Ratio: 1.0>

---

--- 300 --
Question ID: 021a6dc595fc0f9782bcb9027efb61934f4c3d13_0
Original Code:
```
def calculate(a, b, c,):
    discriminant = b ** 2 - 4 * a * c
    if discriminant < 0:
        return None, None
    x1 = (2 * c) / (-b + math.sqrt(discriminant))
    x2 = (2 * c) / (-b - math.sqrt(discriminant))
    return x1, x2
```


Overlapping Code:
```
b, c,):
discriminant = b ** 2 - 4 * a * c
if discriminant < 0:
return None, None
x1 = (2 * c) / (-b + math.sqrt(discriminant))
x2 = (2 * c) / (-b - math.sqrt(discriminant))
retur
```
<Overlap Ratio: 0.8768472906403941>

---

--- 301 --
Question ID: 20c0ea7cc1dc5ceb8e4405692f0ade77a4859382_1
Original Code:
```
def trunk_2(arr_2, size_2):
    arrs = []
    while len(arr_2) > size_2:
        pice = arr_2[:size_2]
        arrs.append(pice)
        arr_2 = arr_2[size:]
    arrs.append(arr_2)
    return arrs
```


Overlapping Code:
```
unk_2(arr_2, size_2):
arrs = []
while len(arr_2) > size_2:
pice = arr_2[:size_2]
arrs.append(pice)
arr_2 = arr_2[size:]
arrs.append(arr_2)
return arrs
```
<Overlap Ratio: 0.9615384615384616>

---

--- 302 --
Question ID: 53cb68c5ace8dc97c23abeaf69c885638d283f98_2
Original Code:
```
def ODEs_mean_1(X, t, xi, Pert): 
    S, I, J,  D, H, R, sumI, sumH = X  
    dSdt = -(BetaI_PINN[-1]  * (1+xi*Pert) *(I+eps1*J+eps2*H)/N)*S - V_1(t)/N*S
    delay = (BetaI_PINN[-1]  * (1+xi*Pert) *(I+eps1*J+eps2*H)/N)*S  
    dIdt = delta*delay - Gamma*I 
    dJdt = (1-delta)*delay - gammaA*J
    dDdt = (q_mean*phiD)*H
    dHdt = (p_mean*Gamma)*I - (q_mean*phiD) * H - ((1-q_mean)*phiR) * H
    dRdt = gammaA*J + ((1-p_mean)*Gamma)*I + ((1-q_mean)*phiR)*H + V_1(t)/N*S
    dsumIdt = delta*delay
    dsumHdt = (p_mean*Gamma)*I   
    return [dSdt, dIdt, dJdt, dDdt, dHdt, dRdt, dsumIdt, dsumHdt] 
```


Overlapping Code:
```
 xi, Pert): 
S, I, J, D, H, R, sumI, sumH = X 
dSdt = -(BetaI_PINN[-1] * (1+xi*Pert) *(I+eps1*J+eps2*H)/N)*S - V_1(t)/N*S
delay = (BetaI_PINN[-1] * (1+xi*Pert) *(I+eps1*J+eps2*H)/N)*S 
dIdt = delta*delay - Gamma*I 
dJdt = (1-delta)*delay - gammaA*J
dDdt = (q_mean*phiD)*H
dHdt = (p_mean*Gamma)*I - (q_mean*phiD) * H - ((1-q_mean)*phiR) * H
dRdt = gammaA*J + ((1-p_mean)*Gamma)*I + ((1-q_mean)*phiR)*H + V_1(t)/N*S
dsumIdt = delta*delay
dsumHdt = (p_mean*Gamma)*I 
return [dSdt, dIdt, dJdt, dDdt, dHdt, 
```
<Overlap Ratio: 0.9194139194139194>

---

--- 303 --
Question ID: 406e17d5ac00499f0b9089fab72ff6712a066708_0
Original Code:
```
def thread_run_query(query, barrier):
    env = Env(decodeResponses=True)
    conn = env.getConnection()
    graph = Graph(GRAPH_ID, conn)

    if barrier is not None:
        barrier.wait()
    
    try:
        result = graph.query(query)
        return { "result_set": result.result_set, 
            "nodes_created": result.nodes_created, 
            "properties_set": result.properties_set }
    except ResponseError as e:
        return str(e)
```


Overlapping Code:
```
 thread_run_query(query, barrier):
env = Env(decodeResponses=True)
conn = env.getConnection()
graph = Graph(GRAPH_ID, conn)
if barrier is not None:
barrier.wait()

try:
result = graph.query(query)
return { "result_set": result.result_set, 
"nodes_created": result.nodes_created, 
"properties_set": result.properties_set }
except ResponseError as e:
r
```
<Overlap Ratio: 0.958904109589041>

---

--- 304 --
Question ID: d18056486919411cbd22f586342d4119fc9b25d6_4
Original Code:
```
@pytest.fixture(scope="class")
def node_factory(request, bitcoind):
    executor = futures.ThreadPoolExecutor(max_workers=20)
    node_factory = NodeFactory(request._pyfuncitem.name, executor, bitcoind)
    yield node_factory
    node_factory.killall()
    executor.shutdown(wait=False)
```


Overlapping Code:
```
"class")
def node_factory(request, bitcoind):
executor = futures.ThreadPoolExecutor(max_workers=20)
node_factory = NodeFactory(request._pyfuncitem.name, executor, bitcoind)
yield node_factory
node_fac
```
<Overlap Ratio: 0.7518796992481203>

---

--- 305 --
Question ID: 41a777a7c2c3b3cd8331177bcc54b8e534199a39_2
Original Code:
```
def find_answer_starts(doc_toks, ans_toks):
    # CONSIDER: handle also Europe/European, portrait/portraits
    # also cases like South Korean/South Korea
    starts = []
    anslen = len(ans_toks)
    for s in range(len(doc_toks)-(anslen-1)):
        if ans_toks == doc_toks[s:s+anslen]:
            starts.append(s)
    return starts
```


Overlapping Code:
```
, ans_toks):
# CONSIDER: handle also Europe/European, portrait/portraits
# also cases like South Korean/South Korea
starts = []
anslen = len(ans_toks)
for s in range(len(doc_toks)-(anslen-1)):
if ans_toks == doc_toks[s:s+anslen]:
starts.append(s)
ret
```
<Overlap Ratio: 0.8591065292096219>

---

--- 306 --
Question ID: 0bd1e8099b37fdc953669c4b6d9e7016634cd84f_3
Original Code:
```
def gen_vis_weight(path, weight_max=10.0, weight_min=0.1):
    vismap = np.load(path)
    weight = vismap
    for i in range(0,32):
        for j in range(0,32):
            for k in range(0,100):
                if vismap[k,i,j] == 1.0:
                    weight[k,i,j] = weight_max
                elif vismap[k,i,j] == 0.0:
                    weight[k,i,j] = weight_min
                else:
                    print('There is something wrong!')
    return weight
```


Overlapping Code:
```
ht(path, weight_max=10.0, weight_min=0.1):
vismap = np.load(path)
weight = vismap
for i in range(0,32):
for j in range(0,32):
for k in range(0,100):
if vismap[k,i,j] == 1.0:
weight[k,i,j] = weight_max
elif vismap[k,i,j] == 0.0:
weight[k,i,j] = weight_min
else:
print('There is something wrong!')
return weight
```
<Overlap Ratio: 0.9507692307692308>

---

--- 307 --
Question ID: b75459388bec1684e8dba5668ad183ef8260c436_0
Original Code:
```
def confirm(prompt='Confirm', default=False):
    """
    https://code.activestate.com/recipes/541096-prompt-the-user-for-confirmation/
    prompts for yes or no response from the user. Returns True for yes and False for no.

    'resp' should be set to the default value assumed by the caller when user simply types ENTER.

    >>> confirm(prompt='Create Directory?', default=True)
    Create Directory? [y]|n:
    True
    >>> confirm(prompt='Create Directory?', default=False)
    Create Directory? [n]|y:
    False
    >>> confirm(prompt='Create Directory?', default=False)
    Create Directory? [n]|y: y
    True

    """

    if default:
        prompt = '%s [%s]|%s: ' % (prompt, 'y', 'n')
    else:
        prompt = '%s [%s]|%s: ' % (prompt, 'n', 'y')

    while True:
        ans = input(prompt)
        if not ans:
            return default
        if ans not in ['y', 'Y', 'n', 'N']:
            print('please enter y or n.')
            continue
        if ans.lower() == 'y':
            return True
        if ans.lower() == 'n':
            return False
```


Overlapping Code:
```
alse):
"""
https://code.activestate.com/recipes/541096-prompt-the-user-for-confirmation/
prompts for yes or no response from the user. Returns True for yes and False for no.
'resp' should be set to the default value assumed by the caller when user simply types ENTER.
>>> confirm(prompt='Create Directory?', default=True)
Create Directory? [y]|n:
True
>>> confirm(prompt='Create Directory?', default=False)
Create Directory? [n]|y:
False
>>> confirm(prompt='Create Directory?', default=False)
Create Directory? [n]|y: y
True
"""
if default:
prompt = '%s [%s]|%s: ' % (prompt, 'y', 'n')
else:
prompt = '%s [%s]|%s: ' % (prompt, 'n', 'y')
while True:
ans = input(prompt)
if not ans:
return default
if ans not in ['y', 'Y', 'n', 'N']:
print('please enter y or n.')
continue
if ans.lower() == 'y':
return
```
<Overlap Ratio: 0.9090909090909091>

---

--- 308 --
Question ID: f4baece3b1689b1dde25233a9ee3f6d169e536e6_0
Original Code:
```
def render(image_id, requested_size):
    print('image_id: "{image_id}", size: {requested_size}'.format(**locals()))

    # width and height will be -1 if not set in QML
    if requested_size == (-1, -1):
        requested_size = (300, 300)

    width, height = requested_size

    # center for circle
    cx, cy = width/2, 10

    pixels = []
    for y in range(height):
        for x in range(width):
            pixels.extend(reversed([
                255, # alpha
                int(10 + 10 * ((x - y * 0.5) % 20)), # red
                20 + 10 * (y % 20), # green
                int(255 * abs(math.sin(0.3*math.sqrt((cx-x)**2 + (cy-y)**2)))) # blue
            ]))
    return bytearray(pixels), (width, height), pyotherside.format_argb32
```


Overlapping Code:
```
render(image_id, requested_size):
print('image_id: "{image_id}", size: {requested_size}'.format(**locals()))
# width and height will be -1 if not set in QML
if requested_size == (-1, -1):
requested_size = (300, 300)
width, height = requested_size
# center for circle
cx, cy = width/2, 10
pixels = []
for y in range(height):
for x in range(width):
pixels.extend(reversed([
255, # alpha
int(10 + 10 * ((x - y * 0.5) % 20)), # red
20 + 10 * (y % 20), # green
int(255 * abs(math.sin(0.3*math.sqrt((cx-x)**2 + (cy-y)**2)))) # blue
]))
return bytearray(pixels), (width, height), pyotherside.
```
<Overlap Ratio: 0.9717607973421927>

---

--- 309 --
Question ID: 9907caf7dfd173e92aca5156c33e78088d92ebe9_6
Original Code:
```
def _check_info(info, base_env=False, agent_ids=None):
    if base_env:
        for _, multi_agent_dict in info.items():
            for agent_id, inf in multi_agent_dict.items():
                if not isinstance(inf, dict):
                    raise ValueError(
                        "Your step function must return infos that are a dict. "
                        f"instead was a {type(inf)}: element: {inf}"
                    )
                if not (agent_id in agent_ids or agent_id == "__all__"):
                    error = (
                        f"Your dones dictionary must have agent ids that belong to "
                        f"the environment. Agent_ids recieved from "
                        f"env.get_agent_ids() are: {agent_ids}"
                    )
                    raise ValueError(error)
    elif not isinstance(info, dict):
        error = (
            "Your step function must return a info that "
            f"is a dict. element type: {type(info)}. element: {info}"
        )
        raise ValueError(error)
```


Overlapping Code:
```
(info, base_env=False, agent_ids=None):
if base_env:
for _, multi_agent_dict in info.items():
for agent_id, inf in multi_agent_dict.items():
if not isinstance(inf, dict):
raise ValueError(
"Your step function must return infos that are a dict. "
f"instead was a {type(inf)}: element: {inf}"
)
if not (agent_id in agent_ids or agent_id == "__all__"):
error = (
f"Your dones dictionary must have agent ids that belong to "
f"the environment. Agent_ids recieved from "
f"env.get_agent_ids() are: {agent_ids}"
)
raise ValueError(error)
elif not isinstance(info, dict):
error = (
"Your step function must return a info that "
f"is a dict. element type: {type(info)}. element: {info}"
)
raise ValueError(er
```
<Overlap Ratio: 0.9735744089012517>

---

--- 310 --
Question ID: b706e640a9917675466c2306fe364d4663b81823_4
Original Code:
```
@pytest.mark.asyncio
async def test_get_status():
    result = await test.get_status()
    await handler.save_result('test_get_status', result)
```


Overlapping Code:
```
.mark.asyncio
async def test_get_status():
result = await test.get_status()
await handler.save_result('test_get_status', result)
```
<Overlap Ratio: 0.9481481481481482>

---

--- 311 --
Question ID: 8a57a06e794da49cb6d24638c9cade0b5d7c551d_7
Original Code:
```
def test_balancer_list_members(driver):
    extra = {'pool_id': '4d360b1f-bc2c-4ab7-9884-1f03ba2768f7',
             'network_domain_id': '1234'}
    balancer = LoadBalancer(
                            id='234',
                            name='test',
                            state=State.RUNNING,
                            ip='1.2.3.4',
                            port=1234,
                            driver=driver,
                            extra=extra
                           )
    members = driver.balancer_list_members(balancer)
    assert 2 == len(members)
    assert members[0].ip ==  '10.0.3.13'
    assert members[0].id == '3dd806a2-c2c8-4c0c-9a4f-5219ea9266c0'
    assert members[0].port == 9889
```


Overlapping Code:
```
ef test_balancer_list_members(driver):
extra = {'pool_id': '4d360b1f-bc2c-4ab7-9884-1f03ba2768f7',
'network_domain_id': '1234'}
balancer = LoadBalancer(
id='234',
name='test',
state=State.RUNNING,
ip='1.2.3.4',
port=1234,
driver=driver,
extra=extra
)
members = driver.balancer_list_members(balancer)
assert 2 == len(members)
assert members[0].ip == '10.0.3.13'
assert members[0].id == '3dd806a2-c2c8-4c0c-9a4f-5219ea9266c0'
assert members[0].port == 
```
<Overlap Ratio: 0.989010989010989>

---

--- 312 --
Question ID: a0c89e48a9b7570d3b3706f3bab5a0fcb21e6941_21
Original Code:
```
def pad(tensor, paddings, mode='CONSTANT', constant_values=0):
    """
    Pads a tensor.

    Parameters
    ----------
    tensor : tensor
        A Tensor.
    paddings : tensor
        A Tensor of type int32.
    mode : str
        One of "CONSTANT", "REFLECT", or "SYMMETRIC" (case-insensitive)
    constant_values : int
        In "CONSTANT" mode, the scalar pad value to use. Must be same type as tensor.

    Returns
    -------
        A Tensor. Has the same type as tensor.
    """
    pad_obj = Pad(paddings, mode, constant_values=constant_values)
    return pad_obj(tensor)
```


Overlapping Code:
```
d(tensor, paddings, mode='CONSTANT', constant_values=0):
"""
Pads a tensor.
Parameters
----------
tensor : tensor
A Tensor.
paddings : tensor
A Tensor of type int32.
mode : str
One of "CONSTANT", "REFLECT", or "SYMMETRIC" (case-insensitive)
constant_values : int
In "CONSTANT" mode, the scalar pad value to use. Must be same type as tensor.
Returns
-------
A Tensor. Has the same type as tensor.
"""
pad_obj = Pad(paddings, mode, constant_values=constant_values)
return pad_obj(tensor)
```
<Overlap Ratio: 0.9877800407331976>

---

--- 313 --
Question ID: a29848e6f69b4f35cafc72b8a84fea6a83f8192f_0
Original Code:
```
def get_labelname(labelmap, labels):
    num_labels = len(labelmap)
    labelnames = []
    if type(labels) is not list:
        labels = [labels]
    for label in labels:
        labelnames.append(labelmap[int(label)])
    return labelnames
```


Overlapping Code:
```
f get_labelname(labelmap, labels):
num_labels = len(labelmap)
labelnames = []
if type(labels) is not list:
labels = [labels]
for label in labels:
labelnames.append(labelmap
```
<Overlap Ratio: 0.8390243902439024>

---

--- 314 --
Question ID: 226bcc6fbccf1244851ea24b16eccb42a0dec529_1
Original Code:
```
def run_job(spark, config, mode, s3_bucket=None, phase=None):
    """ Runs Data Preparation job"""
    raw_df = _read_data(spark, config, mode, phase, s3_bucket)
    phase = 'train' if "DEFAULT" in raw_df.columns else 'test'
    df = Pipe([
        IF(IF.Predicate.has_column('DEFAULT'), then=[
            RemoveDuplicates(config['id_col'])
        ]),
        ConvertStrToDate(config['date_str_cols']),
        GetAge(config['age_cols']),
        ExtractTimePeriodMths(config['tenure_cols']),
        ReplaceStrRegex(config['str_replace_cols']),
        ImputeCategoricalMissingVals(config['impute_cat_cols']),
        DropColumns(config['drop_cols']),
    ]).transform(raw_df)
    if mode == "local":
        df.write.parquet(config['processed_data_dir'] + f"{phase}.parquet", mode='overwrite')
    else:
        df.write.parquet(config['s3_processed_data_dir'].format(s3_bucket) + f"{phase}.parquet", 
                        mode='overwrite')
```


Overlapping Code:
```
rk, config, mode, s3_bucket=None, phase=None):
""" Runs Data Preparation job"""
raw_df = _read_data(spark, config, mode, phase, s3_bucket)
phase = 'train' if "DEFAULT" in raw_df.columns else 'test'
df = Pipe([
IF(IF.Predicate.has_column('DEFAULT'), then=[
RemoveDuplicates(config['id_col'])
]),
ConvertStrToDate(config['date_str_cols']),
GetAge(config['age_cols']),
ExtractTimePeriodMths(config['tenure_cols']),
ReplaceStrRegex(config['str_replace_cols']),
ImputeCategoricalMissingVals(config['impute_cat_cols']),
DropColumns(config['drop_cols']),
]).transform(raw_df)
if mode == "local":
df.write.parquet(config['processed_data_dir'] + f"{phase}.parquet", mode='overwrite')
else:
df.write.parquet(config['s3_processed_data_dir'].format(s3_bucket) + f"{phase}
```
<Overlap Ratio: 0.9452054794520548>

---

--- 315 --
Question ID: d75e4ebf9a812335b7560c458cab8467af7eb8ee_9
Original Code:
```
def jac(X, B, g):
  N = B.shape[0]
  SI = X.reshape((2,N))
  S = SI[0]
  I = SI[1]

  # derivative of f_S
  A1 = -  np.diag(np.einsum('ij,j->i', B, I))
  A2 = - np.einsum('ij,i->ij', B, S)
  A = np.concatenate([A1, A2], axis=1)

  # derivative of f_I
  B1 = -A1
  B2 = -A2 - g*np.eye(N)
  B = np.concatenate([B1, B2], axis=1)

  return np.concatenate([A,B], axis=0)
```


Overlapping Code:
```
 B.shape[0]
SI = X.reshape((2,N))
S = SI[0]
I = SI[1]
# derivative of f_S
A1 = - np.diag(np.einsum('ij,j->i', B, I))
A2 = - np.einsum('ij,i->ij', B, S)
A = np.concatenate([A1, A2], axis=1)
# derivative of f_I
B1 = -A1
B2 = -A2 - g*np.eye(N)
B = np.concatenate([B1, B2], axis=1)
return np.concatenate(
```
<Overlap Ratio: 0.8955223880597015>

---

--- 316 --
Question ID: 7b4accb344a7c5bc9011a33b491440566105035e_4
Original Code:
```
def validate_config(app, config):
    if len(app.config.panels_delimiters) != 3:
        raise AssertionError(
            "panels_delimiters config must be of form: (header, body, footer)"
        )
    if len(set(app.config.panels_delimiters)) != 3:
        raise AssertionError("panels_delimiters config must contain unique values")
    try:
        app.config.panels_delimiters = tuple(
            [re.compile(s) for s in app.config.panels_delimiters]
        )
    except Exception as err:
        raise AssertionError(
            "panels_delimiters config must contain only compilable regexes: {}".format(
                err
            )
        )
```


Overlapping Code:
```
lidate_config(app, config):
if len(app.config.panels_delimiters) != 3:
raise AssertionError(
"panels_delimiters config must be of form: (header, body, footer)"
)
if len(set(app.config.panels_delimiters)) != 3:
raise AssertionError("panels_delimiters config must contain unique values")
try:
app.config.panels_delimiters = tuple(
[re.compile(s) for s in app.config.panels_delimiters]
)
except Exception as err:
raise AssertionError(
"panels_delimiters config must contain only compilable regexes: {}".
```
<Overlap Ratio: 0.9596928982725528>

---

--- 317 --
Question ID: 8e53c3c74c80b4de0ef275553982b145b9cda73c_2
Original Code:
```
def get_caller_module_path(depth: int = 2) -> str:
    """Get the caller module path.

    We use sys._getframe instead of inspect.stack(0) because the latter is way slower, since it iterates over
    all the frames in the stack.
    """
    frame = _getframe(depth)
    return getframeinfo(frame, context=0).filename
```


Overlapping Code:
```
) -> str:
"""Get the caller module path.
We use sys._getframe instead of inspect.stack(0) because the latter is way slower, since it iterates over
all the frames in the stack.
"""
frame = _getframe(depth)
return getframeinfo(frame, context=0).filenam
```
<Overlap Ratio: 0.8561643835616438>

---

--- 318 --
Question ID: 387fcf1f324b8306f23da251bcbbc77f05345086_0
Original Code:
```
@pytest.fixture(params=params, ids=ids)
def attention_setup(request):
    sl, bs = 3, 2
    edq, edk = request.param

    # query would be the hidden state of the decoder
    keys = to_gpu(V(T(np.random.rand(sl, bs, edk))))
    query = to_gpu(V(T(np.random.rand(bs, edq))))
    return keys, query
```


Overlapping Code:
```
def attention_setup(request):
sl, bs = 3, 2
edq, edk = request.param
# query would be the hidden state of the decoder
keys = to_gpu(V(T(np.random.rand(sl, bs, edk))))
query = to_gpu(V(T(np.random.rand(bs
```
<Overlap Ratio: 0.7490774907749077>

---

--- 319 --
Question ID: 5896fe849ac0cfd44b6065f64f05244189a14044_0
Original Code:
```
@pytest.fixture
def get_request():
    req = APIRequestFactory().get("/", HTTP_ACCEPT="text/html")
    return APIView().initialize_request(req)
```


Overlapping Code:
```
def get_request():
req = APIRequestFactory().get("/", HTTP_ACCEPT="text/html")
return APIView().init
```
<Overlap Ratio: 0.7407407407407407>

---

--- 320 --
Question ID: e6c2a00b8f42410bfe9bfd9c8b2f683b0ac63e3a_0
Original Code:
```
def glorot(tensor):
    if tensor is not None:
        stdv = math.sqrt(6.0 / (tensor.size(-2) + tensor.size(-1)))
        tensor.data.uniform_(-stdv, stdv)
```


Overlapping Code:
```
ef glorot(tensor):
if tensor is not None:
stdv = math.sqrt(6.0 / (tensor.size(-2) + tensor.size(-1)))
tensor.data.uniform_(-stdv, stdv
```
<Overlap Ratio: 0.9852941176470589>

---

--- 321 --
Question ID: 897605ab48e22dd8b2c5b5938d21db144d77699d_0
Original Code:
```
def split_name (name):
    """Returns base, lower, upper strings of name"""
    def _find (n, s):
        idx = n.find(s)
        return idx if idx > 0 else len(n)

    base_end = min(map(lambda x: _find(name, x), [LOWER_TOK, UPPER_TOK]))
    low_start = _find(name, LOWER_TOK)
    up_start = _find(name, UPPER_TOK)
    low_end = up_start if up_start > low_start else len(name)
    up_end = low_start if up_start < low_start else len(name)
    base = name[:base_end]
    low = name[low_start:low_end].strip(LOWER_TOK + '{' + '}')
    up = name[up_start:up_end].strip(UPPER_TOK + '{' + '}')
    return base, low, up
```


Overlapping Code:
```
ase, lower, upper strings of name"""
def _find (n, s):
idx = n.find(s)
return idx if idx > 0 else len(n)
base_end = min(map(lambda x: _find(name, x), [LOWER_TOK, UPPER_TOK]))
low_start = _find(name, LOWER_TOK)
up_start = _find(name, UPPER_TOK)
low_end = up_start if up_start > low_start else len(name)
up_end = low_start if up_start < low_start else len(name)
base = name[:base_end]
low = name[low_start:low_end].strip(LOWER_TOK + '{' + '}')
up = name[up_start:up_end].strip(UPPER_TOK + '{' + '}')
re
```
<Overlap Ratio: 0.9041591320072333>

---

--- 322 --
Question ID: cb25cf5c30ed70a963f0519eb7f6e0049109895a_0
Original Code:
```
def cross_corr(a, b):
    """Cross-correlation

    Calculate the cross correlation of array b against array a.

    Args:
        a (array): numpy vector. Reference against which cross
            correlation is calculated.
        b (array): numpy vector. The resulting cross-correlation function
            will show how b should be shifted to line up with vector a.

    Returns:
        array: cross-correlation function
    """
    # noramlize a & b
    a = (a-np.min(a))/(np.max(a)-np.min(a))
    b = (b-np.min(b))/(np.max(b)-np.min(b))

    # compute the Fast Fourrier Transform
    f_a = np.fft.fft(a)
    f_b = np.fft.fft(b)

    # get the complex conjugate
    f_a_c = np.conj(f_a)

    # Convolution Theorem: The Fourier transform of the convolution is
    # the product of the two Fourier transforms

    # Correlation theorem: multiplying the Fourier transform of
    # one function by the complex conjugate of the Fourier transform of
    # the other gives the Fourier transform of their correlation
    # The inverse then brings us back to the original domain
    c_corr = np.fft.ifft(f_a_c*f_b)

    # FFT cross corr method gives the cyclic cross-correlation
    # "first n points in c_corr[0..2*n] stored in wrap-around order,
    # i.e., correlations at increasingly negative lags are in c_corr[n]
    # on down to c_corr[n/2+1], while correlations at increasingly
    # positive lags are in c_corr[0] (zero lag) on up to c_corr[n/2]."
    # --> Numerical Recipes in C to get the linear correlation, need to
    # circularly rotate the data this puts the peaks of the signal
    # together
    c_corr = np.abs(np.roll(c_corr, len(c_corr) // 2))
    # above does the same as np.fft.fftshift
    # note that the shift occurs on a pixel/array element level,
    # so len/2 has to be an integer so enforce floor/int division here

    # normalizing, may help peak fitting
    c_corr = (c_corr-np.min(c_corr))/(np.max(c_corr)-np.min(c_corr))

    return c_corr
```


Overlapping Code:
```
rr(a, b):
"""Cross-correlation
Calculate the cross correlation of array b against array a.
Args:
a (array): numpy vector. Reference against which cross
correlation is calculated.
b (array): numpy vector. The resulting cross-correlation function
will show how b should be shifted to line up with vector a.
Returns:
array: cross-correlation function
"""
# noramlize a & b
a = (a-np.min(a))/(np.max(a)-np.min(a))
b = (b-np.min(b))/(np.max(b)-np.min(b))
# compute the Fast Fourrier Transform
f_a = np.fft.fft(a)
f_b = np.fft.fft(b)
# get the complex conjugate
f_a_c = np.conj(f_a)
# Convolution Theorem: The Fourier transform of the convolution is
# the product of the two Fourier transforms
# Correlation theorem: multiplying the Fourier transform of
# one function by the complex conjugate of the Fourier transform of
# the other gives the Fourier transform of their correlation
# The inverse then brings us back to the original domain
c_corr = np.fft.ifft(f_a_c*f_b)
# FFT cross corr method gives the cyclic cross-correlation
# "first n points in c_corr[0..2*n] stored in wrap-around order,
# i.e., correlations at increasingly negative lags are in c_corr[n]
# on down to c_corr[n/2+1], while correlations at increasingly
# positive lags are in c_corr[0] (zero lag) on up to c_corr[n/2]."
# --> Numerical Recipes in C to get the linear correlation, need to
# circularly rotate the data this puts the peaks of the signal
# together
c_corr = np.abs(np.roll(c_corr, len(c_corr) // 2))
# above does the same as np.fft.fftshift
# note that the shift occurs on a pixel/array element level,
# so len/2 has to be an integer so enforce floor/int division here
# normalizing, may help peak fitting
c_corr = (c_corr-np.min(c_corr))/(np.max(c_corr)-np.min(c_corr)
```
<Overlap Ratio: 0.9848058525604952>

---

--- 323 --
Question ID: 7c11b3b1eddd029e69bf5bba21e4c070a90bb2f9_1
Original Code:
```
@pytest.fixture(scope="module")
def model_data():
    mnist = mx.test_utils.get_mnist()
    train_data = array_module.array(mnist["train_data"].reshape(-1, 784))
    train_label = array_module.array(mnist["train_label"])
    test_data = array_module.array(mnist["test_data"].reshape(-1, 784))
    return train_data, train_label, test_data
```


Overlapping Code:
```
ata():
mnist = mx.test_utils.get_mnist()
train_data = array_module.array(mnist["train_data"].reshape(-1, 784))
train_label = array_module.array(mnist["train_label"])
test_data = array_module.array(mnist["test_data"].reshape(-1, 784))
return train_dat
```
<Overlap Ratio: 0.7861635220125787>

---

--- 324 --
Question ID: af38d43d09853349aa74f4954f9df7f77f9f8183_0
Original Code:
```
def cached(key, timeout=3600):
    """Cache the return value of the decorated function with the given key.

    Key can be a String or a function.
    If key is a function, it must have the same arguments as the decorated function,
    otherwise it cannot be called successfully.
    """

    def decorator(f):
        @wraps(f)
        def wrapped(*args, **kwargs):
            cache = get_cache()
            # Check if key is a function
            if callable(key):
                cache_key = key(*args, **kwargs)
            else:
                cache_key = key
            # Try to get the value from cache
            cached_val = cache.get(cache_key)
            if cached_val is None:
                # Call the original function and cache the result
                cached_val = f(*args, **kwargs)
                cache.set(cache_key, cached_val, timeout)
            return cached_val

        return wrapped

    return decorator
```


Overlapping Code:
```
"""Cache the return value of the decorated function with the given key.
Key can be a String or a function.
If key is a function, it must have the same arguments as the decorated function,
otherwise it cannot be called successfully.
"""
def decorator(f):
@wraps(f)
def wrapped(*args, **kwargs):
cache = get_cache()
# Check if key is a function
if callable(key):
cache_key = key(*args, **kwargs)
else:
cache_key = key
# Try to get the value from cache
cached_val = cache.get(cache_key)
if cached_val is None:
# Call the original function and cache the result
cached_val = f(*args, **kwargs)
cache.set(cache_key, cached_val, timeout)
return cached_val
r
```
<Overlap Ratio: 0.9142053445850914>

---

--- 325 --
Question ID: 2f1913765aa6cc21a9f98c848fc9a38bfb006c61_14
Original Code:
```
def get_needed_cities(request):
    if 'city' in request.GET:
        city_from_user = request.GET['city']

        # Search similar in db
        needed_cities = City.objects.filter(
            name__icontains=city_from_user).only('name')[:10]

        # Dump to json
        return HttpResponse(json.dumps([city.name for city in needed_cities]), content_type="application/json")
    return HttpResponse()
```


Overlapping Code:
```
equest.GET:
city_from_user = request.GET['city']
# Search similar in db
needed_cities = City.objects.filter(
name__icontains=city_from_user).only('name')[:10]
# Dump to json
return HttpResponse(json.dumps([city.name for city in needed_cities]), content_type="application/json")
return HttpResponse(
```
<Overlap Ratio: 0.863768115942029>

---

--- 326 --
Question ID: 8600fc6fc5e2cffc5173a4638948df030a5c1d80_0
Original Code:
```
def route2cost(route, dist):
    assert route[0] == 0
    assert route[-1] == 0
    
    return dist[(route[:-1], route[1:])].sum()
```


Overlapping Code:
```
e2cost(route, dist):
assert route[0] == 0
assert route[-1] == 0

return dist[(route[:-1], route[1:])
```
<Overlap Ratio: 0.8695652173913043>

---

--- 327 --
Question ID: 1fad3b8ef3251f78078d3369644fbeef33711b60_4
Original Code:
```
@login_required(login_url='/camp/login/')
def post_review(request, slug=None):
    if request.method == "POST":
        camp = get_object_or_404(Camp, slug=slug)
        user = request.user

        rating = request.POST.get('user-rating')
        comment = request.POST.get('user-review')
        
        rate_obj = Rate(camp=camp, user=user, rating=rating, comment=comment)
        rate_obj.save()

        return redirect('camp_detail', slug=slug)

    else:
        return HttpResponse('NOT ALLOWED')
```


Overlapping Code:
```
_url='/camp/login/')
def post_review(request, slug=None):
if request.method == "POST":
camp = get_object_or_404(Camp, slug=slug)
user = request.user
rating = request.POST.get('user-rating')
comment = request.POST.get('user-review')

rate_obj = Rate(camp=camp, user=user, rating=rating, comment=comment)
rate_obj.save()
return redirect('camp_detail', slug=slug)
else:
return HttpResponse('NOT ALLOWED'
```
<Overlap Ratio: 0.9478672985781991>

---

--- 328 --
Question ID: 76b0879b1d116786730e0b4b06b7b6527d94d5ec_47
Original Code:
```
def test_dns_service(client, compose):
    template = '''
    web1:
        image: nginx
    web2:
        image: nginx
    web:
        image: rancher/dns-service
        links:
        - web1
        - web2
    '''
    project_name = create_project(compose, input=template)

    project = find_one(client.list_stack, name=project_name)
    services = project.services()

    assert len(services) == 3

    web = _get_service(services, 'web')

    assert web.type == 'dnsService'
    consumed = web.consumedservices()

    assert len(consumed) == 2
    names = {x.name for x in consumed}

    assert names == {'web1', 'web2'}
```


Overlapping Code:
```
vice(client, compose):
template = '''
web1:
image: nginx
web2:
image: nginx
web:
image: rancher/dns-service
links:
- web1
- web2
'''
project_name = create_project(compose, input=template)
project = find_one(client.list_stack, name=project_name)
services = project.services()
assert len(services) == 3
web = _get_service(services, 'web')
assert web.type == 'dnsService'
consumed = web.consumedservices()
assert len(consumed) == 2
names = {x.name for x
```
<Overlap Ratio: 0.87890625>

---

--- 329 --
Question ID: a7949c8a1d4ce2bfd5a91876e53711bd34fab737_3
Original Code:
```
def get_access_token(request):
    # Happens when the user hits index the first time and hasn't authenticated on Learn
    # Part II. Get an access token for the user that logged in. Put that on their session.
    bb_json = request.session.get('bb_json')
    target_view = request.session.get('target_view')
    print('VIEWS: get_access_token: got BbRest from session')
    bb = jsonpickle.decode(bb_json)
    bb.supported_functions() # This and the following are required after
    bb.method_generator()    # unpickling the pickled object.
    # Next, get the code parameter value from the request
    redirect_uri = reverse(get_access_token)
    absolute_redirect_uri = f"https://{request.get_host()}{redirect_uri}"

    state = request.GET.get('state', default= "NOSTATE")
    print(f'VIEWS: get_access_token: GOT BACK state: {state}')
    stored_state = request.session.get('state')
    print(f'VIEWS: get_access_token: STORED STATE: {stored_state}')
    if (stored_state != state):
        return HttpResponseRedirect(reverse('notauthorized'))

    code =  request.GET.get('code', default = None)
    if (code == None):
        exit()

    #Rebuild a new BbRest object to get an access token with the user's authcode.
    # if (CUSTOM_LOGIN_URL):
    #     print("CUSTOM_LOGIN_URL")
    #     user_bb = BbRest(KEY, SECRET, f"https://{CUSTOM_LOGIN_URL}", code=code, redirect_uri=absolute_redirect_uri )
    # else:
    user_bb = BbRest(KEY, SECRET, f"https://{LEARNFQDN}", code=code, redirect_uri=absolute_redirect_uri )    
    bb_json = jsonpickle.encode(user_bb)
    if (isGuestUser(bb_json)):
        context = {
            'learn_server': LEARNFQDN,
        }   
        return render(request, 'guestusernotallowed.html', context=context )

    print('VIEWS: get_access_token: pickled BbRest and putting it on session')
    request.session['bb_json'] = bb_json
    return HttpResponseRedirect(reverse(f'{target_view}'))
```


Overlapping Code:
```
st):
# Happens when the user hits index the first time and hasn't authenticated on Learn
# Part II. Get an access token for the user that logged in. Put that on their session.
bb_json = request.session.get('bb_json')
target_view = request.session.get('target_view')
print('VIEWS: get_access_token: got BbRest from session')
bb = jsonpickle.decode(bb_json)
bb.supported_functions() # This and the following are required after
bb.method_generator() # unpickling the pickled object.
# Next, get the code parameter value from the request
redirect_uri = reverse(get_access_token)
absolute_redirect_uri = f"https://{request.get_host()}{redirect_uri}"
state = request.GET.get('state', default= "NOSTATE")
print(f'VIEWS: get_access_token: GOT BACK state: {state}')
stored_state = request.session.get('state')
print(f'VIEWS: get_access_token: STORED STATE: {stored_state}')
if (stored_state != state):
return HttpResponseRedirect(reverse('notauthorized'))
code = request.GET.get('code', default = None)
if (code == None):
exit()
#Rebuild a new BbRest object to get an access token with the user's authcode.
# if (CUSTOM_LOGIN_URL):
# print("CUSTOM_LOGIN_URL")
# user_bb = BbRest(KEY, SECRET, f"https://{CUSTOM_LOGIN_URL}", code=code, redirect_uri=absolute_redirect_uri )
# else:
user_bb = BbRest(KEY, SECRET, f"https://{LEARNFQDN}", code=code, redirect_uri=absolute_redirect_uri ) 
bb_json = jsonpickle.encode(user_bb)
if (isGuestUser(bb_json)):
context = {
'learn_server': LEARNFQDN,
} 
return render(request, 'guestusernotallowed.html', context=context )
print('VIEWS: get_access_token: pickled BbRest and putting it on session')
request.session['bb_json'] = bb_json
return HttpResponseRedirect(reverse(f'{t
```
<Overlap Ratio: 0.9770114942528736>

---

--- 330 --
Question ID: fc004b91f3e58f1e94c240732f876a5bacc896ad_2
Original Code:
```
def doBinomialTest(p, sample_size, observed, significance_threshold=0.05):
    """perform a binomial test.

    Given are p: the probability of the NULL hypothesis, the sample_size
    and the number of observed counts.
    """
    pass
```


Overlapping Code:
```
Test(p, sample_size, observed, significance_threshold=0.05):
"""perform a binomial test.
Given are p: the probability of the NULL hypothesis, the sample_size
and the number of obse
```
<Overlap Ratio: 0.8372093023255814>

---

--- 331 --
Question ID: 99723bae9f12e77b9eb428cc5f968407bdbb58e7_2
Original Code:
```
def writer(id, u_dict):
  '''
  

   -> csv
  '''
  dict_path = "./config/guild/" + str(id) + "/" + "dict.csv"
  with open(dict_path,mode="w",encoding="utf-16") as f:
    writer = csv.writer(f)
    for k, v in u_dict.items():
      writer.writerow([k,v])
```


Overlapping Code:
```
id, u_dict):
'''

 -> csv
'''
dict_path = "./config/guild/" + str(id) + "/" + "dict.csv"
with open(dict_path,mode="w",encoding="utf-16") as f:
writer = csv.writer(f)
for k, v in u_dict.items(
```
<Overlap Ratio: 0.847457627118644>

---

--- 332 --
Question ID: 34d7f11c6d32fae190ddc29826215149e2291bf7_0
Original Code:
```
@shared_task
def sync_social_accounts(user_pk):
    from social_django.models import UserSocialAuth
    from forsta_auth.backend_meta import BackendMeta
    session = apps.get_app_config('forsta_auth').session

    user = get_user_model().objects.get(pk=user_pk)
    if not user.primary:
        return

    user_social_auths = UserSocialAuth.objects.filter(user=user)
    by_upstream_id = {str(usa.pk): usa
                      for usa in user_social_auths}
    online_account_url = urljoin(settings.IDM_CORE_API_URL, 'online-account/')

    results, url = [], online_account_url
    while url:
        response = session.get(url,
                               params={'identity': user.identity_id,
                                       'managed_by': settings.IDM_APPLICATION_ID})
        response.raise_for_status()
        response_data = response.json()
        results.extend(response_data['results'])
        url = response_data.get('next')

    for result in results:
        usa = by_upstream_id.get(result['upstream_id'])
        if usa:
            backend_meta = BackendMeta.wrap(usa)
            if backend_meta.username != result['screen_name']:
                session.patch(result['url'], json={'screen_name': backend_meta.username}).raise_for_status()
            del by_upstream_id[result['upstream_id']]
        else:
            session.delete(result['url']).raise_for_status()

    for upstream_id, usa in by_upstream_id.items():
        backend_meta = BackendMeta.wrap(usa)
        provider_id = provider_id_override.get(backend_meta.provider, backend_meta.provider)
        if provider_id is None:
            continue
        response = session.post(online_account_url, json={
            'identity': str(user.identity_id),
            'upstream_id': upstream_id,
            'provider_id': provider_id,
            'screen_name': backend_meta.username,
            'validated': True,
            'context': 'home',
            'managed': True,
            'manage_url': 'https://{}{}'.format(get_current_site(None).domain,
                                                reverse('social-logins'))
        })
        if not response.ok:
            logger.error("Couldn't create online-account:\n{}".format(response.content))
        response.raise_for_status()
```


Overlapping Code:
```
:
from social_django.models import UserSocialAuth
from forsta_auth.backend_meta import BackendMeta
session = apps.get_app_config('forsta_auth').session
user = get_user_model().objects.get(pk=user_pk)
if not user.primary:
return
user_social_auths = UserSocialAuth.objects.filter(user=user)
by_upstream_id = {str(usa.pk): usa
for usa in user_social_auths}
online_account_url = urljoin(settings.IDM_CORE_API_URL, 'online-account/')
results, url = [], online_account_url
while url:
response = session.get(url,
params={'identity': user.identity_id,
'managed_by': settings.IDM_APPLICATION_ID})
response.raise_for_status()
response_data = response.json()
results.extend(response_data['results'])
url = response_data.get('next')
for result in results:
usa = by_upstream_id.get(result['upstream_id'])
if usa:
backend_meta = BackendMeta.wrap(usa)
if backend_meta.username != result['screen_name']:
session.patch(result['url'], json={'screen_name': backend_meta.username}).raise_for_status()
del by_upstream_id[result['upstream_id']]
else:
session.delete(result['url']).raise_for_status()
for upstream_id, usa in by_upstream_id.items():
backend_meta = BackendMeta.wrap(usa)
provider_id = provider_id_override.get(backend_meta.provider, backend_meta.provider)
if provider_id is None:
continue
response = session.post(online_account_url, json={
'identity': str(user.identity_id),
'upstream_id': upstream_id,
'provider_id': provider_id,
'screen_name': backend_meta.username,
'validated': True,
'context': 'home',
'managed': True,
'manage_url': 'https://{}{}'.format(get_current_site(None).domain,
reverse('social-logins'))
})
if not response.ok:
logger.error("Couldn't create online-account:\n{}".format(response.content))
response.raise_for_status()
```
<Overlap Ratio: 0.9741863075196409>

---

--- 333 --
Question ID: 94bcdb86ef6b1e1256808a02f4d67adf2208cdea_7
Original Code:
```
def _compare_traces(expected: Trace, received: Trace, ignored: Set[str]) -> None:
    """Compare two traces for differences.

    The given traces are assumed to be in BFS order.
    """
    if len(received) > len(expected):
        names = ["'%s'" % s["name"] for s in received[len(expected) - len(received) :]]
        raise AssertionError(
            f"Received more spans ({len(received)}) than expected ({len(expected)}). Received unmatched spans: {', '.join(names)}"
        )
    elif len(expected) > len(received):
        names = ["'%s'" % s["name"] for s in expected[len(received) - len(expected) :]]
        raise AssertionError(
            f"Received fewer spans ({len(received)}) than expected ({len(expected)}). Expected unmatched spans: {', '.join(names)}"
        )

    for s_exp, s_rec in zip(expected, received):
        with CheckTrace.add_frame(
            f"snapshot compare of span '{s_exp['name']}' at position {s_exp['span_id']} in trace"
        ) as frame:
            frame.add_item(f"Expected span:\n{pprint.pformat(s_exp)}")
            frame.add_item(f"Received span:\n{pprint.pformat(s_rec)}")
            top_level_diffs, meta_diffs, metrics_diffs = _diff_spans(
                s_exp, s_rec, ignored
            )

            for diffs, diff_type, d_exp, d_rec in [
                (top_level_diffs, "span", s_exp, s_rec),
                (meta_diffs, "meta", s_exp["meta"], s_rec["meta"]),
                (metrics_diffs, "metrics", s_exp["metrics"], s_rec["metrics"]),
            ]:
                for diff_key in diffs:
                    if diff_key not in d_exp:
                        raise AssertionError(
                            f"Span{' ' + diff_type if diff_type != 'span' else ''} value '{diff_key}' in received span but is not in the expected span."
                        )
                    elif diff_key not in d_rec:
                        raise AssertionError(
                            f"Span{' ' + diff_type if diff_type != 'span' else ''} value '{diff_key}' in expected span but is not in the received span."
                        )
                    else:
                        raise AssertionError(
                            f"{diff_type} mismatch on '{diff_key}': got '{d_rec[diff_key]}' which does not match expected '{d_exp[diff_key]}'."
                        )
```


Overlapping Code:
```
s(expected: Trace, received: Trace, ignored: Set[str]) -> None:
"""Compare two traces for differences.
The given traces are assumed to be in BFS order.
"""
if len(received) > len(expected):
names = ["'%s'" % s["name"] for s in received[len(expected) - len(received) :]]
raise AssertionError(
f"Received more spans ({len(received)}) than expected ({len(expected)}). Received unmatched spans: {', '.join(names)}"
)
elif len(expected) > len(received):
names = ["'%s'" % s["name"] for s in expected[len(received) - len(expected) :]]
raise AssertionError(
f"Received fewer spans ({len(received)}) than expected ({len(expected)}). Expected unmatched spans: {', '.join(names)}"
)
for s_exp, s_rec in zip(expected, received):
with CheckTrace.add_frame(
f"snapshot compare of span '{s_exp['name']}' at position {s_exp['span_id']} in trace"
) as frame:
frame.add_item(f"Expected span:\n{pprint.pformat(s_exp)}")
frame.add_item(f"Received span:\n{pprint.pformat(s_rec)}")
top_level_diffs, meta_diffs, metrics_diffs = _diff_spans(
s_exp, s_rec, ignored
)
for diffs, diff_type, d_exp, d_rec in [
(top_level_diffs, "span", s_exp, s_rec),
(meta_diffs, "meta", s_exp["meta"], s_rec["meta"]),
(metrics_diffs, "metrics", s_exp["metrics"], s_rec["metrics"]),
]:
for diff_key in diffs:
if diff_key not in d_exp:
raise AssertionError(
f"Span{' ' + diff_type if diff_type != 'span' else ''} value '{diff_key}' in received span but is not in the expected span."
)
elif diff_key not in d_rec:
raise AssertionError(
f"Span{' ' + diff_type if diff_type != 'span' else ''} value '{diff_key}' in expected span but is not in the received span."
)
else:
raise AssertionError(
f"{diff_type} mismatch on '{diff_key}': got '{d_rec[diff_key]}' which does not match expected '{d_exp[di
```
<Overlap Ratio: 0.982594048287479>

---

--- 334 --
Question ID: 6f8ec2105f8f4269bedaa2795a1bb80004667fe2_0
Original Code:
```
@celery_app.task(ignore_result=True, time_limit=600)
def do_refresh_config():
    # 
    inject.clear_and_configure(bind, bind_in_runtime=False)
    config: Config = inject.instance(Config)
    logger.info(f'run do_refresh_config done, config is {config}')
```


Overlapping Code:
```
t=True, time_limit=600)
def do_refresh_config():
# 
inject.clear_and_configure(bind, bind_in_runtime=False)
config: Config = inject.instance(Config)
logger.info(f'run do_refresh_config done, confi
```
<Overlap Ratio: 0.819672131147541>

---

--- 335 --
Question ID: 8ad289b92000df0c97a926e605855965c9db0ef2_0
Original Code:
```
async def async_setup_platform(hass, config, async_add_entities, discovery_info=None):
    """Set up the Sense sensor."""
    if discovery_info is None:
        return
    data = hass.data[SENSE_DATA]

    @Throttle(MIN_TIME_BETWEEN_DAILY_UPDATES)
    async def update_trends():
        """Update the daily power usage."""
        await data.update_trend_data()

    async def update_active():
        """Update the active power usage."""
        await data.update_realtime()

    devices = []
    for typ in SENSOR_TYPES.values():
        for var in SENSOR_VARIANTS:
            name = typ.name
            sensor_type = typ.sensor_type
            is_production = var == PRODUCTION_NAME.lower()
            if sensor_type == ACTIVE_TYPE:
                update_call = update_active
            else:
                update_call = update_trends
            devices.append(Sense(data, name, sensor_type, is_production, update_call))

    async_add_entities(devices)
```


Overlapping Code:
```
async def async_setup_platform(hass, config, async_add_entities, discovery_info=None):
"""Set up the Sense sensor."""
if discovery_info is None:
return
data = hass.data[SENSE_DATA]
@Throttle(MIN_TIME_BETWEEN_DAILY_UPDATES)
async def update_trends():
"""Update the daily power usage."""
await data.update_trend_data()
async def update_active():
"""Update the active power usage."""
await data.update_realtime()
devices = []
for typ in SENSOR_TYPES.values():
for var in SENSOR_VARIANTS:
name = typ.name
sensor_type = typ.sensor_type
is_production = var == PRODUCTION_NAME.lower()
if sensor_type == ACTIVE_TYPE:
update_call = update_active
else:
update_call = update_trends
devices.append(Sense(data, name, sensor_type, is_production, update_call))
```
<Overlap Ratio: 0.963777490297542>

---

--- 336 --
Question ID: cfb4f274b6427f7e0848af2f473761abab2a00fb_0
Original Code:
```
def test_schemas():
  modules = look_for_schemas_dirs_tests()
  for (module, schema, files) in modules:
    for (isValid, path, data) in files:
      try:
        validate(data, schema)
        if not isValid:
          raise Exception("Validation for {} should have failed".format(path))
      except ValidationError:
        if isValid:
          raise
```


Overlapping Code:
```
rs_tests()
for (module, schema, files) in modules:
for (isValid, path, data) in files:
try:
validate(data, schema)
if not isValid:
raise Exception("Validation for {} should have failed".format(path))

```
<Overlap Ratio: 0.6896551724137931>

---

--- 337 --
Question ID: 3371c94e95dca7ace8a0ad2189b18574f1e55b17_0
Original Code:
```
def pred_only(coco_json, add_score=None):
    coco_json_path = path(coco_json)
    coco_dict, setname = read_coco_json(coco_json_path)
    if add_score is not None:
        assert isinstance(add_score, float)
        for annot in coco_dict["annotations"]:
            annot["score"] = add_score
    annotations = coco_dict["annotations"]
    out = coco_json_path.parent / f"{coco_json_path.stem}_pred.json"
    write_json(out, annotations)
```


Overlapping Code:
```
d_only(coco_json, add_score=None):
coco_json_path = path(coco_json)
coco_dict, setname = read_coco_json(coco_json_path)
if add_score is not None:
assert isinstance(add_score, float)
for annot in coco_dict["annotations"]:
annot["score"] = add_score
annotations = coco_dict["annotations"]
out = coco_json_path.parent / f"{coco_json_path.stem}_pred.json
```
<Overlap Ratio: 0.9043927648578811>

---

--- 338 --
Question ID: 073900b812eade913892526f02d60c827bc0c8b0_2
Original Code:
```
def test_output(tmpdir):
    f = tmpdir.join("test.py")
    f.write(
        """
import ddtrace
""".lstrip()
    )
    p = subprocess.Popen(
        ["ddtrace-run", sys.executable, "test.py"],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        cwd=str(tmpdir),
    )
    p.wait()
    assert p.stderr.read() == six.b("")
    assert p.stdout.read() == six.b("")
    assert p.returncode == 0
```


Overlapping Code:
```
tmpdir):
f = tmpdir.join("test.py")
f.write(
"""
import ddtrace
""".lstrip()
)
p = subprocess.Popen(
["ddtrace-run", sys.executable, "test.py"],
stdout=subprocess.PIPE,
stderr=subprocess.PIPE,
cwd=str(tmpdir),
)
p.wait()
assert p.stderr.read() == six.b("")
assert p.stdout.read() == six.b("")
assert p.ret
```
<Overlap Ratio: 0.9159159159159159>

---

--- 339 --
Question ID: 4b0bd9fdd83363d0c9a5038d97c6a43cfbd57a0b_2
Original Code:
```
def filter_by_period_freq (period_frequencies, period_thresh=5):
	""" Return True if more than `period_thresh` periods have zero counts"""
	zero_freq_dist = [period_frequencies[period] == 0 for period in period_frequencies]
	return is_count_greater (zero_freq_dist, thresh=period_thresh)
```


Overlapping Code:
```
by_period_freq (period_frequencies, period_thresh=5):
""" Return True if more than `period_thresh` periods have zero counts"""
zero_freq_dist = [period_frequencies[period] == 0 for period in period_frequencies]
return is_count_greater (zero_freq_dist
```
<Overlap Ratio: 0.8802816901408451>

---

--- 340 --
Question ID: a2da1fda6f5da272aa59b296808b668b20521756_1
Original Code:
```
@caching.cached_api_call(in_memory=True)
def get_buckets(context: models.Context) -> Mapping[str, Bucket]:

  buckets: Dict[str, Bucket] = {}
  if not apis.is_enabled(context.project_id, 'storage'):
    return buckets
  gcs_api = apis.get_api('storage', 'v1', context.project_id)
  logging.info('fetching list of GCS buckets in project %s', context.project_id)
  query = gcs_api.buckets().list(project=context.project_id)
  try:
    resp = query.execute(num_retries=config.API_RETRIES)
    if 'items' not in resp:
      return buckets
    for resp_b in resp['items']:
      # verify that we have some minimal data that we expect
      if 'id' not in resp_b:
        raise RuntimeError('missing data in bucket response')
      f = Bucket(project_id=context.project_id, resource_data=resp_b)
      buckets[f.full_path] = f
  except googleapiclient.errors.HttpError as err:
    raise utils.GcpApiError(err) from err
  return buckets
```


Overlapping Code:
```
ll(in_memory=True)
def get_buckets(context: models.Context) -> Mapping[str, Bucket]:
buckets: Dict[str, Bucket] = {}
if not apis.is_enabled(context.project_id, 'storage'):
return buckets
gcs_api = apis.get_api('storage', 'v1', context.project_id)
logging.info('fetching list of GCS buckets in project %s', context.project_id)
query = gcs_api.buckets().list(project=context.project_id)
try:
resp = query.execute(num_retries=config.API_RETRIES)
if 'items' not in resp:
return buckets
for resp_b in resp['items']:
# verify that we have some minimal data that we expect
if 'id' not in resp_b:
raise RuntimeError('missing data in bucket response')
f = Bucket(project_id=context.project_id, resource_data=resp_b)
buckets[f.full_path] = f
except googleapiclient.errors.HttpError as err:
raise utils.GcpApiError(err) from err
return 
```
<Overlap Ratio: 0.9660421545667447>

---

--- 341 --
Question ID: b40bd299a26c37f69ba583ce535e99e2ba71fd32_6
Original Code:
```
@pytest.mark.skip("")
@pytest.mark.parametrize('op', BINARY_MATH_OPS_ZERO_ISSUES)
@given(a=npst.arrays(shape=len(JAN_EVENT_2020_VALUES),
                     dtype=np.float,
                     elements=st.floats(allow_infinity=False, allow_nan=False)))
def test_div_array(a, op):
    # Not supported as the cmp operators are handled by numpy comparing each item individually.
    # np.testing.assert_array_equal(op(a, JAN_EVENT).sample_from(DATES_2020),
    #                               op(a, JAN_EVENT_2020_VALUES))

    a[a == 0] = 1

    np.testing.assert_array_equal(op(JAN_EVENT, a).sample_from(DATES_2020),
                                  op(JAN_EVENT_2020_VALUES, a))
```


Overlapping Code:
```
ytest.mark.parametrize('op', BINARY_MATH_OPS_ZERO_ISSUES)
@given(a=npst.arrays(shape=len(JAN_EVENT_2020_VALUES),
dtype=np.float,
elements=st.floats(allow_infinity=False, allow_nan=False)))
def test_div_array(a, op):
# Not supported as the cmp operators are handled by numpy comparing each item individually.
# np.testing.assert_array_equal(op(a, JAN_EVENT).sample_from(DATES_2020),
# op(a, JAN_EVENT_2020_VALUES))
a[a == 0] = 1
np.testing.assert_array_equal(op(JAN_EVENT, a).sample_from(DATES_2020),
op(JAN_EVENT_2
```
<Overlap Ratio: 0.9294755877034359>

---

--- 342 --
Question ID: 1ce101dc7e5c518d0d0e6dd29f7bf6b707078f68_24
Original Code:
```
def test_registry_decorator():
    async def _command():
        return ''

    registry = CommandRegistry()
    wrapper = registry.decorator(FirstWordTrigger('one'))
    result = wrapper(_command)
    assert result is _command
    assert registry[FirstWordTrigger('one')]._command_func is result
```


Overlapping Code:
```
try_decorator():
async def _command():
return ''
registry = CommandRegistry()
wrapper = registry.decorator(FirstWordTrigger('one'))
result = wrapper(_command)
assert result is _command
assert registry
```
<Overlap Ratio: 0.7604562737642585>

---

--- 343 --
Question ID: d01958d5bdff8057ec2a9bafa4da149c845a20eb_0
Original Code:
```
@dispatch(Tensor)
def bgr_to_rgb(image: Tensor) -> Tensor:
    """Convert a BGR image to RGB.

    Args:
        image (Tensor[B, 3, H, W]):
            BGR Image to be converted to BGR.

    Returns:
        rgb (Tensor[B, 3, H, W]):
            RGB version of the image.
    """
    # Flip image channels
    rgb = image.flip(-3)
    return rgb
```


Overlapping Code:
```
patch(Tensor)
def bgr_to_rgb(image: Tensor) -> Tensor:
"""Convert a BGR image to RGB.
Args:
image (Tensor[B, 3, H, W]):
BGR Image to be converted to BGR.
Returns:
rgb (Tensor[B, 3, H, W]):
RGB version of the image.
"""
# Flip image channels
rgb = ima
```
<Overlap Ratio: 0.9057971014492754>

---

--- 344 --
Question ID: abe83e0211a1980d4f506b8843b7188c6bd41fbd_0
Original Code:
```
def parse_method_info(method):
    sig = inspect.signature(method)
    params = sig.parameters
    return params
```


Overlapping Code:
```
_info(method):
sig = inspect.signature(method)
par
```
<Overlap Ratio: 0.5>

---

--- 345 --
Question ID: 42c0928e47b62e26ce976862771fd390bddeabb1_0
Original Code:
```
def run_demo(cfg, frame_provider):
    """
    Run visualization visualization.
    Args:
        cfg (CfgNode): configs. Details can be found in
            slowfast/config/defaults.py
        frame_provider (iterator): Python iterator that return task objects that are filled
            with necessary information such as `frames`, `id` and `num_buffer_frames` for the
            prediction and visualization pipeline.
    """
    # Set random seed from configs.
    np.random.seed(cfg.RNG_SEED)
    torch.manual_seed(cfg.RNG_SEED)
    # Setup logging format.
    logging.setup_logging(cfg.OUTPUT_DIR)
    # Print config.
    logger.info("Run visualization with config:")
    logger.info(cfg)
    common_classes = (
        cfg.DEMO.COMMON_CLASS_NAMES
        if len(cfg.DEMO.LABEL_FILE_PATH) != 0
        else None
    )

    video_vis = VideoVisualizer(
        num_classes=cfg.MODEL.HEAD.NUM_CLASSES,
        class_names_path=cfg.DEMO.LABEL_FILE_PATH,
        thres=cfg.DEMO.COMMON_CLASS_THRES,
        lower_thres=cfg.DEMO.UNCOMMON_CLASS_THRES,
        common_class_names=common_classes,
        mode=cfg.DEMO.VIS_MODE,
    )

    async_vis = AsyncVis(video_vis, n_workers=cfg.DEMO.NUM_VIS_INSTANCES)

    if cfg.NUM_GPUS <= 1:
        model = ActionPredictor(cfg=cfg, async_vis=async_vis)
    else:
        model = AsyncActionPredictor(cfg=cfg, async_vis=async_vis)

    seq_len = cfg.DATASETS.CLIP_LEN * cfg.DATASETS.NUM_CLIPS

    assert (
            cfg.DEMO.BUFFER_SIZE <= seq_len // 2
    ), "Buffer size cannot be greater than half of sequence length."
    num_task = 0
    # Start reading frames.
    frame_provider.start()
    for able_to_read, task in frame_provider:
        if not able_to_read:
            break
        if task is None:
            time.sleep(0.02)
            continue
        num_task += 1

        model.put(task)
        try:
            task = model.get()
            num_task -= 1
            yield task
        except IndexError:
            continue

    while num_task != 0:
        try:
            task = model.get()
            num_task -= 1
            yield task
        except IndexError:
            continue
```


Overlapping Code:
```
emo(cfg, frame_provider):
"""
Run visualization visualization.
Args:
cfg (CfgNode): configs. Details can be found in
slowfast/config/defaults.py
frame_provider (iterator): Python iterator that return task objects that are filled
with necessary information such as `frames`, `id` and `num_buffer_frames` for the
prediction and visualization pipeline.
"""
# Set random seed from configs.
np.random.seed(cfg.RNG_SEED)
torch.manual_seed(cfg.RNG_SEED)
# Setup logging format.
logging.setup_logging(cfg.OUTPUT_DIR)
# Print config.
logger.info("Run visualization with config:")
logger.info(cfg)
common_classes = (
cfg.DEMO.COMMON_CLASS_NAMES
if len(cfg.DEMO.LABEL_FILE_PATH) != 0
else None
)
video_vis = VideoVisualizer(
num_classes=cfg.MODEL.HEAD.NUM_CLASSES,
class_names_path=cfg.DEMO.LABEL_FILE_PATH,
thres=cfg.DEMO.COMMON_CLASS_THRES,
lower_thres=cfg.DEMO.UNCOMMON_CLASS_THRES,
common_class_names=common_classes,
mode=cfg.DEMO.VIS_MODE,
)
async_vis = AsyncVis(video_vis, n_workers=cfg.DEMO.NUM_VIS_INSTANCES)
if cfg.NUM_GPUS <= 1:
model = ActionPredictor(cfg=cfg, async_vis=async_vis)
else:
model = AsyncActionPredictor(cfg=cfg, async_vis=async_vis)
seq_len = cfg.DATASETS.CLIP_LEN * cfg.DATASETS.NUM_CLIPS
assert (
cfg.DEMO.BUFFER_SIZE <= seq_len // 2
), "Buffer size cannot be greater than half of sequence length."
num_task = 0
# Start reading frames.
frame_provider.start()
for able_to_read, task in frame_provider:
if not able_to_read:
break
if task is None:
time.sleep(0.02)
continue
num_task += 1
model.put(task)
try:
task = model.get()
num_task -= 1
yield task
except IndexError:
continue
while num_task != 0:
try:
task = model.get()
num_task -= 1
yield task
except IndexError:
co
```
<Overlap Ratio: 0.9911764705882353>

---

--- 346 --
Question ID: a447bf1ee450b2312b15331c0e994fd894e68be9_1
Original Code:
```
def get_data(subset):
    # something that yields [[SHAPE, SHAPE, CHANNELS], [1]]
    ds = FakeData([[SHAPE, SHAPE, CHANNELS], [1]], 1000, random=False,
                  dtype=['float32', 'uint8'], domain=[(0, 255), (0, 10)])
    ds = PrefetchDataZMQ(ds, 2)
    ds = BatchData(ds, BATCH_SIZE)
    return ds
```


Overlapping Code:
```
def get_data(subset):
# something that yields [[SHAPE, SHAPE, CHANNELS], [1]]
ds = FakeData([[SHAPE, SHAPE, CHANNELS], [1]], 1000, random=False,
dtype=['float32', 'uint8'], domain=[(0, 255), (0, 10)])
ds = PrefetchDataZMQ(ds, 2)
ds = BatchData(ds, BATCH_SIZE)

```
<Overlap Ratio: 0.966542750929368>

---

--- 347 --
Question ID: ac81e12f856586081d738f3e2858299fe94b6c30_70
Original Code:
```
def lisp_close_socket ( sock , internal_name ) :
 sock . close ( )
 if ( os . path . exists ( internal_name ) ) : os . system ( "rm " + internal_name )
 return
 if 64 - 64: i1IIi / OoO0O00
 if 68 - 68: I11i * O0 * oO0o + OoOoOO00 / IiII
 if 42 - 42: iIii1I11I1II1 % i1IIi - OoOoOO00 % I1ii11iIi11i * Ii1I + i11iIiiIii
 if 40 - 40: OOooOOo
 if 30 - 30: o0oOOo0O0Ooo - Oo0Ooo + iII111i / O0
 if 94 - 94: IiII
 if 69 - 69: I1Ii111 . I1Ii111
 if 53 - 53: i11iIiiIii + iII111i * Oo0Ooo - I1Ii111
```


Overlapping Code:
```
f lisp_close_socket ( sock , internal_name ) :
sock . close ( )
if ( os . path . exists ( internal_name ) ) : os . system ( "rm " + internal_name )
return
if 64 - 64: i1IIi / OoO0O00
if 68 - 68: I11i * O0 * oO0o + OoOoOO00 / IiII
if 42 - 42: iIii1I11I1II1 % i1IIi - OoOoOO00 % I1ii11iIi11i * Ii1I + i11iIiiIii
if 40 - 40: OOooOOo
if 30 - 30: o0oOOo0O0Ooo - Oo0Ooo + iII111i / O0
if 94 - 94: IiII
if 69 - 69: I1Ii111 . I1Ii111
if 53 - 53: i11iIiiIii + iII111i * Oo0
```
<Overlap Ratio: 0.9686847599164927>

---

--- 348 --
Question ID: 4a9b46d66378f5fe1cb4b07da4884761faa854f9_1
Original Code:
```
def save_adata_json(adata, schema, output_directory):
    logger.info('Save adata')
    os.makedirs(output_directory, exist_ok=True)
    with open(os.path.join(output_directory, 'schema.json'), 'wt') as f:
        # json.dump(result, f)
        f.write(ujson.dumps(schema, double_precision=2, orient='values'))

    save_adata_X(adata, output_directory)
    save_data_obs(adata, output_directory)
    save_data_obsm(adata, output_directory)
```


Overlapping Code:
```
_adata_json(adata, schema, output_directory):
logger.info('Save adata')
os.makedirs(output_directory, exist_ok=True)
with open(os.path.join(output_directory, 'schema.json'), 'wt') as f:
# json.dump(result, f)
f.write(ujson.dumps(schema, double_precision=2, orient='values'))
save_adata_X(adata, output_directory)
save_data_obs(adata, output_directory
```
<Overlap Ratio: 0.8771929824561403>

---

--- 349 --
Question ID: 62c05c106a7b4220e421a5e8dbd4ee6ac90c3b40_1
Original Code:
```
def generate_ionstats_basecaller(
    unmapped_bam_filenames, ionstats_basecaller_filename, library_key, histogram_length
):

    com = generate_ionstats_basecaller_cmd(
        unmapped_bam_filenames,
        ionstats_basecaller_filename,
        library_key,
        histogram_length,
    )
    try:
        printtime("DEBUG: Calling '%s'" % com)
        subprocess.call(com, shell=True)
    except Exception:
        printtime("Failed ionstats basecaller")
        traceback.print_exc()
```


Overlapping Code:
```
r(
unmapped_bam_filenames, ionstats_basecaller_filename, library_key, histogram_length
):
com = generate_ionstats_basecaller_cmd(
unmapped_bam_filenames,
ionstats_basecaller_filename,
library_key,
histogram_length,
)
try:
printtime("DEBUG: Calling '%s'" % com)
subprocess.call(com, shell=True)
except Exception:
printtime("Failed ionstats basecaller"
```
<Overlap Ratio: 0.8663366336633663>

---

--- 350 --
Question ID: 352ab39ca3d85482307e29526b91c57912e4a1ac_1
Original Code:
```
def inspect_list(report, terse=None, header=None):
    """Implements method ``buildtest inspect list``"""

    test_ids = report.get_ids()

    table = {"name": [], "id": []}

    # print output in terse format
    if terse:
        # print column headers if --no-header is not specified
        if not header:
            print("|".join(table.keys()))

        for uid, name in test_ids.items():
            print(f"{uid}|{name}")
        return

    for identifier, name in test_ids.items():
        table["name"].append(name)
        table["id"].append(identifier)

    if os.getenv("BUILDTEST_COLOR") == "True":
        print(
            tabulate(
                table,
                headers=[
                    colored(field, "blue", attrs=["bold"]) for field in table.keys()
                ],
                tablefmt="grid",
            )
        )
        return
    print(tabulate(table, headers=table.keys(), tablefmt="grid"))
```


Overlapping Code:
```
ef inspect_list(report, terse=None, header=None):
"""Implements method ``buildtest inspect list``"""
test_ids = report.get_ids()
table = {"name": [], "id": []}
# print output in terse format
if terse:
# print column headers if --no-header is not specified
if not header:
print("|".join(table.keys()))
for uid, name in test_ids.items():
print(f"{uid}|{name}")
return
for identifier, name in test_ids.items():
table["name"].append(name)
table["id"].append(identifier)
if os.getenv("BUILDTEST_COLOR") == "True":
print(
tabulate(
table,
headers=[
colored(field, "blue", attrs=["bold"]) for field in table.keys()
],
tablefmt="grid",
)
)
return
print(tabulate(table, headers=table.keys(), tablefmt="grid"))
```
<Overlap Ratio: 0.9985734664764622>

---

--- 351 --
Question ID: f147fe2ce8778eb046f933fca8c16491d9307826_1
Original Code:
```
def create_actor(cfg: dict) -> BaseActor:
    import_module(cfg.actor.import_names)
    if cfg.actor.actor_type not in actor_mapping.keys():
        raise KeyError("not support actor type: {}".format(cfg.actor.actor_type))
    else:
        return actor_mapping[cfg.actor.actor_type](cfg)
```


Overlapping Code:
```
t) -> BaseActor:
import_module(cfg.actor.import_names)
if cfg.actor.actor_type not in actor_mapping.keys():
raise KeyError("not support actor type: {}".format(cfg.actor.actor_type))
else:
return actor
```
<Overlap Ratio: 0.7692307692307693>

---

--- 352 --
Question ID: 34492ccf6d8eb8df4f400edd6f8c5fd4455ea9a6_5
Original Code:
```
def prepare_dataloaders(data, opt):
    train_loader = torch.utils.data.DataLoader(
        TedDataset(
            src_word2idx=data['dict'],
            src_insts=data['train']['src'],
            tgt_insts=data['train']['tgt']
            ),
            num_workers=opt.n_workers,
            batch_size=opt.batch_size,
            collate_fn=partial(collate_fn, opt=opt),
            shuffle=True)

    valid_loader = torch.utils.data.DataLoader(
        TedDataset(
            src_word2idx=data['dict'],
            src_insts=data['valid']['src'],
            tgt_insts=data['valid']['tgt']
            ),
            num_workers=opt.n_workers,
            batch_size=opt.batch_size,
            collate_fn=partial(collate_fn, opt=opt))

    return train_loader, valid_loader
```


Overlapping Code:
```
(data, opt):
train_loader = torch.utils.data.DataLoader(
TedDataset(
src_word2idx=data['dict'],
src_insts=data['train']['src'],
tgt_insts=data['train']['tgt']
),
num_workers=opt.n_workers,
batch_size=opt.batch_size,
collate_fn=partial(collate_fn, opt=opt),
shuffle=True)
valid_loader = torch.utils.data.DataLoader(
TedDataset(
src_word2idx=data['dict'],
src_insts=data['valid']['src'],
tgt_insts=data['valid']['tgt']
),
num_workers=opt.n_workers,
batch_size=opt.batch_size,
collate_fn=partial(collate_fn, opt
```
<Overlap Ratio: 0.8896672504378283>

---

--- 353 --
Question ID: b107d2de721ccfeffa46f77baa875d6b1dec2eb9_0
Original Code:
```
def main():

    parser = argparse.ArgumentParser(description='Convert DEM to OBJ format tri mesh')
    parser.add_argument("-i", "--input", nargs=1, help="filename of a GDAL-supported raster format DEM", required=True)
    parser.add_argument("-o", "--output", nargs=1, help="filename to write to", required=True)
    parser.add_argument("-x", "--exaggeration", type=float, nargs=1, help="vertical exaggeration (default 1.0)", required=False)
    parser.add_argument("-s", "--scaling", type=float, nargs=1, help="global scaling (default 0.001)", required=False)
    parser.add_argument("-v", "--verbose", action='store_true', help="verbose (show progress & scary messages)", required=False)
    parser.add_argument("-w", "--wgs84", action='store_true',  help="wgs84 settings (x,y in degrees, elevation in meters", required=False)
    parser.add_argument("-j", "--jitter", action='store_true', help="add jitter (small random offset to x and y)", required=False)

    scale = 1.0
    exaggeration = 1.0
    jitter = False

    arguments = parser.parse_args()
    filename = arguments.input[0]
    filename_out = arguments.output[0]
    if arguments.jitter:
        jitter = True
    if arguments.scaling:
        scale = arguments.scaling[0]
    if arguments.exaggeration:
        exaggeration = arguments.exaggeration[0]
    verbose = arguments.verbose
    wgs84 = arguments.wgs84

    if verbose:
        logging.basicConfig(format='%(asctime)s %(message)s', level=logging.DEBUG, datefmt='%m/%d/%Y %I:%M:%S %p')
    else:
        logging.basicConfig(format='%(asctime)s %(message)s', level=logging.INFO, datefmt='%m/%d/%Y %I:%M:%S %p')

    if wgs84:
        scale = 1.0
        exaggeration = scale/110000.0
        logging.info("Using WGS84 mode (scale={:.2f}, axeggeration={:.8f}".format(scale, exaggeration))

    reader = RasterReader()
    metadata = reader.get_metadata(filename)
    size = (metadata["width"], metadata["height"])
    logging.info("Image size is {}".format(size))
    obj_maker = ObjBuilder(size)
    mid_x, mid_y = (metadata["center_x"], metadata["center_y"])
    logging.info("Mid point at {},{}".format(mid_x, mid_y))

    logging.info("Scanning raster for xyz values...")
    points = 0

    dx = 0.25 * metadata["size_x"]
    dy = 0.25 * metadata["size_y"]

    for x, y, z in reader.load_raster_xyz(filename):
        if not jitter:
            obj_maker.add_vertex(((x-mid_x)*scale, (y-mid_y)*scale, z*scale*exaggeration))
        else:
            x_offset = random.uniform(-dx, dx)
            y_offset = random.uniform(-dy, dy)
            obj_maker.add_vertex(((x - mid_x + x_offset) * scale, (y - mid_y + y_offset) * scale, z * scale * exaggeration))
        points += 1
        if points % 10000 == 0:
            percent = (points/(size[0]*size[1]))*100.0
            logging.debug("Added {} vertices ({:.2f}%)".format(points, percent))
    logging.info("Writing OBJ file...")
    obj_maker.write_file(filename_out)
    logging.info("OBJ file written")
```


Overlapping Code:
```
def main():
parser = argparse.ArgumentParser(description='Convert DEM to OBJ format tri mesh')
parser.add_argument("-i", "--input", nargs=1, help="filename of a GDAL-supported raster format DEM", required=True)
parser.add_argument("-o", "--output", nargs=1, help="filename to write to", required=True)
parser.add_argument("-x", "--exaggeration", type=float, nargs=1, help="vertical exaggeration (default 1.0)", required=False)
parser.add_argument("-s", "--scaling", type=float, nargs=1, help="global scaling (default 0.001)", required=False)
parser.add_argument("-v", "--verbose", action='store_true', help="verbose (show progress & scary messages)", required=False)
parser.add_argument("-w", "--wgs84", action='store_true', help="wgs84 settings (x,y in degrees, elevation in meters", required=False)
parser.add_argument("-j", "--jitter", action='store_true', help="add jitter (small random offset to x and y)", required=False)
scale = 1.0
exaggeration = 1.0
jitter = False
arguments = parser.parse_args()
filename = arguments.input[0]
filename_out = arguments.output[0]
if arguments.jitter:
jitter = True
if arguments.scaling:
scale = arguments.scaling[0]
if arguments.exaggeration:
exaggeration = arguments.exaggeration[0]
verbose = arguments.verbose
wgs84 = arguments.wgs84
if verbose:
logging.basicConfig(format='%(asctime)s %(message)s', level=logging.DEBUG, datefmt='%m/%d/%Y %I:%M:%S %p')
else:
logging.basicConfig(format='%(asctime)s %(message)s', level=logging.INFO, datefmt='%m/%d/%Y %I:%M:%S %p')
if wgs84:
scale = 1.0
exaggeration = scale/110000.0
logging.info("Using WGS84 mode (scale={:.2f}, axeggeration={:.8f}".format(scale, exaggeration))
reader = RasterReader()
metadata = reader.get_metadata(filename)
size = (metadata["width"], metadata["height"])
logging.info("Image size is {}".format(size))
obj_maker = ObjBuilder(size)
mid_x, mid_y = (metadata["center_x"], metadata["center_y"])
logging.info("Mid point at {},{}".format(mid_x, mid_y))
logging.info("Scanning raster for xyz values...")
points = 0
dx = 0.25 * metadata["size_x"]
dy = 0.25 * metadata["size_y"]
for x, y, z in reader.load_raster_xyz(filename):
if not jitter:
obj_maker.add_vertex(((x-mid_x)*scale, (y-mid_y)*scale, z*scale*exaggeration))
else:
x_off
```
<Overlap Ratio: 0.9942196531791907>

---

--- 354 --
Question ID: c55a06a4a9e4cd06ad98ec382a568e6b037654e6_0
Original Code:
```
@pytest.mark.parametrize('test_input,migrate', [
    ('IPv6:::1\n', True),
    ('IPv6:0:0:0:0:0:0:0:1\n', False),
])
def test_check_migration(tmpdir, monkeypatch, test_input, migrate):
    test_cfg_path = text_type(tmpdir)
    test_cfg_file = os.path.join(test_cfg_path, 'sendmail.cf')
    with open(test_cfg_file, 'w') as file_out:
        file_out.write(test_input)
    monkeypatch.setattr(checksendmail, 'SendmailConfDir', test_cfg_path)
    files = checksendmail.check_files_for_compressed_ipv6()
    if migrate:
        assert files == [test_cfg_file]
    else:
        assert files == []
```


Overlapping Code:
```
ytest.mark.parametrize('test_input,migrate', [
('IPv6:::1\n', True),
('IPv6:0:0:0:0:0:0:0:1\n', False),
])
def test_check_migration(tmpdir, monkeypatch, test_input, migrate):
test_cfg_path = text_type(tmpdir)
test_cfg_file = os.path.join(test_cfg_path, 'sendmail.cf')
with open(test_cfg_file, 'w') as file_out:
file_out.write(test_input)
monkeypatch.setattr(checksendmail, 'SendmailConfDir', test_cfg_path)
files = checksendmail.check_files_for_compressed_ipv6()
if migrate:
assert files == [test_cfg
```
<Overlap Ratio: 0.9380863039399625>

---

--- 355 --
Question ID: a2d49ebfc04c520a45f79375100a44409a55e260_6
Original Code:
```
def compute_fairseq(ref_file, hyp_file, output_file):
    # Get generate-tests
    generate_test_path = os.path.join(os.path.dirname(hyp_file), "generate-test.txt")
    if os.path.exists(generate_test_path):
        # Read, parse and save lines
        lines = [utils.read_file_lines(generate_test_path, autoclean=True)[-1]]
        utils.write_file_lines(lines=lines, filename=output_file, insert_break_line=True)
    else:
        print("\t- [INFO]: No 'generate-test.txt' was found.")
```


Overlapping Code:
```
def compute_fairseq(ref_file, hyp_file, output_file):
# Get generate-tests
generate_test_path = os.path.join(os.path.dirname(hyp_file), "generate-test.txt")
if os.path.exists(generate_test_path):
# Read, parse and save lines
lines = [utils.read_file_lines(generate_test_path, autoclean=True)[-1]]
utils.write_file_lines(lines=lines, filename=output_file, insert_break_line=True)
else:
print("\t- [INFO]: No 'generate-test.txt' was
```
<Overlap Ratio: 0.979498861047836>

---

--- 356 --
Question ID: b8b73599affe70caf337aa01207aa7e753e94c1f_0
Original Code:
```
def sketch(image):
    # Convert image to gray scale
    img_gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)

    # Clean up image using Gaussian Blur
    img_gray_blur = cv.GaussianBlur(img_gray, (5, 5), 0)

    # Extract Edges
    canny_edges = cv.Canny(img_gray_blur, 30, 70)

    # Do an invert binarize the image
    ret, mask = cv.threshold(canny_edges, 120, 255, cv.THRESH_BINARY_INV)

    return mask
```


Overlapping Code:
```
(image):
# Convert image to gray scale
img_gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)
# Clean up image using Gaussian Blur
img_gray_blur = cv.GaussianBlur(img_gray, (5, 5), 0)
# Extract Edges
canny_edges = cv.Canny(img_gray_blur, 30, 70)
# Do an invert binarize the image
ret, mask = cv.threshold(canny_edges, 120, 255, cv.THRESH_BINARY_INV)
return
```
<Overlap Ratio: 0.958904109589041>

---

--- 357 --
Question ID: 4b89517d38a090a0880bc09b2ac0cea4be3c964a_5
Original Code:
```
def main():
    annotPath = r'.\res\PennFudanPed\Annotation'
    imgPath = r'.\res\PennFudanPed\PNGImages'
    dst = r'.\res\PennFudanPed\Label'
    if len(sys.argv)==2:
        imgPath = sys.argv[1]
    elif len(sys.argv)==3:
        imgPath = sys.argv[1]
        dst = sys.argv[2]
    print('imagePath=',imgPath)
    print('dst=',dst)
        
    generateImageLabel(imgPath,annotPath,dst)
    '''
    deleteFolder(dst)
    createPath(dst)
    for i in listFile(imgPath,'png'):
        H,W = getImgHW(loadImg(i))
        #print(H,W)
        fAnnot = getImgAnnotFile(annotPath,i)
        fAnnotName = getFileName(fAnnot)
        dstFile = dst+ '\\' +  fAnnotName
        print('fAnnot=', fAnnot)
        print('dstFile=', dstFile)
        
        deleteFile(dstFile)
        
        coordinates = getFileCoordinates(fAnnot)
        writeToAnnotFile(H,W,dstFile,coordinates)
    '''
```


Overlapping Code:
```
ath = r'.\res\PennFudanPed\Annotation'
imgPath = r'.\res\PennFudanPed\PNGImages'
dst = r'.\res\PennFudanPed\Label'
if len(sys.argv)==2:
imgPath = sys.argv[1]
elif len(sys.argv)==3:
imgPath = sys.argv[1]
dst = sys.argv[2]
print('imagePath=',imgPath)
print('dst=',dst)

generateImageLabel(imgPath,annotPath,dst)
'''
deleteFolder(dst)
createPath(dst)
for i in listFile(imgPath,'png'):
H,W = getImgHW(loadImg(i))
#print(H,W)
fAnnot = getImgAnnotFile(annotPath,i)
fAnnotName = getFileName(fAnnot)
dstFile = dst+ '\\' + fAnnotName
print('fAnnot=', fAnnot)
print('dstFile=', dstFile)

deleteFile(dstFile)

coordinates = getFileCoordinates(fAnnot)
writeToAnno
```
<Overlap Ratio: 0.9260312944523471>

---

--- 358 --
Question ID: 6ee4a7a1bf37d799738f456c5c942a298c4d124b_7
Original Code:
```
def test_dereference_as_vmethod_using_known_methods_x(mock_indexed_resource):
    resource = Resource(
        id="did:example:123#did-communication",
        service_endpoint="did:example:123",
        type="did-communication",
    )
    test = mock_indexed_resource(resource)
    with pytest.raises(ValueError):
        test.dereference_as(KnownVerificationMethods, "test")
```


Overlapping Code:
```
nce_as_vmethod_using_known_methods_x(mock_indexed_resource):
resource = Resource(
id="did:example:123#did-communication",
service_endpoint="did:example:123",
type="did-communication",
)
test = mock_indexed_resource(resource)
with pytest.raises(ValueError):
test.dereference_as(KnownVerificationMethods, "test"
```
<Overlap Ratio: 0.944954128440367>

---

--- 359 --
Question ID: 74494d5bd7009eefa8bef398eb0fa6085ce734cc_3
Original Code:
```
def test_ngram_first_word_match():
    """
    Test that a first word match is not enough to match.
    """
    c = load_from_file(fixture_location('long.conll'))
    it = find_ngrams(c, 'un cabinet'.split())

    with pytest.raises(StopIteration):
        next(it)
```


Overlapping Code:
```
():
"""
Test that a first word match is not enough to match.
"""
c = load_from_file(fixture_location('long.conll'))
it = find_ngrams(c, 'un cabinet'.split())
with pytest.raises(StopIteration):
next(it
```
<Overlap Ratio: 0.8620689655172413>

---

--- 360 --
Question ID: 69bef9cec9270b99d230d6e3ac4423b2de4d63ed_0
Original Code:
```
def penalize_repetition(next_token_logits, sampled_token_sequences, repetition_penalty):
    """repetition penalty from CTRL paper (https://arxiv.org/abs/1909.05858)"""
    #TODO: Fix bug in this function
    if repetition_penalty != 1.0:
        for i in range(next_token_logits.shape[0]):
            for previous_token in set(sampled_token_sequences[i]):
                # if score < 0 then repetition penalty has to be multiplied to reduce the previous
                # token probability
                if next_token_logits[i, previous_token] < 0:
                    next_token_logits[i, previous_token] *= repetition_penalty
                else:
                    next_token_logits[i, previous_token] /= repetition_penalty
    return next_token_logits
```


Overlapping Code:
```
_token_logits, sampled_token_sequences, repetition_penalty):
"""repetition penalty from CTRL paper (https://arxiv.org/abs/1909.05858)"""
#TODO: Fix bug in this function
if repetition_penalty != 1.0:
for i in range(next_token_logits.shape[0]):
for previous_token in set(sampled_token_sequences[i]):
# if score < 0 then repetition penalty has to be multiplied to reduce the previous
# token probability
if next_token_logits[i, previous_token] < 0:
next_token_logits[i, previous_token] *= repetition_penalty
else:
next_token_logits[i, previous_token] /= rep
```
<Overlap Ratio: 0.8906752411575563>

---

--- 361 --
Question ID: 462b3496b8740b44a6ccafdec9fa5da42fa91f0d_3
Original Code:
```
def is_version_in_range(v, min_version, max_version):
    fmin = flatten_version(min_version)
    fmax = flatten_version(max_version)
    f = flatten_version(v)
    #print("testing ", v, ", as ", f)
    return f >= fmin and f <= fmax
```


Overlapping Code:
```
ersion_in_range(v, min_version, max_version):
fmin = flatten_version(min_version)
fmax = flatten_version(max_version)
f = flatten_version(v)
#print("testing ", v, ", as ", f)
return f >= fmin and f <=
```
<Overlap Ratio: 0.9389671361502347>

---

--- 362 --
Question ID: 640a2884cf23cb7d454440c26836b2a01294ac62_0
Original Code:
```
def load_strains(db): 
  logger.info('Loading strains...')
  andersen_strains = fetch_andersen_strains()
  db.session.bulk_insert_mappings(Strain, andersen_strains)
  db.session.commit()
  logger.info(f"Inserted {Strain.query.count()} strains")
```


Overlapping Code:
```
er.info('Loading strains...')
andersen_strains = fetch_andersen_strains()
db.session.bulk_insert_mappings(Strain, andersen_strains)
db.session.commit()
logger.info(f"Inserted {Strain.query.count()} st
```
<Overlap Ratio: 0.8547008547008547>

---

--- 363 --
Question ID: cf3a71a276988b7eff40f4617414c23a9c5cb292_71
Original Code:
```
def get_bounds(geometry, north_up=True, transform=None):
    """Bounding box of a GeoJSON geometry, GeometryCollection, or FeatureCollection.
    left, bottom, right, top
    *not* xmin, ymin, xmax, ymax
    If not north_up, y will be switched to guarantee the above.
    Source code adapted from https://github.com/mapbox/rasterio/blob/master/rasterio/features.py#L361
    """

    if 'bbox' in geometry:
        return tuple(geometry['bbox'])

    geometry = geometry.get('geometry') or geometry  

    # geometry must be a geometry, GeometryCollection, or FeatureCollection
    if not ('coordinates' in geometry or 'geometries' in geometry or 'features' in geometry):
        raise ValueError(
            "geometry must be a GeoJSON-like geometry, GeometryCollection, "
            "or FeatureCollection"
        )

    if 'features' in geometry:
        # Input is a FeatureCollection
        xmins = []
        ymins = []
        xmaxs = []
        ymaxs = []
        for feature in geometry['features']:
            xmin, ymin, xmax, ymax = get_bounds(feature['geometry'])
            xmins.append(xmin)
            ymins.append(ymin)
            xmaxs.append(xmax)
            ymaxs.append(ymax)
        if north_up:
            return min(xmins), min(ymins), max(xmaxs), max(ymaxs)
        else:
            return min(xmins), max(ymaxs), max(xmaxs), min(ymins)

    elif 'geometries' in geometry:
        # Input is a geometry collection
        xmins = []
        ymins = []
        xmaxs = []
        ymaxs = []
        for geometry in geometry['geometries']:
            xmin, ymin, xmax, ymax = get_bounds(geometry)
            xmins.append(xmin)
            ymins.append(ymin)
            xmaxs.append(xmax)
            ymaxs.append(ymax)
        if north_up:
            return min(xmins), min(ymins), max(xmaxs), max(ymaxs)
        else:
            return min(xmins), max(ymaxs), max(xmaxs), min(ymins)

    elif 'coordinates' in geometry:
        # Input is a singular geometry object
        if transform is not None:
            xyz = list(explode(geometry['coordinates']))
            xyz_px = [transform * point for point in xyz]
            xyz = tuple(zip(*xyz_px))
            return min(xyz[0]), max(xyz[1]), max(xyz[0]), min(xyz[1])
        else:
            xyz = tuple(zip(*list(explode(geometry['coordinates']))))
            if north_up:
                return min(xyz[0]), min(xyz[1]), max(xyz[0]), max(xyz[1])
            else:
                return min(xyz[0]), max(xyz[1]), max(xyz[0]), min(xyz[1])

    # all valid inputs returned above, so whatever falls through is an error
    raise ValueError(
            "geometry must be a GeoJSON-like geometry, GeometryCollection, "
            "or FeatureCollection"
        )
```


Overlapping Code:
```
eometry, north_up=True, transform=None):
"""Bounding box of a GeoJSON geometry, GeometryCollection, or FeatureCollection.
left, bottom, right, top
*not* xmin, ymin, xmax, ymax
If not north_up, y will be switched to guarantee the above.
Source code adapted from https://github.com/mapbox/rasterio/blob/master/rasterio/features.py#L361
"""
if 'bbox' in geometry:
return tuple(geometry['bbox'])
geometry = geometry.get('geometry') or geometry 
# geometry must be a geometry, GeometryCollection, or FeatureCollection
if not ('coordinates' in geometry or 'geometries' in geometry or 'features' in geometry):
raise ValueError(
"geometry must be a GeoJSON-like geometry, GeometryCollection, "
"or FeatureCollection"
)
if 'features' in geometry:
# Input is a FeatureCollection
xmins = []
ymins = []
xmaxs = []
ymaxs = []
for feature in geometry['features']:
xmin, ymin, xmax, ymax = get_bounds(feature['geometry'])
xmins.append(xmin)
ymins.append(ymin)
xmaxs.append(xmax)
ymaxs.append(ymax)
if north_up:
return min(xmins), min(ymins), max(xmaxs), max(ymaxs)
else:
return min(xmins), max(ymaxs), max(xmaxs), min(ymins)
elif 'geometries' in geometry:
# Input is a geometry collection
xmins = []
ymins = []
xmaxs = []
ymaxs = []
for geometry in geometry['geometries']:
xmin, ymin, xmax, ymax = get_bounds(geometry)
xmins.append(xmin)
ymins.append(ymin)
xmaxs.append(xmax)
ymaxs.append(ymax)
if north_up:
return min(xmins), min(ymins), max(xmaxs), max(ymaxs)
else:
return min(xmins), max(ymaxs), max(xmaxs), min(ymins)
elif 'coordinates' in geometry:
# Input is a singular geometry object
if transform is not None:
xyz = list(explode(geometry['coordinates']))
xyz_px = [transform * point for point in xyz]
xyz = tuple(zip(*xyz_px))
return min(xyz[0]), max(xyz[1]), max(xyz[0]), min(xyz[1])
else:
xyz = tuple(zip(*list(explode(geometry['coordinates']))))
if north_up:
return min(xyz[0]), min(xyz[1]), max(xyz[0]), max(xyz[1])
```
<Overlap Ratio: 0.9775051124744376>

---

--- 364 --
Question ID: 85f14149a4c507ac9aed029bb9abf76e6e40b575_3
Original Code:
```
def pybind11_get_include():
    """Get pybind11 include paths if it's installed as a Python package."""
    try:
        import pybind11
        try:
            return [pybind11.get_include(True), pybind11.get_include(False)]
        except AttributeError:
            return []
    except ImportError:
        return []
```


Overlapping Code:
```
 include paths if it's installed as a Python package."""
try:
import pybind11
try:
return [pybind11.get_include(True), pybind11.get_include(False)]
except AttributeError:
return []
except ImportError:
```
<Overlap Ratio: 0.7905138339920948>

---

--- 365 --
Question ID: 7f85061713c663e6a4dccde0e1ed24d18277597a_0
Original Code:
```
def common_options():
    """Collects & returns options shared by all module implementations
    :return: dict
    """
    # Just API params for now
    return API_CONFIG
```


Overlapping Code:
```
ns():
"""Collects & returns options shared by all module implementations
:return: dict
"""
# Just AP
```
<Overlap Ratio: 0.6666666666666666>

---

--- 366 --
Question ID: 62466fb0cd5a3d0a4c3396d9d64dfc18c359c381_1
Original Code:
```
def _f_fit_ ( func , histo , *args ) :
    """Fit histogram (Actually delegate to TH1::Fit method)
    >>> func  = ...
    >>> histo = ...
    >>> func.Fit ( histo , .... )
    """
    return histo.Fit( func , *args )
```


Overlapping Code:
```
Fit histogram (Actually delegate to TH1::Fit method)
>>> func = ...
>>> histo = ...
>>> func.Fit ( histo , .... )
"""
return histo.Fit( func , *args )
```
<Overlap Ratio: 0.78125>

---

--- 367 --
Question ID: 44c50dded00c553f091bf66142e1117deaf0d6f7_30
Original Code:
```
def _build_mFIZ_tab(parent_layout):
    mFIZ_tab_layout = pm.columnLayout('mFIZTab',
                                       adj=True,
                                       width=100)

    _build_add_mFIZ_node_frame(mFIZ_tab_layout)

    pm.setParent(parent_layout)
    return mFIZ_tab_layout
```


Overlapping Code:
```
yout):
mFIZ_tab_layout = pm.columnLayout('mFIZTab',
adj=True,
width=100)
_build_add_mFIZ_node_frame(mFIZ_tab_layout)
pm.setParent(parent_layout)
retur
```
<Overlap Ratio: 0.7653061224489796>

---

--- 368 --
Question ID: b2e59251331de614416c333e4dce8ecc6593f543_2
Original Code:
```
def _create_pyramid(video, pyramid_levels, pyramid_fn):
    vid_pyramid = []
    # frame_count, height, width, colors = video.shape
    for frame_number, frame in enumerate(video):
        frame_pyramid = pyramid_fn(frame, pyramid_levels)

        for pyramid_level, pyramid_sub_frame in enumerate(frame_pyramid):
            if frame_number == 0:
                vid_pyramid.append(
                    numpy.zeros((video.shape[0], pyramid_sub_frame.shape[0], pyramid_sub_frame.shape[1], 3),
                                dtype="float"))

            vid_pyramid[pyramid_level][frame_number] = pyramid_sub_frame

    return vid_pyramid
```


Overlapping Code:
```
yramid(video, pyramid_levels, pyramid_fn):
vid_pyramid = []
# frame_count, height, width, colors = video.shape
for frame_number, frame in enumerate(video):
frame_pyramid = pyramid_fn(frame, pyramid_levels)
for pyramid_level, pyramid_sub_frame in enumerate(frame_pyramid):
if frame_number == 0:
vid_pyramid.append(
numpy.zeros((video.shape[0], pyramid_sub_frame.shape[0], pyramid_sub_frame.shape[1], 3),
dtype="float"))
vid_pyramid[pyramid_level][fram
```
<Overlap Ratio: 0.8806262230919765>

---

--- 369 --
Question ID: 142745156023a2dec6586b6ac306c21912cfd8de_4
Original Code:
```
def tag(tags, api_version=None, ids=None, is_incremental=None, latest_include_preview=None, name=None, namespace=None, parent=None, resource_group=None, resource_type=None):
    '''
    Tag a resource.

    Required Parameters:
    - tags -- space-separated tags: key[=value] [key[=value] ...]. Use '' to clear existing tags.

    Optional Parameters:
    - api_version -- The api version of the resource (omit for the latest stable version)
    - ids -- One or more resource IDs (space-delimited). If provided, no other "Resource Id" arguments should be specified.
    - is_incremental -- The option to add tags incrementally without deleting the original tags. If the key of new tag and original tag are duplicated, the original value will be overwritten.
    - latest_include_preview -- Indicate that the latest api-version will be used regardless of whether it is preview version (like 2020-01-01-preview) or not. For example, if the supported api-version of resource provider is 2020-01-01-preview and 2019-01-01: when passing in this parameter it will take the latest version 2020-01-01-preview, otherwise it will take the latest stable version 2019-01-01 without passing in this parameter
    - name -- The resource name. (Ex: myC)
    - namespace -- Provider namespace (Ex: 'Microsoft.Provider')
    - parent -- The parent path (Ex: 'resA/myA/resB/myB')
    - resource_group -- Name of resource group. You can configure the default group using `az configure --defaults group=<name>`
    - resource_type -- The resource type (Ex: 'resC'). Can also accept namespace/type format (Ex: 'Microsoft.Provider/resC')
    '''
    return _call_az("az resource tag", locals())
```


Overlapping Code:
```
tag(tags, api_version=None, ids=None, is_incremental=None, latest_include_preview=None, name=None, namespace=None, parent=None, resource_group=None, resource_type=None):
'''
Tag a resource.
Required Parameters:
- tags -- space-separated tags: key[=value] [key[=value] ...]. Use '' to clear existing tags.
Optional Parameters:
- api_version -- The api version of the resource (omit for the latest stable version)
- ids -- One or more resource IDs (space-delimited). If provided, no other "Resource Id" arguments should be specified.
- is_incremental -- The option to add tags incrementally without deleting the original tags. If the key of new tag and original tag are duplicated, the original value will be overwritten.
- latest_include_preview -- Indicate that the latest api-version will be used regardless of whether it is preview version (like 2020-01-01-preview) or not. For example, if the supported api-version of resource provider is 2020-01-01-preview and 2019-01-01: when passing in this parameter it will take the latest version 2020-01-01-preview, otherwise it will take the latest stable version 2019-01-01 without passing in this parameter
- name -- The resource name. (Ex: myC)
- namespace -- Provider namespace (Ex: 'Microsoft.Provider')
- parent -- The parent path (Ex: 'resA/myA/resB/myB')
- resource_group -- Name of resource group. You can configure the default group using `az configure --defaults group=<name>`
- resource_type -- The resource type (Ex: 'resC'). Can also accept namespace/type format (Ex: 'Microsoft.Provider/resC')
'''
return _call_az("az resource tag", locals(
```
<Overlap Ratio: 0.9962640099626401>

---

--- 370 --
Question ID: 97bc33429e8de10e703c38622e297136a8a6870b_24
Original Code:
```
def test_validate_pairs(default_conf, mocker):  # test exchange.validate_pairs directly
    api_mock = MagicMock()
    type(api_mock).load_markets = MagicMock(return_value={
        'ETH/BTC': {'quote': 'BTC'},
        'LTC/BTC': {'quote': 'BTC'},
        'XRP/BTC': {'quote': 'BTC'},
        'NEO/BTC': {'quote': 'BTC'},
    })
    id_mock = PropertyMock(return_value='test_exchange')
    type(api_mock).id = id_mock

    mocker.patch('freqtrade.exchange.Exchange._init_ccxt', MagicMock(return_value=api_mock))
    mocker.patch('freqtrade.exchange.Exchange.validate_timeframes')
    mocker.patch('freqtrade.exchange.Exchange._load_async_markets')
    mocker.patch('freqtrade.exchange.Exchange.validate_stakecurrency')
    Exchange(default_conf)
```


Overlapping Code:
```
def test_validate_pairs(default_conf, mocker): # test exchange.validate_pairs directly
api_mock = MagicMock()
type(api_mock).load_markets = MagicMock(return_value={
'ETH/BTC': {'quote': 'BTC'},
'LTC/BTC': {'quote': 'BTC'},
'XRP/BTC': {'quote': 'BTC'},
'NEO/BTC': {'quote': 'BTC'},
})
id_mock = PropertyMock(return_value='test_exchange')
type(api_mock).id = id_mock
mocker.patch('freqtrade.exchange.Exchange._init_ccxt', MagicMock(return_value=api_mock))
mocker.patch('freqtrade.exchange.Exchange.validate_timeframes')
mocker.patch('freqtrade.exchange.Exchange._load_async_markets')
mocker.patch('freqtrade.exchange.Exchange.validate_stakecurrency')
Exchange(default_conf)
```
<Overlap Ratio: 1.0>

---

--- 371 --
Question ID: b90abd4cbd8ae14e472891ad622a88c42d689980_14
Original Code:
```
@given(numeric_arrays, numeric_arrays)
def test_pow_special_cases_two_args_equal__less_2(arg1, arg2):
    """
    Special case test for `__pow__(self, other, /)`:

        -   If `x1_i` is `+0` and `x2_i` is less than `0`, the result is `+infinity`.

    """
    res = arg1.__pow__(arg2)
    mask = logical_and(exactly_equal(arg1, zero(arg1.shape, arg1.dtype)), less(arg2, zero(arg2.shape, arg2.dtype)))
    assert_exactly_equal(res[mask], (infinity(arg1.shape, arg1.dtype))[mask])
```


Overlapping Code:
```
given(numeric_arrays, numeric_arrays)
def test_pow_special_cases_two_args_equal__less_2(arg1, arg2):
"""
Special case test for `__pow__(self, other, /)`:
- If `x1_i` is `+0` and `x2_i` is less than `0`, the result is `+infinity`.
"""
res = arg1.__pow__(arg2)
mask = logical_and(exactly_equal(arg1, zero(arg1.shape, arg1.dtype)), less(arg2, zero(arg2.shape, arg2.dtype)))
assert_exactly_equal(res[mask], (infinity(arg1.shape, arg1.dtype))[mask])
```
<Overlap Ratio: 0.9977528089887641>

---

--- 372 --
Question ID: bf2b77d462fd3190c2d9561fc842f4ec0ac12183_0
Original Code:
```
def parse_args():
    parser = argparse.ArgumentParser(
        description="""Create a Node toolchain by downloading components from
https://nodejs.org and vendor it into the repo. Example:

    ./create_node_toolchain.py --output ./v10.16.0 v10.16.0
""",
        formatter_class=RawTextHelpFormatter,
    )
    parser.add_argument(
        "--output",
        help="If specified, overwrite this directory with the generated DotSlash files.",
    )
    parser.add_argument(
        "--retain-forever",
        action="store_true",
        help="""Store the artifacts in Everstore with indefinite retention.
Only use when you plan to check the result of this script into the repo.
""",
    )
    parser.add_argument(
        "toolchain_version", help="toolchain version, such as 'v10.16.0'"
    )
    return parser.parse_args()
```


Overlapping Code:
```
def parse_args():
parser = argparse.ArgumentParser(
description="""Create a Node toolchain by downloading components from
https://nodejs.org and vendor it into the repo. Example:
./create_node_toolchain.py --output ./v10.16.0 v10.16.0
""",
formatter_class=RawTextHelpFormatter,
)
parser.add_argument(
"--output",
help="If specified, overwrite this directory with the generated DotSlash files.",
)
parser.add_argument(
"--retain-forever",
action="store_true",
help="""Store the artifacts in Everstore with indefinite retention.
Only use when you plan to check the result of this script into the repo.
""",
)
parser.add_argument(
"toolchain_version", help="toolchain version, such as 'v10.16.0'"
)
return parser.parse_args(
```
<Overlap Ratio: 0.9986149584487535>

---

--- 373 --
Question ID: 527688881363ac531808f4c8fa7ed0c84a6eaedc_0
Original Code:
```
def train():
    img_input = tf.placeholder(tf.float32, shape=(FLAGS.batch_size, 16, 112, 112, 3))
    y_target = tf.placeholder(tf.float32, shape=(FLAGS.batch_size,FLAGS.dimension))

    y = model.C3D(img_input, dimensions=FLAGS.dimension,dropout=False,regularizer=True) # not label!

    global_step = tf.Variable(0, trainable=False)

    varlist_weight = []
    varlist_bias = []
    trainable_variables = tf.trainable_variables()
    for var in trainable_variables:
        if 'weight' in var.name:
            varlist_weight.append(var)
        elif 'bias' in var.name:
            varlist_bias.append(var)

    lr_weight = tf.train.exponential_decay(FLAGS.base_lr, global_step, 20000, 0.1,
                                           staircase=True)
    lr_bias = tf.train.exponential_decay(FLAGS.base_lr * 2, global_step, 20000, 0.1,
                                         staircase=True)

    opt_weight = tf.train.MomentumOptimizer(lr_weight, momentum=momentum)
    opt_bias = tf.train.MomentumOptimizer(lr_bias, momentum=momentum)

    mse_loss = tf.reduce_mean(tf.squared_difference(y, y_target))

    weight_decay_loss = tf.add_n(tf.get_collection('weight_decay_loss'))

    loss = mse_loss + weight_decay_loss

    tf.summary.scalar('mse_loss', mse_loss)
    tf.summary.scalar('weight_decay_loss', weight_decay_loss)
    tf.summary.scalar('total_loss', loss)

    grad_weight = opt_weight.compute_gradients(loss, varlist_weight)
    grad_bias = opt_bias.compute_gradients(loss, varlist_bias)
    apply_gradient_op_weight = opt_weight.apply_gradients(grad_weight)
    apply_gradient_op_bias = opt_bias.apply_gradients(grad_bias, global_step=global_step)
    train_op = tf.group(apply_gradient_op_weight, apply_gradient_op_bias)

    saver = tf.train.Saver()
    merged = tf.summary.merge_all()

    rgb_list = 'list/rgb_train_linux.list'
    u_flow_list = 'list/u_flow_train_linux.list'
    v_flow_list = 'list/v_flow_train_linux.list'


    with tf.Session() as sess:
        train_writer = tf.summary.FileWriter('./visual_logs/train', sess.graph)
        init = tf.global_variables_initializer()
        sess.run(init)

        for i in range(FLAGS.max_iter):
            start_time = time.time()

            train_images, train_labels, next_batch_start = input_data.read_all(
                rgb_filename=rgb_list,
                u_flow_filename=u_flow_list,
                v_flow_filename=v_flow_list,
                batch_size=FLAGS.batch_size,
                start_pos=-1,
                shuffle=True,
                cpu_num=FLAGS.cpu_num
            )


            duration = time.time() - start_time
            print('read data time %.3f sec' % (duration))

            summary, loss_value, ce_loss, _, old_weight = sess.run([
                merged, loss, mse_loss, train_op, grad_weight], feed_dict={
                img_input: train_images,
                y_target: train_labels
            })

            if i % (FLAGS.display) == 0:
                print("mse_loss:", ce_loss)
                print("loss:", loss_value)
                train_writer.add_summary(summary, i)
            duration = time.time() - start_time
            print('Step %d: %.3f sec' % (i, duration))


            if i % 1000 == 0:
                saver.save(sess, os.path.join(FLAGS.model_save_path, model_name), global_step=global_step)
```


Overlapping Code:
```
 train():
img_input = tf.placeholder(tf.float32, shape=(FLAGS.batch_size, 16, 112, 112, 3))
y_target = tf.placeholder(tf.float32, shape=(FLAGS.batch_size,FLAGS.dimension))
y = model.C3D(img_input, dimensions=FLAGS.dimension,dropout=False,regularizer=True) # not label!
global_step = tf.Variable(0, trainable=False)
varlist_weight = []
varlist_bias = []
trainable_variables = tf.trainable_variables()
for var in trainable_variables:
if 'weight' in var.name:
varlist_weight.append(var)
elif 'bias' in var.name:
varlist_bias.append(var)
lr_weight = tf.train.exponential_decay(FLAGS.base_lr, global_step, 20000, 0.1,
staircase=True)
lr_bias = tf.train.exponential_decay(FLAGS.base_lr * 2, global_step, 20000, 0.1,
staircase=True)
opt_weight = tf.train.MomentumOptimizer(lr_weight, momentum=momentum)
opt_bias = tf.train.MomentumOptimizer(lr_bias, momentum=momentum)
mse_loss = tf.reduce_mean(tf.squared_difference(y, y_target))
weight_decay_loss = tf.add_n(tf.get_collection('weight_decay_loss'))
loss = mse_loss + weight_decay_loss
tf.summary.scalar('mse_loss', mse_loss)
tf.summary.scalar('weight_decay_loss', weight_decay_loss)
tf.summary.scalar('total_loss', loss)
grad_weight = opt_weight.compute_gradients(loss, varlist_weight)
grad_bias = opt_bias.compute_gradients(loss, varlist_bias)
apply_gradient_op_weight = opt_weight.apply_gradients(grad_weight)
apply_gradient_op_bias = opt_bias.apply_gradients(grad_bias, global_step=global_step)
train_op = tf.group(apply_gradient_op_weight, apply_gradient_op_bias)
saver = tf.train.Saver()
merged = tf.summary.merge_all()
rgb_list = 'list/rgb_train_linux.list'
u_flow_list = 'list/u_flow_train_linux.list'
v_flow_list = 'list/v_flow_train_linux.list'
with tf.Session() as sess:
train_writer = tf.summary.FileWriter('./visual_logs/train', sess.graph)
init = tf.global_variables_initializer()
sess.run(init)
for i in range(FLAGS.max_iter):
start_time = time.time()
train_images, train_labels, next_batch_start = input_data.read_all(
rgb_filename=rgb_list,
u_flow_filename=u_flow_list,
v_flow_filename=v_flow_list,
batch_si
```
<Overlap Ratio: 0.9824144486692015>

---

--- 374 --
Question ID: 91ed15839cd6e88d40d65fba2750b5249cff81c1_0
Original Code:
```
def parse_options():
    """ This parses the CLI arguments and validates the arguments
        Returns:
            the path where the LCT directory is located
    """
    input_path = ""
    
    # read in flags passed in with command line argument
    try:
        opts, args = getopt.getopt(sys.argv[1:], "hf:", "help")
    except getopt.GetoptError as err:
        print(err)
        sys.exit(2)

    # make sure that options which need an argument (namely -f for the input file path) have them
    for opt, arg in opts:
        if opt in ("-h", "--help"):
            print("use -f to specify the directory of LVT dataset")
            sys.exit(2)
        elif opt == "-f": # and len(opts) == 2:
            input_path = arg
        else:
            # only reach here if the the arguments were incorrect
            print("Invalid set of arguments entered. Please refer to -h flag for more information.")
            sys.exit(2)

    return input_path  
```


Overlapping Code:
```
 arguments and validates the arguments
Returns:
the path where the LCT directory is located
"""
input_path = ""

# read in flags passed in with command line argument
try:
opts, args = getopt.getopt(sys.argv[1:], "hf:", "help")
except getopt.GetoptError as err:
print(err)
sys.exit(2)
# make sure that options which need an argument (namely -f for the input file path) have them
for opt, arg in opts:
if opt in ("-h", "--help"):
print("use -f to specify the directory of LVT dataset")
sys.exit(2)
elif opt == "-f": # and len(opts) == 2:
input_path = arg
else:
# only reach here if the the arguments were incorrect
print("Invalid set of arguments entered. Please refer to -h flag for more information."
```
<Overlap Ratio: 0.9032258064516129>

---

--- 375 --
Question ID: 0f1310d9efc0a4298e2fd3feb80cc1468f538147_0
Original Code:
```
def _run(args, subset=None, append=None):
    logging.info("Loading expressions")
    manager = FeatureMatrix.build_manager(args.expression_folder, filters = args.expression_filters, standardize=True, subset=subset)

    logging.info("Saving")
    Utilities.ensure_requisite_folders(args.output)
    manager.save_covariances(args.output, append=append)

    logging.info("Ran.")
```


Overlapping Code:
```
f _run(args, subset=None, append=None):
logging.info("Loading expressions")
manager = FeatureMatrix.build_manager(args.expression_folder, filters = args.expression_filters, standardize=True, subset=subset)
logging.info("Saving")
Utilities.ensure_requisite_folders(args.output)
manager.save_covariances(args.output, append=append)
logging.info("Ran.")
```
<Overlap Ratio: 0.9943181818181818>

---

--- 376 --
Question ID: 63515e40a6b59b2f9111de23a8cf0af9fbe36523_0
Original Code:
```
def statespace(endog, exog=None, order=(0, 0, 0),
               seasonal_order=(0, 0, 0, 0), include_constant=True,
               enforce_stationarity=True, enforce_invertibility=True,
               concentrate_scale=False, start_params=None, fit_kwargs=None):
    """
    Estimate SARIMAX parameters using state space methods.

    Parameters
    ----------
    endog : array_like
        Input time series array.
    order : tuple, optional
        The (p,d,q) order of the model for the number of AR parameters,
        differences, and MA parameters. Default is (0, 0, 0).
    seasonal_order : tuple, optional
        The (P,D,Q,s) order of the seasonal component of the model for the
        AR parameters, differences, MA parameters, and periodicity. Default
        is (0, 0, 0, 0).
    include_constant : bool, optional
        Whether to add a constant term in `exog` if it's not already there.
        The estimate of the constant will then appear as one of the `exog`
        parameters. If `exog` is None, then the constant will represent the
        mean of the process.
    enforce_stationarity : bool, optional
        Whether or not to transform the AR parameters to enforce stationarity
        in the autoregressive component of the model. Default is True.
    enforce_invertibility : bool, optional
        Whether or not to transform the MA parameters to enforce invertibility
        in the moving average component of the model. Default is True.
    concentrate_scale : bool, optional
        Whether or not to concentrate the scale (variance of the error term)
        out of the likelihood. This reduces the number of parameters estimated
        by maximum likelihood by one.
    start_params : array_like, optional
        Initial guess of the solution for the loglikelihood maximization. The
        AR polynomial must be stationary. If `enforce_invertibility=True` the
        MA poylnomial must be invertible. If not provided, default starting
        parameters are computed using the Hannan-Rissanen method.
    fit_kwargs : dict, optional
        Arguments to pass to the state space model's `fit` method.

    Returns
    -------
    parameters : SARIMAXParams object
    other_results : Bunch
        Includes two components, `spec`, containing the `SARIMAXSpecification`
        instance corresponding to the input arguments; and
        `state_space_results`, corresponding to the results from the underlying
        state space model and Kalman filter / smoother.

    Notes
    -----
    The primary reference is [1]_.

    References
    ----------
    .. [1] Durbin, James, and Siem Jan Koopman. 2012.
       Time Series Analysis by State Space Methods: Second Edition.
       Oxford University Press.
    """
    # Handle including the constant (need to do it now so that the constant
    # parameter can be included in the specification as part of `exog`.)
    if include_constant:
        exog = np.ones_like(endog) if exog is None else add_constant(exog)

    # Create the specification
    spec = SARIMAXSpecification(
        endog, exog=exog, order=order, seasonal_order=seasonal_order,
        enforce_stationarity=enforce_stationarity,
        enforce_invertibility=enforce_invertibility,
        concentrate_scale=concentrate_scale)
    endog = spec.endog
    exog = spec.exog
    p = SARIMAXParams(spec=spec)

    # Check start parameters
    if start_params is not None:
        sp = SARIMAXParams(spec=spec)
        sp.params = start_params

        if spec.enforce_stationarity and not sp.is_stationary:
            raise ValueError('Given starting parameters imply a non-stationary'
                             ' AR process with `enforce_stationarity=True`.')

        if spec.enforce_invertibility and not sp.is_invertible:
            raise ValueError('Given starting parameters imply a non-invertible'
                             ' MA process with `enforce_invertibility=True`.')

    # Create and fit the state space model
    mod = SARIMAX(endog, exog=exog, order=spec.order,
                  seasonal_order=spec.seasonal_order,
                  enforce_stationarity=spec.enforce_stationarity,
                  enforce_invertibility=spec.enforce_invertibility,
                  concentrate_scale=spec.concentrate_scale)
    if fit_kwargs is None:
        fit_kwargs = {}
    fit_kwargs.setdefault('disp', 0)
    res_ss = mod.fit(start_params=start_params, **fit_kwargs)

    # Construct results
    p.params = res_ss.params
    res = Bunch({
        'spec': spec,
        'statespace_results': res_ss,
    })

    return p, res
```


Overlapping Code:
```
endog, exog=None, order=(0, 0, 0),
seasonal_order=(0, 0, 0, 0), include_constant=True,
enforce_stationarity=True, enforce_invertibility=True,
concentrate_scale=False, start_params=None, fit_kwargs=None):
"""
Estimate SARIMAX parameters using state space methods.
Parameters
----------
endog : array_like
Input time series array.
order : tuple, optional
The (p,d,q) order of the model for the number of AR parameters,
differences, and MA parameters. Default is (0, 0, 0).
seasonal_order : tuple, optional
The (P,D,Q,s) order of the seasonal component of the model for the
AR parameters, differences, MA parameters, and periodicity. Default
is (0, 0, 0, 0).
include_constant : bool, optional
Whether to add a constant term in `exog` if it's not already there.
The estimate of the constant will then appear as one of the `exog`
parameters. If `exog` is None, then the constant will represent the
mean of the process.
enforce_stationarity : bool, optional
Whether or not to transform the AR parameters to enforce stationarity
in the autoregressive component of the model. Default is True.
enforce_invertibility : bool, optional
Whether or not to transform the MA parameters to enforce invertibility
in the moving average component of the model. Default is True.
concentrate_scale : bool, optional
Whether or not to concentrate the scale (variance of the error term)
out of the likelihood. This reduces the number of parameters estimated
by maximum likelihood by one.
start_params : array_like, optional
Initial guess of the solution for the loglikelihood maximization. The
AR polynomial must be stationary. If `enforce_invertibility=True` the
MA poylnomial must be invertible. If not provided, default starting
parameters are computed using the Hannan-Rissanen method.
fit_kwargs : dict, optional
Arguments to pass to the state space model's `fit` method.
Returns
-------
parameters : SARIMAXParams object
other_results : Bunch
Includes two components, `spec`, containing the `SARIMAXSpecification`
instance corresponding to the input arguments; and
`state_space_results`, corresponding to the results from the underlying
state space model and Kalman fil
```
<Overlap Ratio: 0.9880514705882353>

---

--- 377 --
Question ID: 71ea046df258c106b4c8f2d6daf009537ec7c40c_0
Original Code:
```
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("N", help="Number of complex samples.",
                    type=int)
    parser.add_argument("mod", help="Number of bits per sample.",
                    type=int, choices=[2,4,6,8,10], metavar='Mod')
    parser.add_argument("--snr", help="Signal to noise ratio (dB).",
                    type=float, nargs='?',default = 10, metavar='SNR')
    parser.add_argument("--Nr", help="Number of RX antennas.",
                    type=int, nargs='?',default = 1, metavar='Nr')
    parser.add_argument("--Nt", help="Number of TX antennas.",
                    type=int, nargs='?',default = 1, metavar='Nt')
    parser.add_argument("--txmode", help="Transmission moTX mode. Use multiple antennas for channel diversity or multiple streams.",
                    type=int, nargs='?', choices=[0,1], default = 0, metavar='TX mode')
    args = parser.parse_args()
    N = args.N
    mod = args.mod
    snr = args.snr
    Nr = args.Nr
    Nt = args.Nt
    tx_mode = args.txmode
    N0 = 1/np.power(10,snr/10)

    #if Nt != Nr:
    #    raise ValueError('Currently only Nr=Nt supported.')

    NoS = min(Nr, Nt) # maximum number of possible streams
    H = generateChMatrix(Nr,Nt,Channel.RAND_UNIT_GOOD)
    print('Condition number of the generated channel: '+str(np.linalg.cond(H)))

    # generate the baseband IQ signal
    X = generateIQ(Nt, N, mod, tx_mode)
    #plotConstell(x)

    # Starting with diversity gain
    # NOTE: Replicate same signal on all transmit antennas
    Xin = X#np.asmatrix([x]*Nt)
    Cx = np.var(X)*np.identity(Nt) #all antennas receiving same data
    pltx = plotConstell(Xin)
    plt.title('Transmit signal constellation')


    # Pass through the channel
    Xout = H*Xin

    # Adding white gaussian noise
    # The signal should have unit power. (?)
    Y = awgnChannel(Xout,N0)
    print('Size of received signal (Nr x N): '+str(Y.shape))
    plty = plotConstell(Y)
    plt.title('Received signal constellation')

    # Covariance matrix of noise. Currently assuming uncorrelated across antennas.
    Cz = np.identity(Nr)

    Eq = getEqualizer(H, Cx, Cz, Equalizer.ZF)
    t_Yhat = Eq*Y
    print('Size of Equalized signal (Nt x N): '+str(t_Yhat.shape))

    # NOTE: Following is done assuming all Nt antennas had the same data and RX
    # diversity is being exploited
    # Yhat = np.mean(t_Yhat,0)

    Yhat = t_Yhat
    print('Size of Equalized signal (Nt x N): '+str(Yhat.shape))
    pltyhat = plotConstell(Yhat)
    plt.title('Equalized signal constellation')

    Xrec = mlDetectionIQ(Yhat, mod)
    #plotConstell(Xrec)

    nofsamp_err = getSER(X,Xrec)
    evm = getEVM(X,Yhat,mod)
    print('SER = '+str(nofsamp_err/N/Nt))
    print('EVM = '+str(evm)+' dB')
    #plt.show()
    #sphereDecoder(H, X, Y, mod, 'basic', 4)
    if Nt==1:
        print('Using diversity gain.')
        Ycomb = equalRatioCombine(Y, H)
        Ycomb = maxRatioCombine(Y, H)
        Ycomb = selectRatioCombine(Y, H)
```


Overlapping Code:
```
def main():
parser = argparse.ArgumentParser()
parser.add_argument("N", help="Number of complex samples.",
type=int)
parser.add_argument("mod", help="Number of bits per sample.",
type=int, choices=[2,4,6,8,10], metavar='Mod')
parser.add_argument("--snr", help="Signal to noise ratio (dB).",
type=float, nargs='?',default = 10, metavar='SNR')
parser.add_argument("--Nr", help="Number of RX antennas.",
type=int, nargs='?',default = 1, metavar='Nr')
parser.add_argument("--Nt", help="Number of TX antennas.",
type=int, nargs='?',default = 1, metavar='Nt')
parser.add_argument("--txmode", help="Transmission moTX mode. Use multiple antennas for channel diversity or multiple streams.",
type=int, nargs='?', choices=[0,1], default = 0, metavar='TX mode')
args = parser.parse_args()
N = args.N
mod = args.mod
snr = args.snr
Nr = args.Nr
Nt = args.Nt
tx_mode = args.txmode
N0 = 1/np.power(10,snr/10)
#if Nt != Nr:
# raise ValueError('Currently only Nr=Nt supported.')
NoS = min(Nr, Nt) # maximum number of possible streams
H = generateChMatrix(Nr,Nt,Channel.RAND_UNIT_GOOD)
print('Condition number of the generated channel: '+str(np.linalg.cond(H)))
# generate the baseband IQ signal
X = generateIQ(Nt, N, mod, tx_mode)
#plotConstell(x)
# Starting with diversity gain
# NOTE: Replicate same signal on all transmit antennas
Xin = X#np.asmatrix([x]*Nt)
Cx = np.var(X)*np.identity(Nt) #all antennas receiving same data
pltx = plotConstell(Xin)
plt.title('Transmit signal constellation')
# Pass through the channel
Xout = H*Xin
# Adding white gaussian noise
# The signal should have unit power. (?)
Y = awgnChannel(Xout,N0)
print('Size of received signal (Nr x N): '+str(Y.shape))
plty = plotConstell(Y)
plt.title('Received signal constellation')
# Covariance matrix of noise. Currently assuming uncorrelated across antennas.
Cz = np.identity(Nr)
Eq = getEqualizer(H, Cx, Cz, Equalizer.ZF)
t_Yhat = Eq*Y
print('Size of Equalized signal (Nt x N): '+str(t_Yhat.shape))
# NOTE: Following is done assuming all Nt antennas had the same data and RX
# diversity is being exploited
# Yhat = np.mean(t_Yhat,0)
Yhat = t_Yhat
print('Size of Equalized signal (Nt x N): 
```
<Overlap Ratio: 0.9880349746893695>

---

--- 378 --
Question ID: 28fbfae961021e5d283c9a3c8c8f91cda4973696_4
Original Code:
```
def preprocess_image(img,args):
    """
        Processes image for input
    """
    
    composed_transforms = transforms.Compose([        
        transforms.ToTensor(),
        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))])
    im_as_var = composed_transforms(img)
    im_as_var = Variable(im_as_var.unsqueeze(0)).cuda().requires_grad_()
    return im_as_var
```


Overlapping Code:
```
f preprocess_image(img,args):
"""
Processes image for input
"""

composed_transforms = transforms.Compose([ 
transforms.ToTensor(),
transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))])
im_as_var = composed_transforms(img)
im_as_var = Variable(im_as_var.unsqueeze(0)).cuda().requires_grad_()
return i
```
<Overlap Ratio: 0.9700598802395209>

---

--- 379 --
Question ID: b39c0b56e981e84669201b598a62d33237035acb_16
Original Code:
```
def test_match_view_to_dash():
    content_results = [{'dashboard.id': 1, 'dashboard_element.id': 1, 'dashboard_element.type': 'vis', 'dashboard_element.result_source': 'Lookless', 'query.model': 'bq', 'query.view': 'order_items',
                        'query.formatted_fields': '["order_items.created_month", "order_items.count"]', 'query.id': 59, 'dashboard.title': 'dash_1', 'look.id': None, 'sql_joins': ['`looker-private-demo.ecomm.order_items`']}]
    explore_results = ipe.fetch_view_files(project)
    sql_table_name = sql_table_names
    test = ipe.match_view_to_dash(content_results=content_results,
                                  explore_results=explore_results, sql_table_name=sql_table_name, proj=project)
    assert isinstance(test, list)
    assert len(test[0]) == 6
    assert isinstance(test[0]['fields_used'], str)
    assert test[0]['element_id'] == 1
```


Overlapping Code:
```
s = [{'dashboard.id': 1, 'dashboard_element.id': 1, 'dashboard_element.type': 'vis', 'dashboard_element.result_source': 'Lookless', 'query.model': 'bq', 'query.view': 'order_items',
'query.formatted_fields': '["order_items.created_month", "order_items.count"]', 'query.id': 59, 'dashboard.title': 'dash_1', 'look.id': None, 'sql_joins': ['`looker-private-demo.ecomm.order_items`']}]
explore_results = ipe.fetch_view_files(project)
sql_table_name = sql_table_names
test = ipe.match_view_to_dash(content_results=content_results,
explore_results=explore_results, sql_table_name=sql_table_name, proj=project)
assert isinstance(test, list)
assert len(test[0]) == 6
assert isinstance(test[0]['fields_used']
```
<Overlap Ratio: 0.89171974522293>

---

--- 380 --
Question ID: 0adc66960576bca6324bd7ce27dec57428ef8969_2
Original Code:
```
def compute_power_kernel_params_k(params_k, power):
    '''
    returns dictionary of power kernel parameter
    
    params_k: dictionary for kernel params
    power: power of the kernel to be evaluated must lie in [0.5, 1]; and needs to satisfy other conditions for different kernels 
          based on the discussion of last appendix of https://arxiv.org/pdf/2110.01593.pdf 
    
    '''
    
    params_k_power = dict()
    suffix = "_rt" if power == 0.5 else f"{power}_rt"
    params_k_power["name"]  = params_k["name"] + suffix
    
    d = params_k["d"]
    params_k_power["d"] = params_k["d"]
    
    if "gauss" in params_k["name"]:
        params_k_power["var"] = params_k["var"] * power
        return(params_k_power)
    
    if "sinc" in params_k["name"]:
        params_k_power["var"] = params_k["var"] # the var parameter doesn't change, only the kernel gets scaled; which we don't care for KT
        return(params_k_power)
    
    if "laplace" in params_k["name"]:
        params_k_power["var"] = params_k["var"]
        assert(power> d/(d+1.))
        params_k_power["nu"] = power * (d+1)/2.
        return(params_k_power)
    
    if "matern" in params_k["name"]:
        params_k_power["var"] = params_k["var"]
        nu = params_k["nu"]
        assert(power > d/(2. * nu))
        params_k_power["nu"] = power * nu
        return(params_k_power)
    
    if "imq" in params_k["name"]:  # currently we implement only sqrt imq kernels using eqn 117 from https://arxiv.org/pdf/2105.05842.pdf [our choice is valid for all nu]
        assert(power==0.5)
        params_k_power["var"] = params_k["var"]
        params_k_power["nu"] = d/4 + params_k["nu"]/2.
        return(params_k_power)
        
    if "bspline" in params_k["name"]:  # taken from last appendix of https://arxiv.org/pdf/2110.01593.pdf
        beta = params_k["nu"]
        if beta%2 == 1:
            assert(power == 0.5)
        if beta%2 == 0:
            assert(power== (beta+2)/(2*beta+2))
            params_k_power["var"] = params_k["var"]
            params_k_power["nu"] = int(beta/2)
            assert(params_k_power["nu"] >=0)
        return(params_k_power)

    raise ValueError("Unrecognized kernel name {}".format(params_k["name"]))
```


Overlapping Code:
```
power_kernel_params_k(params_k, power):
'''
returns dictionary of power kernel parameter

params_k: dictionary for kernel params
power: power of the kernel to be evaluated must lie in [0.5, 1]; and needs to satisfy other conditions for different kernels 
based on the discussion of last appendix of https://arxiv.org/pdf/2110.01593.pdf 

'''

params_k_power = dict()
suffix = "_rt" if power == 0.5 else f"{power}_rt"
params_k_power["name"] = params_k["name"] + suffix

d = params_k["d"]
params_k_power["d"] = params_k["d"]

if "gauss" in params_k["name"]:
params_k_power["var"] = params_k["var"] * power
return(params_k_power)

if "sinc" in params_k["name"]:
params_k_power["var"] = params_k["var"] # the var parameter doesn't change, only the kernel gets scaled; which we don't care for KT
return(params_k_power)

if "laplace" in params_k["name"]:
params_k_power["var"] = params_k["var"]
assert(power> d/(d+1.))
params_k_power["nu"] = power * (d+1)/2.
return(params_k_power)

if "matern" in params_k["name"]:
params_k_power["var"] = params_k["var"]
nu = params_k["nu"]
assert(power > d/(2. * nu))
params_k_power["nu"] = power * nu
return(params_k_power)

if "imq" in params_k["name"]: # currently we implement only sqrt imq kernels using eqn 117 from https://arxiv.org/pdf/2105.05842.pdf [our choice is valid for all nu]
assert(power==0.5)
params_k_power["var"] = params_k["var"]
params_k_power["nu"] = d/4 + params_k["nu"]/2.
return(params_k_power)

if "bspline" in params_k["name"]: # taken from last appendix of https://arxiv.org/pdf/2110.01593.pdf
beta = params_k["nu"]
if beta%2 == 1:
assert(power == 0.5)
if beta%2 == 0:
assert(power== (beta+2)/(2*beta+2))
params_k_power["var"] = params_k["var"]
params_k_power["nu"] = int(beta/2)
assert(params_k_power["nu"] >=0)
return(params_k_power)
raise ValueError("Unrecognized kernel name {}".format(params_k["name"])
```
<Overlap Ratio: 0.99308142629058>

---

--- 381 --
Question ID: f078afa2ebfb3cc439cbeeb8307fb8affce1793a_3
Original Code:
```
async def sample_update_datasource_credential_async(datasource_credential):
    # [START update_datasource_credential_async]
    from azure.ai.metricsadvisor import MetricsAdvisorKeyCredential, MetricsAdvisorAdministrationClient

    service_endpoint = os.getenv("METRICS_ADVISOR_ENDPOINT")
    subscription_key = os.getenv("METRICS_ADVISOR_SUBSCRIPTION_KEY")
    api_key = os.getenv("METRICS_ADVISOR_API_KEY")

    client = MetricsAdvisorAdministrationClient(service_endpoint,
                                  MetricsAdvisorKeyCredential(subscription_key, api_key))

    datasource_credential.description = "updated description"

    updated = await client.update_datasource_credential(datasource_credential)
    print("Credential type: {}".format(updated.credential_type))
    print("Credential name: {}".format(updated.name))
    print("Description: {}\n".format(updated.description))
```


Overlapping Code:
```
asource_credential_async(datasource_credential):
# [START update_datasource_credential_async]
from azure.ai.metricsadvisor import MetricsAdvisorKeyCredential, MetricsAdvisorAdministrationClient
service_endpoint = os.getenv("METRICS_ADVISOR_ENDPOINT")
subscription_key = os.getenv("METRICS_ADVISOR_SUBSCRIPTION_KEY")
api_key = os.getenv("METRICS_ADVISOR_API_KEY")
client = MetricsAdvisorAdministrationClient(service_endpoint,
MetricsAdvisorKeyCredential(subscription_key, api_key))
datasource_credential.description = "updated description"
updated = await client.update_datasource_credential(datasource_credential)
print("Credential type: {}".format(updated.credential_type))
print("Credential name: {}".format(updated.name))
print("Description: {}\n".format(updated.descript
```
<Overlap Ratio: 0.9602977667493796>

---

--- 382 --
Question ID: ff9b196d55a53480d03f206f97fbba23a16107fc_1
Original Code:
```
def getMetaEbible():
    try:
        base_url = 'http://ebible.org/Scriptures/copyright.php'
        soup = BeautifulSoup(requests.get(base_url).content)
        tables=soup.select('table')
        dfs=[]
        for table in tables:
            dfs.append(pd.read_html(table.prettify(), flavor='bs4',header=0)[0])
        df=pd.concat(dfs, sort=True)
        mask=(df['FCBH/DBS'].str.len() == 6) & (df['FCBH/DBS'].str.isupper())
    except:
        soup = BeautifulSoup(open("../meta/ebible.html") )
        tables=soup.select('table')
        dfs=[]
        for table in tables:
            dfs.append(pd.read_html(table.prettify(), flavor='bs4',header=0)[0])
        df=pd.concat(dfs, sort=True)
        mask=(df['FCBH/DBS'].str.len() == 6) & (df['FCBH/DBS'].str.isupper())

    df = df.loc[mask]
    df['iso']=[x[0:3] for x in df['ID'].tolist()]
    df=df[['iso','FCBH/DBS','Language in English', 'Year','Short Title']]
    df=df.rename(index=str,columns={'iso':'language_iso','FCBH/DBS':'trans_ID','Language in English':'language_name','Short Title':'Description','Date':'Year'})
    df=df[['trans_ID','language_iso','language_name','Description','Year']]
    df.set_index('trans_ID')
    return df
```


Overlapping Code:
```
_url = 'http://ebible.org/Scriptures/copyright.php'
soup = BeautifulSoup(requests.get(base_url).content)
tables=soup.select('table')
dfs=[]
for table in tables:
dfs.append(pd.read_html(table.prettify(), flavor='bs4',header=0)[0])
df=pd.concat(dfs, sort=True)
mask=(df['FCBH/DBS'].str.len() == 6) & (df['FCBH/DBS'].str.isupper())
except:
soup = BeautifulSoup(open("../meta/ebible.html") )
tables=soup.select('table')
dfs=[]
for table in tables:
dfs.append(pd.read_html(table.prettify(), flavor='bs4',header=0)[0])
df=pd.concat(dfs, sort=True)
mask=(df['FCBH/DBS'].str.len() == 6) & (df['FCBH/DBS'].str.isupper())
df = df.loc[mask]
df['iso']=[x[0:3] for x in df['ID'].tolist()]
df=df[['iso','FCBH/DBS','Language in English', 'Year','Short Title']]
df=df.rename(index=str,columns={'iso':'language_iso','FCBH/DBS':'trans_ID','Language in English':'language_name','Short Title':'Description','Date':'Year'})
df=df[['trans_ID','language_iso','language_name','Description','Year']]
df.set_index('trans_ID')

```
<Overlap Ratio: 0.9624639076034649>

---

--- 383 --
Question ID: 8f93ab9ae8042a57f2d0acfbbf7ce9221e376616_12
Original Code:
```
def restart():
    file = initDreplace()
    data = mw.execShell(file + ' restart')
    if data[1] == '':
        return 'ok'
    return data[1]
```


Overlapping Code:
```
ef restart():
file = initDreplace()
data = mw.execShell(file + ' restart')
if data[1] == '':
return 'ok'
return d
```
<Overlap Ratio: 0.9416666666666667>

---

