--- 0 --
Question ID: 39f09795a7cfe287cf26316abfab0ef79424135a_4
Original Code:
```
def check_password(password):
    if re.match(r'[a-zA-Z_]+[A-Za-z0-9@#!$%^&+=]{8,}', str(password)):
        return False
    response = {'message': 'Password should contain at least eight ' +
                           'characters with at least one digit, one ' +
                           'uppercase letter and one lowercase letter'}
    return jsonify(response), 400
```


Overlapping Code:
```
e.match(r'[a-zA-Z_]+[A-Za-z0-9@#!$%^&+=]{8,}', str(password)):
return False
response = {'message': 'Password should contain at least eight ' +
'characters with at least one digit, one ' +
'uppercase letter and one lowercase letter'}
return jsonify(re
```
<Overlap Ratio: 0.8445945945945946>

---

--- 1 --
Question ID: c694ec0cb531e0a4637de6993f900eb0609c3342_1
Original Code:
```
@_retry.with_exponential_backoff(initial_delay_secs=1.0, num_retries=10)
def _copy(gcs_path, model_dir, path_to_gsutil):
  """Copy files from gcs to a local path.

  Behaves similar to the linux cp command.
  Sample behavior:
  dir1/
    file1
    file2
    dir2/
      file3

  _copy("dir1", "/tmp", path_to_gsutil)
  After copy:
  tmp/
    dir1/
      file1
      ...

  _copy("dir1/", "/tmp", path_to_gsutil)
  After copy:
  tmp/
    file1
    file2
    dir2/
      file3

  Args:
    gcs_path: Source GCS path that we're copying from.
    model_dir: Destination local path that we're copying to.
    path_to_gsutil: Location of gsutil executable.

  Raises:
    Exception: If gsutil is not found.
  """
  copy_start_time = time.time()
  logging.debug("Starting to copy files from %s to %s", gcs_path, model_dir)
  if not os.path.exists(model_dir):
    os.makedirs(model_dir)
  # Simulate behavior of the linux cp command, where if the source is a
  # directory ending in "/", files and directories in source are copied to the
  # destination without the parent directory structure.
  if gcs_path.endswith("/"):
    gcs_path = os.path.join(gcs_path, "*")
  path_to_gsutil = path_to_gsutil or os.environ.get("PATH_TO_GSUTIL") or ""
  if not path_to_gsutil:
    raise Exception("File copy failed: gsutil not found.")
  logging.debug("Using gsutil on path %s to perform file copy",
                path_to_gsutil)
  try:
    # Removed parallel downloads ("-m") because it was not working well in
    # gVisor (b/37269226).
    subprocess.check_call([
        path_to_gsutil, "-o", "GoogleCompute:service_account=default",
        "cp", "-R", gcs_path, model_dir], stdin=subprocess.PIPE)
  except subprocess.CalledProcessError as e:
    logging.error(str(e))
    raise
  logging.debug("Files copied from %s to %s: took %f seconds", gcs_path,
                model_dir, time.time() - copy_start_time)
```


Overlapping Code:
```
onential_backoff(initial_delay_secs=1.0, num_retries=10)
def _copy(gcs_path, model_dir, path_to_gsutil):
"""Copy files from gcs to a local path.
Behaves similar to the linux cp command.
Sample behavior:
dir1/
file1
file2
dir2/
file3
_copy("dir1", "/tmp", path_to_gsutil)
After copy:
tmp/
dir1/
file1
...
_copy("dir1/", "/tmp", path_to_gsutil)
After copy:
tmp/
file1
file2
dir2/
file3
Args:
gcs_path: Source GCS path that we're copying from.
model_dir: Destination local path that we're copying to.
path_to_gsutil: Location of gsutil executable.
Raises:
Exception: If gsutil is not found.
"""
copy_start_time = time.time()
logging.debug("Starting to copy files from %s to %s", gcs_path, model_dir)
if not os.path.exists(model_dir):
os.makedirs(model_dir)
# Simulate behavior of the linux cp command, where if the source is a
# directory ending in "/", files and directories in source are copied to the
# destination without the parent directory structure.
if gcs_path.endswith("/"):
gcs_path = os.path.join(gcs_path, "*")
path_to_gsutil = path_to_gsutil or os.environ.get("PATH_TO_GSUTIL") or ""
if not path_to_gsutil:
raise Exception("File copy failed: gsutil not found.")
logging.debug("Using gsutil on path %s to perform file copy",
path_to_gsutil)
try:
# Removed parallel downloads ("-m") because it was not working well in
# gVisor (b/37269226).
subprocess.check_call([
path_to_gsutil, "-o", "GoogleCompute:service_account=default",
"cp", "-R", gcs_path, model_dir], stdin=subprocess.PIPE)
except subprocess.CalledProcessError as e:
logging.error(str(e))
raise
logging.debug("Files copied from %s to %s: took %f seconds", gcs_path,
model_dir, time.time() - c
```
<Overlap Ratio: 0.9816893089190786>

---

--- 2 --
Question ID: c4a3e2bd55619ba48cb984724f3222c423a71af9_1
Original Code:
```
def test_QHsmTst_dispatch(qutest_noreset):
    qutest = qutest_noreset # name change

    qutest.dispatch("A_SIG")
    qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=A_SIG,State=s211")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s211")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s21")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s21")
    qutest.expect("===RTC===> St-Init  Obj=the_hsm,State=s21->s211")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s211")
    qutest.expect("%timestamp ===>Tran Obj=the_hsm,Sig=A_SIG,State=s21->s211")
    qutest.expect("%timestamp Trg-Done QS_RX_EVENT")

    qutest.dispatch("B_SIG")
    qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=B_SIG,State=s211")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s211")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s211")
    qutest.expect("%timestamp ===>Tran Obj=the_hsm,Sig=B_SIG,State=s21->s211")
    qutest.expect("%timestamp Trg-Done QS_RX_EVENT")

    qutest.dispatch("D_SIG")
    qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=D_SIG,State=s211")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s211")
    qutest.expect("===RTC===> St-Init  Obj=the_hsm,State=s21->s211")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s211")
    qutest.expect("%timestamp ===>Tran Obj=the_hsm,Sig=D_SIG,State=s211->s211")
    qutest.expect("%timestamp Trg-Done QS_RX_EVENT")

    qutest.dispatch("E_SIG")
    qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=E_SIG,State=s211")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s211")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s21")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s2")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s1")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s11")
    qutest.expect("%timestamp ===>Tran Obj=the_hsm,Sig=E_SIG,State=s->s11")
    qutest.expect("%timestamp Trg-Done QS_RX_EVENT")

    qutest.dispatch("I_SIG")
    qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=I_SIG,State=s11")
    qutest.expect("%timestamp =>Intern Obj=the_hsm,Sig=I_SIG,State=s1")
    qutest.expect("%timestamp Trg-Done QS_RX_EVENT")

    qutest.dispatch("F_SIG")
    qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=F_SIG,State=s11")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s11")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s1")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s2")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s21")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s211")
    qutest.expect("%timestamp ===>Tran Obj=the_hsm,Sig=F_SIG,State=s1->s211")
    qutest.expect("%timestamp Trg-Done QS_RX_EVENT")

    qutest.dispatch("I_SIG")
    qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=I_SIG,State=s211")
    qutest.expect("%timestamp =>Intern Obj=the_hsm,Sig=I_SIG,State=s2")
    qutest.expect("%timestamp Trg-Done QS_RX_EVENT")

    qutest.dispatch("I_SIG")
    qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=I_SIG,State=s211")
    qutest.expect("===RTC===> St-Unhnd Obj=the_hsm,Sig=I_SIG,State=s2")
    qutest.expect("%timestamp =>Intern Obj=the_hsm,Sig=I_SIG,State=s")
    qutest.expect("%timestamp Trg-Done QS_RX_EVENT")

    qutest.dispatch("F_SIG")
    qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=F_SIG,State=s211")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s211")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s21")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s2")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s1")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s11")
    qutest.expect("%timestamp ===>Tran Obj=the_hsm,Sig=F_SIG,State=s2->s11")
    qutest.expect("%timestamp Trg-Done QS_RX_EVENT")

    qutest.dispatch("A_SIG")
    qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=A_SIG,State=s11")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s11")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s1")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s1")
    qutest.expect("===RTC===> St-Init  Obj=the_hsm,State=s1->s11")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s11")
    qutest.expect("%timestamp ===>Tran Obj=the_hsm,Sig=A_SIG,State=s1->s11")
    qutest.expect("%timestamp Trg-Done QS_RX_EVENT")

    qutest.dispatch("B_SIG")
    qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=B_SIG,State=s11")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s11")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s11")
    qutest.expect("%timestamp ===>Tran Obj=the_hsm,Sig=B_SIG,State=s1->s11")
    qutest.expect("%timestamp Trg-Done QS_RX_EVENT")

    qutest.dispatch("D_SIG")
    qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=D_SIG,State=s11")
    qutest.expect("===RTC===> St-Unhnd Obj=the_hsm,Sig=D_SIG,State=s11")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s11")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s1")
    qutest.expect("===RTC===> St-Init  Obj=the_hsm,State=s->s11")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s1")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s11")
    qutest.expect("%timestamp ===>Tran Obj=the_hsm,Sig=D_SIG,State=s1->s11")
    qutest.expect("%timestamp Trg-Done QS_RX_EVENT")

    qutest.dispatch("D_SIG")
    qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=D_SIG,State=s11")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s11")
    qutest.expect("===RTC===> St-Init  Obj=the_hsm,State=s1->s11")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s11")
    qutest.expect("%timestamp ===>Tran Obj=the_hsm,Sig=D_SIG,State=s11->s11")
    qutest.expect("%timestamp Trg-Done QS_RX_EVENT")

    qutest.dispatch("E_SIG")
    qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=E_SIG,State=s11")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s11")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s1")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s1")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s11")
    qutest.expect("%timestamp ===>Tran Obj=the_hsm,Sig=E_SIG,State=s->s11")
    qutest.expect("%timestamp Trg-Done QS_RX_EVENT")

    qutest.dispatch("G_SIG")
    qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=G_SIG,State=s11")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s11")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s1")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s2")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s21")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s211")
    qutest.expect("%timestamp ===>Tran Obj=the_hsm,Sig=G_SIG,State=s11->s211")
    qutest.expect("%timestamp Trg-Done QS_RX_EVENT")

    qutest.dispatch("H_SIG")
    qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=H_SIG,State=s211")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s211")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s21")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s2")
    qutest.expect("===RTC===> St-Init  Obj=the_hsm,State=s->s11")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s1")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s11")
    qutest.expect("%timestamp ===>Tran Obj=the_hsm,Sig=H_SIG,State=s211->s11")
    qutest.expect("%timestamp Trg-Done QS_RX_EVENT")

    qutest.dispatch("H_SIG")
    qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=H_SIG,State=s11")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s11")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s1")
    qutest.expect("===RTC===> St-Init  Obj=the_hsm,State=s->s11")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s1")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s11")
    qutest.expect("%timestamp ===>Tran Obj=the_hsm,Sig=H_SIG,State=s11->s11")
    qutest.expect("%timestamp Trg-Done QS_RX_EVENT")

    qutest.dispatch("C_SIG")
    qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=C_SIG,State=s11")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s11")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s1")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s2")
    qutest.expect("===RTC===> St-Init  Obj=the_hsm,State=s2->s211")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s21")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s211")
    qutest.expect("%timestamp ===>Tran Obj=the_hsm,Sig=C_SIG,State=s1->s211")
    qutest.expect("%timestamp Trg-Done QS_RX_EVENT")

    qutest.dispatch("G_SIG")
    qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=G_SIG,State=s211")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s211")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s21")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s2")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s1")
    qutest.expect("===RTC===> St-Init  Obj=the_hsm,State=s1->s11")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s11")
    qutest.expect("%timestamp ===>Tran Obj=the_hsm,Sig=G_SIG,State=s21->s11")
    qutest.expect("%timestamp Trg-Done QS_RX_EVENT")

    qutest.dispatch("C_SIG")
    qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=C_SIG,State=s11")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s11")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s1")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s2")
    qutest.expect("===RTC===> St-Init  Obj=the_hsm,State=s2->s211")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s21")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s211")
    qutest.expect("%timestamp ===>Tran Obj=the_hsm,Sig=C_SIG,State=s1->s211")
    qutest.expect("%timestamp Trg-Done QS_RX_EVENT")

    qutest.dispatch("C_SIG")
    qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=C_SIG,State=s211")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s211")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s21")
    qutest.expect("===RTC===> St-Exit  Obj=the_hsm,State=s2")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s1")
    qutest.expect("===RTC===> St-Init  Obj=the_hsm,State=s1->s11")
    qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s11")
    qutest.expect("%timestamp ===>Tran Obj=the_hsm,Sig=C_SIG,State=s2->s11")
    qutest.expect("%timestamp Trg-Done QS_RX_EVENT")
```


Overlapping Code:
```
est_QHsmTst_dispatch(qutest_noreset):
qutest = qutest_noreset # name change
qutest.dispatch("A_SIG")
qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=A_SIG,State=s211")
qutest.expect("===RTC===> St-Exit Obj=the_hsm,State=s211")
qutest.expect("===RTC===> St-Exit Obj=the_hsm,State=s21")
qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s21")
qutest.expect("===RTC===> St-Init Obj=the_hsm,State=s21->s211")
qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s211")
qutest.expect("%timestamp ===>Tran Obj=the_hsm,Sig=A_SIG,State=s21->s211")
qutest.expect("%timestamp Trg-Done QS_RX_EVENT")
qutest.dispatch("B_SIG")
qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=B_SIG,State=s211")
qutest.expect("===RTC===> St-Exit Obj=the_hsm,State=s211")
qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s211")
qutest.expect("%timestamp ===>Tran Obj=the_hsm,Sig=B_SIG,State=s21->s211")
qutest.expect("%timestamp Trg-Done QS_RX_EVENT")
qutest.dispatch("D_SIG")
qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=D_SIG,State=s211")
qutest.expect("===RTC===> St-Exit Obj=the_hsm,State=s211")
qutest.expect("===RTC===> St-Init Obj=the_hsm,State=s21->s211")
qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s211")
qutest.expect("%timestamp ===>Tran Obj=the_hsm,Sig=D_SIG,State=s211->s211")
qutest.expect("%timestamp Trg-Done QS_RX_EVENT")
qutest.dispatch("E_SIG")
qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=E_SIG,State=s211")
qutest.expect("===RTC===> St-Exit Obj=the_hsm,State=s211")
qutest.expect("===RTC===> St-Exit Obj=the_hsm,State=s21")
qutest.expect("===RTC===> St-Exit Obj=the_hsm,State=s2")
qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s1")
qutest.expect("===RTC===> St-Entry Obj=the_hsm,State=s11")
qutest.expect("%timestamp ===>Tran Obj=the_hsm,Sig=E_SIG,State=s->s11")
qutest.expect("%timestamp Trg-Done QS_RX_EVENT")
qutest.dispatch("I_SIG")
qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=I_SIG,State=s11")
qutest.expect("%timestamp =>Intern Obj=the_hsm,Sig=I_SIG,State=s1")
qutest.expect("%timestamp Trg-Done QS_RX_EVENT")
qutest.dispatch("F_SIG")
qutest.expect("%timestamp Disp===> Obj=the_hsm,Sig=F_SIG,State=s11")
qutest.expect("===RTC===> St-Exit Obj=the_hsm,State=s11")
qutest.expect("===RTC===> St-Exit Obj=the_hsm,State=s1")
qutest.expect("===RTC===> St-Entry Obj=the_hsm,St
```
<Overlap Ratio: 0.997411561691113>

---

--- 3 --
Question ID: fc376780cca12cf7d8b363ab2ea7991d81344231_0
Original Code:
```
def VSFcalc(u,v,lat,lon, nd):
    """
    : VSFcalc:
      Calculate Vortex-surface fields applying
      solution of geodesic using Vincenty formula
    """

    # vectorize the computation:
    # Slice the arrays for differencing
    du_j = u[1:nd,:] - u[0:nd-1,:]
    dv_j = v[1:nd,:] - v[0:nd-1,:]

    arr1 = np.array((lat[0:nd-1,:]))
    arr2 = np.array((lon[0:nd-1,:]))
    arr3 = np.array((lat[1:nd,:]))
    arr4 = np.array((lon[1:nd,:]))

    # Warning: geopy.distance.vincenty is depracated!
    #          Try geopy.distance.geodesic for more accurate numbers
    print('')
    print(' Begin "vincenty" calculations... ')
    # This part consumes more resources and can be parallelized
    # if you intend to manipulate a 3D array or larger 2D arrays
    # It takes about 30seconds for the current array dims nd, nt
    dx_j = [ vincenty((kj,lj),(mj,nj)).km if np.isfinite(oj) else np.nan 
             for kj,lj,mj,nj,oj in np.nditer([arr1,arr2,arr1,arr4,du_j]) ] 
    dy_j = [ vincenty((kj,lj),(mj,nj)).km if np.isfinite(oj) else np.nan 
             for kj,lj,mj,nj,oj in np.nditer([arr1,arr2,arr3,arr2,du_j]) ] 
    dr_j = [ vincenty((kj,lj),(mj,nj)).km if np.isfinite(oj) else np.nan 
             for kj,lj,mj,nj,oj in np.nditer([arr1,arr2,arr3,arr4,du_j]) ] 
    # "dr_j2" would be necessary if an iterator is returned by the function
    #dr_j2 = [ (yield vincenty((kj,lj),(mj,nj)).km) if np.isfinite(oj) else (yield np.nan) 
    #         for kj,lj,mj,nj,oj in np.nditer([arr1,arr2,arr3,arr4,du_j]) ] 

    dx_s = [ np.sign(kj-lj) if np.isfinite(oj) else np.nan 
             for kj,lj,oj in np.nditer([arr4,arr2,du_j]) ] 
    dy_s = [ np.sign(kj-lj) if np.isfinite(oj) else np.nan 
             for kj,lj,oj in np.nditer([arr3,arr1,du_j]) ] 
    print(' "vincenty" calculations Finished')

    # Mask the variables to avoid 'NaNs'
    dx_j = np.ma.masked_where(np.isfinite(dx_j), dx_j)
    dy_j = np.ma.masked_where(np.isfinite(dy_j), dy_j)
    dx_s = np.ma.masked_where(np.isfinite(dx_s), dx_s)
    dy_s = np.ma.masked_where(np.isfinite(dy_s), dy_s)

    print(' Begin functions mapping... ')
    # - "dx=dx_j.data*dx_s.data" and dy=dy_j.data*dy_s.data"
    #   would also work but could result to
    #   erroneous numbers. It is not clear how Numpy handles 'NaN'
    # - Using the conditions a below will only give correct results
    #   if both boolean values of the ordered pair are similar
    #   otherwise the truth table of the if condition will not
    #   result to the expected results
    # - The map function generates an iterator which is more efficient
    dx   = map( lambda x: x[0]*x[1] if np.any([x[0], x[1]], axis=0)   
                else np.nan, list(zip(dx_j.data,dx_s.data))) 
    dy   = map( lambda y: y[0]*y[1] if np.any([y[0], y[1]], axis=0)  
                else np.nan, list(zip(dy_j.data,dy_s.data)))  

    # It is necessary to copy your generators here for multiple usage
    dx, dxObj = itertools.tee(dx)
    dy, dyObj = itertools.tee(dy)
   
    # - "dl=(du_j*dx + dv_j*dy)/dr_j" and "dt=(-du_j*dy + dv_j*dx)/dr_j" 
    #   would also work but could result to
    #   erroneous numbers. It is not clear how Numpy handles 'NaN'
    # - Using the conditions a below will only give correct results
    #   if both boolean values of the ordered tuple are similar
    #   otherwise the truth table of the if condition will not
    #   result to the expected results
    # - The map function generates an iterator which is more efficient
    dl   = map( lambda dj: (dj[0]*dj[2] + dj[1]*dj[3])/dj[4] if np.any([dj[0], dj[4]], axis=0)     
                else np.nan, list(zip(*du_j,*dv_j,list(dx),list(dy),dr_j)))    
    dt   = map( lambda dj: (-dj[0]*dj[3] + dj[1]*dj[2])/dj[4] if np.any([dj[0], dj[4]], axis=0)     
                else np.nan, list(zip(*du_j,*dv_j,list(dxObj),list(dyObj),dr_j)))      
    print(' Functions mapping Finished ')

    print('... returning a list of output')
    # returning list consumes a lot of memory
    # and slows down the I/O. This can be avoided
    # by returning an iterator which can be 
    # used to write data to an appendable text file
    return list(dl), list(dt), dr_j
```


Overlapping Code:
```
""
: VSFcalc:
Calculate Vortex-surface fields applying
solution of geodesic using Vincenty formula
"""
# vectorize the computation:
# Slice the arrays for differencing
du_j = u[1:nd,:] - u[0:nd-1,:]
dv_j = v[1:nd,:] - v[0:nd-1,:]
arr1 = np.array((lat[0:nd-1,:]))
arr2 = np.array((lon[0:nd-1,:]))
arr3 = np.array((lat[1:nd,:]))
arr4 = np.array((lon[1:nd,:]))
# Warning: geopy.distance.vincenty is depracated!
# Try geopy.distance.geodesic for more accurate numbers
print('')
print(' Begin "vincenty" calculations... ')
# This part consumes more resources and can be parallelized
# if you intend to manipulate a 3D array or larger 2D arrays
# It takes about 30seconds for the current array dims nd, nt
dx_j = [ vincenty((kj,lj),(mj,nj)).km if np.isfinite(oj) else np.nan 
for kj,lj,mj,nj,oj in np.nditer([arr1,arr2,arr1,arr4,du_j]) ] 
dy_j = [ vincenty((kj,lj),(mj,nj)).km if np.isfinite(oj) else np.nan 
for kj,lj,mj,nj,oj in np.nditer([arr1,arr2,arr3,arr2,du_j]) ] 
dr_j = [ vincenty((kj,lj),(mj,nj)).km if np.isfinite(oj) else np.nan 
for kj,lj,mj,nj,oj in np.nditer([arr1,arr2,arr3,arr4,du_j]) ] 
# "dr_j2" would be necessary if an iterator is returned by the function
#dr_j2 = [ (yield vincenty((kj,lj),(mj,nj)).km) if np.isfinite(oj) else (yield np.nan) 
# for kj,lj,mj,nj,oj in np.nditer([arr1,arr2,arr3,arr4,du_j]) ] 
dx_s = [ np.sign(kj-lj) if np.isfinite(oj) else np.nan 
for kj,lj,oj in np.nditer([arr4,arr2,du_j]) ] 
dy_s = [ np.sign(kj-lj) if np.isfinite(oj) else np.nan 
for kj,lj,oj in np.nditer([arr3,arr1,du_j]) ] 
print(' "vincenty" calculations Finished')
# Mask the variables to avoid 'NaNs'
dx_j = np.ma.masked_where(np.isfinite(dx_j), dx_j)
dy_j = np.ma.masked_where(np.isfinite(dy_j), dy_j)
dx_s = np.ma.masked_where(np.isfinite(dx_s), dx_s)
dy_s = np.ma.masked_where(np.isfinite(dy_s), dy_s)
print(' Begin functions mapping... ')
# - "dx=dx_j.data*dx_s.data" and dy=dy_j.data*dy_s.data"
# would also work but could result to
# erroneous numbers. It is not clear how Numpy handles 'NaN'
# - Using the conditions a below will only give correct results
# if both boolean values of the ordered pair are similar
# otherwise the truth
```
<Overlap Ratio: 0.9649910233393177>

---

--- 4 --
Question ID: 0d2bf0fdee0f33905ae357656cd830d99f221b96_2
Original Code:
```
def calc_graph(analysis_fields, data_frame, substation_plot_flag):
    # calculate graph
    graph = []
    # format demand values
    data = data_frame[0].fillna(value=0)
    data = pd.DataFrame(data.sum(axis=0), columns=[analysis_fields[0]])
    if not substation_plot_flag:
        data1 = data_frame[1].fillna(value=0)
        data1 = pd.DataFrame(data1.sum(axis=0), columns=[analysis_fields[1]])
        # calculate total
        total = pd.DataFrame(data.values + data1.values, index=data1.index, columns=['total'])
        # join dataframes
        data = data.join(data1)
        data_frame = data.join(total)
        data_frame = data_frame.sort_values(by='total', ascending=False)  # this will get the maximum value to the left
    else:
        data_frame = data.sort_values(by=analysis_fields[0], ascending=False)
    # iterate through data to plot
    for field in analysis_fields:
        if not substation_plot_flag:
            total_perc = (data_frame[field].values.reshape(1, len(total.index)) / data_frame['total'].values.reshape(1, len(
                total.index)) * 100).round(2)[0]
            total_perc_txt = ["(" + str(x) + " %)" for x in total_perc]
            trace = go.Bar(x=data_frame.index, y=data_frame[field].values, name=NAMING[field],
                           text=total_perc_txt,
                           orientation='v',
                           marker=dict(color=COLOR[field]))
        else:
            trace = go.Bar(x=data_frame.index, y=data_frame[field].values, name=NAMING[field],
                           orientation='v',
                           marker=dict(color=COLOR[field]))
        graph.append(trace)

    return graph
```


Overlapping Code:
```
calc_graph(analysis_fields, data_frame, substation_plot_flag):
# calculate graph
graph = []
# format demand values
data = data_frame[0].fillna(value=0)
data = pd.DataFrame(data.sum(axis=0), columns=[analysis_fields[0]])
if not substation_plot_flag:
data1 = data_frame[1].fillna(value=0)
data1 = pd.DataFrame(data1.sum(axis=0), columns=[analysis_fields[1]])
# calculate total
total = pd.DataFrame(data.values + data1.values, index=data1.index, columns=['total'])
# join dataframes
data = data.join(data1)
data_frame = data.join(total)
data_frame = data_frame.sort_values(by='total', ascending=False) # this will get the maximum value to the left
else:
data_frame = data.sort_values(by=analysis_fields[0], ascending=False)
# iterate through data to plot
for field in analysis_fields:
if not substation_plot_flag:
total_perc = (data_frame[field].values.reshape(1, len(total.index)) / data_frame['total'].values.reshape(1, len(
total.index)) * 100).round(2)[0]
total_perc_txt = ["(" + str(x) + " %)" for x in total_perc]
trace = go.Bar(x=data_frame.index, y=data_frame[field].values, name=NAMING[field],
text=total_perc_txt,
orientation='v',
marker=dict(color=COLOR[field]))
else:
trace = go.Bar(x=data_frame.index, y=data_frame[field].values, name=NAMING[field],
orientation='v',
marker=dict(color=COLOR[field]))
graph.append(trace)
return grap
```
<Overlap Ratio: 0.9962852897473997>

---

--- 5 --
Question ID: 6a660cf0a5e11b4dcec0f57e569a500951cfaa24_0
Original Code:
```
@rule
async def setup_isort(isort: Isort) -> IsortSetup:
  config_path: Optional[List[str]] = isort.options.config
  config_snapshot = await Get[Snapshot](PathGlobs(include=config_path or ()))
  requirements_pex = await Get[Pex](
    CreatePex(
      output_filename="isort.pex",
      requirements=PexRequirements(requirements=tuple(isort.get_requirement_specs())),
      interpreter_constraints=PexInterpreterConstraints(
        constraint_set=tuple(isort.default_interpreter_constraints)
      ),
      entry_point=isort.get_entry_point(),
    )
  )
  return IsortSetup(
    requirements_pex=requirements_pex,
    config_snapshot=config_snapshot,
    passthrough_args=tuple(isort.options.args),
    skip=isort.options.skip,
  )
```


Overlapping Code:
```
le
async def setup_isort(isort: Isort) -> IsortSetup:
config_path: Optional[List[str]] = isort.options.config
config_snapshot = await Get[Snapshot](PathGlobs(include=config_path or ()))
requirements_pex = await Get[Pex](
CreatePex(
output_filename="isort.pex",
requirements=PexRequirements(requirements=tuple(isort.get_requirement_specs())),
interpreter_constraints=PexInterpreterConstraints(
constraint_set=tuple(isort.default_interpreter_constraints)
),
entry_point=isort.get_entry_point(),
)
)
return IsortSetup(
requirements_pex=requirements_pex,
config_snapshot=config_snapshot,
passthrough_args=tuple(isort.options.args),
skip=isort.options.ski
```
<Overlap Ratio: 0.989345509893455>

---

--- 6 --
Question ID: 57c643192d592d35df1b3836680cc57d0a7af84d_0
Original Code:
```
def test_type_respects_inheritance():
    bl = BusList()
    assert type(bl) == BusList
    assert type(bl) != Iterable
    assert type(bl) != VehicleList
```


Overlapping Code:
```
ects_inheritance():
bl = BusList()
assert type(bl) == BusList
assert type(bl) != Iterable
assert typ
```
<Overlap Ratio: 0.7246376811594203>

---

--- 7 --
Question ID: 4e419e25f5bf7447b19908801f30f84deced2394_1
Original Code:
```
def load_data_and_labels(positive_data_file, negative_data_file):
    """
    Loads MR polarity data from files, splits the data into words and generates labels.
    Returns split sentences and labels.
    """
    # Load data from files
    positive_examples = list(open(positive_data_file, "r").readlines())
    positive_examples = [s.strip() for s in positive_examples]
    negative_examples = list(open(negative_data_file, "r").readlines())
    negative_examples = [s.strip() for s in negative_examples]
    # Split by words
    x_text = positive_examples + negative_examples
    x_text = [clean_str(sent) for sent in x_text]
    # Generate labels
    positive_labels = [[0, 1] for _ in positive_examples]
    negative_labels = [[1, 0] for _ in negative_examples]
    y = np.concatenate([positive_labels, negative_labels], 0)
    return [x_text, y]
```


Overlapping Code:
```
ef load_data_and_labels(positive_data_file, negative_data_file):
"""
Loads MR polarity data from files, splits the data into words and generates labels.
Returns split sentences and labels.
"""
# Load data from files
positive_examples = list(open(positive_data_file, "r").readlines())
positive_examples = [s.strip() for s in positive_examples]
negative_examples = list(open(negative_data_file, "r").readlines())
negative_examples = [s.strip() for s in negative_examples]
# Split by words
x_text = positive_examples + negative_examples
x_text = [clean_str(sent) for sent in x_text]
# Generate labels
positive_labels = [[0, 1] for _ in positive_examples]
negative_labels = [[1, 0] for _ in negative_examples]
y = np.concatenate([positive_labels, negative_labels], 0)
return [x_text, y
```
<Overlap Ratio: 0.9974457215836526>

---

--- 8 --
Question ID: aca7b839e586cbe4b05be2d1afaa21cbad2cff67_1
Original Code:
```
def __query_json(west=-122.2981,north=37.8790,east=-122.2547,south=37.8594,exclude_tertiary=True):

    infrastructure = 'way["highway"]'
    timeout = 180
    osm_filter = '["area"!~"yes"]["motor_vehicle"!~"no"]["motorcar"!~"no"]["access"!~"private"]["service"!~"parking|parking_aisle|driveway|private|emergency_access"]'

    if exclude_tertiary:
        osm_filter = osm_filter + '["highway"!~"footway|bridleway|steps|path|living_street|service|pedestrian|track|bus_guideway|escape|raceway|cycleway|proposed|construction|bus_stop|crossing|elevator|emergency_access_point|give_way|mini_roundabout|motorway_junction|passing_place|rest_area|speed_camera|street_lamp|services|corridor|abandoned|platform|tertiary|unclassified|residential|tertiary_link"]'
    else:
        osm_filter = osm_filter + '["highway"!~"footway|bridleway|steps|path|living_street|service|pedestrian|track|bus_guideway|escape|raceway|cycleway|proposed|construction|bus_stop|crossing|elevator|emergency_access_point|give_way|mini_roundabout|motorway_junction|passing_place|rest_area|speed_camera|street_lamp|services|corridor|abandoned|platform"]'

    maxsize = ''

    # turn bbox into a polygon and project to local UTM
    polygon = Polygon([(west, south), (east, south), (east, north), (west, north)])
    geometry, crs_proj = __project_geometry(polygon)

    if isinstance(geometry, Polygon):
        geometry_proj_consolidated_subdivided = MultiPolygon([geometry])

    geometry, _ = __project_geometry(geometry_proj_consolidated_subdivided, crs=crs_proj, to_latlong=True)

    response_jsons = []

    for poly in geometry:

        west, south, east, north = poly.bounds
        query_template = '[out:json][timeout:{timeout}]{maxsize};({infrastructure}{filters}({south:.6f},{west:.6f},{north:.6f},{east:.6f});>;);out;'
        query_str = query_template.format(north=north, south=south,
                                          east=east, west=west,
                                          infrastructure=infrastructure,
                                          filters=osm_filter,
                                          timeout=timeout, maxsize=maxsize)
        response_json = __overpass_request(data={'data': query_str}, timeout=timeout)
        response_jsons.append(response_json)

    return response_jsons
```


Overlapping Code:
```
ry_json(west=-122.2981,north=37.8790,east=-122.2547,south=37.8594,exclude_tertiary=True):
infrastructure = 'way["highway"]'
timeout = 180
osm_filter = '["area"!~"yes"]["motor_vehicle"!~"no"]["motorcar"!~"no"]["access"!~"private"]["service"!~"parking|parking_aisle|driveway|private|emergency_access"]'
if exclude_tertiary:
osm_filter = osm_filter + '["highway"!~"footway|bridleway|steps|path|living_street|service|pedestrian|track|bus_guideway|escape|raceway|cycleway|proposed|construction|bus_stop|crossing|elevator|emergency_access_point|give_way|mini_roundabout|motorway_junction|passing_place|rest_area|speed_camera|street_lamp|services|corridor|abandoned|platform|tertiary|unclassified|residential|tertiary_link"]'
else:
osm_filter = osm_filter + '["highway"!~"footway|bridleway|steps|path|living_street|service|pedestrian|track|bus_guideway|escape|raceway|cycleway|proposed|construction|bus_stop|crossing|elevator|emergency_access_point|give_way|mini_roundabout|motorway_junction|passing_place|rest_area|speed_camera|street_lamp|services|corridor|abandoned|platform"]'
maxsize = ''
# turn bbox into a polygon and project to local UTM
polygon = Polygon([(west, south), (east, south), (east, north), (west, north)])
geometry, crs_proj = __project_geometry(polygon)
if isinstance(geometry, Polygon):
geometry_proj_consolidated_subdivided = MultiPolygon([geometry])
geometry, _ = __project_geometry(geometry_proj_consolidated_subdivided, crs=crs_proj, to_latlong=True)
response_jsons = []
for poly in geometry:
west, south, east, north = poly.bounds
query_template = '[out:json][timeout:{timeout}]{maxsize};({infrastructure}{filters}({south:.6f},{west:.6f},{north:.6f},{east:.6f});>;);out;'
query_str = query_template.format(north=north, south=south,
east=east, west=west,
infrastructure=infrastructure,
filters=osm_filter,
timeout=timeout, maxsize=maxsize)
response_json = __overpass_request(data={'data': query_str}, timeout=timeout)
response_jsons.append(response_json)
```
<Overlap Ratio: 0.9845309381237525>

---

--- 9 --
Question ID: f5a4db3668dc937e3959615b4d2fcbb357d2769c_0
Original Code:
```
@common.arg(
    'node',
    metavar='<node_uuid>',
    help='Create a port based on a given ironic node uuid.')
@common.arg(
    '-m', '--mac',
    help='MAC Address of the HPE OneView Server Hardware.')
def do_port_create(args):
    """Create port based on a Ironic Node.

    If not specified, it retrieves the mac address of the first '-a' available
    port at the Server Hardware to which the Ironic Node is related to. It
    also gathers the local link connection if the Ironic Node is enabled to
    use the OneView ml2 driver.
    """
    facade_obj = facade.Facade(args)
    port_creator = PortCreator(facade_obj)

    ironic_node = facade_obj.get_ironic_node(args.node)
    port = port_creator.create_port(args, ironic_node)

    if port:
        print("Created port %s" % port.uuid)

```


Overlapping Code:
```
='Create a port based on a given ironic node uuid.')
@common.arg(
'-m', '--mac',
help='MAC Address of the HPE OneView Server Hardware.')
def do_port_create(args):
"""Create port based on a Ironic Node.
If not specified, it retrieves the mac address of the first '-a' available
port at the Server Hardware to which the Ironic Node is related to. It
also gathers the local link connection if the Ironic Node is enabled to
use the OneView ml2 driver.
"""
facade_obj = facade.Facade(args)
port_creator = PortCreator(facade_obj)
ironic_node = facade_obj.get_ironic_node(args.node)
port = port_creator.create_port(args, ironic_node)
if port:
print("Created
```
<Overlap Ratio: 0.9027777777777778>

---

--- 10 --
Question ID: 123ebd763cbf4c742c2363c86f93d8dac352b66d_0
Original Code:
```
def get_digikey_parts_set(path):
    """
    Reads in the digikey part dictionary and yeilds each part.
    """
    all_parts = set()
    with open(path, "r") as csvinput:
        reader = csv.reader(csvinput)
        for line in reader:
            (part, url) = line
            all_parts.add(part)
    return all_parts
```


Overlapping Code:
```
t_digikey_parts_set(path):
"""
Reads in the digikey part dictionary and yeilds each part.
"""
all_parts = set()
with open(path, "r") as csvinput:
reader = csv.reader(csvinput)
for line in reader:
(part, url) = line
all_parts.add(part)
return all_part
```
<Overlap Ratio: 0.9727626459143969>

---

--- 11 --
Question ID: 6770c4f3dbff2ad3e1b3908d11f1c10abd6cada9_6
Original Code:
```
def _has_any_component(durationstr, components):
    #Given a duration string, and a list of components, returns True
    #if any of the listed components are present, False otherwise.
    #
    #For instance:
    #durationstr = 'P1Y'
    #components = ['Y', 'M']
    #
    #returns True
    #
    #durationstr = 'P1Y'
    #components = ['M', 'D']
    #
    #returns False

    for component in components:
        if durationstr.find(component) != -1:
            return True

    return False
```


Overlapping Code:
```
y_component(durationstr, components):
#Given a duration string, and a list of components, returns True
#if any of the listed components are present, False otherwise.
#
#For instance:
#durationstr = 'P1Y'
#components = ['Y', 'M']
#
#returns True
#
#durationstr = 'P1Y'
#components = ['M', 'D']
#
#returns False
for component in components:
if durationstr.find(component) != -1:
return True
return Fals
```
<Overlap Ratio: 0.970873786407767>

---

--- 12 --
Question ID: 29cbfb2c722f4efa5ded92398163040c8bf192d7_1
Original Code:
```
def test_yelp():
    location_input = "times square"
    result = yelp(location_input)
    result = result["id"]
    test_list = ["U5hCNNyJmb7f3dmC1HTzSQ", "22nKUyCIbpnzR6R3_g1ptQ", "DoSU8IPq-Py_YV3kYmXPfQ", "al9HKZ3kCJipAJW4uxzj4A", "5TX0X8w5ssIACU_pnBEq6g"]
    assert result in test_list
```


Overlapping Code:
```
ation_input = "times square"
result = yelp(location_input)
result = result["id"]
test_list = ["U5hCNNyJmb7f3dmC1HTzSQ", "22nKUyCIbpnzR6R3_g1ptQ", "DoSU8IPq-Py_YV3kYmXPfQ", "al9HKZ3kCJipAJW4uxzj4A", "5TX0X8w5ssIACU_pnBEq6g"]
assert result in test_list
```
<Overlap Ratio: 0.9259259259259259>

---

--- 13 --
Question ID: 863c1598e480b1daf740339d36af7ac540aeacb2_1
Original Code:
```
def get_ip(request):
    x_forwarded_for = request.META.get('HTTP_X_FORWARDED_FOR')
    if x_forwarded_for:
        ip = x_forwarded_for.split(',')[0]
    else:
        ip = request.META.get('REMOTE_ADDR')
    return ip
```


Overlapping Code:
```
ef get_ip(request):
x_forwarded_for = request.META.get('HTTP_X_FORWARDED_FOR')
if x_forwarded_for:
ip = x_forwarded_for.split(',')[0]
else:
ip = request.META.get('REMOTE_ADDR')
return ip
```
<Overlap Ratio: 0.9946524064171123>

---

--- 14 --
Question ID: 312c418a2503ed30629cb40e75e01138460f851f_1
Original Code:
```
@pytest.fixture(scope="session")
def session_dir(request):
    # Temporary directory that gets deleted at the session
    # pytest tmpdir doesn't support a non-function scoped temporary directory
    session_dir = Path(tempfile.mkdtemp())
    request.addfinalizer(lambda: rmtree(session_dir))
    return session_dir
```


Overlapping Code:
```
ion_dir(request):
# Temporary directory that gets deleted at the session
# pytest tmpdir doesn't support a non-function scoped temporary directory
session_dir = Path(tempfile.mkdtemp())
request.addfinalizer(lambda: rmtree(session_dir))
return session_di
```
<Overlap Ratio: 0.8576271186440678>

---

--- 15 --
Question ID: 307c6094661be4ed4c6c1a79d64411f905fb1eda_8
Original Code:
```
@mock.patch("tt.task.get")
@mock.patch("tt.task.update")
def test_describe_invalid_task(update, get, task_service, mocker):
    get.side_effect = NoResultFound

    with pytest.raises(BadRequest):
        task_service.describe("some task", "description")

    get.assert_called_once_with(name="some task")
    assert not update.called
```


Overlapping Code:
```
k.patch("tt.task.get")
@mock.patch("tt.task.update")
def test_describe_invalid_task(update, get, task_service, mocker):
get.side_effect = NoResultFound
with pytest.raises(BadRequest):
task_service.describe("some task", "description")
get.assert_called_once_with(name="some task")
assert not update.ca
```
<Overlap Ratio: 0.974025974025974>

---

--- 16 --
Question ID: 586625de5a994cf06a894c3ba33fcdbb23b4b66f_0
Original Code:
```
def get_all_csindex(only_china=True):
    all_index = []
    page_size = 50
    page_cnt = 1

    curr_page = 1
    while curr_page <= page_cnt:
        url = 'http://www.csindex.com.cn/zh-CN/indices/index?page={curr_page}&page_size={page_size}&by=desc&order=指数代码&data_type=json'.format(**locals())
        if only_china:
            url += '&class_7=7'
        resp = requests.get(url)
        ret = resp.json()
        page_cnt = ret['total_page']
        all_index.extend(ret['list'])
        curr_page += 1

    return all_index
```


Overlapping Code:
```
index = []
page_size = 50
page_cnt = 1
curr_page = 1
while curr_page <= page_cnt:
url = 'http://www.csindex.com.cn/zh-CN/indices/index?page={curr_page}&page_size={page_size}&by=desc&order=指数代码&data_type=json'.format(**locals())
if only_china:
url += '&class_7=7'
resp = requests.get(url)
ret = resp.json()
page_cnt = ret['total_page']
all_index.exten
```
<Overlap Ratio: 0.7990867579908676>

---

--- 17 --
Question ID: b2c6ee12faa5f6701e61eda71d9198494de49f15_0
Original Code:
```
def ccmUnred(wave, flux, EBV, R_V=3.1):

    flux = np.array(flux)
    x = 10000. / wave                # Convert to inverse microns
    npts = len(x)
    a = np.zeros(npts)
    b = np.zeros(npts)

    good = np.where((x > 0.3) & (x < 1.1))[0]       # Infrared
    if len(good) > 0:
        a[good] = 0.574 * x[good] ** (1.61)
        b[good] = -0.527 * x[good] ** (1.61)

    good = np.where((x >= 1.1) & (x < 3.3))        # Optical/NIR
    if len(good[0]) > 0:
        y = x[good] - 1.82
        c1 = np.array([1., 0.104, -0.609, 0.701, 1.137, -1.718, -0.827,
                       1.647, -0.505])   # From O'Donnell (1994)
        c2 = np.array([0., 1.952, 2.908, -3.989, -7.985, 11.102,
                       5.491, -10.805, 3.347])

        a[good] = np.polyval(c1[::-1], y)
        b[good] = np.polyval(c2[::-1], y)

    good = np.where((x >= 3.3) & (x < 8))[0]           # Mid-UV
    if len(good) > 0:
        y = x[good]
        F_a = np.zeros(len(good))
        F_b = np.zeros(len(good))

        good1 = np.where(y > 5.9)
        if len(good1) > 0:
            y1 = y[good1] - 5.9
            F_a[good1] = -0.04473 * y1 ** 2 - 0.009779 * y1 ** 3
            F_b[good1] = 0.2130 * y1 ** 2 + 0.1207 * y1 ** 3

        a[good] = 1.752 - 0.316 * y - (0.104 / ((y - 4.67)**2 + 0.341)) + F_a
        b[good] = -3.090 + 1.825 * y + (1.206 / ((y - 4.62)**2 + 0.263)) + F_b

    good = np.where((x >= 8) & (x <= 11))[0]         # Far-UV
    if len(good) > 0:
        y = x[good] - 8.
        c1 = np.array([-1.073, -0.628, 0.137, -0.070])
        c2 = np.array([13.670, 4.257, -0.420, 0.374])

        a[good] = np.polyval(c1[::-1], y)
        b[good] = np.polyval(c2[::-1], y)

    A_V = R_V * EBV
    A_lambda = A_V * (a + b / R_V)

    funred = flux * 10. ** (0.4 * A_lambda)

    return funred
```


Overlapping Code:
```
 = np.array(flux)
x = 10000. / wave # Convert to inverse microns
npts = len(x)
a = np.zeros(npts)
b = np.zeros(npts)
good = np.where((x > 0.3) & (x < 1.1))[0] # Infrared
if len(good) > 0:
a[good] = 0.574 * x[good] ** (1.61)
b[good] = -0.527 * x[good] ** (1.61)
good = np.where((x >= 1.1) & (x < 3.3)) # Optical/NIR
if len(good[0]) > 0:
y = x[good] - 1.82
c1 = np.array([1., 0.104, -0.609, 0.701, 1.137, -1.718, -0.827,
1.647, -0.505]) # From O'Donnell (1994)
c2 = np.array([0., 1.952, 2.908, -3.989, -7.985, 11.102,
5.491, -10.805, 3.347])
a[good] = np.polyval(c1[::-1], y)
b[good] = np.polyval(c2[::-1], y)
good = np.where((x >= 3.3) & (x < 8))[0] # Mid-UV
if len(good) > 0:
y = x[good]
F_a = np.zeros(len(good))
F_b = np.zeros(len(good))
good1 = np.where(y > 5.9)
if len(good1) > 0:
y1 = y[good1] - 5.9
F_a[good1] = -0.04473 * y1 ** 2 - 0.009779 * y1 ** 3
F_b[good1] = 0.2130 * y1 ** 2 + 0.1207 * y1 ** 3
a[good] = 1.752 - 0.316 * y - (0.104 / ((y - 4.67)**2 + 0.341)) + F_a
b[good] = -3.090 + 1.825 * y + (1.206 / ((y - 4.62)**2 + 0.263)) + F_b
good = np.where((x >= 8) & (x <= 11))[0] # Far-UV
if len(good) > 0:
y = x[good] - 8.
c1 = np.array([-1.073, -0.628, 0.137, -0.070])
c2 = np.array([13.670, 4.257, -0.420, 0.374])
a[good] = np.polyval(c1[::-1], y)
b[good] = np.polyval(c2[::-1], y)
A_V = R_V * EBV
A_lambda = A_V * (a + b / R_V)
funred = 
```
<Overlap Ratio: 0.9388038942976356>

---

--- 18 --
Question ID: dae114589dc9b5d7656022e074c5f0eb58b326c1_0
Original Code:
```
def get_base_connectors(tiles):
    """
    Places basic connectors for rooms,
    single door or double door, using the middle
    :param tiles: The tiles to evaluate
    :return: The Connector Dict
    """
    height = len(tiles) - 1
    width = max((len(row) for row in tiles)) - 1
    center_width = int(width / 2)
    center_height = int(height / 2)
    return {
        Direction.North: (
            connectors.DungeonSingleDoor((center_width, 0)),
            connectors.DungeonDoubleDoor(
                (center_width, 0),
                (center_width + 1, 0)
            ),
        ),
        Direction.South: (
            connectors.DungeonSingleDoor((center_width, height)),
            connectors.DungeonDoubleDoor(
                (center_width, height),
                (center_width + 1, height)
            ),
        ),
        Direction.East: (
            connectors.DungeonSingleDoor((width, center_height)),
            connectors.DungeonDoubleDoor(
                (width, center_height),
                (width + 1, center_height),
            ),
        ),
        Direction.West: (
            connectors.DungeonSingleDoor((0, center_height)),
            connectors.DungeonDoubleDoor(
                (0, center_height),
                (0, center_height),
            ),
        )
    }
```


Overlapping Code:
```
nectors(tiles):
"""
Places basic connectors for rooms,
single door or double door, using the middle
:param tiles: The tiles to evaluate
:return: The Connector Dict
"""
height = len(tiles) - 1
width = max((len(row) for row in tiles)) - 1
center_width = int(width / 2)
center_height = int(height / 2)
return {
Direction.North: (
connectors.DungeonSingleDoor((center_width, 0)),
connectors.DungeonDoubleDoor(
(center_width, 0),
(center_width + 1, 0)
),
),
Direction.South: (
connectors.DungeonSingleDoor((center_width, height)),
connectors.DungeonDoubleDoor(
(center_width, height),
(center_width + 1, height)
),
),
Direction.East: (
connectors.DungeonSingleDoor((width, center_height)),
connectors.DungeonDoubleDoor(
(width, center_height),
(width + 1, center_height),
),
),
Direction.West: (
connectors.DungeonSingleDoor((0, center_height)),
connectors.DungeonDoubleDoor(
(0, center_height),
(0, cente
```
<Overlap Ratio: 0.9646302250803859>

---

--- 19 --
Question ID: eba211ec623ebe87dd4049f9d60b910827efdef1_1
Original Code:
```
def test_mod_get() :
    '''
    >>> test_mod_get()
    Initialization.
    Module: <<multiagent.Module memory_size=0>>
    Position: None
    Angle: None
    Velocity: None
    Angular Velocity: None
    Force: None
    Color: None
    Radio In Messages: []
    Radio Out Message: None
    Radar Detect: []
    Radar Distance: None
    '''
    print("Initialization.")
    mod = Module()
    print("Module: %s" % mod.info())
    print("Position: %s" % mod.get_pos())
    print("Angle: %s" % mod.get_angle())
    print("Velocity: %s" % mod.get_vel())
    print("Angular Velocity: %s" % mod.get_avel())
    print("Force: %s" % mod.get_force())
    print("Color: %s" % mod.get_color())
    print("Radio In Messages: %s" % mod.get_radio_in_msgs())
    print("Radio Out Message: %s" % mod.get_radio_out_msg())
    print("Radar Detect: %s" % mod.get_radar_detect())
    print("Radar Distance: %s" % mod.get_radar_dist())
```


Overlapping Code:
```
st_mod_get()
Initialization.
Module: <<multiagent.Module memory_size=0>>
Position: None
Angle: None
Velocity: None
Angular Velocity: None
Force: None
Color: None
Radio In Messages: []
Radio Out Message: None
Radar Detect: []
Radar Distance: None
'''
print("Initialization.")
mod = Module()
print("Module: %s" % mod.info())
print("Position: %s" % mod.get_pos())
print("Angle: %s" % mod.get_angle())
print("Velocity: %s" % mod.get_vel())
print("Angular Velocity: %s" % mod.get_avel())
print("Force: %s" % mod.get_force())
print("Color: %s" % mod.get_color())
print("Radio In Messages: %s" % mod.get_radio_in_msgs())
print("Radio Out Message: %s" % mod.get_radio_out_msg())
print("Radar Detect: %s" % mod.get_radar_detect())
print("Radar Distance: %s" %
```
<Overlap Ratio: 0.933997509339975>

---

--- 20 --
Question ID: ad98b1576f343fcacd3cbee72169b039a416cdf4_8
Original Code:
```
def test_that_viewspec_prints_help_format(capsys):

    rc = perform_viewspec(["help-format"])
    sys_out_lines, sys_err_lines = capsys.readouterr()

    assert 1 == rc

    # print ">>>" + "
".join(sys_out_lines) + "<<<<"

    expected =       """Viewspec File Format
====================

The viewspec file format used by this tool is a collection of headers
(using the typical one-per-line name:value syntax), followed by an
empty line, followed by a set of one-per-line rules.

The headers must contain at least the following:

    Format   - version of the viewspec format used throughout the file
    Url      - base URL applied to all rules; tree checkout location

The following headers are optional:

    Revision - version of the tree items to checkout

Following the headers and blank line separator are the path rules.
The rules are list of URLs -- relative to the base URL stated in the
headers -- with optional annotations to specify the desired working
copy depth of each item:

    PATH/**  - checkout PATH and all its children to infinite depth
    PATH/*   - checkout PATH and its immediate children
    PATH/~   - checkout PATH and its file children
    PATH     - checkout PATH non-recursively

By default, the top-level directory (associated with the base URL) is
checked out with empty depth.  You can override this using the special
rules '**', '*', and '~' as appropriate.

It is not necessary to explicitly list the parent directories of each
path associated with a rule.  If the parent directory of a given path
is not "covered" by a previous rule, it will be checked out with empty
depth.

Examples
========

Here's a sample viewspec file:

    Format: 1
    Url: http://svn.apache.org/repos/asf/subversion
    Revision: 36366

    trunk/**
    branches/1.5.x/**
    branches/1.6.x/**
    README
    branches/1.4.x/STATUS
    branches/1.4.x/subversion/tests/cmdline/~

You may wish to version your viewspec files.  If so, you can use this
script in conjunction with 'svn cat' to fetch, parse, and act on a
versioned viewspec file:

    $ svn cat http://svn.example.com/specs/dev-spec.txt |
         __SCRIPTNAME__ checkout - /path/to/target/directory
         """.replace("__SCRIPTNAME__", __SCRIPTNAME__)

    all_the_lines_should_be_the_same(expected, sys_out_lines)

    all_the_lines_should_be_the_same([], sys_err_lines)

```


Overlapping Code:
```
est_that_viewspec_prints_help_format(capsys):
rc = perform_viewspec(["help-format"])
sys_out_lines, sys_err_lines = capsys.readouterr()
assert 1 == rcle Format
====================
The viewspec file format used by this tool is a collection of headers
(using the typical one-per-line name:value syntax), followed by an
empty line, followed by a set of one-per-line rules.
The headers must contain at least the following:
Format - version of the viewspec format used throughout the file
Url - base URL applied to all rules; tree checkout location
The following headers are optional:
Revision - version of the tree items to checkout
Following the headers and blank line separator are the path rules.
The rules are list of URLs -- relative to the base URL stated in the
headers -- with optional annotations to specify the desired working
copy depth of each item:
PATH/** - checkout PATH and all its children to infinite depth
PATH/* - checkout PATH and its immediate children
PATH/~ - checkout PATH and its file children
PATH - checkout PATH non-recursively
By default, the top-level directory (associated with the base URL) is
checked out with empty depth. You can override this using the special
rules '**', '*', and '~' as appropriate.
It is not necessary to explicitly list the parent directories of each
path associated with a rule. If the parent directory of a given path
is not "covered" by a previous rule, it will be checked out with empty
depth.
Examples
========
Here's a sample viewspec file:
Format: 1
Url: http://svn.apache.org/repos/asf/subversion
Revision: 36366
trunk/**
branches/1.5.x/**
branches/1.6.x/**
README
branches/1.4.x/STATUS
branches/1.4.x/subversion/tests/cmdline/~
You may wish to version your viewspec files. If so, you can use this
script in conjunction with 'svn cat' to fetch, parse, and act on a
versioned viewspec file:
$ svn cat http://svn.example.com/specs/dev-spec.txt |
__SCRIPTNAME__ checkout - /path/to/target/directory
""".replace("__SCRIPTNAME__", __SCRIPTNAME__)
all_the_lines_should_be_the_same(expected, sys_out_lines)
all_the_lines_should_be_the_same([], sys_err_lines)
```
<Overlap Ratio: 0.9635202918376653>

---

--- 21 --
Question ID: 22736bbda1d169aac567567dd0013574d0991d3d_1
Original Code:
```
def doc(*args):
    '''
    Return the docstrings for all modules. Optionally, specify a module or a
    function to narrow the selection.

    The strings are aggregated into a single document on the master for easy
    reading.

    Multiple modules/functions can be specified.

    CLI Example:

    .. code-block:: bash

        salt '*' sys.doc
        salt '*' sys.doc sys
        salt '*' sys.doc sys.doc
        salt '*' sys.doc network.traceroute user.info
    '''
    docs = {}
    if not args:
        for fun in __salt__:
            docs[fun] = __salt__[fun].__doc__
        return _strip_rst(docs)

    for module in args:
        if module:
            # allow both "sys" and "sys." to match sys, without also matching
            # sysctl
            target_mod = module + '.' if not module.endswith('.') else module
        else:
            target_mod = ''
        for fun in __salt__:
            if fun == module or fun.startswith(target_mod):
                docs[fun] = __salt__[fun].__doc__
    return _strip_rst(docs)
```


Overlapping Code:
```
def doc(*args):
'''
Return the docstrings for all modules. Optionally, specify a module or a
function to narrow the selection.
The strings are aggregated into a single document on the master for easy
reading.
Multiple modules/functions can be specified.
CLI Example:
.. code-block:: bash
salt '*' sys.doc
salt '*' sys.doc sys
salt '*' sys.doc sys.doc
salt '*' sys.doc network.traceroute user.info
'''
docs = {}
if not args:
for fun in __salt__:
docs[fun] = __salt__[fun].__doc__
return _strip_rst(docs)
for module in args:
if module:
# allow both "sys" and "sys." to match sys, without also matching
# sysctl
target_mod = module + '.' if not module.endswith('.') else module
else:
target_mod = ''
for fun in __salt__:
if fun == module or fun.startswith(target_mod):
docs[fun] = __salt__[fun].__doc__
return _strip_rst(do
```
<Overlap Ratio: 0.9963547995139733>

---

--- 22 --
Question ID: 10d8af270631cf45c1e1bdca2e88d6528cfd84cf_0
Original Code:
```
def test_Cluster_inputs():
    input_map = dict(
        args=dict(argstr='%s', ),
        connectivity=dict(argstr='--connectivity=%d', ),
        cope_file=dict(
            argstr='--cope=%s',
            extensions=None,
        ),
        dlh=dict(argstr='--dlh=%.10f', ),
        environ=dict(
            nohash=True,
            usedefault=True,
        ),
        find_min=dict(
            argstr='--min',
            usedefault=True,
        ),
        fractional=dict(
            argstr='--fractional',
            usedefault=True,
        ),
        in_file=dict(
            argstr='--in=%s',
            extensions=None,
            mandatory=True,
        ),
        minclustersize=dict(
            argstr='--minclustersize',
            usedefault=True,
        ),
        no_table=dict(
            argstr='--no_table',
            usedefault=True,
        ),
        num_maxima=dict(argstr='--num=%d', ),
        out_index_file=dict(
            argstr='--oindex=%s',
            hash_files=False,
        ),
        out_localmax_txt_file=dict(
            argstr='--olmax=%s',
            hash_files=False,
        ),
        out_localmax_vol_file=dict(
            argstr='--olmaxim=%s',
            hash_files=False,
        ),
        out_max_file=dict(
            argstr='--omax=%s',
            hash_files=False,
        ),
        out_mean_file=dict(
            argstr='--omean=%s',
            hash_files=False,
        ),
        out_pval_file=dict(
            argstr='--opvals=%s',
            hash_files=False,
        ),
        out_size_file=dict(
            argstr='--osize=%s',
            hash_files=False,
        ),
        out_threshold_file=dict(
            argstr='--othresh=%s',
            hash_files=False,
        ),
        output_type=dict(),
        peak_distance=dict(argstr='--peakdist=%.10f', ),
        pthreshold=dict(
            argstr='--pthresh=%.10f',
            requires=['dlh', 'volume'],
        ),
        std_space_file=dict(
            argstr='--stdvol=%s',
            extensions=None,
        ),
        threshold=dict(
            argstr='--thresh=%.10f',
            mandatory=True,
        ),
        use_mm=dict(
            argstr='--mm',
            usedefault=True,
        ),
        volume=dict(argstr='--volume=%d', ),
        warpfield_file=dict(
            argstr='--warpvol=%s',
            extensions=None,
        ),
        xfm_file=dict(
            argstr='--xfm=%s',
            extensions=None,
        ),
    )
    inputs = Cluster.input_spec()

    for key, metadata in list(input_map.items()):
        for metakey, value in list(metadata.items()):
            assert getattr(inputs.traits()[key], metakey) == value

```


Overlapping Code:
```
st_Cluster_inputs():
input_map = dict(
args=dict(argstr='%s', ),
connectivity=dict(argstr='--connectivity=%d', ),
cope_file=dict(
argstr='--cope=%s',
extensions=None,
),
dlh=dict(argstr='--dlh=%.10f', ),
environ=dict(
nohash=True,
usedefault=True,
),
find_min=dict(
argstr='--min',
usedefault=True,
),
fractional=dict(
argstr='--fractional',
usedefault=True,
),
in_file=dict(
argstr='--in=%s',
extensions=None,
mandatory=True,
),
minclustersize=dict(
argstr='--minclustersize',
usedefault=True,
),
no_table=dict(
argstr='--no_table',
usedefault=True,
),
num_maxima=dict(argstr='--num=%d', ),
out_index_file=dict(
argstr='--oindex=%s',
hash_files=False,
),
out_localmax_txt_file=dict(
argstr='--olmax=%s',
hash_files=False,
),
out_localmax_vol_file=dict(
argstr='--olmaxim=%s',
hash_files=False,
),
out_max_file=dict(
argstr='--omax=%s',
hash_files=False,
),
out_mean_file=dict(
argstr='--omean=%s',
hash_files=False,
),
out_pval_file=dict(
argstr='--opvals=%s',
hash_files=False,
),
out_size_file=dict(
argstr='--osize=%s',
hash_files=False,
),
out_threshold_file=dict(
argstr='--othresh=%s',
hash_files=False,
),
output_type=dict(),
peak_distance=dict(argstr='--peakdist=%.10f', ),
pthreshold=dict(
argstr='--pthresh=%.10f',
requires=['dlh', 'volume'],
),
std_space_file=dict(
argstr='--stdvol=%s',
extensions=None,
),
threshold=dict(
argstr='--thresh=%.10f',
mandatory=True,
),
use_mm=dict(
argstr='--mm',
usedefault=True,
),
volume=dict(argstr='--volume=%d', ),
warpfield_file=dict(
argstr='--warpvol=%s',
extensions=None,
),
xfm_file=dict(
argstr
```
<Overlap Ratio: 0.9766855702583491>

---

--- 23 --
Question ID: 918ab2735794b082c2165714e70722c28913def1_11
Original Code:
```
def get_rep_frags(frags, loci, loci_ids, num_reps=4, no_cache=False):
    """Get a number of representatives for each cluster

    [description]

    Arguments:
        frags {list} -- List of numpy arrays representing the fragment
        num_reps {int} -- Number of representatives
    """
    num_frags = len(frags)

    if num_frags < 5:
        sizes = np.zeros([num_frags])

        for i, frag in enumerate(frags):
            sizes[i] = np.prod(frag.shape[0:2])

        idx = np.argsort(sizes).astype(np.uint8)[::-1]

        return [frags[i] for i in idx], idx

    out, _, _ = get_scale_frags_to_same_size(
        frags, loci_ids, 32, no_cache
    )

    # Get largest frag based on world coords
    largest_a = 0
    for i, locus in enumerate(loci):
        a = abs(locus[1] - locus[0]) * abs(locus[3] - locus[2])
        if a > largest_a:
            largest_a = a
            largest_frag_idx = i

    mean_frag = np.nanmean(out, axis=0)
    diff_mean_frags = out - mean_frag

    # Sum each x,y and c (channel) value up per f (fragment) and take the
    # sqaure root to get the L2 norm
    dist_to_mean = np.sqrt(
        np.einsum('fxyc,fxyc->f', diff_mean_frags, diff_mean_frags)
    )

    # Get the fragment closest to the mean
    # Get the index of the i-th smallest value i=0 == smallest value
    closest_mean_frag_idx = np.argpartition(dist_to_mean, 0)[0]
    if closest_mean_frag_idx == largest_frag_idx:
        closest_mean_frag_idx = np.argpartition(dist_to_mean, 1)[1]

    # Get the frag farthest away from
    for i in range(len(dist_to_mean) - 1, -1, -1):
        farthest_mean_frag_idx = np.argpartition(dist_to_mean, i)[i]
        if (
            farthest_mean_frag_idx != largest_frag_idx and
            farthest_mean_frag_idx != closest_mean_frag_idx
        ):
            break

    # Distance to farthest away frag
    diff_farthest_frags = out - out[np.argmax(dist_to_mean)]
    dist_to_farthest = np.sqrt(
        np.einsum('fxyc,fxyc->f', diff_farthest_frags, diff_farthest_frags)
    )

    # Get the frag farthest away from the frag farthest away from the mean
    for i in range(len(dist_to_farthest) - 1, -1, -1):
        farthest_farthest_frag_idx = np.argpartition(dist_to_farthest, i)[i]
        if (
            farthest_farthest_frag_idx != largest_frag_idx and
            farthest_farthest_frag_idx != closest_mean_frag_idx and
            farthest_farthest_frag_idx != farthest_mean_frag_idx
        ):
            break

    frags = [
        frags[largest_frag_idx],
        frags[closest_mean_frag_idx],
        frags[farthest_mean_frag_idx],
        frags[farthest_farthest_frag_idx]
    ]

    idx = [
        largest_frag_idx,
        closest_mean_frag_idx,
        farthest_mean_frag_idx,
        farthest_farthest_frag_idx
    ]

    return frags, idx
```


Overlapping Code:
```
s, num_reps=4, no_cache=False):
"""Get a number of representatives for each cluster
[description]
Arguments:
frags {list} -- List of numpy arrays representing the fragment
num_reps {int} -- Number of representatives
"""
num_frags = len(frags)
if num_frags < 5:
sizes = np.zeros([num_frags])
for i, frag in enumerate(frags):
sizes[i] = np.prod(frag.shape[0:2])
idx = np.argsort(sizes).astype(np.uint8)[::-1]
return [frags[i] for i in idx], idx
out, _, _ = get_scale_frags_to_same_size(
frags, loci_ids, 32, no_cache
)
# Get largest frag based on world coords
largest_a = 0
for i, locus in enumerate(loci):
a = abs(locus[1] - locus[0]) * abs(locus[3] - locus[2])
if a > largest_a:
largest_a = a
largest_frag_idx = i
mean_frag = np.nanmean(out, axis=0)
diff_mean_frags = out - mean_frag
# Sum each x,y and c (channel) value up per f (fragment) and take the
# sqaure root to get the L2 norm
dist_to_mean = np.sqrt(
np.einsum('fxyc,fxyc->f', diff_mean_frags, diff_mean_frags)
)
# Get the fragment closest to the mean
# Get the index of the i-th smallest value i=0 == smallest value
closest_mean_frag_idx = np.argpartition(dist_to_mean, 0)[0]
if closest_mean_frag_idx == largest_frag_idx:
closest_mean_frag_idx = np.argpartition(dist_to_mean, 1)[1]
# Get the frag farthest away from
for i in range(len(dist_to_mean) - 1, -1, -1):
farthest_mean_frag_idx = np.argpartition(dist_to_mean, i)[i]
if (
farthest_mean_frag_idx != largest_frag_idx and
farthest_mean_frag_idx != closest_mean_frag_idx
):
break
# Distance to farthest away frag
diff_farthest_frags = out - out[np.argmax(dist_to_mean)]
dist_to_farthest = np.sqrt(
np.einsum('fxyc,fxyc->f', diff_farthest_frags, diff_farthest_frags)
)
# Get the frag farthest away from the frag farthest away from the mean
for i in range(len(dist_to_farthest) - 1, -1, -1):
farthest_farthest_frag_idx = np.argpartition(dist_to_farthest, i)[i]
if (
farthest_farthest_frag_idx != largest_frag_idx and
farthest_farthest_frag_idx != closest_mean_frag_idx and
farthest_farthest_frag_idx != farthest_mean_frag_idx
):
break
frags 
```
<Overlap Ratio: 0.9804202483285578>

---

--- 24 --
Question ID: 6fe7e0b26af6a6ead0ebd871ebcc5206fb1fcece_13
Original Code:
```
@bot.command(pass_context=True)
async def dog(ctx):
    '''Check out a random cute or funny dog!\nUsage: !dog\nAliases: None\nPermissions: None'''
    r = requests.get(f'https://api.thedogapi.co.uk/v2/dog.php/')
    json = r.json()
    if r.status_code == 200:
        sdog = discord.Embed(title='Dog', description='A random cute dog!', color=0x00FF00)
        sdog.set_author(name=f'{ctx.message.author.display_name}', icon_url=f'{ctx.message.author.avatar_url}')
        sdog.set_image(url=json['data'][0]['url'])
        sdog.set_footer(text='Dogs by http://thedogapi.co.uk/!')
        return await bot.say(embed=sdog)
    else:
        rdog = discord.Embed(title='Error', description='I could not access the API! Direct Message Pointless#1278 so this can be fixed! (You will be credited for finding it out!)', color=0xFF0000)
        rdog.set_author(name=f'{ctx.message.author.display_name}', icon_url=f'{ctx.message.author.avatar_url}')
        return await bot.say(embed=rdog)
```


Overlapping Code:
```
set_author(name=f'{ctx.message.author.display_name}', icon_url=f'{ctx.message.author.avatar_url}')set_author(name=f'{ctx.message.author.display_name}', icon_url=f'{ctx.message.author.avatar_url}')
return await bot.say(embed=
```
<Overlap Ratio: 0.24944320712694878>

---

--- 25 --
Question ID: 83d0fd24c824480938c493ec8afd0bfbc45d9062_0
Original Code:
```
def load_data(shuffle=True, n_cols=None):
    train_path = get_p1_file('http://ftp.mcs.anl.gov/pub/candle/public/benchmarks/P1B1/P1B1.train.csv')
    test_path = get_p1_file('http://ftp.mcs.anl.gov/pub/candle/public/benchmarks/P1B1/P1B1.test.csv')

    usecols = list(range(n_cols)) if n_cols else None

    df_train = pd.read_csv(train_path, engine='c', usecols=usecols)
    df_test = pd.read_csv(test_path, engine='c', usecols=usecols)

    df_train = df_train.drop('case_id', 1).astype(np.float32)
    df_test = df_test.drop('case_id', 1).astype(np.float32)

    if shuffle:
        df_train = df_train.sample(frac=1, random_state=seed)
        df_test = df_test.sample(frac=1, random_state=seed)

    X_train = df_train.as_matrix()
    X_test = df_test.as_matrix()

    scaler = MaxAbsScaler()
    mat = np.concatenate((X_train, X_test), axis=0)
    mat = scaler.fit_transform(mat)

    X_train = mat[:X_train.shape[0], :]
    X_test = mat[X_train.shape[0]:, :]

    return X_train, X_test
```


Overlapping Code:
```
s=None):
train_path = get_p1_file('http://ftp.mcs.anl.gov/pub/candle/public/benchmarks/P1B1/P1B1.train.csv')
test_path = get_p1_file('http://ftp.mcs.anl.gov/pub/candle/public/benchmarks/P1B1/P1B1.test.csv')
usecols = list(range(n_cols)) if n_cols else None
df_train = pd.read_csv(train_path, engine='c', usecols=usecols)
df_test = pd.read_csv(test_path, engine='c', usecols=usecols)
df_train = df_train.drop('case_id', 1).astype(np.float32)
df_test = df_test.drop('case_id', 1).astype(np.float32)
if shuffle:
df_train = df_train.sample(frac=1, random_state=seed)
df_test = df_test.sample(frac=1, random_state=seed)
X_train = df_train.as_matrix()
X_test = df_test.as_matrix()
scaler = MaxAbsScaler()
mat = np.concatenate((X_train, X_test), axis=0)
mat = scaler.fit_transform(mat)
X_train = mat[:X_train.shape[0], :]
X_test = mat[X_train.shape[0]:, :]
return X_train,
```
<Overlap Ratio: 0.9558011049723757>

---

--- 26 --
Question ID: 17870da4921bac8774076b766611ff5de08b7172_8
Original Code:
```
def create_actor_with_or_without_sso_account(
    context: Context, actor_aliases: str, has_or_does_not_have: str
):
    actor_aliases = [alias.strip() for alias in actor_aliases.split(",")]
    for actor_alias in actor_aliases:
        if has_or_does_not_have in ["has", "have"]:
            actor = get_actor(context, actor_alias)
            account = Account("verified Individual")
            profile_enrol_individual(context, actor, account=account)
        else:
            supplier = unauthenticated_supplier(actor_alias)
            add_actor(context, supplier)
```


Overlapping Code:
```
count(
context: Context, actor_aliases: str, has_or_does_not_have: str
):
actor_aliases = [alias.strip() for alias in actor_aliases.split(",")]
for actor_alias in actor_aliases:
if has_or_does_not_have in ["has", "have"]:
actor = get_actor(context, actor_alias)
account = Account("verified Individual")
profile_enrol_individual(context, actor, account=account)
else:
supplier = unauthenticated_suppli
```
<Overlap Ratio: 0.8281573498964804>

---

--- 27 --
Question ID: 4d7cc775f00b1b11a0c08dffa7ffc626adaef5d6_5
Original Code:
```
def strip_leader(s, prefix):
    """Remove given prefix from underscored name."""
    leader = prefix + "_"
    if s.startswith(leader):
        return s[len(leader) :]
    else:
        return s
```


Overlapping Code:
```
en prefix from underscored name."""
leader = prefix + "_"
if s.startswith(leader):
return s[len(lead
```
<Overlap Ratio: 0.6134969325153374>

---

--- 28 --
Question ID: 309ccd53e1e00c54829cda0b87d065c0ada74854_3
Original Code:
```
def t_COLON(t):
    r":"
    t.value = ":"
    return t
```


Overlapping Code:
```

```
<Overlap Ratio: 0.0>

---

--- 29 --
Question ID: be10fad1a82c3d77b9214d5fb02e516227b5fbc7_25
Original Code:
```
def up(interface, iface_type=None):  # pylint: disable=invalid-name,unused-argument
    '''
    Enable the specified interface

    Change adapter mode to TCP/IP. If previous adapter mode was EtherCAT, the target will need reboot.

    :param str interface: interface label
    :return: True if the service was enabled, otherwise an exception will be thrown.
    :rtype: bool

    CLI Example:

    .. code-block:: bash

        salt '*' ip.up interface-label
    '''
    return _change_state(interface, 'up')
```


Overlapping Code:
```
=None): # pylint: disable=invalid-name,unused-argument
'''
Enable the specified interface
Change adapter mode to TCP/IP. If previous adapter mode was EtherCAT, the target will need reboot.
:param str interface: interface label
:return: True if the service was enabled, otherwise an exception will be thrown.
:rtype: bool
CLI Example:
.. code-block:: bash
salt '*' ip.up interface-label
'''
return _change_state(interface,
```
<Overlap Ratio: 0.9252747252747253>

---

--- 30 --
Question ID: e6f51f4eea05df238f553a0d9a0d19499c5001c1_10
Original Code:
```
def test_service_connect__no_name_given():
    runtime = BaseCumulusCI(
        config={
            "services": {"test-type": {"attributes": {"attr": {"required": False}}}}
        }
    )

    result = run_cli_command("service", "connect", "test-type", runtime=runtime)

    # service_name is None, so the alias when setting the service should be 'default'
    assert (
        "No service name specified. Using 'default' as the service name."
        in result.output
    )
    assert "default" in runtime.keychain.list_services()["test-type"]
```


Overlapping Code:
```
_service_connect__no_name_given():
runtime = BaseCumulusCI(
config={
"services": {"test-type": {"attributes": {"attr": {"required": False}}}}
}
)
result = run_cli_command("service", "connect", "test-type", runtime=runtime)
# service_name is None, so the alias when setting the service should be 'default'
assert (
"No service name specified. Using 'default' as the service name."
in result.output
)
assert "default" in runtime.keychain.list_services(
```
<Overlap Ratio: 0.9533898305084746>

---

--- 31 --
Question ID: 495cfdfe0cf21298881ddfe6ecb70dadde1e1e2d_1
Original Code:
```
def find_posts(path):
    def root_to_directory_name(root):
        x = os.path.join(root, "") # Forces a trailing \ or / depending on the OS
        return os.path.basename(os.path.dirname(x)) 

    def process_folder(root, files):
        if root.endswith("thumbnails"): 
            return None

        images = []
        for image in files:
            full_path = os.path.join(root, image)
            images.append(full_path)

        return images
        

    posts = {}
    for root, dirs, files in os.walk(path):
        images = process_folder(root, files)

        if images:
            relative_folder = root_to_directory_name(root)
            posts[relative_folder] = images
    return posts
```


Overlapping Code:
```
root):
x = os.path.join(root, "") # Forces a trailing \ or / depending on the OS
return os.path.basename(os.path.dirname(x)) 
def process_folder(root, files):
if root.endswith("thumbnails"): 
return None
images = []
for image in files:
full_path = os.path.join(root, image)
images.append(full_path)
return images

posts = {}
for root, dirs, files in os.walk(path):
images = process_folder(root, files)
if images:
relative_folder = root_to_directory_name(root)
posts[relative_folder] = images
return p
```
<Overlap Ratio: 0.9041591320072333>

---

--- 32 --
Question ID: 0f52dba356db45cc2f7bfa252ba3ac7775d838c8_10
Original Code:
```
@my_decorator3
def greet4(message):
    """
    greet4
    :param message:
    :return:
    """
    print(message)
```


Overlapping Code:
```

```
<Overlap Ratio: 0.0>

---

--- 33 --
Question ID: bf2ad86e797c921b9ad0d196307756a1b5568545_1
Original Code:
```
def get_interventi():
    with get_cursor() as cur:
        cur.execute("SELECT id, titolo FROM INTERVENTO")
        return list(cur)
```


Overlapping Code:
```
f get_interventi():
with get_cursor() as cur:
cur.execute("SELECT id, titolo FROM INTERVENTO")
retur
```
<Overlap Ratio: 0.8849557522123894>

---

--- 34 --
Question ID: 2b053e5ce8173dec6b079e08e571935d22125f2f_0
Original Code:
```
@FFF_POST.route('/api/v1/orders', methods=['POST'])
def place_order():
    """
     method to create new order and apend to the existing list
    """
    if request.method == 'POST':
        data = request.get_json()
        if not data.get('order_number'):
            return FeedbackResponse.display("set order number please", 406)
        if not data.get('order_description'):
            return FeedbackResponse.display("set description please", 406)
        if not data.get('size'):
            return FeedbackResponse.display("set size please ", 406)
        if not data.get('order_price'):
            return FeedbackResponse.display("set price please", 406)
        order_number = data.get('order_number')
        order_description = data.get('order_description')
        order_price = data.get('order_price')
        size = data.get('size')

        new_order = Order(order_number, order_description,
                          order_price, size)

        customer_orders.place_order(new_order)
        return FeedbackResponse.display(
            "order number " +
            order_number +
            " successfully placed",
            200)
```


Overlapping Code:
```
@FFF_POST.route('/api/v1/orders', methods=['POST'])
def place_order():
"""
method to create new order and apend to the existing list
"""
if request.method == 'POST':
data = request.get_json()
if not data.get('order_number'):
return FeedbackResponse.display("set order number please", 406)
if not data.get('order_description'):
return FeedbackResponse.display("set description please", 406)
if not data.get('size'):
return FeedbackResponse.display("set size please ", 406)
if not data.get('order_price'):
return FeedbackResponse.display("set price please", 406)
order_number = data.get('order_number')
order_description = data.get('order_description')
order_price = data.get('order_price')
size = data.get('size')
new_order = Order(order_number, order_description,
order_price, size)
customer_orders.place_order(new_order)
return FeedbackResponse.display(
"order number " +
order_number +
" successful
```
<Overlap Ratio: 0.982532751091703>

---

--- 35 --
Question ID: 053ae384f11b6fdb22643bfae8e5b0e0d8d4af29_0
Original Code:
```
def loadtxt(filename):
    file = np.loadtxt(filename, delimiter='\t')
    nm = file[1:, 0]
    time = file[0, 1:]
    data = file[1:, 1:]
    
    return nm, time, data
```


Overlapping Code:
```
filename):
file = np.loadtxt(filename, delimiter='\t')
nm = file[1:, 0]
time = file[0, 1:]
data = file[1:, 1:]

return nm, ti
```
<Overlap Ratio: 0.8620689655172413>

---

--- 36 --
Question ID: a6f83601c8b553a2f1d6b3e593f62fdfefa0bb7d_0
Original Code:
```
def validate_feedcode_chars(feedcode):
    """Raise an exception if we contain unapproved characters."""
    for c in feedcode:
        if c not in settings.VALID_CHARS:
            raise ValidationError(u"{} is not a valid character.".format(c))
```


Overlapping Code:
```
dcode_chars(feedcode):
"""Raise an exception if we contain unapproved characters."""
for c in feedcode:
if c not in settings.VALID_CHARS:
raise ValidationError(u"{} is not a valid character.".format(c
```
<Overlap Ratio: 0.9174311926605505>

---

--- 37 --
Question ID: 0bf992a42d350a6bdf5fe8e1f0e2fc0b740a73e3_27
Original Code:
```
def distanz(id1, id2):
    x1, y1 = hole_koord(id1)
    x2, y2 = hole_koord(id2)
    return sqrt((x2 -x1) ** 2 + (y2 - y1) ** 2)
```


Overlapping Code:
```
rd(id1)
x2, y2 = hole_koord(id2)
return sqrt((x2 -
```
<Overlap Ratio: 0.43103448275862066>

---

--- 38 --
Question ID: f3e572c7d77ef35ad25253d0adfa09f6260c2cb7_4
Original Code:
```
def display_capital(investment_length, added_yearly, initial_capital):
    total_capital = round(initial_capital + (investment_length*added_yearly))
    formatted_capital = str(format(total_capital, ",d"))
    results_string = ("Total Invesment Capital: $" + formatted_capital)
    CAPITAL_VAR.set(results_string)
```


Overlapping Code:
```
ef display_capital(investment_length, added_yearly, initial_capital):
total_capital = round(initial_capital + (investment_length*added_yearly))
formatted_capital = str(format(total_capital, ",d"))
results_string = ("Total Invesment Capital: $" + form
```
<Overlap Ratio: 0.8417508417508418>

---

--- 39 --
Question ID: a8fe82ce71a4845dcf222f6cdbdf250abebb61ac_1
Original Code:
```
def size(device):
    """ return the size of the device in bytes

        This is fastest most efficient method as os.lseek() calls just
        set the fd->offset, and os.SEEK_END asks the kernel for the
        end of the device """
    fd = os.open(device, os.O_RDONLY)
    try:
        return os.lseek(fd, 0, os.SEEK_END)
    finally:
        os.close(fd)
```


Overlapping Code:
```
he device in bytes
This is fastest most efficient method as os.lseek() calls just
set the fd->offset, and os.SEEK_END asks the kernel for the
end of the device """
fd = os.open(device, os.O_RDONLY)
try:
return os.lseek(fd, 0, os.SEEK_END)
finally:
os.close(fd
```
<Overlap Ratio: 0.8576158940397351>

---

--- 40 --
Question ID: 90350a12c6bbab1041e72554c0000f43e3f679b0_1
Original Code:
```
def calc_sum(A, x):
    ret = 0
    for i, a in enumerate(A):
        ret += abs(x - i) * a
    return ret
```


Overlapping Code:
```
for i, a in enumerate(A):
ret += abs(x - i) * a
re
```
<Overlap Ratio: 0.5813953488372093>

---

--- 41 --
Question ID: d0a342dd9bc21f5a13452e59322a4a47220800d5_1
Original Code:
```
def get_simulated_distribution(n, k, sampler_name, num_trials):
    if sampler_name == 'right':
        Sampler = PacketSampler
    elif sampler_name == 'wrong':
        Sampler = PacketSamplerWrong
    else:
        raise ValueError('Unrecognized sampler name.')
    
    packet_counter = {p: 0 for p in range(n)}
    for trial_ind in range(num_trials):
        subset = get_packet_subset(n, Sampler(k))
        for p in subset:
            packet_counter[p] += 1
    
    return packet_counter
```


Overlapping Code:
```
e, num_trials):
if sampler_name == 'right':
Sampler = PacketSampler
elif sampler_name == 'wrong':
Sampler = PacketSamplerWrong
else:
raise ValueError('Unrecognized sampler name.')

packet_counter = {p: 0 for p in range(n)}
for trial_ind in range(num_trials):
subset = get_packet_subset(n, Sampler(k))
for p in subset:
packet_counter[p] += 1

return p
```
<Overlap Ratio: 0.851581508515815>

---

--- 42 --
Question ID: 54a89802d87fea559c56f88830b6e2a6e36c25e8_4
Original Code:
```
def get_method_user_init():
    User = get_user_model()
    method_original = User.__init__

    def method_init(self, *args, **kwargs):
        _instance_extra_data = kwargs.pop('_instance_extra_data', {})
        result = method_original(self, *args, **kwargs)
        for key, value in _instance_extra_data.items():
            setattr(self, key, value)

        return result

    return method_init
```


Overlapping Code:
```
init():
User = get_user_model()
method_original = User.__init__
def method_init(self, *args, **kwargs):
_instance_extra_data = kwargs.pop('_instance_extra_data', {})
result = method_original(self, *args, **kwargs)
for key, value in _instance_extra_data.items():
setattr(self, key, value)
return resul
```
<Overlap Ratio: 0.8823529411764706>

---

--- 43 --
Question ID: 23d0435f0ab0a1ac950c9194bbb0e5d8f6fdf62f_2
Original Code:
```
def add_groups_item_to_dict(init_json, df, nestcol, newcolname):
    """
    init_json: Initial Json Array of Objects
    df: Dataframe to add group items
    nestcol: Name of columns that will be nested (thrown into a list)
    newcolname: Name of new column

    Matches on guid

    Adds a specific column (nestcol) with name (newcolname) from
    Pandas dataframe (df) to the array (init_json)
    """

    new_dict = uf.nest_for_json(
        prune_dataframe(df, ['guid', nestcol]),
        'guid',
        nestcol,
        newcolname
    ).to_dict('r')

    for init_item in init_json:
        for new_item in new_dict:
            # Matches on guid between the two items
            if init_item['guid'] == new_item['guid']:
                init_item[newcolname] = new_item[newcolname]
```


Overlapping Code:
```
oups_item_to_dict(init_json, df, nestcol, newcolname):
"""
init_json: Initial Json Array of Objects
df: Dataframe to add group items
nestcol: Name of columns that will be nested (thrown into a list)
newcolname: Name of new column
Matches on guid
Adds a specific column (nestcol) with name (newcolname) from
Pandas dataframe (df) to the array (init_json)
"""
new_dict = uf.nest_for_json(
prune_dataframe(df, ['guid', nestcol]),
'guid',
nestcol,
newcolname
).to_dict('r')
for init_item in init_json:
for new_item in new_dict:
# Matches on guid between the two items
if init_item['guid'] == new_item['guid']:
init_item[newcolname] = new_item[newcolname]
```
<Overlap Ratio: 0.9848484848484849>

---

--- 44 --
Question ID: 0991fd41708c384f3d4879fbe359511b6dce95d7_0
Original Code:
```
def resize_point(point, in_size, out_size):
    """Adapt point coordinates to the rescaled image space.

    Args:
        point (~numpy.ndarray): Points in the image.
            The shape of this array is :math:`(P, 2)`. :math:`P` is the number
            of points in the image.
            The last dimension is composed of :math:`y` and :math:`x`
            coordinates of the points.
        in_size (tuple): A tuple of length 2. The height and the width
            of the image before resized.
        out_size (tuple): A tuple of length 2. The height and the width
            of the image after resized.

    Returns:
        ~numpy.ndarray:
        Points rescaled according to the given image shapes.

    """
    point = point.copy()
    y_scale = float(out_size[0]) / in_size[0]
    x_scale = float(out_size[1]) / in_size[1]
    point[:, 0] = y_scale * point[:, 0]
    point[:, 1] = x_scale * point[:, 1]
    return point
```


Overlapping Code:
```
resize_point(point, in_size, out_size):
"""Adapt point coordinates to the rescaled image space.
Args:
point (~numpy.ndarray): Points in the image.
The shape of this array is :math:`(P, 2)`. :math:`P` is the number
of points in the image.
The last dimension is composed of :math:`y` and :math:`x`
coordinates of the points.
in_size (tuple): A tuple of length 2. The height and the width
of the image before resized.
out_size (tuple): A tuple of length 2. The height and the width
of the image after resized.
Returns:
~numpy.ndarray:
Points rescaled according to the given image shapes.
"""
point = point.copy()
y_scale = float(out_size[0]) / in_size[0]
x_scale = float(out_size[1]) / in_size[1]
point[:, 0] = y_scale * point[:, 0]
point[:, 1] = x_scal
```
<Overlap Ratio: 0.959079283887468>

---

--- 45 --
Question ID: d17203bc58489c2d4bf54d79f6379d4ff366e7c1_3
Original Code:
```
def add_K_Relations(searchExe, varRels):
    relations = searchExe.relations
    tasks = collections.defaultdict(set)
    for (acro, ks) in varRels.items():
        j = searchExe.relationFromName[acro]
        ji = searchExe.converse[j]
        if ji < j:
            (j, ji) = (ji, j)
        acro = relations[j]["acro"]
        acroi = relations[ji]["acro"]
        tasks[(j, acro, ji, acroi)] |= ks

    for ((j, acro, ji, acroi), ks) in tasks.items():
        for k in ks:
            newAcro = acro.replace("k", str(k))
            newAcroi = acroi.replace("k", str(k))
            r = relations[j]
            ri = relations[ji]
            lr = len(relations)
            relations.extend(
                [
                    dict(
                        name=acro,
                        acro=newAcro,
                        spin=r["spin"],
                        func=r["func"](k),
                        desc=r["desc"],
                    ),
                    dict(
                        name=acroi,
                        acro=newAcroi,
                        spin=ri["spin"],
                        func=ri["func"](k),
                        desc=ri["desc"],
                    ),
                ]
            )
            searchExe.relationFromName[newAcro] = lr
            searchExe.relationFromName[newAcroi] = lr + 1
            searchExe.converse[lr] = lr + 1
            searchExe.converse[lr + 1] = lr
```


Overlapping Code:
```
e, varRels):
relations = searchExe.relations
tasks = collections.defaultdict(set)
for (acro, ks) in varRels.items():
j = searchExe.relationFromName[acro]
ji = searchExe.converse[j]
if ji < j:
(j, ji) = (ji, j)
acro = relations[j]["acro"]
acroi = relations[ji]["acro"]
tasks[(j, acro, ji, acroi)] |= ks
for ((j, acro, ji, acroi), ks) in tasks.items():
for k in ks:
newAcro = acro.replace("k", str(k))
newAcroi = acroi.replace("k", str(k))
r = relations[j]
ri = relations[ji]
lr = len(relations)
relations.extend(
[
dict(
name=acro,
acro=newAcro,
spin=r["spin"],
func=r["func"](k),
desc=r["desc"],
),
dict(
name=acroi,
acro=newAcroi,
spin=ri["spin"],
func=ri["func"](k),
desc=ri["desc"],
),
]
)
searchExe.relationFromName[newAcro] = lr
searchExe.relationFromName[newAcroi] = lr + 1
searchExe.converse[l
```
<Overlap Ratio: 0.9184845005740528>

---

--- 46 --
Question ID: b162d0a08c962dc7fe541b326ece9bb04c1eca83_0
Original Code:
```
def connect():
	conn = None;
	try:
		conn = MySQLdb.connect(host = config.mysql.host, user = config.mysql.user, passwd = config.mysql.pwd, db = config.mysql.db, port = config.mysql.port);
		cur = conn.cursor()
		cur.execute("set names " + config.mysql.charset +";");
		cur.close();
	except MySQLdb.Error as e:
		std.log.warn("Mysql Connect Error %d: %s" % (e.args[0], e.args[1]));
	#endtry
	
	return conn;	
```


Overlapping Code:
```
one;
try:
conn = MySQLdb.connect(host = config.mysql.host, user = config.mysql.user, passwd = config.mysql.pwd, db = config.mysql.db, port = config.mysql.port);
cur = conn.cursor()
cur.execute("set names " + config.mysql.charset +";");
cur.close();
except MySQLdb.Error as e:
std.log.warn("Mysql Connect Error %d: %s" % (e.args[0], e.args[1]));
#endt
```
<Overlap Ratio: 0.8997429305912596>

---

--- 47 --
Question ID: c84b5d3f6cf6b459dd29dc38116560721d195f3a_1
Original Code:
```
def ShuffleOMES(sequences, times=10000, cutoff=0.2, core=0, output=1, cluster=0, save=False):
    '''It is a function to calculate the p value for shuffled OMES.
    Given the sequences in a list with no format.
    times is the shuffle times.
    cutoff is the lower cutoff. (Haven't finished yet. Calc all now.)
    core is the process number to run.
    output is a mark for output.'''
    import os
    from os import path
    from mbio.Application import job_organization as jo
    scriptfile = path.join(_path__, '..', 'Scripts', 'omes_mpi.c')
    jobnumber = jo.AskJobNumber()
    f = open(path.join(_path__, '..', '.Cache', jobnumber + '.fasta'), 'w')
    f.write('\n'.join(sequences))
    f.close()
    jo.MkdirResult()
    f = open(scriptfile, 'r')
    script = f.read()
    f.close()
    output = '1' if output else '0'
    jo.Writejob(jobnumber, script.replace
               ('#define seqnum', '#define seqnum ' + str(len(sequences)))
                .replace
               ('#define lennum', '#define lennum ' +
                str(len(sequences[0]) + 1))
                .replace
               ('file.fasta', path.join(
                _path__, '..', '.Cache', jobnumber + '.fasta'))
                .replace
               ('#define OUTPUT', '#define OUTPUT ' + str(output))
                .replace
               ('#define times', '#define times ' + str(times))
                .replace
               ('#define cutoff', '#define cutoff ' + str(1 - cutoff))
                .replace
               ("OMESsave.save", path.join(
                _path__, '..', '.Result', jobnumber + '-omes.save'))
                .replace
               ("Psave.save", path.join(_path__, '..', '.Result', jobnumber + '-p.save')))
    jo.SubShufflejob(jobnumber, cluster, core)
    if path.exists(path.join(_path__, '..', '.Result', jobnumber + '-omes.save')):
        from mbio.IO import matrix
        m = matrix.ReadMatrix(path.join(
            _path__, '..', '.Result', jobnumber + '-omes.save'), 'd', len(sequences[0]))
        if save:
            import shutil
            shutil.copy(path.join(
                _path__, '..', '.Result', jobnumber + '-omes.save'),  './')
            os.rename(path.join('.', jobnumber + '-omes.save'), './omes.save')
    else:
        return None
    if path.exists(path.join(_path__, '..', '.Result', jobnumber + '-p.save')):
        from mbio.IO import matrix
        p = matrix.ReadMatrix(path.join(
            _path__, '..', '.Result', jobnumber + '-p.save'), 'i', len(sequences[0]))
        if save:
            import shutil
            shutil.copy(path.join(
                _path__, '..', '.Result', jobnumber + '-p.save'),  './')
            os.rename(path.join('.', jobnumber + '-p.save'), './p.save')
    else:
        return None
    jo.Clearjob(jobnumber)
    return p
```


Overlapping Code:
```
ShuffleOMES(sequences, times=10000, cutoff=0.2, core=0, output=1, cluster=0, save=False):
'''It is a function to calculate the p value for shuffled OMES.
Given the sequences in a list with no format.
times is the shuffle times.
cutoff is the lower cutoff. (Haven't finished yet. Calc all now.)
core is the process number to run.
output is a mark for output.'''
import os
from os import path
from mbio.Application import job_organization as jo
scriptfile = path.join(_path__, '..', 'Scripts', 'omes_mpi.c')
jobnumber = jo.AskJobNumber()
f = open(path.join(_path__, '..', '.Cache', jobnumber + '.fasta'), 'w')
f.write('\n'.join(sequences))
f.close()
jo.MkdirResult()
f = open(scriptfile, 'r')
script = f.read()
f.close()
output = '1' if output else '0'
jo.Writejob(jobnumber, script.replace
('#define seqnum', '#define seqnum ' + str(len(sequences)))
.replace
('#define lennum', '#define lennum ' +
str(len(sequences[0]) + 1))
.replace
('file.fasta', path.join(
_path__, '..', '.Cache', jobnumber + '.fasta'))
.replace
('#define OUTPUT', '#define OUTPUT ' + str(output))
.replace
('#define times', '#define times ' + str(times))
.replace
('#define cutoff', '#define cutoff ' + str(1 - cutoff))
.replace
("OMESsave.save", path.join(
_path__, '..', '.Result', jobnumber + '-omes.save'))
.replace
("Psave.save", path.join(_path__, '..', '.Result', jobnumber + '-p.save')))
jo.SubShufflejob(jobnumber, cluster, core)
if path.exists(path.join(_path__, '..', '.Result', jobnumber + '-omes.save')):
from mbio.IO import matrix
m = matrix.ReadMatrix(path.join(
_path__, '..', '.Result', jobnumber + '-omes.save'), 'd', len(sequences[0]))
if save:
import shutil
shutil.copy(path.join(
_path__, '..', '.Result', jobnumber + '-omes.save'), './')
os.rename(path.join('.', jobnumber + '-omes.save'), './omes.save')
else:
return None
if path.exists(path.join(_path__, '..', '.Result', jobnumber + '-p.save')):
from mbio.IO import matrix
p = matrix.ReadMatrix(path.join(
_path__, '..', '.Result', jobnu
```
<Overlap Ratio: 0.992992992992993>

---

--- 48 --
Question ID: 218d136505d79730039ed6eaeaedc8ce0b3c6f09_0
Original Code:
```
def test_duplicate_axis():
    a = ng.make_axis(name='X')
    b = ng.make_axis(name='X')
    with pytest.raises(ValueError):
        ng.make_axes([a, b])
```


Overlapping Code:
```
est_duplicate_axis():
a = ng.make_axis(name='X')
b = ng.make_axis(name='X')
with pytest.raises(ValueError):
ng.make_axes([
```
<Overlap Ratio: 0.9172932330827067>

---

--- 49 --
Question ID: 0ee24f0ede5963637b0001c5322ef2a31c5be87f_6
Original Code:
```
def get_init_bg(data):
    #Compute the log background frequency of all words
    sums = np.sum(data, axis=0)+1
    print("Computing background frequencies")
    print("Min/max word counts in training data: %d %d" % (int(np.min(sums)), int(np.max(sums))))
    bg = np.array(np.log(sums) - np.log(float(np.sum(sums))), dtype=np.float32)
    return bg
```


Overlapping Code:
```
nd frequency of all words
sums = np.sum(data, axis=0)+1
print("Computing background frequencies")
print("Min/max word counts in training data: %d %d" % (int(np.min(sums)), int(np.max(sums))))
bg = np.array(np.log(sums) - np.log(float(np.sum(sums))), dtype=np.float32
```
<Overlap Ratio: 0.8184615384615385>

---

--- 50 --
Question ID: 81fe826519dffc4a279b13276c37745c436038e7_3
Original Code:
```
@pytest.mark.parametrize('number_of_nodes', [2])
@pytest.mark.parametrize('channels_per_node', [1])
def test_receive_directtransfer_invalidsender(raiden_network, deposit, token_addresses):
    app0, app1 = raiden_network
    token_address = token_addresses[0]
    other_key, other_address = make_privkey_address()
    token_network_identifier = views.get_token_network_identifier_by_token_address(
        views.state_from_app(app0),
        app0.raiden.default_registry.address,
        token_address,
    )

    channel0 = get_channelstate(app0, app1, token_network_identifier)
    channel_identifier = channel0.identifier
    message_identifier = random.randint(0, UINT64_MAX)

    direct_transfer_message = DirectTransfer(
        chain_id=UNIT_CHAIN_ID,
        message_identifier=message_identifier,
        payment_identifier=1,
        nonce=1,
        token_network_address=token_network_identifier,
        token=token_address,
        channel_identifier=channel_identifier,
        transferred_amount=10,
        locked_amount=0,
        recipient=app0.raiden.address,
        locksroot=EMPTY_MERKLE_ROOT,
    )

    sign_and_inject(
        direct_transfer_message,
        other_key,
        other_address,
        app0,
    )

    assert_synched_channel_state(
        token_network_identifier,
        app0, deposit, [],
        app1, deposit, [],
    )
```


Overlapping Code:
```
@pytest.mark.parametrize('number_of_nodes', [2])
@pytest.mark.parametrize('channels_per_node', [1])
def test_receive_directtransfer_invalidsender(raiden_network, deposit, token_addresses):
app0, app1 = raiden_network
token_address = token_addresses[0]
other_key, other_address = make_privkey_address()
token_network_identifier = views.get_token_network_identifier_by_token_address(
views.state_from_app(app0),
app0.raiden.default_registry.address,
token_address,
)
channel0 = get_channelstate(app0, app1, token_network_identifier)
channel_identifier = channel0.identifier
message_identifier = random.randint(0, UINT64_MAX)
direct_transfer_message = DirectTransfer(
chain_id=UNIT_CHAIN_ID,
message_identifier=message_identifier,
payment_identifier=1,
nonce=1,
token_network_address=token_network_identifier,
token=token_address,
channel_identifier=channel_identifier,
transferred_amount=10,
locked_amount=0,
recipient=app0.raiden.address,
locksroot=EMPTY_MERKLE_ROOT,
)
sign_and_inject(
direct_transfer_message,
other_key,
other_address,
app0,
)
assert_synched_channel_state(
token_network_identifier,
app0, deposit, [],
app1, deposi
```
<Overlap Ratio: 0.9929824561403509>

---

--- 51 --
Question ID: 0ecb8aaf798556d79dff55a03c6528ada755164d_4
Original Code:
```
@pytest.mark.parametrize(
    "model_args,expected",
    test_data,
    ids=["scalar", "vector", "matrix", "3D array"],
)
def test_get_cons(model_args, expected):
    # Test consumption calculation
    r, w, b, b_splus1, n, bq, net_tax, tau_c, p = model_args
    test_value = household.get_cons(
        r, w, b, b_splus1, n, bq, net_tax, p.e, tau_c, p
    )

    assert np.allclose(test_value, expected)
```


Overlapping Code:
```
ize(
"model_args,expected",
test_data,
ids=["scalar", "vector", "matrix", "3D array"],
)
def test_get_cons(model_args, expected):
# Test consumption calculation
r, w, b, b_splus1, n, bq, net_tax, tau_c, p = model_args
test_value = household.get_cons(
r, w, b, b_splus1, n, bq, net_tax, p.e, tau_c, p

```
<Overlap Ratio: 0.8264462809917356>

---

--- 52 --
Question ID: 4387826def52741beff368d6355d43a7716ebfd5_1
Original Code:
```
def run_yolov2(args):

    implot = {'rand': False, 'count': 0}
    if args.implot_seq and args.implot_seq > 0:
        imgplot['count'] = args.implot_seq
    elif args.implot_rand and args.implot_seq > 0:
        imgplot['rand'] = True
        imgplot['count'] = args.implot_seq
    else:
        implot = None

    flow_eval = DarkflowEvalPTI01(args.gtpath, args.loadfrom, args.impath, metric=args.metric, limit=args.limit, plot=args.plot, implot=implot)
    flow_eval.eval()
```


Overlapping Code:
```
rand': False, 'count': 0}
if args.implot_seq and args.implot_seq > 0:
imgplot['count'] = args.implot_seq
elif args.implot_rand and args.implot_seq > 0:
imgplot['rand'] = True
imgplot['count'] = args.implot_seq
else:
implot = None
flow_eval = DarkflowEvalPTI01(args.gtpath, args.loadfrom, args.impath, metric=args.metric, limit=args.limit, plot=args.p
```
<Overlap Ratio: 0.8353221957040573>

---

--- 53 --
Question ID: 563c8fb82d218639c28cd03716c63d9198272fba_11
Original Code:
```
def add_generatedby_to_tree(xmldocu,treeroot,skipel,uuid):
    # skipel is None or perhaps the lip:process element we have been creating
    # so that we don't list dependence on that

    for descendent in iterelementsbutskip(treeroot,skipel): #  iterate through descendents, but ignore the provenance tag structure we just created. 
        # print "descendent=%s" % (str(descendent))
        oldwgb=""
        if LIP+"wasgeneratedby" in descendent.attrib:
            oldwgb=descendent.attrib[LIP+"wasgeneratedby"]
            pass
        
        descendent.attrib[LIP+"wasgeneratedby"]=oldwgb + "uuid="+uuid+";"
        pass
    pass
```


Overlapping Code:
```
pel,uuid):
# skipel is None or perhaps the lip:process element we have been creating
# so that we don't list dependence on that
for descendent in iterelementsbutskip(treeroot,skipel): # iterate through descendents, but ignore the provenance tag structure we just created. 
# print "descendent=%s" % (str(descendent))
oldwgb=""
if LIP+"wasgeneratedby" in descendent.attrib:
oldwgb=descendent.attrib[LIP+"wasgeneratedby"]
pass

descendent.attrib[LIP+"wasgeneratedby"]=oldwgb + "uuid="+uuid+";"
pass
pas
```
<Overlap Ratio: 0.9107468123861566>

---

--- 54 --
Question ID: 843939e1080a3e1d6989a28073c7853ea42c9d1e_3
Original Code:
```
def evalVertLocations(ob):    
    verts = {}
    for v in ob.data.vertices:
        verts[v.index] = v.co.copy()
    for skey in ob.data.shape_keys.key_blocks:
        if skey.name == "Basis":
            continue       
        for n,v in enumerate(skey.data):
            bv = ob.data.vertices[n]
            vec = v.co - bv.co
            verts[n] += skey.value*vec
    return verts            
```


Overlapping Code:
```
= {}
for v in ob.data.vertices:
verts[v.index] = v.co.copy()
for skey in ob.data.shape_keys.key_blocks:
if skey.name == "Basis":
continue 
for n,v in enumerate(skey.data):
bv = ob.data.vertices[n]
vec = v.co - bv.co
verts[n] += skey.value*vec
return ver
```
<Overlap Ratio: 0.8754325259515571>

---

--- 55 --
Question ID: 98b02d7ee5a90de461996e55891fb796e6e7e795_3
Original Code:
```
def _get_families(req):
    families = [f for f in req.params.get('family', '').split(',') if f]
    if families:
        return DBSession.query(Languoid).filter(Languoid.id.in_(families)).all()
    return []
```


Overlapping Code:
```
get_families(req):
families = [f for f in req.params.get('family', '').split(',') if f]
if families:
return DBSession.query(Languoid).filter(Languoid.
```
<Overlap Ratio: 0.7978723404255319>

---

--- 56 --
Question ID: 84a2893af711539b1cd601c448f8e3a443d5c48d_5
Original Code:
```
def strip_parens(text: str) -> str:
    """ Remove any parentheses blocks. """

    stripped = text

    # note that we search for paren blocks but only use the matches to find a starting position
    # since parens can be nested inside other parens, we have to manually count opening and
    # closing parens to find the entire block that we want to strip
    pattern = re.compile(r'\(.*?\)', re.DOTALL)  # paren blocks can span more than one line

    match = pattern.search(stripped)

    while match is not None:
        starting = match.start()
        ending = starting

        depth_count = 0

        for c in text[starting:]:
            if c == '(':
                depth_count += 1
            elif c == ')':
                depth_count -= 1

            ending += 1

            if depth_count == 0:
                break

        block = text[starting:ending]
        replacement = blanked(block)

        stripped = stripped[:starting] + replacement + stripped[ending:]

        match = pattern.search(stripped)

    return stripped
```


Overlapping Code:
```
y parentheses blocks. """
stripped = text
# note that we search for paren blocks but only use the matches to find a starting position
# since parens can be nested inside other parens, we have to manually count opening and
# closing parens to find the entire block that we want to strip
pattern = re.compile(r'\(.*?\)', re.DOTALL) # paren blocks can span more than one line
match = pattern.search(stripped)
while match is not None:
starting = match.start()
ending = starting
depth_count = 0
for c in text[starting:]:
if c == '(':
depth_count += 1
elif c == ')':
depth_count -= 1
ending += 1
if depth_count == 0:
break
block = text[starting:ending]
replacement = blanked(block)
stripped = stripped[:starting] + replacement + stripped[ending:]
match = p
```
<Overlap Ratio: 0.8949880668257757>

---

--- 57 --
Question ID: f1a2db0b85a7a5ad6c5e1de5eabd127688ba3c22_6
Original Code:
```
async def watchCompetition(competition: Competition, serverName: str,unified_channel = None,role = None ,category = None):
    """
    Adds a compeitition to be monitored. Also updates matches and competitions accordingly.
    :param competition: Competition to be monitored.
    :param serverName: Name of the discord server
    """
    logger.info(f"Start watching competition {competition} on {serverName}")

    season = Season.objects.filter(competition=competition).order_by('start_date').last()
    if season == None:
        getAndSaveData(getAllSeasons, idCompetitions=competition.id)
        season = Season.objects.filter(competition=competition).order_by('start_date').last()
    server = DiscordServer(name=serverName)
    server.save()

    updateMatchesSingleCompetition(competition=competition, season=season)

    compWatcher = CompetitionWatcher(competition=competition,
                                     current_season=season, applicable_server=server, current_matchday=1,role=role,category=category)
    if unified_channel is not None:
        compWatcher.unified_channel = unified_channel

    compWatcher.save()
    Scheduler.addCompetition(compWatcher)
```


Overlapping Code:
```
tchCompetition(competition: Competition, serverName: str,unified_channel = None,role = None ,category = None):
"""
Adds a compeitition to be monitored. Also updates matches and competitions accordingly.
:param competition: Competition to be monitored.
:param serverName: Name of the discord server
"""
logger.info(f"Start watching competition {competition} on {serverName}")
season = Season.objects.filter(competition=competition).order_by('start_date').last()
if season == None:
getAndSaveData(getAllSeasons, idCompetitions=competition.id)
season = Season.objects.filter(competition=competition).order_by('start_date').last()
server = DiscordServer(name=serverName)
server.save()
updateMatchesSingleCompetition(competition=competition, season=season)
compWatcher = CompetitionWatcher(competition=competition,
current_season=season, applicable_server=server, current_matchday=1,role=role,category=category)
if unified_channel is not None:
compWatcher.unified_channel = unified_channel
compWatcher.sav
```
<Overlap Ratio: 0.949667616334283>

---

--- 58 --
Question ID: f175033c687cadc33b77cae0272891c7cab454f5_4
Original Code:
```
@given(st.lists(subtitles()))
def test_compose_and_parse_strict(input_subs):
    composed = srt.compose(input_subs, reindex=False)
    reparsed_subs = srt.parse(composed)
    subs_eq(reparsed_subs, input_subs)
```


Overlapping Code:
```
ts(subtitles()))
def test_compose_and_parse_strict(input_subs):
composed = srt.compose(input_subs, reindex=False)
reparsed_subs = srt.parse(composed)
subs_eq(reparsed_subs, input_s
```
<Overlap Ratio: 0.9137055837563451>

---

--- 59 --
Question ID: 6e4673b7d92e5792fda28b6efd0785c3de795621_1
Original Code:
```
def xenstore_list(path, client):
    result = []
    if client is None:
        p = Popen(
            ['xenstore-ls', path],
            stdout=PIPE,
            stderr=PIPE
        )
        out, _ = p.communicate()
        if p.returncode == 0:
            decoded_out = out.decode('utf-8').split('\n')
            result = [
                item.split(' = ')[0] for item in decoded_out if item
            ]
    else:
        for item in client.list(path):
            result.append(item.decode('utf-8').strip())

    return result
```


Overlapping Code:
```
_list(path, client):
result = []
if client is None:
p = Popen(
['xenstore-ls', path],
stdout=PIPE,
stderr=PIPE
)
out, _ = p.communicate()
if p.returncode == 0:
decoded_out = out.decode('utf-8').split('\n')
result = [
item.split(' = ')[0] for item in decoded_out if item
]
else:
for item in client.list(path):
result.append(item.decode('utf-8').strip(
```
<Overlap Ratio: 0.9259259259259259>

---

--- 60 --
Question ID: 3e7fcca0fd6e6c0e725d6cce7ae6b5f93aec761e_0
Original Code:
```
def installopenjdk():
    hookenv.log('Installing OpenJDK')
    conf = hookenv.config()
    install_type = conf['install-type']
    java_major = conf['java-major']
    #openjdk 8 is not included in ubuntu repos
    if java_major == '8':
        charms.apt.add_source('ppa:openjdk-r/ppa')
    charms.apt.queue_install(['openjdk-%s-jre-headless' % java_major]) # pylint: disable=e1101
    if install_type == 'full':
        charms.apt.queue_install(['openjdk-%s-jdk' % java_major])# pylint: disable=e1101
        # return 'openjdk-%s-jdk' % java_major
    #TODO remove when reactive fixed
    return 'openjdk-%s-jre-headless' % java_major
```


Overlapping Code:
```
njdk():
hookenv.log('Installing OpenJDK')
conf = hookenv.config()
install_type = conf['install-type']
java_major = conf['java-major']
#openjdk 8 is not included in ubuntu repos
if java_major == '8':
charms.apt.add_source('ppa:openjdk-r/ppa')
charms.apt.queue_install(['openjdk-%s-jre-headless' % java_major]) # pylint: disable=e1101
if install_type == 'full':
charms.apt.queue_install(['openjdk-%s-jdk' % java_major])# pylint: disable=e1101
# return 'openjdk-%s-jdk' % java_major
#TODO remove when reactive fixed
return 'openjdk-%s-jre-headless' % ja
```
<Overlap Ratio: 0.9615384615384616>

---

--- 61 --
Question ID: aa66a49476a0b4505dcdb47e193eb599e909f699_0
Original Code:
```
def dnw_4_normal(input_text):
    """
    源代码基于 http://spaces.ac.cn/archives/3491/
    原理基于 http://www.matrix67.com/blog/archives/5044
    :param input_text:
    :return:
    """
    # 定义要去掉的标点字
    drop_dict = [u'，', u'\n', u'。', u'、', u'：', u'(', u')',
                 u'[', u']', u'.', u',', u' ', u'\u3000', u'”', u'“', u'？',
                 u'?',
                 u'！', u'‘', u'’', u'…']
    for i in drop_dict:  # 去掉标点字
        input_text = input_text.replace(i, '')

    min_count = 2  # 录取词语最小出现次数
    min_support = 4  # 录取词语最低支持度，1代表着随机组合
    min_s = 2  # 录取词语最低信息熵，越大说明越有可能独立成词
    max_sep = 20  # 候选词语的最大字数

    # 为了方便调用，自定义了一个正则表达式的词典
    regexes = {}
    for i in range(2, max_sep + 1):
        k = i
        v = '(' + '.' * i + ')'
        regexes[k] = v

    t = [pd.Series(list(input_text)).value_counts()]  # 保存结果用。

    tsum = t[0].sum()  # 统计总字数
    rt = []  # 保存结果用

    for m in range(2, max_sep + 1):
        print(u'正在生成%s字词...' % m)
        t.append([])
        for i in range(m):  # 生成所有可能的m字词
            t[m - 1] = t[m - 1] + re.findall(regexes[m], input_text[i:])

        t[m - 1] = pd.Series(t[m - 1]).value_counts()  # 逐词统计
        t[m - 1] = t[m - 1][t[m - 1] > min_count]  # 最小次数筛选
        tt = t[m - 1][:]
        for k in range(m - 1):
            qq = np.array(list(map(lambda ms: tsum * t[m - 1][ms] / t[m - 2 - k][ms[:m - 1 - k]] / t[k][ms[m - 1 - k:]],  # noqa
                                   tt.index))) > min_support  # 最小支持度筛选。
            tt = tt[qq]
        rt.append(tt.index)

    def cal_S(sl):  # 信息熵计算函数
        from math import log
        return -((sl / sl.sum()).apply(log) * sl / sl.sum()).sum()

    for i in range(2, max_sep + 1):
        print(u'正在进行%s字词的最大熵筛选(%s)...' % (i, len(rt[i - 2])))
        pp = []  # 保存所有的左右邻结果
        for j in range(i):
            pp = pp + re.findall('(.)%s(.)' % regexes[i], input_text[j:])
        pp = pd.DataFrame(pp).set_index(1).sort_index()  # 先排序，这个很重要，可以加快检索速度
        index = np.sort(np.intersect1d(rt[i - 2], pp.index))  # 作交集
        # 下面两句分别是左邻和右邻信息熵筛选
        index = index[np.array(
            list(map(lambda s: cal_S(pd.Series(pp[0][s]).value_counts()), index))) > min_s]  # noqa
        rt[i - 2] = index[np.array(
            list(map(lambda s: cal_S(pd.Series(pp[2][s]).value_counts()), index))) > min_s]  # noqa

    # 下面都是输出前处理
    for i in range(len(rt)):
        t[i + 1] = t[i + 1][rt[i]]
        t[i + 1].sort(ascending=False)

    # 保存结果并输出
    return pd.DataFrame(pd.concat(t[1:]))
```


Overlapping Code:
```
text):
"""
源代码基于 http://spaces.ac.cn/archives/3491/
原理基于 http://www.matrix67.com/blog/archives/5044
:param input_text:
:return:
"""
# 定义要去掉的标点字
drop_dict = [u'，', u'\n', u'。', u'、', u'：', u'(', u')',
u'[', u']', u'.', u',', u' ', u'\u3000', u'”', u'“', u'？',
u'?',
u'！', u'‘', u'’', u'…']
for i in drop_dict: # 去掉标点字
input_text = input_text.replace(i, '')
min_count = 2 # 录取词语最小出现次数
min_support = 4 # 录取词语最低支持度，1代表着随机组合
min_s = 2 # 录取词语最低信息熵，越大说明越有可能独立成词
max_sep = 20 # 候选词语的最大字数
# 为了方便调用，自定义了一个正则表达式的词典
regexes = {}
for i in range(2, max_sep + 1):
k = i
v = '(' + '.' * i + ')'
regexes[k] = v
t = [pd.Series(list(input_text)).value_counts()] # 保存结果用。
tsum = t[0].sum() # 统计总字数
rt = [] # 保存结果用
for m in range(2, max_sep + 1):
print(u'正在生成%s字词...' % m)
t.append([])
for i in range(m): # 生成所有可能的m字词
t[m - 1] = t[m - 1] + re.findall(regexes[m], input_text[i:])
t[m - 1] = pd.Series(t[m - 1]).value_counts() # 逐词统计
t[m - 1] = t[m - 1][t[m - 1] > min_count] # 最小次数筛选
tt = t[m - 1][:]
for k in range(m - 1):
qq = np.array(list(map(lambda ms: tsum * t[m - 1][ms] / t[m - 2 - k][ms[:m - 1 - k]] / t[k][ms[m - 1 - k:]], # noqa
tt.index))) > min_support # 最小支持度筛选。
tt = tt[qq]
rt.append(tt.index)
def cal_S(sl): # 信息熵计算函数
from math import log
return -((sl / sl.sum()).apply(log) * sl / sl.sum()).sum()
for i in range(2, max_sep + 1):
print(u'正在进行%s字词的最大熵筛选(%s)...' % (i, len(rt[i - 2])))
pp = [] # 保存所有的左右邻结果
for j in range(i):
pp = pp + re.findall('(.)%s(.)' % regexes[i], input_text[j:])
pp = pd.DataFrame(pp).set_index(1).sort_index() # 先排序，这个很重要，可以加快检索速度
index = np.sort(np.intersect1d(rt[i - 2], pp.index)) # 作交集
# 下面两句分别是左邻和右邻信息熵筛选
index = index[np.array(
list(map(lambda s: cal_S(pd.Series(pp[0][s]).value_counts()), index))) > min_s] # noqa
rt[i - 2] = index[np.array(
list(map(lambda s: cal_S(pd.Series(pp[2][s]).value_counts()), index))) > min_s] # noqa
# 下面都是输出前处理
for i in range(len(rt)):
t[i + 1] = t[i + 1][rt[i]]
t[i + 1].sort(ascending=False)
#
```
<Overlap Ratio: 0.9672619047619048>

---

--- 62 --
Question ID: 5d465ffbed86fda15f5be978f767e4c9543847ba_30
Original Code:
```
def test_location_event():
    message = parse_user_msg("""
    <xml>
        <ToUserName><![CDATA[toUser]]></ToUserName>
        <FromUserName><![CDATA[fromUser]]></FromUserName>
        <CreateTime>123456789</CreateTime>
        <MsgType><![CDATA[event]]></MsgType>
        <Event><![CDATA[LOCATION]]></Event>
        <Latitude>23.137466</Latitude>
        <Longitude>113.352425</Longitude>
        <Precision>119.385040</Precision>
    </xml>
    """)
    assert message.target == "toUser"
    assert message.source == "fromUser"
    assert message.time == 123456789
    assert message.type == "location_event"
    assert message.latitude == 23.137466
    assert message.longitude == 113.352425
    assert message.precision == 119.385040
```


Overlapping Code:
```
_location_event():
message = parse_user_msg("""
<xml>
<ToUserName><![CDATA[toUser]]></ToUserName>
<FromUserName><![CDATA[fromUser]]></FromUserName>
<CreateTime>123456789</CreateTime>
<MsgType><![CDATA[event]]></MsgType>
<Event><![CDATA[LOCATION]]></Event>
<Latitude>23.137466</Latitude>
<Longitude>113.352425</Longitude>
<Precision>119.385040</Precision>
</xml>
""")
assert message.target == "toUser"
assert message.source == "fromUser"
assert message.time == 123456789
assert message.type == "location_event"
assert message.latitude == 23.137466
assert message.longitude == 113.352425
assert message.precision == 119
```
<Overlap Ratio: 0.9762658227848101>

---

--- 63 --
Question ID: 48001d96d99461626ef538dafa8e93a96f02c5b0_1
Original Code:
```
def bindListByTitle(column, dataList):
    d1, d2 = {}, {}
    for j in range(len(dataList)):
        i = 0
        for x in dataList[j]:
            d1[column[i]], d2[j] = x, d1
            i += 1
    return d2
```


Overlapping Code:
```
}, {}
for j in range(len(dataList)):
i = 0
for x in dataList[j]:
d1[column[i]], d2[j] = x, d1
i += 1
```
<Overlap Ratio: 0.6289308176100629>

---

--- 64 --
Question ID: 04f0cac2861b26994ed2dd31f456ed53f4772036_2
Original Code:
```
def s3_copy(target_bucket, source, region):
    """
    Executes S3 copy operation.

    Args:
        target_bucket (str): Name of S3 bucket.
        source (dict): Identify source cuboid, keys: 'Bucket', 'Key'.
        region (str): AWS region.
    """

    # Append version (always 0 particularly since we're copying to a new
    # channel.
    versioned_key = '{}&0'.format(source['Key'])

    s3 = boto3.client('s3', region_name=region)
    s3.copy_object(
        Bucket=target_bucket,
        CopySource=source,
        Key=versioned_key
    )
```


Overlapping Code:
```
f s3_copy(target_bucket, source, region):
"""
Executes S3 copy operation.
Args:
target_bucket (str): Name of S3 bucket.
source (dict): Identify source cuboid, keys: 'Bucket', 'Key'.
region (str): AWS region.
"""
# Append version (always 0 particularly since we're copying to a new
# channel.
versioned_key = '{}&0'.format(source['Key'])
s3 = boto3.client('s3', region_name=region)
s3.copy_object(
Bucket=target_bucket,
CopySource=source,
Key=versione
```
<Overlap Ratio: 0.9803921568627451>

---

--- 65 --
Question ID: 4dcd098102ec7daa0dcea3fff0f2d244b5d66970_2
Original Code:
```
@pytest.mark.parametrize(
    "encoding, mapping",
    (
        (b"\x00\xc0", {0: 0}),
        (
            b"\x00\xce\xcd\x83\x13\x88\xf9\x88\x1b\xc1mgN\xc8\x00\x00",
            {0: 0, token_id_encode("QETH"): int(2e18)},
        ),
        (
            b"\x00\xcf\xce\x83\x13\x88\xf9\x89\x1e?\xce;\x96\xdb\xf8\x00\x00",
            {0: 0, token_id_encode("QETH"): int(558e18), token_id_encode("QETC"): 0},
        ),
        (
            b"\x00\xce\xcd\x83\x13\x88\xf9\x88)\xa2$\x1a\xf6,\x00\x00",
            {
                0: 0,
                token_id_encode("QETH"): int(3e18),
                token_id_encode("QETC"): 0,
                token_id_encode("QA"): 0,
                token_id_encode("QB"): 0,
                token_id_encode("QC"): 0,
                token_id_encode("QD"): 0,
                token_id_encode("QE"): 0,
                token_id_encode("QF"): 0,
                token_id_encode("QG"): 0,
                token_id_encode("QH"): 0,
                token_id_encode("QI"): 0,
                token_id_encode("QJ"): 0,
                token_id_encode("QK"): 0,
                token_id_encode("QL"): 0,
                token_id_encode("QM"): 0,
            },
        ),
    ),
)
def test_encode_zero_balance(encoding, mapping):
    # starting from blank account
    b0 = TokenBalances(b"", InMemoryDb())
    for k, v in mapping.items():
        b0.balances[k] = v
    assert b0.balances == mapping
    assert b0.serialize() == encoding

    # starting from RLP encoding
    b1 = TokenBalances(encoding, InMemoryDb())
    assert b1.balances == {k: v for k, v in mapping.items() if v != 0}
    if b1.balances:
        assert b1.serialize() == encoding
    else:
        assert b1.serialize() == b""
```


Overlapping Code:
```
est.mark.parametrize(
"encoding, mapping",
(
(b"\x00\xc0", {0: 0}),
(
b"\x00\xce\xcd\x83\x13\x88\xf9\x88\x1b\xc1mgN\xc8\x00\x00",
{0: 0, token_id_encode("QETH"): int(2e18)},
),
(
b"\x00\xcf\xce\x83\x13\x88\xf9\x89\x1e?\xce;\x96\xdb\xf8\x00\x00",
{0: 0, token_id_encode("QETH"): int(558e18), token_id_encode("QETC"): 0},
),
(
b"\x00\xce\xcd\x83\x13\x88\xf9\x88)\xa2$\x1a\xf6,\x00\x00",
{
0: 0,
token_id_encode("QETH"): int(3e18),
token_id_encode("QETC"): 0,
token_id_encode("QA"): 0,
token_id_encode("QB"): 0,
token_id_encode("QC"): 0,
token_id_encode("QD"): 0,
token_id_encode("QE"): 0,
token_id_encode("QF"): 0,
token_id_encode("QG"): 0,
token_id_encode("QH"): 0,
token_id_encode("QI"): 0,
token_id_encode("QJ"): 0,
token_id_encode("QK"): 0,
token_id_encode("QL"): 0,
token_id_encode("QM"): 0,
},
),
),
)
def test_encode_zero_balance(encoding, mapping):
# starting from blank account
b0 = TokenBalances(b"", InMemoryDb())
for k, v in mapping.items():
b0.balances[k] = v
assert b0.balances == mapping
assert b0.serialize() == encoding
# starting from RLP encoding
b1 = TokenBalances(encoding, InMemoryDb())
assert b1.balances == {k: v for k, v in mapping.items() if v != 0}
if b1.balances:
assert b1.serialize() == encoding
else:
assert b1.serial
```
<Overlap Ratio: 0.9873217115689382>

---

--- 66 --
Question ID: 717e4f6a4a61e96e0f81647e2663fd06afc02356_7
Original Code:
```
def test_tensorget_disconnect(env):
    con = get_connection(env, 't_FLOAT')
    ret = con.execute_command('AI.TENSORSET', 't_FLOAT', 'FLOAT', 2, 'VALUES', 2, 3)
    env.assertEqual(ret, b'OK')
    ret = send_and_disconnect(('AI.TENSORGET', 't_FLOAT', 'META'), con)
    env.assertEqual(ret, None)
```


Overlapping Code:
```
ensorget_disconnect(env):
con = get_connection(env, 't_FLOAT')
ret = con.execute_command('AI.TENSORSET', 't_FLOAT', 'FLOAT', 2, 'VALUES', 2, 3)
env.assertEqual(ret, b'OK')
ret = send_and_disconnect(('AI.TENSORGET', 't_FLOAT', 'META'), con)
env.assert
```
<Overlap Ratio: 0.9057971014492754>

---

--- 67 --
Question ID: 22217d3a519e212ebef80b36b4a5516f4fca76a4_5
Original Code:
```
def GetKeyIdx(i, isWhite=True):
    a = int(i / 7)
    b = i % 7
    b *= 2
    if b > 4:
        b -= 1
    key_idx = a*12+b
    if not isWhite:
        key_idx += 1
    return key_idx
```


Overlapping Code:
```
KeyIdx(i, isWhite=True):
a = int(i / 7)
b = i % 7
b *= 2
if b > 4:
b -= 1
key_idx = a*12+b
if not is
```
<Overlap Ratio: 0.7092198581560284>

---

--- 68 --
Question ID: b0f11662cf6307bdcf8e8cfc5d2b6a52da5ec243_13
Original Code:
```
def CBIR(query_image, image_set, method):
    comp_method = [cv2.cv.CV_COMP_CORREL, cv2.cv.CV_COMP_INTERSECT, \
        cv2.cv.CV_COMP_CHISQR, cv2.cv.CV_COMP_BHATTACHARYYA]
    if method < 12:
        return compare_hist(query_image, image_set, method // 4, comp_method[method % 4])
    elif method == 12:
        from ccv import CCV
        ccv = CCV(query_image).get_vector()
        ccv_set = [CCV(i).get_vector() for i in image_set]
        l1_distance = [L1_distance(ccv, i) for i in ccv_set]
        return np.argmin(l1_distance)
    elif method == 13:
        from crh import CRH
        crh = CRH(query_image).get_vector()
        crh_set = [CRH(i).get_vector() for i in image_set]
        l1_distance = [L1_distance(crh, i) for i in crh_set]
        return np.argmin(l1_distance)
    elif method == 14:
        from ccdr import CCDR
        ccdr = CCDR(query_image).get_vector()
        ccdr_set = [CCDR(i).get_vector() for i in image_set]
        l1_distance = [L1_distance(ccdr, i) for i in ccdr_set]
        return np.argmin(l1_distance)
    return 0
```


Overlapping Code:
```
t, method):
comp_method = [cv2.cv.CV_COMP_CORREL, cv2.cv.CV_COMP_INTERSECT, \
cv2.cv.CV_COMP_CHISQR, cv2.cv.CV_COMP_BHATTACHARYYA]
if method < 12:
return compare_hist(query_image, image_set, method // 4, comp_method[method % 4])
elif method == 12:
from ccv import CCV
ccv = CCV(query_image).get_vector()
ccv_set = [CCV(i).get_vector() for i in image_set]
l1_distance = [L1_distance(ccv, i) for i in ccv_set]
return np.argmin(l1_distance)
elif method == 13:
from crh import CRH
crh = CRH(query_image).get_vector()
crh_set = [CRH(i).get_vector() for i in image_set]
l1_distance = [L1_distance(crh, i) for i in crh_set]
return np.argmin(l1_distance)
elif method == 14:
from ccdr import CCDR
ccdr = CCDR(query_image).get_vector()
ccdr_set = [CCDR(i).get_vector() for i in image_set]
l1_distance = [L1_distance(ccdr, i) for i in ccdr_set]
return np.argmin
```
<Overlap Ratio: 0.9423503325942351>

---

--- 69 --
Question ID: 1459454e2e53d67f8bf74512d0c34f48b41635d4_19
Original Code:
```
@main.route("/search")
def search():
    text = request.args.get("text", "", type=str)
    if len(text) == 0 or len(text) > 128:
        return redirect(url_for("main.index"))

    page = request.args.get("page", 1, type=int)
    pagination = Post.query.filter_by(disable=False).msearch(
        text, fields=["html", "title"]
    ).order_by(
        Post.timestamp.desc()
    ).paginate(
        page, current_app.config.get("FLASK_POST_PER_PAGE", 20), error_out=False
    )
    posts = pagination.items
    return render_template(
        "main/search.html", posts=posts, pagination=pagination, text=text
    )
```


Overlapping Code:
```
arch():
text = request.args.get("text", "", type=str)
if len(text) == 0 or len(text) > 128:
return redirect(url_for("main.index"))
page = request.args.get("page", 1, type=int)
pagination = Post.query.filter_by(disable=False).msearch(
text, fields=["html", "title"]
).order_by(
Post.timestamp.desc()
).paginate(
page, current_app.config.get("FLASK_POST_PER_PAGE", 20), error_out=False
)
posts = pagination.items
return render_template(
"main/search.html", posts=posts, pagination=pagination, text=text
```
<Overlap Ratio: 0.9416195856873822>

---

--- 70 --
Question ID: 44428a69cc518f2445275546933662907b58a396_0
Original Code:
```
def populate_users():
    for i in range(1, 171):
        user_list = []
        page = requests.get(RANKLIST_URL + str(i))
        page = BeautifulSoup(page.text)
        ranklist = page.find_all(class_="ratingsDatatable")
        users = ranklist[0].find_all('td')
        for i in range(1, 800, 4):
            username = users[i].text.split()[0]
            rating = int(users[i+2].text)
            user_list.append(str(tuple((str(username), int(rating)))))
        user_list = ", ".join(user_list)
        query = """
            INSERT INTO "user_table"(handle, rating)
                 VALUES {}
        """.format(user_list)
        with engine.connect() as connection:
            connection.execute(sqlalchemy.text(query))
```


Overlapping Code:
```
i in range(1, 171):
user_list = []
page = requests.get(RANKLIST_URL + str(i))
page = BeautifulSoup(page.text)
ranklist = page.find_all(class_="ratingsDatatable")
users = ranklist[0].find_all('td')
for i in range(1, 800, 4):
username = users[i].text.split()[0]
rating = int(users[i+2].text)
user_list.append(str(tuple((str(username), int(rating)))))
user_list = ", ".join(user_list)
query = """
INSERT INTO "user_table"(handle, rating)
VALUES {}
""".format(user_list)
with engine.connect() as connection:
connection.execute(sqlalchemy.text(
```
<Overlap Ratio: 0.9423076923076923>

---

--- 71 --
Question ID: 8a990c53227e57f5486eec784e7182db31b2d07f_6
Original Code:
```
def _height_fit_fun(parameters,
                    names,
                    heights_dict,  # in um
                    radius,  # in um
                    data_dict=None,  # in units [1, nm/mV, pN/nm]
                    errors_dict=None,  # in units [1, nm/mV, pN/nm]
                    lateral_dict=None,
                    method='viscosity',
                    return_fit_dict=False,
                    fit_dissens_osci=False,
                    dissens_fun_kw={}):
    """
    Calculate the residuals of the height-dependent fit.

    If no data is given the function returns the evaluated function for the
    given parameters.

    Arguments
    ---------
    parameters : lmfit.Parameters
        Parameters object holding the lmfit.Parameter objects: beta_, mbeta_,
        kappa_, mkappa_, focal_shift, corr and h0, where "_" referes to the
        names of the axes.
    names : list of str
        List holding the names of the axes.
    height_dict : OrderedDict
        Dictionary holding the height vectors for the different axes and the
        height vector for the "rel_drag" to be fitted. So the following key
        names are expected: 'kappa_x_pc', 'beta_x_pc' etc.
    radius : float
        Specified radius of the microsphere in micrometers
    focal_shift : float
    data_dict : OrderedDict
        Dictionary of the data to be fitted with same keys as height_dict.
    errors_dict : OrderedDict
        Dictionary of the errors of the data to be fitted with same keys as
        height_dict.
    lateral : OrderedDict
        Dictionary with same keys as height_dict refering to whether the
        axis is in the lateral or axial direction. E.g. for 'x', 'y', 'z' and
        'rel_drag' as names for the three axes and the drag:
         lateral_dict = {'x': True, 'y': True, 'z': False}
    method : str
        Either 'viscosity' or 'radius', referes to the fitting routine used,
        where the drag is either calculated by:
         drag = 6 * pi * corr * eta * r * Faxen(r)
        or
         drag = 6 * pi * eta * corr * r * Faxen(corr * r).
    return_fit_dict : bool
        Return a dictionary (True) or a flattened array (False)
    fit_dissens_osci : bool
        Whether to try to fit oscillations on the displacement sensitivity. If
        True, the fit will have an additional summand of the shape:
        A * exp(d * heights) * sin( 4 * pi / (n * wavelength) * focal_shift *
        heigths + phi).
    dissens_fun_kw : dict
        If fit_dissens_osci is True, this dictionary needs to be provided. It
        holds the following key-value pairs:

         - ref_ind -- refractive index
         - wavelength -- wavelegth of the detection (trapping) laser in vacuum


    Returns
    -------
    residuals : array or dict
    """
    p = parameters.valuesdict()

    beta_ = OrderedDict()    # value at true surface
    mbeta_ = OrderedDict()   # slope with respect to apparent distance
    kappa_ = OrderedDict()   # value at true surface
    mkappa_ = OrderedDict()  # slope with respect to apparent distance

    for name in names:
        beta_[name] = p['beta_' + name]
        mbeta_[name] = p['mbeta_' + name]
        kappa_[name] = p['kappa_' + name]
        mkappa_[name] = p['mkappa_' + name]

    if fit_dissens_osci:
        A_ = OrderedDict()
        d_ = OrderedDict()
        phi_ = OrderedDict()
        for name in names:
            A_[name] = p['A_' + name]
            d_[name] = p['d_' + name]
            phi_[name] = p['phi_' + name]

    rel_drag = _rel_drag_fit_fun(parameters,
                                 heights_dict['rel_drag'],
                                 radius,
                                 lateral=lateral_dict['rel_drag'],
                                 method=method)

    model_ = [list(rel_drag)]
    model_dict = OrderedDict()
    model_dict['rel_drag'] = rel_drag

    for name in names:
        if fit_dissens_osci:
            dissens_fun_kw['A'] = A_[name]
            dissens_fun_kw['d'] = d_[name]
            dissens_fun_kw['phi'] = phi_[name]

        dissens = _dissens_fit_fun(parameters,
                                   heights_dict['beta_' + name + '_pc'],
                                   beta_[name],
                                   mbeta_[name],
                                   radius,
                                   lateral=lateral_dict[name],
                                   method=method,
                                   fit_osci=fit_dissens_osci,
                                   fun_kw=dissens_fun_kw)
        model_.append(dissens)
        model_dict['beta_' + name + '_pc'] = dissens

        kappa = _kappa_fit_fun(parameters,
                               heights_dict['kappa_' + name + '_pc'],
                               kappa_[name],
                               mkappa_[name],
                               radius,
                               lateral=lateral_dict[name],
                               method=method)
        model_.append(kappa)
        model_dict['kappa_' + name + '_pc'] = kappa

    result_flat = array(list(flatten_list(model_)))

    if not return_fit_dict:
        if data_dict is None:
            return result_flat

        data_ = [data_dict['rel_drag']]
        for name in names:
            data_.append(data_dict['beta_' + name + '_pc'])
            data_.append(data_dict['kappa_' + name + '_pc'])
        data_flat = array(list(flatten_list(data_)))

        if errors_dict is None:
            return (data_flat - result_flat)
        else:
            err_ = [errors_dict['rel_drag']]
            for name in names:
                err_.append(errors_dict['beta_' + name + '_pc'])
                err_.append(errors_dict['kappa_' + name + '_pc'])
            err_flat = array(list(flatten_list(err_)))
            return ((data_flat - result_flat) / err_flat)
    else:
        if data_dict is None:
            return model_dict

        result = OrderedDict()
        if errors_dict is None:
            for k, data in data_dict.items():
                result[k] = data - model_dict[k]
            return result
        else:
            for k, data in data_dict.items():
                result[k] = ((data - model_dict[k]) / errors_dict[k])
            return result
```


Overlapping Code:
```
ight_fit_fun(parameters,
names,
heights_dict, # in um
radius, # in um
data_dict=None, # in units [1, nm/mV, pN/nm]
errors_dict=None, # in units [1, nm/mV, pN/nm]
lateral_dict=None,
method='viscosity',
return_fit_dict=False,
fit_dissens_osci=False,
dissens_fun_kw={}):
"""
Calculate the residuals of the height-dependent fit.
If no data is given the function returns the evaluated function for the
given parameters.
Arguments
---------
parameters : lmfit.Parameters
Parameters object holding the lmfit.Parameter objects: beta_, mbeta_,
kappa_, mkappa_, focal_shift, corr and h0, where "_" referes to the
names of the axes.
names : list of str
List holding the names of the axes.
height_dict : OrderedDict
Dictionary holding the height vectors for the different axes and the
height vector for the "rel_drag" to be fitted. So the following key
names are expected: 'kappa_x_pc', 'beta_x_pc' etc.
radius : float
Specified radius of the microsphere in micrometers
focal_shift : float
data_dict : OrderedDict
Dictionary of the data to be fitted with same keys as height_dict.
errors_dict : OrderedDict
Dictionary of the errors of the data to be fitted with same keys as
height_dict.
lateral : OrderedDict
Dictionary with same keys as height_dict refering to whether the
axis is in the lateral or axial direction. E.g. for 'x', 'y', 'z' and
'rel_drag' as names for the three axes and the drag:
lateral_dict = {'x': True, 'y': True, 'z': False}
method : str
Either 'viscosity' or 'radius', referes to the fitting routine used,
where the drag is either calculated by:
drag = 6 * pi * corr * eta * r * Faxen(r)
or
drag = 6 * pi * eta * corr * r * Faxen(corr * r).
return_fit_dict : bool
Return a dictionary (True) or a flattened array (False)
fit_dissens_osci : bool
Whether to try to fit oscillations on the displacement sensitivity. If
True, the fit will have an additional summand of the shape:
A * exp(d * heights) * sin( 4 * pi / (n * wavelength) * focal_shift *
heigths + phi).
dissens_fun_kw : dict
If fi
```
<Overlap Ratio: 0.9950248756218906>

---

--- 72 --
Question ID: 69d259d599fbb8035a16997abad356c12bd44c46_0
Original Code:
```
@mod_technologies.route('/', methods=['GET'])
@login_required
def get_technologies():
    """Get a list of all the technologies in the system"""

    technology_schema = TechnologySchema()

    return jsonify( [technology_schema.dump(v) for v in Technology.query.all()] )
```


Overlapping Code:
```
ute('/', methods=['GET'])
@login_required
def get_technologies():
"""Get a list of all the technologies in the system"""
technology_schema = TechnologySchema()
return jsonify( [technology_schema.dump(
```
<Overlap Ratio: 0.7782101167315175>

---

--- 73 --
Question ID: e59c80ef8a635988b4cffd366e830cd69c875e76_2
Original Code:
```
@app.route('/download')
def download():
    """Download a csv file of all the data."""

    current_date = str(datetime.date.today())
    csv_name = 'mapping-gun-violence-dump-' + current_date + '.csv'

    cd = os.path.dirname(__file__)
    with open(os.path.join(cd, 'static/final-output.geojson')) as f:
        data = geojson.loads(f.read())

    short_to_long_name = {
        'coordinates': 'coordinates',
        'articleUrl': 'url',
        'articleTitle': 'title',
        'date': 'date',
        'time': 'time',
        'knewEachOther': 'The shooter and the victim knew each other',
        'domesticViolence': 'The incident was a case of domestic violence',
        'anotherCrime': 'The firearm was used during another crime',
        'selfDefense': 'The firearm was used in self defense',
        'alcohol': 'Alcohol was involved',
        'drugs': 'Drugs (other than alcohol) were involved',
        'selfDirected': 'The shooting was self-directed',
        'suicideOrAttempt': 'The shooting was a suicide or suicide attempt',
        'unintentional': 'The shooting was unintentional',
        'byOfficer': 'The shooting was by a police officer',
        'atOfficer': 'The shooting was directed at a police officer',
        'stolen': 'The firearm was stolen',
        'familyOwned': 'The firearm was owned by the victim/victims family'
    }

    fieldnames = ['title', 'url', 'date', 'time', 'coordinates',
                  'The shooter and the victim knew each other',
                  'The incident was a case of domestic violence',
                  'The firearm was used during another crime',
                  'The firearm was used in self defense',
                  'Alcohol was involved',
                  'Drugs (other than alcohol) were involved',
                  'The shooting was self-directed',
                  'The shooting was a suicide or suicide attempt',
                  'The shooting was unintentional',
                  'The shooting was by a police officer',
                  'The shooting was directed at a police officer',
                  'The firearm was stolen',
                  'The firearm was owned by the victim/victims family']

    output = io.StringIO()
    wr = csv.DictWriter(output, fieldnames=fieldnames)
    wr.writeheader()

    for feature in data.features:
        row = {}
        row['coordinates'] = str(feature.geometry.coordinates)

        for key, value in feature.properties.items():
            row[short_to_long_name[key]] = value

        wr.writerow(row)

    return Response(output.getvalue(), mimetype='text/csv', headers={'Content-disposition': 'attachment; filename={}'.format(csv_name)})
```


Overlapping Code:
```
e('/download')
def download():
"""Download a csv file of all the data."""
current_date = str(datetime.date.today())
csv_name = 'mapping-gun-violence-dump-' + current_date + '.csv'
cd = os.path.dirname(__file__)
with open(os.path.join(cd, 'static/final-output.geojson')) as f:
data = geojson.loads(f.read())
short_to_long_name = {
'coordinates': 'coordinates',
'articleUrl': 'url',
'articleTitle': 'title',
'date': 'date',
'time': 'time',
'knewEachOther': 'The shooter and the victim knew each other',
'domesticViolence': 'The incident was a case of domestic violence',
'anotherCrime': 'The firearm was used during another crime',
'selfDefense': 'The firearm was used in self defense',
'alcohol': 'Alcohol was involved',
'drugs': 'Drugs (other than alcohol) were involved',
'selfDirected': 'The shooting was self-directed',
'suicideOrAttempt': 'The shooting was a suicide or suicide attempt',
'unintentional': 'The shooting was unintentional',
'byOfficer': 'The shooting was by a police officer',
'atOfficer': 'The shooting was directed at a police officer',
'stolen': 'The firearm was stolen',
'familyOwned': 'The firearm was owned by the victim/victims family'
}
fieldnames = ['title', 'url', 'date', 'time', 'coordinates',
'The shooter and the victim knew each other',
'The incident was a case of domestic violence',
'The firearm was used during another crime',
'The firearm was used in self defense',
'Alcohol was involved',
'Drugs (other than alcohol) were involved',
'The shooting was self-directed',
'The shooting was a suicide or suicide attempt',
'The shooting was unintentional',
'The shooting was by a police officer',
'The shooting was directed at a police officer',
'The firearm was stolen',
'The firearm was owned by the victim/victims family']
output = io.StringIO()
wr = csv.DictWriter(output, fieldnames=fieldnames)
wr.writeheader()
for feature in data.features:
row = {}
row['coordinates'] = str(feature.geometry.coordinates)
for key, value in feature.properties.items():
row[short_t
```
<Overlap Ratio: 0.9891196834817013>

---

--- 74 --
Question ID: 3caae1436844f7aab10709883f2a9ec0b05df2a7_3
Original Code:
```
def encode_path(file_path, encoder_name=DEFAULT_CODEC_NAME):
    """
    Encode file path
    """

    return encode(read_image(file_path), encoder_name)
```


Overlapping Code:
```
e_path, encoder_name=DEFAULT_CODEC_NAME):
"""
Encode file path
"""
return encode(read_image(file_pat
```
<Overlap Ratio: 0.7352941176470589>

---

--- 75 --
Question ID: 30f90defea366450f18f134a6c378f7ef8fb6a36_6
Original Code:
```
def update_indices(years=None):
    '''
    Update all geophysical indices (e.g., KP, DST, AE).

    update_indices(years=None)

    :param years: (optional) a list of years to download.
            If this input is not provided, default
            values will be used.
    '''

    update_kpap(years=years)
    update_dst(years=years)
    update_ae(years=years)

    return
```


Overlapping Code:
```
ef update_indices(years=None):
'''
Update all geophysical indices (e.g., KP, DST, AE).
update_indices(years=None)
:param years: (optional) a list of years to download.
If this input is not provided, default
values will be used.
'''
update_kpap(years=years)
update_dst(years=years)
update_ae(years=yea
```
<Overlap Ratio: 0.9646302250803859>

---

--- 76 --
Question ID: 426f8b7ee439ef81a41d42973ec077ef34881137_10
Original Code:
```
def get_class(class_name):
    """
    Returns the class corresponding to a string
    :param class_name: the given string pointing to the class from the working directory
    :return: the class as an object
    """
    parts = class_name.split('.')
    class_module = ".".join(parts[:-1])
    m = __import__(class_module)
    for comp in parts[1:]:
        m = getattr(m, comp)
    return m
```


Overlapping Code:
```
ef get_class(class_name):
"""
Returns the class corresponding to a string
:param class_name: the given string pointing to the class from the working directory
:return: the class as an object
"""
parts = class_name.split('.')
class_module = ".".join(parts[:-1])
m = __import__(class_module)
for comp in parts[1:]:
m = getattr(m, comp)
return m
```
<Overlap Ratio: 0.9970845481049563>

---

--- 77 --
Question ID: 6d039c7bbc47a6d65a19e61994249628981e4472_0
Original Code:
```
def main():
    logging.config.fileConfig('logging.conf')
    logger = logging.getLogger('exampleApp')

    logger.info('progress started')
    result = otherMod2.add(7, 8)
    logger.info('done!')
```


Overlapping Code:
```
ef main():
logging.config.fileConfig('logging.conf')
logger = logging.getLogger('exampleApp')
logger.info('progress started')
result = otherMod2.add(7, 8)
logger.info('don
```
<Overlap Ratio: 0.9715909090909091>

---

--- 78 --
Question ID: 4314aac00eaeeabab48a847e52fe1c44fe584df9_0
Original Code:
```
def do_something(logf):
    ### This does the "work" of the daemon

    logger = logging.getLogger('eg_daemon')
    logger.setLevel(logging.INFO)

    fh = logging.FileHandler(logf)
    fh.setLevel(logging.INFO)

    formatstr = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    formatter = logging.Formatter(formatstr)

    fh.setFormatter(formatter)

    logger.addHandler(fh)

    while True:
        logger.debug("this is a DEBUG message")
        logger.info("this is an INFO message")
        logger.error("this is an ERROR message")
        time.sleep(5)

        sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
        print('starting up on {}'.format(server_address))
        sock.bind(server_address)

        # Listen for incoming connections
        sock.listen(1)

        while True:
            # Wait for a connection
            print('waiting for a connection')
            connection, client_address = sock.accept()
            try:
                print('connection from', client_address)

                # Receive the data in small chunks and retransmit it
                while True:
                    data = connection.recv(16)
                    print('received {!r}'.format(data))
                    if data:
                        print('sending data back to the client')
                        connection.sendall(data)
                    else:
                        print('no data from', client_address)
                        break

            finally:
                # Clean up the connection
                connection.close()
```


Overlapping Code:
```
is does the "work" of the daemon
logger = logging.getLogger('eg_daemon')
logger.setLevel(logging.INFO)
fh = logging.FileHandler(logf)
fh.setLevel(logging.INFO)
formatstr = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
formatter = logging.Formatter(formatstr)
fh.setFormatter(formatter)
logger.addHandler(fh)
while True:
logger.debug("this is a DEBUG message")
logger.info("this is an INFO message")
logger.error("this is an ERROR message")
time.sleep(5)
sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
print('starting up on {}'.format(server_address))
sock.bind(server_address)
# Listen for incoming connections
sock.listen(1)
while True:
# Wait for a connection
print('waiting for a connection')
connection, client_address = sock.accept()
try:
print('connection from', client_address)
# Receive the data in small chunks and retransmit it
while True:
data = connection.recv(16)
print('received {!r}'.format(data))
if data:
print('sending data back to the client')
connection.sendall(data)
else:
print('no data from', client_address)
break
finally:
# Clean up the connection
connection.close()
```
<Overlap Ratio: 0.9736842105263158>

---

--- 79 --
Question ID: aba991ef9af9032eec6e066ebc3aa37ebcf824df_16
Original Code:
```
def _get_ambient_temps(temps: List[float]) -> Dict[subsystems.TecUnit, float]:
    """Get (and judge) ambient temp readings for TEC operation.

    :returns: Dict of two temperatures to use for SHGs and MIOB. VHBG has no "ambient".
    :raises ConnectionError: Temperature readings are not consistent.
    :raises ValueError: At least one ambient temp is out of safe bounds for the
                respective component.
    """
    assert len(temps) == len(subsystems.AuxTemp)
    ambient = {}  # type: Dict[subsystems.TecUnit, float]

    # MiOB
    candidate = temps[subsystems.AuxTemp.HEATSINK_A]
    second = temps[subsystems.AuxTemp.HEATSINK_B]
    if abs(candidate - second) > cs.TEMP_LASER_TRAY_DELTA:
        raise ConnectionError("Erroneous laser tray temp reading {}.".format(candidate))
    if (candidate < cs.TEMP_HEATSINK_RANGE_LASER[0]
            or candidate > cs.TEMP_HEATSINK_RANGE_LASER[1]):
        raise ValueError("Laser tray temperature {} out of safe range.".format(candidate))
    ambient[subsystems.TecUnit.MIOB] = candidate

    # SHGs
    candidate = temps[subsystems.AuxTemp.SHG]
    second = temps[subsystems.AuxTemp.CELL]
    if abs(candidate - second) > cs.TEMP_SPEC_TRAY_DELTA:
        raise ConnectionError("Erroneous spec tray temp reading {}".format(candidate))
    if (candidate < cs.TEMP_HEATSINK_RANGE_SPEC[0]
            or candidate > cs.TEMP_HEATSINK_RANGE_SPEC[1]):
        raise ValueError("Spec tray temperature {} out of safe range.".format(candidate))
    ambient[subsystems.TecUnit.SHGA] = candidate
    ambient[subsystems.TecUnit.SHGB] = candidate

    return ambient
```


Overlapping Code:
```
nt_temps(temps: List[float]) -> Dict[subsystems.TecUnit, float]:
"""Get (and judge) ambient temp readings for TEC operation.
:returns: Dict of two temperatures to use for SHGs and MIOB. VHBG has no "ambient".
:raises ConnectionError: Temperature readings are not consistent.
:raises ValueError: At least one ambient temp is out of safe bounds for the
respective component.
"""
assert len(temps) == len(subsystems.AuxTemp)
ambient = {} # type: Dict[subsystems.TecUnit, float]
# MiOB
candidate = temps[subsystems.AuxTemp.HEATSINK_A]
second = temps[subsystems.AuxTemp.HEATSINK_B]
if abs(candidate - second) > cs.TEMP_LASER_TRAY_DELTA:
raise ConnectionError("Erroneous laser tray temp reading {}.".format(candidate))
if (candidate < cs.TEMP_HEATSINK_RANGE_LASER[0]
or candidate > cs.TEMP_HEATSINK_RANGE_LASER[1]):
raise ValueError("Laser tray temperature {} out of safe range.".format(candidate))
ambient[subsystems.TecUnit.MIOB] = candidate
# SHGs
candidate = temps[subsystems.AuxTemp.SHG]
second = temps[subsystems.AuxTemp.CELL]
if abs(candidate - second) > cs.TEMP_SPEC_TRAY_DELTA:
raise ConnectionError("Erroneous spec tray temp reading {}".format(candidate))
if (candidate < cs.TEMP_HEATSINK_RANGE_SPEC[0]
or candidate > cs.TEMP_HEATSINK_RANGE_SPEC[1]):
raise ValueError("Spec tray temperature {} out of safe range.".format(candidate))
ambient[subsystems.TecUnit.SHGA] = candidate
ambient[subsystems
```
<Overlap Ratio: 0.9621993127147767>

---

--- 80 --
Question ID: ac0edbd146e8c4a09a7099dda01e52ac7cfcbefd_0
Original Code:
```
def class_factory(card_name, card_type, card_scheme=None, card_tag=None, card_padding=None):

    def get_grids_factory(card_scheme):
        fields_info = [(index, field_info) for index, field_info in enumerate(card_scheme) if
                       field_info.update_grid or
                       field_info.subscheme and any(x.update_grid for x in field_info.subscheme.scheme)]

        def wrapped(self):
            grids = set()

            for index, field_info in fields_info:

                if field_info.seq_type:

                    if field_info.subscheme:

                        for subfield in self.fields[index]:

                            for subsubfield, subsubfield_info in zip(subfield, field_info.subscheme.scheme):

                                if subsubfield_info.update_grid:

                                    if subsubfield_info.seq_type:
                                        grids |= set(subsubfield)
                                    else:
                                        grids.add(subsubfield)
                    else:

                        if field_info.update_grid:
                            grids |= set(self.fields[index])
                else:

                    if field_info.subscheme:

                        for subfield, subfield_info in zip(field, field_info.subscheme.scheme):

                            if subfield_info.update_grid:

                                if subfield_info.seq_type:
                                    grids |= set(subfield)
                                else:
                                    grids.add(subfield)
                    else:

                        if field_info.update_grid:
                            grids.add(self.fields[index])

            return grids

        return wrapped

    def get_field_factory(index, field_info, alternate_name=False):

        if field_info.seq_type == 'vector':

            if field_info.type == 'grid':

                def wrapped(self):
                    vector = self.fields[index]

                    if alternate_name:

                        if not vector is None and isinstance(vector[0], (int, Card)):
                            vector = vector[0]
                        else:
                            vector = None
                    else:

                        if vector is None:
                            vector = np.array([0.0, 0.0, 0.0])
                        elif isinstance(vector[0], Card):
                            vector = None

                    return vector
            else:

                def wrapped(self):
                    vector = self.fields[index]

                    if vector is None:
                        vector = np.array([0.0, 0.0, 0.0])

                    return vector
        else:

            def wrapped(self):
                return self.fields[index]

        return wrapped

    def set_field_factory(index, field_info, is_subfield=False, alternate_name=False):

        if field_info.type:

            if field_info.seq_type:

                if field_info.seq_type == 'vector':

                    def wrapped(self, value):
                        old_value = self.fields[index]

                        if is_subfield:
                            card = self.card
                        else:
                            card = self

                        try:
                            old_value[0]._unsubscribe(card)

                            if field_info.update_grid:
                                old_value[0].elems.remove(card)
                        except (TypeError, AttributeError):
                            pass

                        if value is None:
                            self.fields[index] = None
                        else:
                            vector = value

                            try:
                                value._subscribe(card)
                                vector = [value, None, None]

                                if field_info.update_grid:
                                    value.elems.add(card)
                            except AttributeError:
                                pass

                            self.fields[index] = np.array(vector)
                else:

                    def wrapped(self, value):
                        raise AttributeError("can't set attribute")

            else:

                def wrapped(self, value):
                    old_value = self.fields[index]

                    if not value is old_value:

                        if is_subfield:
                            card = self.card
                        else:
                            card = self

                        try:
                            old_value._unsubscribe(card)

                            if field_info.update_grid:
                                old_value.elems.remove(card)
                        except AttributeError:
                            pass

                        try:
                            value._subscribe(card)

                            if field_info.update_grid:
                                value.elems.add(card)
                        except AttributeError:
                            pass

                        self.fields[index] = value
        else:

            def wrapped(self, value):
                self.fields[index] = value

        return wrapped

    def add_subscheme_factory(index, field_info):

        def wrapped(self, *args, **kwargs):

            if kwargs:
                args = list()

                for subfield_info in field_info.subscheme.scheme:

                    try:
                        args.append(kwargs[subfield_info.name])
                    except KeyError:
                        args.append(None)

            subscheme = field_info.subscheme(args, self)

            if field_info.seq_type == 'list':
                self.fields[index].append(subscheme)
            elif field_info.seq_type == 'set':
                self.fields[index].add(subscheme)

        return wrapped

    if card_name in ('FORCE', 'MOMENT'):
        cls_parents = (SetCard, VectorCard,)
    elif card_type in ('mpc', 'spc', 'load'):
        cls_parents = (SetCard,)
    elif card_type == 'coord':
        cls_parents = (CoordCard,)
    elif card_type == 'elem':
        cls_parents = (ElemCard,)
    elif card_type == 'grid':
        cls_parents = (GridCard,)
    elif card_type == 'include':
        cls_parents = (IncludeCard,)
    else:
        cls_parents = (Card,)

    cls = type(card_name, cls_parents, {})
    cls.type = card_type
    cls.tag = card_tag
    cls._scheme = card_scheme

    if card_scheme:
        cls._optional_scheme = {field_info.name: (index, field_info) for
                               index, field_info in enumerate(card_scheme) if
                               field_info.optional}

    cls._padding = card_padding

    if cls._optional_scheme and not cls._padding:
        cls._padding = Padding()

    if card_scheme:

        for index, field_info in enumerate(card_scheme):

            if field_info.subscheme:
                subscheme_cls = type('{}_{}'.format(card_name, field_info.name), (Subscheme,), {})
                subscheme_cls.scheme = field_info.subscheme
                field_info.subscheme = subscheme_cls

                if field_info.seq_type:
                    setattr(cls, 'add_{}'.format(get_singular(field_info.name)),
                            add_subscheme_factory(index, field_info))

                for subindex, subfield_info in enumerate(field_info.subscheme.scheme):

                    if subfield_info.name:
                        setattr(field_info.subscheme, subfield_info.name,
                                property(get_field_factory(subindex, subfield_info),
                                         set_field_factory(subindex, subfield_info,
                                                           is_subfield=True)))

            if field_info.name and not hasattr(cls, field_info.name):
                setattr(cls, field_info.name,
                        property(get_field_factory(index, field_info),
                                 set_field_factory(index, field_info)))

            if field_info.alternate_name and not hasattr(cls, field_info.alternate_name):
                setattr(cls, field_info.alternate_name,
                        property(get_field_factory(index, field_info, alternate_name=True),
                                 set_field_factory(index, field_info, alternate_name=True)))

        if card_type == 'elem' and not 'grids' in [x.name for x in card_scheme]:
            setattr(cls, 'grids', property(get_grids_factory(card_scheme)))

    if card_name in card_interfaces_additional:

        for method_name, (function, is_property) in card_interfaces_additional[card_name].items():

            if is_property:
                setattr(cls, method_name, property(function))
            else:
                setattr(cls, method_name, function)

    return cls
```


Overlapping Code:
```
card_type, card_scheme=None, card_tag=None, card_padding=None):
def get_grids_factory(card_scheme):
fields_info = [(index, field_info) for index, field_info in enumerate(card_scheme) if
field_info.update_grid or
field_info.subscheme and any(x.update_grid for x in field_info.subscheme.scheme)]
def wrapped(self):
grids = set()
for index, field_info in fields_info:
if field_info.seq_type:
if field_info.subscheme:
for subfield in self.fields[index]:
for subsubfield, subsubfield_info in zip(subfield, field_info.subscheme.scheme):
if subsubfield_info.update_grid:
if subsubfield_info.seq_type:
grids |= set(subsubfield)
else:
grids.add(subsubfield)
else:
if field_info.update_grid:
grids |= set(self.fields[index])
else:
if field_info.subscheme:
for subfield, subfield_info in zip(field, field_info.subscheme.scheme):
if subfield_info.update_grid:
if subfield_info.seq_type:
grids |= set(subfield)
else:
grids.add(subfield)
else:
if field_info.update_grid:
grids.add(self.fields[index])
return grids
return wrapped
def get_field_factory(index, field_info, alternate_name=False):
if field_info.seq_type == 'vector':
if field_info.type == 'grid':
def wrapped(self):
vector = self.fields[index]
if alternate_name:
if not vector is None and isinstance(vector[0], (int, Card)):
vector = vector[0]
else:
vector = None
else:
if vector is None:
vector = np.array([0.0, 0.0, 0.0])
elif isinstance(vector[0], C
```
<Overlap Ratio: 0.9762900976290098>

---

--- 81 --
Question ID: b74c22a548eea2d8fd026e1d0f5f5426a57d4274_3
Original Code:
```
def test_parse_pbo_nlc():
    input_text = "*zorro!\nmin: -40 x1 3 x2 ~x3 \n" + input_text_nlc
    input_file = StringIO.StringIO(input_text)
    instance = borg.domains.pb.opb.parse_opb_file(input_file)

    nose.tools.assert_equal(len(instance.constraints), 4)
    nose.tools.assert_equal(instance.objective, [(-40, [1]), (3, [2, -3])])
```


Overlapping Code:
```

input_text = "*zorro!\nmin: -40 x1 3 x2 ~x3 \n" + input_text_nlc
input_file = StringIO.StringIO(input_text)
instance = borg.domains.pb.opb.parse_opb_file(input_file)
nose.tools.assert_equal(len(instance.constraints), 4)
nose.tools.assert_equal(instance.objective,
```
<Overlap Ratio: 0.832807570977918>

---

--- 82 --
Question ID: 08d2f5a01d17227166db812376a83627a485d222_6
Original Code:
```
def test_predictWoolf_f1fOREST():
	classifierType = 'fOREST'
	scalerString = 'None'
	cvFolds = 5
	scoringM = 'accuracy'
	nNhrs = range(15,20)
	nTrs = range(1,15,2)
	minL = range(10,30,3)
	inputCSV = classBDtable

	model = woolfClassifier.buildWoolf(classifierType, scalerString, cvFolds, scoringM, nNhrs, nTrs, minL)
	woolfClassifier.trainModel(model, inputCSV)
	resultsDict, score = woolfClassifier.predictWoolf(model, inputCSV)
	assert model.best_score_ == 0.9777777777777779
	assert resultsDict['AAM63403.1'] == 1
	assert score == 1
```


Overlapping Code:
```
 test_predictWoolf_f1fOREST():
classifierType = 'fOREST'
scalerString = 'None'
cvFolds = 5
scoringM = 'accuracy'
nNhrs = range(15,20)
nTrs = range(1,15,2)
minL = range(10,30,3)
inputCSV = classBDtable
model = woolfClassifier.buildWoolf(classifierType, scalerString, cvFolds, scoringM, nNhrs, nTrs, minL)
woolfClassifier.trainModel(model, inputCSV)
resultsDict, score = woolfClassifier.predictWoolf(model, inputCSV)
assert model.best_score_ == 0.9777777777777779
assert resultsDict['AAM63403.1'] == 1

```
<Overlap Ratio: 0.9615384615384616>

---

--- 83 --
Question ID: 6c128b492f71ce909275b5e6645bcedcce4f03aa_0
Original Code:
```
def ex1_met1(x):
    "Pas a pas"

    print("Avec x= ",x)
    a = x + 1
    b = a * 2
    c = b - 3

    print("-------------> Le resultat est : ",c)
```


Overlapping Code:
```
as a pas"
print("Avec x= ",x)
a = x + 1
b = a * 2
c = b - 3
print("-------------> Le resultat est : 
```
<Overlap Ratio: 0.8130081300813008>

---

--- 84 --
Question ID: 2fa5d7e276ad3f742196d6271ee2753812425e18_2
Original Code:
```
def active_status(senseHat):
    """
    A function to update the LED matrix regularly
    to show that the experiment is progressing
    """
    # a list with all possible rotation values
    orientation = [0,90,270,180]
    # pick one at random
    rot = random.choice(orientation)
    # set the rotation
    senseHat.set_rotation(rot)
    senseHat.set_pixels(img1)
```


Overlapping Code:
```
t):
"""
A function to update the LED matrix regularly
to show that the experiment is progressing
"""
# a list with all possible rotation values
orientation = [0,90,270,180]
# pick one at random
rot = random.choice(orientation)
# set the rotation
sens
```
<Overlap Ratio: 0.7739938080495357>

---

--- 85 --
Question ID: 6eb7dc28dc13b150a82a7aa82c8765acb1568f43_1
Original Code:
```
def download(making_links):
    for link in making_links:
        file_name = link.split('/')[-1]
        print("Downloading : " + file_name)
        r = requests.get(link, stream=True)
        with open(file_name, 'wb') as f:
            total_length = int(r.headers.get('content-length'))
            for chunk in progress.bar(r.iter_content(chunk_size=1024), expected_size=(total_length / 1024) + 1):
                if chunk:
                    f.write(chunk)
                    f.flush()
        print(file_name + " Downloaded ;)")
    print("All videos Downloaded")
```


Overlapping Code:
```
 making_links:
file_name = link.split('/')[-1]
print("Downloading : " + file_name)
r = requests.get(link, stream=True)
with open(file_name, 'wb') as f:
total_length = int(r.headers.get('content-length'))
for chunk in progress.bar(r.iter_content(chunk_size=1024), expected_size=(total_length / 1024) + 1):
if chunk:
f.write(chunk)
f.flush()
print(file_name + " Downloaded ;)")
print("All videos Downlo
```
<Overlap Ratio: 0.898876404494382>

---

--- 86 --
Question ID: c826db6970532e15b43d7ec1037d00e74c3995a8_2
Original Code:
```
def weight_matrix(training_filename, get_scale=False, delim=','):
    """
    Returns the weight matrix built from the data in the file
    at the filename given as the first argument, scaled according to
    the values in the file.
    """
    training_scale = scale(training_filename, delim)
    with open(training_filename, 'r') as training_file:
        for line in training_file:
            x_i, y_i = parse_vectors(line, training_scale, delim)
            try:
                sum_xi += x_i * x_i.T
                sum_yi += x_i * y_i.T
            except NameError:
                sum_xi = x_i * x_i.T
                sum_yi = x_i * y_i.T
            except ValueError: # row has differing number of attributes
                if sum_xi.shape[0] < x_i.shape[0]:
                    # more attributes, use this as the standard
                    sum_xi = x_i * x_i.T
                    sum_yi = x_i * y_i.T
                else:
                    # less attributes, ignore it
                    pass
    try:
        W = sum_xi.I * sum_yi # will raise exception if no inverse
    except linalg.LinAlgError:
        W = (sum_xi + 0.00001*identity(sum_xi.shape[0])).I * sum_yi
    if get_scale:
        return W, training_scale
    return W
```


Overlapping Code:
```
e=False, delim=','):
"""
Returns the weight matrix built from the data in the file
at the filename given as the first argument, scaled according to
the values in the file.
"""
training_scale = scale(training_filename, delim)
with open(training_filename, 'r') as training_file:
for line in training_file:
x_i, y_i = parse_vectors(line, training_scale, delim)
try:
sum_xi += x_i * x_i.T
sum_yi += x_i * y_i.T
except NameError:
sum_xi = x_i * x_i.T
sum_yi = x_i * y_i.T
except ValueError: # row has differing number of attributes
if sum_xi.shape[0] < x_i.shape[0]:
# more attributes, use this as the standard
sum_xi = x_i * x_i.T
sum_yi = x_i * y_i.T
else:
# less attributes, ignore it
pass
try:
W = sum_xi.I * sum_yi # will raise exception if no inverse
except linalg.LinAlgError:
W = (sum_xi + 0.00001*identity(sum_xi.shape[0])).I * sum_yi
if get_scal
```
<Overlap Ratio: 0.9129967776584318>

---

--- 87 --
Question ID: 41a117bd1c9bb6acbb54ee9487d1923bfc39cda0_0
Original Code:
```
def read_json_content(filename):
  json_content = {}
  with codecs.open(filename, encoding="utf-8") as f:
    json_content = json.loads(f.read())
  if not json_content:
    print("ERROR: No content found in ", filename)
  return json_content
```


Overlapping Code:
```
json_content = {}
with codecs.open(filename, encoding="utf-8") as f:
json_content = json.loads(f.read())
if not json_content:
print("ERROR: No content found in ", fi
```
<Overlap Ratio: 0.7333333333333333>

---

--- 88 --
Question ID: 56690d670f8e3cc5abf9235f44543bab55462b75_4
Original Code:
```
def _read_template(template_name):
    """
    Open a template file, read the definition, and translate it into the format expected by boto.
    If log_location is supplied, insert it into the template definition before returning it.
    """
    with open_normalized(DataPipelineConsts.TEMPLATE_DIR, template_name + ".json") as f:
        template_data = json.load(f)
    boto_objects, boto_params = template_to_boto(template_data)
    return boto_objects, boto_params
```


Overlapping Code:
```
ame):
"""
Open a template file, read the definition, and translate it into the format expected by boto.
If log_location is supplied, insert it into the template definition before returning it.
"""
with open_normalized(DataPipelineConsts.TEMPLATE_DIR, template_name + ".json") as f:
template_data = json.load(f)
boto_objects, boto_params = template_to_boto(template_data)
return boto_objects, boto_par
```
<Overlap Ratio: 0.9259259259259259>

---

--- 89 --
Question ID: f07be9c18ba9de55a8e23ff331fe6a38e916c333_2
Original Code:
```
@blueprint.get('/roles/<role_id>')
@permission_required('role.view')
@templated
def role_view(role_id):
    """View role details."""
    role = authorization_service.find_role(role_id)

    if role is None:
        abort(404)

    all_permissions = permission_registry.get_registered_permissions()

    role_permission_ids = authorization_service.get_permission_ids_for_role(
        role.id
    )

    permissions = {
        permission
        for permission in all_permissions
        if permission.id in role_permission_ids
    }

    user_ids = authorization_service.find_user_ids_for_role(role.id)
    users = user_service.get_users(user_ids, include_avatars=True)

    return {
        'role': role,
        'permissions': permissions,
        'users': users,
    }
```


Overlapping Code:
```
print.get('/roles/<role_id>')
@permission_required('role.view')
@templated
def role_view(role_id):
"""View role details."""
role = authorization_service.find_role(role_id)
if role is None:
abort(404)
all_permissions = permission_registry.get_registered_permissions()
role_permission_ids = authorization_service.get_permission_ids_for_role(
role.id
)
permissions = {
permission
for permission in all_permissions
if permission.id in role_permission_ids
}
user_ids = authorization_service.find_user_ids_for_role(role.id)
users = user_service.get_users(user_ids, include_avatars=True)
return {
'role': role,
'permissions': permiss
```
<Overlap Ratio: 0.9571865443425076>

---

--- 90 --
Question ID: 2e35e9946a5e52b471300f5be0dd7b5ee6330705_1
Original Code:
```
def crosscorr1(img, refim, shrange, dsh=(1,1)):
	"""
	Calculate cross-correlation for only 1 image. See crosscorr() for 
	details.
	"""

	if (img.shape != refim.shape):
		raise ValueError("<refim> should be same size as <img>")

	sh0, sh1 = shrange
	dsh0, dsh1 = dsh
	imsz0, imsz1 = img.shape

	# Shift ranges need to be larger than 0
	if (sh0 < 1 or sh1 < 1):
		raise ValueError("<shrange> should be larger than 0")

	# We need a crop window to allow for image shifting
	sm_crop = [slice(sh0, -sh0), slice(sh1, -sh1)]

	# Calculate correlation for img with <refim>
	xcorr = np.r_[ [[
		np.sum(refim[sh0+shi:imsz0-sh0+shi, sh1+shj:imsz1-sh1+shj] * img[sm_crop])
		for shj in xrange(-sh1, sh1+1, dsh1)]
			for shi in xrange(-sh0, sh0+1, dsh0)]
				] # // np.r_

	return xcorr
```


Overlapping Code:
```
efim, shrange, dsh=(1,1)):
"""
Calculate cross-correlation for only 1 image. See crosscorr() for 
details.
"""
if (img.shape != refim.shape):
raise ValueError("<refim> should be same size as <img>")
sh0, sh1 = shrange
dsh0, dsh1 = dsh
imsz0, imsz1 = img.shape
# Shift ranges need to be larger than 0
if (sh0 < 1 or sh1 < 1):
raise ValueError("<shrange> should be larger than 0")
# We need a crop window to allow for image shifting
sm_crop = [slice(sh0, -sh0), slice(sh1, -sh1)]
# Calculate correlation for img with <refim>
xcorr = np.r_[ [[
np.sum(refim[sh0+shi:imsz0-sh0+shi, sh1+shj:imsz1-sh1+shj] * img[sm_crop])
for shj in xrange(-sh1, sh1+1, dsh1)]
for shi in xrange(-sh0, sh0+1, dsh0)]
] # // np.r
```
<Overlap Ratio: 0.9525745257452575>

---

--- 91 --
Question ID: 66a05b4333837a57f5f32f3533c1867f2d117f04_16
Original Code:
```
def splice(image, frame_width, frame_height, margin_x=0, margin_y=0):
    # Arguments: image is of pygame.Surface
    x = 0
    y = 0

    sub_images = []

    src_width, src_height = image.get_size()

    while x + frame_width <= src_width and y + frame_height <= src_height:
        crop = Surface((frame_width, frame_height), flags=pygame.SRCALPHA)
        crop.blit(image, (0, 0), (x, y, frame_width, frame_height))

        sub_images.append(crop)

        x += frame_width + margin_x
        if x + frame_width > src_width:
            x = 0
            y += frame_height + margin_y

    return sub_images
```


Overlapping Code:
```
f splice(image, frame_width, frame_height, margin_x=0, margin_y=0):
# Arguments: image is of pygame.Surface
x = 0
y = 0
sub_images = []
src_width, src_height = image.get_size()
while x + frame_width <= src_width and y + frame_height <= src_height:
crop = Surface((frame_width, frame_height), flags=pygame.SRCALPHA)
crop.blit(image, (0, 0), (x, y, frame_width, frame_height))
sub_images.append(crop)
x += frame_width + margin_x
if x + frame_width > src_width:
x = 0
y += frame_height + margin_y
return
```
<Overlap Ratio: 0.9746588693957114>

---

--- 92 --
Question ID: f79f4efbf73553d718a1d08b005b37e6f035abe7_12
Original Code:
```
def main():
    """
    Runs data processing scripts to turn raw data from (../raw) into
    cleaned data ready to be analyzed (saved in ../processed).
    """
    logger = logging.getLogger(__name__)

    if os.path.exists(processed_filepath):
        logger.info('remove existing processed dataset')
        os.remove(processed_filepath)

    manager = Manager(get_data_file())
    logger.info('creating tables')
    manager.create_tables()
    logger.info('populating the database')
    manager.populate_tables()
    logger.info('recording metrics')
    manager.write_metrics()

    logger.info('modifying database')
    modifier = DatabaseModifier()

    logger.info('dataset generation complete')
```


Overlapping Code:
```
""
Runs data processing scripts to turn raw data from (../raw) into
cleaned data ready to be analyzed (saved in ../processed).
"""
logger = logging.getLogger(__name__)
if os.path.exists(processed_filepath):
logger.info('remove existing processed dataset')
os.remove(processed_filepath)
manager = Manager(get_data_file())
logger.info('creating tables')
manager.create_tables()
logger.info('populating the database')
manager.populate_tables()
logger.info('recording metrics')
manager.write_metrics()
logger.info('modifying database')
modifier = DatabaseModifier()
l
```
<Overlap Ratio: 0.9124797406807131>

---

--- 93 --
Question ID: 8f4a2bd629b69e0fdd1ee52758e0d8fce11f8c51_7
Original Code:
```
def searchImage(searchName): # 태그나 파일명에 searchName이 포함되어 있는 파일 리스트를 검색하는 함수
    taglist = getTagList(); # 태그 먼저 검색
    result = [] # 검색결과를 저장할 배열
    for item in taglist:
        f = open(item, 'r')
        data = f.read()
        f.close()
        if (searchName not in data)==False: # 검색대상이 발견된 항목
            result.append(item)
    for i in range(0, len(result)):
        result[i] = result[i].replace('_tag.txt', '.jpg')
        print(result[i])
    imagelist = getImageList() # 이제 이미지 차례
    for item in imagelist:
        if (searchName not in item)==False: # 검색대상이 발견된 항목
            if item not in result:
                result.append(item)
    return result
```


Overlapping Code:
```
searchName이 포함되어 있는 파일 리스트를 검색하는 함수
taglist = getTagList(); # 태그 먼저 검색
result = [] # 검색결과를 저장할 배열
for item in taglist:
f = open(item, 'r')
data = f.read()
f.close()
if (searchName not in data)==False: # 검색대상이 발견된 항목
result.append(item)
for i in range(0, len(result)):
result[i] = result[i].replace('_tag.txt', '.jpg')
print(result[i])
imagelist = getImageList() # 이제 이미지 차례
for item in imagelist:
if (searchName not in item)==False: # 검색대상이 발견된 항목
if item not in result:
result.append(item)
return result
```
<Overlap Ratio: 0.9264705882352942>

---

--- 94 --
Question ID: 0af90ad7836c0460c70f2e6cc90a31a37fb93734_3
Original Code:
```
@asyncio.coroutine
def test_setup_component_test_servcie_stop(hass):
    """Setup ffmpeg component test service stop."""
    with assert_setup_component(2):
        yield from async_setup_component(
            hass, ffmpeg.DOMAIN, {ffmpeg.DOMAIN: {}})

    ffmpeg_dev = MockFFmpegDev(hass, False)
    yield from ffmpeg_dev.async_added_to_hass()

    ffmpeg.async_stop(hass)
    yield from hass.async_block_till_done()

    assert ffmpeg_dev.called_stop
```


Overlapping Code:
```
syncio.coroutine
def test_setup_component_test_servcie_stop(hass):
"""Setup ffmpeg component test service stop."""
with assert_setup_component(2):
yield from async_setup_component(
hass, ffmpeg.DOMAIN, {ffmpeg.DOMAIN: {}})
ffmpeg_dev = MockFFmpegDev(hass, False)
yield from ffmpeg_dev.async_added_to_hass()
ffmpeg.async_stop(hass)
yield from hass.async_block_till_done()
assert ffmpeg_dev.called_
```
<Overlap Ratio: 0.9850746268656716>

---

--- 95 --
Question ID: 74334800222db36105559125b406dbe04a585da0_16
Original Code:
```
def error_022_category_with_spaces(text):
    """Fix the error and return (new_text, replacements_count) tuple."""
    correct = len(re.findall(r"\[\[Категория:[^ ]", text))
    (text, fixed) = re.subn(r"\[\[\s*Категория\s*:", "[[Категория:", text, flags=re.I)
    count1 = fixed - correct

    (text, count2) = re.subn(r"(\[\[Категория:[^\[\]|]+?)\s+([\]|])", "\\1\\2", text, flags=re.I)
    return (text, count1 + count2)
```


Overlapping Code:
```
_spaces(text):
"""Fix the error and return (new_text, replacements_count) tuple."""
correct = len(re.findall(r"\[\[Категория:[^ ]", text))
(text, fixed) = re.subn(r"\[\[\s*Категория\s*:", "[[Категория:", text, flags=re.I)
count1 = fixed - correct
(text, count2) = re.subn(r"(\[\[Категория:[^\[\]|]+?)\s+([\]|])", "\\1\\2", text, flags=re.I)
return (text, count1 + count2
```
<Overlap Ratio: 0.9296482412060302>

---

--- 96 --
Question ID: 59ffcf0a499658edb4bd910b1c895224c8574a99_2
Original Code:
```
def route(*methods):
    """
    Method decorator to route HTTP methods to a method.  Called with
    an optional list of method strings (which will be canonicalized to
    uppercase).  If no methods are specified, all otherwise undefined
    methods will be routed to the decorated method.  This decorator is
    designed to work both with and without arguments--that is,
    ``@obj.route`` is equivalent to ``@obj.route()``.

    This decorator attaches a list of ``Method`` objects to the
    decorated function; these will be added to the controller class's
    root object appropriately by the metaclass.

    :returns: Either the appropriately decorated method, or a
              decorator for a method.
    """

    def decorator(func):
        meth_list = []

        # Construct the new Method objects
        seen = set()
        if methods:
            for meth_str in methods:
                if meth_str in seen:
                    continue
                seen.add(meth_str)

                meth = Method(meth_str, func)
                meth_list.append(meth)
        else:
            meth = Method(None, func)
            meth_list.append(meth)

        # Attach the method list to the function; this will be picked
        # up by the metaclass
        func._micropath_methods = meth_list

        # Mark the function as a handler
        func._micropath_handler = True

        # Pre-compute its want signature
        injector.WantSignature.from_func(func)

        return func

    # Check if methods consists of a single callable element
    if len(methods) == 1 and callable(methods[0]):
        func = methods[0]
        methods = ()
        return decorator(func)

    return decorator
```


Overlapping Code:
```
te(*methods):
"""
Method decorator to route HTTP methods to a method. Called with
an optional list of method strings (which will be canonicalized to
uppercase). If no methods are specified, all otherwise undefined
methods will be routed to the decorated method. This decorator is
designed to work both with and without arguments--that is,
``@obj.route`` is equivalent to ``@obj.route()``.
This decorator attaches a list of ``Method`` objects to the
decorated function; these will be added to the controller class's
root object appropriately by the metaclass.
:returns: Either the appropriately decorated method, or a
decorator for a method.
"""
def decorator(func):
meth_list = []
# Construct the new Method objects
seen = set()
if methods:
for meth_str in methods:
if meth_str in seen:
continue
seen.add(meth_str)
meth = Method(meth_str, func)
meth_list.append(meth)
else:
meth = Method(None, func)
meth_list.append(meth)
# Attach the method list to the function; this will be picked
# up by the metaclass
func._micropath_methods = meth_list
# Mark the function as a handler
func._micropath_handler = True
# Pre-compute its want signature
injector.WantSignature.from_func(func)
return func
# Check if methods consists of a single callable element
if len(methods) == 1 and callable(methods[0]):
func = methods[0]
methods = ()
return decorator(func)
r
```
<Overlap Ratio: 0.9839650145772595>

---

--- 97 --
Question ID: e48af0bdd98e9a7254e68425c45f6cfd6c83dbc7_1
Original Code:
```
def parse_args():
    parser = argparse.ArgumentParser(
        description=__doc__,
        formatter_class=argparse.RawDescriptionHelpFormatter)

    parser.add_argument(
        '--host',
        help=f"""
        The server host.
        Default: {DEFAULT_HOST}
        """,
        default=DEFAULT_HOST)

    parser.add_argument(
        '--port', '-p',
        help=f"""
        The server port.
        Default: {DEFAULT_PORT}
        """,
        default=DEFAULT_PORT)

    parser.add_argument(
        'config_file',
        help=f"""
        The config file to use.
        Default: {DEFAULT_CONFIG_FILE}
        """,
        nargs='?',
        default=DEFAULT_CONFIG_FILE)

    argcomplete.autocomplete(parser)
    return parser.parse_args()
```


Overlapping Code:
```
def parse_args():
parser = argparse.ArgumentParser(
description=__doc__,
formatter_class=argparse.RawDescriptionHelpFormatter)
parser.add_argument(
'--host',
help=f"""
The server host.
Default: {DEFAULT_HOST}
""",
default=DEFAULT_HOST)
parser.add_argument(
'--port', '-p',
help=f"""
The server port.
Default: {DEFAULT_PORT}
""",
default=DEFAULT_PORT)
parser.add_argument(
'config_file',
help=f"""
The config file to use.
Default: {DEFAULT_CONFIG_FILE}
""",
nargs='?',
default=DEFAULT_CONFIG_FILE)
argcomplete.autocomplete(parser)
return parser.parse_arg
```
<Overlap Ratio: 0.9946043165467626>

---

--- 98 --
Question ID: 622c1a885856c432caebf0f02b52153443e2833e_3
Original Code:
```
def extract_parent_folder_id(html):
    soup = BeautifulSoup(html, 'lxml')
    folder_ids = soup.find_all(attrs={"name": "parent_folder_id"})

    if len(folder_ids) != 1:
        raise ParserError("Could not find parent folder ID")

    return folder_ids.pop().attrs.get("value", "")
```


Overlapping Code:
```
t_parent_folder_id(html):
soup = BeautifulSoup(html, 'lxml')
folder_ids = soup.find_all(attrs={"name": "parent_folder_id"})
if len(folder_ids) != 1:
raise ParserError("Could not find parent folder ID")
return folder_ids.pop().attrs.get
```
<Overlap Ratio: 0.9108527131782945>

---

--- 99 --
Question ID: 7c5bbb49679574a12c70037527b70d8e9a56695f_3
Original Code:
```
@unix
def test_popen_2():
    command = Popen(['ls', '-la'])

    assert command.communicate()[0] == run('ls -la').stdout
```


Overlapping Code:
```
():
command = Popen(['ls', '-la'])
assert command.
```
<Overlap Ratio: 0.44642857142857145>

---

--- 100 --
Question ID: 3ef0fddaaa76a4ae827f0e7576220719084d5b5a_11
Original Code:
```
def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):
    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)
    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)
    abs_sobelx = np.absolute(sobelx)
    abs_sobely = np.absolute(sobely)
    absgraddir = np.arctan2(abs_sobely, abs_sobelx)
    binary_output = np.zeros_like(absgraddir)
    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1
    return binary_output
```


Overlapping Code:
```
def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):
gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)
sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)
abs_sobelx = np.absolute(sobelx)
abs_sobely = np.absolute(sobely)
absgraddir = np.arctan2(abs_sobely, abs_sobelx)
binary_output = np.zeros_like(absgraddir)
binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1
return binary_output
```
<Overlap Ratio: 1.0>

---

--- 101 --
Question ID: a3dfb069e512b715ce960b986c0367d328ad5c7b_0
Original Code:
```
def test_Extract_inputs():
    input_map = dict(
        args=dict(argstr='%s', ),
        count=dict(
            argstr='-count %s',
            sep=',',
        ),
        environ=dict(
            nohash=True,
            usedefault=True,
        ),
        flip_any_direction=dict(
            argstr='-any_direction',
            xor=('flip_positive_direction', 'flip_negative_direction',
                 'flip_any_direction'),
        ),
        flip_negative_direction=dict(
            argstr='-negative_direction',
            xor=('flip_positive_direction', 'flip_negative_direction',
                 'flip_any_direction'),
        ),
        flip_positive_direction=dict(
            argstr='-positive_direction',
            xor=('flip_positive_direction', 'flip_negative_direction',
                 'flip_any_direction'),
        ),
        flip_x_any=dict(
            argstr='-xanydirection',
            xor=('flip_x_positive', 'flip_x_negative', 'flip_x_any'),
        ),
        flip_x_negative=dict(
            argstr='-xdirection',
            xor=('flip_x_positive', 'flip_x_negative', 'flip_x_any'),
        ),
        flip_x_positive=dict(
            argstr='+xdirection',
            xor=('flip_x_positive', 'flip_x_negative', 'flip_x_any'),
        ),
        flip_y_any=dict(
            argstr='-yanydirection',
            xor=('flip_y_positive', 'flip_y_negative', 'flip_y_any'),
        ),
        flip_y_negative=dict(
            argstr='-ydirection',
            xor=('flip_y_positive', 'flip_y_negative', 'flip_y_any'),
        ),
        flip_y_positive=dict(
            argstr='+ydirection',
            xor=('flip_y_positive', 'flip_y_negative', 'flip_y_any'),
        ),
        flip_z_any=dict(
            argstr='-zanydirection',
            xor=('flip_z_positive', 'flip_z_negative', 'flip_z_any'),
        ),
        flip_z_negative=dict(
            argstr='-zdirection',
            xor=('flip_z_positive', 'flip_z_negative', 'flip_z_any'),
        ),
        flip_z_positive=dict(
            argstr='+zdirection',
            xor=('flip_z_positive', 'flip_z_negative', 'flip_z_any'),
        ),
        image_maximum=dict(argstr='-image_maximum %s', ),
        image_minimum=dict(argstr='-image_minimum %s', ),
        image_range=dict(argstr='-image_range %s %s', ),
        input_file=dict(
            argstr='%s',
            extensions=None,
            mandatory=True,
            position=-2,
        ),
        nonormalize=dict(
            argstr='-nonormalize',
            xor=('normalize', 'nonormalize'),
        ),
        normalize=dict(
            argstr='-normalize',
            xor=('normalize', 'nonormalize'),
        ),
        out_file=dict(
            argstr='> %s',
            extensions=None,
            genfile=True,
            position=-1,
        ),
        output_file=dict(
            extensions=None,
            hash_files=False,
            keep_extension=False,
            name_source=['input_file'],
            name_template='%s.raw',
            position=-1,
        ),
        start=dict(
            argstr='-start %s',
            sep=',',
        ),
        write_ascii=dict(
            argstr='-ascii',
            xor=('write_ascii', 'write_ascii', 'write_byte', 'write_short',
                 'write_int', 'write_long', 'write_float', 'write_double',
                 'write_signed', 'write_unsigned'),
        ),
        write_byte=dict(
            argstr='-byte',
            xor=('write_ascii', 'write_ascii', 'write_byte', 'write_short',
                 'write_int', 'write_long', 'write_float', 'write_double',
                 'write_signed', 'write_unsigned'),
        ),
        write_double=dict(
            argstr='-double',
            xor=('write_ascii', 'write_ascii', 'write_byte', 'write_short',
                 'write_int', 'write_long', 'write_float', 'write_double',
                 'write_signed', 'write_unsigned'),
        ),
        write_float=dict(
            argstr='-float',
            xor=('write_ascii', 'write_ascii', 'write_byte', 'write_short',
                 'write_int', 'write_long', 'write_float', 'write_double',
                 'write_signed', 'write_unsigned'),
        ),
        write_int=dict(
            argstr='-int',
            xor=('write_ascii', 'write_ascii', 'write_byte', 'write_short',
                 'write_int', 'write_long', 'write_float', 'write_double',
                 'write_signed', 'write_unsigned'),
        ),
        write_long=dict(
            argstr='-long',
            xor=('write_ascii', 'write_ascii', 'write_byte', 'write_short',
                 'write_int', 'write_long', 'write_float', 'write_double',
                 'write_signed', 'write_unsigned'),
        ),
        write_range=dict(argstr='-range %s %s', ),
        write_short=dict(
            argstr='-short',
            xor=('write_ascii', 'write_ascii', 'write_byte', 'write_short',
                 'write_int', 'write_long', 'write_float', 'write_double',
                 'write_signed', 'write_unsigned'),
        ),
        write_signed=dict(
            argstr='-signed',
            xor=('write_signed', 'write_unsigned'),
        ),
        write_unsigned=dict(
            argstr='-unsigned',
            xor=('write_signed', 'write_unsigned'),
        ),
    )
    inputs = Extract.input_spec()

    for key, metadata in list(input_map.items()):
        for metakey, value in list(metadata.items()):
            assert getattr(inputs.traits()[key], metakey) == value

```


Overlapping Code:
```
inputs():
input_map = dict(
args=dict(argstr='%s', ),
count=dict(
argstr='-count %s',
sep=',',
),
environ=dict(
nohash=True,
usedefault=True,
),
flip_any_direction=dict(
argstr='-any_direction',
xor=('flip_positive_direction', 'flip_negative_direction',
'flip_any_direction'),
),
flip_negative_direction=dict(
argstr='-negative_direction',
xor=('flip_positive_direction', 'flip_negative_direction',
'flip_any_direction'),
),
flip_positive_direction=dict(
argstr='-positive_direction',
xor=('flip_positive_direction', 'flip_negative_direction',
'flip_any_direction'),
),
flip_x_any=dict(
argstr='-xanydirection',
xor=('flip_x_positive', 'flip_x_negative', 'flip_x_any'),
),
flip_x_negative=dict(
argstr='-xdirection',
xor=('flip_x_positive', 'flip_x_negative', 'flip_x_any'),
),
flip_x_positive=dict(
argstr='+xdirection',
xor=('flip_x_positive', 'flip_x_negative', 'flip_x_any'),
),
flip_y_any=dict(
argstr='-yanydirection',
xor=('flip_y_positive', 'flip_y_negative', 'flip_y_any'),
),
flip_y_negative=dict(
argstr='-ydirection',
xor=('flip_y_positive', 'flip_y_negative', 'flip_y_any'),
),
flip_y_positive=dict(
argstr='+ydirection',
xor=('flip_y_positive', 'flip_y_negative', 'flip_y_any'),
),
flip_z_any=dict(
argstr='-zanydirection',
xor=('flip_z_positive', 'flip_z_negative', 'flip_z_any'),
),
flip_z_negative=dict(
argstr='-zdirection',
xor=('flip_z_positive', 'flip_z_negative', 'flip_z_any'),
),
flip_z_positive=dict(
argstr='+zdirection',
xor=('flip_z_positive', 'flip_z_negative', 'flip_z_any'),
),
image_maximum=dict(argstr='-image_maximum %s', ),
image_minimum=dict(argstr='-image_minimum %s', ),
image_range=dict(argstr='-image_range %s %s', ),
input_file=dict(
argstr='%s',
extensions=None,
mandatory=True,
position=-2,
),
nonormalize=dic
```
<Overlap Ratio: 0.9892715979672502>

---

--- 102 --
Question ID: cfcf75474e5dcdd262c7b2b5f09cb4c25b966506_1
Original Code:
```
def include_version(global_root: str, version_obj: models.Version, hardlink: bool = True):
    """Include files in existing bundle version.

    Including a file means to link them into a folder in the root directory
    """
    LOG.info("Use global root path %s", global_root)
    global_root_dir = Path(global_root)
    if version_obj.included_at:
        raise VersionIncludedError(f"version included on {version_obj.included_at}")

    # generate root directory
    version_root_dir = global_root_dir / version_obj.relative_root_dir
    version_root_dir.mkdir(parents=True, exist_ok=True)
    LOG.info("created new bundle version dir: %s", version_root_dir)

    for file_obj in version_obj.files:
        # hardlink file to the internal structure
        file_obj_path = Path(file_obj.path)
        new_path = version_root_dir / file_obj_path.name
        link_file(file_path=file_obj_path, new_path=new_path, hardlink=hardlink)
        file_obj.path = str(new_path).replace(f"{global_root_dir}/", EMPTY_STR, 1)
```


Overlapping Code:
```
version(global_root: str, version_obj: models.Version, hardlink: bool = True):
"""Include files in existing bundle version.
Including a file means to link them into a folder in the root directory
"""
LOG.info("Use global root path %s", global_root)
global_root_dir = Path(global_root)
if version_obj.included_at:
raise VersionIncludedError(f"version included on {version_obj.included_at}")
# generate root directory
version_root_dir = global_root_dir / version_obj.relative_root_dir
version_root_dir.mkdir(parents=True, exist_ok=True)
LOG.info("created new bundle version dir: %s", version_root_dir)
for file_obj in version_obj.files:
# hardlink file to the internal structure
file_obj_path = Path(file_obj.path)
new_path = version_root_dir / file_obj_path.name
link_file(file_path=file_obj_path, new_path=new_path, hardlink=hardlink)
file_obj.path = str(new_path).replace(f"{global_root_dir}/", EMPT
```
<Overlap Ratio: 0.9771986970684039>

---

--- 103 --
Question ID: 71df144473af483112b363980909e14e73842e5c_1
Original Code:
```
def test_adddockerfile_todest(tmpdir, docker_tasker):  # noqa
    df_content = """
FROM fedora
RUN yum install -y python-django
CMD blabla"""
    df = df_parser(str(tmpdir))
    df.content = df_content

    workflow = DockerBuildWorkflow(MOCK_SOURCE, 'test-image')
    workflow.builder = X
    workflow.builder.df_path = df.dockerfile_path
    workflow.builder.df_dir = str(tmpdir)

    runner = PreBuildPluginsRunner(
        docker_tasker,
        workflow,
        [{
            'name': AddDockerfilePlugin.key,
            'args': {'nvr': 'jboss-eap-6-docker-6.4-77',
                     'destdir': '/usr/share/doc/'}
        }]
    )
    runner.run()
    assert AddDockerfilePlugin.key is not None

    expected_output = """
FROM fedora
RUN yum install -y python-django
ADD Dockerfile-jboss-eap-6-docker-6.4-77 /usr/share/doc/Dockerfile-jboss-eap-6-docker-6.4-77
CMD blabla"""
    assert df.content == expected_output
```


Overlapping Code:
```
adddockerfile_todest(tmpdir, docker_tasker): # noqa
df_content = """
FROM fedora
RUN yum install -y python-django
CMD blabla"""
df = df_parser(str(tmpdir))
df.content = df_content
workflow = DockerBuildWorkflow(MOCK_SOURCE, 'test-image')
workflow.builder = X
workflow.builder.df_path = df.dockerfile_path
workflow.builder.df_dir = str(tmpdir)
runner = PreBuildPluginsRunner(
docker_tasker,
workflow,
[{
'name': AddDockerfilePlugin.key,
'args': {'nvr': 'jboss-eap-6-docker-6.4-77',
'destdir': '/usr/share/doc/'}
}]
)
runner.run()
assert AddDockerfilePlugin.key is not None
expected_output = """
FROM fedora
RUN yum install -y python-django
ADD Dockerfile-jboss-eap-6-docker-6.4-77 /usr/share/doc/Dockerfile-jboss-eap-6-docker-6.4-77
CMD blabla"""
asse
```
<Overlap Ratio: 0.9481668773704172>

---

--- 104 --
Question ID: 9a7ce1cf4d5eaf6ad19181b37c1636128e793f30_3
Original Code:
```
def check_users():
    users = User.select()
    if not users.exists():
        create_user()
```


Overlapping Code:
```

```
<Overlap Ratio: 0.0>

---

--- 105 --
Question ID: 3e15b7f3f0991a77263001ed74033e3b858aa94f_1
Original Code:
```
def reverse_dns(ip):
	if ip is not None:
		try:
			return socket.gethostbyaddr(ip)[0]
		except socket.herror:
			return None
	else:
		return None
```


Overlapping Code:
```
ne:
try:
return socket.gethostbyaddr(ip)[0]
except socket.herror:
```
<Overlap Ratio: 0.4961832061068702>

---

--- 106 --
Question ID: aa3a4fa744b7067b924e6a35d22ff8d6899b4410_12
Original Code:
```
@add_.register(nd.NDArray)
def _(x , a, y):
    if a is 0: return
    if a is 1: x[:] += y
    else: x[:] += a*y
```


Overlapping Code:
```
 _(x , a, y):
if a is 0: return
if a is 1: x[:] +=
```
<Overlap Ratio: 0.5>

---

--- 107 --
Question ID: ab1453923530e269def244db6932ea0cea4bd9ab_10
Original Code:
```
def read_struct_array(fd, endian, header):
    """Read a struct array.
    Returns a dict with fields of the struct array.
    """
    # read field name length (unused, as strings are null terminated)
    field_name_length = read_elements(fd, endian, ['miINT32'])
    if field_name_length > 32:
        raise ParseError('Unexpected field name length: {}'.format(
                         field_name_length))

    # read field names
    fields = read_elements(fd, endian, ['miINT8'], is_name=True)
    if isinstance(fields, basestring):
        fields = [fields]

    # read rows and columns of each field
    empty = lambda: [list() for i in range(header['dims'][0])]
    array = {}
    for row in range(header['dims'][0]):
        for col in range(header['dims'][1]):
            for field in fields:
                # read the matrix header and array
                vheader, next_pos, fd_var = read_var_header(fd, endian)
                data = read_var_array(fd_var, endian, vheader)
                if field not in array:
                    array[field] = empty()
                array[field][row].append(data)
                # move on to next field
                fd.seek(next_pos)
    # pack the nested arrays
    for field in fields:
        rows = array[field]
        for i in range(header['dims'][0]):
            rows[i] = squeeze(rows[i])
        array[field] = squeeze(array[field])
    return array
```


Overlapping Code:
```
ay(fd, endian, header):
"""Read a struct array.
Returns a dict with fields of the struct array.
"""
# read field name length (unused, as strings are null terminated)
field_name_length = read_elements(fd, endian, ['miINT32'])
if field_name_length > 32:
raise ParseError('Unexpected field name length: {}'.format(
field_name_length))
# read field names
fields = read_elements(fd, endian, ['miINT8'], is_name=True)
if isinstance(fields, basestring):
fields = [fields]
# read rows and columns of each field
empty = lambda: [list() for i in range(header['dims'][0])]
array = {}
for row in range(header['dims'][0]):
for col in range(header['dims'][1]):
for field in fields:
# read the matrix header and array
vheader, next_pos, fd_var = read_var_header(fd, endian)
data = read_var_array(fd_var, endian, vheader)
if field not in array:
array[field] = empty()
array[field][row].append(data)
# move on to next field
fd.seek(next_pos)
# pack the nested arrays
for field in fields:
rows = array[field]
for i in range(header['dims'][0]):
rows[i] = squeeze(rows[i])
array[field] = squeeze(array[field])
return arr
```
<Overlap Ratio: 0.9812667261373773>

---

--- 108 --
Question ID: ac5adc216e25d4e12328bbe4b1ed47787893ea3f_11
Original Code:
```
def parameters_for_script(script_name, config):
    """Return a list consisting of :py:class:`cea.config.Parameter` objects for each parameter of a script"""
    import cea.scripts
    parameters = [p for _, p in config.matching_parameters(cea.scripts.by_name(script_name).parameters)]
    return parameters
```


Overlapping Code:
```
rameters_for_script(script_name, config):
"""Return a list consisting of :py:class:`cea.config.Parameter` objects for each parameter of a script"""
import cea.scripts
parameters = [p for _, p in config.matching_parameters(cea.scripts.by_name(script_name).parameters)]
return p
```
<Overlap Ratio: 0.9484536082474226>

---

--- 109 --
Question ID: 0443e73ee7d41587d26b2bc3e017b0aef2cec36e_7
Original Code:
```
def load_SL_data(City, path):

    ########################  loading data and graph #######################
    edges = pd.read_table("data/" + City.location + "Graph.txt",
                          sep=" ",
                          header=None,
                          names=['vx', 'vy', 'weight'])

    graph = nx.from_pandas_edgelist(edges, 'vx', 'vy', 'weight')

    temp1 = np.load(os.path.join(
        path, City.location + "DistanceMatrix0.dat"))
    temp2 = np.load(os.path.join(
        path, City.location + "DistanceMatrix1.dat"))
    test_distance_matrix = np.concatenate((temp1, temp2), axis=0)
    distance_matrix = np.load(os.path.join(
        path, City.location + "LandmarkDistanceMatrix.dat"))
    print("Matrix is loaded")

    ######################## preprocessing data #######################
    max_distance = np.amax(test_distance_matrix)
    distance_matrix = distance_matrix / max_distance
    test_distance_matrix = test_distance_matrix / max_distance

    return (distance_matrix, test_distance_matrix, max_distance)
```


Overlapping Code:
```
load_SL_data(City, path):
######################## loading data and graph #######################
edges = pd.read_table("data/" + City.location + "Graph.txt",
sep=" ",
header=None,
names=['vx', 'vy', 'weight'])
graph = nx.from_pandas_edgelist(edges, 'vx', 'vy', 'weight')
temp1 = np.load(os.path.join(
path, City.location + "DistanceMatrix0.dat"))
temp2 = np.load(os.path.join(
path, City.location + "DistanceMatrix1.dat"))
test_distance_matrix = np.concatenate((temp1, temp2), axis=0)
distance_matrix = np.load(os.path.join(
path, City.location + "LandmarkDistanceMatrix.dat"))
print("Matrix is loaded")
######################## preprocessing data #######################
max_distance = np.amax(test_distance_matrix)
distance_matrix = distance_matrix / max_distance
test_distance_matrix = test_distance_matrix / max_distance
return (distance_matrix, test_distance_matri
```
<Overlap Ratio: 0.9775280898876404>

---

--- 110 --
Question ID: 5642bea2a4d006a16cb5dc638961e8224156c351_1
Original Code:
```
@CELERY.task
def add_task(name):
    """Run the slow task as a subprocess and send results to the web site."""
    args = './slow_task.sh', str(name)
    with Popen(args, stdout=PIPE, universal_newlines=True) as proc:
        for line in proc.stdout:
            SOCKETIO.emit('log', {'data': line.rstrip()})
```


Overlapping Code:
```
Run the slow task as a subprocess and send results to the web site."""
args = './slow_task.sh', str(name)
with Popen(args, stdout=PIPE, universal_newlines=True) as proc:
for line in proc.stdout:
SOCKE
```
<Overlap Ratio: 0.7246376811594203>

---

--- 111 --
Question ID: db06d0b14e9aad2ae963b334510ce8660f791696_4
Original Code:
```
@app.route('/user/<int:user_id>')
def user(user_id):
    u = User()
    return render_template('user.html', user=u.getUser(user_id))
```


Overlapping Code:
```
@app.route('/user/<int:user_id>')
def user(user_id):
u = User()
return render_template('user.html'
```
<Overlap Ratio: 0.7903225806451613>

---

--- 112 --
Question ID: 2b79d969415fd169a171e0d4ec07c0f23e0b6f98_1
Original Code:
```
def _decoding_base_info(encoded_info):
    """
    Decode base info

    Args:
        encoded_info(list or dict): encoded base info
    """
    if isinstance(encoded_info, dict):
        return encoded_info
    base_info = dict()
    for item in encoded_info:
        base_info[item['symbol']] = item['base']
    return base_info
```


Overlapping Code:
```
se_info(encoded_info):
"""
Decode base info
Args:
encoded_info(list or dict): encoded base info
"""
if isinstance(encoded_info, dict):
return encoded_info
base_info = dict()
for item in encoded_info:
base_info[item['symbol']] = item['base']
return ba
```
<Overlap Ratio: 0.9157509157509157>

---

--- 113 --
Question ID: d6bde785ae4a603ccea1d9f9eddf6af4a21ebf1f_0
Original Code:
```
def get_token():
    request = requests.get('http://randomword.setgetgo.com/get.php')
    word = request.text
    print("")
    print('\x1b[0m' + "Hashing the word "  + '\033[93m' + word + '\x1b[0m' + ". Please wait..." + '\033[92m')
    print('\033[92m')
    password = word.encode(encoding='UTF-8',errors='strict')
    hashed = bcrypt.hashpw(password, bcrypt.gensalt(14))
    return hashed
```


Overlapping Code:
```
andomword.setgetgo.com/get.php')
word = request.text
print("")
print('\x1b[0m' + "Hashing the word " + '\033[93m' + word + '\x1b[0m' + ". Please wait..." + '\033[92m')
print('\033[92m')
password = word.encohashed = bcrypt.hashpw(password, bcrypt.gensalt(14))
retur
```
<Overlap Ratio: 0.7374301675977654>

---

--- 114 --
Question ID: 6f065391b142fb5086549b76efcd40486efd4aa6_0
Original Code:
```
def interactive(*args, **kwargs):
    '''Creates a SparkContext for interactive use.
    '''
    import pyspark
    conf = pyspark.SparkConf(*args, **kwargs)
    ctx = pyspark.SparkContext(conf=conf)
    return ctx
```


Overlapping Code:
```
):
'''Creates a SparkContext for interactive use.
'''
import pyspark
conf = pyspark.SparkConf(*args, **kwargs)
ctx = pyspark.SparkContext(conf=conf)
r
```
<Overlap Ratio: 0.7894736842105263>

---

--- 115 --
Question ID: 263abdc55241644f3988aed23d8d9bdecca25e2d_4
Original Code:
```
def banr(regs: Sequence[int], a: int, b: int, c: int) -> List[int]:
    result = list(regs)
    result[c] = result[a] & result[b]
    return result
```


Overlapping Code:
```
(regs: Sequence[int], a: int, b: int, c: int) -> List[int]:
result = list(regs)
result[c] = result[a] & result[b]
return resu
```
<Overlap Ratio: 0.9259259259259259>

---

--- 116 --
Question ID: 0b03a1493e6c7828ba6a88636633e53bdfc3dcc0_4
Original Code:
```
def __readRawcStream(f):
    vertexes = []
    faces = []
    for line in f.readlines():
        lnarr = line.strip().split(' ')
        lenlarr = len(lnarr)
        if lenlarr == 2:
            # number of vertexes and number of faces
            pass
        elif lenlarr == 6:
            vertex = [
                float(lnarr[0]),
                float(lnarr[1]),
                float(lnarr[2])
            ]
            vertexes.append(vertex)
        elif lenlarr == 3:
            face = [
                int(lnarr[0]),
                int(lnarr[2]),
                int(lnarr[1])
            ]
            faces.append(face)

    return vertexes, faces
```


Overlapping Code:
```
_readRawcStream(f):
vertexes = []
faces = []
for line in f.readlines():
lnarr = line.strip().split(' ')
lenlarr = len(lnarr)
if lenlarr == 2:
# number of vertexes and number of faces
pass
elif lenlarr == 6:
vertex = [
float(lnarr[0]),
float(lnarr[1]),
float(lnarr[2])
]
vertexes.append(vertex)
elif lenlarr == 3:
face = [
int(lnarr[0]),
int(lnarr[2]),
int(lnarr[1])
]
faces.append(face)
return vertexes,
```
<Overlap Ratio: 0.9734299516908212>

---

--- 117 --
Question ID: a76539d63c30a989cb7da6378964de67e875ec90_4
Original Code:
```
def get_credentials(rcfile='~/.virlrc'):
    """
    Used to get the VIRL credentials

    * The login credentials are taken in the following order

    * Check for .virlrc in current directory

    * Check environment variables

    * Check ~/.virlrc

    * Prompt user

    """
    # initialize vars
    host = None
    username = None
    password = None
    config = dict()

    host = get_prop('VIRL_HOST')
    username = get_prop('VIRL_USERNAME')
    password = get_prop('VIRL_PASSWORD')

    # some additional configuration that can be set / overriden
    configurable_props = ['VIRL_TELNET_COMMAND', 'VIRL_CONSOLE_COMMAND',
                          'VIRL_SSH_COMMAND', 'VIRL_SSH_USERNAME']

    for p in configurable_props:
        if get_prop(p):
            config[p] = get_prop(p)

    if not host:  # pragma: no cover
        prompt = 'Please enter the IP / hostname of your virl server: '
        host = _get_from_user(prompt)

    if not username:
        username = _get_from_user("Please enter your VIRL username: ")

    if not password:
        password = _get_password("Please enter your password: ")

    if not all([host, username, password]):  # pragma: no cover
        prompt = "Unable to determine VIRL credentials, please see docs"
        sys.exit(prompt)
    else:
        return (host, username, password, config)
```


Overlapping Code:
```
f get_credentials(rcfile='~/.virlrc'):
"""
Used to get the VIRL credentials
* The login credentials are taken in the following order
* Check for .virlrc in current directory
* Check environment variables
* Check ~/.virlrc
* Prompt user
"""
# initiali')
username = get_prop('VIRL_USERNAME')
password = get_prop('VIRL_PASSWORD')
# some additional configuration that can be set / overriden
configurable_props = ['VIRL_TELNET_COMMAND', 'VIRL_CONSOLE_COMMAND',
'VIRL_SSH_COMMAND', 'VIRL_SSH_USERNAME']
for p in configurable_props:
if get_prop(p):
config[p] = get_prop(p)
if not host: # pragma: no cover
prompt = 'Please enter the IP / hostname of your virl server: '
host = _get_from_user(prompt)
if not username:
username = _get_from_user("Please enter your VIRL username: ")
if not password:
password = _get_password("Please enter your password: ")
if not all([host, username, password]): # pragma: no cover
prompt = "Unable to determine VIRL credentials, please see docs"
sys.exit(prompt)
else:
return 
```
<Overlap Ratio: 0.8849557522123894>

---

--- 118 --
Question ID: 3db2c6e6cf4d2fec1d014dae352f88a3c154522f_35
Original Code:
```
def priors(name, vary):
    """Return covariance matrix with prior knowledge about parameters"""
    
    mock = pickle.load(open('../data/mock_{}.params'.format(name), 'rb'))
    
    cprog = mock['prog_prior']
    cbary = np.array([0.1*x.value for x in pparams_fid[:5]])**-2
    chalo = np.zeros(4)
    cdipole = np.zeros(3)
    cquad = np.zeros(5)
    coctu = np.zeros(7)
    
    priors = {'progenitor': cprog, 'bary': cbary, 'halo': chalo, 'dipole': cdipole, 'quad': cquad, 'octu': coctu}
    cprior = np.empty(0)
    for v in vary:
        cprior = np.concatenate([cprior, priors[v]])
    
    pxi = np.diag(cprior)
    
    return pxi
```


Overlapping Code:
```
rix with prior knowledge about parameters"""

mock = pickle.load(open('../data/mock_{}.params'.format(name), 'rb'))

cprog = mock['prog_prior']
cbary = np.array([0.1*x.value for x in pparams_fid[:5]])**-2
chalo = np.zeros(4)
cdipole = np.zeros(3)
cquad = np.zeros(5)
coctu = np.zeros(7)

priors = {'progenitor': cprog, 'bary': cbary, 'halo': chalo, 'dipole': cdipole, 'quad': cquad, 'octu': coctu}
cprior = np.empty(0)
for v in vary:
cprior = np.concatenate([cprior, priors[v]])

pxi = np.diag(cprior
```
<Overlap Ratio: 0.8912655971479501>

---

--- 119 --
Question ID: 21bf5be63116fa725f3351ed4123e8717c4be72c_4
Original Code:
```
def shuffle(x):
    x = list(x)
    random.shuffle(x)
    return x
```


Overlapping Code:
```

```
<Overlap Ratio: 0.0>

---

--- 120 --
Question ID: d4cb0cc6d7a63e94ae40b4bd4009e81ad2f8c88c_8
Original Code:
```
def checkarguments():
    global lval

    if len(sys.argv) != 2:
        return

    if sys.argv[1] == "debug":
        run_test()
        time.sleep(2)
        sensors.stop()
        webserver.stop()
        log.info("main", "exit (debug)")
        GPIO.cleanup()
        exit()
    if sys.argv[1] == "fakeval":
        analyze("$1;1;;10,1;20,2;30,3;40,4;50,5;60,6;70,7;80,8;90,9;10,1;11,2;12,3;13,4;14,5;15,6;16,7")
        lval = list(values)
        lval[0] = "8.8"
        lval[1] = "22.5"
        once_a_hour()
        once_a_day(0)
        analyze("$1;1;;10,1;20,2;30,3;40,4;50,5;60,6;70,7;80,8;90,9;10,1;11,2;12,3;13,4;14,5;15,6;16,7")

    return
```


Overlapping Code:
```
v) != 2:
return
if sys.argv[1] == "debug":
run_test()
time.sleep(2)
sensors.stop()
webserver.stop()
log.info("main", "exit (debug)")
GPIO.cleanup()
exit()
if sys.argv[1] == "fakeval":
analyze("$1;1;;10,1;20,2;30,3;40,4;50,5;60,6;70,7;80,8;90,9;10,1;11,2;12,3;13,4;14,5;15,6;16,7")
lval = list(values)
lval[0] = "8.8"
lval[1] = "22.5"
once_a_hour()
once_a_day(0)
analyze("$1;1;;10,1;20,2;30,3;40,4;50,5;60,6;70,7;80,8;90,9;10,1;11,2;12,3;13,4;14,5;15,
```
<Overlap Ratio: 0.8771929824561403>

---

--- 121 --
Question ID: 78e91249c82c500bcea7e9536046e7cb366ad21f_12
Original Code:
```
def VonMises_dQ (Y, sigm, dsbar, theta):
    dQ_dsigm = 0.0
    dQ_dJ2 = 1.5/dsbar
    dQ_dJ3 = 0.0
    return (dQ_dsigm, dQ_dJ2, dQ_dJ3)
```


Overlapping Code:
```
 = 0.0
dQ_dJ2 = 1.5/dsbar
dQ_dJ3 = 0.0
return (dQ_
```
<Overlap Ratio: 0.4132231404958678>

---

--- 122 --
Question ID: c1f5f70ec491155a8d91b27953e2928c89b71a7a_1
Original Code:
```
def get_quantiles_summary(cds_cai_dat,num_of_quantiles,R20_vec_compare,vec_cost):
    # we can use this 'qcut' function from pandas to divide our proteins by the quantiles ...
    category,bins = pd.qcut(cds_cai_dat['CAI'],q=num_of_quantiles,retbins=True,labels=False)
    # then we could iterate over proteins/cDNAs in these categories ...
    fivywrel_cat, r20_cat, cost_cat = [],[],[]
    for cat in range(num_of_quantiles):
        cds_cai_category = cds_cai_dat[category==cat]
        protein_length_distro = cds_cai_category['protein'].str.len()
        # average protein length per quantile as a stability measure ...
        average_length = protein_length_distro.mean()
        # total proteins length in quantile for AA freqs calculations ...
        total_length = protein_length_distro.sum()
        IVYWREL = sum(cds_cai_category['protein'].str.count(aa).sum() for aa in list('IVYWREL'))
        # IVYWREL = cds_cai_category['protein'].str.count('|'.join("IVYWREL")).sum() # tiny bit slower ...
        f_IVYWREL = float(IVYWREL)/float(total_length)
        # 20-vector for of amino acid composition ...
        aa_freq_20 = np.true_divide([cds_cai_category['protein'].str.count(aa).sum() for aa in aacids],float(total_length))
        # slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)
        _1,_2,R20,_4,_5 = stats.linregress(aa_freq_20, R20_vec_compare)
        # Akashi ...
        cost = np.dot(aa_freq_20,vec_cost)
        # storing info ...
        fivywrel_cat.append(f_IVYWREL)
        r20_cat.append(R20)
        cost_cat.append(cost)
    #returning ...
    return (fivywrel_cat,r20_cat,cost_cat)
```


Overlapping Code:
```
ef get_quantiles_summary(cds_cai_dat,num_of_quantiles,R20_vec_compare,vec_cost):
# we can use this 'qcut' function from pandas to divide our proteins by the quantiles ...
category,bins = pd.qcut(cds_cai_dat['CAI'],q=num_of_quantiles,retbins=True,labels=False)
# then we could iterate over proteins/cDNAs in these categories ...
fivywrel_cat, r20_cat, cost_cat = [],[],[]
for cat in range(num_of_quantiles):
cds_cai_category = cds_cai_dat[category==cat]
protein_length_distro = cds_cai_category['protein'].str.len()
# average protein length per quantile as a stability measure ...
average_length = protein_length_distro.mean()
# total proteins length in quantile for AA freqs calculations ...
total_length = protein_length_distro.sum()
IVYWREL = sum(cds_cai_category['protein'].str.count(aa).sum() for aa in list('IVYWREL'))
# IVYWREL = cds_cai_category['protein'].str.count('|'.join("IVYWREL")).sum() # tiny bit slower ...
f_IVYWREL = float(IVYWREL)/float(total_length)
# 20-vector for of amino acid composition ...
aa_freq_20 = np.true_divide([cds_cai_category['protein'].str.count(aa).sum() for aa in aacids],float(total_length))
# slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)
_1,_2,R20,_4,_5 = stats.linregress(aa_freq_20, R20_vec_compare)
# Akashi ...
cost = np.dot(aa_freq_20,vec_cost)
# storing info ...
fivywrel_cat.append(f_IVYWREL)
r20_cat.append(R20)
cost_cat.append(cost)
#returning ...
return (fivywrel_cat,r2
```
<Overlap Ratio: 0.989041095890411>

---

--- 123 --
Question ID: db1870fa35799b9026517c24a66b55fd6be52186_4
Original Code:
```
def test_test_simple_passed(runner):
    with mock.patch('easyci.commands.test.load_user_config') as mocked:
        mocked.return_value = {
            'tests': ['true', 'true'],
            'history_limit': 1,
            'collect_results': [],
        }
        result = runner.invoke(cli, ['test'])
    assert result.exit_code == exit_codes.SUCCESS
    assert 'Passed' in result.output
    assert 'Failed' not in result.output
```


Overlapping Code:
```
er):
with mock.patch('easyci.commands.test.load_user_config') as mocked:
mocked.return_value = {
'tests': ['true', 'true'],
'history_limit': 1,
'collect_results': [],
}
result = runner.invoke(cli, ['test'])
assert result.exit_code == exit_codes.SUCCESS
assert 'Passed' in result.output
assert 'Failed' not in res
```
<Overlap Ratio: 0.8813559322033898>

---

--- 124 --
Question ID: 19ce5ff6fe21bd6c01fbb0e5b1a0d665ab576091_3
Original Code:
```
def mean_similarity(sent1, sent2):
    sent1 = sent1.strip().split(" ")
    sent2 = sent2.strip().split(" ")

    hypothesis_dict = {}
    sent22 = [word2.lower() for word2 in sent2 if word2.lower() in model.vocab]
    sent11 = [word1.lower() for word1 in sent1 if word1.lower() in model.vocab]

    for word2 in sent22:
        sim = 0
        for word1 in sent11:
            currsim = model.similarity(word2, word1)
            if currsim > sim:
                sim = currsim
                hypothesis_dict[word2] = (word1, currsim)

    sum = 0
    for k, (v1, v2) in hypothesis_dict.items():
        sum += v2
    if len(hypothesis_dict.items()) > 0:
        return sum/len(hypothesis_dict.items()) # normalize sum
    else:
        return 0
```


Overlapping Code:
```
ty(sent1, sent2):
sent1 = sent1.strip().split(" ")
sent2 = sent2.strip().split(" ")
hypothesis_dict = {}
sent22 = [word2.lower() for word2 in sent2 if word2.lower() in model.vocab]
sent11 = [word1.lower() for word1 in sent1 if word1.lower() in model.vocab]
for word2 in sent22:
sim = 0
for word1 in sent11:
currsim = model.similarity(word2, word1)
if currsim > sim:
sim = currsim
hypothesis_dict[word2] = (word1, currsim)
sum = 0
for k, (v1, v2) in hypothesis_dict.items():
sum += v2
if len(hypothesis_dict.items()) > 0:
return sum/len(hypothesis_dic
```
<Overlap Ratio: 0.9046052631578947>

---

--- 125 --
Question ID: 38692937cb4cdc55ef409bcac4ef0cf5e6ae0d61_2
Original Code:
```
def test_terasort():

    dataset = [gen_fragment() for _ in range(10)]
    dds = DDS().load(dataset, -1).sort_by_key().collect()
    prev = 0

    for i, k in dds:
        assert i > prev
        prev = i
```


Overlapping Code:
```
() for _ in range(10)]
dds = DDS().load(dataset, -1).sort_by_key().collect()
prev = 0
for i, k in dd
```
<Overlap Ratio: 0.5847953216374269>

---

--- 126 --
Question ID: f6152f39e24bb9dd54ca82ec028f1d08a4de483f_13
Original Code:
```
def get_config_drive_configuration(session, vdiuuid):
    log.info("get_config_drive_configuration from vdi %s" % (vdiuuid))
    tempdir = None
    umountrequired = False
    filename = api_helper.export_disk(session, vdiuuid)
    try:
        tempdir = tempfile.mkdtemp()
        cmd = ['mount', '-o', 'loop', '-t', 'iso9660', filename, tempdir]
        util.runlocal(cmd)
        umountrequired = True
        userdatapath_template = os.path.join(
            tempdir, 'openstack', 'latest', 'user_data.template')
        content = util.read_file(userdatapath_template)
    finally:
        os.remove(filename)
        if umountrequired:
            cmd = ['umount', tempdir]
            util.runlocal(cmd)
        if tempdir:
            os.rmdir(tempdir)
    return content
```


Overlapping Code:
```
id):
log.info("get_config_drive_configuration from vdi %s" % (vdiuuid))
tempdir = None
umountrequired = False
filename = api_helper.export_disk(session, vdiuuid)
try:
tempdir = tempfile.mkdtemp()
cmd = ['mount', '-o', 'loop', '-t', 'iso9660', filename, tempdir]
util.runlocal(cmd)
umountrequired = True
userdatapath_template = os.path.join(
tempdir, 'openstack', 'latest', 'user_data.template')
content = util.read_file(userdatapath_template)
finally:
os.remove(filename)
if umountrequired:
cmd = ['umount', tempdir]
util.runlocal(cmd)
if tempdir:
os
```
<Overlap Ratio: 0.8744038155802861>

---

--- 127 --
Question ID: 8689bbb1e745aba7506d2f433d9b6475e3278f84_1
Original Code:
```
def _make_query_response(
        entity_pbs, cursor_as_bytes, more_results_enum, skipped_results):
    from google.cloud.datastore_v1.proto import datastore_pb2
    from google.cloud.datastore_v1.proto import query_pb2

    return datastore_pb2.RunQueryResponse(
        batch=query_pb2.QueryResultBatch(
            skipped_results=skipped_results,
            end_cursor=cursor_as_bytes,
            more_results=more_results_enum,
            entity_results=[
                query_pb2.EntityResult(entity=entity)
                for entity in entity_pbs
            ],
        ),
    )
```


Overlapping Code:
```
ake_query_response(
entity_pbs, cursor_as_bytes, more_results_enum, skipped_results):
from google.cloud.datastore_v1.proto import datastore_pb2
from google.cloud.datastore_v1.proto import query_pb2
return datastore_pb2.RunQueryResponse(
batch=query_pb2.QueryResultBatch(
skipped_results=skipped_results,
end_cursor=cursor_as_bytes,
more_results=more_results_enum,
entity_results=[
query_pb2.EntityResult(entity=entity)
for entity in 
```
<Overlap Ratio: 0.9474835886214442>

---

--- 128 --
Question ID: 9cf0448ac4d589d7b40f2636a8a339e0094cee15_13
Original Code:
```
def best_bet(team_stat, file_value):

    max_pct = 0
    max_teams = ""

    for mt in team_stat:
        if mt["prob"] > max_pct:
            max_pct = mt["prob"]
            max_teams = mt["teams"]

    print("")
    print("-------------------------------------------------------------------------------------------")
    print("Best Bet: ", max_teams, '{0:.2f}'.format(max_pct * 100) + "% to win")
    print("-------------------------------------------------------------------------------------------")
    print("")

    file_value.write("\r\n")
    file_value.write("-------------------------------------------------------------------------------------------\r\n")
    file_value.write("Best Bet:  " + max_teams + "  " + '{0:.2f}'.format(max_pct * 100) + "% to win" + "\r\n")
    file_value.write("-------------------------------------------------------------------------------------------\r\n")
    file_value.write("\r\n")
```


Overlapping Code:
```
_value):
max_pct = 0
max_teams = ""
for mt in team_stat:
if mt["prob"] > max_pct:
max_pct = mt["prob"]
max_teams = mt["teams"]
print("")
print("-------------------------------------------------------------------------------------------")
print("Best Bet: ", max_teams, '{0:.2f}'.format(max_pct * 100) + "% to win")
print("-------------------------------------------------------------------------------------------")
print("")
file_value.write("\r\n")
file_value.write("-------------------------------------------------------------------------------------------\r\n")
file_value.write("Best Bet: " + max_teams + " " + '{0:.2f}'.format(max_pct * 100) + "% to win" + "\r\n")
file_value.write("-------------------------------------------------------------------------------------------\r\n")
file_value.wr
```
<Overlap Ratio: 0.9535714285714286>

---

--- 129 --
Question ID: 78e91249c82c500bcea7e9536046e7cb366ad21f_21
Original Code:
```
def calculate_body_load (strain, mat_D, g_mat, g_num, a, nn):
    ndim = 3
    nod = 8
    nels = g_mat.shape[0]
    deriv = shape_der_hexahedron(a, a/2)
    B = beemat(deriv)
    body_load = zeros((nn,ndim), float64)
    for iel in range(nels):
        eload = product(a) * dot(transpose(B),
                  dot(mat_D[g_mat[iel]], strain[iel]))
        body_load[g_num[iel,:],:] += eload.reshape((nod,ndim))
    return body_load
```


Overlapping Code:
```
rain, mat_D, g_mat, g_num, a, nn):
ndim = 3
nod = 8
nels = g_mat.shape[0]
deriv = shape_der_hexahedron(a, a/2)
B = beemat(deriv)
body_load = zeros((nn,ndim), float64)
for iel in range(nels):
eload = product(a) * dot(transpose(B),
dot(mat_D[g_mat[iel]], strain[iel]))
body_load[g_num[iel,:],:] += eloa
```
<Overlap Ratio: 0.821917808219178>

---

--- 130 --
Question ID: c1260a861035781f39ed776ff6f4f5ae51270c55_3
Original Code:
```
def _netbsd_balloon_stat(label):
    """Returns the value for the named label, or None if an error occurs."""

    import commands

    xend2netbsd_labels = { 'current'      : 'kern.xen.balloon.current',
                           'target'       : 'kern.xen.balloon.target',
                           'low-balloon'  : None,
                           'high-balloon' : None,
                           'limit'        : None }

    cmdarg = xend2netbsd_labels[label]
    if cmdarg is None:
        return None
    cmd = "/sbin/sysctl " + cmdarg
    sysctloutput = commands.getoutput(cmd)
    (name, value) = sysctloutput.split('=')
    return int(value)
```


Overlapping Code:
```
oon_stat(label):
"""Returns the value for the named label, or None if an error occurs."""
import commands
xend2netbsd_labels = { 'current' : 'kern.xen.balloon.current',
'target' : 'kern.xen.balloon.target',
'low-balloon' : None,
'high-balloon' : None,
'limit' : None }
cmdarg = xend2netbsd_labels[label]
if cmdarg is None:
return None
cmd = "/sbin/sysctl " + cmdarg
sysctloutput = commands.getoutput(cmd)
(name, value) = sysctlout
```
<Overlap Ratio: 0.899581589958159>

---

--- 131 --
Question ID: 8a408f5613a018c669ff52f4bb2e33a522789493_64
Original Code:
```
def makePanel(nper=None):
    with warnings.catch_warnings(record=True):
        warnings.filterwarnings("ignore", "\\nPanel", FutureWarning)
        cols = ['Item' + c for c in string.ascii_uppercase[:K - 1]]
        data = {c: makeTimeDataFrame(nper) for c in cols}
        return Panel.fromDict(data)
```


Overlapping Code:
```
None):
with warnings.catch_warnings(record=True):
warnings.filterwarnings("ignore", "\\nPanel", FutureWarning)
cols = ['Item' + c for c in string.ascii_uppercase[:K - 1]]
data = {c: makeTimeDataFrame(
```
<Overlap Ratio: 0.7490636704119851>

---

--- 132 --
Question ID: f37cafaf66bf50f3beea539655b834171e43f9f3_1
Original Code:
```
def test_insertShiftArray_length():
    """Checks for length aftering inserting value into array"""
    arr = shift_array.insertShiftArray(testArray, 100)
    assert len(arr) == 5
```


Overlapping Code:
```
""Checks for length aftering inserting value into array"""
arr = shift_array.insertShiftArray(testAr
```
<Overlap Ratio: 0.5988023952095808>

---

--- 133 --
Question ID: e4f1f10e63f81cf4c3b16e852831294914278b82_0
Original Code:
```
def pick_dat(cols, initdir='RDAT', title="Select file"):
    """
    Data reader that is called within many other functions.
    :param initdir: This is the directory that the function will open by default to look for the data (.csv or .h5).
    :param title: The message to display at the top of the dialogue box.
    :param cols: Headers to give to the data.
    :return: Pandas DataFrame with headers that contains the selected data.
    """
    root = Tk()
    root.filename = filedialog.askopenfilename(initialdir="C:\\Users\Josh\IdeaProjects\PulsedNMR\{}".format(initdir),
                                               title=title)
    filename_parts = root.filename.split('/')[-1]
    if 'csv' in root.filename:
        data = read_csv(root.filename, names=cols, engine='c')
        return data, filename_parts
    elif 'h5' in root.filename:
        data = read_hdf(root.filename, 'table', names=cols, engine='c')
        return data, filename_parts
    else:
        print('Unexpected file type. Choose either a .csv or .h5 file.')
```


Overlapping Code:
```
itdir='RDAT', title="Select file"):
"""
Data reader that is called within many other functions.
:param initdir: This is the directory that the function will open by default to look for the data (.csv or .h5).
:param title: The message to display at the top of the dialogue box.
:param cols: Headers to give to the data.
:return: Pandas DataFrame with headers that contains the selected data.
"""
root = Tk()
root.filename = filedialog.askopenfilename(initialdir="C:\\Users\Josh\IdeaProjects\PulsedNMR\{}".format(initdir),
title=title)
filename_parts = root.filename.split('/')[-1]
if 'csv' in root.filename:
data = read_csv(root.filename, names=cols, engine='c')
return data, filename_parts
elif 'h5' in root.filename:
data = read_hdf(root.filename, 'table', names=cols, engine='c')
return data, filename_parts
else:
print('Unexpected file type. Choo
```
<Overlap Ratio: 0.9423503325942351>

---

--- 134 --
Question ID: cb740bae988930c3351e3b9a0d512bf202ad6dcc_1
Original Code:
```
def outlier_rejection(X, y):
    model = IsolationForest(max_samples=100,
                            contamination=0.4,
                            random_state=rng)
    model.fit(X)
    y_pred = model.predict(X)
    return X[y_pred == 1], y[y_pred == 1]
```


Overlapping Code:
```
outlier_rejection(X, y):
model = IsolationForest(max_samples=100,
contamination=0.4,
random_state=rng)
model.fit(X)
y_pred = model.predict(X)
return X[y_pred == 1], y
```
<Overlap Ratio: 0.907103825136612>

---

--- 135 --
Question ID: ec87d86573c9d0408b7099b2894f05355039e762_8
Original Code:
```
def MvNormalLogp():
    """Compute the log pdf of a multivariate normal distribution.

    This should be used in MvNormal.logp once Theano#5908 is released.

    Parameters
    ----------
    cov : tt.matrix
        The covariance matrix.
    delta : tt.matrix
        Array of deviations from the mean.
    """
    cov = tt.matrix('cov')
    cov.tag.test_value = floatX(np.eye(3))
    delta = tt.matrix('delta')
    delta.tag.test_value = floatX(np.zeros((2, 3)))

    solve_lower = tt.slinalg.Solve(A_structure='lower_triangular')
    solve_upper = tt.slinalg.Solve(A_structure='upper_triangular')
    cholesky = Cholesky(lower=True, on_error='nan')

    n, k = delta.shape
    n, k = f(n), f(k)
    chol_cov = cholesky(cov)
    diag = tt.nlinalg.diag(chol_cov)
    ok = tt.all(diag > 0)

    chol_cov = tt.switch(ok, chol_cov, tt.fill(chol_cov, 1))
    delta_trans = solve_lower(chol_cov, delta.T).T

    result = n * k * tt.log(f(2) * np.pi)
    result += f(2) * n * tt.sum(tt.log(diag))
    result += (delta_trans ** f(2)).sum()
    result = f(-.5) * result
    logp = tt.switch(ok, result, -np.inf)

    def dlogp(inputs, gradients):
        g_logp, = gradients
        cov, delta = inputs

        g_logp.tag.test_value = floatX(1.)
        n, k = delta.shape

        chol_cov = cholesky(cov)
        diag = tt.nlinalg.diag(chol_cov)
        ok = tt.all(diag > 0)

        chol_cov = tt.switch(ok, chol_cov, tt.fill(chol_cov, 1))
        delta_trans = solve_lower(chol_cov, delta.T).T

        inner = n * tt.eye(k) - tt.dot(delta_trans.T, delta_trans)
        g_cov = solve_upper(chol_cov.T, inner)
        g_cov = solve_upper(chol_cov.T, g_cov.T)

        tau_delta = solve_upper(chol_cov.T, delta_trans.T)
        g_delta = tau_delta.T

        g_cov = tt.switch(ok, g_cov, -np.nan)
        g_delta = tt.switch(ok, g_delta, -np.nan)

        return [-0.5 * g_cov * g_logp, -g_delta * g_logp]

    return theano.OpFromGraph(
        [cov, delta], [logp], grad_overrides=dlogp, inline=True)
```


Overlapping Code:
```
:
"""Compute the log pdf of a multivariate normal distribution.
This should be used in MvNormal.logp once Theano#5908 is released.
Parameters
----------
cov : tt.matrix
The covariance matrix.
delta : tt.matrix
Array of deviations from the mean.
"""
cov = tt.matrix('cov')
cov.tag.test_value = floatX(np.eye(3))
delta = tt.matrix('delta')
delta.tag.test_value = floatX(np.zeros((2, 3)))
solve_lower = tt.slinalg.Solve(A_structure='lower_triangular')
solve_upper = tt.slinalg.Solve(A_structure='upper_triangular')
cholesky = Cholesky(lower=True, on_error='nan')
n, k = delta.shape
n, k = f(n), f(k)
chol_cov = cholesky(cov)
diag = tt.nlinalg.diag(chol_cov)
ok = tt.all(diag > 0)
chol_cov = tt.switch(ok, chol_cov, tt.fill(chol_cov, 1))
delta_trans = solve_lower(chol_cov, delta.T).T
result = n * k * tt.log(f(2) * np.pi)
result += f(2) * n * tt.sum(tt.log(diag))
result += (delta_trans ** f(2)).sum()
result = f(-.5) * result
logp = tt.switch(ok, result, -np.inf)
def dlogp(inputs, gradients):
g_logp, = gradients
cov, delta = inputs
g_logp.tag.test_value = floatX(1.)
n, k = delta.shape
chol_cov = cholesky(cov)
diag = tt.nlinalg.diag(chol_cov)
ok = tt.all(diag > 0)
chol_cov = tt.switch(ok, chol_cov, tt.fill(chol_cov, 1))
delta_trans = solve_lower(chol_cov, delta.T).T
inner = n * tt.eye(k) - tt.dot(delta_trans.T, delta_trans)
g_cov = solve_upper(chol_cov.T, inner)
g_cov = solve_upper(chol_cov.T, g_cov.T)
tau_delta = solve_upper(chol_cov.T, delta_trans.T)
g_delta = tau_delta.T
g_cov = tt.switch(ok, g_cov, -np.nan)
g_delta = tt.switch(ok, g_delta, -np.nan)
return [-0.5 * g_cov * g_logp, -g_delta * g_logp]
return theano.OpFromGraph(
[cov, delta], [logp], grad_overrides=dlogp, inline=True
```
<Overlap Ratio: 0.9889083479276124>

---

--- 136 --
Question ID: 8598044e62a6a62f45c02f4ff506e417d6d1df1c_3
Original Code:
```
def write(base, db_url, output):
    output = Path(output)
    for fixed in fixed_queries(Path(base)):
        fixed.write_to(output)

    for query in generate_queries(db_url):
        query.write_to(output)
```


Overlapping Code:
```
write(base, db_url, output):
output = Path(output)
for fixed in fixed_queries(Path(base)):
fixed.write_to(output)
for query in generate_queries(db_url
```
<Overlap Ratio: 0.8379888268156425>

---

--- 137 --
Question ID: b1cbd1c9e79eba860e76bd0bb1560ecd424ba8d7_0
Original Code:
```
def create_fake_random_string(length: int) -> str:
    assert length > 0

    md5_list = [get_md5(create_guid().encode("utf-8")) for _ in range(math.ceil(length / 30) + 1)]

    return "".join(md5_list)[:length]
```


Overlapping Code:
```
tring(length: int) -> str:
assert length > 0
md5_list = [get_md5(create_guid().encode("utf-8")) for _ in range(math.ceil(length / 30) + 1)]
return "".
```
<Overlap Ratio: 0.7614213197969543>

---

--- 138 --
Question ID: 983d53cab55783ca6f9037de1063a9f3a9151399_44
Original Code:
```
def server_stats_restarts():
    cur.execute("SELECT restarts FROM server_stats;")
    sqlresult = cur.fetchone()
    return str(sqlresult[0])
```


Overlapping Code:
```
def server_stats_restarts():
cur.execute("SELECT restarts FROM server_stats;")
sqlresult = cur.fetchone()
return str(sqlresult[
```
<Overlap Ratio: 0.9769230769230769>

---

--- 139 --
Question ID: 241fee9df6a2648ce6bff61320bbfc470557e17a_7
Original Code:
```
@app.route('/login' , methods=['POST'])
def login():
    username = request.get_json(force=True)['username']
    password = request.get_json(force=True)['password']

    user = next(iter([user for user in users if user.name == username]), None) 

    if user != None and user.password == password:
        print('Logged in user %s' % (user.name))
        login_user(user)
        return 'Success', 200
    else:
       return 'Error: incorrect credentials', 401
```


Overlapping Code:
```
, methods=['POST'])
def login():
username = request.get_json(force=True)['username']
password = request.get_json(force=True)['password']
user = next(iter([user for user in users if user.name == username]), None) 
if user != None and user.password == password:
print('Logged in user %s' % (user.name))
login_user(user)
return 'Success', 200
else:
return 'Error: inco
```
<Overlap Ratio: 0.8946078431372549>

---

--- 140 --
Question ID: 742ad604de0f6aef053e6c6a60279b2f11fb6047_3
Original Code:
```
@baker.command
def show_npz_info(*npz_file):
    import numpy as np

    for fname in npz_file:
        print('filename', fname)
        x, y, qid, docno = core.io.load_npz(fname)
        if docno is not None:
            print('x', x.shape, 'y', y.shape, 'qid', qid.shape, 'docno', docno.shape)
        else:
            print('x', x.shape, 'y', y.shape, 'qid', qid.shape, 'docno', None)

        print('labels:', {int(k): v for k, v in zip(*map(list, np.unique(y, return_counts=True)))})

        unique_qid = np.unique(qid)
        print('qid (unique):', unique_qid.size)
        print(unique_qid)
        print()
```


Overlapping Code:
```
):
import numpy as np
for fname in npz_file:
print('filename', fname)
x, y, qid, docno = core.io.load_npz(fname)
if docno is not None:
print('x', x.shape, 'y', y.shape, 'qid', qid.shape, 'docno', docno.shape)
else:
print('x', x.shape, 'y', y.shape, 'qid', qid.shape, 'docno', None)
print('labels:', {int(k): v for k, v in zip(*map(list, np.unique(y, return_counts=True)))})
unique_qid = np.unique(qid)
print('qid (unique):', unique_qid.size)
print(un
```
<Overlap Ratio: 0.8840864440078585>

---

--- 141 --
Question ID: 491cd31433245be5f70acf3ca25e1b46c94ffcc3_0
Original Code:
```
def make_window(length):
  # Based on https://github.com/WebKit/webkit/blob/89c28d471fae35f1788a0f857067896a10af8974/Source/WebCore/Modules/webaudio/RealtimeAnalyser.cpp
  alpha = 0.16
  a0 = 0.5 * (1.0 - alpha)
  a1 = 0.5
  a2 = 0.5 * alpha
  ts = np.arange(0, length, 1.0).astype(np.float32) / length
  return a0 - a1 * np.cos(2 * np.pi * ts) + a2 * np.cos(4 * np.pi * ts)
```


Overlapping Code:
```
ps://github.com/WebKit/webkit/blob/89c28d471fae35f1788a0f857067896a10af8974/Source/WebCore/Modules/webaudio/RealtimeAnalyser.cpp
alpha = 0.16
a0 = 0.5 * (1.0 - alpha)
a1 = 0.5
a2 = 0.5 * alpha
ts = np.arange(0, length, 1.0).astype(np.float32) / length
return a0 - a1 * np.cos(2 * np.pi * ts) + a2 * np.cos(4 *
```
<Overlap Ratio: 0.8583333333333333>

---

--- 142 --
Question ID: e25842941d48d41714f3658be3a09747ddafaa6a_2
Original Code:
```
def parse_setting_args():
    ''' 解析传入到 POST 的 body 参数'''
    parser = reqparse.RequestParser()
    parser.add_argument('name', type=str, required=True, location='json')
    parser.add_argument('value', default='', location='json')
    args = parser.parse_args()
    return args
```


Overlapping Code:
```
 POST 的 body 参数'''
parser = reqparse.RequestParser()
parser.add_argument('name', type=str, required=True, location='json')
parser.add_argument('value', default='', location='json')
args = parser.parse
```
<Overlap Ratio: 0.7874015748031497>

---

--- 143 --
Question ID: fa77dd08a8bc2cf62a61f8d1b262aa436172e746_11
Original Code:
```
def get_cell_ngrams(
    mention: Union[Candidate, Mention, TemporarySpanMention],
    attrib: str = "words",
    n_min: int = 1,
    n_max: int = 1,
    lower: bool = True,
) -> Iterator[str]:
    """Get the ngrams that are in the Cell of the given mention, not including itself.

    Note that if a candidate is passed in, all of its Mentions will be searched.

    :param mention: The Mention whose Cell is being searched
    :param attrib: The token attribute type (e.g. words, lemmas, poses)
    :param n_min: The minimum n of the ngrams that should be returned
    :param n_max: The maximum n of the ngrams that should be returned
    :param lower: If True, all ngrams will be returned in lower case
    :rtype: a *generator* of ngrams
    """
    spans = _to_spans(mention)
    for span in spans:
        for ngram in get_sentence_ngrams(
            span, attrib=attrib, n_min=n_min, n_max=n_max, lower=lower
        ):
            yield ngram
        if span.sentence.is_tabular():
            for ngram in chain.from_iterable(
                [
                    tokens_to_ngrams(
                        getattr(sentence, attrib), n_min=n_min, n_max=n_max, lower=lower
                    )
                    for sentence in _get_table_cells(span.sentence.table)[
                        span.sentence.cell
                    ]
                    if sentence != span.sentence
                ]
            ):
                yield ngram
```


Overlapping Code:
```
grams(
mention: Union[Candidate, Mention, TemporarySpanMention],
attrib: str = "words",
n_min: int = 1,
n_max: int = 1,
lower: bool = True,
) -> Iterator[str]:
"""Get the ngrams that are in the Cell of the given mention, not including itself.
Note that if a candidate is passed in, all of its Mentions will be searched.
:param mention: The Mention whose Cell is being searched
:param attrib: The token attribute type (e.g. words, lemmas, poses)
:param n_min: The minimum n of the ngrams that should be returned
:param n_max: The maximum n of the ngrams that should be returned
:param lower: If True, all ngrams will be returned in lower case
:rtype: a *generator* of ngrams
"""
spans = _to_spans(mention)
for span in spans:
for ngram in get_sentence_ngrams(
span, attrib=attrib, n_min=n_min, n_max=n_max, lower=lower
):
yield ngram
if span.sentence.is_tabular():
for ngram in chain.from_iterable(
[
tokens_to_ngrams(
getattr(sentence, attrib), n_min=n_min, n_max=n_max, lower=lower
)
for sentence in _get_table_cells(span.sentence.table)[
span.sentence.cell
]
if sentence != span.sentence
]
):
yield ngra
```
<Overlap Ratio: 0.9865951742627346>

---

--- 144 --
Question ID: 8282b7c9525f4039a97c0b515ce586b7a0996f57_0
Original Code:
```
def world_configuration(world_width, world_height):
    world = VisualWorld(width=world_width, height=world_height)
    world.set_engine(Engine(world))  # TODO: Smelly design

    lines = [
        Line(start=(0, 0.2), end=(world_width, 0.2)),
        Line(start=(0, world_height / 2), end=(world_width, world_height / 2), discontinuous=True, color='y'),
        Line(start=(0, world_height - 0.2), end=(world_width, world_height - 0.2))
    ]
    lines_visuals = [
        LinePyplot(line=lines[0], width=LANE_WIDTH),
        # LinePyplot(line=lines[1], width=LANE_WIDTH),
        LinePyplot(line=lines[2], width=LANE_WIDTH),
    ]

    lanes = [
        Lane(lines[0], lines[1], direction=LaneDirection.START_TO_END),
        Lane(lines[1], lines[2], direction=LaneDirection.END_TO_START)
    ]

    signs = [
        SenseFloorSign(lanes[0]),
        SenseFloorSign(lanes[1])
    ]
    signs_visuals = [
        DirectionSignPyplot(floor_sign=signs[0], scale=ARROWS_SCALE),
        DirectionSignPyplot(floor_sign=signs[1], scale=ARROWS_SCALE),
    ]

    world.semantics.extend(lines)
    world.visuals.extend(lines_visuals)

    world.semantics.extend(lanes)

    world.semantics.extend(signs)
    world.visuals.extend(signs_visuals)

    return world, lanes
```


Overlapping Code:
```
_width, world_height):
world = VisualWorld(width=world_width, height=world_height)
world.set_engine(Engine(world)) # TODO: Smelly design
lines = [
Line(start=(0, 0.2), end=(world_width, 0.2)),
Line(start=(0, world_height / 2), end=(world_width, world_height / 2), discontinuous=True, color='y'),
Line(start=(0, world_height - 0.2), end=(world_width, world_height - 0.2))
]
lines_visuals = [
LinePyplot(line=lines[0], width=LANE_WIDTH),
# LinePyplot(line=lines[1], width=LANE_WIDTH),
LinePyplot(line=lines[2], width=LANE_WIDTH),
]
lanes = [
Lane(lines[0], lines[1], direction=LaneDirection.START_TO_END),
Lane(lines[1], lines[2], direction=LaneDirection.END_TO_START)
]
signs = [
SenseFloorSign(lanes[0]),
SenseFloorSign(lanes[1])
]
signs_visuals = [
DirectionSignPyplot(floor_sign=signs[0], scale=ARROWS_SCALE),
DirectionSignPyplot(floor_sign=signs[1], scale=ARROWS_SCALE),
]
world.semantics.extend(lines)
world.visuals.extend(lines_visuals)
world.semantics.extend(lanes)
world.semantics.extend(signs)
world.visuals.extend(signs_visuals)
return world
```
<Overlap Ratio: 0.9668508287292817>

---

--- 145 --
Question ID: a81c57f6681f6f3b6919557e9362fc190809d5a0_0
Original Code:
```
def process_rows(db_url, sql, uuid_dict):
    connection = make_db_connection(db_url)
    try:
        cursor = connection.cursor()
        cursor.execute(sql)
        with tqdm(desc=sql) as pbar:
            row = cursor.fetchone()
            pbar.update()
            while row:
                (key, uuid, size) = row
                uuid_dict[uuid] = (key, size)
                row = cursor.fetchone()
                pbar.update()
    finally:
        connection.close()
```


Overlapping Code:
```
:
connection = make_db_connection(db_url)
try:
cursor = connection.cursor()
cursor.execute(sql)
with tqdm(desc=sql) as pbar:
row = cursor.fetchone()
pbar.update()
while row:
(key, uuid, size) = row
uuid_dict[uuid] = (key, size)
row = cursor.fetchone(
```
<Overlap Ratio: 0.7507507507507507>

---

--- 146 --
Question ID: 9960509163541c33ee25ff4bb44842a269538709_1
Original Code:
```
def _host_make_bigfile(self: Host, path: str, mount_point: str) -> None:
    output = self.check_output('df --output=size,used %s | tail -n 1' % mount_point)
    # Sizes in kiB
    size = int(output.split()[0])
    used = int(output.split()[1])
    # Want to get it up to 92% full
    needed = int(0.92 * size) - used
    self.check_output('dd if=/dev/zero of=%s bs=1M count=%d' % (path, int(needed / 1024)))
```


Overlapping Code:
```
ount_point: str) -> None:
output = self.check_output('df --output=size,used %s | tail -n 1' % mount_point)
# Sizes in kiB
size = int(output.split()[0])
used = int(output.split()[1])
# Want to get it up to 92% full
needed = int(0.92 * size) - used
self.check_output('dd if=/dev/zero of=%s bs=1M count=
```
<Overlap Ratio: 0.7894736842105263>

---

--- 147 --
Question ID: 466a8269775df60cf80920230c95c8e3a32ee9a9_2
Original Code:
```
@server.register_function()
async def testcorogen(a, b):
    for i in range(10):
        await asyncio.sleep(0.1)
        yield i + a + b
```


Overlapping Code:
```
server.register_function()
async def testcorogen(a, b):
for i in range(10):
await asyncio.sleep(0.1)
yield i + 
```
<Overlap Ratio: 0.9487179487179487>

---

--- 148 --
Question ID: f6d281e3a449003cb559ce98389d32a9d539c8da_2
Original Code:
```
def truncate_string_right(s, N, suff=' [..]'):
    if len(s) > N:
        s = s[:N-len(suff)] + suff
    return s
```


Overlapping Code:
```
:
if len(s) > N:
s = s[:N-len(suff)] + suff
return
```
<Overlap Ratio: 0.5154639175257731>

---

--- 149 --
Question ID: 02dc3296d27288660daaaaf7bc5adc5c4fce8b50_0
Original Code:
```
def py2_encode(s, encoding='utf-8'):
   """
   Encode Python 2 ``unicode`` to ``str``

   In Python 3 the string is not changed.   
   """
   if PY2 and isinstance(s, unicode):
       s = s.encode(encoding)
   return s
```


Overlapping Code:
```
ncode(s, encoding='utf-8'):
"""
Encode Python 2 ``unicode`` to ``str``
In Python 3 the string is not changed. 
"""
if PY2 and isinstance(s, unicode):
s = s.encode(encoding)
re
```
<Overlap Ratio: 0.9210526315789473>

---

--- 150 --
Question ID: c478fd461ccb3296545e71b836f66e0cd6f99257_8
Original Code:
```
def _find_type_from_comment_hint(context, node, varlist, name):
    index = None
    if varlist.type in ("testlist_star_expr", "exprlist"):
        # something like "a, b = 1, 2"
        index = 0
        for child in varlist.children:
            if child == name:
                break
            if child.type == "operator":
                continue
            index += 1
        else:
            return []

    comment = node.get_following_comment_same_line()
    if comment is None:
        return []
    match = re.match(r"^#\s*type:\s*([^#]*)", comment)
    if not match:
        return []
    annotation = tree.String(
        repr(str(match.group(1).strip())),
        node.start_pos)
    annotation.parent = node.parent
    return _evaluate_for_annotation(context, annotation, index)
```


Overlapping Code:
```
ind_type_from_comment_hint(context, node, varlist, name):
index = None
if varlist.type in ("testlist_star_expr", "exprlist"):
# something like "a, b = 1, 2"
index = 0
for child in varlist.children:
if child == name:
break
if child.type == "operator":
continue
index += 1
else:
return []
comment = node.get_following_comment_same_line()
if comment is None:
return []
match = re.match(r"^#\s*type:\s*([^#]*)", comment)
if not match:
return []
annotation = tree.String(
repr(str(match.group(1).strip())),
node.start_pos)
annotation.parent = node.parent
return _evaluate_for_annotation(con
```
<Overlap Ratio: 0.9512195121951219>

---

--- 151 --
Question ID: e587239959d45e22a6d7ce4487f4fb1c425fc866_0
Original Code:
```
def bq_to_gcs(table, blob):  # type: (bigquery.TableReference, storage.Blob) -> None
    bq = bigquery.Client()
    extract_job = bq.extract_table(table, gcs_path(blob))
    extract_job.result()
```


Overlapping Code:
```
lob): # type: (bigquery.TableReference, storage.Blob) -> None
bq = bigquery.Client()
extract_job = bq.extract_table(table, gcs_path(blob))
extract_job
```
<Overlap Ratio: 0.8287292817679558>

---

--- 152 --
Question ID: a9651422a5c14480fc7b5698510f7b7b9bd1137c_1
Original Code:
```
def form_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description='Ingest jsonl data into an Elasticsearch instance.')

    parser.add_argument("-e","--host",help="ip address of Elasticsearch host. Defaults to localhost:9200",default=None)
    parser.add_argument("-a","--aws",help="Using Amazon Web Services: requires boto3",action="store_true")
    parser.add_argument("-r","--aws_region",help="AWS region of Elasticsearch instance",default="us-east-2")
    parser.add_argument("index",help="Elasticsearch index to be used.")
    return parser
```


Overlapping Code:
```
rm_parser() -> argparse.ArgumentParser:
parser = argparse.ArgumentParser(description='Ingest jsonl data into an Elasticsearch instance.')
parser.add_argument("-e","--host",help="ip address of Elasticsearch host. Defaults to localhost:9200",default=None)
parser.add_argument("-a","--aws",help="Using Amazon Web Services: requires boto3",action="store_true")
parser.add_argument("-r","--aws_region",help="AWS region of Elasticsearch instance",default="us-east-2")
parser.add_argument("index",help="Elasticsearch index to be used.")
return
```
<Overlap Ratio: 0.97632058287796>

---

--- 153 --
Question ID: a1dbe188d4233759a02c189d1a6e59e0d05a4336_3
Original Code:
```
@magicWord(category=CATEGORY_ADMINISTRATOR, types=[str, str, int])
def accessLevel(accessLevel, storage='PERSISTENT', showGM=1):
    """
    Modify the target's access level.
    """
    accessName2Id = {
        'user': CATEGORY_USER.defaultAccess,
        'u': CATEGORY_USER.defaultAccess,
        'communitymanager': CATEGORY_COMMUNITY_MANAGER.defaultAccess,
        'community': CATEGORY_COMMUNITY_MANAGER.defaultAccess,
        'c': CATEGORY_COMMUNITY_MANAGER.defaultAccess,
        'moderator': CATEGORY_MODERATOR.defaultAccess,
        'mod': CATEGORY_MODERATOR.defaultAccess,
        'm': CATEGORY_MODERATOR.defaultAccess,
        'creative': CATEGORY_CREATIVE.defaultAccess,
        'creativity': CATEGORY_CREATIVE.defaultAccess,
        'c': CATEGORY_CREATIVE.defaultAccess,
        'programmer': CATEGORY_PROGRAMMER.defaultAccess,
        'coder': CATEGORY_PROGRAMMER.defaultAccess,
        'p': CATEGORY_PROGRAMMER.defaultAccess,
        'administrator': CATEGORY_ADMINISTRATOR.defaultAccess,
        'admin': CATEGORY_ADMINISTRATOR.defaultAccess,
        'a': CATEGORY_ADMINISTRATOR.defaultAccess,
        'systemadministrator': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess,
        'systemadmin': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess,
        'sysadministrator': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess,
        'sysadmin': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess,
        'system': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess,
        'sys': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess,
        's': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess
    }
    try:
        accessLevel = int(accessLevel)
    except:
        if accessLevel not in accessName2Id:
            return 'Invalid access level!'
        accessLevel = accessName2Id[accessLevel]
    if accessLevel not in accessName2Id.values():
        return 'Invalid access level!'
    target = spellbook.getTarget()
    invoker = spellbook.getInvoker()
    if invoker == target:
        return "You can't set your own access level!"
    if not accessLevel < invoker.getAdminAccess():
        return "The target's access level must be lower than yours!"
    if target.getAdminAccess() == accessLevel:
        return "%s's access level is already %d!" % (target.getName(), accessLevel)
    target.b_setAdminAccess(accessLevel)
    if showGM:
        target.b_setGM(accessLevel)
    temporary = storage.upper() in ('SESSION', 'TEMP', 'TEMPORARY')
    if not temporary:
        target.air.dbInterface.updateObject(
            target.air.dbId,
            target.getDISLid(),
            target.air.dclassesByName['AccountAI'],
            {'ADMIN_ACCESS': accessLevel})
    if not temporary:
        target.d_setSystemMessage(0, '%s set your access level to %d!' % (invoker.getName(), accessLevel))
        return "%s's access level has been set to %d." % (target.getName(), accessLevel)
    else:
        target.d_setSystemMessage(0, '%s set your access level to %d temporarily!' % (invoker.getName(), accessLevel))
        return "%s's access level has been set to %d temporarily." % (target.getName(), accessLevel)
```


Overlapping Code:
```
=[str, str, int])
def accessLevel(accessLevel, storage='PERSISTENT', showGM=1):
"""
Modify the target's access level.
"""
accessName2Id = {
'user': CATEGORY_USER.defaultAccess,
'u': CATEGORY_USER.defaultAccess,
'communitymanager': CATEGORY_COMMUNITY_MANAGER.defaultAccess,
'community': CATEGORY_COMMUNITY_MANAGER.defaultAccess,
'c': CATEGORY_COMMUNITY_MANAGER.defaultAccess,
'moderator': CATEGORY_MODERATOR.defaultAccess,
'mod': CATEGORY_MODERATOR.defaultAccess,
'm': CATEGORY_MODERATOR.defaultAccess,
'creative': CATEGORY_CREATIVE.defaultAccess,
'creativity': CATEGORY_CREATIVE.defaultAccess,
'c': CATEGORY_CREATIVE.defaultAccess,
'programmer': CATEGORY_PROGRAMMER.defaultAccess,
'coder': CATEGORY_PROGRAMMER.defaultAccess,
'p': CATEGORY_PROGRAMMER.defaultAccess,
'administrator': CATEGORY_ADMINISTRATOR.defaultAccess,
'admin': CATEGORY_ADMINISTRATOR.defaultAccess,
'a': CATEGORY_ADMINISTRATOR.defaultAccess,
'systemadministrator': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess,
'systemadmin': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess,
'sysadministrator': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess,
'sysadmin': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess,
'system': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess,
'sys': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess,
's': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess
}
try:
accessLevel = int(accessLevel)
except:
if accessLevel not in accessName2Id:
return 'Invalid access level!'
accessLevel = accessName2Id[accessLevel]
if accessLevel not in accessName2Id.values():
return 'Invalid access level!'
target = spellbook.getTarget()
invoker = spellbook.getInvoker()
if invoker == target:
return "You can't set your own access level!"
if not accessLevel < invoker.getAdminAccess():
return "The target's access level must be lower than yours!"
if target.getAdminAccess() == accessLevel:
return "%s's access level is already %d!" % (target.getName(), accessLevel)
target.b_setAdminAccess(accessLevel)
if showGM:
target.b_setGM(accessLevel)
temporary = storage.upper() in ('SESSION', 'TEMP', 'TEMPORARY')
if not temporary:
target.air.dbInterface.updateObject
```
<Overlap Ratio: 0.9767441860465116>

---

--- 154 --
Question ID: aa6c4544883b12bb9db3b8af141a9ca74517d178_1
Original Code:
```
def test_create_project_without_gitlab_ci(tmpfolder):
    # Given options without the GitLab extension,
    opts = dict(project_path="proj")

    # when the project is created,
    create_project(opts)

    # then GitLab files should not exist
    assert not path_exists("proj/.gitlab-ci.yml")
```


Overlapping Code:
```
create_project_without_gitlab_ci(tmpfolder):
# Given options without the GitLab extension,
opts = dict(project_path="proj")
# when the project is created,
create_project(opts)
# then GitLab files should not exist
assert not path_exists("proj/.gitlab-
```
<Overlap Ratio: 0.9363295880149812>

---

--- 155 --
Question ID: f4d668ab8a23815224a9c6ddab557d9c4726aed8_7
Original Code:
```
def verify_submodule_branch_structure(repo, branch_name, fetch=True,
                                      remote='origin'):
    """
    Throws an exception unless the commit at the tip of branch_name
    in the supermodule points to the tip of branch_name in each of
    the submodules
    """
    remote_branch = '/'.join([remote, branch_name])

    repo.git.reset('--hard', 'HEAD')
    repo.git.checkout('-f', branch_name)
    repo.git.reset('--hard', remote_branch)
    if fetch:
        repo.git.submodule('update', '--init')
        repo.git.submodule('foreach', 'git fetch')
    else:
        repo.git.submodule('update', '--init', '--no-fetch')
    try:
        repo.git.submodule('foreach', "git diff --quiet %s" % remote_branch)
    except GitCommandError:
        raise InvalidSubmoduleBranch(branch_name)
```


Overlapping Code:
```
erify_submodule_branch_structure(repo, branch_name, fetch=True,
remote='origin'):
"""
Throws an exception unless the commit at the tip of branch_name
in the supermodule points to the tip of branch_name in each of
the submodules
"""
remote_branch = '/'.join([remote, branch_name])
repo.git.reset('--hard', 'HEAD')
repo.git.checkout('-f', branch_name)
repo.git.reset('--hard', remote_branch)
if fetch:
repo.git.submodule('update', '--init')
repo.git.submodule('foreach', 'git fetch')
else:
repo.git.submodule('update', '--init', '--no-fetch')
try:
repo.git.submodule('foreach', "git diff --quiet %s" % remote_branch)
except GitCommandError:
raise Inval
```
<Overlap Ratio: 0.948905109489051>

---

--- 156 --
Question ID: fe9c8b90029c8526e886a9efc289c0719645fbfe_0
Original Code:
```
def test_pattern_match_none():
    data = pd.Series(["foo", "bar"])
    values = ["baz"]

    obs = utils.pattern_match(data, values)
    assert (obs == [False, False]).all()
```


Overlapping Code:
```
["foo", "bar"])
values = ["baz"]
obs = utils.pattern_match(data, values)
assert (obs == [False, Fals
```
<Overlap Ratio: 0.6369426751592356>

---

--- 157 --
Question ID: 18a9c07a4f52c6aca1030058e12b8543cff475cc_2
Original Code:
```
@task
@suggest_localhost
def powerline_shell():
    '''Install or update and set up powerline-shell prompt.

    powerline-shell (https://github.com/b-ryan/powerline-shell) is a beautiful
    and useful prompt for your shell.

    More infos:
     * https://github.com/b-ryan/powerline-shell
     * https://askubuntu.com/questions/283908/how-can-i-install-and-use-powerline-plugin

    Touched files, dirs, and installed packages:

        ~/.config/powerline-shell/config.json
        pip install powerline-shell
    '''
    assert env.host == 'localhost', 'This task cannot run on a remote host'
    setup_fonts_for_powerline_shell()
    install_pip_package()
    install_config()
    install_bash_enabler()
```


Overlapping Code:
```
 powerline_shell():
'''Install or update and set up powerline-shell prompt.
powerline-shell (https://github.com/b-ryan/powerline-shell) is a beautiful
and useful prompt for your shell.
More infos:
* https://github.com/b-ryan/powerline-shell
* https://askubuntu.com/questions/283908/how-can-i-install-and-use-powerline-plugin
Touched files, dirs, and installed packages:
~/.config/powerline-shell/config.json
pip install powerline-shell
'''
assert env.host == 'localhost', 'This task cannot run on a remote host'
setup_fonts_for_powerline_shell()
install_pip_package()
install_config()
install_bash_en
```
<Overlap Ratio: 0.9448818897637795>

---

--- 158 --
Question ID: 2efc0051df1c6a001fe11757a856aeeebbb1e79c_2
Original Code:
```
@app.route("/set-ip/<string:ip>",methods=['GET'])
def set_ip(ip):
    global server_list
    server_list = ['http://' + ip + ':6001/',
               'http://' + ip + ':6002/',
               'http://' + ip + ':6003/',
               'http://' + ip + ':6004/',]
    return '', 200
```


Overlapping Code:
```
te("/set-ip/<string:ip>",methods=['GET'])
def set_ip(ip):
global server_list
server_list = ['http://' + ip + ':6001/',
'http://' + ip + ':6002/',
'http://' + ip + ':6003/',
'http://' + ip + ':6004/',]
```
<Overlap Ratio: 0.8968609865470852>

---

--- 159 --
Question ID: f9fb953da7000c2d128f3ddaf6797febacc8609b_0
Original Code:
```
def get_log_volume_map(root_log_dir, dockerrun_dict):
    """
    Return host log path to container log path mapping if Logging is provided
    in the dockerrun, and otherwise return empty dict.
    :param root_log_dir: str: the root local logs directory
    :param dockerrun_dict: dict: Dockerrun.aws.json as dict
    :return: dict
    """

    if not dockerrun_dict:
        return {}
    host_log = get_host_log_path(root_log_dir)
    container_log = dockerrun.get_logdir(dockerrun_dict)
    return {host_log: container_log} if container_log else {}
```


Overlapping Code:
```
lume_map(root_log_dir, dockerrun_dict):
"""
Return host log path to container log path mapping if Logging is provided
in the dockerrun, and otherwise return empty dict.
:param root_log_dir: str: the root local logs directory
:param dockerrun_dict: dict: Dockerrun.aws.json as dict
:return: dict
"""
if not dockerrun_dict:
return {}
host_log = get_host_log_path(root_log_dir)
container_log = dockerrun.get_logdir(dockerrun_dict)
return {host_log: container_log} if c
```
<Overlap Ratio: 0.9318637274549099>

---

--- 160 --
Question ID: b729daa5f12ea230cfe0dff6099efd889b2bedff_3
Original Code:
```
def analyze_variational_sampling(autoencoder: vae.VariationalAutoEncoder, shape: [int], low: float, high: float, savedir: str, ndims: int, frequencies: [float], times: [float]) -> None:
    """
    If a Variational AE, this samples from latent space and plots a swathe of spectrograms.
    """
    if ndims < 3:
        testvae._plot_samples_from_latent_space(autoencoder, shape, savedir, frequencies, times, ndims)
        testvae._plot_topographic_swathe(autoencoder, shape, low, high, savedir, frequencies, times, ndims)
```


Overlapping Code:
```
e.VariationalAutoEncoder, shape: [int], low: float, high: float, savedir: str, ndims: int, frequencies: [float], times: [float]) -> None:
"""
If a Variational AE, this samples from latent space and plots a swathe of spectrograms.
"""
if ndims < 3:
testvae._plot_samples_from_latent_space(autoencoder, shape, savedir, frequencies, times, ndims)
testvae._plot_topographic_swathe(autoencoder, shape, low, high, save
```
<Overlap Ratio: 0.8391038696537678>

---

--- 161 --
Question ID: 695ce0583333dbe567a3599e2a959f8a1ebf3dd9_0
Original Code:
```
def a_pool(layer_input, input_shp, poolsize, stride=(1, 1), padding=(0, 0),
           mode="max"):
    """Returns estimated activation of pool layer.

    :param Numlike layer_input: Numlike input in input_shp format
    :param tuple of 3 integers input_shp: input shape in format (n_channels,
                                          height, width)
    :param pair of integers poolsize: pool size in format (height, width)
    :param pair of integers stride: stride of max pool
    :param pair of integers padding: padding of pool, non-trivial padding is
                                     not allowed for 'max" mode
    :param mode: specifies whether it is max pool or average pool
    :type mode: 'max' or 'avg'
    :rtype: Numlike
    """
    assert_numlike(layer_input)
    if mode not in ["max", "avg"]:
        raise ValueError("pool mode should be 'max' or 'avg'")
    is_max = mode == "max"
    # n_in, h, w - number of input channels, image height, image width
    n_in, h, w = input_shp
    n_out = n_in

    # padding
    pad_h, pad_w = padding
    if padding != (0, 0):
        layer_input = layer_input.reshape_for_padding((1, n_in, h, w), padding)
        h += 2 * pad_h
        w += 2 * pad_w
    else:
        layer_input = layer_input.reshape((1, n_in, h, w))

    # fh, fw - pool height, pool width
    fh, fw = poolsize
    stride_h, stride_w = stride
    output_h = (h - fh) / stride_h + 1
    output_w = (w - fw) / stride_w + 1
    output_shp = (n_out, output_h, output_w)
    result = layer_input.from_shape(output_shp, neutral=True)
    for at_h in xrange(0, h - fh + 1, stride_h):
        # at_out_h - height of output corresponding to pool at position at_h
        at_out_h = at_h / stride_h
        for at_w in xrange(0, w - fw + 1, stride_w):
            # at_out_w - height of output corresponding to pool at
            # position at_w
            at_out_w = at_w / stride_w
            input_slice = layer_input[:, :, at_h:(at_h + fh), at_w:(at_w + fw)]
            if is_max:
                pool_res = input_slice.amax(axis=(0, 2, 3), keepdims=False)
            else:
                pool_res = input_slice.sum(axis=(0, 2, 3), keepdims=False) \
                    / float(fh * fw)
            result[:, at_out_h, at_out_w] = pool_res
    return result
```


Overlapping Code:
```
layer_input, input_shp, poolsize, stride=(1, 1), padding=(0, 0),
mode="max"):
"""Returns estimated activation of pool layer.
:param Numlike layer_input: Numlike input in input_shp format
:param tuple of 3 integers input_shp: input shape in format (n_channels,
height, width)
:param pair of integers poolsize: pool size in format (height, width)
:param pair of integers stride: stride of max pool
:param pair of integers padding: padding of pool, non-trivial padding is
not allowed for 'max" mode
:param mode: specifies whether it is max pool or average pool
:type mode: 'max' or 'avg'
:rtype: Numlike
"""
assert_numlike(layer_input)
if mode not in ["max", "avg"]:
raise ValueError("pool mode should be 'max' or 'avg'")
is_max = mode == "max"
# n_in, h, w - number of input channels, image height, image width
n_in, h, w = input_shp
n_out = n_in
# padding
pad_h, pad_w = padding
if padding != (0, 0):
layer_input = layer_input.reshape_for_padding((1, n_in, h, w), padding)
h += 2 * pad_h
w += 2 * pad_w
else:
layer_input = layer_input.reshape((1, n_in, h, w))
# fh, fw - pool height, pool width
fh, fw = poolsize
stride_h, stride_w = stride
output_h = (h - fh) / stride_h + 1
output_w = (w - fw) / stride_w + 1
output_shp = (n_out, output_h, output_w)
result = layer_input.from_shape(output_shp, neutral=True)
for at_h in xrange(0, h - fh + 1, stride_h):
# at_out_h - height of output corresponding to pool at position at_h
at_out_h = at_h / stride_h
for at_w in xrange(0, w - fw + 1, stride_w):
# at_out_w - height of output corresponding to pool at
# position at_w
at_out_w = at_w / stride_w
input_slice = layer_input[:, :, at_h:(at_h + fh), at_w:(at_w + fw)]
if is_max:
pool_res = input_slice.amax(axis=(0, 2, 3), keepdims=False)
else:
pool_res = input_slice.sum(axis=(0, 2, 3), keepdims=False) \
/ float(fh * fw)
result[:, at_out
```
<Overlap Ratio: 0.9739500265816056>

---

--- 162 --
Question ID: 6be19c45758d540b1ce3cd61658649f47a2b1f38_0
Original Code:
```
def mrr_score(ranks):
    '''Calculates the mrr for a list of ranks. Remarks: Ranks can also be zero.'''
    Q = len(ranks)
    sum = 0.0

    for rank in ranks:
        if rank != 0:
            sum += 1 / float(rank)

    mrr_score = 1.0 / Q * sum

    return mrr_score
```


Overlapping Code:
```
_score(ranks):
'''Calculates the mrr for a list of ranks. Remarks: Ranks can also be zero.'''
Q = len(ranks)
sum = 0.0
for rank in ranks:
if rank != 0:
sum += 1 / float(rank)
mrr_score = 1.0 / Q * sum
```
<Overlap Ratio: 0.8928571428571429>

---

--- 163 --
Question ID: 7128a296797722bcd64be5dc83a5dd4d8a6a968b_0
Original Code:
```
def getEpicListByStart(startTime_iso,proj="K2"):
    """
    Filtered Query of Mast for a specific project
    with observations within .25 days of a known start time
    Intended for finding observations of one K2 campaign.
    Returns a list of epic ids
    """


    t=Time(startTime_iso,format='iso', scale='utc')
    tmjd=t.mjd
    
    requestFilters = [
                             {"paramName":"project",
                              "values":[proj],
                              "separator":";"
                             },
                             {"paramName":"t_min",
                              "values":[{"min":tmjd-.5 , "max":tmjd+.5}]
                              },
                         ]
    
    mashupRequest = {"service":"Mast.Caom.Filtered",
                     "format":"json",
                     "params":{
                         #"columns":"COUNT_BIG(*)",
                         "columns":"*",
                         "filters":requestFilters
                         }}
    
    headers,outString = api.mastQuery(mashupRequest)
    countData = json.loads(outString)
    pdata=p.DataFrame.from_dict(countData['data'])
    
    epicids=list(map(lambda x: x[4:13], pdata['obs_id']))
    
    return epicids
```


Overlapping Code:
```
ListByStart(startTime_iso,proj="K2"):
"""
Filtered Query of Mast for a specific project
with observations within .25 days of a known start time
Intended for finding observations of one K2 campaign.
Returns a list of epic ids
"""
t=Time(startTime_iso,format='iso', scale='utc')
tmjd=t.mjd

requestFilters = [
{"paramName":"project",
"values":[proj],
"separator":";"
},
{"paramName":"t_min",
"values":[{"min":tmjd-.5 , "max":tmjd+.5}]
},
]

mashupRequest = {"service":"Mast.Caom.Filtered",
"format":"json",
"params":{
#"columns":"COUNT_BIG(*)",
"columns":"*",
"filters":requestFilters
}}

headers,outString = api.mastQuery(mashupRequest)
countData = json.loads(outString)
pdata=p.DataFrame.from_dict(countData['data'])

epicids=list(map(lambda x: x[4:1
```
<Overlap Ratio: 0.9398496240601504>

---

--- 164 --
Question ID: 4a48f9b0a5fc8a0a948ea48ef5a05d386b879425_0
Original Code:
```
def _input(prompt=None):
    """Wrap input() and raw_input() on Python 3 and 2 respectively.

    :param prompt: Optional[str]
    :return: str
    """
    try:
        return raw_input(prompt)
    except NameError:
        return input(prompt)
```


Overlapping Code:
```
""Wrap input() and raw_input() on Python 3 and 2 respectively.
:param prompt: Optional[str]
:return: str
"""
try:
return raw_input(prompt)
except NameError:
return input(prompt)
```
<Overlap Ratio: 0.8719211822660099>

---

--- 165 --
Question ID: 624d01d94f701f5e51d7157f58b97ca40947585f_2
Original Code:
```
def _structured_value_screen(self, key, val):
    '''A function for use as the screen method of a class built by :class:`StructuredValue`.

       If `key` is not a supported field, raise :class:`KeyError`.
       If `val` is not a supported lexical value type for field, raise :class:`TypeError`.
       If `val` is not a supported lexical value for field, raise :class:`ValueError`.
       Otherwise, return the canonical value for field from lexical value `val`.
    '''
    try:
        return self.fields[key](val)
    except KeyError:
        raise KeyError('unsupported field for {}: {}'.format(self.name, key))
    except ValueError:
        raise ValueError('bad value for {} field {}: {}'.format(self.name, key, val))
    except TypeError:
        raise TypeError('bad value for {} field {}: {}'.format(self.name, key, val))
```


Overlapping Code:
```
screen(self, key, val):
'''A function for use as the screen method of a class built by :class:`StructuredValue`.
If `key` is not a supported field, raise :class:`KeyError`.
If `val` is not a supported lexical value type for field, raise :class:`TypeError`.
If `val` is not a supported lexical value for field, raise :class:`ValueError`.
Otherwise, return the canonical value for field from lexical value `val`.
'''
try:
return self.fields[key](val)
except KeyError:
raise KeyError('unsupported field for {}: {}'.format(self.name, key))
except ValueError:
raise ValueError('bad value for {} field {}: {}'.format(self.name, key, val))
except TypeError:
raise TypeError('bad value for {} field {}: {}'.f
```
<Overlap Ratio: 0.9345794392523364>

---

--- 166 --
Question ID: 1d137ae8cf1fa460376a3d8f64d5ac93171b952d_16
Original Code:
```
def _validate_subscription_batch_creation(order, collection, timeslot):
    start, end = utilities.get_subscription_duration(order, collection)
    if order.status in (Order.SUBMITTED, Order.CANCELLED, Order.TERMINATED):
        logger.error("Order {!r} has a {!r} status. Cannot create new "
                     "batches".format(order.id, order.status))
        raise errors.InvalidOrderIdentifierError()
    elif not (start <= timeslot <= end):
        logger.debug("Requested timeslot is outside of subscription's "
                     "temporal range. Cannot create new batch")
        raise errors.InvalidOrderIdentifierError()
```


Overlapping Code:
```
tion_batch_creation(order, collection, timeslot):
start, end = utilities.get_subscription_duration(order, collection)
if order.status in (Order.SUBMITTED, Order.CANCELLED, Order.TERMINATED):
logger.error("Order {!r} has a {!r} status. Cannot create new "
"batches".format(order.id, order.status))
raise errors.InvalidOrderIdentifierError()
elif not (start <= timeslot <= end):
logger.debug("Requested timeslot is outside of subscription's "
"temporal range. Cannot create new batch")
raise errors.Inv
```
<Overlap Ratio: 0.9124087591240876>

---

--- 167 --
Question ID: 53a3685fd3dc15d196a75e19574000efd6e57805_12
Original Code:
```
def _noise_model_program_header(noise_model):
    """
    Generate the header for a pyquil Program that uses ``noise_model`` to overload noisy gates.
    The program header consists of 3 sections:

        - The ``DEFGATE`` statements that define the meaning of the newly introduced "noisy" gate
          names.
        - The ``PRAGMA ADD-KRAUS`` statements to overload these noisy gates on specific qubit
          targets with their noisy implementation.
        - THe ``PRAGMA READOUT-POVM`` statements that define the noisy readout per qubit.

    :param NoiseModel noise_model: The assumed noise model.
    :return: A quil Program with the noise pragmas.
    :rtype: pyquil.quil.Program
    """
    from pyquil.quil import Program
    p = Program()
    defgates = set()
    for k in noise_model.gates:

        # obtain ideal gate matrix and new, noisy name by looking it up in the NOISY_GATES dict
        try:
            ideal_gate, new_name = get_noisy_gate(k.gate, tuple(k.params))

            # if ideal version of gate has not yet been DEFGATE'd, do this
            if new_name not in defgates:
                p.defgate(new_name, ideal_gate)
                defgates.add(new_name)
        except NoisyGateUndefined:
            print("WARNING: Could not find ideal gate definition for gate {}".format(k.gate),
                  file=sys.stderr)
            new_name = k.gate

        # define noisy version of gate on specific targets
        p.define_noisy_gate(new_name, k.targets, k.kraus_ops)

    # define noisy readouts
    for q, ap in noise_model.assignment_probs.items():
        p.define_noisy_readout(q, p00=ap[0, 0], p11=ap[1, 1])
    return p
```


Overlapping Code:
```
el_program_header(noise_model):
"""
Generate the header for a pyquil Program that uses ``noise_model`` to overload noisy gates.
The program header consists of 3 sections:
- The ``DEFGATE`` statements that define the meaning of the newly introduced "noisy" gate
names.
- The ``PRAGMA ADD-KRAUS`` statements to overload these noisy gates on specific qubit
targets with their noisy implementation.
- THe ``PRAGMA READOUT-POVM`` statements that define the noisy readout per qubit.
:param NoiseModel noise_model: The assumed noise model.
:return: A quil Program with the noise pragmas.
:rtype: pyquil.quil.Program
"""
from pyquil.quil import Program
p = Program()
defgates = set()
for k in noise_model.gates:
# obtain ideal gate matrix and new, noisy name by looking it up in the NOISY_GATES dict
try:
ideal_gate, new_name = get_noisy_gate(k.gate, tuple(k.params))
# if ideal version of gate has not yet been DEFGATE'd, do this
if new_name not in defgates:
p.defgate(new_name, ideal_gate)
defgates.add(new_name)
except NoisyGateUndefined:
print("WARNING: Could not find ideal gate definition for gate {}".format(k.gate),
file=sys.stderr)
new_name = k.gate
# define noisy version of gate on specific targets
p.define_noisy_gate(new_name, k.targets, k.kraus_ops)
# define noisy readouts
for q, ap in noise_model.assignment_probs.items():
p.define_noisy_reado
```
<Overlap Ratio: 0.9601990049751243>

---

--- 168 --
Question ID: ce225d5eef0ece22880f86f9a252c0b10ca8a724_3
Original Code:
```
@pytest.mark.django_db()
def test_safe_navigation():
    position = mommy.make('position.Position')

    assert safe_navigation(position, "post") is None

    position.post = mommy.make('organization.Post')
    position.save()

    assert safe_navigation(position, "post") is not None
    assert safe_navigation(position, "post.location") is None

    position.post.location = mommy.make('organization.Location')
    position.save()

    assert safe_navigation(position, "post.location") is not None
```


Overlapping Code:
```
ion():
position = mommy.make('position.Position')
assert safe_navigation(position, "post") is None
position.post = mommy.make('organization.Post')
position.save()
assert safe_navigation(position, "post") is not None
assert safe_navigation(position, "post.location") is None
position.post.location = mommy.make('organization.Location')
position.save()
assert safe_navigation(position, "post.location")
```
<Overlap Ratio: 0.8733624454148472>

---

--- 169 --
Question ID: 9cfde3110ba8c9d509b9cdc3a55a2dbc1342ffb1_2
Original Code:
```
def build_generator_resnet_9blocks_tf(inputgen, name="generator", skip=False):
    with tf.variable_scope(name):
        f = 7
        ks = 3
        padding = "REFLECT"

        pad_input = tf.pad(inputgen, [[0, 0], [ks, ks], [
            ks, ks], [0, 0]], padding)
        o_c1 = layers.general_conv2d(
            pad_input, ngf, f, f, 1, 1, 0.02, name="c1")
        o_c2 = layers.general_conv2d(
            o_c1, ngf * 2, ks, ks, 2, 2, 0.02, "SAME", "c2")
        o_c3 = layers.general_conv2d(
            o_c2, ngf * 4, ks, ks, 2, 2, 0.02, "SAME", "c3")

        o_r1 = build_resnet_block(o_c3, ngf * 4, "r1", padding)
        o_r2 = build_resnet_block(o_r1, ngf * 4, "r2", padding)
        o_r3 = build_resnet_block(o_r2, ngf * 4, "r3", padding)
        o_r4 = build_resnet_block(o_r3, ngf * 4, "r4", padding)
        o_r5 = build_resnet_block(o_r4, ngf * 4, "r5", padding)
        o_r6 = build_resnet_block(o_r5, ngf * 4, "r6", padding)
        o_r7 = build_resnet_block(o_r6, ngf * 4, "r7", padding)
        o_r8 = build_resnet_block(o_r7, ngf * 4, "r8", padding)
        o_r9 = build_resnet_block(o_r8, ngf * 4, "r9", padding)

        o_c4 = layers.general_deconv2d(
            o_r9, [BATCH_SIZE, 128, 128, ngf * 2], ngf * 2, ks, ks, 2, 2, 0.02,
            "SAME", "c4")
        o_c5 = layers.general_deconv2d(
            o_c4, [BATCH_SIZE, 256, 256, ngf], ngf, ks, ks, 2, 2, 0.02,
            "SAME", "c5")
        o_c6 = layers.general_conv2d(o_c5, IMG_CHANNELS, f, f, 1, 1,
                                     0.02, "SAME", "c6",
                                     do_norm=False, do_relu=False)

        if skip is True:
            out_gen = tf.nn.tanh(inputgen + o_c6, "t1")
        else:
            out_gen = tf.nn.tanh(o_c6, "t1")

        return out_gen
```


Overlapping Code:
```
r_resnet_9blocks_tf(inputgen, name="generator", skip=False):
with tf.variable_scope(name):
f = 7
ks = 3
padding = "REFLECT"
pad_input = tf.pad(inputgen, [[0, 0], [ks, ks], [
ks, ks], [0, 0]], padding)
o_c1 = layers.general_conv2d(
pad_input, ngf, f, f, 1, 1, 0.02, name="c1")
o_c2 = layers.general_conv2d(
o_c1, ngf * 2, ks, ks, 2, 2, 0.02, "SAME", "c2")
o_c3 = layers.general_conv2d(
o_c2, ngf * 4, ks, ks, 2, 2, 0.02, "SAME", "c3")
o_r1 = build_resnet_block(o_c3, ngf * 4, "r1", padding)
o_r2 = build_resnet_block(o_r1, ngf * 4, "r2", padding)
o_r3 = build_resnet_block(o_r2, ngf * 4, "r3", padding)
o_r4 = build_resnet_block(o_r3, ngf * 4, "r4", padding)
o_r5 = build_resnet_block(o_r4, ngf * 4, "r5", padding)
o_r6 = build_resnet_block(o_r5, ngf * 4, "r6", padding)
o_r7 = build_resnet_block(o_r6, ngf * 4, "r7", padding)
o_r8 = build_resnet_block(o_r7, ngf * 4, "r8", padding)
o_r9 = build_resnet_block(o_r8, ngf * 4, "r9", padding)
o_c4 = layers.general_deconv2d(
o_r9, [BATCH_SIZE, 128, 128, ngf * 2], ngf * 2, ks, ks, 2, 2, 0.02,
"SAME", "c4")
o_c5 = layers.general_deconv2d(
o_c4, [BATCH_SIZE, 256, 256, ngf], ngf, ks, ks, 2, 2, 0.02,
"SAME", "c5")
o_c6 = layers.general_conv2d(o_c5, IMG_CHANNELS, f, f, 1, 1,
0.02, "SAME", "c6",
do_norm=False, do_relu=False)
if skip is True:
out_gen = tf.nn.tanh(inputgen + o_c6, "t1")
else:
out_gen = tf.nn.tanh(o_c6, "t1")
```
<Overlap Ratio: 0.9764453961456103>

---

--- 170 --
Question ID: 6859cb5b8630fc59b4f1eee81a4bc2cc6bd8303b_0
Original Code:
```
def poly_lr_scheduler(optimizer, init_lr, iter, lr_decay_iter=1, max_iter=30000, power=0.9,):
    """Polynomial decay of learning rate
        :param init_lr is base learning rate
        :param iter is a current iteration
        :param lr_decay_iter how frequently decay occurs, default is 1
        :param max_iter is number of maximum iterations
        :param power is a polymomial power

    """
    if iter % lr_decay_iter or iter > max_iter:
        return optimizer

    for param_group in optimizer.param_groups:
        param_group['lr'] = init_lr*(1 - iter/max_iter)**power
```


Overlapping Code:
```
def poly_lr_scheduler(optimizer, init_lr, iter, lr_decay_iter=1, max_iter=30000, power=0.9,):
"""Polynomial decay of learning rate
:param init_lr is base learning rate
:param iter is a current iteration
:param lr_decay_iter how frequently decay occurs, default is 1
:param max_iter is number of maximum iterations
:param power is a polymomial power
"""
if iter % lr_decay_iter or iter > max_iter:
return optimizer
for param_group in optimizer.param_groups:
param_group['lr'] = init_lr*(1 - iter/max_iter)**pow
```
<Overlap Ratio: 0.9960861056751468>

---

--- 171 --
Question ID: 8393024796feb1fac5d2a8be7ed14164b561a575_0
Original Code:
```
def main(url):
    response = requests.get(url)
    if not response.status_code == 200:
        print('Ошибка ({}) {}'.format(response.status_code, url))
        sys.exit(1)
    html = response.content
    soup = BeautifulSoup(html,'html.parser')
    print('{} (via tmfeed CLI)'.format(soup.html.head.title.text))
    for link in soup.find_all('li', 'tm-post'):
        post = link.find_all('div')
        print(post[0].a.text, end=' ')
        print(colored(post[0].span.text, 'cyan'))
        print(colored(post[1].a.text), 'blue')
        print(colored(post[1].a['href'] , 'green'), end=' ')
        print(colored('{}'.format(post[3].find_all('div')[0].text), 'cyan'))
    print('2006 — 2018 «TM»')
```


Overlapping Code:
```
(url):
response = requests.get(url)
if not response.status_code == 200:
print('Ошибка ({}) {}'.format(response.status_code, url))
sys.exit(1)
html = response.content
soup = BeautifulSoup(html,'html.parser')
print('{} (via tmfeed CLI)'.format(soup.html.head.title.text))
for link in soup.find_all('li', 'tm-post'):
post = link.find_all('div')
print(post[0].a.text, end=' ')
print(colored(post[0].span.text, 'cyan'))
print(colored(post[1].a.text), 'blue')
print(colored(post[1].a['href'] , 'green'), end=' ')
print(colored('{}'.format(post[3].find_all('div')[0].text), 'cyan'))
print('200
```
<Overlap Ratio: 0.9622331691297209>

---

--- 172 --
Question ID: a434b6b354a6d5d7005c5c262a075319e18701d6_1
Original Code:
```
def transform_into_boolean_list(stream_data, indexed_rules, request):
    '''
    Converts a stream field of strings and rules into a list
    of booleans (evaluated rule evaluations), strings and nested lists

    Sample Input:
    [
        {u'type': u'Rule', u'value': u'UserIsLoggedInRule_0'},
        {u'type': u'Operator', u'value': u'and'},
        {u'type': u'NestedLogic', u'value': {
            u'operator': u'or',
            u'rule_1': u'TimeRule_0',
            u'rule_2': u'TimeRule_1'}
        }
    ]

    Output:
    [True, 'and', [False, 'or', True]]
    '''
    return_value = []
    for block in stream_data:
        if block['type'] == 'Rule':
            rule = get_rule(block['value'], indexed_rules)
            return_value.append(rule.test_user(request))
        elif block['type'] == 'Operator':
            return_value.append(block['value'])
        elif block['type'] == 'NestedLogic':
            values = block['value']
            rule_1 = get_rule(values['rule_1'], indexed_rules)
            rule_2 = get_rule(values['rule_2'], indexed_rules)
            return_value.append([
                rule_1.test_user(request),
                values['operator'],
                rule_2.test_user(request)
            ])

    return return_value
```


Overlapping Code:
```
a, indexed_rules, request):
'''
Converts a stream field of strings and rules into a list
of booleans (evaluated rule evaluations), strings and nested lists
Sample Input:
[
{u'type': u'Rule', u'value': u'UserIsLoggedInRule_0'},
{u'type': u'Operator', u'value': u'and'},
{u'type': u'NestedLogic', u'value': {
u'operator': u'or',
u'rule_1': u'TimeRule_0',
u'rule_2': u'TimeRule_1'}
}
]
Output:
[True, 'and', [False, 'or', True]]
'''
return_value = []
for block in stream_data:
if block['type'] == 'Rule':
rule = get_rule(block['value'], indexed_rules)
return_value.append(rule.test_user(request))
elif block['type'] == 'Operator':
return_value.append(block['value'])
elif block['type'] == 'NestedLogic':
values = block['value']
rule_1 = get_rule(values['rule_1'], indexed_rules)
rule_2 = get_rule(values['rule_2'], indexed_rules)
return_value.append([
rule_1.test_user(request),
values['operator'],
rule
```
<Overlap Ratio: 0.9127789046653144>

---

--- 173 --
Question ID: 3d41a1043b73edfafa118ad4b6bca6353ad92830_0
Original Code:
```
def test_QHsmTst_init(qutest):
    qutest.init()
    qutest.expect("%timestamp BSP_DISPLAY top-INIT;")
    qutest.expect("%timestamp BSP_DISPLAY s-ENTRY;")
    qutest.expect("%timestamp BSP_DISPLAY s2-ENTRY;")
    qutest.expect("%timestamp BSP_DISPLAY s2-INIT;")
    qutest.expect("%timestamp BSP_DISPLAY s21-ENTRY;")
    qutest.expect("%timestamp BSP_DISPLAY s211-ENTRY;")
    qutest.expect("%timestamp Trg-Done QS_RX_EVENT")
```


Overlapping Code:
```
)
qutest.expect("%timestamp BSP_DISPLAY top-INIT;")
qutest.expect("%timestamp BSP_DISPLAY s-ENTRY;")
qutest.expect("%timestamp BSP_DISPLAY s2-ENTRY;")
qutest.expect("%timestamp BSP_DISPLAY s2-INIT;")
qutest.expect("%timestamp BSP_DISPLAY s21-ENTRY;")
qutest.expect("%timestamp BSP_DISPLAY s211-ENTRY;")
qutest.expect("%timestamp Trg-Done QS_RX_EVENT")
```
<Overlap Ratio: 0.8908629441624365>

---

--- 174 --
Question ID: 4f09f6de9b9d647c930fa411ca5ad7349fe99a13_5
Original Code:
```
def ConvertFromAbsolutePosition(map, absolute_x, absolute_y):
    tile_width = map.tiles[(0, 0)].width # accesses tile (0,0) (Which will ALWAYS exist in a non-malformed map) to get its height and width
    tile_height = map.tiles[(0, 0)].height
    
    tile_location = (absolute_x // tile_width, absolute_y // tile_height)
    sub_location = [absolute_x - (tile_width * tile_location[0]), absolute_y - (tile_height * tile_location[0])]

    return tile_location, sub_location
```


Overlapping Code:
```
tePosition(map, absolute_x, absolute_y):
tile_width = map.tiles[(0, 0)].width # accesses tile (0,0) (Which will ALWAYS exist in a non-malformed map) to get its height and width
tile_height = map.tiles[(0, 0)].height

tile_location = (absolute_x // tile_width, absolute_y // tile_height)
sub_location = [absolute_x - (tile_width * tile_location[0]), absolute_y - (tile_height * tile_location[0])]
retu
```
<Overlap Ratio: 0.8869179600886918>

---

--- 175 --
Question ID: 753d190a89a43e55aa47e1b2e59fd721228a02a9_13
Original Code:
```
def password_strength_check(handle, descr=None, **kwargs):
    """
    Check password strength for locally authenticated user

    Args:
        handle (UcscHandle)
        descr (string): description
        **kwargs: Any additional key-value pair of managed object(MO)'s
                  property and value, which are not part of regular args.
                  This should be used for future version compatibility.
    Returns:
        AaaUserEp: Managed Object

    Example:
        password_strength_check(handle)
    """

    mo = handle.query_dn(ucsc_base_dn + "/pwd-profile")
    mo.pwd_strength_check = "yes"
    mo.descr = descr

    mo.set_prop_multiple(**kwargs)

    handle.set_mo(mo)
    handle.commit()
    return mo
```


Overlapping Code:
```
f password_strength_check(handle, descr=None, **kwargs):
"""
Check password strength for locally authenticated user
Args:
handle (UcscHandle)
descr (string): description
**kwargs: Any additional key-value pair of managed object(MO)'s
property and value, which are not part of regular args.
This should be used for future version compatibility.
Returns:
AaaUserEp: Managed Object
Example:
password_strength_check(handle)
"""
mo = handle.query_dn(ucsc_base_dn + "/pwd-profile")
mo.pwd_strength_check = "yes"
mo.descr = descr
mo.set_prop_multiple(**kwargs)
handle.set_mo(mo)
handle.commit()
return m
```
<Overlap Ratio: 0.994991652754591>

---

--- 176 --
Question ID: 9b4ff6733b5a77f3fd810e8d919f031c83cbf26b_3
Original Code:
```
def Fun_locateCorr(scoreMap, band):
    assert len(scoreMap.shape) == 3
    M_s = np.amax(scoreMap, axis = 2)
    M_s = np.repeat(M_s[:, :, np.newaxis], band, axis=2) ##? Normalization?
    maxIdxMap = np.argmax(scoreMap, axis = 2)
    return M_s, maxIdxMap
```


Overlapping Code:
```
locateCorr(scoreMap, band):
assert len(scoreMap.shape) == 3
M_s = np.amax(scoreMap, axis = 2)
M_s = np.repeat(M_s[:, :, np.newaxis], band, axis=2) ##? Normalization?
maxIdxMap = np.argmax(scoreMap, axi
```
<Overlap Ratio: 0.8481012658227848>

---

--- 177 --
Question ID: 5aa39826b0ba3d16cc815957fb5bbd5f31dce53e_0
Original Code:
```
async def ex(message, client):
    if len(list(message.mentions)) > 0:
        member = message.mentions[0]
        xp = level_system.get_xp(member)
        level = int(int(xp) / 1000)
        progress = (int(xp) % 1000) / 1000
        progress_bar = "[" + "===================="[:int(progress * 20)] + "                    "[int(progress * 20):] + "]\n\n   " + str(int(progress * 100)) + "% to next LVL"
        await client.send_message(message.channel, embed=Embed(color=discord.Color.gold(),
                                                               title=member.name + "'s Level",
                                                               description=("**[LVL %s]**  `%s XP`\n```\n%s\n```" % (level, xp, progress_bar))))

    else:
        gettedtable = level_system.get_table()
        temptable = dict([(k, gettedtable[k]) for k in sorted(gettedtable, key=gettedtable.get, reverse=True)])
        table = {}
        if len(temptable.keys()) <= 20:
            table = temptable
        else:
            _count = 0
            for k in temptable:
                table[k] = temptable.get(k)
                _count += 1
                if _count >= 20:
                    break
        out = ""
        _count = 0
        for memb_id in table:
            try:
                _count += 1
                out += "%s. - **%s:**  **`%s XP`** \n" % (_count, discord.utils.get(message.server.members, id=memb_id).name, table[memb_id])
            except:
                pass
        await client.send_message(message.channel, "**XP LIST**\n\n" + out[:1980])
```


Overlapping Code:
```
ent):
if len(list(message.mentions)) > 0:
member = message.mentions[0]
xp = level_system.get_xp(member)
level = int(int(xp) / 1000)
progress = (int(xp) % 1000) / 1000
progress_bar = "[" + "===================="[:int(progress * 20)] + " "[int(progress * 20):] + "]\n\n " + str(int(progress * 100)) + "% to next LVL"
await client.send_message(message.channel, embed=Embed(color=discord.Color.gold(),
title=member.name + "'s Level",
description=("**[LVL %s]** `%s XP`\n```\n%s\n```" % (level, xp, progress_bar))))
else:
gettedtable = level_system.get_table()
temptable = dict([(k, gettedtable[k]) for k in sorted(gettedtable, key=gettedtable.get, reverse=True)])
table = {}
if len(temptable.keys()) <= 20:
table = temptable
else:
_count = 0
for k in temptable:
table[k] = temptable.get(k)
_count += 1
if _count >= 20:
break
out = ""
_count = 0
for memb_id in table:
try:
_count += 1
out += "%s. - **%s:** **`%s XP`** \n" % (_count, discord.utils.get(message.server.members, id=memb_id).name, table[memb_id])
except:
pass
await client.send_message(message.channel, 
```
<Overlap Ratio: 0.9498657117278424>

---

--- 178 --
Question ID: 310eadaec8c5992bd946709947ef3fb84083991f_2
Original Code:
```
def choose_img(picture_path,name_mask):
  picture_file_name = name_mask[:-8]+".jpg"
  full_path = os.path.join(picture_path,picture_file_name)
  return(full_path)
```


Overlapping Code:
```
me_mask):
picture_file_name = name_mask[:-8]+".jpg"
full_path = os.path.join(picture_path,picture_fi
```
<Overlap Ratio: 0.6410256410256411>

---

--- 179 --
Question ID: 7b1dbade1c2965786e5ac5e4ee395dfa28cd7ce9_1
Original Code:
```
def plot_ensembl_logo(self, fname=None, ic=True, title=True, letters=True, height=2):
    """Plot motif logo.

    This is an implementation of the logo presented here:
    http://www.ensembl.info/2018/10/15/new-ensembl-motif-features/

    Parameters
    ----------
    fname : str, optional
        If fname is set, the plot will be saved with fname as filename.
    ic : bool, optional
        Use the bit score. If this is set to False, the frequency
        will be used.
    title : bool, optional
        Plot the motif id as the title.
    letters : bool, optional
        Plot the nucleotides in the bars.
    height : float, optional
        Height of the plot.
    """
    width = 0.94

    ppm = self.ppm
    nucs = np.array(["A", "C", "G", "T"])

    neg_matrix = np.zeros((len(ppm), 4))

    pos_matrix = []
    nuc_ppm = []
    for row in ppm:
        if ic:
            ylabel = "bits"
            ic_row = []
            y_max = 2
            for p in row:
                if p < 0.25:
                    ic_row.append(0)
                else:
                    ic_row.append(p * np.log2((p) / 0.25))

        else:
            ic_row = row
            ylabel = "frequency"
            y_max = 1
        idx = np.argsort(ic_row)
        pos_matrix.append(np.array(ic_row)[idx])
        nuc_ppm.append(nucs[idx])

    colors = {
        "A": (0.308, 0.709, 0.280),
        "C": (0.145, 0.362, 0.6),
        "G": (0.969, 0.702, 0.172),
        "T": (0.841, 0.158, 0.224),
    }

    # x_max = np.max([np.sum(row) for row in pos_matrix])
    # x_min = -np.min([np.sum(row) for row in neg_matrix])
    # neg_matrix = neg_matrix / x_min * x_max

    plt.figure(figsize=(len(ppm) * 0.3, height))
    for (sign, matrix) in [(1, pos_matrix), (-1, neg_matrix)]:
        minbottom = np.zeros(len(matrix))
        alpha = 1
        if sign == -1:
            minbottom = np.array([np.sum(row) for row in matrix])
            alpha = 0.5

        # Print the bars
        for i in range(0, len(ppm[0])):

            pheight = [abs(r[i]) for r in matrix]
            bottom = minbottom + [sum(np.abs(r[:i])) for r in matrix]

            c = [colors[r[i]] for r in nuc_ppm]
            plt.bar(
                range(1, len(ppm) + 1),
                width=width,
                height=pheight,
                bottom=bottom,
                color=c,
                alpha=alpha,
            )

        if letters:
            # Print the letters
            for i in range(len(ppm)):
                for n in range(4):
                    x = i + 1
                    y = matrix[i][n] / 2 + sum(matrix[i][:n])
                    nuc = nuc_ppm[i][n]
                    c = "white"
                    if abs(matrix[i][n]) * height >= 0.5:
                        plt.text(
                            x,
                            y,
                            nuc,
                            horizontalalignment="center",
                            verticalalignment="center",
                            fontsize=8 + 10 * (matrix[i][n] / y_max),
                            color=c,
                        )

    # Remove axis lines
    ax = plt.gca()
    for spine in ax.spines.values():
        spine.set_color("none")

    if title:
        plt.title(self.id)
    plt.xlim(0.47, len(self) + 0.5)
    plt.xticks(range(1, len(ppm) + 1))
    plt.ylabel(ylabel)

    if fname:
        plt.savefig(fname, dpi=300)
        plt.close()
    else:
        return ax
```


Overlapping Code:
```
 plot_ensembl_logo(self, fname=None, ic=True, title=True, letters=True, height=2):
"""Plot motif logo.
This is an implementation of the logo presented here:
http://www.ensembl.info/2018/10/15/new-ensembl-motif-features/
Parameters
----------
fname : str, optional
If fname is set, the plot will be saved with fname as filename.
ic : bool, optional
Use the bit score. If this is set to False, the frequency
will be used.
title : bool, optional
Plot the motif id as the title.
letters : bool, optional
Plot the nucleotides in the bars.
height : float, optional
Height of the plot.
"""
width = 0.94
ppm = self.ppm
nucs = np.array(["A", "C", "G", "T"])
neg_matrix = np.zeros((len(ppm), 4))
pos_matrix = []
nuc_ppm = []
for row in ppm:
if ic:
ylabel = "bits"
ic_row = []
y_max = 2
for p in row:
if p < 0.25:
ic_row.append(0)
else:
ic_row.append(p * np.log2((p) / 0.25))
else:
ic_row = row
ylabel = "frequency"
y_max = 1
idx = np.argsort(ic_row)
pos_matrix.append(np.array(ic_row)[idx])
nuc_ppm.append(nucs[idx])
colors = {
"A": (0.308, 0.709, 0.280),
"C": (0.145, 0.362, 0.6),
"G": (0.969, 0.702, 0.172),
"T": (0.841, 0.158, 0.224),
}
# x_max = np.max([np.sum(row) for row in pos_matrix])
# x_min = -np.min([np.sum(row) for row in neg_matrix])
# neg_matrix = neg_matrix / x_min * x_max
plt.figure(figsize=(len(ppm) * 0.3, height))
for (sign, matrix) in [(1, pos_matrix), (-1, neg_matrix)]:
minbottom = np.zeros(len(matrix))
alpha = 1
if sign == -1:
minbottom = np.array([np.sum(row) for row in matrix])
alpha = 0.5
# Print the bars
for i in range(0, len(ppm[0])):
pheight = [abs(r[i]) for r in matrix]
bottom = minbottom + [sum(np.abs(r[:i])) for r in matrix]
c = [colors[r[i]] for r in nuc_ppm]
plt.bar(
range(1, len(ppm) + 1),
width=width,
height=pheight,
bottom=bottom,
color=c,
alpha=alpha,
)
if lette
```
<Overlap Ratio: 0.9719222462203023>

---

--- 180 --
Question ID: 9a4e8312a8b2593027b6224a3d1ea116e2b47859_0
Original Code:
```
def findCorrectClasses(y_values):
    y_classes = []
    for classes in y_values:
        for i, class_values in enumerate(classes):
            if class_values == 1:
                y_classes.append(i)
                break
    return y_classes
```


Overlapping Code:
```
classes = []
for classes in y_values:
for i, class_values in enumerate(classes):
if class_values == 
```
<Overlap Ratio: 0.5524861878453039>

---

--- 181 --
Question ID: d9e1bbfe4521aff871c953fa4504d8d0371e2889_4
Original Code:
```
def get_filtered_path(path_to_image, filename_key, storage):
    """
    Return the 'filtered path'
    """
    containing_folder, filename = os.path.split(path_to_image)

    filtered_filename = get_filtered_filename(filename, filename_key)
    path_to_return = os.path.join(*[
        containing_folder,
        VERSATILEIMAGEFIELD_FILTERED_DIRNAME,
        filtered_filename
    ])
    # Removing spaces so this path is memcached key friendly
    path_to_return = path_to_return.replace(' ', '')
    return path_to_return
```


Overlapping Code:
```
def get_filtered_path(path_to_image, filename_key, storage):
"""
Return the 'filtered path'
"""
containing_folder, filename = os.path.split(path_to_image)
filtered_filename = get_filtered_filename(filename, filename_key)
path_to_return = os.path.join(*[
containing_folder,
VERSATILEIMAGEFIELD_FILTERED_DIRNAME,
filtered_filename
])
# Removing spaces so this path is memcached key friendly
path_to_return = path_to_return.replace(' ', '')
return path_to_r
```
<Overlap Ratio: 0.9891067538126361>

---

--- 182 --
Question ID: 2ac3a7f55130bc75a7cd25c38393cea4a8cafd3f_6
Original Code:
```
def test_generate_date_series_end_date_none(start_date, interval, granularity):
    (interval_param, interval, interval_str) = interval
    (start_date_param, start_date, start_date_str) = start_date
    (granularity_param, granularity, granularity_str) = granularity
    if start_date_param and interval_param:
        end_date_str = start_date.strftime('%Y-%m-%d %H:%M:%S.%f')
    else:
        end_date_str = UTCNOW.strftime('%Y-%m-%d %H:%M:%S.%f')

    if not start_date_param:
        expected = 'generate_series(DATE {} - INTERVAL {}, {}, {})'.format(
            end_date_str, interval_str, end_date_str, granularity_str)
    elif not interval_param:
        expected = 'generate_series({}, {}, {})'.format(start_date_str, end_date_str, granularity_str)
    else:
        expected = 'generate_series({}, DATE {} + INTERVAL {}, {})'.format(
            start_date_str, end_date_str, interval_str, granularity_str)

    query = generate_date_series(start_date_param, None, interval_param, granularity_param)
    expression = query.compile(dialect=postgresql.dialect())
    actual = str(expression) % expression.params
    assert expected == actual
```


Overlapping Code:
```
t_date, interval, granularity):
(interval_param, interval, interval_str) = interval
(start_date_param, start_date, start_date_str) = start_date
(granularity_param, granularity, granularity_str) = granularity
if start_date_param and interval_param:
end_date_str = start_date.strftime('%Y-%m-%d %H:%M:%S.%f')
else:
end_date_str = UTCNOW.strftime('%Y-%m-%d %H:%M:%S.%f')
if not start_date_param:
expected = 'generate_series(DATE {} - INTERVAL {}, {}, {})'.format(
end_date_str, interval_str, end_date_str, granularity_str)
elif not interval_param:
expected = 'generate_series({}, {}, {})'.format(start_date_str, end_date_str, granularity_str)
else:
expected = 'generate_series({}, DATE {} + INTERVAL {}, {})'.format(
start_date_str, end_date_str, interval_str, granularity_str)
query = generate_date_series(start_date_param, None, interval_param, granularity_param)
expression = query.compile(dialect=postgresql.dialect())
actual = str(expression) % expression.params
assert expected == actua
```
<Overlap Ratio: 0.9527938342967245>

---

--- 183 --
Question ID: 21cd10ec0c43a2a5245ac89b17664c6b6824fc20_13
Original Code:
```
def template_to_filepath(template, metadata, template_patterns=None):
	"""Create directory structure and file name based on metadata template.

	Parameters:
		template (str): A filepath which can include template patterns as defined by :param template_patterns:.

		metadata (dict): A metadata dict.

		template_patterns (dict): A dict of ``pattern: field`` pairs used to replace patterns with metadata field values.
			Default: :const TEMPLATE_PATTERNS:

	Returns:
		A filepath.
	"""

	if template_patterns is None:
		template_patterns = TEMPLATE_PATTERNS

	metadata = metadata if isinstance(metadata, dict) else _mutagen_fields_to_single_value(metadata)
	assert isinstance(metadata, dict)

	suggested_filename = get_suggested_filename(metadata).replace('.mp3', '')

	if template == os.getcwd() or template == '%suggested%':
		filepath = suggested_filename
	else:
		t = template.replace('%suggested%', suggested_filename)
		filepath = _replace_template_patterns(t, metadata, template_patterns)

	return filepath
```


Overlapping Code:
```
plate_to_filepath(template, metadata, template_patterns=None):
"""Create directory structure and file name based on metadata template.
Parameters:
template (str): A filepath which can include template patterns as defined by :param template_patterns:.
metadata (dict): A metadata dict.
template_patterns (dict): A dict of ``pattern: field`` pairs used to replace patterns with metadata field values.
Default: :const TEMPLATE_PATTERNS:
Returns:
A filepath.
"""
if template_patterns is None:
template_patterns = TEMPLATE_PATTERNS
metadata = metadata if isinstance(metadata, dict) else _mutagen_fields_to_single_value(metadata)
assert isinstance(metadata, dict)
suggested_filename = get_suggested_filename(metadata).replace('.mp3', '')
if template == os.getcwd() or template == '%suggested%':
filepath = suggested_filename
else:
t = template.replace('%suggested%', suggested_filename)
filepath = _replace_template_patterns(t, metadata, template_patterns)
```
<Overlap Ratio: 0.9763617677286742>

---

--- 184 --
Question ID: b05d4c763dce74af14b2e274a94368cfa50e03ab_6
Original Code:
```
def expand_env_variables(self, env, string_to_process):
        """
        развернуть в строке переменные окружения zoo
        поискать в строке '%KEY%' если есть то заменить на соответсвующее значение из словаря
        и так для каждого ключа в словаре

        :param string_to_process:
        :return:
        """
        result = string_to_process
        for (key, value) in env.items():
            if string_to_process.lower() != key.lower():
                result = result.lower().replace("%" + key.lower() + "%", value)

        if result.lower().find("%") != -1:
            #repeat if nested expand needed
            for (key, value) in env.items():
                if string_to_process.lower() != key.lower():
                    result = result.lower().replace("%" + key.lower() + "%", value)


        if result.lower() != string_to_process.lower():
            logging.debug("expand_zoo_variables > {0} --> {1}".format( string_to_process, result.lower()))
        return result.lower()
```


Overlapping Code:
```
lf, env, string_to_process):
"""
развернуть в строке переменные окружения zoo
поискать в строке '%KEY%' если есть то заменить на соответсвующее значение из словаря
и так для каждого ключа в словаре
:param string_to_process:
:return:
"""
result = string_to_process
for (key, value) in env.items():
if string_to_process.lower() != key.lower():
result = result.lower().replace("%" + key.lower() + "%", value)
if result.lower().find("%") != -1:
#repeat if nested expand needed
for (key, value) in env.items():
if string_to_process.lower() != key.lower():
result = result.lower().replace("%" + key.lower() + "%", value)
if result.lower() != string_to_process.lower():
logging.debug("expand_zoo_variables > {0} --> {1}".format( string_to_process, result.lo
```
<Overlap Ratio: 0.9305210918114144>

---

--- 185 --
Question ID: 608ad476dcddc19b5eeda58febe9d10c1af35542_1
Original Code:
```
def _reshape_chisqr(
    grid_ref: dict[str, np.ndarray], grid_result: GridResult
) -> np.ndarray:
    keys = list(grid_result.grid)
    order = [keys.index(key) for key in grid_ref if key in keys]
    axes_to_reduce = tuple(sorted(set(range(len(keys))) - set(order)))
    order.extend(axes_to_reduce)

    # After transpose, axes are shuffled
    axes_to_reduce = tuple(order.index(index) for index in axes_to_reduce)

    chisqr_final = grid_result.chisqr.transpose(order)
    chisqr_final = np.minimum.reduce(chisqr_final, axis=axes_to_reduce)

    shape = tuple(
        len(grid_ref[key]) if key in grid_result.grid else 1 for key in grid_ref
    )
    chisqr_final = chisqr_final.reshape(shape)
    return chisqr_final
```


Overlapping Code:
```
_reshape_chisqr(
grid_ref: dict[str, np.ndarray], grid_result: GridResult
) -> np.ndarray:
keys = list(grid_result.grid)
order = [keys.index(key) for key in grid_ref if key in keys]
axes_to_reduce = tuple(sorted(set(range(len(keys))) - set(order)))
order.extend(axes_to_reduce)
# After transpose, axes are shuffled
axes_to_reduce = tuple(order.index(index) for index in axes_to_reduce)
chisqr_final = grid_result.chisqr.transpose(order)
chisqr_final = np.minimum.reduce(chisqr_final, axis=axes_to_reduce)
shape = tuple(
len(grid_ref[key]) if key in grid_result.grid else 1 for key in grid_ref
)
chisqr_final = chisqr_final.reshape(shape)
return chisq
```
<Overlap Ratio: 0.983358547655068>

---

--- 186 --
Question ID: cde243e8eb7a9479473ffccc06e6d83a5603d6a2_0
Original Code:
```
def get_dividend(url):
    html_doc = requests.get(url)
    soup = BeautifulSoup(html_doc.text, 'html.parser')
    table = soup.find('table', {'id': 'divCapGainsTable'})
    thead = [
        'distribution-type',
        'distribution',
        'record-date',
        'ex-dividend-date',
        'payable-date',
        'distribution-yield',
        'sec-yield'
    ]

    ex_dividend_list = []

    for tr in table.find_all('tr')[1:]:
        ex_dividend_dict = {}
        for index, td in enumerate(tr.find_all('td')):
            ex_dividend_dict[thead[index]] = td.text
        ex_dividend_list.append(ex_dividend_dict)

    for record in ex_dividend_list:
        if record['ex-dividend-date'] == today:
            message = textwrap.dedent("""\
            <table border="0" style="font-family: Verdana">
                <tr>
                    <td>
                        <h3>Today is {} Ex-Dividend Date</h3>
                    </td>
                </tr>
                <tr>
                    <td>
                        <ul>
                            <li>Type: {}</li>
                            <li>Distribution: {}</li>
                            <li>Payable Date: {}</li>
                        </ul>
                    </td>
                </tr>
            </table>
            """.format(
                symbol,
                record['distribution-type'],
                record['distribution'],
                record['payable-date'])
            )
            send_email(message)
```


Overlapping Code:
```
dend(url):
html_doc = requests.get(url)
soup = BeautifulSoup(html_doc.text, 'html.parser')
table = soup.find('table', {'id': 'divCapGainsTable'})
thead = [
'distribution-type',
'distribution',
'record-date',
'ex-dividend-date',
'payable-date',
'distribution-yield',
'sec-yield'
]
ex_dividend_list = []
for tr in table.find_all('tr')[1:]:
ex_dividend_dict = {}
for index, td in enumerate(tr.find_all('td')):
ex_dividend_dict[thead[index]] = td.text
ex_dividend_list.append(ex_dividend_dict)
for record in ex_dividend_list:
if record['ex-dividend-date'] == today:
message = textwrap.dedent("""\
<table border="0" style="font-family: Verdana">
<tr>
<td>
<h3>Today is {} Ex-Dividend Date</h3>
</td>
</tr>
<tr>
<td>
<ul>
<li>Type: {}</li>
<li>Distribution: {}</li>
<li>Payable Date: {}</li>
</ul>
</td>
</tr>
</table>
""".format(
symbol,
record['distribution-type'],
record['distribution'],
record['payabl
```
<Overlap Ratio: 0.9544008483563097>

---

--- 187 --
Question ID: 0f595c3e546e8f2d5186f0ef90499cb20eba8fbe_0
Original Code:
```
def includeme(config):
    LOGGER.info("init audit-request plugin")
    config.set_authentication_policy(
        AuthenticationPolicy(config.registry.settings["auth.file"])
    )
    add_design()
    config.add_subscriber(set_logging_context, ContextFound)
    config.add_request_method(extract_request, "request", reify=True)
    config.add_request_method(request_from_data)
    config.scan("openprocurement.audit.request.views")
```


Overlapping Code:
```

LOGGER.info("init audit-request plugin")
config.set_authentication_policy(
AuthenticationPolicy(config.registry.settings["auth.file"])
)
add_design()
config.add_subscriber(set_logging_context, ContextFound)
config.add_request_method(extract_request, "request", reify=True)
config.add_request_method(request_from_data)
config.scan("openprocurement.au
```
<Overlap Ratio: 0.8951406649616368>

---

--- 188 --
Question ID: e7d3606bac6fcead226a24baebb27cda88f01438_1
Original Code:
```
def group_covmtx(rho_intra, rho_inter, num_groups, num_objects):
    ''' create a covarince matrix with groups
    
    create covariance matrix for num_groups*num_objects variables 
    in each group are num_objects with a covariance of rho_intra. 
    objects between groups have a covariance of rho_intra 
    '''

    intra_mtx_size = int((num_objects ** 2 - num_objects) / 2)
    intra_cov = 1 - squareform([1 - rho_intra] * intra_mtx_size)

    cov = rho_inter * np.ones((num_groups * num_objects, num_groups * num_objects))
    for group_num in range(num_groups):
        cov[group_num * num_objects:(group_num + 1) * num_objects,
            group_num * num_objects:(group_num + 1) * num_objects] = intra_cov
    return cov
```


Overlapping Code:
```
tx(rho_intra, rho_inter, num_groups, num_objects):
''' create a covarince matrix with groups

create covariance matrix for num_groups*num_objects variables 
in each group are num_objects with a covariance of rho_intra. 
objects between groups have a covariance of rho_intra 
'''
intra_mtx_size = int((num_objects ** 2 - num_objects) / 2)
intra_cov = 1 - squareform([1 - rho_intra] * intra_mtx_size)
cov = rho_inter * np.ones((num_groups * num_objects, num_groups * num_objects))
for group_num in range(num_groups):
cov[group_num * num_objects:(group_num + 1) * num_objects,
group_num * num_objects:(group_num + 1) * num_objects] = intra_cov
return co
```
<Overlap Ratio: 0.9774436090225563>

---

--- 189 --
Question ID: f04d43d82ea8ea1bb7ad46bfa134e3179aa1625b_7
Original Code:
```
def test_unexpected_datetime_column_handled_without_errors():
    df_titanic_train, df_titanic_test = utils.get_titanic_binary_classification_dataset()

    column_descriptions = {
        'survived': 'output'
        , 'sex': 'categorical'
        , 'embarked': 'categorical'
        , 'pclass': 'categorical'
    }

    ml_predictor = Predictor(type_of_estimator='classifier', column_descriptions=column_descriptions)

    ml_predictor.train(df_titanic_train)

    test_dict = df_titanic_test.sample(frac=0.1).to_dict('records')[0]

    test_dict['unexpected_column'] = datetime.date.today()
    test_dict['anoter_unexpected_column'] = datetime.datetime.today()

    ml_predictor.predict(test_dict)

    # We want to make sure the above does not throw an error
    assert True
```


Overlapping Code:
```
umn_handled_without_errors():
df_titanic_train, df_titanic_test = utils.get_titanic_binary_classification_dataset()
column_descriptions = {
'survived': 'output'
, 'sex': 'categorical'
, 'embarked': 'categorical'
, 'pclass': 'categorical'
}
ml_predictor = Predictor(type_of_estimator='classifier', column_descriptions=column_descriptions)
ml_predictor.train(df_titanic_train)
test_dict = df_titanic_test.sample(frac=0.1).to_dict('records')[0]
test_dict['unexpected_column'] = datetime.date.today()
test_dict['anoter_unexpected_column'] = datetime.datetime.today()
ml_predictor.predict(test_dict)
# We want to make sure the above does not throw an erro
```
<Overlap Ratio: 0.935251798561151>

---

--- 190 --
Question ID: b8d67363e898f17fe8aab28f24eca8aad0fc2d1b_0
Original Code:
```
@pytest.fixture(scope="function")
def memoized_mock(mocker):
    func = mocker.MagicMock()

    memoized_func = si.utils.memoize(func)

    return func, memoized_func
```


Overlapping Code:
```
re(scope="function")
def memoized_mock(mocker):
func = mocker.MagicMock()
memoized_func = si.utils.m
```
<Overlap Ratio: 0.6578947368421053>

---

--- 191 --
Question ID: 1455f9173559a159403d491702b38de8f0f2948a_0
Original Code:
```
def grouper(iterable, n, fillvalue=None):
    "Collect data into fixed-length chunks or blocks"
    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx"
    args = [iter(iterable)] * n
    return zip_longest(*args, fillvalue=fillvalue)
```


Overlapping Code:
```
def grouper(iterable, n, fillvalue=None):
"Collect data into fixed-length chunks or blocks"
# grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx"
args = [iter(iterable)] * n
return zip_longest(*args, fillvalue=fillvalue)
```
<Overlap Ratio: 1.0>

---

--- 192 --
Question ID: 6871d242a87563196769668b49bf737e1f7830fb_2
Original Code:
```
def _build_spin_matrices(basis: Basis) -> dict[str, np.ndarray]:
    size = len(basis) * len(model.states)
    matrices: dict[str, np.ndarray] = defaultdict(lambda: np.zeros((size, size)))
    for transition_name, state in product(_TRANSITIONS, model.states):
        if not basis.type.endswith("_diff") and transition_name.startswith("d_"):
            continue
        name = transition_name.format(state=state)
        indices, values = _get_indices(basis, transition_name, state)
        if values:
            matrices[name][indices] = values
    return matrices
```


Overlapping Code:
```
in_matrices(basis: Basis) -> dict[str, np.ndarray]:
size = len(basis) * len(model.states)
matrices: dict[str, np.ndarray] = defaultdict(lambda: np.zeros((size, size)))
for transition_name, state in product(_TRANSITIONS, model.states):
if not basis.type.endswith("_diff") and transition_name.startswith("d_"):
continue
name = transition_name.format(state=state)
indices, values = _get_indices(basis, transition_name, state)
if values:
matrices[name][i
```
<Overlap Ratio: 0.9090909090909091>

---

--- 193 --
Question ID: 8a34957e7780f695319c738019d5856b172ee9c5_1
Original Code:
```
def load_data(nb_classes, PL, gParameters):
    train_path=gParameters['train_path']
    test_path=gParameters['test_path'] 
    outdir = gParameters['output_dir']
    df_train = (pd.read_csv(train_path,header=None).values).astype('float32')
    df_test = (pd.read_csv(test_path,header=None).values).astype('float32')

    print('df_train shape:', df_train.shape)
    print('df_test shape:', df_test.shape)

    df_y_train = df_train[:,0].astype('int')
    df_y_test = df_test[:,0].astype('int')

    Y_train = np_utils.to_categorical(df_y_train,nb_classes)
    train_classes = np.argmax(Y_train, axis=1)
    np.savetxt(outdir+"/train_classes.csv", train_classes, delimiter=",", fmt="%d")
    
    Y_test = np_utils.to_categorical(df_y_test,nb_classes)
    test_classes = np.argmax(Y_test, axis=1)
    np.savetxt(outdir+"/test_classes.csv", test_classes, delimiter=",", fmt="%d")
              
    df_x_train = df_train[:, 1:PL].astype(np.float32)
    df_x_test = df_test[:, 1:PL].astype(np.float32)
            
    # not sure the extra variable is needed, and is this a copy or reference
    X_train = df_x_train
    X_test = df_x_test
            
    scaler = MaxAbsScaler()
    mat = np.concatenate((X_train, X_test), axis=0)
    mat = scaler.fit_transform(mat)
       
    X_train = mat[:X_train.shape[0], :]
    X_test = mat[X_train.shape[0]:, :]
        
    return X_train, Y_train, X_test, Y_test
```


Overlapping Code:
```
L, gParameters):
train_path=gParameters['train_path']
test_path=gParameters['test_path'] 
outdir = gParameters['output_dir']
df_train = (pd.read_csv(train_path,header=None).values).astype('float32')
df_test = (pd.read_csv(test_path,header=None).values).astype('float32')
print('df_train shape:', df_train.shape)
print('df_test shape:', df_test.shape)
df_y_train = df_train[:,0].astype('int')
df_y_test = df_test[:,0].astype('int')
Y_train = np_utils.to_categorical(df_y_train,nb_classes)
train_classes = np.argmax(Y_train, axis=1)
np.savetxt(outdir+"/train_classes.csv", train_classes, delimiter=",", fmt="%d")

Y_test = np_utils.to_categorical(df_y_test,nb_classes)
test_classes = np.argmax(Y_test, axis=1)
np.savetxt(outdir+"/test_classes.csv", test_classes, delimiter=",", fmt="%d")

df_x_train = df_train[:, 1:PL].astype(np.float32)
df_x_test = df_test[:, 1:PL].astype(np.float32)

# not sure the extra variable is needed, and is this a copy or reference
X_train = df_x_train
X_test = df_x_test

scaler = MaxAbsScaler()
mat = np.concatenate((X_train, X_test), axis=0)
mat = scaler.fit_transform(mat)

X_train = mat[:X_train.shape[0], :]
X_test = mat[X_train.shape[0]:, :]

return X_train, Y_train, X_t
```
<Overlap Ratio: 0.9694288012872083>

---

--- 194 --
Question ID: 08d449c0712e896bbf5e1bfd27f30e8b29e31227_3
Original Code:
```
def _sa_bind_mastery():
    global Mastery

    @cassiopeia.type.core.common.inheritdocs
    class Mastery(Mastery, cassiopeia.type.dto.common.BaseDB):
        __tablename__ = "MasterySlot"
        id = sqlalchemy.Column(sqlalchemy.Integer)
        rank = sqlalchemy.Column(sqlalchemy.Integer)
        _id = sqlalchemy.Column(sqlalchemy.Integer, primary_key=True)
        _page_id = sqlalchemy.Column(sqlalchemy.Integer, sqlalchemy.ForeignKey("MasteryPage.id", ondelete="CASCADE"))
```


Overlapping Code:
```
_mastery():
global Mastery
@cassiopeia.type.core.common.inheritdocs
class Mastery(Mastery, cassiopeia.type.dto.common.BaseDB):
__tablename__ = "MasterySlot"
id = sqlalchemy.Column(sqlalchemy.Integer)
rank = sqlalchemy.Column(sqlalchemy.Integer)
_id = sqlalchemy.Column(sqlalchemy.Integer, primary_key=True)
_page_id = sqlalchemy.Column(sqlalchemy.Integer, sqlalchemy.ForeignKey("MasteryPage.id", ondelete="
```
<Overlap Ratio: 0.9485981308411215>

---

--- 195 --
Question ID: dacc161b4f5ccec815fbafc9482e0ca6b5ec3fa4_11
Original Code:
```
@pytest.mark.parametrize(
    "base_tpi,base_params,reform_tpi, reform_params,ineq_measure,"
    + "pctiles,plot_type",
    [
        (base_tpi, base_params, None, None, "gini", None, "levels"),
        (
            base_tpi,
            base_params,
            reform_tpi,
            reform_params,
            "gini",
            None,
            "levels",
        ),
        (
            base_tpi,
            base_params,
            reform_tpi,
            reform_params,
            "var_of_logs",
            None,
            "diff",
        ),
        (
            base_tpi,
            base_params,
            reform_tpi,
            reform_params,
            "pct_ratio",
            (0.9, 0.1),
            "levels",
        ),
        (
            base_tpi,
            base_params,
            reform_tpi,
            reform_params,
            "top_share",
            (0.01),
            "pct_diff",
        ),
    ],
    ids=[
        "Just baseline",
        "Baseline + Reform",
        "Base + Refore, var logs, diff",
        "Base + Refore, pct ratios",
        "Base + Refore, top share, pct diff",
    ],
)
def test_inequality_plot(
    base_tpi,
    base_params,
    reform_tpi,
    reform_params,
    ineq_measure,
    pctiles,
    plot_type,
):
    fig = output_plots.inequality_plot(
        base_tpi,
        base_params,
        reform_tpi=reform_tpi,
        reform_params=reform_params,
        ineq_measure=ineq_measure,
        pctiles=pctiles,
        plot_type=plot_type,
    )
    assert fig

```


Overlapping Code:
```
_tpi,base_params,reform_tpi, reform_params,ineq_measure,"
+ "pctiles,plot_type",
[
(base_tpi, base_params, None, None, "gini", None, "levels"),
(
base_tpi,
base_params,
reform_tpi,
reform_params,
"gini",
None,
"levels",
),
(
base_tpi,
base_params,
reform_tpi,
reform_params,
"var_of_logs",
None,
"diff",
),
(
base_tpi,
base_params,
reform_tpi,
reform_params,
"pct_ratio",
(0.9, 0.1),
"levels",
),
(
base_tpi,
base_params,
reform_tpi,
reform_params,
"top_share",
(0.01),
"pct_diff",
),
],
ids=[
"Just baseline",
"Baseline + Reform",
"Base + Refore, var logs, diff",
"Base + Refore, pct ratios",
"Base + Refore, top share, pct diff",
],
)
def test_inequality_plot(
base_tpi,
base_params,
reform_tpi,
reform_params,
ineq_measure,
pctiles,
plot_type,
):
fig = output_plots.inequality_plot(
base_tpi,
base_params,
reform_tpi=reform_tpi,
reform_params=reform_params,
ineq_measure=ineq_measure,
pctiles=pctiles
```
<Overlap Ratio: 0.9318885448916409>

---

--- 196 --
Question ID: ce4c9032abe8b95d9d76a67f5262faff20fc1f26_1
Original Code:
```
def clone_or_reset(pkgname, freeworldname, *, rffree):
    SCM.mkdir(exist_ok=True)
    repo = SCM / freeworldname
    if not repo.exists():
        with cd(SCM):
            rfpkg_clone(freeworldname, free=rffree)
    with cd(repo):
        setup_remotes(pkgname, freeworldname)
        git('fetch', '--all')
        git('checkout', 'master')
        git('reset', '--hard', 'origin/master')
        git('clean', '-f')
```


Overlapping Code:
```
kgname, freeworldname, *, rffree):
SCM.mkdir(exist_ok=True)
repo = SCM / freeworldname
if not repo.exists():
with cd(SCM):
rfpkg_clone(freeworldname, free=rffree)
with cd(repo):
setup_remotes(pkgname, freeworldname)
git('fetch', '--all')
git('checkout', 'master')
git('reset', '--hard', 'origin/maste
```
<Overlap Ratio: 0.8771929824561403>

---

--- 197 --
Question ID: b9605f2be3730f95c4dd922e6faea910daf36f76_22
Original Code:
```
@raises(ValueError)
def test_fill_option_not_found():
    browser.open('/form/select')
    browser.document.forms[0].fill({'sel': 'unexisting'})
```


Overlapping Code:
```
und():
browser.open('/form/select')
browser.docume
```
<Overlap Ratio: 0.36764705882352944>

---

--- 198 --
Question ID: 333798cbe019c32d34e40d9f47e4ae6232ce343c_0
Original Code:
```
def test_response_set_content_type_set():
    resp = falcon.Response()
    resp._set_media_type(MEDIA_TEXT)
    assert resp._headers['content-type'] == MEDIA_TEXT
```


Overlapping Code:
```
onse_set_content_type_set():
resp = falcon.Response()
resp._set_media_type(MEDIA_TEXT)
assert resp._headers['content-
```
<Overlap Ratio: 0.78>

---

--- 199 --
Question ID: 741823f78624eaea0ad9e096224c532974649085_7
Original Code:
```
def test_verify_wal_starts_at_bof():
    with TemporaryFile("w+b") as tmp_file:
        tmp_file.write(WAL_HEADER_95 + b"XXX" * 100)
        tmp_file.seek(10)
        wal.verify_wal(wal_name="0000002F000000110000009C", fileobj=tmp_file)
```


Overlapping Code:
```
rify_wal_starts_at_bof():
with TemporaryFile("w+b") as tmp_file:
tmp_file.write(WAL_HEADER_95 + b"XXX" * 100)
tmp_file.seek(10)
wal.verify_wal(wal_name="0000002F000000110000009C", fileo
```
<Overlap Ratio: 0.8894230769230769>

---

--- 200 --
Question ID: 73522e27bdcbd82940751288419ad30f090999e0_1
Original Code:
```
def test_read_file():
    files = read('__mocks__/file.txt')

    assert len(files) == 1
    assert_file(files[0], 'Nossa senhora nosso')
```


Overlapping Code:
```
_mocks__/file.txt')
assert len(files) == 1
assert_
```
<Overlap Ratio: 0.4032258064516129>

---

--- 201 --
Question ID: 84534447ea7ed77ef1df250535cfd0fadca4a84d_3
Original Code:
```
def OnImportHdf(event):
	path_temp=''
	path_temp='python '+path+'proc_hdf_in.py'
	wx.Execute(path_temp, False)
```


Overlapping Code:
```
event):
path_temp=''
path_temp='python '+path+'proc_
```
<Overlap Ratio: 0.48598130841121495>

---

--- 202 --
Question ID: 42d9327787c0bc8a99aab5e63601a658e8f5825d_7
Original Code:
```
def remove_node(network, node):
    if node is None:
        raise ValueError("Node must be specified when trying to remove it.")
    network.getNodes().remove(node)
```


Overlapping Code:
```
de(network, node):
if node is None:
raise ValueError("Node must be specified when trying to remove it.")
network.getNodes(
```
<Overlap Ratio: 0.8187919463087249>

---

--- 203 --
Question ID: d86669715093918ca78ec99c89eefc422ff594e0_0
Original Code:
```
def _norm_input_labels_index(input, labels=None, index=None):
    """
    Normalize arguments to a standard form.
    """

    input = _compat._asarray(input)

    if labels is None:
        labels = dask.array.ones(input.shape, dtype=int, chunks=input.chunks)
        index = dask.array.ones(tuple(), dtype=int, chunks=tuple())
    elif index is None:
        labels = (labels > 0).astype(int)
        index = dask.array.ones(tuple(), dtype=int, chunks=tuple())

    labels = _compat._asarray(labels)
    index = _compat._asarray(index)

    if index.ndim > 1:
        warnings.warn(
            "Having index with dimensionality greater than 1 is undefined.",
            FutureWarning
        )

    if input.shape != labels.shape:
        raise ValueError("The input and labels arrays must be the same shape.")

    return (input, labels, index)
```


Overlapping Code:
```
 _norm_input_labels_index(input, labels=None, index=None):
"""
Normalize arguments to a standard form.
"""
input = _compat._asarray(input)
if labels is None:
labels = dask.array.ones(input.shape, dtype=int, chunks=input.chunks)
index = dask.array.ones(tuple(), dtype=int, chunks=tuple())
elif index is None:
labels = (labels > 0).astype(int)
index = dask.array.ones(tuple(), dtype=int, chunks=tuple())
labels = _compat._asarray(labels)
index = _compat._asarray(index)
if index.ndim > 1:
warnings.warn(
"Having index with dimensionality greater than 1 is undefined.",
FutureWarning
)
if input.shape != labels.shape:
raise ValueError("The input and labels arrays must be the same shape.")
return (input, labels
```
<Overlap Ratio: 0.9847009735744089>

---

--- 204 --
Question ID: e43b3a1fe43de5f1d5d6e3356c571467f39ad036_1
Original Code:
```
def tick():
    input_noise = simulation_config["input_noise"]
    energy_input = simulation_config["energy_input"] + \
        random.randint(-input_noise, input_noise)

    print("Energy outcome: " + str(energy_input) + "kWh")
    if energy_input > 0:
        sell_energy(energy_input)
    elif energy_input < 0:
        consume_energy(-energy_input)
```


Overlapping Code:
```
ise = simulation_config["input_noise"]
energy_input = simulation_config["energy_input"] + \
random.randint(-input_noise, input_noise)
print("Energy outcome: " + str(energy_input) + "kWh")
if energy_input > 0:
sell_energy(energy_input)
elif energy_inp
```
<Overlap Ratio: 0.8143322475570033>

---

--- 205 --
Question ID: 64e670dd99f55537c86b06007c5a54c613560b4f_12
Original Code:
```
def to_safe_annotation_key(key):
    """Xray doesn't like keys that have punctuations
    and likes to silently drop things."""
    safe_key = key.translate(str.maketrans("", "", string.punctuation))
    return safe_key
```


Overlapping Code:
```
ey(key):
"""Xray doesn't like keys that have punctuations
and likes to silently drop things."""
safe_key = key.translate(str.maketrans("", "", string.punctuation))
return 
```
<Overlap Ratio: 0.8423645320197044>

---

--- 206 --
Question ID: 5b2e1ce6d66d773df80f4ca163042513cf4342b7_0
Original Code:
```
@aiohttp_jinja2.template('index.html')
async def root(request):
    print(request)
    agent = request.app['agent']
    agent.offer_endpoint = request.url.scheme + '://' + request.url.host
    print(agent.offer_endpoint)
    agent.endpoint = request.url.scheme + '://' + request.url.host
    if request.url.port is not None:
        agent.endpoint += ':' + str(request.url.port) + '/indy'
        agent.offer_endpoint += ':' + str(request.url.port) + '/offer'
    else:
        agent.endpoint += '/indy'
        agent.offer_endpoint += '/offer'
    return {'ui_token': agent.ui_token}
```


Overlapping Code:
```
aiohttp_jinja2.template('index.html')
async def root(request):
print(request)
agent = request.app['agent']
agent.offer_endpoint = request.url.scheme + '://' + request.url.host
print(agent.offer_endpoint)
agent.endpoint = request.url.scheme + '://' + request.url.host
if request.url.port is not None:
agent.endpoint += ':' + str(request.url.port) + '/indy'
agent.offer_endpoint += ':' + str(request.url.port) + '/offer'
else:
agent.endpoint += '/indy'
agent.offer_endpoint += '/offer'
return {'ui_token': ag
```
<Overlap Ratio: 0.9730769230769231>

---

--- 207 --
Question ID: 04985fa76afb07ef54a2fc2d1b68301480b22e88_6
Original Code:
```
def api_get_doc_by_hl_id(request):
    response = {}
    context = {}
    forum = Forum.objects.get(id=request.session['forum_id'])
    # retrieve docs in a folder
    hl_id = request.REQUEST.get("hl_id")
    hl = Highlight.objects.get(id = hl_id)
    sec = DocSection.objects.get(id=hl.context.id)
    doc = sec.doc
    context['doc_name'] = doc.title
    context['sections'] = []
    context['doc_id'] = doc.id
    ordered_sections = doc.sections.filter(order__isnull=False).order_by('order')
    for section in ordered_sections:
        context['sections'].append(section.getAttr(forum))
    unordered_sections = doc.sections.filter(order__isnull=True).order_by('updated_at')
    for section in unordered_sections:
        context['sections'].append(section.getAttr(forum))
    response['workbench_document'] = render_to_string("workbench-document.html", context)
    response['doc_id'] = doc.id
    return HttpResponse(json.dumps(response), mimetype='application/json')
```


Overlapping Code:
```
_get_doc_by_hl_id(request):
response = {}
context = {}
forum = Forum.objects.get(id=request.session['forum_id'])
# retrieve docs in a folder
hl_id = request.REQUEST.get("hl_id")
hl = Highlight.objects.get(id = hl_id)
sec = DocSection.objects.get(id=hl.context.id)
doc = sec.doc
context['doc_name'] = doc.title
context['sections'] = []
context['doc_id'] = doc.id
ordered_sections = doc.sections.filter(order__isnull=False).order_by('order')
for section in ordered_sections:
context['sections'].append(section.getAttr(forum))
unordered_sections = doc.sections.filter(order__isnull=True).order_by('updated_at')
for section in unordered_sections:
context['sections'].append(section.getAttr(forum))
response['workbench_document'] = render_to_string("workbench-document.html", context)
response['doc_id'] = doc.id
return HttpResponse(json.dumps(response), mimetype='application/json')
```
<Overlap Ratio: 0.992090395480226>

---

--- 208 --
Question ID: 297acdd5259eadc3a4d3639a0e498a4f05e5c74a_0
Original Code:
```
def mypca(X):
  """  Principal Component Analysis
    input: X, matrix with training data stored as flattened arrays in rows
    return: projection matrix (with important dimensions first), variance
    and mean."""

  # get dimensions
  num_data,dim = X.shape

  # center data
  mean_X = X.mean(axis=0)
  B = X - mean_X

  
  S = dot(B,B.T)/3# covariance matrix
  print("S")
  print(S)
  e,EV = linalg.eigh(S) # eigenvalues and eigenvectors
  e=e[::-1]
  print("e")
  print(e)
  EV=fliplr(EV)
  print("EV")
  print(EV)
  y0 = dot(EV.T,B) # this is the compact trick
  
  S = sqrt(e)
  print("S")
  print(S)
  

  # return the projection matrix, the variance and the mean
  return y0,mean_X
```


Overlapping Code:
```
a(X):
""" Principal Component Analysis
input: X, matrix with training data stored as flattened arrays in rows
return: projection matrix (with important dimensions first), variance
and mean."""
# get dimensions
num_data,dim = X.shape
# center data
mean_X = X.mean(axis=0)
B = X - mean_X

S = dot(B,B.T)/3# covariance matrix
print("S")
print(S)
e,EV = linalg.eigh(S) # eigenvalues and eigenvectors
e=e[::-1]
print("e")
print(e)
EV=fliplr(EV)
print("EV")
print(EV)
y0 = dot(EV.T,B) # this is the compact trick

S = sqrt(e)
print("S")
print(S)

# return the projection matrix, the variance and the me
```
<Overlap Ratio: 0.956661316211878>

---

--- 209 --
Question ID: fa4628fb553045029e402bf1c9c87b1266a99438_7
Original Code:
```
def submitRequests(client, wallet, op):
    req = wallet.signOp(op)
    # TODO: This looks boilerplate
    wallet.pendRequest(req)
    reqs = wallet.preparePending()
    return client.submitReqs(*reqs)[0]
```


Overlapping Code:
```
 submitRequests(client, wallet, op):
req = wallet.signOp(op)
# TODO: This looks boilerplate
wallet.pendRequest(req)
reqs = wallet.preparePending()
return client.submit
```
<Overlap Ratio: 0.907608695652174>

---

--- 210 --
Question ID: 538eedad8191a365da10e9b7023b9960d180637a_3
Original Code:
```
def __update_template_path():
    # Sometimes, when caching templates bottle doesn't clear the faulty
    # templates and the error persists even upon restarting the app.
    # The solution is to clear the templates explicitly with this statement:
    TEMPLATES.clear()

    for m in registered_methods:
        method_path = unicode('./{0}/{1}/'.format(config.FP_SUBDIR, m.subdir))
        if method_path not in TEMPLATE_PATH:
            TEMPLATE_PATH.insert(0, method_path)

    logger.info('updated TEMPLATE_PATH')
```


Overlapping Code:
```
h():
# Sometimes, when caching templates bottle doesn't clear the faulty
# templates and the error persists even upon restarting the app.
# The solution is to clear the templates explicitly with this statement:
TEMPLATES.clear()
for m in registered_methods:
method_path = unicode('./{0}/{1}/'.format(config.FP_SUBDIR, m.subdir))
if method_path not in TEMPLATE_PATH:
TEMPLATE_PATH.insert(0, method_pat
```
<Overlap Ratio: 0.8620689655172413>

---

--- 211 --
Question ID: 345df7bf91ff226dd9bde7abb29abec23aeb04fc_1
Original Code:
```
def vars_extractor(node):
    def selectVarsEmptyClass(source_ref):
        return makeExpressionBuiltinLocals(
            provider   = node.getParentVariableProvider(),
            source_ref = source_ref
        )

    return BuiltinParameterSpecs.extractBuiltinArgs(
        node                = node,
        builtin_class       = ExpressionBuiltinVars,
        builtin_spec        = BuiltinParameterSpecs.builtin_vars_spec,
        empty_special_class = selectVarsEmptyClass
    )
```


Overlapping Code:
```
(node):
def selectVarsEmptyClass(source_ref):
return makeExpressionBuiltinLocals(
provider = node.getParentVariableProvider(),
source_ref = source_ref
)
return BuiltinParameterSpecs.extractBuiltinArgs(
node = node,
builtin_class = ExpressionBuiltinVars,
builtin_spec = BuiltinParameterSpecs.builtin_vars_spec,
empty_special_class = selectVarsEmptyClass
)
```
<Overlap Ratio: 0.9516129032258065>

---

--- 212 --
Question ID: 4ecb5eff00676edae80b7e1b8c995053e5236cf4_4
Original Code:
```
def _write_header(path,H):
    f=open(path,"wb")
    try:
        _write_int32(f,H.dt_code)
        _write_int32(f,H.num_bytes_per_entry)
        if H.uses64bitdims:
            _write_int32(f,-H.num_dims)
            for j in range(0,H.num_dims):
                _write_int64(f,H.dims[j])
        else:
            _write_int32(f,H.num_dims)
            for j in range(0,H.num_dims):
                _write_int32(f,H.dims[j])
        f.close()
        return True
    except Exception as e: # catch *all* exceptions
        print (e)
        f.close()
        return False
```


Overlapping Code:
```
y:
_write_int32(f,H.dt_code)
_write_int32(f,H.num_bytes_per_entry)
if H.uses64bitdims:
_write_int32(f,-H.num_dims)
for j in range(0,H.num_dims):
_write_int64(f,H.dims[j])
else:
_write_int32(f,H.num_dims)
for j in range(0,H.num_dims):
_write_int32(f,H.dims[j])
f.close()
return True
except Exception as e: # catch *all* exceptions
print (e)
f.close()
return Fa
```
<Overlap Ratio: 0.8777506112469438>

---

--- 213 --
Question ID: 7176d48aa3e455abf69479e0f3bb1398c4b23650_77
Original Code:
```
def p_more_sub_struct(p):
  '''more_sub_struct : more_sub_struct sub_struct_operator sub_struct_body
                     | empty'''
  pass
```


Overlapping Code:
```
re_sub_struct(p):
'''more_sub_struct : more_sub_struct sub_struct_operator sub_struct_body
| empty''
```
<Overlap Ratio: 0.8771929824561403>

---

--- 214 --
Question ID: 84f7c24f7cafb3a118bd48ccf37435e4063f8d79_1
Original Code:
```
def connect_db():
    """Connects to the specific database."""
    # TODO: Configuration
    rv = sqlite3.connect('the.db')
    rv.row_factory = sqlite3.Row
    return rv
```


Overlapping Code:
```
def connect_db():
"""Connects to the specific database."""
# TODO: Configuration
rv = sqlite3.connect('the.db')
rv.row_factory 
```
<Overlap Ratio: 0.8466666666666667>

---

--- 215 --
Question ID: 651f9d71ce14d4ef7bc0720374e523952f4d1d9c_2
Original Code:
```
def get_server_id_by_partial_name(body_response_server_list, partial_server_name):
    """
    Looks for server Id in the server list by server name
    :param body_response_server_list: Parsed response (python dic). List of deployed instances
    :param partial_name: The name of the server to find (or a substring)
    :return: Server ID
    """
    server_id = None
    for server in body_response_server_list['servers']:
        if partial_server_name in server['name']:
            server_id = server['id']
            break

    return server_id
```


Overlapping Code:
```
er_id_by_partial_name(body_response_server_list, partial_server_name):
"""
Looks for server Id in the server list by server name
:param body_response_server_list: Parsed response (python dic). List of deployed instances
:param partial_name: The name of the server to find (or a substring)
:return: Server ID
"""
server_id = None
for server in body_response_server_list['servers']:
if partial_server_name in server['name']:
server_id = server['id']
br
```
<Overlap Ratio: 0.9336099585062241>

---

--- 216 --
Question ID: 8875c72c11f22dea78b588ad39cb3064d09651fa_4
Original Code:
```
def test_add_label(session):
    #Add a node with type disease
    create_node(session)
    #Now, have the same identifier, but a subclass
    node = KNode(TEST_ID, node_types.GENETIC_CONDITION)
    #export, and pull the node
    export_node(node,session)
    rounder = get_node(TEST_ID,session)
    assert len(rounder.labels) == 2
    assert node_types.DISEASE in rounder.labels
    assert node_types.GENETIC_CONDITION in rounder.labels
```


Overlapping Code:
```
d_label(session):
#Add a node with type disease
create_node(session)
#Now, have the same identifier, but a subclass
node = KNode(TEST_ID, node_types.GENETIC_CONDITION)
#export, and pull the node
export_node(node,session)
rounder = get_node(TEST_ID,session)
assert len(rounder.labels) == 2
assert node_types.DISEASE in rounder.labels
assert node_types.GENETIC_CONDITION in roun
```
<Overlap Ratio: 0.947103274559194>

---

--- 217 --
Question ID: 0ac5ccb450a98c3002fb86acb68bef39e0d57096_0
Original Code:
```
def cache():
    """Tests that a value can be retrieved from cache.

    :returns: Dictionary indicating results. {'status': True}
    :rtype: dict
    """
    key = 'test_cache_key'
    val = 'test_cache_val'
    result = dict(status=None)
    try:
        django_cache.add(key, val, 3600)
        cache_val = django_cache.get(key)
        if cache_val == val:
            result['status'] = True
    except Exception as e:
        result['status'] = False
    return result
```


Overlapping Code:
```
"""Tests that a value can be retrieved from cache.
:returns: Dictionary indicating results. {'status': True}
:rtype: dict
"""
key = 'test_cache_key'
val = 'test_cache_val'
result = dict(status=None)
try:
django_cache.add(key, val, 3600)
cache_val = django_cache.get(key)
if cache_val == val:
result['status'] = True
except Exception as e:
result['status'] = False
re
```
<Overlap Ratio: 0.9384615384615385>

---

--- 218 --
Question ID: 1361759f484b66b307f8c5a3d31a2b5a9c67f540_2
Original Code:
```
def draw_lines(img, lines, color=[255, 0, 0], thickness=10):
	"""
	NOTE: this is the function you might want to use as a starting point once you want to
	average/extrapolate the line segments you detect to map out the full
	extent of the lane (going from the result shown in raw-lines-example.mp4
	to that shown in P1_example.mp4).

	Think about things like separating line segments by their
	slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left
	line vs. the right line.  Then, you can average the position of each of
	the lines and extrapolate to the top and bottom of the lane.

	This function draws `lines` with `color` and `thickness`.
	Lines are drawn on the image inplace (mutates the image).
	If you want to make the lines semi-transparent, think about combining
	this function with the weighted_img() function below
	"""
	# In case of error, don't draw the line(s)
	if lines is None:
		return
	if len(lines) == 0:
		return
	draw_right = True
	draw_left = True

	# Find slopes of all lines
	# But only care about lines where abs(slope) > slope_threshold
	slope_threshold = 0.5
	slopes = []
	new_lines = []
	for line in lines:
		x1, y1, x2, y2 = line[0]  # line = [[x1, y1, x2, y2]]

		# Calculate slope
		if x2 - x1 == 0.:  # corner case, avoiding division by 0
			slope = 999.  # practically infinite slope
		else:
			slope = (y2 - y1) / (x2 - x1)

		# Filter lines based on slope
		if abs(slope) > slope_threshold:
			slopes.append(slope)
			new_lines.append(line)

	lines = new_lines

	# Split lines into right_lines and left_lines, representing the right and left lane lines
	# Right/left lane lines must have positive/negative slope, and be on the right/left half of the image
	right_lines = []
	left_lines = []
	for i, line in enumerate(lines):
		x1, y1, x2, y2 = line[0]
		img_x_center = img.shape[1] / 2  # x coordinate of center of image
		if slopes[i] > 0 and x1 > img_x_center and x2 > img_x_center:
			right_lines.append(line)
		elif slopes[i] < 0 and x1 < img_x_center and x2 < img_x_center:
			left_lines.append(line)

	# Run linear regression to find best fit line for right and left lane lines
	# Right lane lines
	right_lines_x = []
	right_lines_y = []

	for line in right_lines:
		x1, y1, x2, y2 = line[0]

		right_lines_x.append(x1)
		right_lines_x.append(x2)

		right_lines_y.append(y1)
		right_lines_y.append(y2)

	if len(right_lines_x) > 0:
		right_m, right_b = np.polyfit(right_lines_x, right_lines_y, 1)  # y = m*x + b
	else:
		right_m, right_b = 1, 1
		draw_right = False

	# Left lane lines
	left_lines_x = []
	left_lines_y = []

	for line in left_lines:
		x1, y1, x2, y2 = line[0]

		left_lines_x.append(x1)
		left_lines_x.append(x2)

		left_lines_y.append(y1)
		left_lines_y.append(y2)

	if len(left_lines_x) > 0:
		left_m, left_b = np.polyfit(left_lines_x, left_lines_y, 1)  # y = m*x + b
	else:
		left_m, left_b = 1, 1
		draw_left = False

	# Find 2 end points for right and left lines, used for drawing the line
	# y = m*x + b --> x = (y - b)/m
	y1 = img.shape[0]
	y2 = img.shape[0] * (1 - trap_height)

	right_x1 = (y1 - right_b) / right_m
	right_x2 = (y2 - right_b) / right_m

	left_x1 = (y1 - left_b) / left_m
	left_x2 = (y2 - left_b) / left_m

	# Convert calculated end points from float to int
	y1 = int(y1)
	y2 = int(y2)
	right_x1 = int(right_x1)
	right_x2 = int(right_x2)
	left_x1 = int(left_x1)
	left_x2 = int(left_x2)
  
	# Draw the right and left lines on image
	# if draw_right:
	# 	cv2.line(img, (right_x1, y1), (right_x2, y2), color, thickness)
	# if draw_left:
	# 	cv2.line(img, (left_x1, y1), (left_x2, y2), color, thickness)
	
	line_right = (right_x1, y1, right_x2, y2)
	line_left = (left_x1, y1, left_x2, y2)
	return [line_right, line_left]
```


Overlapping Code:
```
def draw_lines(img, lines, color=[255, 0, 0], thickness=10):
"""
NOTE: this is the function you might want to use as a starting point once you want to
average/extrapolate the line segments you detect to map out the full
extent of the lane (going from the result shown in raw-lines-example.mp4
to that shown in P1_example.mp4).
Think about things like separating line segments by their
slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left
line vs. the right line. Then, you can average the position of each of
the lines and extrapolate to the top and bottom of the lane.
This function draws `lines` with `color` and `thickness`.
Lines are drawn on the image inplace (mutates the image).
If you want to make the lines semi-transparent, think about combining
this function with the weighted_img() function below
"""
# In case of error, don't draw the line(s)
if lines is None:
return
if len(lines) == 0:
return
draw_right = True
draw_left = True
# Find slopes of all lines
# But only care about lines where abs(slope) > slope_threshold
slope_threshold = 0.5
slopes = []
new_lines = []
for line in lines:
x1, y1, x2, y2 = line[0] # line = [[x1, y1, x2, y2]]
# Calculate slope
if x2 - x1 == 0.: # corner case, avoiding division by 0
slope = 999. # practically infinite slope
else:
slope = (y2 - y1) / (x2 - x1)
# Filter lines based on slope
if abs(slope) > slope_threshold:
slopes.append(slope)
new_lines.append(line)
lines = new_lines
# Split lines into right_lines and left_lines, representing the right and left lane lines
# Right/left lane lines must have positive/negative slope, and be on the right/left half of the image
right_lines = []
left_lines = []
for i, line in enumerate(lines):
x1, y1, x2, y2 = line[0]
img_x_center = img.shape[1] / 2 # x coordinate of center of image
if slopes[i] > 0 and x1 > img_x_center and x2 > img_x_center:
right_lines.append(line)
elif slopes[i] < 0 and x1 < img_x_center and x2 < img_x_center:
left_lines.append(line)
# Run linear regression to find best fit line for right and left lane lines
# Right lane lines
right_lines_x = []
right_lines_y = []
for line in right_lines:
x1, y1, x2, y2 = line[0]
right_lines_x.append(x1)
right_lines_x.append(x2)
right_lines_y.append(y1)
right_lines_y.append(y2)
if len(right_lines_x) > 0:
right_m, right_b = np.polyfit(right_lines_x, right_lines_y, 1) # y = m*x + b
else:
right_m, right_b =
```
<Overlap Ratio: 0.998742665549036>

---

--- 219 --
Question ID: dbf3f28def60bd4f9849e7b28bedaee9ac70ae92_2
Original Code:
```
def create_custom_exception(exc_type, exc_val, exc_tb, strategy_filename):
    try:
        msg = str(exc_val)
    except:
        msg = ""

    error = CustomError()
    error.set_msg(msg)
    error.set_exc(exc_type, exc_val, exc_tb)

    import linecache

    filename = ''
    tb = exc_tb
    while tb:
        co = tb.tb_frame.f_code
        filename = co.co_filename
        if filename != strategy_filename:
            tb = tb.tb_next
            continue
        lineno = tb.tb_lineno
        func_name = co.co_name
        code = linecache.getline(filename, lineno).strip()
        error.add_stack_info(filename, lineno, func_name, code, tb.tb_frame.f_locals)
        tb = tb.tb_next

    if filename == strategy_filename:
        error.error_type = EXC_TYPE.USER_EXC

    user_exc = CustomException(error)
    return user_exc
```


Overlapping Code:
```
reate_custom_exception(exc_type, exc_val, exc_tb, strategy_filename):
try:
msg = str(exc_val)
except:
msg = ""
error = CustomError()
error.set_msg(msg)
error.set_exc(exc_type, exc_val, exc_tb)
import linecache
filename = ''
tb = exc_tb
while tb:
co = tb.tb_frame.f_code
filename = co.co_filename
if filename != strategy_filename:
tb = tb.tb_next
continue
lineno = tb.tb_lineno
func_name = co.co_name
code = linecache.getline(filename, lineno).strip()
error.add_stack_info(filename, lineno, func_name, code, tb.tb_frame.f_locals)
tb = tb.tb_next
if filename == strategy_filename:
error.error_type = EXC_TYPE.USER_EXC
user_exc = CustomException(error)
return user
```
<Overlap Ratio: 0.9865671641791045>

---

--- 220 --
Question ID: 670556a64036e6dc9b05da2a7fa0dd9dd60c6184_2
Original Code:
```
def launch(env, logdir, n_epochs, num_cpu, seed, replay_strategy, policy_save_interval, clip_return,
           override_params=None, save_policies=True):
    """
    launch training with mpi

    :param env: (str) environment ID
    :param logdir: (str) the log directory
    :param n_epochs: (int) the number of training epochs
    :param num_cpu: (int) the number of CPUs to run on
    :param seed: (int) the initial random seed
    :param replay_strategy: (str) the type of replay strategy ('future' or 'none')
    :param policy_save_interval: (int) the interval with which policy pickles are saved.
        If set to 0, only the best and latest policy will be pickled.
    :param clip_return: (float): clip returns to be in [-clip_return, clip_return]
    :param override_params: (dict) override any parameter for training
    :param save_policies: (bool) whether or not to save the policies
    """

    if override_params is None:
        override_params = {}
    # Fork for multi-CPU MPI implementation.
    if num_cpu > 1:
        try:
            whoami = mpi_fork(num_cpu, ['--bind-to', 'core'])
        except CalledProcessError:
            # fancy version of mpi call failed, try simple version
            whoami = mpi_fork(num_cpu)

        if whoami == 'parent':
            sys.exit(0)
        tf_util.single_threaded_session().__enter__()
    rank = MPI.COMM_WORLD.Get_rank()

    # Configure logging
    if rank == 0:
        if logdir or logger.get_dir() is None:
            logger.configure(folder=logdir)
    else:
        logger.configure()
    logdir = logger.get_dir()
    assert logdir is not None
    os.makedirs(logdir, exist_ok=True)

    # Seed everything.
    rank_seed = seed + 1000000 * rank
    set_global_seeds(rank_seed)

    # Prepare params.
    params = config.DEFAULT_PARAMS
    params['env_name'] = env
    params['replay_strategy'] = replay_strategy
    if env in config.DEFAULT_ENV_PARAMS:
        params.update(config.DEFAULT_ENV_PARAMS[env])  # merge env-specific parameters in
    params.update(**override_params)  # makes it possible to override any parameter
    with open(os.path.join(logger.get_dir(), 'params.json'), 'w') as file_handler:
        json.dump(params, file_handler)
    params = config.prepare_params(params)
    config.log_params(params, logger_input=logger)

    if num_cpu == 1:
        logger.warn()
        logger.warn('*** Warning ***')
        logger.warn(
            'You are running HER with just a single MPI worker. This will work, but the ' +
            'experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) ' +
            'were obtained with --num_cpu 19. This makes a significant difference and if you ' +
            'are looking to reproduce those results, be aware of this. Please also refer to ' +
            'https://github.com/openai/stable_baselines/issues/314 for further details.')
        logger.warn('****************')
        logger.warn()

    dims = config.configure_dims(params)
    policy = config.configure_ddpg(dims=dims, params=params, clip_return=clip_return)

    rollout_params = {
        'exploit': False,
        'use_target_net': False,
        # 'use_demo_states': True,
        'compute_q': False,
        'time_horizon': params['time_horizon'],
    }

    eval_params = {
        'exploit': True,
        'use_target_net': params['test_with_polyak'],
        # 'use_demo_states': False,
        'compute_q': True,
        'time_horizon': params['time_horizon'],
    }

    for name in ['time_horizon', 'rollout_batch_size', 'noise_eps', 'random_eps']:
        rollout_params[name] = params[name]
        eval_params[name] = params[name]

    rollout_worker = RolloutWorker(params['make_env'], policy, dims, logger, **rollout_params)
    rollout_worker.seed(rank_seed)

    evaluator = RolloutWorker(params['make_env'], policy, dims, logger, **eval_params)
    evaluator.seed(rank_seed)

    train(
        policy=policy, rollout_worker=rollout_worker,
        evaluator=evaluator, n_epochs=n_epochs, n_test_rollouts=params['n_test_rollouts'],
        n_cycles=params['n_cycles'], n_batches=params['n_batches'],
        policy_save_interval=policy_save_interval, save_policies=save_policies)
```


Overlapping Code:
```
, logdir, n_epochs, num_cpu, seed, replay_strategy, policy_save_interval, clip_return,
override_params=None, save_policies=True):
"""
launch training with mpi
:param env: (str) environment ID
:param logdir: (str) the log directory
:param n_epochs: (int) the number of training epochs
:param num_cpu: (int) the number of CPUs to run on
:param seed: (int) the initial random seed
:param replay_strategy: (str) the type of replay strategy ('future' or 'none')
:param policy_save_interval: (int) the interval with which policy pickles are saved.
If set to 0, only the best and latest policy will be pickled.
:param clip_return: (float): clip returns to be in [-clip_return, clip_return]
:param override_params: (dict) override any parameter for training
:param save_policies: (bool) whether or not to save the policies
"""
if override_params is None:
override_params = {}
# Fork for multi-CPU MPI implementation.
if num_cpu > 1:
try:
whoami = mpi_fork(num_cpu, ['--bind-to', 'core'])
except CalledProcessError:
# fancy version of mpi call failed, try simple version
whoami = mpi_fork(num_cpu)
if whoami == 'parent':
sys.exit(0)
tf_util.single_threaded_session().__enter__()
rank = MPI.COMM_WORLD.Get_rank()
# Configure logging
if rank == 0:
if logdir or logger.get_dir() is None:
logger.configure(folder=logdir)
else:
logger.configure()
logdir = logger.get_dir()
assert logdir is not None
os.makedirs(logdir, exist_ok=True)
# Seed everything.
rank_seed = seed + 1000000 * rank
set_global_seeds(rank_seed)
# Prepare params.
params = config.DEFAULT_PARAMS
params['env_name'] = env
params['replay_strategy'] = replay_strategy
if env in config.DEFAULT_ENV_PARAMS:
params.update(config.DEFAULT_ENV_PARAMS[env]) # merge env-specific parameters in
params.update(**override_params) # makes it possible to override any parameter
with open(os.path.join(logger.get_dir(), 'params.json'), 'w') as file_handler:
json.dump(params, file_handler)
params = config.prepare_params(params)
config.log_params(params, logger_input=logger)
if num_cpu == 1:
logger.warn()
logger.warn('*** Warning ***')
logger.warn(
'You are running HER with just a single MPI worker. 
```
<Overlap Ratio: 0.9916589434661723>

---

--- 221 --
Question ID: 6fea3de05c7bf763b51e5261c176aa7945155989_0
Original Code:
```
def N(m, L):
    if (m, L) in cache.keys():
        return cache[(m, L)]
    else:
        cache[(m, L)] = _N(m, L)
        return cache[(m, L)]
```


Overlapping Code:
```
in cache.keys():
return cache[(m, L)]
else:
cache[(m, L)] = _N(m, L)
r
```
<Overlap Ratio: 0.625>

---

--- 222 --
Question ID: 9aaf68766526eab088a45acee5974261d7ebd3aa_0
Original Code:
```
def test_send_reminder_emails(reminder_email_subscriber_factory):
    sub = reminder_email_subscriber_factory()

    command = Command()
    sub.user.primary_email.email = "test@knowme.works"
    sent = command.send_reminder_email(sub)

    assert sent
```


Overlapping Code:
```
d_reminder_emails(reminder_email_subscriber_factory):
sub = reminder_email_subscriber_factory()
comm
```
<Overlap Ratio: 0.43478260869565216>

---

--- 223 --
Question ID: 4f0a291cfbfe239a46d45fb7bffcee4e0979aaea_5
Original Code:
```
def prep_H(conn):
    q = Qubit(conn)
    q.H()
    return q
```


Overlapping Code:
```

```
<Overlap Ratio: 0.0>

---

--- 224 --
Question ID: 792a06433102075502db4b1733b021f572e9080b_0
Original Code:
```
def main():
    N = 100000

    xy = rand(N, 2)

    r = xy[:,0] ** 2 + xy[:,1]**2

    n = sum(r < 1)

    pi_est = 4 * n / float(N)

    print(pi_est)
```


Overlapping Code:
```
00
xy = rand(N, 2)
r = xy[:,0] ** 2 + xy[:,1]**2
n = sum(r < 1)
pi_est = 4 * n / float(N)
print(pi_e
```
<Overlap Ratio: 0.8130081300813008>

---

--- 225 --
Question ID: 229479105143b94f443c7ad689bedda1c1ec27e1_2
Original Code:
```
def powerlaw_sequence(n,exponent=2.0):
    """
    Return sample sequence of length n from a power law distribution.
    """
    return [random.paretovariate(exponent-1) for i in range(n)]
```


Overlapping Code:
```
w_sequence(n,exponent=2.0):
"""
Return sample sequence of length n from a power law distribution.
"""
return [random.paretovariate(exponent-1) for i in range(
```
<Overlap Ratio: 0.9186046511627907>

---

--- 226 --
Question ID: 38bf50b1c1ad069611c020e0df44711105596d91_3
Original Code:
```
def check_comment_spacing(self, lines):
    comment_line = self.current_line_num
    prev_line = comment_line - 1

    if self.current_line_num == 0 or (lines[comment_line] != '/**/' and not re.search(r'^\s*//', lines[comment_line])):
        return

    # Check that there is a blank link above a comment.
    if (lines[prev_line] != '/**/' and not re.search(r'^\s*//', lines[prev_line]) and \
        not re.search(r'[\}\{\:]\s*$', lines[prev_line]) and \
        (not lines[prev_line].isspace() and lines[prev_line])):
            # Add 1 to line number because indexes start with 0
            self.add_error("MISSING_COMMENT_SEPERATION", line = comment_line + 1)

    # Check if there is a blank line below a comment.
    next_line = comment_line + 1
    if (len(lines) < next_line and (lines[next_line].isspace() or not lines[next_line])):
        # Make sure this is not the top comment
        while prev_line > 0 and (lines[prev_line] == '/**/' or re.search(r'^\s*//', lines[prev_line])):
            prev_line = prev_line - 1
            #print(prev_line, ": ", lines[prev_line])

        if prev_line > 0:
            self.add_error("EXTRA_COMMENT_SEPERATION", line = comment_line + 1)
```


Overlapping Code:
```
nes):
comment_line = self.current_line_num
prev_line = comment_line - 1
if self.current_line_num == 0 or (lines[comment_line] != '/**/' and not re.search(r'^\s*//', lines[comment_line])):
return
# Check that there is a blank link above a comment.
if (lines[prev_line] != '/**/' and not re.search(r'^\s*//', lines[prev_line]) and \
not re.search(r'[\}\{\:]\s*$', lines[prev_line]) and \
(not lines[prev_line].isspace() and lines[prev_line])):
# Add 1 to line number because indexes start with 0
self.add_error("MISSING_COMMENT_SEPERATION", line = comment_line + 1)
# Check if there is a blank line below a comment.
next_line = comment_line + 1
if (len(lines) < next_line and (lines[next_line].isspace() or not lines[next_line])):
# Make sure this is not the top comment
while prev_line > 0 and (lines[prev_line] == '/**/' or re.search(r'^\s*//', lines[prev_line])):
prev_line = prev_line - 1
#print(prev_line, ": ", lines[prev_line])
if prev_line > 0:
self.add_error("EXTRA_COMMENT_SEPERATION", line =
```
<Overlap Ratio: 0.9505703422053232>

---

--- 227 --
Question ID: d1267f95c8d6024b1d0fdf76614c62ea7746645c_0
Original Code:
```
def test_linearizer_performs_topological_ordering(valid_graph, linearizer):
    ordering = linearizer.linearize(valid_graph)
    assert set(ordering) == set(valid_graph)
    for index, item in enumerate(ordering):
        assert valid_graph[item].parents <= set(ordering[:index])
```


Overlapping Code:
```
opological_ordering(valid_graph, linearizer):
ordering = linearizer.linearize(valid_graph)
assert set(ordering) == set(valid_graph)
for index, item in enumerate(ordering):
assert valid_graph[item].par
```
<Overlap Ratio: 0.7722007722007722>

---

--- 228 --
Question ID: a4ce892062d387b5973accb20a658592f680c02e_2
Original Code:
```
def test_read_one(address_source_params, one_address_result_session):
    source = DatabaseSource(**address_source_params)
    with patch('pyramid_oereb.core.adapter.DatabaseAdapter.get_session', return_value=one_address_result_session()):  # noqa: E501
        source.read(Parameter('xml'), 'teststreet', 4050, '99a')
        assert len(source.records) == 1
        assert isinstance(source.records[0], AddressRecord)
        assert source.records[0].street_name == 'teststreet'
        assert source.records[0].street_number == '99a'
        assert source.records[0].zip_code == 4050
        assert source.records[0].geom.coords[0] == (1.0, 1.0)
```


Overlapping Code:
```
rce_params, one_address_result_session):
source = DatabaseSource(**address_source_params)
with patch('pyramid_oereb.core.adapter.DatabaseAdapter.get_session', return_value=one_address_result_session()): # noqa: E501
source.read(Parameter('xml'), 'teststreet', 4050, '99a')
assert len(source.records) == 1
assert isinstance(source.records[0], AddressRecord)
assert source.records[0].street_name == 'teststreet'
assert source.records[0].street_number == '99a'
assert source.records[0].zip_code == 4050
assert source.records[0].geom.coords[0] == (1.0, 1
```
<Overlap Ratio: 0.9450171821305842>

---

--- 229 --
Question ID: 46a9281c563606af24a5b890ea416f878cedc5b9_280
Original Code:
```
@_f
@_p.types(None,_cs.GLfloat,_cs.GLfloat,_cs.GLfloat)
def glTranslatef(x,y,z):pass

```


Overlapping Code:
```
@_f
@_p.types(None,_cs.GLfloat,_cs.GLfloat,_cs.GLfloat)
def glTranslatef(x,y,z)
```
<Overlap Ratio: 0.9404761904761905>

---

--- 230 --
Question ID: bdc58343ec72b669720d01178a52386e3869bda8_0
Original Code:
```
def extract_evidence(clargs):
    # clargsinputFile = 'DATA-Licensed_test.json'

    sentences = extract_jD(clargs.input_file[0])

    # sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],
    # 			['this', 'is', 'the', 'second', 'sentence'],
    # 			['yet', 'another', 'sentence'],
    # 			['one', 'more', 'sentence'],
    # 			['and', 'the', 'final', 'sentence']]

    # train model
    model = Word2Vec(sentences, min_count=5, size=256)
    # fit a 2d PCA model to the vectors
    X = model[model.wv.vocab]
    pca = PCA(n_components=2)
    result = pca.fit_transform(X)
    # create a scatter plot of the projection
    pyplot.scatter(result[:, 0], result[:, 1])
    words = list(model.wv.vocab)
    for i, word in enumerate(words):
    	pyplot.annotate(word, xy=(result[i, 0], result[i, 1]))
    # pyplot.show()
    pyplot.savefig(os.path.join(os.getcwd(), log + "jDocEmb.jpeg"), bbox_inches='tight')

    model.save(log + 'model.bin')
```


Overlapping Code:
```
gs):
# clargsinputFile = 'DATA-Licensed_test.json'
sentences = extract_jD(clargs.input_file[0])
# sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],
# ['this', 'is', 'the', 'second', 'sentence'],
# ['yet', 'another', 'sentence'],
# ['one', 'more', 'sentence'],
# ['and', 'the', 'final', 'sentence']]
# train model
model = Word2Vec(sentences, min_count=5, size=256)
# fit a 2d PCA model to the vectors
X = model[model.wv.vocab]
pca = PCA(n_components=2)
result = pca.fit_transform(X)
# create a scatter plot of the projection
pyplot.scatter(result[:, 0], result[:, 1])
words = list(model.wv.vocab)
for i, word in enumerate(words):
pyplot.annotate(word, xy=(result[i, 0], result[i, 1]))
# pyplot.show()
pyplot.savefig(os.path.join(os.getcwd(), log + "jDocEmb.jpeg"), bbox_inche
```
<Overlap Ratio: 0.9248554913294798>

---

--- 231 --
Question ID: baabd0ec651cc7945911ca05e7322f11667b65bc_2
Original Code:
```
def test_expose():
    "Check that method locator ignores hidden and unmarked methods"
    class Service(object):
        @prpc.method
        async def exposed(self, ctx):
            'bold'

        async def hidden(self, ctx):
            'sneaky'

        async def _hidden_anyway(self):
            'ninja'

    # Without collect_all, only marked methods should be found
    #
    locator = prpc.TreeMethodLocator(Service(), collect_all=False)
    # Marked methods are always visible
    locator.resolve('exposed', prpc.CallType.UNARY, None)
    # Unmarked method is ignored without collect_all
    with pytest.raises(KeyError):
        locator.resolve('hidden', prpc.CallType.UNARY, None)
    # Methods with leading underscore are hidden unconditionally
    with pytest.raises(KeyError):
        locator.resolve('_hidden_anyway', prpc.CallType.UNARY, None)

    # With collect_all, undecorated methods should appear
    #
    locator = prpc.TreeMethodLocator(Service(), collect_all=True)
    # Marked methods are always visible
    locator.resolve('exposed', prpc.CallType.UNARY, None)
    # Unmarked method should now be visible
    locator.resolve('hidden', prpc.CallType.UNARY, None)
    # Methods with leading underscore are hidden unconditionally
    with pytest.raises(KeyError):
        locator.resolve('_hidden_anyway', prpc.CallType.UNARY, None)
```


Overlapping Code:
```
method locator ignores hidden and unmarked methods"
class Service(object):
@prpc.method
async def exposed(self, ctx):
'bold'
async def hidden(self, ctx):
'sneaky'
async def _hidden_anyway(self):
'ninja'
# Without collect_all, only marked methods should be found
#
locator = prpc.TreeMethodLocator(Service(), collect_all=False)
# Marked methods are always visible
locator.resolve('exposed', prpc.CallType.UNARY, None)
# Unmarked method is ignored without collect_all
with pytest.raises(KeyError):
locator.resolve('hidden', prpc.CallType.UNARY, None)
# Methods with leading underscore are hidden unconditionally
with pytest.raises(KeyError):
locator.resolve('_hidden_anyway', prpc.CallType.UNARY, None)
# With collect_all, undecorated methods should appear
#
locator = prpc.TreeMethodLocator(Service(), collect_all=True)
# Marked methods are always visible
locator.resolve('exposed', prpc.CallType.UNARY, None)
# Unmarked method should now be visible
locator.resolve('hidden', prpc.CallType.UNARY, None)
# Methods with leading underscore are hidden unconditionally
with pytest.raises(KeyError):
locator.resolve('_hidden_anyway', prpc.CallType.UNARY, None)
```
<Overlap Ratio: 0.9738175675675675>

---

--- 232 --
Question ID: 1a149f07f2eaafc186c0e87bc7ff51f7599bb1d3_1
Original Code:
```
def blink():
    while True:
        GPIO.output(23,GPIO.HIGH)
        time.sleep(0.5)
        GPIO.output(23,GPIO.LOW)
        time.sleep(0.5)
```


Overlapping Code:
```
k():
while True:
GPIO.output(23,GPIO.HIGH)
time.sl
```
<Overlap Ratio: 0.4672897196261682>

---

--- 233 --
Question ID: 8a813722604b7fd00175edf26752abe8321303f8_0
Original Code:
```
def includeme(config):
    """ Activate the switchboard; usually called via
    ``config.include('pyramid_switchboard')`` instead of being invoked
    directly. """
    settings = config.registry.settings
    # By setting nested to True, we're only looking for switchboard.* settings.
    configure(settings, nested=True)

    # Create the new application using the updated settings.
    switchboard = SwitchboardMiddleware(app)
    config.add_route('switchboard', '/_switchboard/*subpath')
    permission = settings.get('switchboard.permission', 'admin')
    config.add_view(wsgiapp2(switchboard), route_name='switchboard',
                    permission=permission)
```


Overlapping Code:
```
witchboard; usually called via
``config.include('pyramid_switchboard')`` instead of being invoked
directly. """
settings = config.registry.settings
# By setting nested to True, we're only looking for switchboard.* settings.
configure(settings, nested=True)
# Create the new application using the updated settings.
switchboard = SwitchboardMiddleware(app)
config.add_route('switchboard', '/_switchboard/*subpath')
permission = settings.get('switchboard.permission', 'admin')
config.add_view(wsgiapp2(switchboard), route_name='switchboard',
permission=
```
<Overlap Ratio: 0.9136212624584718>

---

--- 234 --
Question ID: 88cb11ce0d8029c1308187723c316cf051086fad_7
Original Code:
```
def toString(recipes):
    """Return a string representation of the recipes given in `recipes` in
    Recipe-compliant format."""
    recipeStrings = []

    for recipe in recipes:
        output = '] {}\n\n'.format(recipe[TITLE_KEY])

        for ingredient in recipe[INGREDIENTS_KEY]:
            output += '{} {} {}'.format(
                ingredient[INGREDIENT_AMOUNT_KEY],
                ingredient[INGREDIENT_UNIT_KEY],
                ingredient[INGREDIENT_NAME_KEY])

            if ingredient[INGREDIENT_PREPARATION_KEY]:
                output += ', {}'.format(ingredient[INGREDIENT_PREPARATION_KEY])

            if ingredient[INGREDIENT_NOTE_KEY]:
                output += ' ({})'.format(ingredient[INGREDIENT_NOTE_KEY])

            output += '\n'

        output += '\n'

        recipeStrings.append(output + '\n\n'.join(recipe[DIRECTIONS_KEY]))

    return '\n'.join(recipeStrings)
```


Overlapping Code:
```
ring representation of the recipes given in `recipes` in
Recipe-compliant format."""
recipeStrings = []
for recipe in recipes:
output = '] {}\n\n'.format(recipe[TITLE_KEY])
for ingredient in recipe[INGREDIENTS_KEY]:
output += '{} {} {}'.format(
ingredient[INGREDIENT_AMOUNT_KEY],
ingredient[INGREDIENT_UNIT_KEY],
ingredient[INGREDIENT_NAME_KEY])
if ingredient[INGREDIENT_PREPARATION_KEY]:
output += ', {}'.format(ingredient[INGREDIENT_PREPARATION_KEY])
if ingredient[INGREDIENT_NOTE_KEY]:
output += ' ({})'.format(ingredient[INGREDIENT_NOTE_KEY])
output += '\n'
output += '\n'
recipeStrings.append(output + '\n\n'.join(recipe[DIRECTIONS_KEY]))
return '\n'.join
```
<Overlap Ratio: 0.9269662921348315>

---

--- 235 --
Question ID: da9621b3c4280533739732c91ba549470843b191_2
Original Code:
```
def batch_iter(data, batch_size, num_epochs, shuffle=True):
    """
    Generates a batch iterator for a dataset.
    """
    data = np.array(data)
    data_size = len(data)
    num_batches_per_epoch = int((len(data)-1)/batch_size) + 1
    for epoch in range(num_epochs):
        # Shuffle the data at each epoch
        if shuffle:
            shuffle_indices = np.random.permutation(np.arange(data_size))
            shuffled_data = data[shuffle_indices]
        else:
            shuffled_data = data
        for batch_num in range(num_batches_per_epoch):
            start_index = batch_num * batch_size
            end_index = min((batch_num + 1) * batch_size, data_size)
            yield shuffled_data[start_index:end_index]
```


Overlapping Code:
```
def batch_iter(data, batch_size, num_epochs, shuffle=True):
"""
Generates a batch iterator for a dataset.
"""
data = np.array(data)
data_size = len(data)
num_batches_per_epoch = int((len(data)-1)/batch_size) + 1
for epoch in range(num_epochs):
# Shuffle the data at each epoch
if shuffle:
shuffle_indices = np.random.permutation(np.arange(data_size))
shuffled_data = data[shuffle_indices]
else:
shuffled_data = data
for batch_num in range(num_batches_per_epoch):
start_index = batch_num * batch_size
end_index = min((batch_num + 1) * batch_size, data_size)
yield shuffled_data[start_index:end_index]
```
<Overlap Ratio: 1.0>

---

--- 236 --
Question ID: 39b95e7b310ef689457c0d8b33b5bab26c2ec666_8
Original Code:
```
@bp.route("/edit_recipe", methods=["POST"])
@utils.gatekeeper()
def edit_recpie():
    """Edit a recipe that already exists in the data base."""
    try:
        data = request.form.to_dict()
        data = utils.deserialize(data)
        data["user"] = session.get("uid")  # Store info about which user edited last
        data["published"] = False if data.get("published", True).lower() == "false" else True
        url = utils.make_url(data["title"], data["id"])
        data["url"] = url
        image_file = request.files.get("image")
        if not image_file and not data["image"]:
            recipe = recipemodel.Recipe.get(recipemodel.Recipe.id == data["id"])
            if recipe.image:
                try:
                    utils.remove_file(utils.remove_file(os.path.join(current_app.config.get("IMAGE_PATH"), recipe.image)))
                except OSError:
                    current_app.logger.warning(traceback.format_exc())
        else:
            save_image(data, data["id"], image_file)
        recipemodel.edit_recipe(data["id"], data)
        tagmodel.add_tags(data, data["id"])
        return utils.success_response(msg="Recipe saved", url=url)

    except Exception as e:
        current_app.logger.error(traceback.format_exc())
        return utils.error_response(f"Failed to save data: {e}"), 400
```


Overlapping Code:
```
ecipe", methods=["POST"])
@utils.gatekeeper()
def edit_recpie():
"""Edit a recipe that already exists in the data base."""
try:
data = request.form.to_dict()
data = utils.deserialize(data)
data["user"] = session.get("uid") # Store info about which user edited last
data["published"] = False if data.get("published", True).lower() == "false" else True
url = utils.make_url(data["title"], data["id"])
data["url"] = url
image_file = request.files.get("image")
if not image_file and not data["image"]:
recipe = recipemodel.Recipe.get(recipemodel.Recipe.id == data["id"])
if recipe.image:
try:
utils.remove_file(utils.remove_file(os.path.join(current_app.config.get("IMAGE_PATH"), recipe.image)))
except OSError:
current_app.logger.warning(traceback.format_exc())
else:
save_image(data, data["id"], image_file)
recipemodel.edit_recipe(data["id"], data)
tagmodel.add_tags(data, data["id"])
return utils.success_response(msg="Recipe saved", url=url)
except Exception as e:
current_app.logger.error(traceback.format_exc())
return utils.error_response(f"Failed to save data:
```
<Overlap Ratio: 0.973491773308958>

---

--- 237 --
Question ID: 79a23532d268dd0df8b614168b35cdbf71f2bdef_2
Original Code:
```
def getVerticeMenorDistancia(distancia, flaggedVertices):
    
    verticesDistanciasNaoVisitados = []
    vetorIntermediario = []

    for i in range(len(flaggedVertices)):
        if (flaggedVertices[i] == False):
            vetorIntermediario.append(distancia[i])
            vetorIntermediario.append(i)
            verticesDistanciasNaoVisitados.append(vetorIntermediario)
            vetorIntermediario = []

    if (len(verticesDistanciasNaoVisitados)>0):
        menor = min(verticesDistanciasNaoVisitados)
        indiceMenor = menor[1]
        return indiceMenor
    else:
        return 99999
```


Overlapping Code:
```
rticeMenorDistancia(distancia, flaggedVertices):

verticesDistanciasNaoVisitados = []
vetorIntermediario = []
for i in range(len(flaggedVertices)):
if (flaggedVertices[i] == False):
vetorIntermediario.append(distancia[i])
vetorIntermediario.append(i)
verticesDistanciasNaoVisitados.append(vetorIntermediario)
vetorIntermediario = []
if (len(verticesDistanciasNaoVisitados)>0):
menor = min(verticesDistanciasNaoVisitados)
indiceMenor = menor[1]
return
```
<Overlap Ratio: 0.9183673469387755>

---

--- 238 --
Question ID: 867b6c69d51ee9e64e7ce6aa45c08165f2f9aeea_15
Original Code:
```
@auth.requires(auth.has_membership('Faculty') or auth.has_membership('Administrators'))
def GetImportPermissionStatus(account_id):
    ret = "True"
    auth = current.auth # Grab the current auth object
    
    if (auth.has_membership(role='Import', user_id=account_id) == True):
        ret = "True"
    else:
        ret = "False"
    
    return ret
```


Overlapping Code:
```
@auth.requires(auth.has_membership('Faculty') or auth.has_membership('Administrators'))
def GetImportPermissionStatus(account_id):
ret = "True"
auth = current.auth # Grab the current auth object

if (auth.has_membership(role='Import', user_id=account_id) == True):
ret = "True"
else:
ret = "False"

r
```
<Overlap Ratio: 0.970873786407767>

---

--- 239 --
Question ID: c2da72d079646a1532ba05583af48c016a830e2c_0
Original Code:
```
def genData(n, start=0, end=10):
    x = np.linspace(start, end, n)
    y = np.sin(10*x) - x*x
    return y
```


Overlapping Code:
```
=0, end=10):
x = np.linspace(start, end, n)
y = np.sin(10*x) - x*x

```
<Overlap Ratio: 0.7052631578947368>

---

--- 240 --
Question ID: f020e797c30e724301607bec0a8b0a39f790127d_0
Original Code:
```
def imread(path, grayscale = False):
  if (grayscale):
    return scipy.misc.imread(path, flatten = True).astype(np.float)
  else:
    return scipy.misc.imread(path).astype(np.float)
```


Overlapping Code:
```
read(path, grayscale = False):
if (grayscale):
return scipy.misc.imread(path, flatten = True).astype(np.float)
else:
return scipy.misc.imread(path).astype(np.float)
```
<Overlap Ratio: 0.9647058823529412>

---

--- 241 --
Question ID: 5d634ae89c89e67ba3cf126492fabe9b01acf62c_1
Original Code:
```
def test_resolve__default(info):
    with mock.patch.object(Child._meta.model._default_manager, 'get_queryset', return_value=[1, 2, 3]) as get_queryset:
        assert [1, 2, 3] == Parent.children.resolver(None, info(field_name='children'))
        get_queryset.assert_called_with()
```


Overlapping Code:
```
lt(info):
with mock.patch.object(Child._meta.model._default_manager, 'get_queryset', return_value=[1, 2, 3]) as get_queryset:
assert [1, 2, 3] == Parent.children.resolver(None, info(field_name='childr
```
<Overlap Ratio: 0.7633587786259542>

---

--- 242 --
Question ID: e5973cef9d44cbbe65c8ccb8276e1dbd664147e1_5
Original Code:
```
def norm_layer(data, out_dtype):
    """
        Compute data rescaled using the bounds of the output type.

        Args:
            data(array):        Dask Array of image data
            out_dtype(type):    type of the data to output

        Returns:
            Dask Array:         Adjusted harmonic mean projection
    """

    out = data.astype(float)
    out_dtype = numpy.dtype(out_dtype)

    data_min = data.min()
    data_max = data.max()

    out_nan = float("nan")
    out_min = float(0)
    out_max = float(1)
    if issubclass(out_dtype.type, numbers.Integral):
        out_dtype_info = numpy.iinfo(out_dtype.type)

        out_nan = float(0)
        out_min = float(out_dtype_info.min)
        out_max = float(out_dtype_info.max)

    scale = (out_max - out_min) / (data_max - data_min)

    out -= data_min
    out *= scale
    out += out_min

    out = dask.array.clip(out, out_min, out_max)

    out_isnan = dask.array.isnan(out)
    out_isinf = dask.array.isinf(out)
    out_sign = dask.array.sign(out)

    out[out_isinf & (out_sign == -1)] = out_min
    out[out_isinf & (out_sign == 1)] = out_max

    out[out_isnan] = out_nan

    out = out.astype(out_dtype)

    return out
```


Overlapping Code:
```
a, out_dtype):
"""
Compute data rescaled using the bounds of the output type.
Args:
data(array): Dask Array of image data
out_dtype(type): type of the data to output
Returns:
Dask Array: Adjusted harmonic mean projection
"""
out = data.astype(float)
out_dtype = numpy.dtype(out_dtype)
data_min = data.min()
data_max = data.max()
out_nan = float("nan")
out_min = float(0)
out_max = float(1)
if issubclass(out_dtype.type, numbers.Integral):
out_dtype_info = numpy.iinfo(out_dtype.type)
out_nan = float(0)
out_min = float(out_dtype_info.min)
out_max = float(out_dtype_info.max)
scale = (out_max - out_min) / (data_max - data_min)
out -= data_min
out *= scale
out += out_min
out = dask.array.clip(out, out_min, out_max)
out_isnan = dask.array.isnan(out)
out_isinf = dask.array.isinf(out)
out_sign = dask.array.sign(out)
out[out_isinf & (out_sign == -1)] = out_min
out[out_isinf & (out_sign == 1)] = out_max
out[out_isnan] = out_nan
out = out.astype(out_dtype)
return
```
<Overlap Ratio: 0.9776422764227642>

---

--- 243 --
Question ID: 3d017c8f3862f87dea3cbb27cc41173158a94874_13
Original Code:
```
def PositionalEncoding(indices, n_symbols, output_dim, max_len=500, cycle_scale=10000, random_state=None,
                       init="embedding_normal", scale=1., strict=None, name=None):
    pos_name = name + "_pos_cyclic"
    emb_name = name + "_embedding"

    def sincos(x, i):
        if i % 2 == 0:
            return np.sin(x)
        return np.cos(x)

    pe = tf.convert_to_tensor([sincos(pos / (cycle_scale ** (2 * i / float(output_dim))), i)
                               for pos in range(1, max_len + 1)
                               for i in range(1, output_dim + 1)])
    pe = tf.reshape(pe, [-1, max_len, output_dim])
    pe = tf.transpose(pe, [1, 0, 2])

    e_inds, emb = Embedding(indices, n_symbols, output_dim, random_state=random_state,
                            init=init, scale=scale, strict=strict, name=emb_name)

    # hardcode 3d assumption for now
    shp = _shape(indices)
    if len(shp) == 3:
        faker = tf.ones_like(indices)[:, 0, 0]
    else:
        raise ValueError("Currently unsupported input shape {} to PositionalEncoding".format(shp))
    cl = tf.cast(tf.reduce_sum(faker), tf.int32)
    return tf.add(e_inds, pe[:cl]), emb
```


Overlapping Code:
```
def PositionalEncoding(indices, n_symbols, output_dim, max_len=500, cycle_scale=10000, random_state=None,
init="embedding_normal", scale=1., strict=None, name=None):
pos_name = name + "_pos_cyclic"
emb_name = name + "_embedding"
def sincos(x, i):
if i % 2 == 0:
return np.sin(x)
return np.cos(x)
pe = tf.convert_to_tensor([sincos(pos / (cycle_scale ** (2 * i / float(output_dim))), i)
for pos in range(1, max_len + 1)
for i in range(1, output_dim + 1)])
pe = tf.reshape(pe, [-1, max_len, output_dim])
pe = tf.transpose(pe, [1, 0, 2])
e_inds, emb = Embedding(indices, n_symbols, output_dim, random_state=random_state,
init=init, scale=scale, strict=strict, name=emb_name)
# hardcode 3d assumption for now
shp = _shape(indices)
if len(shp) == 3:
faker = tf.ones_like(indices)[:, 0, 0]
else:
raise ValueError("Currently unsupported input shape {} to PositionalEncoding".format(shp))
cl = tf.cast(tf.reduce_sum(faker), tf.int32)
return tf.add(e_inds, pe[
```
<Overlap Ratio: 0.9895833333333334>

---

--- 244 --
Question ID: affdcfc7f9630df73b83f4252621990175eee9f0_0
Original Code:
```
def writetoCSV(arg1, arg2, arg3, arg4, arg5):
    # prop_id, url, lat, lon, price_sq_meter
    fe = []
    fe.append([arg1, arg2, arg3, arg4, arg5])
    df = pd.DataFrame(fe)
    if(not os.path.exists("/home/jm/Documents/master_new_repo/code_data/analysing_data/R/CSVs/df2.csv")):
        df.to_csv("/home/jm/Documents/master_new_repo/code_data/analysing_data/R/CSVs/df2.csv", mode="a", sep=",", na_rep="NA",  index=False, header = ['prop_id', 'req_url', 'lat', 'lon', 'esti_price_sq_meter'])
    else:
        df.to_csv("/home/jm/Documents/master_new_repo/code_data/analysing_data/R/CSVs/df2.csv", mode="a", sep=",", na_rep="NA",  index=False,header=False)
```


Overlapping Code:
```
def writetoCSV(arg1, arg2, arg3, arg4, arg5):
# prop_id, url, lat, lon, price_sq_meter
fe = []
fe.append([arg1, arg2, arg3, arg4, arg5])
df = pd.DataFrame(fe)
if(not os.path.exists("/home/jm/Documents/master_new_repo/code_data/analysing_data/R/CSVs/df2.csv")):
df.to_csv("/home/jm/Documents/master_new_repo/code_data/analysing_data/R/CSVs/df2.csv", mode="a", sep=",", na_rep="NA", index=False, header = ['prop_id', 'req_url', 'lat', 'lon', 'esti_price_sq_meter'])
else:
df.to_csv("/home/jm/Documents/master_new_repo/code_data/analysing_data/R/CSVs/df2.csv", mode="a", sep=",", na_rep="NA", index=Fals
```
<Overlap Ratio: 0.975609756097561>

---

--- 245 --
Question ID: 5735a96ac41e608432d4d92639ff18c16d737c54_2
Original Code:
```
def nwctrl_policy_exists(handle, name, parent_dn="org-root", **kwargs):
    """
    Checks if the given Network Control Policy already exists with the
    same params

    Args:
        handle (UcscHandle)
        name (string) : Network Control Policy Name
        parent_dn (string) : Org Dn or Domain_group Dn
        **kwargs: key-value pair of managed object(MO) property and value, Use
                  'print(ucsccoreutils.get_meta_info(<classid>).config_props)'
                  to get all configurable properties of class
    Returns:
        (True/False, MO/None)
    Example:
        bool_var = nwctrl_policy_exists(handle, "sample_nwcontrol_policy",
                                        "enabled", "all-host-vlans",
                                        "link-down", "allow", "disabled",
                                        "disabled")
    """
    mo = nwctrl_policy_get(handle, name, parent_dn)
    if not mo:
        return (False, None)

    if "forge" in kwargs:
        mo_1_dn = mo.dn + "/mac-sec"
        mo_1 = handle.query_dn(mo_1_dn)
        if not mo_1:
            raise UcscOperationError("nwctrl_policy_exists",
                                     "Mac secure object does not exist")

        args = {'forge': kwargs['forge']}
        if not mo.check_prop_match(**args):
            return (False, None)

        kwargs.pop('forge', None)

    mo_exists = mo.check_prop_match(**kwargs)
    return (mo_exists, mo if mo_exists else None)
```


Overlapping Code:
```
licy_exists(handle, name, parent_dn="org-root", **kwargs):
"""
Checks if the given Network Control Policy already exists with the
same params
Args:
handle (UcscHandle)
name (string) : Network Control Policy Name
parent_dn (string) : Org Dn or Domain_group Dn
**kwargs: key-value pair of managed object(MO) property and value, Use
'print(ucsccoreutils.get_meta_info(<classid>).config_props)'
to get all configurable properties of class
Returns:
(True/False, MO/None)
Example:
bool_var = nwctrl_policy_exists(handle, "sample_nwcontrol_policy",
"enabled", "all-host-vlans",
"link-down", "allow", "disabled",
"disabled")
"""
mo = nwctrl_policy_get(handle, name, parent_dn)
if not mo:
return (False, None)
if "forge" in kwargs:
mo_1_dn = mo.dn + "/mac-sec"
mo_1 = handle.query_dn(mo_1_dn)
if not mo_1:
raise UcscOperationError("nwctrl_policy_exists",
"Mac secure object does not exist")
args = {'forge': kwargs['forge']}
if not mo.check_prop_match(**args):
return (False, None)
kwargs.pop('forge', None)
mo_exists = mo.check_prop_match(**kwargs)
return (mo_exists, mo if mo_exists else None)
```
<Overlap Ratio: 0.9881710646041856>

---

--- 246 --
Question ID: 995b14d4a719784262369151c0522ea38ea5464e_0
Original Code:
```
def only_with_neutron_extension(extension):
    def decorator(func):
        @wraps(func)
        def wrapper(self, *args, **kwargs):
            if self.has_neutron_extension(extension):
                return func(self, *args, **kwargs)
            else:
                self.class_logger.error(('Function %s called that expects neutron extension '
                                         '%s which is not installed.'), func.__name__, extension)
        return wrapper
    return decorator
```


Overlapping Code:
```
neutron_extension(extension):
def decorator(func):
@wraps(func)
def wrapper(self, *args, **kwargs):
if self.has_neutron_extension(extension):
return func(self, *args, **kwargs)
else:
self.class_logger.error(('Function %s called that expects neutron extension '
'%s which is not installed.'), func.__name__, extension)
retu
```
<Overlap Ratio: 0.8870523415977961>

---

--- 247 --
Question ID: 5d761a0e13f37bc08d17a89dfe42bab545b7a800_2
Original Code:
```
def lastfm(data):
    """
    This parser restructures the LastFM API response to
    both eliminate unneeded data and to be more human parsable.

    For more obscure tracks, an album cover may not be available
    so we just provide our own placeholder from the static folder.

    :param data: A serialised JSON string.
    :return: A dictionary object.
    """
    Song.objects.all().delete()
    tracks = data['recenttracks']['track']
    for item in tracks:
        name = item['name']
        if not item['image'][3]['#text']:
            image = '/static/img/no_cover.png'
        else:
            image = item['image'][3]['#text']
        link = item['url']
        artist = item['artist']['#text']

        Song.objects.create(name=name, image=image,
                            link=link, artist=artist)
```


Overlapping Code:
```
def lastfm(data):
"""
This parser restructures the LastFM API response to
both eliminate unneeded data and to be more human parsable.
For more obscure tracks, an album cover may not be available
so we just provide our own placeholder from the static folder.
:param data: A serialised JSON string.
:return: A dictionary object.
"""
Song.objects.all().delete()
tracks = data['recenttracks']['track']
for item in tracks:
name = item['name']
if not item['image'][3]['#text']:
image = '/static/img/no_cover.png'
else:
image = item['image'][3]['#text']
link = item['url']
artist = item['artist']['#text']
Song.objects.create(name=name, image=image,

```
<Overlap Ratio: 0.9625748502994012>

---

--- 248 --
Question ID: f1deaea00c463f5a30b99f5a3f1ed7ef887b84a9_1
Original Code:
```
def send_mail(send_from, send_to, subject, message):
	username = "support@zepko.com"
	password = "a5mGxYTYWo"
	server="smtp.office365.com"
	port=587
	msg = MIMEMultipart('related')
	msg['From'] = send_from
	msg['To'] = send_to 
	msg['Subject'] = subject
	msg.attach( MIMEText(text, 'plain') )
	smtp = smtplib.SMTP(server, port)
	smtp.login(username, password)
	smtp.sendmail(send_from, send_to, msg.as_string())
	smtp.close()
	return True
```


Overlapping Code:
```
365.com"
port=587
msg = MIMEMultipart('related')
msg['From'] = send_from
msg['To'] = send_to 
msg['Subject'] = subject
msg.attach( MIMEText(text, 'plain') )
smtp = smtplib.SMTP(server, port)
smtp.login(username, password)
smtp.sendmail(send_from, send_to, msg.as_string())
smtp.close()

```
<Overlap Ratio: 0.6745283018867925>

---

--- 249 --
Question ID: e4cae06a012c9d8b1998883efa4e87912ce8ece2_27
Original Code:
```
def keywordp(scope, x):
    if x.evaluate(scope).__class__ == Keyword:
        return t
    return nil
```


Overlapping Code:
```
.evaluate(scope).__class__ == Keyword:
return t
re
```
<Overlap Ratio: 0.5813953488372093>

---

--- 250 --
Question ID: 8a3632eafece6174d58590f4f03eef72b734a964_1
Original Code:
```
def test_get_vals(clargs):

    infer_vars, config = forward_pass(clargs)

    programs = []
    a1s,a2s,b1s,b2s,prob_Ys  = [],[],[],[],[]
    for prog_id in sorted(list(infer_vars.keys())):
       a1s += [infer_vars[prog_id]['a1']]
       a2s += [infer_vars[prog_id]['a2']]
       b1s += [list(infer_vars[prog_id]['b1'])]
       b2s += [list(infer_vars[prog_id]['b2'])]
       prob_Ys += [infer_vars[prog_id]['ProbY']]


    return a1s, b1s, a2s, b2s, prob_Ys
```


Overlapping Code:
```
:
infer_vars, config = forward_pass(clargs)
programs = []
a1s,a2s,b1s,b2s,prob_Ys = [],[],[],[],[]
for prog_id in sorted(list(infer_vars.keys())):
a1s += [infer_vars[prog_id]['a1']]
a2s += [infer_vars[prog_id]['a2']]
b1s += [list(infer_vars[prog_id]['b1'])]
b2s += [list(infer_vars[prog_id]['b2'])]
prob_Ys += [infer_vars[prog_id]['ProbY']]
return a1
```
<Overlap Ratio: 0.875>

---

--- 251 --
Question ID: 73f0f69e41eed1defaaac2561403c7d961b60598_1
Original Code:
```
def find_K_means(k):
	centroids = np.random.choice(np.arange(17), k*64, replace=1).reshape(k, 64)		# Randomly initialize k cluster centers
	while True:
		idx_cluster = find_nearest_centre(centroids, X_train, k)			# Seperate data into clusters by finding nearest center
		k_means = []
		for i in range(k):								# Do for all clusters:
			if (len(idx_cluster[i]) != 0):						# If the cluster is not empty
				k_means.append(np.mean(X_train[idx_cluster[i], :], axis=0))	# Move the center to the mean of all vectors in the cluster
			else:						# Otherwise
				k_means.append(centroids[i, :])		# Keep center at its place
		if (np.sum(abs(centroids - k_means)) == 0):		# If there is no change in any of the centers
			break						# Stop moving the centers and exit loop
		centroids = np.asarray(k_means)				# Otherwise repeat with new set of centers

#	Compute Errors :
	MSE = []
	for i in range(k):
		MSE.append(np.nan_to_num(np.divide(np.sum(np.power(X_train[idx_cluster[i], :] - k_means[i], 2)), len(idx_cluster[i]))))
	Avg_MSE = np.divide(np.sum(MSE), np.count_nonzero(idx_cluster))
	Sq_Sep = 0
	for i in range(k):
		for j in range(i+1, k):
			Sq_Sep += np.sum(np.power(k_means[i] - k_means[j], 2))
	MSS = (2*Sq_Sep)/(k*(k-1))
	return np.asarray(k_means)[np.nonzero(idx_cluster)[0], :], MSE, Avg_MSE, MSS, np.asarray(idx_cluster)[np.nonzero(idx_cluster)[0]]
```


Overlapping Code:
```
np.random.choice(np.arange(17), k*64, replace=1).reshape(k, 64) # Randomly initialize k cluster centers
while True:
idx_cluster = find_nearest_centre(centroids, X_train, k) # Seperate data into clusters by finding nearest center
k_means = []
for i in range(k): # Do for all clusters:
if (len(idx_cluster[i]) != 0): # If the cluster is not empty
k_means.append(np.mean(X_train[idx_cluster[i], :], axis=0)) # Move the center to the mean of all vectors in the cluster
else: # Otherwise
k_means.append(centroids[i, :]) # Keep center at its place
if (np.sum(abs(centroids - k_means)) == 0): # If there is no change in any of the centers
break # Stop moving the centers and exit loop
centroids = np.asarray(k_means) # Otherwise repeat with new set of centers
# Compute Errors :
MSE = []
for i in range(k):
MSE.append(np.nan_to_num(np.divide(np.sum(np.power(X_train[idx_cluster[i], :] - k_means[i], 2)), len(idx_cluster[i]))))
Avg_MSE = np.divide(np.sum(MSE), np.count_nonzero(idx_cluster))
Sq_Sep = 0
for i in range(k):
for j in range(i+1, k):
Sq_Sep += np.sum(np.power(k_means[i] - k_means[j], 2))
MSS = (2*Sq_Sep)/(k*(k-1))
return np.asarray(k_means)[np.nonzero(idx_cluster)[0], :], MSE, Avg_MSE, MSS, np
```
<Overlap Ratio: 0.9360374414976599>

---

--- 252 --
Question ID: d4df4e73f5b436e575c01ebed35f2973cdf71f3f_81
Original Code:
```
def _batch_op_init_for_opdef_default_optimizer(opdef, S):
    assert not S.batch_op
    S.batch_op = Operation()
    optdef = util.find_apply(
        [
            lambda: opdef.default_optimizer,
            lambda: _default_optimizer(opdef),
        ]
    )
    _op_init_for_optimizer(optdef, S.batch_op)
```


Overlapping Code:
```
def _batch_op_init_for_opdef_default_optimizer(opdef, S):
assert not S.batch_op
S.batch_op = Operation()
optdef = util.find_apply(
[
lambda: opdef.default_optimizer,
lambda: _default_optimizer(opdef),
```
<Overlap Ratio: 0.8097165991902834>

---

--- 253 --
Question ID: 9f1f41c8e7ab08d3fbdaaf94146c28d7acdf55a7_3
Original Code:
```
def main():
    args = parse_args()

    set_up_logging(args.log)

    if args.hmac_file_secret:
        hmac_secret = get_secret_from_temp_file(args.hmac_file_secret)
        handlers.app.config['jedihttp.hmac_secret'] = b64decode(hmac_secret)
        handlers.app.install(HmacPlugin())

    handlers.app.install(WatchdogPlugin(args.idle_suicide_seconds,
                                        args.check_interval_seconds))

    handlers.wsgi_server = StoppableWSGIServer(handlers.app,
                                               host=args.host,
                                               port=args.port)
    handlers.wsgi_server.start()
```


Overlapping Code:
```
 parse_args()
set_up_logging(args.log)
if args.hmac_file_secret:
hmac_secret = get_secret_from_temp_file(args.hmac_file_secret)
handlers.app.config['jedihttp.hmac_secret'] = b64decode(hmac_secret)
handlers.app.install(HmacPlugin())
handlers.app.install(WatchdogPlugin(args.idle_suicide_seconds,
args.check_interval_seconds))
handlers.wsgi_server = StoppableWSGIServer(handlers.app,
host=args.host,
po
```
<Overlap Ratio: 0.8695652173913043>

---

--- 254 --
Question ID: 2e463ca1f0dceff79cf208407c95964b6725cd5c_11
Original Code:
```
def get_current_spot_price(intent_request):
    """
    Performs dialog management and fulfillment for getting current spot price.
    """
    logger.debug('Current Intent: {}'.format(intent_request['currentIntent']))
    current = intent_request.get('currentIntent')
    slots = current.get('slots') if current else None
    instance_type = slots.get('InstanceType') if slots else None
    amazon_region = slots.get('AmazonRegion') if slots else None
    if intent_request.get('sessionAttributes'):
        session_attributes = intent_request['sessionAttributes']
    else:
        session_attributes = {}

    if intent_request['invocationSource'] == 'DialogCodeHook':
        # Validate any slots which have been specified.  If any are invalid,
        # re-elicit for their value
        validation_result = validate_get_current_spot_price(slots)
        if not validation_result['isValid']:
            slots[validation_result['violatedSlot']] = None
            return elicit_slot(
                session_attributes,
                current['name'],
                slots,
                validation_result['violatedSlot'],
                validation_result['message']
            )

        # Otherwise, let native DM rules determine how to elicit for slots
        # and/or drive confirmation.
        return delegate(session_attributes, slots)

    # Display value. Call backend
    # We get the info and we format the answer
    spot_prices_result = get_price_history([instance_type], amazon_region)
    spot_prices_message = format_price_answer(spot_prices_result)

    message = (
        'The current spot price for a {} instance in {} is {}'
        '.'.format(instance_type, amazon_region, spot_prices_message)
    )
    logger.debug(message)
    return close(
        session_attributes,
        'Fulfilled',
        {
            'contentType': 'PlainText',
            'content': message
        }
    )
```


Overlapping Code:
```
(intent_request):
"""
Performs dialog management and fulfillment for getting current spot price.
"""
logger.debug('Current Intent: {}'.format(intent_request['currentIntent']))
current = intent_request.get('currentIntent')
slots = current.get('slots') if current else None
instance_type = slots.get('InstanceType') if slots else None
amazon_region = slots.get('AmazonRegion') if slots else None
if intent_request.get('sessionAttributes'):
session_attributes = intent_request['sessionAttributes']
else:
session_attributes = {}
if intent_request['invocationSource'] == 'DialogCodeHook':
# Validate any slots which have been specified. If any are invalid,
# re-elicit for their value
validation_result = validate_get_current_spot_price(slots)
if not validation_result['isValid']:
slots[validation_result['violatedSlot']] = None
return elicit_slot(
session_attributes,
current['name'],
slots,
validation_result['violatedSlot'],
validation_result['message']
)
# Otherwise, let native DM rules determine how to elicit for slots
# and/or drive confirmation.
return delegate(session_attributes, slots)
# Display value. Call backend
# We get the info and we format the answer
spot_prices_result = get_price_history([instance_type], amazon_region)
spot_prices_message = format_price_answer(spot_prices_result)
message = (
'The current spot price for a {} instance in {} is {}'
'.'.format(instance_type, amazon_region, spot_prices_message)
)
logger.debug(message)
return close(
session_attributes,
'Fulfilled',
{
'contentType': 'PlainText',
'content': message
}
)
```
<Overlap Ratio: 0.9835129993658845>

---

--- 255 --
Question ID: 90d94790d1781c24778a10f0e097bd70bbc88c3d_4
Original Code:
```
async def lastraid(message, bot_channel, client, player):
    await client.delete_message(message)
    parameters = message.content.split()
    if len(parameters) < 2:
        await client.send_message(bot_channel, "USAGE: !lastraidplayer [player name] or !lastraidguild [guild name]")
        return

    name = " ".join(parameters[1:])
    if not name.isalpha():
        await client.send_message(bot_channel, "Sorry, but the {} name can only contain letters.".format("player" if player else "guild"))
        return

    name = name.lower().capitalize()
    if player:
        try:
            player_url, player_info = await get_player_url(message, bot_channel, client, name)
        except:
            return

        player_overview_url = "http://realmplayers.com/RaidStats/PlayerOverview.aspx?realm={}&player={}".format(
            player_info[0], player_info[1])

        # Get raid stats url from the player
        @get_session(player_overview_url)
        async def get_raid_url(message, bot_channel, client, resp):
            player_doc = await resp.text()
            pattern = '<h2>Attended raids</h2><a href=\"(.+?)\">'
            return re.search(pattern, player_doc)

        try:
            match = await get_raid_url(message, bot_channel, client)
        except:
            return

        if match:
            # Get character info to find out if horde or alliance
            @get_session(player_url)
            async def get_player_doc(message, bot_channel, client, resp):
                return await resp.text()

            try:
                player_doc = await get_player_doc(message, bot_channel, client)
            except:
                return

            is_alliance = re.search('alliance_bg', player_doc)
            if is_alliance:
                player_race_icon = race_icons["alliance"]
            else:
                player_race_icon = race_icons["horde"]

            server = re.search("<span class='divider'>/</span>(.+?)</li>", player_doc)
            if not server:
                await client.send_message(bot_channel,
                                          "Sorry, the web site has been changed and the bot needs an update.\n"
                                          "Please notify the developer.")
                return

            raid_stats = "http://realmplayers.com/RaidStats/{}"

            # Get raid info to get full title and time
            @get_session(raid_stats.format(match.group(1)))
            async def get_raid_doc(message, bot_channel, client, resp):
                return await resp.text()

            try:
                raid_doc = await get_raid_doc(message, bot_channel, client)
            except:
                return

            raid_info = re.search("<a href='(RaidList\.aspx\?Guild=.+?&realm=.+?)'>(.+?)</a></li>"
                                  "<li class='active'><span class='divider'>/</span>(.+?)</li>", raid_doc)
            times = re.search("between (\d{4}(?:-\d{1,2}){2} (?:\d{2}:){2}\d{2}) and "
                              "(\d{4}(?:-\d{1,2}){2} (?:\d{2}:){2}\d{2})", raid_doc)
            if not raid_info or not times:
                await client.send_message(bot_channel,
                                          "Sorry, the web site has been changed and the bot needs an update.\n"
                                          "Please notify the developer.")
                return

            embed = discord.Embed()
            embed.set_author(name=raid_info.group(2), url=raid_stats.format(raid_info.group(1)),
                             icon_url=player_race_icon)
            embed.set_thumbnail(url=raid_icons[re.sub("\(.+?\)", '', raid_info.group(3))])
            embed.colour = discord.Colour.dark_blue()
            embed.title = raid_info.group(3).strip(" ")
            embed.url = raid_stats.format(match.group(1))
            embed.description = "Last recorded raid for **[{}]({})**\n".format(player_info[1], player_url)
            embed.description += "On server {}".format(server.group(1).strip(" "))
            embed.add_field(name="Start", value=times.group(1)).add_field(name="End", value=times.group(2))
            await client.send_message(bot_channel, embed=embed)
        else:
            await client.send_message(bot_channel, "The given player doesn't seem to have any raids on record.")

    else:
        # Get guild url from searching after the guild
        @get_session("http://realmplayers.com/CharacterList.aspx?search={}".format(name))
        async def get_guild_url(message, bot_channel, client, resp):
            search_doc = await resp.text()
            pattern = 'realm=(\w+?)&guild=({})\">&lt;.+?&gt;<\/a></td><td>.*?</td><td>.*?</td><td>.*?</td><td>.*?</td><td>(.+?)</td>'.format(name)
            return re.findall(pattern, search_doc)

        try:
            matches = await get_guild_url(message, bot_channel, client)
        except:
            return

        if len(matches) < 1:
            await client.send_message(bot_channel, 'Sorry, could not find any guild with name "{}".'.format(name))
            return

        guild_tuple = matches[0]
        response = await prompt_user(message, bot_channel, client, name, matches)
        if response:
            await client.delete_message(response)
            guild_tuple = matches[int(response.content) - 1]

        raid_link = "http://realmplayers.com/RaidStats/RaidList.aspx?realm={}&guild={}".format(guild_tuple[0], guild_tuple[1])

        # Get raid link
        @get_session(raid_link)
        async def get_last_raid_url(message, bot_channel, client, resp):
            search_doc = await resp.text()
            pattern = '<a href="(.+?)"><img src="(.+?)"\/>(.+?)<\/a><\/td><td><a href="(.+?)">' \
                      '<img src="(.+?)"\/>(.+?)<\/a><\/td><td>(.+?)<\/td><td>(.+?)<\/td><td>(.+?)<\/td><\/tr>'
            return re.search(pattern, search_doc)

        try:
            match = await get_last_raid_url(message, bot_channel, client)
        except:
            return

        if match:
            embed = discord.Embed()
            raid_stats = "http://realmplayers.com/RaidStats/{}"
            embed.set_author(name=match.group(3), url=raid_stats.format(match.group(1)), icon_url=raid_stats.format(match.group(2)))
            embed.set_thumbnail(url=raid_stats.format(match.group(5)))
            embed.colour = discord.Colour.dark_blue()
            embed.title = match.group(6).strip(" ")
            embed.url = raid_stats.format(match.group(4))
            embed.description = "On server {}".format(match.group(9))
            embed.add_field(name="Start", value=match.group(7)).add_field(name="End", value=match.group(8))
            await client.send_message(bot_channel, embed=embed)
        else:
            await client.send_message(bot_channel,
                                      "There doesn't seem to be any raids recorded for this guild.")
```


Overlapping Code:
```
player):
await client.delete_message(message)
parameters = message.content.split()
if len(parameters) < 2:
await client.send_message(bot_channel, "USAGE: !lastraidplayer [player name] or !lastraidguild [guild name]")
return
name = " ".join(parameters[1:])
if not name.isalpha():
await client.send_message(bot_channel, "Sorry, but the {} name can only contain letters.".format("player" if player else "guild"))
return
name = name.lower().capitalize()
if player:
try:
player_url, player_info = await get_player_url(message, bot_channel, client, name)
except:
return
player_overview_url = "http://realmplayers.com/RaidStats/PlayerOverview.aspx?realm={}&player={}".format(
player_info[0], player_info[1])
# Get raid stats url from the player
@get_session(player_overview_url)
async def get_raid_url(message, bot_channel, client, resp):
player_doc = await resp.text()
pattern = '<h2>Attended raids</h2><a href=\"(.+?)\">'
return re.search(pattern, player_doc)
try:
match = await get_raid_url(message, bot_channel, client)
except:
return
if match:
# Get character info to find out if horde or alliance
@get_session(player_url)
async def get_player_doc(message, bot_channel, client, resp):
return await resp.text()
try:
player_doc = await get_player_doc(message, bot_channel, client)
except:
return
is_alliance = re.search('alliance_bg', player_doc)
if is_alliance:
player_race_icon = race_icons["alliance"]
else:
player_race_icon = race_icons["horde"]
server = re.search("<span class='divider'>/</span>(.+?)</li>", player_doc)
if not server:
await client.send_message(bot_channel,
"Sorry, the web site has been changed and the bot needs an update.\n"
"Please notify the developer.")
return
raid_stats = "http://realmplayers.com/RaidStats/{}"
# Get raid info to get full title and time
@get_session(raid_sta
```
<Overlap Ratio: 0.9493670886075949>

---

--- 256 --
Question ID: 3c6e7f9bfd20d96d7c2999dfcee6ceb737fa9a79_6
Original Code:
```
def printAnswerGraph(answer, headers, meta):
	"""
	printAnswerGraph(answer, headers, meta): Print up a graph of our answer
	"""

	rddata = answer["rddata"]

	print("                                1  1  1  1  1  1")
	print("     0  1  2  3  4  5  6  7  8  9  0  1  2  3  4  5")
	print("   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+")
    
	print("   |  NAME     : %-40s    |" % (rddata["question_text"]))

	for row in rddata["question_meta"]["data_decoded"]:

		if "length" in row:

			key = row["length"]
			value = "(nil)"
			if row["length"]:
				value = row["string"]
			print("   |        len: %3d  value: %-30s  |" % (key, value))

		elif "pointer" in row:
			key = row["pointer"]
			value = row["target"]
			print("   |    pointer: %3d target: %-30s  |" % (key, value))

		else:

			print("   |    UNKNOWN: %25s |" % (row))

	#
	# If the header was set to a negative very (or a very high positive value!)
	# for debugging, ensure the number is negative and the text indicates that
	# debugging is happening.
	#
	if headers["ttl"] >= 4294967293:
		logger.debug("TTL is over 2**32-3, so subtract 2**32")
		headers["ttl"] -= pow(2,32)

	if headers["ttl"] < 0:
		headers["ttl_text"] = "DEBUGGING"

	print("   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+")
	print("   |  TYPE:  %3d - %-38s    |" % (headers["type"], headers["type_text"]))
	print("   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+")
	print("   | CLASS: %3d - %-39s    |" % (headers["class"], headers["class_text"]))
	print("   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+")
	print("   |   TTL: %10d - %-33s   |" % (headers["ttl"], headers["ttl_text"]))
	print("   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+")
	print("   |   RDLENGTH: %3d                                         |" % (headers["rdlength"]))
	print("   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+")
	print("   |     RDDATA: %-40s    |" % (answer["rddata_text"]))
	if "meta" in rddata:
		for row in rddata["meta"]["data_decoded"]:

			if "length" in row:

				key = row["length"]
				value = "(nil)"
				if row["length"]:
					value = row["string"]
				print("   |        len: %3d  value: %-30s  |" % (key, value))

			elif "pointer" in row:
				key = row["pointer"]
				value = row["target"]
				print("   |    pointer: %3d target: %-30s  |" % (key, value))

			else:

				print("   |    UNKNOWN: %35s |" % (row))
	print("   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+")
```


Overlapping Code:
```
wer, headers, meta):
"""
printAnswerGraph(answer, headers, meta): Print up a graph of our answer
"""
rddata = answer["rddata"]
print(" 1 1 1 1 1 1")
print(" 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5")
print(" +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+")

print(" | NAME : %-40s |" % (rddata["question_text"]))
for row in rddata["question_meta"]["data_decoded"]:
if "length" in row:
key = row["length"]
value = "(nil)"
if row["length"]:
value = row["string"]
print(" | len: %3d value: %-30s |" % (key, value))
elif "pointer" in row:
key = row["pointer"]
value = row["target"]
print(" | pointer: %3d target: %-30s |" % (key, value))
else:
print(" | UNKNOWN: %25s |" % (row))
#
# If the header was set to a negative very (or a very high positive value!)
# for debugging, ensure the number is negative and the text indicates that
# debugging is happening.
#
if headers["ttl"] >= 4294967293:
logger.debug("TTL is over 2**32-3, so subtract 2**32")
headers["ttl"] -= pow(2,32)
if headers["ttl"] < 0:
headers["ttl_text"] = "DEBUGGING"
print(" +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+")
print(" | TYPE: %3d - %-38s |" % (headers["type"], headers["type_text"]))
print(" +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+")
print(" | CLASS: %3d - %-39s |" % (headers["class"], headers["class_text"]))
print(" +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+")
print(" | TTL: %10d - %-33s |" % (headers["ttl"], headers["ttl_text"]))
print(" +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+")
print(" | RDLENGTH: %3d |" % (headers["rdlength"]))
print(" +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+")
print(" | RDDATA: %-40s |" % (answer["rddata_text"]))
if "meta" in rddata:
for row in rddata["meta"]["data_decoded"]:
if "length" in row:
key = row["length"]
value = "(nil)"
if row["length"]:
value = row["string"]
print(" | len: %3d value: %-30s |" % (key, value))
elif "pointer" in row:
key = row["pointer"]
value = row["target"]
print(" | pointer: %3d target: %-30s |" % (key, value))
else:
print(" | UNKNOWN: %35s |" % (row))
print(" +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+---
```
<Overlap Ratio: 0.9889349930843707>

---

--- 257 --
Question ID: 40793c0dd18dff62c006cfb6fc284053076cde42_0
Original Code:
```
@pytest.fixture()
def dummy_featuretiles():
    yaml = """
name: vp1
    """
    vp = FeaturetilesWidget('widget1', 'widget1', yaml)
    yield vp
```


Overlapping Code:
```
test.fixture()
def dummy_featuretiles():
yaml = """
name: vp1
"""
vp = FeaturetilesWidget('widget1',
```
<Overlap Ratio: 0.7751937984496124>

---

--- 258 --
Question ID: 6636c2db5d917dd3290a01326f8c2e81f247677a_4
Original Code:
```
@then('they are able to see the Status for each collection exercise')
def survey_ce_state_is_scheduled(context):
    ce_state = collection_exercise.get_table_row_by_period(context.period)['state']
    assert collection_exercise.is_scheduled(ce_state), ce_state
```


Overlapping Code:
```
he Status for each collection exercise')
def survey_ce_state_is_scheduled(context):
ce_state = collection_exercise.get_table_row_by_period(context.period)['state']
assert collection_exercise.is_schedu
```
<Overlap Ratio: 0.7936507936507936>

---

--- 259 --
Question ID: c52f7eda0c1f7bb5409abea39e8d1e8797d1155a_1
Original Code:
```
def history_log(event: str) -> Tuple[bool, str]:
    try:
        with open(HISTORY_LOG_FILE, "a") as file_:
            file_.write(event)
        return True, event
    except Exception as e:
        return False, str(e)
```


Overlapping Code:
```
tr) -> Tuple[bool, str]:
try:
with open(HISTORY_LOG_FILE, "a") as file_:
file_.write(event)
return True, event
except Exception as e:
return False, st
```
<Overlap Ratio: 0.8426966292134831>

---

--- 260 --
Question ID: 8711225fd68c0db2834cf8b69da4b3bfbfbce313_0
Original Code:
```
def escritor(id):
    sleep(random())
    print("   Escritor %d iniciando" % id)
    torniquete.acquire()
    print("   Escritor %d: En el torniquete" % id)
    cuarto_vacio.acquire()
    print("   Escritor %d: El cuarto es mío!" % id)
    escribe(id)
    cuarto_vacio.release()
    torniquete.release()
    print("   Escritor %d se fue" % id)
```


Overlapping Code:
```
:
sleep(random())
print(" Escritor %d iniciando" % id)
torniquete.acquire()
print(" Escritor %d: En el torniquete" % id)
cuarto_vacio.acquire()
print(" Escritor %d: El cuarto es mío!" % id)
escribe(id)
cuarto_vacio.release()
torniquete.release()
prin
```
<Overlap Ratio: 0.847457627118644>

---

--- 261 --
Question ID: dda09ac234d6ae788fe90c15b694d23cc60fef40_1
Original Code:
```
def getBandSongs(artist):
    """Given the Artist you will get all the songs from all the albums and EPs

    Args: Artist

    Return: A List with all the songs
    """
    artist = artist.lower()
    if artist.startswith("the "):
        artist = artist[3:]

    artist = re.sub('[^A-Za-z0-9]+', "", artist)

    url = "http://www.azlyrics.com/"+artist[0]+"/"+artist+".html"

    try:
        content = UrlReq.urlopen(url).read()
        soup = BS(content, 'html.parser')
        songs = []
        songsBackbone = str(soup)
        songsBackbone = songsBackbone.split('songlist')[1]
        songsBackbone = songsBackbone.split('var res')[0]
        for i in range(len(songsBackbone))[1::]:
            try:
                passValue = songsBackbone.split("s:")[i]
                passValue = passValue.split('", h:')[0]
                songs.append(passValue.split('"')[1])
            except IndexError:
                break
        return songs 
    except Exception as e:
        return "Exception occurred \n" + str(e)
```


Overlapping Code:
```
BandSongs(artist):
"""Given the Artist you will get all the songs from all the albums and EPs
Args: Artist
Return: A List with all the songs
"""
artist = artist.lower()
if artist.startswith("the "):
artist = artist[3:]
artist = re.sub('[^A-Za-z0-9]+', "", artist)
url = "http://www.azlyrics.com/"+artist[0]+"/"+artist+".html"
try:
content = UrlReq.urlopen(url).read()
soup = BS(content, 'html.parser')
songs = []
songsBackbone = str(soup)
songsBackbone = songsBackbone.split('songlist')[1]
songsBackbone = songsBackbone.split('var res')[0]
for i in range(len(songsBackbone))[1::]:
try:
passValue = songsBackbone.split("s:")[i]
passValue = passValue.split('", h:')[0]
songs.append(passValue.split('"')[1])
except IndexError:
break
return songs 
except Exception as e:
return "Exception occurred \n" + str(e)
```
<Overlap Ratio: 0.991389913899139>

---

--- 262 --
Question ID: 1a2ee45e0d3505c7a62e3d84edae917cc0417cd5_0
Original Code:
```
def parse_requirements(filename):
    """ load requirements from a pip requirements file """
    lineiter = (line.strip() for line in open(filename))
    return [line for line in lineiter if line and not line.startswith("#")]
```


Overlapping Code:
```
def parse_requirements(filename):
""" load requirements from a pip requirements file """
lineiter = (line.strip() for line in open(filename))
return [line for line in lineiter if line and not line.startswith("#")]
```
<Overlap Ratio: 1.0>

---

--- 263 --
Question ID: 52f79f12acb6e6b69ab5c09a6d8066d3316782da_1
Original Code:
```
def load_quandl_tickers(tickers_path):
    df = pd.read_csv(tickers_path, header=None)
    df.columns = ['Ticker','Name']
    df = df[df.Name.str.contains("\(EQ(.+)\) Unadjusted")]
    tickers = [re.search("\(EQ(.+)\) Unadjusted",s).group(1) for s in df.Name.tolist()]
    names = [s.split(' (EQ'+tickers[i])[0] for i,s in enumerate(df.Name.tolist())]
    names = [s.split("Ltd")[0].strip() for s in names]
    quandl_tickers = df.Ticker.tolist()
    df_dict = {'symbol':tickers,'qsymbol':quandl_tickers, 'name':names}
    tickers = pd.DataFrame(df_dict,columns=['symbol','qsymbol','name'])
    return tickers
```


Overlapping Code:
```
ckers_path):
df = pd.read_csv(tickers_path, header=None)
df.columns = ['Ticker','Name']
df = df[df.Name.str.contains("\(EQ(.+)\) Unadjusted")]
tickers = [re.search("\(EQ(.+)\) Unadjusted",s).group(1) for s in df.Name.tolist()]
names = [s.split(' (EQ'+tickers[i])[0] for i,s in enumerate(df.Name.tolist())]
names = [s.split("Ltd")[0].strip() for s in names]
quandl_tickers = df.Ticker.tolist()
df_dict = {'symbol':tickers,'qsymbol':quandl_tickers, 'name':names}
tickers = pd.DataFrame(df_dict,columns=
```
<Overlap Ratio: 0.8787346221441125>

---

--- 264 --
Question ID: 84e4d96cb329175c11d2e08a06406e840cc45dbf_0
Original Code:
```
def add_missing_fields(*fields):
	"""
	@param do_redirect: throws exception on None, redirects to login on True, redirects to register of False
	@type do_redirect: bool
	"""
	def method_wrapper(f):
		def wrap(*args, **kwargs):
				for k in fields:
					if k not in kwargs:
						kwargs[k] = None
				return f(*args, **kwargs)
		wrap.__doc__ = f.__doc__
		wrap.__name__ = f.__name__
		return wrap
	return method_wrapper
```


Overlapping Code:
```
fields(*fields):
"""
@param do_redirect: throws exception on None, redirects to login on True, redirects to register of False
@type do_redirect: bool
"""
def method_wrapper(f):
def wrap(*args, **kwargs):
for k in fields:
if k not in kwargs:
kwargs[k] = None
return f(*args, **kwargs)
wrap.__doc__ = f.__doc__
wrap.__name__ = f.__name__
return wrap
re
```
<Overlap Ratio: 0.9090909090909091>

---

--- 265 --
Question ID: 5094acb72a162e0540c044d769e1eb38915e0331_0
Original Code:
```
def get_models_from_table_names(table_names, force=None):
    """
    Convert list of table names to table model classes.
    """
    models = []
    errors = []
    for table_name in table_names:
        try:
            models.append(
                get_model_from_table_name(table_name)
            )
        except (
            IncorrectTableNameException,
            ModelDoesNotExistException
        ) as exc:
            if not force:
                raise exc
            errors.append(exc.args)
    return models, errors
```


Overlapping Code:
```
es, force=None):
"""
Convert list of table names to table model classes.
"""
models = []
errors = []
for table_name in table_names:
try:
models.append(
get_model_from_table_name(table_name)
)
except (
IncorrectTableNameException,
ModelDoesNotExistException
) as exc:
if not force:
raise exc
errors.append(e
```
<Overlap Ratio: 0.8116710875331565>

---

--- 266 --
Question ID: 62a48f8a0bbe203927d1de9dbb7edb7d298eb4fe_0
Original Code:
```
def index(request) :
    news = News.objects.filter(published_date__lte=timezone.now()).order_by('-published_date')[:12]
    edicts = Edict.objects.filter(published_date__lte=timezone.now()).order_by('-published_date')[:11]
    articles = {} #Article.objects.filter(published_date__lte=timezone.now()).order_by('-published_date')[:6]
    patriarhia = getPatriarhiaNew()
    return render(request, 'index.html', {'news': news, 'articles':articles, 'patriarhia':patriarhia, 'edicts': edicts})
```


Overlapping Code:
```
ews.objects.filter(published_date__lte=timezone.now()).order_by('-published_date')[:12]
edicts = Edict.objects.filter(published_date__lte=timezone.now()).order_by('-published_date')[:11]
articles = {} #Article.objects.filter(published_date__lte=timezone.now()).order_by('-published_date')[:6]
patriarhia = getPatriarhiaNew()
return render(request, 'index.html', {'news': news, 'articles':articles, 'p
```
<Overlap Ratio: 0.851063829787234>

---

--- 267 --
Question ID: 87534233570507f0d3c843ae7a174085e6179708_0
Original Code:
```
def build_k_indices(y, k_fold, seed):
    """build k indices for k-fold."""
    num_row = len(y)
    interval = int(num_row / k_fold)
    np.random.seed(seed)
    indices = np.random.permutation(num_row)
    k_indices = [indices[k * interval: (k + 1) * interval]
                 for k in range(k_fold)]
    return np.array(k_indices)
```


Overlapping Code:
```
def build_k_indices(y, k_fold, seed):
"""build k indices for k-fold."""
num_row = len(y)
interval = int(num_row / k_fold)
np.random.seed(seed)
indices = np.random.permutation(num_row)
k_indices = [indices[k * interval: (k + 1) * interval]
for k in range(k_fold)]
return np.array(k_indice
```
<Overlap Ratio: 0.9930795847750865>

---

--- 268 --
Question ID: 5563fb5e00980509f3c5704f01d074062dd1d2c1_4
Original Code:
```
@register.filter
def price(value, autoescape=None):
	value = int(value)
	if not value:
		g, s, c = 0, 0, 0
	else:
		g = divmod(value, 10000)[0]
		s = divmod(value, 100)[0] % 100
		c = value % 100

	output = '<span class="price">%s %s %s</span>' % (
		g and PRICE_TEMPLATE % {"amt": g, "letter": "g", "alt": "Gold"} or "",
		s and PRICE_TEMPLATE % {"amt": s, "letter": "s", "alt": "Silver"} or "",
		c and PRICE_TEMPLATE % {"amt": c, "letter": "c", "alt": "Copper"} or "",
	)

	return safestring.mark_safe(output)
```


Overlapping Code:
```
None):
value = int(value)
if not value:
g, s, c = 0, 0, 0
else:
g = divmod(value, 10000)[0]
s = divmod(value, 100)[0] % 100
c = value % 100
output = '<span class="price">%s %s %s</span>' % (
g and PRICE_TEMPLATE % {"amt": g, "letter": "g", "alt": "Gold"} or "",
s and PRICE_TEMPLATE % {"amt": s, "letter": "s", "alt": "Silver"} or "",
c and PRICE_TEMPLATE % {"amt": c, "letter": "c", "alt": "Copper"}
```
<Overlap Ratio: 0.8163265306122449>

---

--- 269 --
Question ID: 5b84f1d6a2df7b3cfcbfe1a31e05024eb40a3ee4_7
Original Code:
```
def b58check_unpack(b58_s):
    """ Takes in a base 58 check string and returns: the version byte, the
        original encoded binary string, and the checksum.
    """
    num_leading_zeros = len(re.match(r'^1*', b58_s).group(0))
    # convert from b58 to b16
    hex_s = change_charset(b58_s, B58_KEYSPACE, HEX_KEYSPACE)
    # if an odd number of hex characters are present, add a zero to the front
    if len(hex_s) % 2 == 1:
        hex_s = "0" + hex_s
    # convert from b16 to b2
    bin_s = binascii.unhexlify(hex_s)
    # add in the leading zeros
    bin_s = '\x00' * num_leading_zeros + bin_s
    # make sure the newly calculated checksum equals the embedded checksum
    newly_calculated_checksum = bin_checksum(bin_s[:-4])
    embedded_checksum = bin_s[-4:]
    if not (newly_calculated_checksum == embedded_checksum):
        raise ValueError('b58check value has an invalid checksum')
    # return values
    version_byte = bin_s[:1]
    encoded_value = bin_s[1:-4]
    checksum = bin_s[-4:]
    return version_byte, encoded_value, checksum
```


Overlapping Code:
```
ef b58check_unpack(b58_s):
""" Takes in a base 58 check string and returns: the version byte, the
original encoded binary string, and the checksum.
"""
num_leading_zeros = len(re.match(r'^1*', b58_s).group(0))
# convert from b58 to b16
hex_s = change_charset(b58_s, B58_KEYSPACE, HEX_KEYSPACE)
# if an odd number of hex characters are present, add a zero to the front
if len(hex_s) % 2 == 1:
hex_s = "0" + hex_s
# convert from b16 to b2
bin_s = binascii.unhexlify(hex_s)
# add in the leading zeros
bin_s = '\x00' * num_leading_zeros + bin_s
# make sure the newly calculated checksum equals the embedded checksum
newly_calculated_checksum = bin_checksum(bin_s[:-4])
embedded_checksum = bin_s[-4:]
if not (newly_calculated_checksum == embedded_checksum):
raise ValueError('b58check value has an invalid checksum')
# return values
version_byte = bin_s[:1]
encoded_value = bin_s[1:-4]
checksum = bin_s[-4:]
return ve
```
<Overlap Ratio: 0.9620253164556962>

---

--- 270 --
Question ID: c351ca5a80af848418394800af518555cda4dd74_1
Original Code:
```
def post_case_event(case_id, category, description):
    logger.debug('Posting case event', case_id=case_id, category=category)

    url = f'{Config.CASE_SERVICE}/cases/{case_id}/events'
    payload = {
        'description': description,
        'category': category,
        'createdBy': 'TESTS'
    }
    response = requests.post(url, json=payload, auth=Config.BASIC_AUTH)
    if response.status_code != 201:
        logger.error('Failed to post case event', status=response.status_code)

    logger.debug('Successfully posted case event',
                 case_id=case_id, category=category)
    return response.json()
```


Overlapping Code:
```
post_case_event(case_id, category, description):
logger.debug('Posting case event', case_id=case_id, category=category)
url = f'{Config.CASE_SERVICE}/cases/{case_id}/events'
payload = {
'description': description,
'category': category,
'createdBy': 'TESTS'
}
response = requests.post(url, json=payload, auth=Config.BASIC_AUTH)
if response.status_code != 201:
logger.error('Failed to post case event', status=response.status_code)
logger.debug('Successfully posted case event',
case_id=case_id, category=category)
return response.json()
```
<Overlap Ratio: 0.9925788497217068>

---

--- 271 --
Question ID: 14e94fa93cb2b7733c73bd1992a949013297b9d3_3
Original Code:
```
def test_set_positive_charges():
    mol = Chem.RWMol()
    mol.AddAtom(Chem.Atom('O'))
    mol.AddAtom(Chem.Atom('H'))
    mol.AddAtom(Chem.Atom('H'))
    mol.AddAtom(Chem.Atom('H'))

    mol.AddBond(0, 1, Chem.BondType.SINGLE)
    mol.AddBond(0, 2, Chem.BondType.SINGLE)
    mol.AddBond(0, 3, Chem.BondType.SINGLE)

    for atom in mol.GetAtoms():
        atom.SetNoImplicit(True)

    set_positive_charges(mol)

    assert mol.GetAtomWithIdx(0).GetFormalCharge() == 1,\
        "Oxygen must have a positive charge."
    return
```


Overlapping Code:
```
m.RWMol()
mol.AddAtom(Chem.Atom('O'))
mol.AddAtom(Chem.Atom('H'))
mol.AddAtom(Chem.Atom('H'))
mol.AddAtom(Chem.Atom('H'))
mol.AddBond(0, 1, Chem.BondType.SINGLE)
mol.AddBond(0, 2, Chem.BondType.SINGLE)
mol.AddBond(0, 3, Chem.BondType.SINGLE)
for atom in mol.GetAtoms():
atom.SetNoImplicit(True)
set_positive_charges(mol)
assert mol.GetAtomWithIdx(0).GetFormalCharge() == 1,\
"Oxygen must have a posit
```
<Overlap Ratio: 0.8676789587852495>

---

--- 272 --
Question ID: b3f7c6bc7ff1be7d1d272943a1844cc2144a065d_4
Original Code:
```
def check_directory(experiment_config, key):
    '''Check whether a value in experiment_config is a valid directory'''
    if not os.path.isdir(experiment_config[key]):
        raise NotADirectoryError('%s is not a valid directory' % key)
```


Overlapping Code:
```
ef check_directory(experiment_config, key):
'''Check whether a value in experiment_config is a valid directory'''
if not os.path.isdir(experiment_config[key]):
raise NotADirectoryError('%s is not a valid directory' % 
```
<Overlap Ratio: 0.9774774774774775>

---

--- 273 --
Question ID: b5f59b4df875ffe640240adcba1fb3213170554f_0
Original Code:
```
def find_harris_conrners(image, block_size=2, ksize=5, k=0.04):
    if len(image.shape) > 2:
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    else:
        gray = image
        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
    gray = np.float32(gray)
    dst = cv2.cornerHarris(src=gray, blockSize=block_size, ksize=ksize, k=k)
    dst = cv2.dilate(dst, None)
    image[dst > 0.01 * dst.max()] = [0, 0, 255]
    return image
```


Overlapping Code:
```
size=5, k=0.04):
if len(image.shape) > 2:
gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
else:
gray = image
image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
gray = np.float32(gray)
dst = cv2.cornerHarris(src=gray, blockSize=block_size, ksize=ksize, k=k)
dst = cv2.dilate(dst, None)
image[dst > 0.01 * dst.max()] = [0, 0, 255]
return imag
```
<Overlap Ratio: 0.875>

---

--- 274 --
Question ID: 7f9756bd198259f4ec9807dfa37dfe4657ea08af_4
Original Code:
```
def get_valid_array_idx(idx, last_idx):  # type: (int, int) -> int
    """Return valid array index value within range [0, last_idx].

    Negative values are interpreted such that it represent number of elements before the array end.
    If `idx` is greater than `last_idx` then it is interpreted as `last_idx` value.

    :param idx: The value of index we would like to get.
    :param last_idx: The maximum available index value.
    :return: Valid index value.
    """
    if idx >= 0:
        return min(idx, last_idx)
    else:
        return max(0, last_idx + idx)
```


Overlapping Code:
```
_idx(idx, last_idx): # type: (int, int) -> int
"""Return valid array index value within range [0, last_idx].
Negative values are interpreted such that it represent number of elements before the array end.
If `idx` is greater than `last_idx` then it is interpreted as `last_idx` value.
:param idx: The value of index we would like to get.
:param last_idx: The maximum available index value.
:return: Valid index value.
"""
if idx >= 0:
return min(idx,
```
<Overlap Ratio: 0.8737864077669902>

---

--- 275 --
Question ID: da955bc72241f3381c36db88f3d20e6ae419e9bc_0
Original Code:
```
def main():
    import random
    secretNumber = random.randint(1, 20)
    print('I am thinking of a number between 1 and 20.')

    # Ask the player to guess 6 times.
    for guessesTaken in range(1, 7):
        print('Take a guess.')
        guess = int(input())

        if guess < secretNumber:
            print('Your guess is too low.')
        elif guess > secretNumber:
            print('Your guess is too high.')
        else:
            break  # This condition is the correct guess!

    if guess == secretNumber:
        print('Good job! You guessed my number in ' + str(guessesTaken) + ' guesses!')
    else:
        print('Nope. The number I was thinking of was ' + str(secretNumber))
```


Overlapping Code:
```

import random
secretNumber = random.randint(1, 20)
print('I am thinking of a number between 1 and 20.')
# Ask the player to guess 6 times.
for guessesTaken in range(1, 7):
print('Take a guess.')
guess = int(input())
if guess < secretNumber:
print('Your guess is too low.')
elif guess > secretNumber:
print('Your guess is too high.')
else:
break # This condition is the correct guess!
if guess == secretNumber:
print('Good job! You guessed my number in ' + str(guessesTaken) + ' guesses!')
else:
print('Nope. The number I was thinking of was ' + str(secretNumber))
```
<Overlap Ratio: 0.9808695652173913>

---

--- 276 --
Question ID: a4f974d6fd908df5e0278126e6ccef0c91fd9c8a_2
Original Code:
```
def getDataSets():
    dirList = os.listdir(dataDir)
    #print(dirList)
    dataSets = {}
    #goes through all pickled objects in the bin folder
    for i in dirList:
        num,trash = i.split(".")
        trash,num = num.split("test")
        dataSets[num] = createFeatureDict(dio.getDataBin(dataDir + "\\" + i,cwd = False))
    return dataSets 
```


Overlapping Code:
```
ef getDataSets():
dirList = os.listdir(dataDir)
#print(dirList)
dataSets = {}
#goes through all pickled objects in the bin folder
for i in dirList:
num,trash = i.split(".")
trash,num = num.split("test")
dataSets[num] = createFeatureDict(dio.getDataBin(dataDir + "\\" + i,cwd = False))
return dataS
```
<Overlap Ratio: 0.9867109634551495>

---

--- 277 --
Question ID: 30dd6dfae915ed34007eec1da2366e5dfe9619da_2
Original Code:
```
@register.filter
def generate_price(amount):
    """ Processes decimal prices into strings. """
    if amount == Decimal('0.0'):
        return "Free"
    elif amount == Decimal('-1.0'):
        return "??"
    else:
        return "$" + str(amount)
```


Overlapping Code:
```
t):
""" Processes decimal prices into strings. """
if amount == Decimal('0.0'):
return "Free"
elif amount == Decimal('-1.0'):
return "??"
else:
return
```
<Overlap Ratio: 0.7177033492822966>

---

--- 278 --
Question ID: 164c656c8ecce496596587b9af4549e57bc15ed3_1
Original Code:
```
def reload_working_set():
    """
    Reinitialize the working set
    """
    WS.initialize(db)
```


Overlapping Code:
```
ad_working_set():
"""
Reinitialize the working set
```
<Overlap Ratio: 0.625>

---

--- 279 --
Question ID: 2de2428529b8f22f30f1acb09075bf5cad5f0428_1
Original Code:
```
def gauss_kl_white_diag(q_mu, q_sqrt, num_latent):
    """
    Compute the KL divergence from 

          q(x) = N(q_mu, q_sqrt^2)
    to 
          p(x) = N(0, I)

    We assume num_latent independent distributions, given by the columns of
    q_mu and q_sqrt. 

    q_mu is a matrix, each column contains a mean

    q_sqrt is a matrix, each columnt represents the diagonal of a square-root
        matrix of the covariance. 

    num_latent is an integer: the number of independent distributions (equal to
        the columns of q_mu and q_sqrt). 
    """
 
    KL = 0.5*tf.reduce_sum(tf.square(q_mu)) #Mahalanobis term
    KL += -0.5*tf.cast(tf.shape(q_sqrt)[0]*num_latent, tf.float64) #Constant term.
    KL += -0.5*tf.reduce_sum(tf.log(tf.square(q_sqrt)))#Log determinant of q covariance.
    KL += 0.5*tf.reduce_sum(tf.square(q_sqrt)) # Trace term
    return KL
```


Overlapping Code:
```
_kl_white_diag(q_mu, q_sqrt, num_latent):
"""
Compute the KL divergence from 
q(x) = N(q_mu, q_sqrt^2)
to 
p(x) = N(0, I)
We assume num_latent independent distributions, given by the columns of
q_mu and q_sqrt. 
q_mu is a matrix, each column contains a mean
q_sqrt is a matrix, each columnt represents the diagonal of a square-root
matrix of the covariance. 
num_latent is an integer: the number of independent distributions (equal to
the columns of q_mu and q_sqrt). 
"""

KL = 0.5*tf.reduce_sum(tf.square(q_mu)) #Mahalanobis term
KL += -0.5*tf.cast(tf.shape(q_sqrt)[0]*num_latent, tf.float64) #Constant term.
KL += -0.5*tf.reduce_sum(tf.log(tf.square(q_sqrt)))#Log determinant of q covariance.
KL += 0.5*tf.reduce_sum(tf.square(q_sqrt)) # Trace ter
```
<Overlap Ratio: 0.974025974025974>

---

--- 280 --
Question ID: 553f2162c7f843d98b3a831692120442cf00ce2a_2
Original Code:
```
def add_local_dep(confspec):
    "Add local project relative paths."

    links = confspec['links']
    links['include/math'] = "../../../tksrc/src/math"
    links['include/models'] = "../../../tksrc/src/models"
    links['include/utils'] = "../../../tksrc/src/utils"

    so_suffix = confspec['so-suffix']
    for module in ('Math', 'Models', 'Utils'):
        lib_so = 'libfmtk%s.%s' % (module, so_suffix)
        subdir = module.lower()
        links['lib/' + lib_so] = "../../../src/%s/%s" % (subdir, lib_so)
```


Overlapping Code:
```
 add_local_dep(confspec):
"Add local project relative paths."
links = confspec['links']
links['include/math'] = "../../../tksrc/src/math"
links['include/models'] = "../../../tksrc/src/models"
links['include/utils'] = "../../../tksrc/src/utils"
so_suffix = confspec['so-suffix']
for module in ('Math', 'Models', 'Utils'):
lib_so = 'libfmtk%s.%s' % (module, so_suffix)
subdir = module.lower()
links['lib/' + lib_so] = "../../../src/%s/%s" % (subdir, li
```
<Overlap Ratio: 0.982532751091703>

---

--- 281 --
Question ID: 3d0692dbf1a0c505a61abcc3814a663a56da7d5f_0
Original Code:
```
def set_params(n_rules = 2, n_out = 2, n_steps = 200, coherences=[.5], stim_noise = 0, rec_noise = 0, L1_rec = 0, L2_firing_rate = 0,
                    sample_size = 128, epochs = 100, N_rec = 50, dale_ratio=0.8, tau=100.0, dt = 10.0, biases = True,
               task='n_back', rt_version=False):
    params = dict()
    params['N_in']             = n_rules*2 
    params['N_out']            = n_out
    params['N_batch']          = sample_size
    params['N_steps']          = n_steps
    params['N_rules']          = n_rules
    params['stim_noise']       = stim_noise
    params['rec_noise']        = rec_noise
    params['sample_size']      = sample_size
    params['epochs']           = epochs
    params['N_rec']            = N_rec
    params['dale_ratio']       = dale_ratio
    params['tau']              = tau
    params['dt']               = dt
    params['alpha']            = dt/tau
    params['task']             = task
    params['L1_rec']           = L1_rec
    params['L2_firing_rate']   = L2_firing_rate
    params['biases']           = biases
    params['coherences']       = coherences
    params['rt_version']       = rt_version

    return params
```


Overlapping Code:
```
ps = 200, coherences=[.5], stim_noise = 0, rec_noise = 0, L1_rec = 0, L2_firing_rate = 0,
sample_size = 128, epochs = 100, N_rec = 50, dale_ratio=0.8, tau=100.0, dt = 10.0, biases = True,
task='n_back', rt_version=False):
params = dict()
params['N_in'] = n_rules*2 
params['N_out'] = n_out
params['N_batch'] = sample_size
params['N_steps'] = n_steps
params['N_rules'] = n_rules
params['stim_noise'] = stim_noise
params['rec_noise'] = rec_noise
params['sample_size'] = sample_size
params['epochs'] = epochs
params['N_rec'] = N_rec
params['dale_ratio'] = dale_ratio
params['tau'] = tau
params['dt'] = dt
params['alpha'] = dt/tau
params['task'] = task
params['L1_rec'] = L1_rec
params['L2_firing_rate'] = L2_firing_rate
params['biases'] = biases
params['coherences'] = coherences
params['rt_version'] = 
```
<Overlap Ratio: 0.9216589861751152>

---

--- 282 --
Question ID: 0a645f40829eca8e6b6ba9afcf05b228df692160_9
Original Code:
```
def __pieMissLerpCallback(t, missDict):
    pie = missDict['pie']
    newPos = missDict['startPos'] * (1.0 - t) + missDict['endPos'] * t
    if t < tPieShrink:
        tScale = 0.0001
    else:
        tScale = (t - tPieShrink) / (1.0 - tPieShrink)
    newScale = missDict['startScale'] * max(1.0 - tScale, 0.01)
    pie.setPos(newPos)
    pie.setScale(newScale)
```


Overlapping Code:
```
ct):
pie = missDict['pie']
newPos = missDict['startPos'] * (1.0 - t) + missDict['endPos'] * t
if t < tPieShrink:
tScale = 0.0001
else:
tScale = (t - tPieShrink) / (1.0 - tPieShrink)
newScale = missDict['startScale'] * max(1.0 - tScale, 0.01)
pie.setP
```
<Overlap Ratio: 0.7861635220125787>

---

--- 283 --
Question ID: 3f17b296fc27a7736813d1a434ca813e7b65c5cf_0
Original Code:
```
def format_line(line, max_width=90):
    ''' Ensures that lines of text terminate reasonably even if document has no newlines '''
    line = line.split()
    while len(line) > 0:
        out = line[0]
        line = line[1:]
        while len(line) > 0 and len(out) + len(line[0]) + 1 < max_width:
            out = " ".join([out, line[0]])
            line = line[1:]
        yield out
```


Overlapping Code:
```
at_line(line, max_width=90):
''' Ensures that lines of text terminate reasonably even if document has no newlines '''
line = line.split()
while len(line) > 0:
out = line[0]
line = line[1:]
while len(line) > 0 and len(out) + len(line[0]) + 1 < max_width:
out = " ".join([out, line[0]])
line = line[1:]

```
<Overlap Ratio: 0.9465408805031447>

---

--- 284 --
Question ID: 20d0c59ae01438b38d34599bae71e44fd9ae656a_1
Original Code:
```
def SetIntersectionIndex (backend="numpy",
                          max_sets=2**32,
                          max_symbols=2**16,
                          init_bucket_size=16,
                          support_most_frequent=True,
                          support_find_similar=True):
        """
        Create a new index for finding intersecting sets.
        
        Keyword arguments:
        
        backend (default: "numpy")
            Specific implementation of a set intersection index to use.
            Currently only "numpy" is supported.
        
        max_sets (default: 2**32, min: 1, max: 2**64)
            Maximum number of sets that this index should be able to handle, note that this doesn't mean unique sets,
            but rather all calls to .add().
            The implementation is free to choose a different number at least as high as the given one.
        
        max_symbols (default: 2**16, min: 1, max: 2**64)
            Maximum number of unique symbols (set items) the index should be able to handle.
            The implementation is free to choose a different number at least as high as the given one.
            Currently, max_symbols should not be greater than max_sets.
        
        init_bucket_size (default: 16, min: 4)
            Initial number of elements in arrays holding (set, symbol) mappings, when they are first allocated.
            (The arrays grow automatically.)
        
        support_most_frequent (default: True)
            Boolean indicating whether additional data allowing the determination of most frequently occurring symbols
            should be kept. Required by the .most_frequent() method.
        
        support_find_similar (default: True)
            Boolean indicating whether the size of each added set should be remembered, for calculating normalized
            similarities between sets by the .find_similar() method.
        """
        
        module = _BACKENDS[backend] = _BACKENDS.get (backend, False) or import_backend (backend)
        return module.SetIntersectionIndex (max_sets=max_sets,
                                            max_symbols=max_symbols,
                                            init_bucket_size=init_bucket_size,
                                            support_most_frequent=support_most_frequent,
                                            support_find_similar=support_find_similar)
```


Overlapping Code:
```
dex (backend="numpy",
max_sets=2**32,
max_symbols=2**16,
init_bucket_size=16,
support_most_frequent=True,
support_find_similar=True):
"""
Create a new index for finding intersecting sets.

Keyword arguments:

backend (default: "numpy")
Specific implementation of a set intersection index to use.
Currently only "numpy" is supported.

max_sets (default: 2**32, min: 1, max: 2**64)
Maximum number of sets that this index should be able to handle, note that this doesn't mean unique sets,
but rather all calls to .add().
The implementation is free to choose a different number at least as high as the given one.

max_symbols (default: 2**16, min: 1, max: 2**64)
Maximum number of unique symbols (set items) the index should be able to handle.
The implementation is free to choose a different number at least as high as the given one.
Currently, max_symbols should not be greater than max_sets.

init_bucket_size (default: 16, min: 4)
Initial number of elements in arrays holding (set, symbol) mappings, when they are first allocated.
(The arrays grow automatically.)

support_most_frequent (default: True)
Boolean indicating whether additional data allowing the determination of most frequently occurring symbols
should be kept. Required by the .most_frequent() method.

support_find_similar (default: True)
Boolean indicating whether the size of each added set should be remembered, for calculating normalized
similarities between sets by the .find_similar() method.
"""

module = _BACKENDS[backend] = _BACKENDS.get (backend, False) or import_backend (backend)
return module.SetIntersectionIndex (max_sets=max_sets,
max_symbols=max_symbols,
init_bucket_size=init_bucket_size,
support_most_frequent=support_most_frequent,
support_find_similar=support_fi
```
<Overlap Ratio: 0.9820426487093153>

---

--- 285 --
Question ID: 7a960a00d0a13229af7e7e6d54c95f137034bee8_12
Original Code:
```
def test_peek_after_push_diff_type(one_nine_stack):
    """
    tests for expected repsonse after str type is pushed to
    array
    """
    one_nine_stack.push('a')
    one_nine_stack.peek().val = 'a'
```


Overlapping Code:
```
ush_diff_type(one_nine_stack):
"""
tests for expected repsonse after str type is pushed to
array
"""
one_nine_stack.push('a')
one_nine_stack.peek().va
```
<Overlap Ratio: 0.8426966292134831>

---

--- 286 --
Question ID: fe113738d2252bc64fa7ad75fcb06d08e471e6cc_4
Original Code:
```
def get_between_to_end_of_str(text, from_letter):
	if text is None:
		return ''

	parts = []
	start_saving = False
	for s in text:
		# if you don't have a string then save it 
		if start_saving and not is_alpha(s) and s !='_' :
			return ''.join(parts)
		# add the letters
		if s == from_letter:
			start_saving = True
		elif start_saving:
			parts.append(s) 
	return ''.join (parts)
```


Overlapping Code:
```
m_letter):
if text is None:
return ''
parts = []
start_saving = False
for s in text:
# if you don't have a string then save it 
if start_saving and not is_alpha(s) and s !='_' :
return ''.join(parts)
# add the letters
if s == from_letter:
start_saving = True
elif start_saving:
parts.append(s) 
retur
```
<Overlap Ratio: 0.8426966292134831>

---

--- 287 --
Question ID: 876cbc39df07ecc0f70543e3329ef1e8cd54713d_1
Original Code:
```
def get_or_create_tag(datasource, tag_name, tag_type, units=None):
    if tag_type == "Numeric":
        current_tag_db, was_new = TagNumeric.objects.get_or_create(data_source=datasource, name=tag_name)
        if was_new and units is not None:
            current_tag_db.units = units
            current_tag_db.save
    elif tag_type == "Discrete":
        current_tag_db, was_new = TagDiscrete.objects.get_or_create(data_source=datasource, name=tag_name)
    else:
        current_tag_db, was_new = TagText.objects.get_or_create(data_source=datasource, name=tag_name)
    return current_tag_db
```


Overlapping Code:
```
atasource, tag_name, tag_type, units=None):
if tag_type == "Numeric":
current_tag_db, was_new = TagNumeric.objects.get_or_create(data_source=datasource, name=tag_name)
if was_new and units is not None:
current_tag_db.units = units
current_tag_db.save
elif tag_type == "Discrete":
current_tag_db, was_new = TagDiscrete.objects.get_or_create(data_source=datasource, name=tag_name)
else:
current_tag_db, was_new = TagText.objects.get_or_create(data_source=datasource, name=tag_name)
return current_tag_d
```
<Overlap Ratio: 0.9541984732824428>

---

--- 288 --
Question ID: ca8086bde315c42a3b27cd777fe492722e528038_1
Original Code:
```
def isValidString(strBytes):
	# 1st check: no invalid characters
	for index in range(0, len(strBytes)):
		if (strBytes[index] < 0x20 and strBytes[index] != 0x0D and strBytes[index] != 0x0A and strBytes[index] != 0x09):
			return False
	# 2nd check: needs at least one SJIS japanese symbol (why TL otherwise?)
	for index in range(0, len(strBytes)):
		if strBytes[index] >= 0x81 and strBytes[index] <= 0xEF and strBytes[index] != 0xA0:
			return True
	# no SJIS symbol found
	return False
```


Overlapping Code:
```
t check: no invalid characters
for index in range(0, len(strBytes)):
if (strBytes[index] < 0x20 and strBytes[index] != 0x0D and strBytes[index] != 0x0A and strBytes[index] != 0x09):
return False
# 2nd check: needs at least one SJIS japanese symbol (why TL otherwise?)
for index in range(0, len(strBytes)):
if strBytes[index] >= 0x81 and strBytes[index] <= 0xEF and strBytes[index] != 0xA0:
return Tru
```
<Overlap Ratio: 0.851063829787234>

---

--- 289 --
Question ID: d87d304d48acdb1ed1538ab797886261c63b61d5_10
Original Code:
```
def psf_iteration_compare(kwargs_psf, **kwargs):
    """

    :param kwargs_psf:
    :param kwargs: kwargs to send to matplotlib.pyplot.matshow()
    :return:
    """
    psf_out = kwargs_psf['kernel_point_source']
    psf_in = kwargs_psf['kernel_point_source_init']
    n_kernel = len(psf_in)
    delta_x = n_kernel/20.
    delta_y = n_kernel/10.

    if not 'cmap' in kwargs:
        kwargs['cmap'] = 'seismic'

    f, axes = plt.subplots(1, 3, figsize=(15, 5))
    ax = axes[0]
    im = ax.matshow(np.log10(psf_in), origin='lower', **kwargs)
    v_min, v_max = im.get_clim()
    if not 'vmin' in kwargs:
        kwargs['vmin'] = v_min
    if not 'vmax' in kwargs:
        kwargs['vmax'] = v_max
    divider = make_axes_locatable(ax)
    cax = divider.append_axes("right", size="5%", pad=0.05)
    plt.colorbar(im, cax=cax)
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    ax.text(delta_x, n_kernel-delta_y, "stacked stars", color="k", fontsize=20, backgroundcolor='w')

    ax = axes[1]
    im = ax.matshow(np.log10(psf_out), origin='lower', **kwargs)
    divider = make_axes_locatable(ax)
    cax = divider.append_axes("right", size="5%", pad=0.05)
    plt.colorbar(im, cax=cax)
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    ax.text(delta_x, n_kernel-delta_y, "iterative reconstruction", color="k", fontsize=20, backgroundcolor='w')

    ax = axes[2]
    kwargs_new = copy.deepcopy(kwargs)
    try:
        del kwargs_new['vmin']
        del kwargs_new['vmax']
    except:
        pass
    im = ax.matshow(psf_out-psf_in, origin='lower', vmin=-10**-3, vmax=10**-3, **kwargs_new)
    divider = make_axes_locatable(ax)
    cax = divider.append_axes("right", size="5%", pad=0.05)
    plt.colorbar(im, cax=cax)
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    ax.text(delta_x, n_kernel-delta_y, "difference", color="k", fontsize=20, backgroundcolor='w')
    f.tight_layout()
    return f, axes
```


Overlapping Code:
```
f psf_iteration_compare(kwargs_psf, **kwargs):
"""
:param kwargs_psf:
:param kwargs: kwargs to send to matplotlib.pyplot.matshow()
:return:
"""
psf_out = kwargs_psf['kernel_point_source']
psf_in = kwargs_psf['kernel_point_source_init']
n_kernel = len(psf_in)
delta_x = n_kernel/20.
delta_y = n_kernel/10.
if not 'cmap' in kwargs:
kwargs['cmap'] = 'seismic'
f, axes = plt.subplots(1, 3, figsize=(15, 5))
ax = axes[0]
im = ax.matshow(np.log10(psf_in), origin='lower', **kwargs)
v_min, v_max = im.get_clim()
if not 'vmin' in kwargs:
kwargs['vmin'] = v_min
if not 'vmax' in kwargs:
kwargs['vmax'] = v_max
divider = make_axes_locatable(ax)
cax = divider.append_axes("right", size="5%", pad=0.05)
plt.colorbar(im, cax=cax)
ax.get_xaxis().set_visible(False)
ax.get_yaxis().set_visible(False)
ax.text(delta_x, n_kernel-delta_y, "stacked stars", color="k", fontsize=20, backgroundcolor='w')
ax = axes[1]
im = ax.matshow(np.log10(psf_out), origin='lower', **kwargs)
divider = make_axes_locatable(ax)
cax = divider.append_axes("right", size="5%", pad=0.05)
plt.colorbar(im, cax=cax)
ax.get_xaxis().set_visible(False)
ax.get_yaxis().set_visible(False)
ax.text(delta_x, n_kernel-delta_y, "iterative reconstruction", color="k", fontsize=20, backgroundcolor='w')
ax = axes[2]
kwargs_new = copy.deepcopy(kwargs)
try:
del kwargs_new['vmin']
del kwargs_new['vmax']
except:
pass
im = ax.matshow(psf_out-psf_in, origin='lower', vmin=-10**-3, vmax=10**-3, **kwargs_new)
divider = make_axes_locatable(ax)
cax = divider.append_axes("right", size="5%", pad=0.05)
plt.colorbar(im, cax=cax)
ax.get_xaxis().set_visible(False)
ax.get_yaxis().set_visible(False)
ax.text(delta_x, n_kernel-delta_y, "difference", color="k", fontsize=20, backgroundcolor
```
<Overlap Ratio: 0.977840909090909>

---

--- 290 --
Question ID: ec2cfd42183da10de05b778fc2c9b56540e4c700_1
Original Code:
```
def test_empty_file():
    with pytest.raises(fcmcmp.UsageError) as exc_info:
        fcmcmp.load_experiments(dummy_data / 'empty_file.yml')
    assert "is empty" in str(exc_info.value)
```


Overlapping Code:
```
_file():
with pytest.raises(fcmcmp.UsageError) as exc_info:
fcmcmp.load_experiments(dummy_data / 'empty_file.yml')
assert "is empty" in str(exc_info.v
```
<Overlap Ratio: 0.8875739644970414>

---

--- 291 --
Question ID: 1fd1ae443ba6add1efcda27b28909db98171de84_0
Original Code:
```
def kmeans():
    X = np.array([[1, 2], [1, 4], [1, 0], [4, 2], [4, 4], [4, 0]])
    kmeans = KMeans(n_clusters=2, random_state=0).fit(X)
    kmeans.labels_
    # array([0, 0, 0, 1, 1, 1], dtype=int32)
    kmeans.predict([[0, 0], [4, 4]])
    # array([0, 1], dtype=int32)
    kmeans.cluster_centers_
```


Overlapping Code:
```
 = np.array([[1, 2], [1, 4], [1, 0], [4, 2], [4, 4], [4, 0]])
kmeans = KMeans(n_clusters=2, random_state=0).fit(X)
kmeans.labels_
# array([0, 0, 0, 1, 1, 1], dtype=int32)
kmeans.predict([[0, 0], [4, 4]])
# arra
```
<Overlap Ratio: 0.7749077490774908>

---

--- 292 --
Question ID: 4557b927561edc09b1bb7c16bba141cc3ad465e3_2
Original Code:
```
def goodData(filename):
    """
    Analizes the input CSV file accordingly with correct values and counts null and error values.
    
    The first iteration shows all titles on header and waits for user answer about which
    title must be used for a dictionary key and which ones for respective values.
    
    Returns a dictionary on the form {key:[values]}.
    """
    key, values = urChoice(filename)

    dBuild = {}
    countNull = {'nC':[], 'nH':[], 'nA':[], 'n3':[]}
    highIssues = {'neg':[], 'pos':[], 'eq':[]}
    count_Errors = 0

    with open(filename, 'r') as csvfile:
        ROWS = csv.reader(csvfile, delimiter=',')
        for r in 0:#ROWS:

            # checking blank data
            if r[5] == '':
                countNull['nC'].append(r[0])
            if r[4] == '':
                countNull['nH'].append(r[0])
            if r[10] == '':
                countNull['nA'].append(r[0])
            if (r[4] == '') and (r[5] == '') and (r[10] == ''):
                countNull['n3'].append(r[0])

            try:
                key = int(r[5])

                if r[4] == '':
                    # check if 'base' > 'topo' --> raise ValueError if convertion to float doesn't work --> but WHY?
                    if float(r[2]) > float(r[3]):
                        highIssues['neg'].append(r[0])
                    elif float(r[2]) < float(r[3]):
                        highIssues['pos'].append(r[0])
                    else:
                        highIssues['eq'].append(r[0])
                    height = 0

                else: height = float(r[4])

                if r[10] == '': area = 0
                else: area = float(r[10])

                dBuild[ key ] = [ height, area ]

            except ValueError:
                # values that we don't care
                # if r[5], r[4] or r[10] is the header
                # if r[5] is empty
                count_Errors += 1
                pass

    if True: # fast trick to pass print
        print("# of blank values:")
        for k in countNull: print("\t" + str(k) + ":", len(countNull[k]))
        print('# of height "blank" values:')
        for k in highIssues: print("\t" + str(k) + ":", len(highIssues[k]))
        print("# of errors:", count_Errors, "\nsize of dataset:", len(dBuild))

        x = 5
        for k in dBuild:
            if x == 5: break
            x += 1
            print(k, ":", dBuild[k])

    return dBuild
```


Overlapping Code:
```
f goodData(filename):
"""
Analizes the input CSV file accordingly with correct values and counts null and error values.

The first iteration shows all titles on header and waits for user answer about which
title must be used for a dictionary key and which ones for respective values.

Returns a dictionary on the form {key:[values]}.
"""
key, values = urChoice(filename)
dBuild = {}
countNull = {'nC':[], 'nH':[], 'nA':[], 'n3':[]}
highIssues = {'neg':[], 'pos':[], 'eq':[]}
count_Errors = 0
with open(filename, 'r') as csvfile:
ROWS = csv.reader(csvfile, delimiter=',')
for r in 0:#ROWS:
# checking blank data
if r[5] == '':
countNull['nC'].append(r[0])
if r[4] == '':
countNull['nH'].append(r[0])
if r[10] == '':
countNull['nA'].append(r[0])
if (r[4] == '') and (r[5] == '') and (r[10] == ''):
countNull['n3'].append(r[0])
try:
key = int(r[5])
if r[4] == '':
# check if 'base' > 'topo' --> raise ValueError if convertion to float doesn't work --> but WHY?
if float(r[2]) > float(r[3]):
highIssues['neg'].append(r[0])
elif float(r[2]) < float(r[3]):
highIssues['pos'].append(r[0])
else:
highIssues['eq'].append(r[0])
height = 0
else: height = float(r[4])
if r[10] == '': area = 0
else: area = float(r[10])
dBuild[ key ] = [ height, area ]
except ValueError:
# values that we don't care
# if r[5], r[4] or r[10] is the header
# if r[5] is empty
count_Errors += 1
pass
if True: # fast trick to pass print
print("# of blank values:")
for k in countNull: print("\t" + str(k) + ":", len(countNull[k]))
print('# of height "blank" values:')
for k in highIssues: print("\t" + str(k) + ":", len(highIssues[k]))
print("# of errors:", count_Errors, "\nsize of dataset:", len(dBuild))
x = 5
for k in dBuild:
if x == 5: break
x += 1
print(k, ":", dBui
```
<Overlap Ratio: 0.9875070982396366>

---

--- 293 --
Question ID: 9305b9d74d47329bbb26439c66ef4462dc6354f2_0
Original Code:
```
def create_ecdsap256_key_pair():
    """
    Create a new ECDSAP256 key pair.

    :returns: a tuple of the public and private keys
    """
    pub  = ECDSAP256PublicKey()
    priv = ECDSAP256PrivateKey()
    rc = _lib.xtt_crypto_create_ecdsap256_key_pair(pub.native, priv.native)
    if rc == RC.SUCCESS:
        return (pub, priv)
    else:
        raise error_from_code(rc)
```


Overlapping Code:
```
pair():
"""
Create a new ECDSAP256 key pair.
:returns: a tuple of the public and private keys
"""
pub = ECDSAP256PublicKey()
priv = ECDSAP256PrivateKey()
rc = _lib.xtt_crypto_create_ecdsap256_key_pair(pub.native, priv.native)
if rc == RC.SUCCESS:
ret
```
<Overlap Ratio: 0.7763975155279503>

---

--- 294 --
Question ID: 924dfff69c54a76ea37a4817b208c91d811542c6_4
Original Code:
```
@csrf_exempt
def post_idea(request, owner, repository, full_repository_name):
    """
    Create issue using the user's account if connected with github, otherwise jucybot
    Return the issue HTML object.
    """
    if not request.user.is_authenticated() or request.method != 'POST' or 'title' not in request.POST:
        raise HttpResponseBadRequest()
    try:
        github = GithubWrapper(request)
    except ObjectDoesNotExist:
        github = jucybot.from_config()
    database_repository = get_object_or_404(models.Repository, owner=owner, name=repository)
    issue = github.create_issue(owner, repository, request.POST['title'], request.POST['content'] if 'content' in request.POST and request.POST['content'] else None, labels=['jucy'])
    idea = models.Idea.objects.create(repository=database_repository, number=issue['number'])
    idea.subscribers.add(request.user)
    idea.save()
    issue['total_subscribers'] = 1
    issue['subscribed'] = True
    return render(request, 'include/idea.html', {
        'issue': issue,
        'is_collaborator': github.is_collaborator_on_repo(owner, repository),
        'full_repository_name': full_repository_name,
    })
```


Overlapping Code:
```
tory, full_repository_name):
"""
Create issue using the user's account if connected with github, otherwise jucybot
Return the issue HTML object.
"""
if not request.user.is_authenticated() or request.method != 'POST' or 'title' not in request.POST:
raise HttpResponseBadRequest()
try:
github = GithubWrapper(request)
except ObjectDoesNotExist:
github = jucybot.from_config()
database_repository = get_object_or_404(models.Repository, owner=owner, name=repository)
issue = github.create_issue(owner, repository, request.POST['title'], request.POST['content'] if 'content' in request.POST and request.POST['content'] else None, labels=['jucy'])
idea = models.Idea.objects.create(repository=database_repository, number=issue['number'])
idea.subscribers.add(request.user)
idea.save()
issue['total_subscribers'] = 1
issue['subscribed'] = True
return render(request, 'include/idea.html', {
'issue': issue,
'is_collaborator': github.is_collaborator_on_repo(owner, repository),
'full_repository_name': full_re
```
<Overlap Ratio: 0.9380863039399625>

---

--- 295 --
Question ID: 38df47c9261a14b27353688a69c605924a32c6e3_36
Original Code:
```
@_endpoint_route('/annotations/delete-paraphrase-question')
@respond_with_json
@requires_auth
def _delete_paraphrase_question(request):
    question_id = required_parameter(request, 'questionId')
    return {'questionId': question_id}
```


Overlapping Code:
```
ndpoint_route('/annotations/delete-paraphrase-question')
@respond_with_json
@requires_auth
def _delete_paraphrase_question(request):
question_id = required_parameter(request, 'questionId')
return {'questionId': question_i
```
<Overlap Ratio: 0.9778761061946902>

---

--- 296 --
Question ID: 00a96ebd907765e144a48d9ec002f49b9336588e_0
Original Code:
```
def update():
    line_renderer.model.vertices = [e.position for e in points]
    line_renderer.model.generate()
    mover_2.look_at_2d(mover)
    # mover_2.position += mover_2.up * mover_2.speed * time.dt
    mover_2.position = lerp(mover_2.position, mover.position, time.dt*2)
```


Overlapping Code:
```
enderer.model.vertices = [e.position for e in points]
line_renderer.model.generate()
mover_2.look_at_2d(mover)
# mover_2.position += mover_2.up * mover_2.speed * time.dt
mover_2.position = lerp(mover_
```
<Overlap Ratio: 0.7751937984496124>

---

--- 297 --
Question ID: b15ca009ea22fb9c3447d2709388472b417f2fe8_5
Original Code:
```
def main():
    """
    Steps if script is run directly
    """
    args = parse_args()

    # Change log level if using verbose
    if args.verbose:
        logging.basicConfig(
            format="%(levelname)s: %(message)s",
            level=logging.DEBUG)
        logging.info("Verbose logging.")
        logging.debug("Supplied Arguments: %s", args)
        logging.debug("Version: %s", VERINFO)
    else:
        logging.basicConfig(format="%(message)s", level=logging.INFO)

    lc_results = find_asg_using_amis(args.ami_ids)
    ec2_results = find_ec2_using_amis(args.ami_ids)

    output = {}
    for ami_id in args.ami_ids:
        output[ami_id] = {
            'lcs': lc_results[ami_id],
            'ec2': ec2_results[ami_id],
            }
    print(json.dumps(output))
```


Overlapping Code:
```
in():
"""
Steps if script is run directly
"""
args = parse_args()
# Change log level if using verbose
if args.verbose:
logging.basicConfig(
format="%(levelname)s: %(message)s",
level=logging.DEBUG)
logging.info("Verbose logging.")
logging.debug("Supplied Arguments: %s", args)
logging.debug("Version: %s", VERINFO)
else:
logging.basicConfig(format="%(message)s", level=logging.INFO)
lc_results = find_asg_using_amis(args.ami_ids)
ec2_results = find_ec2_using_amis(args.ami_ids)
output = {}
for ami_id in args.ami_ids:
output[ami_id] = {
'lcs': lc_results[ami_id],
'ec2': ec2_results[ami_id],
}
print(
```
<Overlap Ratio: 0.96>

---

--- 298 --
Question ID: f2009f7fd850dbd721b9c039c9c30e5358e18cb6_5
Original Code:
```
@app.route('/dashboard', methods=['GET', 'POST'])
@is_logged_in
def dashboard():
    if category_data:
        email = session['email']
        try:
            return render_template('dashboard.html', category_list=category_data[email], email=email)
        except KeyError:
            flash('Create a Recipe Category', 'red')
            return render_template('dashboard.html')

    else:
        flash('Create a Recipe Category', 'red')
        return render_template('dashboard.html')
```


Overlapping Code:
```
@app.route('/dashboard', methods=['GET', 'POST'])
@is_logged_in
def dashboard():
if category_data:
email = session['email']
try:
return render_template('dashboard.html', category_list=category_data[email], email=email)
except KeyError:
flash('Create a Recipe Category', 'red')
return render_template('dashboard.html')
else:
flash('Create a Recipe Category', 'red')
return render_template('dashboa
```
<Overlap Ratio: 0.9777777777777777>

---

--- 299 --
Question ID: ec1cc5b117d52708295b3193208fc2c8a9d02fe7_6
Original Code:
```
def send_file(sftp, target_file, source_path):
    """
    Upload @source_path to @target_dir through @sftp
    """
    with open(source_path, 'rb') as fSource:
        with sftp.file(target_file, 'wb') as fTarget:
            while True:
                copy_buffer = fSource.read(4096)
                if not copy_buffer:
                    break
                fTarget.write(copy_buffer)
```


Overlapping Code:
```
 source_path):
"""
Upload @source_path to @target_dir through @sftp
"""
with open(source_path, 'rb') as fSource:
with sftp.file(target_file, 'wb') as fTarget:
while True:
copy_buffer = fSource.read(4096)
if not copy_buffer:
break
fTarget.write(copy_b
```
<Overlap Ratio: 0.8680555555555556>

---

--- 300 --
Question ID: ecfde9906977a8aed79ef1b62e6ce752015cdf56_2
Original Code:
```
def gcm_send_message(device, message, data=None, collapse_key=None, delay_while_idle=False, time_to_live=0):
    """
    Sends a GCM notification to a single registration_id.

    This will send the notification as form data if possible, otherwise it will
    fall back to json data.
    """
    data["message"] = message
    args = data, collapse_key, delay_while_idle, time_to_live
    try:
        return _gcm_send_plain(device, *args)
    except GCMError:
        # TODO: check error and maybe deactivate user
        return False
```


Overlapping Code:
```
data=None, collapse_key=None, delay_while_idle=False, time_to_live=0):
"""
Sends a GCM notification to a single registration_id.
This will send the notification as form data if possible, otherwise it will
fall back to json data.
"""
data["message"] = message
args = data, collapse_key, delay_while_idle, time_to_live
try:
return _gcm_send_plain(device, *args)
except GCMError:
# TODO: check error and
```
<Overlap Ratio: 0.8456659619450317>

---

--- 301 --
Question ID: 8246eeb2f76437680073f3d376dbef3bc6cf0df9_1
Original Code:
```
def grab_latest_content():
    json_dict = {}
    for i in SESSIONS:
        r = requests.get('{1}/Session{0}/session_{0}_problems.md'.format(i, ROOT_URL)).text
        key = 'session_{0}'.format(i)
        json_dict[key] = markdown.markdown(r, extensions=EXTENTIONS)
    return json_dict
```


Overlapping Code:
```
t():
json_dict = {}
for i in SESSIONS:
r = requests.get('{1}/Session{0}/session_{0}_problems.md'.format(i, ROOT_URL)).text
key = 'session_{0}'.format(i)
json_dict[key] = markdown.markdown(r, extension
```
<Overlap Ratio: 0.7936507936507936>

---

--- 302 --
Question ID: 7d817f751ddab505219f00053d70e33baf50f601_0
Original Code:
```
def test_error_raises_invalid_type(auth_client):
    """Test that an error is raised with inproper input type."""
    with pytest.raises(ValueError):
        auth_client.create_transaction(model='invalid_transaction')
```


Overlapping Code:
```
s_invalid_type(auth_client):
"""Test that an error is raised with inproper input type."""
with pytest.raises(ValueError):
auth_client.create_transacti
```
<Overlap Ratio: 0.746268656716418>

---

--- 303 --
Question ID: ed57d9b3d5c189b14f763887cc109fe1deb8b0e7_1
Original Code:
```
def step(model, sentence, choices, verbose=0):
    vec = w2v(sentence)
    idx = len(sentence) - 1# with just <start>, len is 1. we want post over start, so subtract 1
    probs = model.model.predict(vec)[0,idx,:]
    best = 0.
    best_word = ""
    best_idx = -1
    decisions = []
    for i, word in enumerate(choices):
        word_val = probs[model.igor.vocabs.words[word]]
        decisions.append((word, word_val))
        if word_val > best:
            best = word_val
            best_word = word
            best_idx = i
    #if verbose:
    #    print("selecting {}".format(best_word))
    #    print("-------")
    return sentence + [best_word], best_idx, decisions
```


Overlapping Code:
```
ef step(model, sentence, choices, verbose=0):
vec = w2v(sentence)
idx = len(sentence) - 1# with just <start>, len is 1. we want post over start, so subtract 1
probs = model.model.predict(vec)[0,idx,:]
best = 0.
best_word = ""
best_idx = -1
decisions = []
for i, word in enumerate(choices):
word_val = probs[model.igor.vocabs.words[word]]
decisions.append((word, word_val))
if word_val > best:
best = word_val
best_word = word
best_idx = i
#if verbose:
# print("selecting {}".format(best_word))
# print("-------")
return sentence + [best_word], best_i
```
<Overlap Ratio: 0.975177304964539>

---

--- 304 --
Question ID: 77ddde3673bb0c6e02fa532ee8ea3566c180a568_3
Original Code:
```
def perm():
    for i in range(start, end):
        cube = str(i**3)
        perms = permutations(cube)
        perms = list(set(perms))
        #perms = map(perm_to_float, perms)
        #perms = list(filter(is_cube, perms))
        perms = list(filter(is_cube_perm, perms))
        print(i)
        if len(perms) >= 3:
            print(i, len(perms))
```


Overlapping Code:
```
cube = str(i**3)
perms = permutations(cube)
perms = list(set(perms))
#perms = map(perm_to_float, perms)
#perms = list(filter(is_cube, perms))
perms = list(filter(is_cube_perm, perms))
print(i)
if len(
```
<Overlap Ratio: 0.7326007326007326>

---

--- 305 --
Question ID: beff5a19b7d3a52d3518535dabf124e51e12f614_5
Original Code:
```
def generate_string_to_sign(date, region, canonical_request):
    """
    Generate string to sign.

    :param date: Date is input from :meth:`datetime.datetime`
    :param region: Region should be set to bucket region.
    :param canonical_request: Canonical request generated previously.
    """
    formatted_date_time = date.strftime("%Y%m%dT%H%M%SZ")

    canonical_request_hasher = hashlib.sha256()
    canonical_request_hasher.update(canonical_request.encode('utf-8'))
    canonical_request_sha256 = canonical_request_hasher.hexdigest()
    scope = generate_scope_string(date, region)

    return '\n'.join([_SIGN_V4_ALGORITHM,
                      formatted_date_time,
                      scope,
                      canonical_request_sha256])
```


Overlapping Code:
```
ef generate_string_to_sign(date, region, canonical_request):
"""
Generate string to sign.
:param date: Date is input from :meth:`datetime.datetime`
:param region: Region should be set to bucket region.
:param canonical_request: Canonical request generated previously.
"""
formatted_date_time = date.strftime("%Y%m%dT%H%M%SZ")
canonical_request_hasher = hashlib.sha256()
canonical_request_hasher.update(canonical_request.encode('utf-8'))
canonical_request_sha256 = canonical_request_hasher.hexdigest()
scope = generate_scope_string(date, region)
return '\n'.join([_SIGN_V4_ALGORITHM,
formatted_date_time,
scope,
canonical_request_s
```
<Overlap Ratio: 0.987460815047022>

---

--- 306 --
Question ID: 2afbf2da74a7aae7b5940213796c628982250aa7_7
Original Code:
```
def print_experiment_record_argtable(records):
    """
    Print a table comparing experiment arguments and their results.
    """
    funtion_names = [record.info.get_field(ExpInfoFields.FUNCTION) for record in records]
    args = [record.info.get_field(ExpInfoFields.ARGS) for record in records]
    results = [record.get_result(err_if_none=False) for record in records]

    common_args, different_args = separate_common_items(args)

    record_ids = [record.get_id() for record in records]

    def lookup_fcn(record_id, column):
        index = record_ids.index(record_id)
        if column=='Function':
            return funtion_names[index]
        elif column=='Run Time':
            return records[index].info.get_field_text(ExpInfoFields.RUNTIME)
        elif column=='Common Args':
            return ', '.join('{}={}'.format(k, v) for k, v in common_args)
        elif column=='Different Args':
            return ', '.join('{}={}'.format(k, v) for k, v in different_args[index])
        elif column=='Result':
            return get_oneline_result_string(records[index])
        else:
            bad_value(column)

    rows = build_table(lookup_fcn,
        row_categories=record_ids,
        column_categories=['Function', 'Run Time', 'Common Args', 'Different Args', 'Result'],
        prettify_labels=False
        )

    print(tabulate(rows))
```


Overlapping Code:
```
eriment_record_argtable(records):
"""
Print a table comparing experiment arguments and their results.
"""
funtion_names = [record.info.get_field(ExpInfoFields.FUNCTION) for record in records]
args = [record.info.get_field(ExpInfoFields.ARGS) for record in records]
results = [record.get_result(err_if_none=False) for record in records]
common_args, different_args = separate_common_items(args)
record_ids = [record.get_id() for record in records]
def lookup_fcn(record_id, column):
index = record_ids.index(record_id)
if column=='Function':
return funtion_names[index]
elif column=='Run Time':
return records[index].info.get_field_text(ExpInfoFields.RUNTIME)
elif column=='Common Args':
return ', '.join('{}={}'.format(k, v) for k, v in common_args)
elif column=='Different Args':
return ', '.join('{}={}'.format(k, v) for k, v in different_args[index])
elif column=='Result':
return get_oneline_result_string(records[index])
else:
bad_value(column)
rows = build_table(lookup_fcn,
row_categories=record_ids,
column_categories=['Function', 'Run Time', 'Common Args', 'Different Args', 'Result'],
prettify_labels=False
)
print(tabu
```
<Overlap Ratio: 0.9791847354726799>

---

--- 307 --
Question ID: 8a0f208cf50b13168ae5ac7f2e2b0971910ec1a2_10
Original Code:
```
def get_key(timeout=None):
    init_terminal()
    with terminal.cbreak():
        return terminal.inkey(timeout=timeout)
```


Overlapping Code:
```
init_terminal()
with terminal.cbreak():
return ter
```
<Overlap Ratio: 0.47619047619047616>

---

--- 308 --
Question ID: 8cd8527dcae517b1a1bb913ab6531b6e6cece151_0
Original Code:
```
def selectCenters(image, centers, size):
    size = int(size)
    padded = pad(image, size, 'constant')
    return array([padded[center[0]:center[0]+2*size+1,center[1]:center[1]+2*size+1] for center in centers])
```


Overlapping Code:
```
ize = int(size)
padded = pad(image, size, 'constant')
return array([padded[center[0]:center[0]+2*size+1,center[1]:center[1]+2*size+1] for center in ce
```
<Overlap Ratio: 0.7537688442211056>

---

--- 309 --
Question ID: 214dcf86580adc11e3dab76c3a77e8e0f350eebd_1
Original Code:
```
def navigator(years, current):
    """`years` is an iterable of :class:`BloggerYear` instances.
    """
    if len(years) < 2:
        return ""
    chunks = []
    for y in years:
        if y == current:
            chunks.append(str(y.year))
        else:
            chunks.append(
                ":doc:`{0} <{1}>`".format(y.year, year2docname(y)))
    old = ' '.join(chunks)
    return "\n\n{0}\n\n".format(old)
```


Overlapping Code:
```
ears, current):
"""`years` is an iterable of :class:`BloggerYear` instances.
"""
if len(years) < 2:
return ""
chunks = []
for y in years:
if y == current:
chunks.append(str(y.year))
else:
chunks.append(
":doc:`{0} <{1}>`".format(y.year, year2docname(y)))
old = ' '.join(chunks)
return "\n\n{0}\n\n".f
```
<Overlap Ratio: 0.9230769230769231>

---

--- 310 --
Question ID: 345953517a76826ec606ef9b1ea1d2e49f55af66_0
Original Code:
```
def run(base_url='http://kolibridemo.learningequality.org', learners=3):
    rate = 10
    admin = AdminUser(base_url=base_url)
    KolibriUserBehavior.KOLIBRI_USERS = admin.get_users()
    resources = admin.get_resources()
    exercise = [] if not resources['exercise'] else resources['exercise']
    html5 = [] if not resources['html5'] else resources['html5']
    KolibriUserBehavior.KOLIBRI_RESOURCES = {'video': [], 'html5': html5, 'document': [], 'exercise': exercise}
    launch(WebsiteUser, base_url, learners, rate, run_time=30)
```


Overlapping Code:
```
un(base_url='http://kolibridemo.learningequality.org', learners=3):
rate = 10
admin = AdminUser(base_url=base_url)
KolibriUserBehavior.KOLIBRI_USERS = admin.get_users()
resources = admin.get_resources()
exercise = [] if not resources['exercise'] else resources['exercise']
html5 = [] if not resources['html5'] else resources['html5']
KolibriUserBehavior.KOLIBRI_RESOURCES = {'video': [], 'html5': html5, 'document': [], 'exercise': exercise}
launch(WebsiteUser, base_url, learners, rate, run_time=30)
```
<Overlap Ratio: 0.9900990099009901>

---

--- 311 --
Question ID: d3d69168a927610239335d1b46a4e0afe4b0e6b0_189
Original Code:
```
def test_where():
    ray_df = create_test_dataframe()

    with pytest.raises(NotImplementedError):
        ray_df.where(None)
```


Overlapping Code:
```
e():
ray_df = create_test_dataframe()
with pytest.raises(NotImplementedError):
ray_df.
```
<Overlap Ratio: 0.7818181818181819>

---

--- 312 --
Question ID: a874b8b7c27634c424254598b209bd69c6360f31_4
Original Code:
```
def dset_to_binary_file(data_set, out_file, chan_list=None, chunk_size=8000000):
    """
    :param data_set: a table from an h5 file to write to a binary. has to be daughter of a rec
    :param out_file: binary file - has to be open in 'w' mode.
    :param chan_list: list of channels (must be list or tuple). Default (None) will do the whole table
    :param chunk_size: size in samples of the chunk
    :return:
    """
    samples_data = data_set.shape[0]
    channels_data = data_set.shape[1]
    data_type = data_set.dtype
    logging.info('Ripping dataset from {}'.format(data_set.parent.name))
    if chan_list is None:
        logging.debug('Counting channels')
        chan_list = range(channels_data)
    logging.info('Channel list: {}'.format(chan_list))

    samples_chunk = min(chunk_size, samples_data)
    channels_chunk = len(chan_list)

    chunk_buffer = np.empty((samples_chunk, channels_chunk), dtype=np.dtype(data_type))
    chunk_starts = np.arange(0, samples_data, samples_chunk)
    n_chunks = chunk_starts.size

    logging.info('About to store {} entire chunks'.format(n_chunks - 1))
    for start in chunk_starts:
        logging.info('Chunk start: {0}'.format(start))
        end = min(start + samples_chunk, samples_data)
        chunk_buffer[0: end - start, :] = load_table_slice(data_set,
                                                           np.arange(start, end),
                                                           chan_list)
        out_file.write(chunk_buffer[0: end - start].astype(np.dtype(data_type)).tostring())

    stored = n_chunks * chunk_buffer.size + chunk_buffer[0: end - start, :].size
    logging.info('{} elements written'.format(stored))
    return stored
```


Overlapping Code:
```
file(data_set, out_file, chan_list=None, chunk_size=8000000):
"""
:param data_set: a table from an h5 file to write to a binary. has to be daughter of a rec
:param out_file: binary file - has to be open in 'w' mode.
:param chan_list: list of channels (must be list or tuple). Default (None) will do the whole table
:param chunk_size: size in samples of the chunk
:return:
"""
samples_data = data_set.shape[0]
channels_data = data_set.shape[1]
data_type = data_set.dtype
logging.info('Ripping dataset from {}'.format(data_set.parent.name))
if chan_list is None:
logging.debug('Counting channels')
chan_list = range(channels_data)
logging.info('Channel list: {}'.format(chan_list))
samples_chunk = min(chunk_size, samples_data)
channels_chunk = len(chan_list)
chunk_buffer = np.empty((samples_chunk, channels_chunk), dtype=np.dtype(data_type))
chunk_starts = np.arange(0, samples_data, samples_chunk)
n_chunks = chunk_starts.size
logging.info('About to store {} entire chunks'.format(n_chunks - 1))
for start in chunk_starts:
logging.info('Chunk start: {0}'.format(start))
end = min(start + samples_chunk, samples_data)
chunk_buffer[0: end - start, :] = load_table_slice(data_set,
np.arange(start, end),
chan_list)
out_file.write(chunk_buffer[0: end - start].astype(np.dtype(data_type)).tostring())
stored = n_chunks * chunk_buffer.size + chunk_buffer[0: end - start, :].size
logging.info('{} elements 
```
<Overlap Ratio: 0.9608785175017158>

---

--- 313 --
Question ID: 224f8466d20ea6fbfbf0bcf76d5ef3cc0013b18c_5
Original Code:
```
def Reject(request):
    f=Friend.objects.get(id=request.GET.get("id"))
    f.status=2
    f.save()
    res = redirect("Welcome")
    return res
```


Overlapping Code:
```
t(request):
f=Friend.objects.get(id=request.GET.get("id"))
f.status=2
f.sav
```
<Overlap Ratio: 0.6048387096774194>

---

--- 314 --
Question ID: a4559ffde5465496c709e5729d790051fb880309_1
Original Code:
```
def test_modules_test_no_name_no_prompts(self):
    """Test the check_inputs() function - raise UserWarning prompts are deactivated and module name is not provided."""
    cwd = os.getcwd()
    os.chdir(self.nfcore_modules)
    meta_builder = nf_core.modules.ModulesTest(None, True, "")
    with pytest.raises(UserWarning) as excinfo:
        meta_builder._check_inputs()
    os.chdir(cwd)
    assert "Tool name not provided and prompts deactivated." in str(excinfo.value)
```


Overlapping Code:
```
e_no_prompts(self):
"""Test the check_inputs() function - raise UserWarning prompts are deactivated and module name is not provided."""
cwd = os.getcwd()
os.chdir(self.nfcore_modules)
meta_builder = nf_core.modules.ModulesTest(None, True, "")
with pytest.raises(UserWarning) as excinfo:
meta_builder._check_inputs()
os.chdir(cwd)
assert "Tool name not provided and prompts deactivated." in str(excinf
```
<Overlap Ratio: 0.9174311926605505>

---

--- 315 --
Question ID: 92e133c01edbde47beda7f549525f67aa77057b1_8
Original Code:
```
@mock.patch(
    "cumulusci.core.dependencies.dependencies.install_package_by_namespace_version"
)
def test_install_dependency_installs_managed_package(
    install_package_by_namespace_version,
):
    task = create_task(
        UpdateDependencies,
        {
            "dependencies": [
                {
                    "namespace": "ns",
                    "version": "1.0",
                }
            ]
        },
    )
    task.org_config = mock.Mock()
    task.org_config.installed_packages = {}
    task.org_config.has_minimum_package_version.return_value = False

    task._install_dependency(task.dependencies[0])
    install_package_by_namespace_version.assert_called_once_with(
        task.project_config,
        task.org_config,
        "ns",
        "1.0",
        mock.ANY,
        retry_options=mock.ANY,  # Ignore the options
    )
```


Overlapping Code:
```
ock.patch(
"cumulusci.core.dependencies.dependencies.install_package_by_namespace_version"
)
def test_install_dependency_installs_managed_package(
install_package_by_namespace_version,
):
task = create_task(
UpdateDependencies,
{
"dependencies": [
{
"namespace": "ns",
"version": "1.0",
}
]
},
)
task.org_config = mock.Mock()
task.org_config.installed_packages = {}
task.org_config.has_minimum_package_version.return_value = False
task._install_dependency(task.dependencies[0])
install_package_by_namespace_version.assert_called_once_with(
task.project_config,
task.org_config,
"ns",
"1.0",
mock.ANY,
retry_
```
<Overlap Ratio: 0.9352850539291218>

---

--- 316 --
Question ID: 3b096e61336f791b46468ea40a30af4348efd0c3_0
Original Code:
```
def graph_from_sif (filename, force_undirected = False):
	""" Import a Cytoscape SIF-formatted graph as a NetworkX directed graph (DiGraph object)

		arguments:
			filename (mandatory) - name of a SIF-formatted file
			force_undirected (optional; default: False) - if True, will return
				an undirected (Graph object) rather than a directed graph (DiGraph object)

		See http://wiki.cytoscape.org/Cytoscape_User_Manual/Network_Formats
	"""
	g = networkx.DiGraph()
	fh = open(filename, "rU")

	while True:
		line = fh.readline()
		if (line == ''):
			break

		line = line.strip()
		if (line == ''):
			continue

		# according to the SIF format documentation, a tab character present in a line
		# means the elements of this line must be separated with a tab, and not spaces
		if ('\t' in line):
			elements = line.split('\t')
		else:
			elements = line.split(' ')

		if (len(elements) != 3):
			raise ValueError("invalid line '%s'" % line)

		node_a, edge_type, node_b = elements
		g.add_edge(node_a, node_b, type = edge_type)

	if (force_undirected):
		return g.to_undirected()
	else:
		return g
```


Overlapping Code:
```
ndirected = False):
""" Import a Cytoscape SIF-formatted graph as a NetworkX directed graph (DiGraph object)
arguments:
filename (mandatory) - name of a SIF-formatted file
force_undirected (optional; default: False) - if True, will return
an undirected (Graph object) rather than a directed graph (DiGraph object)
See http://wiki.cytoscape.org/Cytoscape_User_Manual/Network_Formats
"""
g = networkx.DiGraph()
fh = open(filename, "rU")
while True:
line = fh.readline()
if (line == ''):
break
line = line.strip()
if (line == ''):
continue
# according to the SIF format documentation, a tab character present in a line
# means the elements of this line must be separated with a tab, and not spaces
if ('\t' in line):
elements = line.split('\t')
else:
elements = line.split(' ')
if (len(elements) != 3):
raise ValueError("invalid line '%s'" % line)
node_a, edge_type, node_b = elements
g.add_edge(node_a, node_b, type = edge_type)
if (force_undirected):

```
<Overlap Ratio: 0.9259259259259259>

---

--- 317 --
Question ID: 453b0cfe1fea3102dce6c2fd9c13911e161ca3ce_13
Original Code:
```
@gradient(4.0, 5.0, backend=backend_all)
def test_simple_closure(a, b):
    """Test some trivial closures."""

    def f():
        return a + 1.0

    def g():
        return b + 2.0

    return f() * g()
```


Overlapping Code:
```
nd=backend_all)
def test_simple_closure(a, b):
"""Test some trivial closures."""
def f():
return a + 1.0
def g():
return b + 2.0
retu
```
<Overlap Ratio: 0.7823529411764706>

---

--- 318 --
Question ID: c3b98756f25895baff7dda02e966999c7ad4a8be_2
Original Code:
```
def test_check_single_model_access(mock, tmpdir, test_data_path):
    mock.when(
        'POST /login'
    ).reply(
        '"security-token"',
        headers={'Content-Type': 'application/json'},
        times=FOREVER)
    mock.when(
        'POST /access/list',
        body=".+\"test_user\".+",
        headers={'Authorization': 'Bearer security-token'}
    ).reply('[true]',
            headers={'Content-Type': 'application/json'},
            times=FOREVER)
    mock.when(
        'POST /access/list',
        body=".+\"non_granted_user\".+",
        headers={'Authorization': 'Bearer security-token'}
    ).reply(
        '[false]',
        headers={'Content-Type': 'application/json'},
        times=FOREVER)
    test_props = create_local_testdb(db_path=tmpdir,
                                     data_path=test_data_path / 'testdb',
                                     auth_url=mock.pretend_url)

    mp = ixmp.Platform(dbprops=test_props)
    mp.set_log_level('DEBUG')

    granted = mp.check_access('test_user', 'test_model')
    assert granted

    granted = mp.check_access('non_granted_user', 'test_model')
    assert not granted

    granted = mp.check_access('non_existing_user', 'test_model')
    assert not granted
```


Overlapping Code:
```
def test_check_single_model_access(mock, tmpdir, test_data_path):
mock.when(
'POST /login'
).reply(
'"security-token"',
headers={'Content-Type': 'application/json'},
times=FOREVER)
mock.when(
'POST /access/list',
body=".+\"test_user\".+",
headers={'Authorization': 'Bearer security-token'}
).reply('[true]',
headers={'Content-Type': 'application/json'},
times=FOREVER)
mock.when(
'POST /access/list',
body=".+\"non_granted_user\".+",
headers={'Authorization': 'Bearer security-token'}
).reply(
'[false]',
headers={'Content-Type': 'application/json'},
times=FOREVER)
test_props = create_local_testdb(db_path=tmpdir,
data_path=test_data_path / 'testdb',
auth_url=mock.pretend_url)
mp = ixmp.Platform(dbprops=test_props)
mp.set_log_level('DEBUG')
granted = mp.check_access('test_user', 'test_model')
assert granted
granted = mp.check_access('non_granted_user', 'test_model')
assert not granted
granted = mp.check_access('non_existing_user', 'test_model')
assert not grante
```
<Overlap Ratio: 0.9989690721649485>

---

--- 319 --
Question ID: b113786163b690375e45a351d4ca53cd2e4c5754_0
Original Code:
```
def calculate_stride(var: Variable, axis: Axis) -> Union[int, Placeholder]:
    """
    calculate stride for specified dimension of specified variable.

    :param var: variable
    :param axis: axis
    :return: 
    """
    return mul(var.shape[var.order.axes_dict[axis] + 1:])
```


Overlapping Code:
```
tride(var: Variable, axis: Axis) -> Union[int, Placeholder]:
"""
calculate stride for specified dimension of specified variable.
:param var: variable
:param axis: axis
:return: 
"""
return mul(var.sha
```
<Overlap Ratio: 0.8>

---

--- 320 --
Question ID: 3ced3da168b0c4d5fb8345ab35a6e8f79cade777_1
Original Code:
```
@WebGLDescriptorGenerator.register_handler(SplitAxis)
def split_axis(op: SplitAxis) -> List[Kernel]:
    x = op.inputs["x"]
    ys = [op.outputs[f"y{i}"] for i in range(len(op.outputs))]
    sections = [0] + op.sections
    axis = op.axis

    kernels = []

    for i, y in enumerate(ys):
        assert x.order.check_same_axes(y.order)
        assert ChannelMode.get(x) == ChannelMode.get(y) == ChannelModeEnum.R

        name_injector = KernelNameInjector(op)
        uniform_injector = UniformInjector()

        offset = [sections[i] if a == axis else 0 for a in y.order.axes]
        uniform_injector.register({
            "sampler_x": x,

            "texture_stride_y": texture_stride(y),
            "variable_shape_y": _pad_to_4d(y.shape),
            "variable_stride_y": _pad_to_4d(y.stride),

            "texture_shape_x": texture_shape(x),
            "texture_stride_x": texture_stride(x),
            "variable_shape_x": _pad_to_4d([x.shape_dict[a] for a in y.order.axes]),
            "variable_stride_x": _pad_to_4d([x.stride_dict[a] for a in y.order.axes]),

            "offset": _pad_to_4d(offset, 0)
        })

        source = template
        source = uniform_injector.inject(source)
        source = name_injector.inject(source)
        kernel = Kernel(
            source,
            name_injector.name,
            uniform_injector.samplers,
            uniform_injector.uniforms,
            y
        )
        kernels.append(kernel)

    return kernels
```


Overlapping Code:
```
or.register_handler(SplitAxis)
def split_axis(op: SplitAxis) -> List[Kernel]:
x = op.inputs["x"]
ys = [op.outputs[f"y{i}"] for i in range(len(op.outputs))]
sections = [0] + op.sections
axis = op.axis
kernels = []
for i, y in enumerate(ys):
assert x.order.check_same_axes(y.order)
assert ChannelMode.get(x) == ChannelMode.get(y) == ChannelModeEnum.R
name_injector = KernelNameInjector(op)
uniform_injector = UniformInjector()
offset = [sections[i] if a == axis else 0 for a in y.order.axes]
uniform_injector.register({
"sampler_x": x,
"texture_stride_y": texture_stride(y),
"variable_shape_y": _pad_to_4d(y.shape),
"variable_stride_y": _pad_to_4d(y.stride),
"texture_shape_x": texture_shape(x),
"texture_stride_x": texture_stride(x),
"variable_shape_x": _pad_to_4d([x.shape_dict[a] for a in y.order.axes]),
"variable_stride_x": _pad_to_4d([x.stride_dict[a] for a in y.order.axes]),
"offset": _pad_to_4d(offset, 0)
})
source = template
source = uniform_injector.inject(source)
source = name_injector.inject(source)
kernel = Kernel(
source,
name_injector.name,
uniform_injector.samplers,
uniform_injector.uniforms,
y
)
ke
```
<Overlap Ratio: 0.9506802721088435>

---

--- 321 --
Question ID: c2f181d318d1c95b5c4ad17b3e56ea0f34900001_0
Original Code:
```
def make_phrase_from(obj):
    if type(obj) == type(()):
        if len(obj) == 1:
            if obj[0].__class__ == Should:
                return obj[0]
            else:
                obj = obj[0]
        if len(obj) == 2:
            return Verify(*obj)
        else:
            return Phrase(obj[0], obj[1], obj[2:])
    else:
        return obj
```


Overlapping Code:
```
ke_phrase_from(obj):
if type(obj) == type(()):
if len(obj) == 1:
if obj[0].__class__ == Should:
return obj[0]
else:
obj = obj[0]
if len(obj) == 2:
return Verify(*obj)
else:
return Phrase(obj[0], obj[1], obj[2:])
else:
return ob
```
<Overlap Ratio: 0.9700854700854701>

---

--- 322 --
Question ID: b60542abca54e8108b59116374b00bad6cc0b57c_1
Original Code:
```
def write_common_mapping(gids, mapping, output):

    cell_count = len(gids)
    counts_per_cell = mapping.num_compartments

    out_mapping = output.create_group("mapping")

    out_mapping.create_dataset("gids", data=gids, dtype="u4")

    # Number of values per cell
    num_values = numpy.zeros((cell_count), dtype="u4")
    for i in range(cell_count):
        num_values[i] = counts_per_cell(i)
    out_mapping.create_dataset("num_values", data=num_values, dtype="u4")

    # Per cell mapping data
    index = mapping.index
    mapping_data = index.view(dtype="u4").reshape((index.shape[0], 2))[:, 1]
    out_mapping.create_dataset("data", data=mapping_data, dtype="u4")

    return out_mapping
```


Overlapping Code:
```

cell_count = len(gids)
counts_per_cell = mapping.num_compartments
out_mapping = output.create_group("mapping")
out_mapping.create_dataset("gids", data=gids, dtype="u4")
# Number of values per cell
num_values = numpy.zeros((cell_count), dtype="u4")
for i in range(cell_count):
num_values[i] = counts_per_cell(i)
out_mapping.create_dataset("num_values", data=num_values, dtype="u4")
# Per cell mapping data
index = mapping.index
mapping_data = index.view(dtype="u4").reshape((index.shape[0], 2))[:, 1]
out_mapping.create_dataset("data", data=mapping_data, dtype="u4")
```
<Overlap Ratio: 0.8941548183254344>

---

--- 323 --
Question ID: 15512953e72a4d547bc8d97d82ec169af2d846f4_6
Original Code:
```
def test_7():
    """Testing the synthesis of a Python program."""
    code = """
a = HOLE
if x != 5:
    a = a + 1
else:
    a = a - 1
    """
    vars = contract.ProgramVars({'x': 'Int', 'y': 'Int'}, {'a': 'Int'})
    code_pre = 'x >= 1 and y >= 1'
    code_post = 'a == 6*x + y'

    grammar_spec = """
(
    ( Start Int
        ( ( Constant Int ) x y (+ Start Start) (* ( Constant Int ) Start) )
    )
)
    """
    import pysv.templates
    grammar = pysv.templates.load_gramar_from_SYGUS_spec(grammar_spec)
    hole = pysv.smt_synthesis.HoleDecl('HOLE', grammar, {'x': 'Int', 'y': 'Int'}, True, max_depth=3)
    holes_defs = {hole.id: hole}

    res = pysv.smt_synthesis.synthesize(code, code_pre, code_post, vars, holes_defs)

    # Printing result
    print('******** Z3 RESULT ********')
    print(res.text)
    print('--------------------------\n')
    print('SYNTHESIZED PYTHON CODE:')
    print(res.final_code)
```


Overlapping Code:
```
 synthesis of a Python program."""
code = """
a = HOLE
if x != 5:
a = a + 1
else:
a = a - 1
"""
vars = contract.ProgramVars({'x': 'Int', 'y': 'Int'}, {'a': 'Int'})
code_pre = 'x >= 1 and y >= 1'
code_post = 'a == 6*x + y'
grammar_spec = """
(
( Start Int
( ( Constant Int ) x y (+ Start Start) (* ( Constant Int ) Start) )
)
)
"""
import pysv.templates
grammar = pysv.templates.load_gramar_from_SYGUS_spec(grammar_spec)
hole = pysv.smt_synthesis.HoleDecl('HOLE', grammar, {'x': 'Int', 'y': 'Int'}, True, max_depth=3)
holes_defs = {hole.id: hole}
res = pysv.smt_synthesis.synthesize(code, code_pre, code_post, vars, holes_defs)
# Printing result
print('******** Z3 RESULT ********')
print(res.text)
print('--------------------------\n')
print('SYNTHESIZED PYTHON CODE:')
print(res.fina
```
<Overlap Ratio: 0.9572649572649573>

---

--- 324 --
Question ID: ff164fc6af0d809157aa358291edbde4193822a6_0
Original Code:
```
def index(request):
    c = {}
    c.update(csrf(request))
    #print(c)
    if request.method == 'POST':
        username = request.POST['username']
        password = request.POST['password']
        #print(request.POST)
        if "button_click" in request.POST:
            #print(username, password)
            user = authenticate(username=username, password=password)
            if user is not None:
                print('Testing')
                login(request, user)
                return redirect('/homeapp')
            else:
                messages.error(request, "Wrong email and password combination")
    return render(request, 'loginapp/base.html', c)
```


Overlapping Code:
```
))
#print(c)
if request.method == 'POST':
username = request.POST['username']
password = request.POST['password']
#print(request.POST)
if "button_click" in request.POST:
#print(username, password)
user = authenticate(username=username, password=password)
if user is not None:
print('Testing')
login(request, user)
return redirect('/homeapp')
else:
messages.error(request, "Wrong email and password combination")
return render(request, 'loginapp/base.
```
<Overlap Ratio: 0.8875739644970414>

---

--- 325 --
Question ID: a1eba867e80691245a78e1eced9a5e14863b5e36_1
Original Code:
```
def init( i ):
    xparser.parse_file( i )
    
    # To make sure the necessary folders exist.
    os.system("mkdir -p " + config.output_folder + " >/dev/null")
    os.system("mkdir -p " + config.presets_folder + " >/dev/null")

    # Python's file operations do not support tilde (~), so they can be replaced with the users home directory ($HOME).
    config.presets_folder = config.presets_folder.replace( "~", os.path.expanduser("~") )
    config.output_folder = config.output_folder.replace( "~", os.path.expanduser("~") )

    for i in os.listdir( os.path.join( xparser.cwd, config.presets_folder ) ):
        handle_file( i )
```


Overlapping Code:
```
file( i )

# To make sure the necessary folders exist.
os.system("mkdir -p " + config.output_folder + " >/dev/null")
os.system("mkdir -p " + config.presets_folder + " >/dev/null")
# Python's file operations do not support tilde (~), so they can be replaced with the users home directory ($HOME).
config.presets_folder = config.presets_folder.replace( "~", os.path.expanduser("~") )
config.output_folder = config.output_folder.replace( "~", os.path.expanduser("~") )
for i in os.listdir( os.path.join( xparser.cwd, config.presets_folder ) ):
handle_fi
```
<Overlap Ratio: 0.9385665529010239>

---

--- 326 --
Question ID: 70adbf8b9fdaae431948c68fd9cf7d35b7eaa6c4_3
Original Code:
```
def query_for_exptimes(targname, proposid, filt, dateobs=''):
    """Queries FileInfo for exposure times. Assumes querying either by 
    proposid or dateobs. If Dateobs, will query in a range of 30 days.

    Parameters:
        targname : string
            Name of the target cluster.
        proposid : string
            Proposal number. If equals '', then query by just filter.
        filt : string
            Name of the filter.
        dateobs : float
            MJD date of observation. If equals '', then query just by 
            proposal number.

    Returns:
        exptimes : list of floats
            Exposure times.

    Outputs:
        nothing
    """
    FileInfo, Master, Phot, Results = return_tables(targname) 

    if proposid == '':
        query = session.query(FileInfo.exptime)\
           .filter(FileInfo.filter == filt).all()
    elif proposid != '' and dateobs == '':
        query = session.query(FileInfo.exptime)\
                .filter(FileInfo.proposid == proposid)\
                .filter(FileInfo.filter == filt).all()

    elif dateobs != '':
        query = session.query(FileInfo.exptime)\
                .filter(FileInfo.filter == filt)\
                .filter(FileInfo.dateobs <= dateobs+30.)\
                .filter(FileInfo.dateobs >= dateobs-30.).all()

    exptimes = [result[0] for result in query]

    return exptimes
```


Overlapping Code:
```
xptimes(targname, proposid, filt, dateobs=''):
"""Queries FileInfo for exposure times. Assumes querying either by 
proposid or dateobs. If Dateobs, will query in a range of 30 days.
Parameters:
targname : string
Name of the target cluster.
proposid : string
Proposal number. If equals '', then query by just filter.
filt : string
Name of the filter.
dateobs : float
MJD date of observation. If equals '', then query just by 
proposal number.
Returns:
exptimes : list of floats
Exposure times.
Outputs:
nothing
"""
FileInfo, Master, Phot, Results = return_tables(targname) 
if proposid == '':
query = session.query(FileInfo.exptime)\
.filter(FileInfo.filter == filt).all()
elif proposid != '' and dateobs == '':
query = session.query(FileInfo.exptime)\
.filter(FileInfo.proposid == proposid)\
.filter(FileInfo.filter == filt).all()
elif dateobs != '':
query = session.query(FileInfo.exptime)\
.filter(FileInfo.filter == filt)\
.filter(FileInfo.dateobs <= dateobs+30.)\
.filter(FileInfo.dateobs >= dateobs-30.).all()
exptimes = [result[0] for result in
```
<Overlap Ratio: 0.9650735294117647>

---

--- 327 --
Question ID: c36f8c525a000406e0290ecf19216cdc6f1d20b7_0
Original Code:
```
def jsonResponse(f):
    """
    Decorator that converts a route() return value into a JSON-formatted
    string and sets the appropriate content-type and other request values (if
    necessary).
    If f returns a deferred, return a deferred.
    """
    @wraps(f)
    def wrapper(self, request, *a, **kw):
        request.setHeader("Content-Type", "application/json")
        request.setHeader("Expires", "-1") # IE caches way too much
        payload = request.content.read()
        if payload:
            request.payload = json.loads(payload)
        d = defer.maybeDeferred(f, self, request, *a, **kw)
        d.addCallback(json.dumps, indent=2)
        return d
    return wrapper
```


Overlapping Code:
```
ef jsonResponse(f):
"""
Decorator that converts a route() return value into a JSON-formatted
string and sets the appropriate content-type and other request values (if
necessary).
If f returns a deferred, return a deferred.
"""
@wraps(f)
def wrapper(self, request, *a, **kw):
request.setHeader("Content-Type", "application/json")
request.setHeader("Expires", "-1") # IE caches way too much
payload = request.content.read()
if payload:
request.payload = json.loads(payload)
d = defer.maybeDeferred(f, self, request, *a, **kw)
d.addCallback(json.dumps, 
```
<Overlap Ratio: 0.9417808219178082>

---

--- 328 --
Question ID: 9cf092a926a285d817b4ecc99e01425ac70af0b8_5
Original Code:
```
def has_permission(permission):
    def predicate(ctx):
        if ctx.guild is None:
            return False
        if ctx.author.id == ctx.guild.owner_id:
            return True
        if ctx.author.id in config.admins:
            return True
        return has_permission_member(ctx.guild.id, ctx.author, permission)
    return commands.check(predicate)
```


Overlapping Code:
```
ef predicate(ctx):
if ctx.guild is None:
return False
if ctx.author.id == ctx.guild.owner_id:
return True
if ctx.author.id in config.admins:
return True
return has_permission_member(ctx.guild.id, ctx.author, permission)
return commands.check(predicate
```
<Overlap Ratio: 0.8807017543859649>

---

--- 329 --
Question ID: e1e31b439b140e38beb320a6acf73637a8c241ba_1
Original Code:
```
def checkTouchVSide(x, y, w, h, maxW, maxH, tolerance):
    if x <= 0:
        return True
    elif y - tolerance <= 0:
        return True
    elif x + w >= maxW:
        return True
    elif y + h + tolerance >= maxH:
        return True
    else:
        return False
```


Overlapping Code:
```
ef checkTouchVSide(x, y, w, h, maxW, maxH, tolerance):
if x <= 0:
return True
elif y - tolerance <= 0:
return True
elif x + w >= maxW:
return True
elif y + h + tolerance >= maxH:
return True
else:
ret
```
<Overlap Ratio: 0.9523809523809523>

---

--- 330 --
Question ID: 28940e8c7f57d81965cbf8c93980e4b344c4c828_2
Original Code:
```
def fake_city():
    """ Fake repartition (Random Generator) """
    # ["A"][1] not random on purpose
    city = {"A":{1:0, 2:17, 3:7},
            "B":{1:11, 2:1, 3:8},
            "C":{1:9, 2:16, 3:2}}
    return city
```


Overlapping Code:
```
fake_city():
""" Fake repartition (Random Generator) """
# ["A"][1] not random on purpose
city = {"A":{1:0, 2:17, 3:7},
"B":{1:11, 2:1, 3:8},
"C":{1:9, 2:16, 3:2}}
return cit
```
<Overlap Ratio: 0.9720670391061452>

---

--- 331 --
Question ID: da8a9ba0fab63b56e2c89a36aa0cdd84854970ce_2
Original Code:
```
def get_hostname():
    """
    Gets the hostname of the system
    """
    return {'HOSTNAME': socket.getfqdn()}
```


Overlapping Code:
```
et_hostname():
"""
Gets the hostname of the system
```
<Overlap Ratio: 0.5154639175257731>

---

--- 332 --
Question ID: ee784383ede5373c25eb9885e4451ddd04836b26_8
Original Code:
```
def test_string_values():
    x = dict(a='a', b='b')

    with no_mutations(x):
        test = x['a']
    assert test == 'a'

    with pytest.raises(MutationError):
        with no_mutations(x):
            x['c'] = 'c'
    assert 'c' in x
```


Overlapping Code:
```
es():
x = dict(a='a', b='b')
with no_mutations(x):
test = x['a']
assert test == 'a'
with pytest.raises(MutationError):
with no_mutations(x):
x['c'] = 
```
<Overlap Ratio: 0.7936507936507936>

---

--- 333 --
Question ID: 49bdc86bb744fcdbd9a57a823d2581cb7ce538ca_3
Original Code:
```
def is_interactive():
    """
    Check if is in an interactive shell (python or ipython).

    Returns
    -------
    bool

    """
    ipython = False
    try:
        cls_name = get_ipython().__class__.__name__

        if cls_name in ('InteractiveShellEmbed', 'TerminalInteractiveShell'):
            ipython = True
    except NameError:
        pass

    import __main__ as main

    return not hasattr(main, '__file__') or ipython
```


Overlapping Code:
```
tive():
"""
Check if is in an interactive shell (python or ipython).
Returns
-------
bool
"""
ipython = False
try:
cls_name = get_ipython().__class__.__name__
if cls_name in ('InteractiveShellEmbed', 'TerminalInteractiveShell'):
ipython = True
except NameError:
pass
import __main__ as main
return not hasattr(main, '__file__') or ip
```
<Overlap Ratio: 0.9460227272727273>

---

--- 334 --
Question ID: bef0998ea7e8196a7098198c75eeeec8b7332c57_3
Original Code:
```
def anneal(t=1.0):
    """
    Transitions Governor from SA to CB state and inserts annealer
    
    Requirements
    ------------
    * Governor in SA state
    
    Parameters
    ----------
    t: Time to insert annealer paddle. default = 1.0 [s]
              
    Examples
    --------
    anneal()
    anneal(t=5)
    
    """
    if not govStatusGet('SA'):
        print('Not in Governor state SA, exiting')
        return -1
    
    govStateSet('CB')
    
    annealer.air.put(1)
    
    while not annealer.inStatus.get():
        #print(annealer.inStatus.get())
        time.sleep(0.1)
    
    time.sleep(t)
    annealer.air.put(0)
    
    while not annealer.outStatus.get():
        #print(annealer.outStatus.get())
        time.sleep(0.1)
    
    govStateSet('SA')
    
    return
```


Overlapping Code:
```
om SA to CB state and inserts annealer

Requirements
------------
* Governor in SA state

Parameters
----------
t: Time to insert annealer paddle. default = 1.0 [s]

Examples
--------
anneal()
anneal(t=5)

"""
if not govStatusGet('SA'):
print('Not in Governor state SA, exiting')
return -1

govStateSet('CB')

annealer.air.put(1)

while not annealer.inStatus.get():
#print(annealer.inStatus.get())
time.sleep(0.1)

time.sleep(t)
annealer.air.put(0)

while not annealer.outStatus.get():
#print(annealer.outStatus.get())
time.sleep(0.1)

govStateSet('S
```
<Overlap Ratio: 0.9060955518945635>

---

--- 335 --
Question ID: 38b93e3e9c38a1fd8f528b0be2613872a3d07587_0
Original Code:
```
def train(render=False):
    reward100 = 0
    for ep in range(max_episodes):
        obs = env.reset()
        state = obs
        total_reward = 0
        for iter in range(max_iterations):
            if render:
                env.render()
            action = np.argmax(q_table[state,:] + np.random.randn(1,env.action_space.n)*(1./(ep+1)))
            obs, reward, done, info = env.step(action)
            total_reward += reward
            new_state = obs
            # update q table
            q_table[state,action] = q_table[state,action] + learning_rate * (reward + discount_factor *  np.max(q_table[new_state,:]) - q_table[state,action])
            state = new_state
            if done:
                break
        reward100 += total_reward
        if ep % 100 == 0:
            print('Iteration #{} -- Average reward = {}.'.format(ep+1, reward100/100))
            rList.append(reward100/100)
            if reward100/100 >= 0.78:
                print("Solved~!!!!")
                print("Average score every 100 trials: " +  str((rList)))
                print("Mean Score: {}".format(np.mean(rList)))
                break
            reward100 = 0
```


Overlapping Code:
```
00 = 0
for ep in range(max_episodes):
obs = env.reset()
state = obs
total_reward = 0
for iter in range(max_iterations):
if render:
env.render()
action = np.argmax(q_table[state,:] + np.random.randn(1,env.action_space.n)*(1./(ep+1)))
obs, reward, done, info = env.step(action)
total_reward += reward
new_state = obs
# update q table
q_table[state,action] = q_table[state,action] + learning_rate * (reward + discount_factor * np.max(q_table[new_state,:]) - q_table[state,action])
state = new_state
if done:
break
reward100 += total_reward
if ep % 100 == 0:
print('Iteration #{} -- Average reward = {}.'.format(ep+1, reward100/100))
rList.append(reward100/100)
if reward100/100 >= 0.78:
print("Solved~!!!!")
print("Average score every 100 trials: " + str((rList)))
print("Mean Score: {}".format(np.mean(
```
<Overlap Ratio: 0.9302325581395349>

---

--- 336 --
Question ID: e56b0c31d2a5bc7ffc2720650061bdfef0a46562_0
Original Code:
```
def setup_platform(hass, config, add_devices, discovery_info=None):
    """Set up the Alpha Vantage sensor."""
    from alpha_vantage.timeseries import TimeSeries

    api_key = config.get(CONF_API_KEY)
    symbols = config.get(CONF_SYMBOLS)

    timeseries = TimeSeries(key=api_key)

    dev = []
    for symbol in symbols:
        try:
            timeseries.get_intraday(symbol)
        except ValueError:
            _LOGGER.error(
                "API Key is not valid or symbol '%s' not known", symbol)
            return
        dev.append(AlphaVantageSensor(timeseries, symbol))

    add_devices(dev, True)
```


Overlapping Code:
```
def setup_platform(hass, config, add_devices, discovery_info=None):
"""Set up the Alpha Vantage sensor."""
from alpha_vantage.timeseries import TimeSeries
api_key = config.get(CONF_API_KEY)
symbols = config.get(CONF_SYMBOLS)
timeseries = TimeSeries(key=api_key)
dev = []
for symbol in symbols:
try:
timeseries.get_intraday(symbol)
except ValueError:
_LOGGER.error(
"API Key is not valid or symbol '%s' not known", symbol)
return
dev.append(AlphaVantageSensor(timeseries, symbol))
add_devices(dev, 
```
<Overlap Ratio: 0.9900398406374502>

---

--- 337 --
Question ID: e7af35546ac1defd4e29dcd7edcc6de7d041f11a_1
Original Code:
```
def id_convert(inp):
    id = int(inp)
    # Assume is_strictly_sorted(src_issues) and src_issues[0] >= 1
    if id not in src_issues:
        print("WARNING: %d doesn't belong in %s" % (id, src_issues))
        return 0  # dummy value
    already_imported = 0
    for cur in src_issues:
        if id == cur:
            return existing_issues + already_imported + 1
        else:
            already_imported += 1
    print("ERROR: In id_convert(%d): unexpected error" % id)
    exit(2)
```


Overlapping Code:
```
rt(inp):
id = int(inp)
# Assume is_strictly_sorted(src_issues) and src_issues[0] >= 1
if id not in src_issues:
print("WARNING: %d doesn't belong in %s" % (id, src_issues))
return 0 # dummy value
already_imported = 0
for cur in src_issues:
if id == cur:
return existing_issues + already_imported + 1
else:
already_imported += 1
print("ERROR: In id_con
```
<Overlap Ratio: 0.8684863523573201>

---

--- 338 --
Question ID: 9eef3bd9a681da15a892495231745f91dc75f4f3_0
Original Code:
```
def main():
    for tc in range(int(input())):
        N, ans = int(input()), -1
        for a in range(1,N//2):
            b = (N*(2*a-N))//(2*(a-N))
            c = N-a-b
            if a+b+c==N and a*a+b*b==c*c:
                ans = max(ans,a*b*c)
        print(ans)
```


Overlapping Code:
```
def main():
for tc in range(int(input())):
N, ans = int(input()), -1
for a in range(1,N//2):
b = (N*(2*a-N))//(2*(a-N))
c = N-a-b
if a+b+c==N and a*a+
```
<Overlap Ratio: 0.7853403141361257>

---

--- 339 --
Question ID: c6a1ca0121d980851c4169ddc7476becc66c023b_1
Original Code:
```
def edit_author(request, id):
    '''
    Edit author information
    '''
    author = get_object_or_404(Author, id=id)
    if request.method == 'POST':
        form = AuthorForm(request.POST, instance=author)
        if form.is_valid():
            author_edited = form.save(commit=False)
            author.username = author_edited.username
            author.full_name = author_edited.full_name
            author.save()
        return HttpResponseRedirect(reverse('blog.views.get_author',args=(author.id, author.username,)))
    else:
        form = AuthorForm(instance=author)
    return render_to_response('form.html', {'form':form, 'action':'edit_author'}, RequestContext(request))
```


Overlapping Code:
```

'''
Edit author information
'''
author = get_object_or_404(Author, id=id)
if request.method == 'POST':
form = AuthorForm(request.POST, instance=author)
if form.is_valid():
author_edited = form.save(commit=False)
author.username = author_edited.username
author.full_name = author_edited.full_name
author.save()
return HttpResponseRedirect(reverse('blog.views.get_author',args=(author.id, author.username,)))
else:
form = AuthorForm(instance=author)
return render_to_response('form.html', {'form':form, 'action':'edit_author'}, RequestContext(request)
```
<Overlap Ratio: 0.9482758620689655>

---

--- 340 --
Question ID: 847c4570f6262623053abb03128f8be995e0c7a6_1
Original Code:
```
def execute_query(queries, db_name, processed_dir=cn.DB_DIR):
    db_file = os.path.join(processed_dir, db_name + '.db')
    conn = sqlite3.connect(db_file)
    cur = conn.cursor()
    if type(queries) is list:
        for query in queries:
            cur.execute(query)
    else:
        cur.execute(queries)
    conn.commit()
    conn.close()
```


Overlapping Code:
```
ecute_query(queries, db_name, processed_dir=cn.DB_DIR):
db_file = os.path.join(processed_dir, db_name + '.db')
conn = sqlite3.connect(db_file)
cur = conn.cursor()
if type(queries) is list:
for query in queries:
cur.execute(query)
else:
cur.execute(qu
```
<Overlap Ratio: 0.8650519031141869>

---

--- 341 --
Question ID: ee587123466829408959f7abd5c847ce5a4d61fb_0
Original Code:
```
@app.route("/<board>/")
def board_index(board):
    row = get_board_id( board )

    if row == None:
        abort(404)

    threads = get_board_threads( row[0] )
    posts   = [summarize_thread( get_thread_posts(x["id"]))
                      for x in threads]

    boardsum = [{"thread" : x[0], "posts" : x[1][0], "omitted" : x[1][1]}
                    for x in zip(threads, posts)]

    return render_template('board_index.html',
            board            = board,
            boardsum         = boardsum,
            time             = time )
```


Overlapping Code:
```
"/<board>/")
def board_index(board):
row = get_board_id( board )
if row == None:
abort(404)
threads = get_board_threads( row[0] )
posts = [summarize_thread( get_thread_posts(x["id"]))
for x in threads]
boardsum = [{"thread" : x[0], "posts" : x[1][0], "omitted" : x[1][1]}
for x in zip(threads, posts)]
return render_template('board_index.html',
board
```
<Overlap Ratio: 0.8641975308641975>

---

--- 342 --
Question ID: b25d39264152bccb91042dddeb344b4d1c887ff7_0
Original Code:
```
def entry():
  current_dir = os.path.dirname(os.path.realpath(__file__))

  path_files_includes=[
            'lua.h',
            #'lua.hpp', # 20180212 奇怪 GitHub 上的 repo 没有这个文件
            'luaconf.h',
            'lualib.h',
            'lauxlib.h',
  ]

  f = lambda v: os.path.join(current_dir,'..','lua',v)
  path_files_includes = list(map(f,path_files_includes))

  p = os.path.join(current_dir,'include','lua')
  if os.path.exists(p):
    shutil.rmtree(p)
  os.makedirs(p)
  for v in path_files_includes:
    shutil.copy(v,p)
    print('[+] copy {0} to {1}'.format(v,p))

  print('[+] all done')
```


Overlapping Code:
```
):
current_dir = os.path.dirname(os.path.realpath(__file__))
path_files_includes=[
'lua.h',
#'lua.hpp', # 20180212 奇怪 GitHub 上的 repo 没有这个文件
'luaconf.h',
'lualib.h',
'lauxlib.h',
]
f = lambda v: os.path.join(current_dir,'..','lua',v)
path_files_includes = list(map(f,path_files_includes))
p = os.path.join(current_dir,'include','lua')
if os.path.exists(p):
shutil.rmtree(p)
os.makedirs(p)
for v in path_files_includes:
shutil.copy(v,p)
print('[+] copy {0} to {1}'
```
<Overlap Ratio: 0.9112426035502958>

---

--- 343 --
Question ID: 0e3673cfaa673d345b3809f10269b823db00628a_1
Original Code:
```
def encode(*stuff):
	"""Encode components into a proper EDIComm string.

	The proper look for the parameters is:
		edicomm.encode("TLA", "parameter", ["list", "parameter"], ('tuples are', 'also okay'))
	Which should create the EDIComm string:
		"TLA parameter list,parameter tuples\ are,also\ okay"
	"""

	ret = ''

	for i in stuff:
		if isinstance(i, basestring):
			i = i.replace(',', '\\,')
			ret += i.replace(' ', '\\ ') + ' '
		elif hasattr(i, '__iter__'):
			lstr = ''

			for x in i:
				if isinstance(x, basestring):
					x = x.replace(',', '\\,')
					x = x.replace(' ', '\\ ')

				lstr += str(x) + ','

			lstr = lstr.rstrip(',')
			ret += lstr + ' '
		elif i == None:
			pass # --Gandalf
		else:
			ret += str(i) + ' '

	ret = ret.rstrip(' ')

	return ret
```


Overlapping Code:
```
ents into a proper EDIComm string.
The proper look for the parameters is:
edicomm.encode("TLA", "parameter", ["list", "parameter"], ('tuples are', 'also okay'))
Which should create the EDIComm string:
"TLA parameter list,parameter tuples\ are,also\ okay"
"""
ret = ''
for i in stuff:
if isinstance(i, basestring):
i = i.replace(',', '\\,')
ret += i.replace(' ', '\\ ') + ' '
elif hasattr(i, '__iter__'):
lstr = ''
for x in i:
if isinstance(x, basestring):
x = x.replace(',', '\\,')
x = x.replace(' ', '\\ ')
lstr += str(x) + ','
lstr = lstr.rstrip(',')
ret += lstr + ' '
elif i == None:
pass # --Gandalf
else:
ret += str(i) + ' '
ret = ret.rstrip(' '
```
<Overlap Ratio: 0.9312320916905444>

---

--- 344 --
Question ID: 830cae5925482d7554e655183f954ad29a1497d2_3
Original Code:
```
def SideBySide(*plots,**kw):
    n = len(plots)
    iso = kw.get('iso')
    if iso:
        return Vppen(plots,'size=r vpstyle=n gridnum=%d,1' % n)
    else:
        return Vppen(plots,'yscale=%d vpstyle=n gridnum=%d,1' % (n,n))
```


Overlapping Code:
```
 len(plots)
iso = kw.get('iso')
if iso:
return Vppen(plots,'size=r vpstyle=n gridnum=%d,1' % n)
else:
return Vppen(plots,'yscale=%d vpstyle=n gridnum=
```
<Overlap Ratio: 0.7653061224489796>

---

--- 345 --
Question ID: db8109bed31a6a519d2db98e9bae372e324191b8_0
Original Code:
```
def main(args=None):
    if args is None:
        args = sys.argv[1:]
    ParserShell().main(args)
```


Overlapping Code:
```
def main(args=None):
if args is None:
args = sys.argv[1:]
ParserShell().main(args)
```
<Overlap Ratio: 1.0>

---

--- 346 --
Question ID: 78cf1de4bc0b30f7af3b0ec998ebcd26ffff3102_0
Original Code:
```
@app.route('/upload', methods=['GET', 'POST'])
def upload_file():
	# curl -F "filename=@/tmp/abc.txt" http://127.0.0.1:5000/upload
    if request.method == 'POST':
        f = request.files['filename']
        f.save('/tmp/' + secure_filename(f.filename))
```


Overlapping Code:
```
@app.route('/upload', methods=['GET', 'POST'])
def upload_file():
# curl -F "filead
if request.method == 'POST':
f = request.files['filename']
f.save('/tmp/' + secure_filename(f.fil
```
<Overlap Ratio: 0.7735042735042735>

---

--- 347 --
Question ID: 828f5d89780c8fc50eda7c3391de3cc5e5055367_16
Original Code:
```
def filter_candidates(candidates, select_variant_types):
  """Yields the candidate variants whose type is one of select_variant_types.

  This function iterates through candidates and yield each candidate in order
  if it satisfies any of the type constraints implied by select_variant_types.
  For example, if select_variant_types = ['snps'] this function will yield
  candidates that are bi-allelic SNPs only. Multiple select types are treated
  as OR'd together, so ['snps', 'indels'] yields candidates that are bi-allelic
  SNPs or indels.

  Args:
    candidates: Iterable of Variant protos. The candidates we want to select
      from.
    select_variant_types: List of str. The names of the variant type selectors
      we want to use to keep/remove variants. Each string must be part of
      VARIANT_TYPE_SELECTORS or an error will be raised.

  Raises:
    ValueError: if any str in select_variant_types isn't present in
      VARIANT_TYPE_SELECTORS.

  Yields:
    Candidates in order.
  """
  if not all(s in VARIANT_TYPE_SELECTORS for s in select_variant_types):
    raise ValueError('Unexpected select variant type', select_variant_types)

  for candidate in candidates:
    v = candidate.variant
    for select_type in select_variant_types:
      selector = VARIANT_TYPE_SELECTORS[select_type]
      if selector(v):
        yield candidate
        break
```


Overlapping Code:
```
 filter_candidates(candidates, select_variant_types):
"""Yields the candidate variants whose type is one of select_variant_types.
This function iterates through candidates and yield each candidate in order
if it satisfies any of the type constraints implied by select_variant_types.
For example, if select_variant_types = ['snps'] this function will yield
candidates that are bi-allelic SNPs only. Multiple select types are treated
as OR'd together, so ['snps', 'indels'] yields candidates that are bi-allelic
SNPs or indels.
Args:
candidates: Iterable of Variant protos. The candidates we want to select
from.
select_variant_types: List of str. The names of the variant type selectors
we want to use to keep/remove variants. Each string must be part of
VARIANT_TYPE_SELECTORS or an error will be raised.
Raises:
ValueError: if any str in select_variant_types isn't present in
VARIANT_TYPE_SELECTORS.
Yields:
Candidates in order.
"""
if not all(s in VARIANT_TYPE_SELECTORS for s in select_variant_types):
raise ValueError('Unexpected select variant type', select_variant_types)
for candidate in candidates:
v = candidate.variant
for select_type in select_variant_types:
selector = VARIANT_TYPE_SELECTORS[select_type]
if selector(v):
yield candidate
br
```
<Overlap Ratio: 0.9952267303102625>

---

--- 348 --
Question ID: cc20b8d10ba8793748ad472f2f4a3167d7f1623e_0
Original Code:
```
def class_view_decorator(function_decorator):
	"""Convert a function based decorator into a class based decorator usable
	on class based Views.
	Can't subclass the `View` as it breaks inheritance (super in particular),
	so we monkey-patch instead.
	"""

	def simple_decorator(view):
		view.dispatch = method_decorator(function_decorator)(view.dispatch)
		return view

	return simple_decorator
```


Overlapping Code:
```
_decorator(function_decorator):
"""Convert a function based decorator into a class based decorator usable
on class based Views.
Can't subclass the `View` as it breaks inheritance (super in particular),
so we monkey-patch instead.
"""
def simple_decorator(view):
view.dispatch = method_decorator(function_decorator)(view.dispatch)
return view
return simple_deco
```
<Overlap Ratio: 0.9498680738786279>

---

--- 349 --
Question ID: 0877893c370d92ee2ddd760abdbfb2edf5011099_4
Original Code:
```
def compute_confusion_matrix(real, pred, normalization=None):
    "Compute confusion matrix."
    if real.shape == pred.shape:
        conf_mat = confusion_matrix(real, pred)
    else:
        conf_mat = confusion_matrix_probs(pred, real)
    return conf_mat
```


Overlapping Code:
```
mpute_confusion_matrix(real, pred, normalization=None):
"Compute confusion matrix."
if real.shape == pred.shape:
conf_mat = confusion_matrix(real, pred)
else:
conf_mat = confusion_matrix_probs(pred, r
```
<Overlap Ratio: 0.8849557522123894>

---

--- 350 --
Question ID: 3b6e1c7678354b11c31463fa6993eb5863c91a8e_1
Original Code:
```
def get_dataset_input_from_database(customer):
    rows = [];
    try:
        conn = get_connection()
        cur = conn.cursor()
        cur.execute(' SELECT '
                    '     example_value.value '
                    ' FROM '
                    '     example_values example_value '
                    '     INNER JOIN examples example ON example.id = example_value.example_id '
                    '     INNER JOIN fields field ON example_value.field_id = field.id '
                    ' WHERE '
                    '     example.customer = %s '
                    '     AND field.type = \'input\' '
                    '     AND field.customer = %s '
                    ' ORDER BY '
                    '     example_value.example_id , '
                    '     field.name ', [customer, customer])
        rows = cur.fetchall()
        cur.close()
    except (Exception, psycopg2.DatabaseError) as error:
        print(error)
    finally:
        if conn is not None:
            conn.close()
            return join_rows(customer, rows)
```


Overlapping Code:
```
tabase(customer):
rows = [];
try:
conn = get_connection()
cur = conn.cursor()
cur.execute(' SELECT '
' example_value.value '
' FROM '
' example_values example_value '
' INNER JOIN examples example ON example.id = example_value.example_id '
' INNER JOIN fields field ON example_value.field_id = field.id '
' WHERE '
' example.customer = %s '
' AND field.type = \'input\' '
' AND field.customer = %s '
' ORDER BY '
' example_value.example_id , '
' field.name ', [customer, customer])
rows = cur.fetchall()
cur.close()
except (Exception, psycopg2.DatabaseError) as error:
print(error)
finally:
if conn is not None:
conn.close()
return join_rows(customer
```
<Overlap Ratio: 0.9475218658892128>

---

--- 351 --
Question ID: 6e7ed1813d85027d3fe7e7447861410b7ff150a4_1
Original Code:
```
def print_ok(message):
    """Install python module using pip3.

    Args:
        module: module to install

    Returns:
        None

    """
    # Print message
    print('OK - {}'.format(message))
```


Overlapping Code:
```
"Install python module using pip3.
Args:
module: module to install
Returns:
None
"""
# Print message
print('OK 
```
<Overlap Ratio: 0.7025316455696202>

---

--- 352 --
Question ID: 33e95d7df122e5f2ed7af5b12ccad246a89b63bb_2
Original Code:
```
def test(test_data, test_labels, batch_size, model, test_batch_num):
    accuracy = 0.0
    keep_probs_values = [1.0 for i in range(len(model.keep_probs_values))]
    for batch in iterate_minibatches(inputs=test_data, targets=test_labels, batchsize=batch_size):
        test_in, test_target = batch
        # test_in = test_in[:,np.newaxis,:,np.newaxis]
        # print model.sess.run(tf.reduce_sum(tf.equal(tf.argmax(model.output_layer,1), tf.argmax(model.y, 1))) ,
        #                            feed_dict={model.x:test_in, model.y:test_target})
        accuracy += model.sess.run(
            tf.reduce_mean(tf.cast(tf.equal(tf.argmax(model.output_layer, 1), tf.argmax(model._y, 1)), tf.float32)),
            feed_dict={model._x: test_in, model._y: test_target, model.keep_probs: keep_probs_values})
    print('accuracy: {}'.format(accuracy / test_batch_num))
    return accuracy / test_batch_num
```


Overlapping Code:
```
ef test(test_data, test_labels, batch_size, model, test_batch_num):
accuracy = 0.0
keep_probs_values = [1.0 for i in range(len(model.keep_probs_values))]
for batch in iterate_minibatches(inputs=test_data, targets=test_labels, batchsize=batch_size):
test_in, test_target = batch
# test_in = test_in[:,np.newaxis,:,np.newaxis]
# print model.sess.run(tf.reduce_sum(tf.equal(tf.argmax(model.output_layer,1), tf.argmax(model.y, 1))) ,
# feed_dict={model.x:test_in, model.y:test_target})
accuracy += model.sess.run(
tf.reduce_mean(tf.cast(tf.equal(tf.argmax(model.output_layer, 1), tf.argmax(model._y, 1)), tf.float32)),
feed_dict={model._x: test_in, model._y: test_target, model.keep_probs: keep_probs_values})
print('accuracy: {}'.format(accuracy / test_batch_num))
return accuracy / test_batch_nu
```
<Overlap Ratio: 0.9974842767295597>

---

--- 353 --
Question ID: fef2ede203995b63901f96d6524c945990ee8ba9_0
Original Code:
```
def count(s):
    moves=1
    a=s[0]
    b=0
    while(b!=s[2]and s[2]!=a):
        po=min(s[1]-b,a)
        b+=po
        a-=po
        moves+=1
        if(a==[s2] or b==s[2]):break
        if(b==s[1]):
            moves+=1
            b=0
        elif a==0:
            moves+=1
            a=s[0]
    return moves
```


Overlapping Code:
```
[2]and s[2]!=a):
po=min(s[1]-b,a)
b+=po
a-=po
moves+=1
if(a==[s2] or b==s[2]):break
if(b==s[1]):
mov
```
<Overlap Ratio: 0.5208333333333334>

---

--- 354 --
Question ID: 4a9ac355e66dc0b60f30842b6284cbe1ced8a8c1_0
Original Code:
```
def get_stats(df):
    statDF = pd.DataFrame(index=[0])
    statDF["totalNumberCBGValues"] = df.mg_dL.count()

    statDF["mean_mgdL"] = df.mg_dL.mean()
    statDF["std_mgdL"] = df.mg_dL.std()
    statDF["cov_mgdL"] = statDF["std_mgdL"] / statDF["mean_mgdL"]

    statDF["totalBelow54"] = sum(df.mg_dL < 54)
    statDF["totalBelow70"] = sum(df.mg_dL < 70)
    statDF["total54to70"] = sum((df.mg_dL >= 54) & (df.mg_dL < 70))
    statDF["total70to140"] = sum((df.mg_dL >= 70) & (df.mg_dL <= 140))
    statDF["total70to180"] = sum((df.mg_dL >= 70) & (df.mg_dL <= 180))
    statDF["total180to250"] = sum((df.mg_dL > 180) & (df.mg_dL <= 250))
    statDF["totalAbove180"] = sum(df.mg_dL > 180)
    statDF["totalAbove250"] = sum(df.mg_dL > 250)

    statDF["percentBelow54"] = statDF["totalBelow54"] / statDF["totalNumberCBGValues"]
    statDF["percentBelow70"] = statDF["totalBelow70"] / statDF["totalNumberCBGValues"]
    statDF["percent70to140"] = statDF["total70to140"] / statDF["totalNumberCBGValues"]
    statDF["percent70to180"] = statDF["total70to180"] / statDF["totalNumberCBGValues"]
    statDF["percentAbove180"] = statDF["totalAbove180"] / statDF["totalNumberCBGValues"]
    statDF["percentAbove250"] = statDF["totalAbove250"]  / statDF["totalNumberCBGValues"]

    statDF["min_mgdL"] = df.mg_dL.min()
    statDF["median_mgdL"] = df.mg_dL.describe()["50%"]
    statDF["max_mgdL"] = df.mg_dL.max()

    # calculate the start and end time of the cbg data
    startTime = df["localTime"].min()
    statDF["startTime"] = startTime
    endTime = df["localTime"].max()
    statDF["endTime"] = endTime
    statDF["totalNumberPossibleCBGvalues"] = len(pd.date_range(startTime, endTime, freq="5min"))

    # feedback criteria
    # A.  incomplete dataset
    statDF["percentOfExpectedData"] = \
        (((endTime - startTime).days * 86400) +
         ((endTime - startTime).seconds)) / (86400 - (5*60))

    if statDF.loc[0, "percentOfExpectedData"] < 0.834:  # greater than 4 hours of expected data
        statDF["GTE4hoursNoCgmSignal"] = "NA"
        statDF["incompleteDataset"] = "FLAG (" + \
            str(round(statDF.loc[0, "percentOfExpectedData"] * 100, 1)) + "%)"
    else:
        statDF["incompleteDataset"] = np.nan

        # 1.  >=4 hours without CGM signal
        missingCgm = statDF["totalNumberPossibleCBGvalues"] - statDF["totalNumberCBGValues"]
        if missingCgm[0] > (4 * 60 / 5):
            statDF["GTE4hoursNoCgmSignal"] = "FLAG"
        else:
            statDF["GTE4hoursNoCgmSignal"] = np.nan

    # 2.  >= 2 hours 54 <= BG < 70 mg/dl
    if statDF.loc[0, "total54to70"] > (2 * 60 / 5):
        statDF["GTE2hoursBetween54to70"] = \
            "FLAG (" + str(round(statDF.loc[0, "total54to70"] * 5)) + "min)"
    else:
        statDF["GTE2hoursBetween54to70"] = np.nan

    # 3.  >= 15 minutes < 54 mg/dl"
    if statDF.loc[0, "totalBelow54"] > (15 / 5):
        statDF["GTE15minBelow54"] = "FLAG (" + str(round(statDF.loc[0, "totalBelow54"] * 5)) + "min)"
    else:
        statDF["GTE15minBelow54"] = np.nan

    return statDF
```


Overlapping Code:
```
= pd.DataFrame(index=[0])
statDF["totalNumberCBGValues"] = df.mg_dL.count()
statDF["mean_mgdL"] = df.mg_dL.mean()
statDF["std_mgdL"] = df.mg_dL.std()
statDF["cov_mgdL"] = statDF["std_mgdL"] / statDF["mean_mgdL"]
statDF["totalBelow54"] = sum(df.mg_dL < 54)
statDF["totalBelow70"] = sum(df.mg_dL < 70)
statDF["total54to70"] = sum((df.mg_dL >= 54) & (df.mg_dL < 70))
statDF["total70to140"] = sum((df.mg_dL >= 70) & (df.mg_dL <= 140))
statDF["total70to180"] = sum((df.mg_dL >= 70) & (df.mg_dL <= 180))
statDF["total180to250"] = sum((df.mg_dL > 180) & (df.mg_dL <= 250))
statDF["totalAbove180"] = sum(df.mg_dL > 180)
statDF["totalAbove250"] = sum(df.mg_dL > 250)
statDF["percentBelow54"] = statDF["totalBelow54"] / statDF["totalNumberCBGValues"]
statDF["percentBelow70"] = statDF["totalBelow70"] / statDF["totalNumberCBGValues"]
statDF["percent70to140"] = statDF["total70to140"] / statDF["totalNumberCBGValues"]
statDF["percent70to180"] = statDF["total70to180"] / statDF["totalNumberCBGValues"]
statDF["percentAbove180"] = statDF["totalAbove180"] / statDF["totalNumberCBGValues"]
statDF["percentAbove250"] = statDF["totalAbove250"] / statDF["totalNumberCBGValues"]
statDF["min_mgdL"] = df.mg_dL.min()
statDF["median_mgdL"] = df.mg_dL.describe()["50%"]
statDF["max_mgdL"] = df.mg_dL.max()
# calculate the start and end time of the cbg data
startTime = df["localTime"].min()
statDF["startTime"] = startTime
endTime = df["localTime"].max()
statDF["endTime"] = endTime
statDF["totalNumberPossibleCBGvalues"] = len(pd.date_range(startTime, endTime, freq="5min"))
# feedback criteria
# A. incomplete dataset
statDF["percentOfExpectedData"] = \
(((endTime - startTime).days * 86400) +
((endTime - startTime).seconds)) / (86400 - (5*60))
if statDF.loc[0, "percentOfExpectedData"] < 0.834: # greater than 4 hours of expected data
statDF["GTE4hoursNoCgmSignal"] = "NA"
statDF["incompleteDataset"] = "FLAG (" + \
str(round(statDF.loc[0, "percentOfExpectedData"] * 100, 1)) + "%)"
else:
statDF["incompleteDataset"] = np.nan
# 1. >=4 hours without CGM signal
missingCgm = statDF["totalNumberPossibleCBGvalues"] - statDF["totalNumberCBGValues"]
if missingCgm[0] > (4 * 60 / 5):
statDF["GTE4hoursNoCgmSignal"] = "FLAG"
e
```
<Overlap Ratio: 0.9795191451469278>

---

--- 355 --
Question ID: 234b198cddf1b31d8b371a6149352f5430c0e929_2
Original Code:
```
def complete_linkage_dist(nodes, cluster_a, cluster_b, distance_function=euclidean_dist):
    dist = -np.inf

    for a in cluster_a:
        for b in cluster_b:
            dist = max(dist, distance_function(nodes[a], nodes[b]))

    return dist
```


Overlapping Code:
```
f complete_linkage_dist(nodes, cluster_a, cluster_b, distance_function=euclidean_dist):
dist = -np.inf
for a in cluster_a:
for b in cluster_b:
dist = max(dist, distance_function(nodes[a], nodes[b]))
r
```
<Overlap Ratio: 0.9433962264150944>

---

--- 356 --
Question ID: 3f25d260589201e7baec25d76562efa134dffc59_18
Original Code:
```
def get_cookbook_url(config, tmpdir):
    if config.args.custom_ami_cookbook is not None:
        return config.args.custom_ami_cookbook
    else:
        cookbook_version = get_cookbook_version(config, tmpdir)
        if config.region == 'us-gov-west-1':
            return ('https://s3-%s.amazonaws.com/%s-aws-parallelcluster/cookbooks/%s.tgz'
                         % (config.region, config.region, cookbook_version))
        elif config.region == 'us-east-1':
            return ('https://s3.amazonaws.com/%s-aws-parallelcluster/cookbooks/%s.tgz'
                         % (config.region, cookbook_version))
        else:
            return ('https://s3.%s.amazonaws.com/%s-aws-parallelcluster/cookbooks/%s.tgz'
                         % (config.region, config.region, cookbook_version))
```


Overlapping Code:
```
ookbook_url(config, tmpdir):
if config.args.custom_ami_cookbook is not None:
return config.args.custom_ami_cookbook
else:
cookbook_version = get_cookbook_version(config, tmpdir)
if config.region == 'us-gov-west-1':
return ('https://s3-%s.amazonaws.com/%s-aws-parallelcluster/cookbooks/%s.tgz'
% (config.region, config.region, cookbook_version))
elif config.region == 'us-east-1':
return ('https://s3.amazonaws.com/%s-aws-parallelcluster/cookbooks/%s.tgz'
% (config.region, cookbook_version))
else:
return ('https://s3.%s.amazonaws.com/%s-aws-parallelcluster/cookbooks/%s.tgz'
% (config.region, config
```
<Overlap Ratio: 0.9433962264150944>

---

--- 357 --
Question ID: 52ca976eac44d9114107c1b51283d302e02a92d0_2
Original Code:
```
def create_indexed_signal(timestamps, signal): # both assumed to be time frames
    signal['timestamps'] = timestamps
    signal_indexed = signal.set_index(['timestamps'])
    return signal_indexed
```


Overlapping Code:
```
s, signal): # both assumed to be time frames
signal['timestamps'] = timestamps
signal_indexed = signal.set_index(['timestamps'])
return signal_indexed
```
<Overlap Ratio: 0.8108108108108109>

---

--- 358 --
Question ID: bfa9f34ddf9a750adb3d5f51986d19392d63904a_14
Original Code:
```
def test_delete_processor(regress_nifi, fix_proc):
    f_p1 = fix_proc.generate()
    r1 = canvas.delete_processor(f_p1)
    assert r1.status is None
    assert isinstance(r1, nifi.ProcessorEntity)
    # try to delete processor twice
    with pytest.raises(ValueError):
        _ = canvas.delete_processor(f_p1)
    # try to delete running processor
    f_p2 = fix_proc.generate()
    canvas.schedule_processor(f_p2, True)
    with pytest.raises(ValueError):
        _ = canvas.delete_processor(f_p2)
    # and once more with feeling, er, force
    r2 = canvas.delete_processor(f_p2, force=True)
    assert r2.status is None
```


Overlapping Code:
```
def test_delete_processor(regress_nifi, fix_proc):
f_p1 = fix_proc.generate()
r1 = canvas.delete_processor(f_p1)
assert r1.status is None
assert isinstance(r1, nifi.ProcessorEntity)
# try to delete processor twice
with pytest.raises(ValueError):
_ = canvas.delete_processor(f_p1)
# try to delete running processor
f_p2 = fix_proc.generate()
canvas.schedule_processor(f_p2, True)
with pytest.raises(ValueError):
_ = canvas.delete_processor(f_p2)
# and once more with feeling, er, force
r2 = canvas.delete_processor(f_p2, force=True)
assert r2.status i
```
<Overlap Ratio: 0.9892086330935251>

---

--- 359 --
Question ID: 24e907c82bd6ae35b2a2c5fe4a6a8f9847e18cde_2
Original Code:
```
def part_one(target):
    """Return the answer to part one of this day
        Expectation is that the answer is in the
        correct format"""

    '''presume each spiral is a box, the box has a
    length and a max digit value which would be the
    length ** 2 in the bottom right corner'''
    def box_len(index):
        return 1 + 2*(index - 1)
    def box_max(index):
        return box_len(index) ** 2

    '''find the box which contains our target
    value by counting upward from 1 and checking
    if the output is less than the target. If so,
    then the box we're looking at is not the box
    containing our target. Halt when greater or
    equal to the target'''
    rank_of_box = 1
    while box_max(rank_of_box) < target:
        rank_of_box += 1

    '''get the side length of the box
    containing the target value'''
    length = box_len(rank_of_box)

    '''take the diff of the target and the max
    value of the preceeding box, mod by the length
    of the current box to find the distance from the
    center'''
    distance_to_mid = (target - box_max(rank_of_box - 1)) % length

    '''correct for approaching from the left or right of mid'''
    if distance_to_mid > (length - 1) / 2:
        distance_to_mid -= int((length - 1) / 2)

    return distance_to_mid + rank_of_box
```


Overlapping Code:
```
 answer to part one of this day
Expectation is that the answer is in the
correct format"""
'''presume each spiral is a box, the box has a
length and a max digit value which would be the
length ** 2 in the bottom right corner'''
def box_len(index):
return 1 + 2*(index - 1)
def box_max(index):
return box_len(index) ** 2
'''find the box which contains our target
value by counting upward from 1 and checking
if the output is less than the target. If so,
then the box we're looking at is not the box
containing our target. Halt when greater or
equal to the target'''
rank_of_box = 1
while box_max(rank_of_box) < target:
rank_of_box += 1
'''get the side length of the box
containing the target value'''
length = box_len(rank_of_box)
'''take the diff of the target and the max
value of the preceeding box, mod by the length
of the current box to find the distance from the
center'''
distance_to_mid = (target - box_max(rank_of_box - 1)) % length
'''correct for approaching from the left or right of mid'''
if distance_to_mid > (length - 1) / 2:
distance_to_mid -= int((length - 1) / 2)
return distance_to_mid + rank
```
<Overlap Ratio: 0.9635732870771899>

---

--- 360 --
Question ID: 656d68b76888d9319c0b9be481f9b0478ac4314c_0
Original Code:
```
def _iris_data_input_fn():
  # Converts iris data to a logistic regression problem.
  iris = base.load_iris()
  ids = np.where((iris.target == 0) | (iris.target == 1))
  features = constant_op.constant(iris.data[ids], dtype=dtypes.float32)
  labels = constant_op.constant(iris.target[ids], dtype=dtypes.float32)
  labels = array_ops.reshape(labels, labels.get_shape().concatenate(1))
  return features, labels
```


Overlapping Code:
```
ata_input_fn():
# Converts iris data to a logistic regression problem.
iris = base.load_iris()
ids = np.where((iris.target == 0) | (iris.target == 1))
features = constant_op.constant(iris.data[ids], dtype=dtypes.float32)
labels = constant_op.constant(iris.target[ids], dtype=dtypes.float32)
labels = array_ops.reshape(labels, labels.get_shape().conca
```
<Overlap Ratio: 0.8860759493670886>

---

--- 361 --
Question ID: d9e3428e2966176db989cf7f03ab1258cb971577_2
Original Code:
```
def friendly_time(last_update):
    minutes = last_update / 60
    seconds = last_update % 60

    friendly_time = []
    if minutes > 0:
        friendly_time.append(ungettext(
                '%(minutes)i minute',
                '%(minutes)i minutes',
                minutes
        ) % {'minutes': minutes })
    if seconds > 0:
        friendly_time.append(ungettext(
                '%(seconds)i second',
                '%(seconds)i seconds',
                seconds
        ) % {'seconds': seconds })

    return friendly_time or 0
```


Overlapping Code:
```
f friendly_time(last_update):
minutes = last_update / 60
seconds = last_update % 60
friendly_time = []
if minutes > 0:
friendly_time.append(ungettext(
'%(minutes)i minute',
'%(minutes)i minutes',
minutes
) % {'minutes': minutes })
if seconds > 0:
friendly_time.append(ungettext(
'%(seconds)i second',
'%(seconds)i seconds',
seconds
) % {'seconds': se
```
<Overlap Ratio: 0.9067357512953368>

---

--- 362 --
Question ID: 0e53e23550de4108c21d59ae7b69046bae03b85c_1
Original Code:
```
def schedule_menu_button():
    tomorrow_hyb_button = [{
        "action": {
            "type": "text",
            "payload": "{\"button\":\"tomorrow_hyb_button\"}",
            "label": "Расписание с заменами на завтра"
        },
        "color": action_button_color
    }]
    today_hyb_button = [{
        "action": {
            "type": "text",
            "payload": "{\"button\":\"today_hyb_button\"}",
            "label": "Расписание с заменами на сегодня"
        },
        "color": action_button_color
    }]

    tomorrow_sch_button = [{
        "action": {
            "type": "text",
            "payload": "{\"button\":\"tomorrow_sch_button\"}",
            "label": "Расписание без замен на завтра"
        },
        "color": action_button_color
    }]
    today_sch_button = [{
        "action": {
            "type": "text",
            "payload": "{\"button\":\"today_sch_button\"}",
            "label": "Расписание без замен на сегодня"
        },
        "color": action_button_color
    }]

    back_button = [{
        "action": {
            "type": "text",
            "payload": "{\"button\":\"main_menu\"}",
            "label": "Назад"
        },
        "color": sub_menu_button_color
    }]

    return [
        tomorrow_hyb_button, today_hyb_button, tomorrow_sch_button,
        today_sch_button, back_button
    ]
```


Overlapping Code:
```
ef schedule_menu_button():
tomorrow_hyb_button = [{
"action": {
"type": "text",
"payload": "{\"button\":\"tomorrow_hyb_button\"}",
"label": "Расписание с заменами на завтра"
},
"color": action_button_color
}]
today_hyb_button = [{
"action": {
"type": "text",
"payload": "{\"button\":\"today_hyb_button\"}",
"label": "Расписание с заменами на сегодня"
},
"color": action_button_color
}]
tomorrow_sch_button = [{
"action": {
"type": "text",
"payload": "{\"button\":\"tomorrow_sch_button\"}",
"label": "Расписание без замен на завтра"
},
"color": action_button_color
}]
today_sch_button = [{
"action": {
"type": "text",
"payload": "{\"button\":\"today_sch_button\"}",
"label": "Расписание без замен на сегодня"
},
"color": action_button_color
}]
back_button = [{
"action": {
"type": "text",
"payload": "{\"button\":\"main_menu\"}",
"label": "Назад"
},
"color": sub_menu_button_color
}]
return [
tomorrow_hyb_button, today_hyb_button, tomorrow_sch_button
```
<Overlap Ratio: 0.9654471544715447>

---

--- 363 --
Question ID: 5fdbf1bd97929e0ec5856ba7e3de146a99e45281_1
Original Code:
```
@pytest.mark.parametrize("method", methods)
@pytest.mark.moco
def test_create_motion_correction_workflow(method):
    moco_wf = create_motion_correction_workflow(method=method)
    moco_wf.base_dir = '/tmp/spynoza/workingdir'
    moco_wf.inputs.inputspec.in_files = [op.join(test_data_path, 'func', 'sub-0020_task-harriri_bold_cut.nii.gz'),
                                         op.join(test_data_path, 'func', 'sub-0020_task-wm_bold_cut.nii.gz')]
    moco_wf.inputs.inputspec.output_directory = '/tmp/spynoza'
    moco_wf.inputs.inputspec.sub_id = 'sub-0020'
    moco_wf.inputs.inputspec.tr = 2.0
    moco_wf.inputs.inputspec.which_file_is_EPI_space = 'first'
    moco_wf.run()

    datasink = op.join(moco_wf.inputs.inputspec.output_directory,
                       moco_wf.inputs.inputspec.sub_id, 'mcf')
    for f in moco_wf.inputs.inputspec.in_files:

        assert(op.isfile(op.join(datasink, op.basename(f).replace('.nii.gz', '_mcf.nii.gz'))))
        assert(op.isfile(op.join(datasink, 'motion_pars',
                                 op.basename(f).replace('.nii.gz', '_mcf.par'))))
        assert (op.isfile(op.join(datasink, 'motion_plots',
                                  op.basename(f).replace('.nii.gz', '_mcf_rot.png'))))
        assert (op.isfile(op.join(datasink, 'motion_plots',
                                  op.basename(f).replace('.nii.gz', '_mcf_rot.png'))))
```


Overlapping Code:
```
trize("method", methods)
@pytest.mark.moco
def test_create_motion_correction_workflow(method):
moco_wf = create_motion_correction_workflow(method=method)
moco_wf.base_dir = '/tmp/spynoza/workingdir'
moco_wf.inputs.inputspec.in_files = [op.join(test_data_path, 'func', 'sub-0020_task-harriri_bold_cut.nii.gz'),
op.join(test_data_path, 'func', 'sub-0020_task-wm_bold_cut.nii.gz')]
moco_wf.inputs.inputspec.output_directory = '/tmp/spynoza'
moco_wf.inputs.inputspec.sub_id = 'sub-0020'
moco_wf.inputs.inputspec.tr = 2.0
moco_wf.inputs.inputspec.which_file_is_EPI_space = 'first'
moco_wf.run()
datasink = op.join(moco_wf.inputs.inputspec.output_directory,
moco_wf.inputs.inputspec.sub_id, 'mcf')
for f in moco_wf.inputs.inputspec.in_files:
assert(op.isfile(op.join(datasink, op.basename(f).replace('.nii.gz', '_mcf.nii.gz'))))
assert(op.isfile(op.join(datasink, 'motion_pars',
op.basename(f).replace('.nii.gz', '_mcf.par'))))
assert (op.isfile(op.join(datasink, 'motion_plots',
op.basename(f).replace('.nii.gz', '_mcf_rot.png'))))
assert (op.isfile(op.join(datasink, 'motion_plots',
op.basename(f).replace('.n
```
<Overlap Ratio: 0.9608695652173913>

---

--- 364 --
Question ID: 0ed777d146310fec6eba351a6a399a91663445a5_2
Original Code:
```
def test_action_defer_3():
    # GIVEN
    expected = [
        fluent_initiate('a', [], 0),
        action('p1a', [2], (1, 2)),
        action('p2a', [1], (1, 2)),
        action('p1a', [2], (2, 3)),
        action('p2a', [1], (2, 3)),
    ]

    # WHEN
    actual = run_pylps_test_program('misc', 'action_defer_3')

    # THEN
    assert actual == expected
```


Overlapping Code:
```
 = [
fluent_initiate('a', [], 0),
action('p1a', [2], (1, 2)),
action('p2a', [1], (1, 2)),
action('p1a', [2], (2, 3)),
action('p2a', [1], (2, 3)),
]
# WHEN
actual = run_pylps_test_program('misc', 'acti
```
<Overlap Ratio: 0.6944444444444444>

---

--- 365 --
Question ID: 3e587af21fe036f73f1170717fd90b954485b43d_3
Original Code:
```
def download_sstable_to_path(
    config,
    path,
    objects,
    sstable_context,
    mutable_mtime
):
    if (path / 'data').exists():
        """Note that we use the existence of a directory named 'data' to
        inhibit downloads. This stands in contrast to uploads, which we inhibit
        with separate marker files.

        The practical upshot is that, if we are going to put a directory called
        'data' in place, it had better contain valid data.
        """
        return

    provider_args = {
        config['encryption']['provider']: config['encryption']['args']
    }

    uploaded_dir = path / 'uploaded'
    uploaded_dir.mkdir()

    with MovingTemporaryDirectory(path / 'data') as temp:
        for (marker_name, s3_object) in objects:
            context = dict(sstable_context)
            context.update(config['context'])
            context['component'] = marker_name
            context['continuity'] = continuity_code
            if marker_name == 'mutable':
                context['timestamp'] = mutable_mtime

            marker_path = uploaded_dir / marker_name
            download_to_path(
                marker_path,
                s3_object,
                temp.path,
                provider_args,
                context,
            )

        temp.finalize()
```


Overlapping Code:
```
,
path,
objects,
sstable_context,
mutable_mtime
):
if (path / 'data').exists():
"""Note that we use the existence of a directory named 'data' to
inhibit downloads. This stands in contrast to uploads, which we inhibit
with separate marker files.
The practical upshot is that, if we are going to put a directory called
'data' in place, it had better contain valid data.
"""
return
provider_args = {
config['encryption']['provider']: config['encryption']['args']
}
uploaded_dir = path / 'uploaded'
uploaded_dir.mkdir()
with MovingTemporaryDirectory(path / 'data') as temp:
for (marker_name, s3_object) in objects:
context = dict(sstable_context)
context.update(config['context'])
context['component'] = marker_name
context['continuity'] = continuity_code
if marker_name == 'mutable':
context['timestamp'] = mutable_mtime
marker_path = uploaded_dir / marker_name
download_to_path(
marker_path,
s3_object,
temp.path,
provider_args,
context,
)
temp.finaliz
```
<Overlap Ratio: 0.9605662285136501>

---

--- 366 --
Question ID: 06c034cd372e536a6116c1b023c17467b282dc84_3
Original Code:
```
@app.route('/api', methods=['POST', 'GET'])
def api():
    if request.method == "GET":
        q = request.args.get('q', '')
    elif request.method == "POST":
        q = request.form.get('q', '')

    q, vs = process_query(q)

    embedding_sample, low_dim_embedding_sample, label_sample = sample_embedding()

    inx_embedding = vs[EMBEDDING]
    inx_low_dim_embedding = vs[LOW_DIM_EMBEDDING]

    idx, _ = calc_n_cosine_neighbor(
        inx_embedding[np.newaxis, :], embedding_sample, N_NEIGHBOR)
    labels = [label_sample[i] for i in idx]

    # if query does not exist, it is hard to know it's low_dim_embedding coordinates
    # assume it locates in the cloest neighbor
    info = q
    if inx_low_dim_embedding is None:
        inx_low_dim_embedding = low_dim_embedding_sample[idx[-1], :]
        info = "Nonexistent word: " + q

    fig = plot_interactive_scatter(
        low_dim_embedding_sample[idx, :], labels, inx_low_dim_embedding[np.newaxis, :], q, info)

    return mpld3.fig_to_html(fig)
```


Overlapping Code:
```
', 'GET'])
def api():
if request.method == "GET":
q = request.args.get('q', '')
elif request.method == "POST":
q = request.form.get('q', '')
q, vs = process_query(q)
embedding_sample, low_dim_embedding_sample, label_sample = sample_embedding()
inx_embedding = vs[EMBEDDING]
inx_low_dim_embedding = vs[LOW_DIM_EMBEDDING]
idx, _ = calc_n_cosine_neighbor(
inx_embedding[np.newaxis, :], embedding_sample, N_NEIGHBOR)
labels = [label_sample[i] for i in idx]
# if query does not exist, it is hard to know it's low_dim_embedding coordinates
# assume it locates in the cloest neighbor
info = q
if inx_low_dim_embedding is None:
inx_low_dim_embedding = low_dim_embedding_sample[idx[-1], :]
info = "Nonexistent word: " + q
fig = plot_interactive_scatter(
low_dim_embedding_sample[idx, :], labels, inx_low_dim_embedding[np.newaxis, :], q, info)
return mpld3.fig
```
<Overlap Ratio: 0.9486607142857143>

---

--- 367 --
Question ID: 4a1193ffcf4f587b2ebcb0b48dd91207ccdf45e4_22
Original Code:
```
def getTopRigs(conn, limit):
	cursor = conn.cursor()
	query = 'SELECT extra_data, Count(*) AS total FROM blockchain GROUP BY extra_data ORDER BY total DESC LIMIT %s'
	cursor.execute(query,limit)
	data = cursor.fetchall()
	cursor.close()
	return data
```


Overlapping Code:
```
:
cursor = conn.cursor()
query = 'SELECT extra_data, Count(*) AS total FROM blockchain GROUP BY extra_data ORDER BY total DESC LIMIT %s'
cursor.execute(query,limit)
data = cursor.fetchall()
cursor.close()
return data
```
<Overlap Ratio: 0.8888888888888888>

---

--- 368 --
Question ID: 2f859f8994e33ba15117d31607c058c7b04356ed_6
Original Code:
```
def runSimulation():
    global flightScore, otherPartStatus
    # stuff = [[1, 1, 2, [1, 0]], [2, 1, 0, [1, 0]],  [2, 1, 1, [1, 0]] , [2, 1, 2, [1, 0]] , [2, 1, 3, [1, 0]], [2, 1, 4, [1, 0]], [3, 1, 2, [1, 0]], [4, 1, 2, [1, 0]]]
    # stuff = [[-3, 0, -6, [35, 0]], [-3, 1, 2, [35, 0]], [-2, 1, 2, [35, 0]], [-2, 1, 3, [35, 0]], [-1, 1, -4, [35, 0]], [-1, 1, 2, [35, 0]], [-1, 1, 3, [35, 0]], [-1, 1, 4, [35, 0]], [0, 1, -4, [35, 0]], [0, 1, 2, [35, 0]], [0, 1, 3, [35, 0]], [0, 1, 4, [35, 0]], [1, 0, -3, [35, 15]], [1, 1, -4, [35, 0]], [1, 1, -3, [35, 0]], [1, 1, 2, [35, 0]], [1, 1, 3, [35, 0]], [1, 1, 4, [35, 0]], [2, 1, -4, [35, 0]], [2, 1, -3, [35, 0]], [2, 1, -2, [35, 0]], [2, 1, -1, [35, 0]], [2, 1, 0, [35, 0]], [2, 1, 1, [35, 0]], [2, 1, 2, [35, 0]], [2, 1, 3, [35, 0]], [2, 1, 4, [35, 0]], [2, 1, 5, [35, 0]], [2, 1, 6, [35, 0]], [2, 1, 7, [35, 0]], [2, 1, 8, [35, 0]], [2, 2, -4, [35, 0]], [2, 2, -3, [35, 0]], [2, 2, -2, [20, 0]], [2, 2, -1, [35, 0]], [2, 2, 0, [20, 0]], [2, 2, 1, [35, 0]], [2, 2, 2, [20, 0]], [2, 2, 3, [35, 0]], [2, 2, 4, [20, 0]], [2, 2, 5, [35, 0]], [2, 2, 6, [20, 0]], [2, 2, 7, [35, 0]], [2, 2, 8, [20, 0]], [3, 0, 8, [35, 15]], [3, 1, -4, [35, 0]], [3, 1, -3, [35, 0]], [3, 1, -2, [35, 0]], [3, 1, -1, [35, 0]], [3, 1, 0, [35, 0]], [3, 1, 1, [35, 0]], [3, 1, 2, [35, 0]], [3, 1, 3, [35, 0]], [3, 1, 4, [35, 0]], [3, 1, 5, [35, 0]], [3, 1, 6, [35, 0]], [3, 1, 7, [35, 0]], [3, 1, 8, [35, 0]], [3, 1, 9, [35, 0]], [3, 2, -4, [35, 0]], [3, 2, 9, [20, 0]], [3, 3, -4, [35, 0]], [3, 3, -3, [35, 0]], [3, 3, -2, [35, 0]], [3, 3, -1, [35, 0]], [3, 3, 0, [35, 0]], [3, 3, 1, [35, 0]], [3, 3, 2, [35, 0]], [3, 3, 3, [35, 0]], [3, 3, 4, [35, 0]], [3, 3, 5, [35, 0]], [3, 3, 6, [35, 0]], [3, 3, 7, [35, 0]], [3, 3, 8, [20, 0]], [3, 4, -4, [35, 0]], [4, 1, -4, [35, 0]], [4, 1, -3, [35, 0]], [4, 1, -2, [35, 0]], [4, 1, -1, [35, 0]], [4, 1, 0, [35, 0]], [4, 1, 1, [35, 0]], [4, 1, 2, [35, 0]], [4, 1, 3, [35, 0]], [4, 1, 4, [35, 0]], [4, 1, 5, [35, 0]], [4, 1, 6, [35, 0]], [4, 1, 7, [35, 0]], [4, 1, 8, [35, 0]], [4, 2, -4, [35, 0]], [4, 2, -3, [35, 0]], [4, 2, -2, [20, 0]], [4, 2, -1, [35, 0]], [4, 2, 0, [20, 0]], [4, 2, 1, [35, 0]], [4, 2, 2, [20, 0]], [4, 2, 3, [35, 0]], [4, 2, 4, [20, 0]], [4, 2, 5, [35, 0]], [4, 2, 6, [20, 0]], [4, 2, 7, [35, 0]], [4, 2, 8, [20, 0]], [5, 0, -3, [35, 15]], [5, 1, -4, [35, 0]], [5, 1, -3, [35, 0]], [5, 1, 2, [35, 0]], [5, 1, 3, [35, 0]], [5, 1, 4, [35, 0]], [6, 1, -4, [35, 0]], [6, 1, 2, [35, 0]], [6, 1, 3, [35, 0]], [6, 1, 4, [35, 0]], [7, 1, -4, [35, 0]], [7, 1, 2, [35, 0]], [7, 1, 3, [35, 0]], [7, 1, 4, [35, 0]], [8, 1, 2, [35, 0]], [8, 1, 3, [35, 0]], [9, 1, 2, [35, 0]], [11, 0, 10, [45, 0]], [11, 1, 10, [45, 0]], [11, 2, 10, [45, 0]], [11, 3, 10, [45, 0]], [11, 4, 10, [45, 0]], [11, 5, 10, [45, 0]]]
    # stuff = [[-3, 1, 2, [35, 0]], [-2, 1, 2, [35, 0]], [-2, 1, 3, [35, 0]], [-1, 1, -4, [35, 0]], [-1, 1, 2, [35, 0]], [-1, 1, 3, [35, 0]], [-1, 1, 4, [35, 0]], [0, 1, -4, [35, 0]], [0, 1, 2, [35, 0]], [0, 1, 3, [35, 0]], [0, 1, 4, [35, 0]], [1, 0, -3, [35, 15]], [1, 1, -4, [35, 0]], [1, 1, -3, [35, 0]], [1, 1, 2, [35, 0]], [1, 1, 3, [35, 0]], [1, 1, 4, [35, 0]], [2, 1, -4, [35, 0]], [2, 1, -3, [35, 0]], [2, 1, -2, [35, 0]], [2, 1, -1, [35, 0]], [2, 1, 0, [35, 0]], [2, 1, 1, [35, 0]], [2, 1, 2, [35, 0]], [2, 1, 3, [35, 0]], [2, 1, 4, [35, 0]], [2, 1, 5, [35, 0]], [2, 1, 6, [35, 0]], [2, 1, 7, [35, 0]], [2, 1, 8, [35, 0]], [2, 2, -4, [35, 0]], [2, 2, -3, [35, 0]], [2, 2, -2, [20, 0]], [2, 2, -1, [35, 0]], [2, 2, 0, [20, 0]], [2, 2, 1, [35, 0]], [2, 2, 2, [20, 0]], [2, 2, 3, [35, 0]], [2, 2, 4, [20, 0]], [2, 2, 5, [35, 0]], [2, 2, 6, [20, 0]], [2, 2, 7, [35, 0]], [2, 2, 8, [20, 0]], [3, 0, 8, [35, 15]], [3, 1, -4, [35, 0]], [3, 1, -3, [35, 0]], [3, 1, -2, [35, 0]], [3, 1, -1, [35, 0]], [3, 1, 0, [35, 0]], [3, 1, 1, [35, 0]], [3, 1, 2, [35, 0]], [3, 1, 3, [35, 0]], [3, 1, 4, [35, 0]], [3, 1, 5, [35, 0]], [3, 1, 6, [35, 0]], [3, 1, 7, [35, 0]], [3, 1, 8, [35, 0]], [3, 1, 9, [35, 0]], [3, 2, -4, [35, 0]], [3, 2, 9, [20, 0]], [3, 3, -4, [35, 0]], [3, 3, -3, [35, 0]], [3, 3, -2, [35, 0]], [3, 3, -1, [35, 0]], [3, 3, 0, [35, 0]], [3, 3, 1, [35, 0]], [3, 3, 2, [35, 0]], [3, 3, 3, [35, 0]], [3, 3, 4, [35, 0]], [3, 3, 5, [35, 0]], [3, 3, 6, [35, 0]], [3, 3, 7, [35, 0]], [3, 3, 8, [20, 0]], [3, 4, -4, [35, 0]], [4, 1, -4, [35, 0]], [4, 1, -3, [35, 0]], [4, 1, -2, [35, 0]], [4, 1, -1, [35, 0]], [4, 1, 0, [35, 0]], [4, 1, 1, [35, 0]], [4, 1, 2, [35, 0]], [4, 1, 3, [35, 0]], [4, 1, 4, [35, 0]], [4, 1, 5, [35, 0]], [4, 1, 6, [35, 0]], [4, 1, 7, [35, 0]], [4, 1, 8, [35, 0]], [4, 2, -4, [35, 0]], [4, 2, -3, [35, 0]], [4, 2, -2, [20, 0]], [4, 2, -1, [35, 0]], [4, 2, 0, [20, 0]], [4, 2, 1, [35, 0]], [4, 2, 2, [20, 0]], [4, 2, 3, [35, 0]], [4, 2, 4, [20, 0]], [4, 2, 5, [35, 0]], [4, 2, 6, [20, 0]], [4, 2, 7, [35, 0]], [4, 2, 8, [20, 0]], [5, 0, -3, [35, 15]], [5, 1, -4, [35, 0]], [5, 1, -3, [35, 0]], [5, 1, 2, [35, 0]], [5, 1, 3, [35, 0]], [5, 1, 4, [35, 0]], [6, 1, -4, [35, 0]], [6, 1, 2, [35, 0]], [6, 1, 3, [35, 0]], [6, 1, 4, [35, 0]], [7, 1, -4, [35, 0]], [7, 1, 2, [35, 0]], [7, 1, 3, [35, 0]], [7, 1, 4, [35, 0]], [8, 1, 2, [35, 0]], [8, 1, 3, [35, 0]], [9, 1, 2, [35, 0]]]

    # North facing plane
    # stuff = [[-22, 0, -2, [35, 15]], [-22, 0, 2, [35, 15]], [-22, 1, -2, [1, 0]], [-22, 1, -1, [1, 0]], [-22, 1, 0, [1, 0]], [-22, 1, 1, [1, 0]], [-22, 1, 2, [1, 0]], [-22, 2, -1, [1, 0]], [-22, 2, 1, [1, 0]], [-22, 3, 0, [1, 0]], [-21, 1, -1, [1, 0]], [-21, 1, 0, [1, 0]], [-21, 1, 1, [1, 0]], [-21, 2, -1, [20, 0]], [-21, 2, 1, [20, 0]], [-21, 3, 0, [1, 0]], [-20, 1, -1, [1, 0]], [-20, 1, 0, [1, 0]], [-20, 1, 1, [1, 0]], [-20, 2, -1, [1, 0]], [-20, 2, 1, [1, 0]], [-20, 3, 0, [1, 0]], [-19, 1, -1, [1, 0]], [-19, 1, 0, [1, 0]], [-19, 1, 1, [1, 0]], [-19, 2, -1, [20, 0]], [-19, 2, 1, [20, 0]], [-19, 3, 0, [1, 0]], [-18, 1, -1, [1, 0]], [-18, 1, 0, [1, 0]], [-18, 1, 1, [1, 0]], [-18, 2, -1, [1, 0]], [-18, 2, 1, [1, 0]], [-18, 3, 0, [1, 0]], [-17, 1, -6, [1, 0]], [-17, 1, -5, [1, 0]], [-17, 1, -4, [1, 0]], [-17, 1, -3, [1, 0]], [-17, 1, -2, [1, 0]], [-17, 1, -1, [1, 0]], [-17, 1, 0, [1, 0]], [-17, 1, 1, [1, 0]], [-17, 1, 2, [1, 0]], [-17, 1, 3, [1, 0]], [-17, 1, 4, [1, 0]], [-17, 1, 5, [1, 0]], [-17, 1, 6, [1, 0]], [-17, 2, -1, [20, 0]], [-17, 2, 1, [20, 0]], [-17, 3, 0, [1, 0]], [-16, 1, -5, [1, 0]], [-16, 1, -4, [1, 0]], [-16, 1, -3, [1, 0]], [-16, 1, -2, [1, 0]], [-16, 1, -1, [1, 0]], [-16, 1, 0, [1, 0]], [-16, 1, 1, [1, 0]], [-16, 1, 2, [1, 0]], [-16, 1, 3, [1, 0]], [-16, 1, 4, [1, 0]], [-16, 1, 5, [1, 0]], [-16, 2, -1, [1, 0]], [-16, 2, 1, [1, 0]], [-16, 3, 0, [1, 0]], [-15, 1, -4, [1, 0]], [-15, 1, -3, [1, 0]], [-15, 1, -2, [1, 0]], [-15, 1, -1, [1, 0]], [-15, 1, 0, [1, 0]], [-15, 1, 1, [1, 0]], [-15, 1, 2, [1, 0]], [-15, 1, 3, [1, 0]], [-15, 1, 4, [1, 0]], [-15, 2, -1, [20, 0]], [-15, 2, 1, [20, 0]], [-15, 3, 0, [1, 0]], [-14, 1, -1, [1, 0]], [-14, 1, 0, [1, 0]], [-14, 1, 1, [1, 0]], [-14, 2, -1, [1, 0]], [-14, 2, 1, [1, 0]], [-14, 3, 0, [1, 0]], [-13, 1, -1, [1, 0]], [-13, 1, 0, [1, 0]], [-13, 1, 1, [1, 0]], [-13, 2, -1, [20, 0]], [-13, 2, 1, [20, 0]], [-13, 3, 0, [1, 0]], [-12, 1, -1, [1, 0]], [-12, 1, 0, [1, 0]], [-12, 1, 1, [1, 0]], [-12, 2, -1, [1, 0]], [-12, 2, 1, [1, 0]], [-12, 3, 0, [1, 0]], [-11, 0, 0, [35, 15]], [-11, 1, -1, [1, 0]], [-11, 1, 0, [1, 0]], [-11, 1, 1, [1, 0]], [-11, 2, -1, [20, 0]], [-11, 2, 1, [20, 0]], [-11, 3, 0, [20, 0]], [-10, 1, 0, [1, 0]], [-10, 2, 0, [20, 0]]]

    # West facing plane
    # stuff = [[-3, 1, 2, [1, 0]], [-2, 1, 2, [1, 0]], [-2, 1, 3, [1, 0]], [-1, 1, -4, [1, 0]], [-1, 1, 2, [1, 0]], [-1, 1, 3, [1, 0]], [-1, 1, 4, [1, 0]], [0, 1, -4, [1, 0]], [0, 1, 2, [1, 0]], [0, 1, 3, [1, 0]], [0, 1, 4, [1, 0]], [1, 0, -3, [1, 15]], [1, 1, -4, [1, 0]], [1, 1, -3, [1, 0]], [1, 1, 2, [1, 0]], [1, 1, 3, [1, 0]], [1, 1, 4, [1, 0]], [2, 1, -4, [1, 0]], [2, 1, -3, [1, 0]], [2, 1, -2, [1, 0]], [2, 1, -1, [1, 0]], [2, 1, 0, [1, 0]], [2, 1, 1, [1, 0]], [2, 1, 2, [1, 0]], [2, 1, 3, [1, 0]], [2, 1, 4, [1, 0]], [2, 1, 5, [1, 0]], [2, 1, 6, [1, 0]], [2, 1, 7, [1, 0]], [2, 1, 8, [1, 0]], [2, 2, -4, [1, 0]], [2, 2, -3, [1, 0]], [2, 2, -2, [20, 0]], [2, 2, -1, [1, 0]], [2, 2, 0, [20, 0]], [2, 2, 1, [1, 0]], [2, 2, 2, [20, 0]], [2, 2, 3, [1, 0]], [2, 2, 4, [20, 0]], [2, 2, 5, [1, 0]], [2, 2, 6, [20, 0]], [2, 2, 7, [1, 0]], [2, 2, 8, [20, 0]], [3, 0, 8, [1, 15]], [3, 1, -4, [1, 0]], [3, 1, -3, [1, 0]], [3, 1, -2, [1, 0]], [3, 1, -1, [1, 0]], [3, 1, 0, [1, 0]], [3, 1, 1, [1, 0]], [3, 1, 2, [1, 0]], [3, 1, 3, [1, 0]], [3, 1, 4, [1, 0]], [3, 1, 5, [1, 0]], [3, 1, 6, [1, 0]], [3, 1, 7, [1, 0]], [3, 1, 8, [1, 0]], [3, 1, 9, [1, 0]], [3, 2, -4, [1, 0]], [3, 2, 9, [20, 0]], [3, 3, -4, [1, 0]], [3, 3, -3, [1, 0]], [3, 3, -2, [1, 0]], [3, 3, -1, [1, 0]], [3, 3, 0, [1, 0]], [3, 3, 1, [1, 0]], [3, 3, 2, [1, 0]], [3, 3, 3, [1, 0]], [3, 3, 4, [1, 0]], [3, 3, 5, [1, 0]], [3, 3, 6, [1, 0]], [3, 3, 7, [1, 0]], [3, 3, 8, [20, 0]], [3, 4, -4, [1, 0]], [4, 1, -4, [1, 0]], [4, 1, -3, [1, 0]], [4, 1, -2, [1, 0]], [4, 1, -1, [1, 0]], [4, 1, 0, [1, 0]], [4, 1, 1, [1, 0]], [4, 1, 2, [1, 0]], [4, 1, 3, [1, 0]], [4, 1, 4, [1, 0]], [4, 1, 5, [1, 0]], [4, 1, 6, [1, 0]], [4, 1, 7, [1, 0]], [4, 1, 8, [1, 0]], [4, 2, -4, [1, 0]], [4, 2, -3, [1, 0]], [4, 2, -2, [20, 0]], [4, 2, -1, [1, 0]], [4, 2, 0, [20, 0]], [4, 2, 1, [1, 0]], [4, 2, 2, [20, 0]], [4, 2, 3, [1, 0]], [4, 2, 4, [20, 0]], [4, 2, 5, [1, 0]], [4, 2, 6, [20, 0]], [4, 2, 7, [1, 0]], [4, 2, 8, [20, 0]], [5, 0, -3, [1, 15]], [5, 1, -4, [1, 0]], [5, 1, -3, [1, 0]], [5, 1, 2, [1, 0]], [5, 1, 3, [1, 0]], [5, 1, 4, [1, 0]], [6, 1, -4, [1, 0]], [6, 1, 2, [1, 0]], [6, 1, 3, [1, 0]], [6, 1, 4, [1, 0]], [7, 1, -4, [1, 0]], [7, 1, 2, [1, 0]], [7, 1, 3, [1, 0]], [7, 1, 4, [1, 0]], [8, 1, 2, [1, 0]], [8, 1, 3, [1, 0]], [9, 1, 2, [1, 0]]]

    # West experiment
    # stuff = [[-3, 1, 2, [35, 0]], [-2, 1, 2, [35, 0]], [-2, 1, 3, [35, 0]], [-1, 1, -4, [35, 0]], [-1, 1, 2, [35, 0]], [-1, 1, 3, [35, 0]], [-1, 1, 4, [35, 0]], [0, 1, -4, [35, 0]], [0, 1, 2, [35, 0]], [0, 1, 3, [35, 0]], [0, 1, 4, [35, 0]], [1, 0, -3, [35, 15]], [1, 1, -4, [35, 0]], [1, 1, -3, [35, 0]], [1, 1, 2, [35, 0]], [1, 1, 3, [35, 0]], [1, 1, 4, [35, 0]], [2, 1, -4, [35, 0]], [2, 1, -3, [35, 0]], [2, 1, -2, [35, 0]], [2, 1, -1, [35, 0]], [2, 1, 0, [35, 0]], [2, 1, 1, [35, 0]], [2, 1, 2, [35, 0]], [2, 1, 3, [35, 0]], [2, 1, 4, [35, 0]], [2, 1, 5, [35, 0]], [2, 1, 6, [35, 0]], [2, 1, 7, [35, 0]], [2, 1, 8, [35, 0]], [2, 2, -4, [35, 0]], [2, 2, -3, [35, 0]], [2, 2, -2, [20, 0]], [2, 2, -1, [35, 0]], [2, 2, 0, [20, 0]], [2, 2, 1, [35, 0]], [2, 2, 2, [20, 0]], [2, 2, 3, [35, 0]], [2, 2, 4, [20, 0]], [2, 2, 5, [35, 0]], [2, 2, 6, [20, 0]], [2, 2, 7, [35, 0]], [2, 2, 8, [20, 0]], [3, 0, 8, [35, 15]], [3, 1, -4, [35, 0]], [3, 1, -3, [35, 0]], [3, 1, -2, [35, 0]], [3, 1, -1, [35, 0]], [3, 1, 0, [35, 0]], [3, 1, 1, [35, 0]], [3, 1, 2, [35, 0]], [3, 1, 3, [35, 0]], [3, 1, 4, [35, 0]], [3, 1, 5, [35, 0]], [3, 1, 6, [35, 0]], [3, 1, 7, [35, 0]], [3, 1, 8, [35, 0]], [3, 1, 9, [35, 0]], [3, 2, -4, [35, 0]], [3, 2, 9, [20, 0]], [3, 3, -4, [35, 0]], [3, 3, -3, [35, 0]], [3, 3, -2, [35, 0]], [3, 3, -1, [35, 0]], [3, 3, 0, [35, 0]], [3, 3, 1, [35, 0]], [3, 3, 2, [35, 0]], [3, 3, 3, [35, 0]], [3, 3, 4, [35, 0]], [3, 3, 5, [35, 0]], [3, 3, 6, [35, 0]], [3, 3, 7, [35, 0]], [3, 3, 8, [20, 0]], [3, 4, -4, [35, 0]], [4, 1, -4, [35, 0]], [4, 1, -3, [35, 0]], [4, 1, -2, [35, 0]], [4, 1, -1, [35, 0]], [4, 1, 0, [35, 0]], [4, 1, 1, [35, 0]], [4, 1, 2, [35, 0]], [4, 1, 3, [35, 0]], [4, 1, 4, [35, 0]], [4, 1, 5, [35, 0]], [4, 1, 6, [35, 0]], [4, 1, 7, [35, 0]], [4, 1, 8, [35, 0]], [4, 2, -4, [35, 0]], [4, 2, -3, [35, 0]], [4, 2, -2, [20, 0]], [4, 2, -1, [35, 0]], [4, 2, 0, [20, 0]], [4, 2, 1, [35, 0]], [4, 2, 2, [20, 0]], [4, 2, 3, [35, 0]], [4, 2, 4, [20, 0]], [4, 2, 5, [35, 0]], [4, 2, 6, [20, 0]], [4, 2, 7, [35, 0]], [4, 2, 8, [20, 0]], [5, 0, -3, [35, 15]], [5, 1, -4, [35, 0]], [5, 1, -3, [35, 0]], [5, 1, 2, [35, 0]], [5, 1, 3, [35, 0]], [5, 1, 4, [35, 0]], [6, 1, -4, [35, 0]], [6, 1, 2, [35, 0]], [6, 1, 3, [35, 0]], [6, 1, 4, [35, 0]], [7, 1, -4, [35, 0]], [7, 1, 2, [35, 0]], [7, 1, 3, [35, 0]], [7, 1, 4, [35, 0]], [8, 1, 2, [35, 0]], [8, 1, 3, [35, 0]], [9, 1, 2, [35, 0]]]

    # West wool
    WoolStuff = [[13, 1, 2, [35, 14]], [14, 1, 2, [35, 14]], [14, 1, 3, [35, 14]], [15, 1, -4, [35, 13]],
                 [15, 1, 2, [35, 14]], [15, 1, 3, [35, 14]], [15, 1, 4, [35, 14]], [16, 1, -4, [35, 13]],
                 [16, 1, 2, [35, 14]], [16, 1, 3, [35, 14]], [16, 1, 4, [35, 14]], [17, 0, -3, [35, 13]],
                 [17, 1, -4, [35, 13]], [17, 1, -3, [35, 13]], [17, 1, 2, [35, 14]], [17, 1, 3, [35, 14]],
                 [17, 1, 4, [35, 14]], [18, 1, -4, [35, 12]], [18, 1, -3, [35, 5]], [18, 1, -2, [35, 5]],
                 [18, 1, -1, [35, 3]], [18, 1, 0, [35, 3]], [18, 1, 1, [35, 3]], [18, 1, 2, [35, 15]],
                 [18, 1, 3, [35, 15]], [18, 1, 4, [35, 15]], [18, 1, 5, [35, 1]], [18, 1, 6, [35, 1]],
                 [18, 1, 7, [35, 1]], [18, 1, 8, [35, 2]], [18, 2, -4, [35, 12]], [18, 2, -3, [35, 5]],
                 [18, 2, -2, [35, 5]], [18, 2, -1, [35, 3]], [18, 2, 0, [35, 3]], [18, 2, 1, [35, 3]],
                 [18, 2, 2, [35, 15]], [18, 2, 3, [35, 15]], [18, 2, 4, [35, 15]], [18, 2, 5, [35, 1]],
                 [18, 2, 6, [35, 1]], [18, 2, 7, [35, 1]], [18, 2, 8, [35, 2]], [19, 0, 8, [35, 2]],
                 [19, 1, -4, [35, 12]], [19, 1, -3, [35, 5]], [19, 1, -2, [35, 5]], [19, 1, -1, [35, 3]],
                 [19, 1, 0, [35, 3]], [19, 1, 1, [35, 3]], [19, 1, 2, [35, 15]], [19, 1, 3, [35, 15]],
                 [19, 1, 4, [35, 15]], [19, 1, 5, [35, 1]], [19, 1, 6, [35, 1]], [19, 1, 7, [35, 1]],
                 [19, 1, 8, [35, 2]], [19, 1, 9, [35, 2]], [19, 2, -4, [35, 12]], [19, 2, 9, [35, 2]],
                 [19, 3, -4, [35, 12]], [19, 3, -3, [35, 5]], [19, 3, -2, [35, 5]], [19, 3, -1, [35, 3]],
                 [19, 3, 0, [35, 3]], [19, 3, 1, [35, 3]], [19, 3, 2, [35, 15]], [19, 3, 3, [35, 15]],
                 [19, 3, 4, [35, 15]], [19, 3, 5, [35, 1]], [19, 3, 6, [35, 1]], [19, 3, 7, [35, 1]],
                 [19, 3, 8, [35, 2]], [19, 4, -4, [35, 12]], [20, 1, -4, [35, 12]], [20, 1, -3, [35, 5]],
                 [20, 1, -2, [35, 5]], [20, 1, -1, [35, 3]], [20, 1, 0, [35, 3]], [20, 1, 1, [35, 3]],
                 [20, 1, 2, [35, 15]], [20, 1, 3, [35, 15]], [20, 1, 4, [35, 15]], [20, 1, 5, [35, 1]],
                 [20, 1, 6, [35, 1]], [20, 1, 7, [35, 1]], [20, 1, 8, [35, 2]], [20, 2, -4, [35, 12]],
                 [20, 2, -3, [35, 5]], [20, 2, -2, [35, 5]], [20, 2, -1, [35, 3]], [20, 2, 0, [35, 3]],
                 [20, 2, 1, [35, 3]], [20, 2, 2, [35, 15]], [20, 2, 3, [35, 15]], [20, 2, 4, [35, 15]],
                 [20, 2, 5, [35, 1]], [20, 2, 6, [35, 1]], [20, 2, 7, [35, 1]], [20, 2, 8, [35, 2]],
                 [21, 0, -3, [35, 6]], [21, 1, -4, [35, 6]], [21, 1, -3, [35, 6]], [21, 1, 2, [35, 4]],
                 [21, 1, 3, [35, 4]], [21, 1, 4, [35, 4]], [22, 1, -4, [35, 6]], [22, 1, 2, [35, 4]],
                 [22, 1, 3, [35, 4]], [22, 1, 4, [35, 4]], [23, 1, -4, [35, 6]], [23, 1, 2, [35, 4]],
                 [23, 1, 3, [35, 4]], [23, 1, 4, [35, 4]], [24, 1, 2, [35, 4]], [24, 1, 3, [35, 4]],
                 [25, 1, 2, [35, 4]]]

    # West withwool
    # stuff = [[-3, 1, 2, [35, 0], 'Right Wing'], [-2, 1, 2, [35, 0], 'Right Wing'], [-2, 1, 3, [35, 0], 'Right Wing'], [-1, 1, -4, [35, 0], 'Right Tailplane'], [-1, 1, 2, [35, 0], 'Right Wing'], [-1, 1, 3, [35, 0], 'Right Wing'], [-1, 1, 4, [35, 0], 'Right Wing'], [0, 1, -4, [35, 0], 'Right Tailplane'], [0, 1, 2, [35, 0], 'Right Wing'], [0, 1, 3, [35, 0], 'Right Wing'], [0, 1, 4, [35, 0], 'Right Wing'], [1, 0, -3, [35, 15], 'Right Tailplane'], [1, 1, -4, [35, 0], 'Right Tailplane'], [1, 1, -3, [35, 0], 'Right Tailplane'], [1, 1, 2, [35, 0], 'Right Wing'], [1, 1, 3, [35, 0], 'Right Wing'], [1, 1, 4, [35, 0], 'Right Wing'], [2, 1, -4, [35, 0], 'Tail'], [2, 1, -3, [35, 0], 'Rear Cabin'], [2, 1, -2, [35, 0], 'Rear Cabin'], [2, 1, -1, [35, 0], 'Mid Cabin'], [2, 1, 0, [35, 0], 'Mid Cabin'], [2, 1, 1, [35, 0], 'Mid Cabin'], [2, 1, 2, [35, 0], 'Wing Cabin'], [2, 1, 3, [35, 0], 'Wing Cabin'], [2, 1, 4, [35, 0], 'Wing Cabin'], [2, 1, 5, [35, 0], 'Forward Cabin'], [2, 1, 6, [35, 0], 'Forward Cabin'], [2, 1, 7, [35, 0], 'Forward Cabin'], [2, 1, 8, [35, 0], 'Cockpit'], [2, 2, -4, [35, 0], 'Tail'], [2, 2, -3, [35, 0], 'Rear Cabin'], [2, 2, -2, [20, 0], 'Rear Cabin'], [2, 2, -1, [35, 0], 'Mid Cabin'], [2, 2, 0, [20, 0], 'Mid Cabin'], [2, 2, 1, [35, 0], 'Mid Cabin'], [2, 2, 2, [20, 0], 'Wing Cabin'], [2, 2, 3, [35, 0], 'Wing Cabin'], [2, 2, 4, [20, 0], 'Wing Cabin'], [2, 2, 5, [35, 0], 'Forward Cabin'], [2, 2, 6, [20, 0], 'Forward Cabin'], [2, 2, 7, [35, 0], 'Forward Cabin'], [2, 2, 8, [20, 0], 'Cockpit'], [3, 0, 8, [35, 15], 'Cockpit'], [3, 1, -4, [35, 0], 'Tail'], [3, 1, -3, [35, 0], 'Rear Cabin'], [3, 1, -2, [35, 0], 'Rear Cabin'], [3, 1, -1, [35, 0], 'Mid Cabin'], [3, 1, 0, [35, 0], 'Mid Cabin'], [3, 1, 1, [35, 0], 'Mid Cabin'], [3, 1, 2, [35, 0], 'Wing Cabin'], [3, 1, 3, [35, 0], 'Wing Cabin'], [3, 1, 4, [35, 0], 'Wing Cabin'], [3, 1, 5, [35, 0], 'Forward Cabin'], [3, 1, 6, [35, 0], 'Forward Cabin'], [3, 1, 7, [35, 0], 'Forward Cabin'], [3, 1, 8, [35, 0], 'Cockpit'], [3, 1, 9, [35, 0], 'Cockpit'], [3, 2, -4, [35, 0], 'Tail'], [3, 2, 9, [20, 0], 'Cockpit'], [3, 3, -4, [35, 0], 'Tail'], [3, 3, -3, [35, 0], 'Rear Cabin'], [3, 3, -2, [35, 0], 'Rear Cabin'], [3, 3, -1, [35, 0], 'Mid Cabin'], [3, 3, 0, [35, 0], 'Mid Cabin'], [3, 3, 1, [35, 0], 'Mid Cabin'], [3, 3, 2, [35, 0], 'Wing Cabin'], [3, 3, 3, [35, 0], 'Wing Cabin'], [3, 3, 4, [35, 0], 'Wing Cabin'], [3, 3, 5, [35, 0], 'Forward Cabin'], [3, 3, 6, [35, 0], 'Forward Cabin'], [3, 3, 7, [35, 0], 'Forward Cabin'], [3, 3, 8, [20, 0], 'Cockpit'], [3, 4, -4, [35, 0], 'Tail'], [4, 1, -4, [35, 0], 'Tail'], [4, 1, -3, [35, 0], 'Rear Cabin'], [4, 1, -2, [35, 0], 'Rear Cabin'], [4, 1, -1, [35, 0], 'Mid Cabin'], [4, 1, 0, [35, 0], 'Mid Cabin'], [4, 1, 1, [35, 0], 'Mid Cabin'], [4, 1, 2, [35, 0], 'Wing Cabin'], [4, 1, 3, [35, 0], 'Wing Cabin'], [4, 1, 4, [35, 0], 'Wing Cabin'], [4, 1, 5, [35, 0], 'Forward Cabin'], [4, 1, 6, [35, 0], 'Forward Cabin'], [4, 1, 7, [35, 0], 'Forward Cabin'], [4, 1, 8, [35, 0], 'Cockpit'], [4, 2, -4, [35, 0], 'Tail'], [4, 2, -3, [35, 0], 'Rear Cabin'], [4, 2, -2, [20, 0], 'Rear Cabin'], [4, 2, -1, [35, 0], 'Mid Cabin'], [4, 2, 0, [20, 0], 'Mid Cabin'], [4, 2, 1, [35, 0], 'Mid Cabin'], [4, 2, 2, [20, 0], 'Wing Cabin'], [4, 2, 3, [35, 0], 'Wing Cabin'], [4, 2, 4, [20, 0], 'Wing Cabin'], [4, 2, 5, [35, 0], 'Forward Cabin'], [4, 2, 6, [20, 0], 'Forward Cabin'], [4, 2, 7, [35, 0], 'Forward Cabin'], [4, 2, 8, [20, 0], 'Cockpit'], [5, 0, -3, [35, 15], 'Left Tailplane'], [5, 1, -4, [35, 0], 'Left Tailplane'], [5, 1, -3, [35, 0], 'Left Tailplane'], [5, 1, 2, [35, 0], 'Left Wing'], [5, 1, 3, [35, 0], 'Left Wing'], [5, 1, 4, [35, 0], 'Left Wing'], [6, 1, -4, [35, 0], 'Left Tailplane'], [6, 1, 2, [35, 0], 'Left Wing'], [6, 1, 3, [35, 0], 'Left Wing'], [6, 1, 4, [35, 0], 'Left Wing'], [7, 1, -4, [35, 0], 'Left Tailplane'], [7, 1, 2, [35, 0], 'Left Wing'], [7, 1, 3, [35, 0], 'Left Wing'], [7, 1, 4, [35, 0], 'Left Wing'], [8, 1, 2, [35, 0], 'Left Wing'], [8, 1, 3, [35, 0], 'Left Wing'], [9, 1, 2, [35, 0], 'Left Wing']]
    stuff = [[-3, 1, 2, [1, 0], 'Right Wing'], [-2, 1, 2, [1, 0], 'Right Wing'], [-2, 1, 3, [1, 0], 'Right Wing'],
             [-1, 1, -4, [1, 0], 'Right Tailplane'], [-1, 1, 2, [1, 0], 'Right Wing'], [-1, 1, 3, [1, 0], 'Right Wing'],
             [-1, 1, 4, [1, 0], 'Right Wing'], [0, 1, -4, [1, 0], 'Right Tailplane'], [0, 1, 2, [1, 0], 'Right Wing'],
             [0, 1, 3, [1, 0], 'Right Wing'], [0, 1, 4, [1, 0], 'Right Wing'], [1, 0, -3, [35, 15], 'Right Tailplane'],
             [1, 1, -4, [1, 0], 'Right Tailplane'], [1, 1, -3, [1, 0], 'Right Tailplane'],
             [1, 1, 2, [1, 0], 'Right Wing'], [1, 1, 3, [1, 0], 'Right Wing'], [1, 1, 4, [1, 0], 'Right Wing'],
             [2, 1, -4, [1, 0], 'Tail'], [2, 1, -3, [1, 0], 'Rear Cabin'], [2, 1, -2, [1, 0], 'Rear Cabin'],
             [2, 1, -1, [1, 0], 'Mid Cabin'], [2, 1, 0, [1, 0], 'Mid Cabin'], [2, 1, 1, [1, 0], 'Mid Cabin'],
             [2, 1, 2, [1, 0], 'Wing Cabin'], [2, 1, 3, [1, 0], 'Wing Cabin'], [2, 1, 4, [1, 0], 'Wing Cabin'],
             [2, 1, 5, [1, 0], 'Forward Cabin'], [2, 1, 6, [1, 0], 'Forward Cabin'], [2, 1, 7, [1, 0], 'Forward Cabin'],
             [2, 1, 8, [1, 0], 'Cockpit'], [2, 2, -4, [1, 0], 'Tail'], [2, 2, -3, [1, 0], 'Rear Cabin'],
             [2, 2, -2, [20, 0], 'Rear Cabin'], [2, 2, -1, [1, 0], 'Mid Cabin'], [2, 2, 0, [20, 0], 'Mid Cabin'],
             [2, 2, 1, [1, 0], 'Mid Cabin'], [2, 2, 2, [20, 0], 'Wing Cabin'], [2, 2, 3, [1, 0], 'Wing Cabin'],
             [2, 2, 4, [20, 0], 'Wing Cabin'], [2, 2, 5, [1, 0], 'Forward Cabin'], [2, 2, 6, [20, 0], 'Forward Cabin'],
             [2, 2, 7, [1, 0], 'Forward Cabin'], [2, 2, 8, [20, 0], 'Cockpit'], [3, 0, 8, [35, 15], 'Cockpit'],
             [3, 1, -4, [1, 0], 'Tail'], [3, 1, -3, [1, 0], 'Rear Cabin'], [3, 1, -2, [1, 0], 'Rear Cabin'],
             [3, 1, -1, [1, 0], 'Mid Cabin'], [3, 1, 0, [1, 0], 'Mid Cabin'], [3, 1, 1, [1, 0], 'Mid Cabin'],
             [3, 1, 2, [1, 0], 'Wing Cabin'], [3, 1, 3, [1, 0], 'Wing Cabin'], [3, 1, 4, [1, 0], 'Wing Cabin'],
             [3, 1, 5, [1, 0], 'Forward Cabin'], [3, 1, 6, [1, 0], 'Forward Cabin'], [3, 1, 7, [1, 0], 'Forward Cabin'],
             [3, 1, 8, [1, 0], 'Cockpit'], [3, 1, 9, [1, 0], 'Cockpit'], [3, 2, -4, [1, 0], 'Tail'],
             [3, 2, 9, [20, 0], 'Cockpit'], [3, 3, -4, [1, 0], 'Tail'], [3, 3, -3, [1, 0], 'Rear Cabin'],
             [3, 3, -2, [1, 0], 'Rear Cabin'], [3, 3, -1, [1, 0], 'Mid Cabin'], [3, 3, 0, [1, 0], 'Mid Cabin'],
             [3, 3, 1, [1, 0], 'Mid Cabin'], [3, 3, 2, [1, 0], 'Wing Cabin'], [3, 3, 3, [1, 0], 'Wing Cabin'],
             [3, 3, 4, [1, 0], 'Wing Cabin'], [3, 3, 5, [1, 0], 'Forward Cabin'], [3, 3, 6, [1, 0], 'Forward Cabin'],
             [3, 3, 7, [1, 0], 'Forward Cabin'], [3, 3, 8, [20, 0], 'Cockpit'], [3, 4, -4, [1, 0], 'Tail'],
             [4, 1, -4, [1, 0], 'Tail'], [4, 1, -3, [1, 0], 'Rear Cabin'], [4, 1, -2, [1, 0], 'Rear Cabin'],
             [4, 1, -1, [1, 0], 'Mid Cabin'], [4, 1, 0, [1, 0], 'Mid Cabin'], [4, 1, 1, [1, 0], 'Mid Cabin'],
             [4, 1, 2, [1, 0], 'Wing Cabin'], [4, 1, 3, [1, 0], 'Wing Cabin'], [4, 1, 4, [1, 0], 'Wing Cabin'],
             [4, 1, 5, [1, 0], 'Forward Cabin'], [4, 1, 6, [1, 0], 'Forward Cabin'], [4, 1, 7, [1, 0], 'Forward Cabin'],
             [4, 1, 8, [1, 0], 'Cockpit'], [4, 2, -4, [1, 0], 'Tail'], [4, 2, -3, [1, 0], 'Rear Cabin'],
             [4, 2, -2, [20, 0], 'Rear Cabin'], [4, 2, -1, [1, 0], 'Mid Cabin'], [4, 2, 0, [20, 0], 'Mid Cabin'],
             [4, 2, 1, [1, 0], 'Mid Cabin'], [4, 2, 2, [20, 0], 'Wing Cabin'], [4, 2, 3, [1, 0], 'Wing Cabin'],
             [4, 2, 4, [20, 0], 'Wing Cabin'], [4, 2, 5, [1, 0], 'Forward Cabin'], [4, 2, 6, [20, 0], 'Forward Cabin'],
             [4, 2, 7, [1, 0], 'Forward Cabin'], [4, 2, 8, [20, 0], 'Cockpit'], [5, 0, -3, [35, 15], 'Left Tailplane'],
             [5, 1, -4, [1, 0], 'Left Tailplane'], [5, 1, -3, [1, 0], 'Left Tailplane'], [5, 1, 2, [1, 0], 'Left Wing'],
             [5, 1, 3, [1, 0], 'Left Wing'], [5, 1, 4, [1, 0], 'Left Wing'], [6, 1, -4, [1, 0], 'Left Tailplane'],
             [6, 1, 2, [1, 0], 'Left Wing'], [6, 1, 3, [1, 0], 'Left Wing'], [6, 1, 4, [1, 0], 'Left Wing'],
             [7, 1, -4, [1, 0], 'Left Tailplane'], [7, 1, 2, [1, 0], 'Left Wing'], [7, 1, 3, [1, 0], 'Left Wing'],
             [7, 1, 4, [1, 0], 'Left Wing'], [8, 1, 2, [1, 0], 'Left Wing'], [8, 1, 3, [1, 0], 'Left Wing'],
             [9, 1, 2, [1, 0], 'Left Wing']]
    resetWorld()
    #while True:
    #    mc.postToChat("Place your Dots Board on top of the Raspberry Pi and hit enter in the commandline (not Minecraft Pi).")
    #    mc.postToChat(" ")
    #    answer = readInput("", None)
    #    if answer is not None:
    #        break

    mc.setBlock(-27, 3, 2, 20)  #Create a glass platform for the player to stand on
    mc.player.setPos(-27, 4, 2) #Teleport the player to that platform
    waitBlock("Place your dots board on top of the Raspberry Pi and right click the gold block when you are ready.")

    updatedStuff = checkParts(AIRPLANE)
    checkColours()
    demoPlane = offset(updatedStuff, -20, 0, 0)
    if (len(demoPlane) == 93) and (enableRocketEasterEgg == True):
        mc.postToChat("Easter egg!")

        if OtherPartStatus["Cloud"]:
            addClouds(-10, 0, -10)
            #l = Lightning(0, 0, 0, 0, 0)
            #l.daemon = True
            #l.start()
        if OtherPartStatus["Bear"]:
            b = Babbage(babbage, 0, 0, -6, 0, 0)
            b.daemon = True
            b.start()

        runRocket()
        sys.exit(0)
    #mc.setBlock(-27, 3, 2, 20)  #Create a glass platform for the player to stand on
    #mc.player.setPos(-27, 4, 2) #Teleport the player to that platform
    #waitBlock()
    mc.camera.setNormal()
    if demoPlane == []:
        mc.postToChat("")
        mc.postToChat("Dots board not detected! Did you correctly attach it or forget to join the dots?")
        mc.postToChat(" ")
        runSimulation()
    else:

        placeBlocks(demoPlane)
        mc.postToChat(" ")
        #mc.postToChat("When you are ready to test your plane, hit enter in commandline (not Minecraft")
        #input()
        waitBlock("When you are ready to test your plane, right click the golden block again.")

        resetWorld()
        mc.player.setPos(-20, 8, 17)
        mc.setBlock(-20, 7, 17, 20)

        if OtherPartStatus["Cloud"]:
            addClouds()
            l = Lightning(0, 0, 0, 0, 0)
            l.daemon = True
            l.start()
        if OtherPartStatus["Bear"]:
            b = Babbage(babbage, 0, 0, -6, 0, 0)
            b.daemon = True
            b.start()

        if flightScore == 24:
            movePlane(updatedStuff, 20, 0)
        else:
            movePlane(updatedStuff, 20, 10)
        resetWorld()
        mc.player.setPos(-20, 8, 17)
        mc.setBlock(-20, 7, 17, 20)
        createSign()
        mc.player.setPos(-20, 8, 17)
        mc.setBlock(-20, 7, 17, 20)
```


Overlapping Code:
```
0, 0]], [2, 2, 3, [35, 0]], [2, 2, 4, [20, 0]], [2
```
<Overlap Ratio: 0.02011263073209976>

---

--- 369 --
Question ID: 75db92e8c119cf6edfaf274c7b4632092e0a99d9_0
Original Code:
```
def validate_when(value):
    """Used to convert between pendulum and other types of datetime."""
    if isinstance(value, datetime.datetime):
        value = pendulum.from_timestamp(value.timestamp(), tz='UTC')
    elif not isinstance(value, pendulum.DateTime):
        value = pendulum.parse(value)

    value = value.in_tz('UTC')

    return value
```


Overlapping Code:
```
etween pendulum and other types of datetime."""
if isinstance(value, datetime.datetime):
value = pendulum.from_timestamp(value.timestamp(), tz='UTC')
elif not isinstance(value, pendulum.DateTime):
value = pendulum.parse(value)
value = value.in_tz('UT
```
<Overlap Ratio: 0.8012820512820513>

---

--- 370 --
Question ID: b78cbc595a45779867f5678a43f9716bb8fc4c7e_8
Original Code:
```
def delete_note(request, note_id):
    project = Project.objects.get(user=request.user)
    project.note_set.get(pk=note_id).delete()
    return redirect('members')
```


Overlapping Code:
```
(request, note_id):
project = Project.objects.get(user=request.user)
project.note_set.get(pk=note_id
```
<Overlap Ratio: 0.6578947368421053>

---

--- 371 --
Question ID: 1214f067051da2f3fd1fe670843072482b2bc04e_1
Original Code:
```
def logsDirectory():
    """ logsDirectory creates logs directory for dumping logs when there is an error or exception. """
    if not os.path.exists(LOGS_DIRECTORY):
        os.mkdir(LOGS_DIRECTORY)
```


Overlapping Code:
```
ogs directory for dumping logs when there is an error or exception. """
if not os.path.exists(LOGS_D
```
<Overlap Ratio: 0.546448087431694>

---

--- 372 --
Question ID: bf0522d34b8ae7d7fdc3e3249a39882fc2a58087_8
Original Code:
```
@blueprint.get('/<uuid:user_id>/unsuspend')
@permission_required('user.administrate')
@templated
def unsuspend_account_form(user_id, erroneous_form=None):
    """Show form to unsuspend the user account."""
    user = _get_user_for_admin_or_404(user_id)

    if not user.suspended:
        flash_error(
            gettext(
                "User '%(screen_name)s' is not suspended.",
                screen_name=user.screen_name,
            )
        )
        return redirect_to('.view', user_id=user.id)

    form = erroneous_form if erroneous_form else SuspendAccountForm()

    return {
        'profile_user': user,
        'user': user,
        'form': form,
    }
```


Overlapping Code:
```
uspend')
@permission_required('user.administrate')
@templated
def unsuspend_account_form(user_id, erroneous_form=None):
"""Show form to unsuspend the user account."""
user = _get_user_for_admin_or_404(user_id)
if not user.suspended:
flash_error(
gettext(
"User '%(screen_name)s' is not suspended.",
screen_name=user.screen_name,
)
)
return redirect_to('.view', user_id=user.id)
form = erroneous_form if erroneous_form else SuspendAccountForm()
return {
'profile_user': user,
'user': user,
'form': for
```
<Overlap Ratio: 0.9276437847866419>

---

--- 373 --
Question ID: 9039120ed823476f5b8e71cb295b3c259f35f137_0
Original Code:
```
def detect_objects(image_np, sess, detection_graph):
    # Expand dimensions since the model expects images to have shape: [mscoco_label_map.pbtxt, None, None, 3]
    image_np_expanded = np.expand_dims(image_np, axis=0)
    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')

    # Each box represents a part of the image where a particular object was detected.
    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')

    # Each score represent how level of confidence for each of the objects.
    # Score is shown on the result image, together with the class label.
    scores = detection_graph.get_tensor_by_name('detection_scores:0')
    classes = detection_graph.get_tensor_by_name('detection_classes:0')
    num_detections = detection_graph.get_tensor_by_name('num_detections:0')

    # Actual detection.
    (boxes, scores, classes, num_detections) = sess.run(
        [boxes, scores, classes, num_detections],
        feed_dict={image_tensor: image_np_expanded})

    # Visualization of the results of a detection.
    vis_util.visualize_boxes_and_labels_on_image_array(
        image_np,
        np.squeeze(boxes),
        np.squeeze(classes).astype(np.int32),
        np.squeeze(scores),
        category_index,
        use_normalized_coordinates=True,
        line_thickness=8)
    return image_np
```


Overlapping Code:
```
ef detect_objects(image_np, sess, detection_graph):
# Expand dimensions since the model expects images to have shape: [mscoco_label_map.pbtxt, None, None, 3]
image_np_expanded = np.expand_dims(image_np, axis=0)
image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')
# Each box represents a part of the image where a particular object was detected.
boxes = detection_graph.get_tensor_by_name('detection_boxes:0')
# Each score represent how level of confidence for each of the objects.
# Score is shown on the result image, together with the class label.
scores = detection_graph.get_tensor_by_name('detection_scores:0')
classes = detection_graph.get_tensor_by_name('detection_classes:0')
num_detections = detection_graph.get_tensor_by_name('num_detections:0')
# Actual detection.
(boxes, scores, classes, num_detections) = sess.run(
[boxes, scores, classes, num_detections],
feed_dict={image_tensor: image_np_expanded})
# Visualization of the results of a detection.
vis_util.visualize_boxes_and_labels_on_image_array(
image_np,
np.squeeze(boxes),
np.squeeze(classes).astype(np.int32),
np.squeeze(scores),
category_index,
use_normalized_coordinates=True,
line_thickness=8)
return image_np
```
<Overlap Ratio: 0.9991673605328892>

---

--- 374 --
Question ID: 55c4aae866f4552991cfbca3a77d5e6e8d16167b_0
Original Code:
```
def init_inputs(num=1, seq_len=4, shape=(1, 2)):
    inputs = list()
    for i in range(num):
        # i*seq_len+(k+1)
        inputs.append([(i+1)*torch.ones(shape) for k in range(seq_len)])
    return inputs
```


Overlapping Code:
```
t_inputs(num=1, seq_len=4, shape=(1, 2)):
inputs = list()
for i in range(num):
# i*seq_len+(k+1)
inputs.append([(i+1)*torch.ones(shape) for k in range
```
<Overlap Ratio: 0.8241758241758241>

---

--- 375 --
Question ID: 5a0401160161daaf1d5839730d210622bdac0137_4
Original Code:
```
def generate_analysis_target_id(analysis_target, name):
    # this function generates 'machine-id's for analysis target's that
    # might not be hosts.
    #
    # 'machine_id' is what Insights uses to uniquely identify
    # the thing-to-be-analysed.  Primarily it determines when two uploads
    # are for the 'same thing', and so the latest upload should update the
    # later one Up till now that has only been hosts (machines), and so a
    # random uuid (uuid4) machine-id was generated for the host as its machine-id,
    # and written to a file on the host, and reused for all insights
    # uploads for that host.
    #
    # For docker images and containers, it will be difficult to impossible
    # to save their machine id's anywhere.  Also, while containers change
    # over time just like hosts, images don't change over time, though they
    # can be rebuilt.  So for images we want the 'machine-id' for an 'image'
    # to follow the rebuilt image, not change every time the image is rebuilt.
    # Typically when an image is rebuilt, the rebuilt image will have the same
    # name as its predicessor, but a different version (tag).
    #
    # So for images and containers, instead of random uuids, we use namespace uuids
    # (uuid5's).  This generates a new uuid based on a combination of another
    # uuid, and a name (a character string).  This will always generate the
    # same uuid for the same given base uuid and name.  This saves us from
    # having to save the image's uuid anywhere, and lets us control the created uuid
    # by controlling the name used to generate it.  Keep the name and base uuid) the
    # same, we get the same uuid.
    #
    # For the base uuid we use the uuid of the host we are running on.
    # For containers this is the obvious choice, for images it is less obviously
    # what base uuid is correct.  For now we will just go with the host's uuid also.
    #
    # For the name, we leave that outside this function, but in general it should
    # be the name of the container or the name of the image, and if you want to
    # replace the results on the insights server, you have to use the same name

    if analysis_target == "host":
        return generate_machine_id()
    elif (analysis_target == "docker_image" or
            analysis_target == "docker_container" or
            analysis_target == "compressed_file" or
            analysis_target == "mountpoint"):
        return generate_container_id(name)
    else:
        raise ValueError("Unknown analysis target: %s" % analysis_target)
```


Overlapping Code:
```
lysis_target_id(analysis_target, name):
# this function generates 'machine-id's for analysis target's that
# might not be hosts.
#
# 'machine_id' is what Insights uses to uniquely identify
# the thing-to-be-analysed. Primarily it determines when two uploads
# are for the 'same thing', and so the latest upload should update the
# later one Up till now that has only been hosts (machines), and so a
# random uuid (uuid4) machine-id was generated for the host as its machine-id,
# and written to a file on the host, and reused for all insights
# uploads for that host.
#
# For docker images and containers, it will be difficult to impossible
# to save their machine id's anywhere. Also, while containers change
# over time just like hosts, images don't change over time, though they
# can be rebuilt. So for images we want the 'machine-id' for an 'image'
# to follow the rebuilt image, not change every time the image is rebuilt.
# Typically when an image is rebuilt, the rebuilt image will have the same
# name as its predicessor, but a different version (tag).
#
# So for images and containers, instead of random uuids, we use namespace uuids
# (uuid5's). This generates a new uuid based on a combination of another
# uuid, and a name (a character string). This will always generate the
# same uuid for the same given base uuid and name. This saves us from
# having to save the image's uuid anywhere, and lets us control the created uuid
# by controlling the name used to generate it. Keep the name and base uuid) the
# same, we get the same uuid.
#
# For the base uuid we use the uuid of the host we are running on.
# For containers this is the obvious choice, for images it is less obviously
# what base uuid is correct. For now we will just go with the host's uuid also.
#
# For the name, we leave that outside this function, but in general it should
# be the name of the container or the name of the image, and if you want to
# replace the results on the insights server, you have to use the same name
if analysis_target == "host":
return generate_machine_id()
elif (analysis_target == "docker_image" or
analysis_target == "docker_container" or
analysis_target == "compressed_file" or
analysis_target == "mountpoint"):
return generate_container_
```
<Overlap Ratio: 0.985977212971078>

---

--- 376 --
Question ID: 849ce5b6aa5ae2d8c179b69639be0fe0ff21cf6a_2
Original Code:
```
def confirm_order(ident):
    try:
        log.info("confirm order status: %s" %run_casper(confirm_js,[ident]))
    except Exception as e:
        log.error("could not confirm order %s"%ident)
        log.error(e)
        raise
```


Overlapping Code:
```
er(ident):
try:
log.info("confirm order status: %s" %run_casper(confirm_js,[ident]))
except Exception as e:
log.error("could not confirm order %s"%ide
```
<Overlap Ratio: 0.8021390374331551>

---

--- 377 --
Question ID: 19eb7fbf79f25eacd4df46f0592f124449e650f7_4
Original Code:
```
def primes(n):
    ans = set()
    for i in range(2, n):
        prime = True
        for p in ans:
            if i % p == 0:
                prime = False
                break
        if prime:
            ans.add(i)
    return ans
```


Overlapping Code:
```
(2, n):
prime = True
for p in ans:
if i % p == 0:
prime =
```
<Overlap Ratio: 0.4014084507042254>

---

--- 378 --
Question ID: 9cd0547f799989e2a5c180be4c8e2872327b6d35_3
Original Code:
```
@registry.register_hparams
def attention_lm_moe_large():
  """Large model for distributed training.

  Over 1B parameters, so requires multi-gpu training due to memory
   requirements.

  Returns:
    an hparams object.
  """
  hparams = attention_lm_moe_base()
  hparams.num_hidden_layers = 5
  hparams.moe_layers = "3"
  hparams.hidden_size = 1024
  hparams.num_heads = 16
  hparams.filter_size = 4096
  hparams.moe_hidden_size = 4096
  hparams.moe_n1 = 128
  hparams.residual_dropout = 0.2
  return hparams
```


Overlapping Code:
```
attention_lm_moe_large():
"""Large model for distributed training.
Over 1B parameters, so requires multi-gpu training due to memory
requirements.
Returns:
an hparams object.
"""
hparams = attention_lm_moe_base()
hparams.num_hidden_layers = 5
hparams.moe_layers = "3"
hparams.hidden_size = 1024
hparams.num_heads = 16
hparams.filter_size = 4096
hparams.moe_hidden_size = 4096
hparams.moe_n1 = 128
hpar
```
<Overlap Ratio: 0.847457627118644>

---

--- 379 --
Question ID: 93bd61e3346a462733e580f8a7da1cd20aa9edf5_2
Original Code:
```
def broadcast_to_peers(req_method, url, **kwargs):
		"""
		Broadcast some information to all nodes in peer network
		"""

		peers = get_all_peers()

		for peer in peers:
				requests.request(req_method, peer + url, **kwargs)
```


Overlapping Code:
```
:
"""
Broadcast some information to all nodes in peer network
"""
peers = get_all_peers()
for peer in peers:
requests.request(req_method, peer + url, 
```
<Overlap Ratio: 0.7211538461538461>

---

--- 380 --
Question ID: 25c2f4653f0eab1dafaca3c11771959ae8bd21b1_20
Original Code:
```
def reject_assignment(conn, assignment_id, message = None):
    assn = conn.get_assignment(AssignmentId = assignment_id)
    status = assn["Assignment"]["AssignmentStatus"]
    if status == "Approved":
        raise MTurkInvalidStatus("Assignment {} has already been approved!".format(assignment_id))
    elif status == "Rejected":
        return False
    elif status != "Submitted":
        raise MTurkInvalidStatus("Assignment should have status {}, but has status {}".format("Submitted", status))

    conn.reject_assignment(AssignmentId = assignment_id, message = message)
    return True
```


Overlapping Code:
```

```
<Overlap Ratio: 0.0>

---

--- 381 --
Question ID: c93a7e4315cb9aefb80e8a3c0276d57af40d59a0_4
Original Code:
```
def tab_jams(raw_data):
    if ('jams' not in raw_data) or (raw_data.jams.iloc[0] is np.nan):
        print("No jams in this data file.")
        return

    col_dict = {
                'blockingAlertUuid': "blocking_alert_id",
                'startNode': "start_node",
                 'endNode': "end_node",
                 'pubMillis': "pub_millis",
                 'roadType': "road_type",
                 'speedKMH': "speed_kmh",
                 'turnType': "turn_type",
                 }

    other_cols = ['id','city', 'country','delay', 'length',
                  'uuid', 'street', 'level', 'line', 'pub_utc_date']
    col_list = list(col_dict.values())
    col_list = col_list + other_cols

    df_jams = sep_aji_records(raw_data, "jams")
    df_jams = (df_jams
               .rename(columns=col_dict)
               .pipe(align_all_columns, col_list=col_list)
               .assign(pub_utc_date=lambda x: pd.to_datetime(x["pub_millis"], unit='ms'),
                       id=df_jams["rec"].apply(hash_raw_aji)
                      )
              )
    df_jams = df_jams[col_list]

    return df_jams
```


Overlapping Code:
```
data):
if ('jams' not in raw_data) or (raw_data.jams.iloc[0] is np.nan):
print("No jams in this data file.")
return
col_dict = {
'blockingAlertUuid': "blocking_alert_id",
'startNode': "start_node",
'endNode': "end_node",
'pubMillis': "pub_millis",
'roadType': "road_type",
'speedKMH': "speed_kmh",
'turnType': "turn_type",
}
other_cols = ['id','city', 'country','delay', 'length',
'uuid', 'street', 'level', 'line', 'pub_utc_date']
col_list = list(col_dict.values())
col_list = col_list + other_cols
df_jams = sep_aji_records(raw_data, "jams")
df_jams = (df_jams
.rename(columns=col_dict)
.pipe(align_all_columns, col_list=col_list)
.assign(pub_utc_date=lambda x: pd.to_datetime(x["pub_millis"], unit='ms'),
id=df_jams["rec"].apply(hash_raw_aji)
)
)

```
<Overlap Ratio: 0.927070457354759>

---

--- 382 --
Question ID: d6aec1e46549a733a6ef78b43069d013e75b09e1_0
Original Code:
```
def main():
    module = AnsibleModule(
        argument_spec=dict(
            device=dict(),
            ardana_host_info=dict()
        )
    )
    device = module.params['device']
    ardana_host_info = json.loads(module.params['ardana_host_info'])

    if not device and not ardana_host_info:
        module.fail_json(rc=256, msg="No device or Ardana host info specified")

    ardana_disk_models = ardana_host_info['my_disk_models'] \
        if 'my_disk_models' in ardana_host_info else dict()
    ardana_device_groups = ardana_host_info['my_device_groups'] \
        if 'my_device_groups' in ardana_host_info else dict()

    if ardana_host_info:
        rc_cumulative = 0
        err_cumulative = ""
        wwids = dict()

        if ardana_disk_models:
            for volume_group in ardana_disk_models['volume_groups']:
                if 'multipath' in volume_group\
                    and volume_group['multipath'] == True:
                    continue
                for physical_volume in volume_group['physical_volumes']:
                    physical_volume = physical_volume.replace('_root', '')
                    # Not a scsi disk skip
                    if not os.path.exists("/sys/block/%s/device/scsi_disk"
                                          % (os.path.basename(physical_volume))):
                        continue
                    wwid_command = '/lib/udev/scsi_id -g %s' % physical_volume
                    rc, out, err = module.run_command(wwid_command)
                    rc_cumulative += rc
                    err_cumulative += err
                    wwids[physical_volume] = '' if out is None \
                        else out.rstrip("\r\n")

        if ardana_device_groups:
            for device_group in ardana_device_groups:
                for entry in ardana_device_groups[device_group]:
                    if  'multipath' in entry\
                        and entry['multipath'] == True:
                        continue
                    for dev in entry['devices']:
                        # Not a scsi disk skip
                        if not os.path.exists("/sys/block/%s/device/scsi_disk"
                                              % (os.path.basename(dev['name']))):
                            continue
                        wwid_command = '/lib/udev/scsi_id -g %s' % dev['name']
                        rc, out, err = module.run_command(wwid_command)
                        rc_cumulative += rc
                        err_cumulative += err
                        wwids[dev['name']] = '' if out is None \
                            else out.rstrip("\r\n")

        module.exit_json(
            hostname=ardana_host_info['vars']['my_network_name'],
            wwid=wwids,
            rc=rc_cumulative,
            stderr=err_cumulative,
            changed=True
        )

    if device:
        wwid_command = '/lib/udev/scsi_id -g %s' % device
        rc, out, err = module.run_command(wwid_command)

        module.exit_json(
            disk=wwid_command,
            wwid='' if out is None else out.rstrip("\r\n"),
            stderr='' if err is None else err.rstrip("\r\n"),
            rc=rc,
            changed=True
        )
```


Overlapping Code:
```
def main():
module = AnsibleModule(
argument_spec=dict(
device=dict(),
ardana_host_info=dict()
)
)
device = module.params['device']
ardana_host_info = json.loads(module.params['ardana_host_info'])
if not device and not ardana_host_info:
module.fail_json(rc=256, msg="No device or Ardana host info specified")
ardana_disk_models = ardana_host_info['my_disk_models'] \
if 'my_disk_models' in ardana_host_info else dict()
ardana_device_groups = ardana_host_info['my_device_groups'] \
if 'my_device_groups' in ardana_host_info else dict()
if ardana_host_info:
rc_cumulative = 0
err_cumulative = ""
wwids = dict()
if ardana_disk_models:
for volume_group in ardana_disk_models['volume_groups']:
if 'multipath' in volume_group\
and volume_group['multipath'] == True:
continue
for physical_volume in volume_group['physical_volumes']:
physical_volume = physical_volume.replace('_root', '')
# Not a scsi disk skip
if not os.path.exists("/sys/block/%s/device/scsi_disk"
% (os.path.basename(physical_volume))):
continue
wwid_command = '/lib/udev/scsi_id -g %s' % physical_volume
rc, out, err = module.run_command(wwid_command)
rc_cumulative += rc
err_cumulative += err
wwids[physical_volume] = '' if out is None \
else out.rstrip("\r\n")
if ardana_device_groups:
for device_group in ardana_device_groups:
for entry in ardana_device_groups[device_group]:
if 'multipath' in entry\
and entry['multipath'] == True:
continue
for dev in entry['devices']:
# Not a scsi disk skip
if not os.path.exists("/sys/block/%s/device/scsi_disk"
% (os.path.basename(dev['name']))):
continue
wwid_command = '/lib/udev/scsi_id -g %s' % dev['name']
rc, out, err = module.run_command(wwid_command)
rc_cumulative += rc
err_
```
<Overlap Ratio: 0.9988158673771462>

---

--- 383 --
Question ID: 860274e394e7aeec502f7c490666c2395635f468_1
Original Code:
```
def getTargetMap():
    maps =getMapList()
    map_counts = len(maps)
    dice = random.randrange(map_counts)
    target_map_name = maps['map'][dice]
    target_map_path = maps['filepath'][dice]
    return target_map_name, target_map_path
```


Overlapping Code:
```
MapList()
map_counts = len(maps)
dice = random.randrange(map_counts)
target_map_name = maps['map'][dice]
target_map_path = maps['filepath'][dice]
retu
```
<Overlap Ratio: 0.7009345794392523>

---

