{"hexsha": "38b93e3e9c38a1fd8f528b0be2613872a3d07587", "ext": "py", "lang": "Python", "content": "def train(render=False):\n    reward100 = 0\n    for ep in range(max_episodes):\n        obs = env.reset()\n        state = obs\n        total_reward = 0\n        for iter in range(max_iterations):\n            if render:\n                env.render()\n            action = np.argmax(q_table[state,:] + np.random.randn(1,env.action_space.n)*(1./(ep+1)))\n            obs, reward, done, info = env.step(action)\n            total_reward += reward\n            new_state = obs\n            # update q table\n            q_table[state,action] = q_table[state,action] + learning_rate * (reward + discount_factor *  np.max(q_table[new_state,:]) - q_table[state,action])\n            state = new_state\n            if done:\n                break\n        reward100 += total_reward\n        if ep % 100 == 0:\n            print('Iteration #{} -- Average reward = {}.'.format(ep+1, reward100/100))\n            rList.append(reward100/100)\n            if reward100/100 >= 0.78:\n                print(\"Solved~!!!!\")\n                print(\"Average score every 100 trials: \" +  str((rList)))\n                print(\"Mean Score: {}\".format(np.mean(rList)))\n                break\n            reward100 = 0", "fn_id": 0, "class_fn": false, "repo": "spirosbax/HittingTheGym", "file": "FrozenLake-v0/frozenLake-v0.py", "last_update_at": "2018-06-26T18:41:33+00:00", "question_id": "38b93e3e9c38a1fd8f528b0be2613872a3d07587_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def train(render=False):\n    reward100 = 0\n    for ep in range(max_episodes):\n        obs = env.reset()\n        state = obs\n        total_reward = 0\n        for iter in range(max_iterations):\n            if render:\n                env.render()\n            action = np.argmax(q_table[state, :] + np.random.randn(1, env.action_space.n) * (1.0 / (ep + 1)))\n            obs, reward, done, info = env.step(action)\n            total_reward += reward\n            new_state = obs\n            q_table[state, action] = q_table[state, action] + learning_rate * (reward + discount_factor * np.max(q_table[new_state, :]) - q_table[state, action])\n            state = new_state\n            if done:\n                break\n        reward100 += total_reward\n        if ep % 100 == 0:\n            print('Iteration #{} -- Average reward = {}.'.format(ep + 1, reward100 / 100))\n            rList.append(reward100 / 100)\n            if reward100 / 100 >= 0.78:\n                print('Solved~!!!!')\n                print('Average score every 100 trials: ' + str(rList))\n                print('Mean Score: {}'.format(np.mean(rList)))\n                break\n"]]}
{"hexsha": "e48af0bdd98e9a7254e68425c45f6cfd6c83dbc7", "ext": "py", "lang": "Python", "content": "def parse_args():\n    parser = argparse.ArgumentParser(\n        description=__doc__,\n        formatter_class=argparse.RawDescriptionHelpFormatter)\n\n    parser.add_argument(\n        '--host',\n        help=f\"\"\"\n        The server host.\n        Default: {DEFAULT_HOST}\n        \"\"\",\n        default=DEFAULT_HOST)\n\n    parser.add_argument(\n        '--port', '-p',\n        help=f\"\"\"\n        The server port.\n        Default: {DEFAULT_PORT}\n        \"\"\",\n        default=DEFAULT_PORT)\n\n    parser.add_argument(\n        'config_file',\n        help=f\"\"\"\n        The config file to use.\n        Default: {DEFAULT_CONFIG_FILE}\n        \"\"\",\n        nargs='?',\n        default=DEFAULT_CONFIG_FILE)\n\n    argcomplete.autocomplete(parser)\n    return parser.parse_args()", "fn_id": 1, "class_fn": false, "repo": "metakirby5/web.sh", "file": "webcon/webcon.py", "last_update_at": "2018-03-28T14:39:33+00:00", "question_id": "e48af0bdd98e9a7254e68425c45f6cfd6c83dbc7_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def parse_args():\n    parser = argparse.ArgumentParser(description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter)\n    parser.add_argument('--host', help=f'\\n        The server host.\\n        Default: {DEFAULT_HOST}\\n        ', default=DEFAULT_HOST)\n    parser.add_argument('--port', '-p', help=f'\\n        The server port.\\n        Default: {DEFAULT_PORT}\\n        ', default=DEFAULT_PORT)\n    parser.add_argument('config_file', help=f'\\n        The config file to use.\\n        Default: {DEFAULT_CONFIG_FILE}\\n        ', nargs='?', default=DEFAULT_CONFIG_FILE)\n    argcomplete.autocomplete(parser)\n"]]}
{"hexsha": "e59c80ef8a635988b4cffd366e830cd69c875e76", "ext": "py", "lang": "Python", "content": "@app.route('/download')\ndef download():\n    \"\"\"Download a csv file of all the data.\"\"\"\n\n    current_date = str(datetime.date.today())\n    csv_name = 'mapping-gun-violence-dump-' + current_date + '.csv'\n\n    cd = os.path.dirname(__file__)\n    with open(os.path.join(cd, 'static/final-output.geojson')) as f:\n        data = geojson.loads(f.read())\n\n    short_to_long_name = {\n        'coordinates': 'coordinates',\n        'articleUrl': 'url',\n        'articleTitle': 'title',\n        'date': 'date',\n        'time': 'time',\n        'knewEachOther': 'The shooter and the victim knew each other',\n        'domesticViolence': 'The incident was a case of domestic violence',\n        'anotherCrime': 'The firearm was used during another crime',\n        'selfDefense': 'The firearm was used in self defense',\n        'alcohol': 'Alcohol was involved',\n        'drugs': 'Drugs (other than alcohol) were involved',\n        'selfDirected': 'The shooting was self-directed',\n        'suicideOrAttempt': 'The shooting was a suicide or suicide attempt',\n        'unintentional': 'The shooting was unintentional',\n        'byOfficer': 'The shooting was by a police officer',\n        'atOfficer': 'The shooting was directed at a police officer',\n        'stolen': 'The firearm was stolen',\n        'familyOwned': 'The firearm was owned by the victim/victims family'\n    }\n\n    fieldnames = ['title', 'url', 'date', 'time', 'coordinates',\n                  'The shooter and the victim knew each other',\n                  'The incident was a case of domestic violence',\n                  'The firearm was used during another crime',\n                  'The firearm was used in self defense',\n                  'Alcohol was involved',\n                  'Drugs (other than alcohol) were involved',\n                  'The shooting was self-directed',\n                  'The shooting was a suicide or suicide attempt',\n                  'The shooting was unintentional',\n                  'The shooting was by a police officer',\n                  'The shooting was directed at a police officer',\n                  'The firearm was stolen',\n                  'The firearm was owned by the victim/victims family']\n\n    output = io.StringIO()\n    wr = csv.DictWriter(output, fieldnames=fieldnames)\n    wr.writeheader()\n\n    for feature in data.features:\n        row = {}\n        row['coordinates'] = str(feature.geometry.coordinates)\n\n        for key, value in feature.properties.items():\n            row[short_to_long_name[key]] = value\n\n        wr.writerow(row)\n\n    return Response(output.getvalue(), mimetype='text/csv', headers={'Content-disposition': 'attachment; filename={}'.format(csv_name)})", "fn_id": 2, "class_fn": false, "repo": "yoninachmany/us-shooting-tracker", "file": "app/routes.py", "last_update_at": "2018-01-20T20:11:14+00:00", "question_id": "e59c80ef8a635988b4cffd366e830cd69c875e76_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@app.route('/download')\ndef download():\n    \"\"\"Download a csv file of all the data.\"\"\"\n    current_date = str(datetime.date.today())\n    csv_name = 'mapping-gun-violence-dump-' + current_date + '.csv'\n    cd = os.path.dirname(__file__)\n    with open(os.path.join(cd, 'static/final-output.geojson')) as f:\n        data = geojson.loads(f.read())\n    short_to_long_name = {'coordinates': 'coordinates', 'articleUrl': 'url', 'articleTitle': 'title', 'date': 'date', 'time': 'time', 'knewEachOther': 'The shooter and the victim knew each other', 'domesticViolence': 'The incident was a case of domestic violence', 'anotherCrime': 'The firearm was used during another crime', 'selfDefense': 'The firearm was used in self defense', 'alcohol': 'Alcohol was involved', 'drugs': 'Drugs (other than alcohol) were involved', 'selfDirected': 'The shooting was self-directed', 'suicideOrAttempt': 'The shooting was a suicide or suicide attempt', 'unintentional': 'The shooting was unintentional', 'byOfficer': 'The shooting was by a police officer', 'atOfficer': 'The shooting was directed at a police officer', 'stolen': 'The firearm was stolen', 'familyOwned': 'The firearm was owned by the victim/victims family'}\n    fieldnames = ['title', 'url', 'date', 'time', 'coordinates', 'The shooter and the victim knew each other', 'The incident was a case of domestic violence', 'The firearm was used during another crime', 'The firearm was used in self defense', 'Alcohol was involved', 'Drugs (other than alcohol) were involved', 'The shooting was self-directed', 'The shooting was a suicide or suicide attempt', 'The shooting was unintentional', 'The shooting was by a police officer', 'The shooting was directed at a police officer', 'The firearm was stolen', 'The firearm was owned by the victim/victims family']\n    output = io.StringIO()\n    wr = csv.DictWriter(output, fieldnames=fieldnames)\n    wr.writeheader()\n    for feature in data.features:\n        row = {}\n        row['coordinates'] = str(feature.geometry.coordinates)\n        for key, value in feature.properties.items():\n            row[short_to_long_name[key]] = value\n        wr.writerow(row)\n"]]}
{"hexsha": "3d41a1043b73edfafa118ad4b6bca6353ad92830", "ext": "py", "lang": "Python", "content": "def test_QHsmTst_init(qutest):\n    qutest.init()\n    qutest.expect(\"%timestamp BSP_DISPLAY top-INIT;\")\n    qutest.expect(\"%timestamp BSP_DISPLAY s-ENTRY;\")\n    qutest.expect(\"%timestamp BSP_DISPLAY s2-ENTRY;\")\n    qutest.expect(\"%timestamp BSP_DISPLAY s2-INIT;\")\n    qutest.expect(\"%timestamp BSP_DISPLAY s21-ENTRY;\")\n    qutest.expect(\"%timestamp BSP_DISPLAY s211-ENTRY;\")\n    qutest.expect(\"%timestamp Trg-Done QS_RX_EVENT\")", "fn_id": 0, "class_fn": false, "repo": "LotusEngineering/qp-plus", "file": "qspypy/tests/test_qhsm-funct.py", "last_update_at": "2018-09-18T15:40:17+00:00", "question_id": "3d41a1043b73edfafa118ad4b6bca6353ad92830_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_QHsmTst_init(qutest):\n    qutest.init()\n    qutest.expect('%timestamp BSP_DISPLAY top-INIT;')\n    qutest.expect('%timestamp BSP_DISPLAY s-ENTRY;')\n    qutest.expect('%timestamp BSP_DISPLAY s2-ENTRY;')\n    qutest.expect('%timestamp BSP_DISPLAY s2-INIT;')\n    qutest.expect('%timestamp BSP_DISPLAY s21-ENTRY;')\n    qutest.expect('%timestamp BSP_DISPLAY s211-ENTRY;')\n"]]}
{"hexsha": "6f065391b142fb5086549b76efcd40486efd4aa6", "ext": "py", "lang": "Python", "content": "def interactive(*args, **kwargs):\n    '''Creates a SparkContext for interactive use.\n    '''\n    import pyspark\n    conf = pyspark.SparkConf(*args, **kwargs)\n    ctx = pyspark.SparkContext(conf=conf)\n    return ctx", "fn_id": 0, "class_fn": false, "repo": "ankit-vaghela30/hydrus-p1", "file": "hydrus/__init__.py", "last_update_at": "2018-02-02T18:21:46+00:00", "question_id": "6f065391b142fb5086549b76efcd40486efd4aa6_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def interactive(*args, **kwargs):\n    \"\"\"Creates a SparkContext for interactive use.\n    \"\"\"\n    import pyspark\n    conf = pyspark.SparkConf(*args, **kwargs)\n    ctx = pyspark.SparkContext(conf=conf)\n"]]}
{"hexsha": "46a9281c563606af24a5b890ea416f878cedc5b9", "ext": "py", "lang": "Python", "content": "@_f\n@_p.types(None,_cs.GLfloat,_cs.GLfloat,_cs.GLfloat)\ndef glTranslatef(x,y,z):pass\n", "fn_id": 280, "class_fn": false, "repo": "5gconnectedbike/Navio2", "file": "env/Lib/site-packages/OpenGL/raw/GL/VERSION/GL_1_0.py", "last_update_at": "2018-08-13T19:08:08+00:00", "question_id": "46a9281c563606af24a5b890ea416f878cedc5b9_280", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@_f\n@_p.types(None, _cs.GLfloat, _cs.GLfloat, _cs.GLfloat)\ndef glTranslatef(x, y, z):\n"]]}
{"hexsha": "affdcfc7f9630df73b83f4252621990175eee9f0", "ext": "py", "lang": "Python", "content": "def writetoCSV(arg1, arg2, arg3, arg4, arg5):\n    # prop_id, url, lat, lon, price_sq_meter\n    fe = []\n    fe.append([arg1, arg2, arg3, arg4, arg5])\n    df = pd.DataFrame(fe)\n    if(not os.path.exists(\"/home/jm/Documents/master_new_repo/code_data/analysing_data/R/CSVs/df2.csv\")):\n        df.to_csv(\"/home/jm/Documents/master_new_repo/code_data/analysing_data/R/CSVs/df2.csv\", mode=\"a\", sep=\",\", na_rep=\"NA\",  index=False, header = ['prop_id', 'req_url', 'lat', 'lon', 'esti_price_sq_meter'])\n    else:\n        df.to_csv(\"/home/jm/Documents/master_new_repo/code_data/analysing_data/R/CSVs/df2.csv\", mode=\"a\", sep=\",\", na_rep=\"NA\",  index=False,header=False)", "fn_id": 0, "class_fn": false, "repo": "dmpe/wg-gesucht", "file": "sreality/analysing_data/scrapy/cepa/cepa/spiders/cepa2.py", "last_update_at": "2018-03-19T10:10:33+00:00", "question_id": "affdcfc7f9630df73b83f4252621990175eee9f0_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def writetoCSV(arg1, arg2, arg3, arg4, arg5):\n    fe = []\n    fe.append([arg1, arg2, arg3, arg4, arg5])\n    df = pd.DataFrame(fe)\n    if not os.path.exists('/home/jm/Documents/master_new_repo/code_data/analysing_data/R/CSVs/df2.csv'):\n        df.to_csv('/home/jm/Documents/master_new_repo/code_data/analysing_data/R/CSVs/df2.csv', mode='a', sep=',', na_rep='NA', index=False, header=['prop_id', 'req_url', 'lat', 'lon', 'esti_price_sq_meter'])\n    else:\n"]]}
{"hexsha": "c6a1ca0121d980851c4169ddc7476becc66c023b", "ext": "py", "lang": "Python", "content": "def edit_author(request, id):\n    '''\n    Edit author information\n    '''\n    author = get_object_or_404(Author, id=id)\n    if request.method == 'POST':\n        form = AuthorForm(request.POST, instance=author)\n        if form.is_valid():\n            author_edited = form.save(commit=False)\n            author.username = author_edited.username\n            author.full_name = author_edited.full_name\n            author.save()\n        return HttpResponseRedirect(reverse('blog.views.get_author',args=(author.id, author.username,)))\n    else:\n        form = AuthorForm(instance=author)\n    return render_to_response('form.html', {'form':form, 'action':'edit_author'}, RequestContext(request))", "fn_id": 1, "class_fn": false, "repo": "mikebull/simpleblog", "file": "blog/views.py", "last_update_at": "2018-02-23T09:02:15+00:00", "question_id": "c6a1ca0121d980851c4169ddc7476becc66c023b_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def edit_author(request, id):\n    \"\"\"\n    Edit author information\n    \"\"\"\n    author = get_object_or_404(Author, id=id)\n    if request.method == 'POST':\n        form = AuthorForm(request.POST, instance=author)\n        if form.is_valid():\n            author_edited = form.save(commit=False)\n            author.username = author_edited.username\n            author.full_name = author_edited.full_name\n            author.save()\n        return HttpResponseRedirect(reverse('blog.views.get_author', args=(author.id, author.username)))\n    else:\n        form = AuthorForm(instance=author)\n"]]}
{"hexsha": "62a48f8a0bbe203927d1de9dbb7edb7d298eb4fe", "ext": "py", "lang": "Python", "content": "def index(request) :\n    news = News.objects.filter(published_date__lte=timezone.now()).order_by('-published_date')[:12]\n    edicts = Edict.objects.filter(published_date__lte=timezone.now()).order_by('-published_date')[:11]\n    articles = {} #Article.objects.filter(published_date__lte=timezone.now()).order_by('-published_date')[:6]\n    patriarhia = getPatriarhiaNew()\n    return render(request, 'index.html', {'news': news, 'articles':articles, 'patriarhia':patriarhia, 'edicts': edicts})", "fn_id": 0, "class_fn": false, "repo": "varkon/eparhiaodua", "file": "eparhiapp/views.py", "last_update_at": "2018-04-24T10:41:15+00:00", "question_id": "62a48f8a0bbe203927d1de9dbb7edb7d298eb4fe_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def index(request):\n    news = News.objects.filter(published_date__lte=timezone.now()).order_by('-published_date')[:12]\n    edicts = Edict.objects.filter(published_date__lte=timezone.now()).order_by('-published_date')[:11]\n    articles = {}\n    patriarhia = getPatriarhiaNew()\n"]]}
{"hexsha": "baabd0ec651cc7945911ca05e7322f11667b65bc", "ext": "py", "lang": "Python", "content": "def test_expose():\n    \"Check that method locator ignores hidden and unmarked methods\"\n    class Service(object):\n        @prpc.method\n        async def exposed(self, ctx):\n            'bold'\n\n        async def hidden(self, ctx):\n            'sneaky'\n\n        async def _hidden_anyway(self):\n            'ninja'\n\n    # Without collect_all, only marked methods should be found\n    #\n    locator = prpc.TreeMethodLocator(Service(), collect_all=False)\n    # Marked methods are always visible\n    locator.resolve('exposed', prpc.CallType.UNARY, None)\n    # Unmarked method is ignored without collect_all\n    with pytest.raises(KeyError):\n        locator.resolve('hidden', prpc.CallType.UNARY, None)\n    # Methods with leading underscore are hidden unconditionally\n    with pytest.raises(KeyError):\n        locator.resolve('_hidden_anyway', prpc.CallType.UNARY, None)\n\n    # With collect_all, undecorated methods should appear\n    #\n    locator = prpc.TreeMethodLocator(Service(), collect_all=True)\n    # Marked methods are always visible\n    locator.resolve('exposed', prpc.CallType.UNARY, None)\n    # Unmarked method should now be visible\n    locator.resolve('hidden', prpc.CallType.UNARY, None)\n    # Methods with leading underscore are hidden unconditionally\n    with pytest.raises(KeyError):\n        locator.resolve('_hidden_anyway', prpc.CallType.UNARY, None)", "fn_id": 2, "class_fn": false, "repo": "datadvance/prpc", "file": "prpc/test/test_method_locator.py", "last_update_at": "2018-06-28T10:46:47+00:00", "question_id": "baabd0ec651cc7945911ca05e7322f11667b65bc_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_expose():\n    \"\"\"Check that method locator ignores hidden and unmarked methods\"\"\"\n\n    class Service(object):\n\n        @prpc.method\n        async def exposed(self, ctx):\n            \"\"\"bold\"\"\"\n\n        async def hidden(self, ctx):\n            \"\"\"sneaky\"\"\"\n\n        async def _hidden_anyway(self):\n            \"\"\"ninja\"\"\"\n    locator = prpc.TreeMethodLocator(Service(), collect_all=False)\n    locator.resolve('exposed', prpc.CallType.UNARY, None)\n    with pytest.raises(KeyError):\n        locator.resolve('hidden', prpc.CallType.UNARY, None)\n    with pytest.raises(KeyError):\n        locator.resolve('_hidden_anyway', prpc.CallType.UNARY, None)\n    locator = prpc.TreeMethodLocator(Service(), collect_all=True)\n    locator.resolve('exposed', prpc.CallType.UNARY, None)\n    locator.resolve('hidden', prpc.CallType.UNARY, None)\n    with pytest.raises(KeyError):\n"]]}
{"hexsha": "73522e27bdcbd82940751288419ad30f090999e0", "ext": "py", "lang": "Python", "content": "def test_read_file():\n    files = read('__mocks__/file.txt')\n\n    assert len(files) == 1\n    assert_file(files[0], 'Nossa senhora nosso')", "fn_id": 1, "class_fn": false, "repo": "guidiego/impysonator", "file": "impysonator/reader/tests/test_init.py", "last_update_at": "2018-04-09T14:11:26+00:00", "question_id": "73522e27bdcbd82940751288419ad30f090999e0_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_read_file():\n    files = read('__mocks__/file.txt')\n    assert len(files) == 1\n"]]}
{"hexsha": "2e463ca1f0dceff79cf208407c95964b6725cd5c", "ext": "py", "lang": "Python", "content": "def get_current_spot_price(intent_request):\n    \"\"\"\n    Performs dialog management and fulfillment for getting current spot price.\n    \"\"\"\n    logger.debug('Current Intent: {}'.format(intent_request['currentIntent']))\n    current = intent_request.get('currentIntent')\n    slots = current.get('slots') if current else None\n    instance_type = slots.get('InstanceType') if slots else None\n    amazon_region = slots.get('AmazonRegion') if slots else None\n    if intent_request.get('sessionAttributes'):\n        session_attributes = intent_request['sessionAttributes']\n    else:\n        session_attributes = {}\n\n    if intent_request['invocationSource'] == 'DialogCodeHook':\n        # Validate any slots which have been specified.  If any are invalid,\n        # re-elicit for their value\n        validation_result = validate_get_current_spot_price(slots)\n        if not validation_result['isValid']:\n            slots[validation_result['violatedSlot']] = None\n            return elicit_slot(\n                session_attributes,\n                current['name'],\n                slots,\n                validation_result['violatedSlot'],\n                validation_result['message']\n            )\n\n        # Otherwise, let native DM rules determine how to elicit for slots\n        # and/or drive confirmation.\n        return delegate(session_attributes, slots)\n\n    # Display value. Call backend\n    # We get the info and we format the answer\n    spot_prices_result = get_price_history([instance_type], amazon_region)\n    spot_prices_message = format_price_answer(spot_prices_result)\n\n    message = (\n        'The current spot price for a {} instance in {} is {}'\n        '.'.format(instance_type, amazon_region, spot_prices_message)\n    )\n    logger.debug(message)\n    return close(\n        session_attributes,\n        'Fulfilled',\n        {\n            'contentType': 'PlainText',\n            'content': message\n        }\n    )", "fn_id": 11, "class_fn": false, "repo": "sandtable/sbot", "file": "lambda_function.py", "last_update_at": "2018-06-29T05:55:04+00:00", "question_id": "2e463ca1f0dceff79cf208407c95964b6725cd5c_11", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_current_spot_price(intent_request):\n    \"\"\"\n    Performs dialog management and fulfillment for getting current spot price.\n    \"\"\"\n    logger.debug('Current Intent: {}'.format(intent_request['currentIntent']))\n    current = intent_request.get('currentIntent')\n    slots = current.get('slots') if current else None\n    instance_type = slots.get('InstanceType') if slots else None\n    amazon_region = slots.get('AmazonRegion') if slots else None\n    if intent_request.get('sessionAttributes'):\n        session_attributes = intent_request['sessionAttributes']\n    else:\n        session_attributes = {}\n    if intent_request['invocationSource'] == 'DialogCodeHook':\n        validation_result = validate_get_current_spot_price(slots)\n        if not validation_result['isValid']:\n            slots[validation_result['violatedSlot']] = None\n            return elicit_slot(session_attributes, current['name'], slots, validation_result['violatedSlot'], validation_result['message'])\n        return delegate(session_attributes, slots)\n    spot_prices_result = get_price_history([instance_type], amazon_region)\n    spot_prices_message = format_price_answer(spot_prices_result)\n    message = 'The current spot price for a {} instance in {} is {}.'.format(instance_type, amazon_region, spot_prices_message)\n    logger.debug(message)\n"]]}
{"hexsha": "6eb7dc28dc13b150a82a7aa82c8765acb1568f43", "ext": "py", "lang": "Python", "content": "def download(making_links):\n    for link in making_links:\n        file_name = link.split('/')[-1]\n        print(\"Downloading : \" + file_name)\n        r = requests.get(link, stream=True)\n        with open(file_name, 'wb') as f:\n            total_length = int(r.headers.get('content-length'))\n            for chunk in progress.bar(r.iter_content(chunk_size=1024), expected_size=(total_length / 1024) + 1):\n                if chunk:\n                    f.write(chunk)\n                    f.flush()\n        print(file_name + \" Downloaded ;)\")\n    print(\"All videos Downloaded\")", "fn_id": 1, "class_fn": false, "repo": "matosBrent/PythonScripts", "file": "scripts/python/Download.py", "last_update_at": "2018-10-27T04:55:14+00:00", "question_id": "6eb7dc28dc13b150a82a7aa82c8765acb1568f43_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def download(making_links):\n    for link in making_links:\n        file_name = link.split('/')[-1]\n        print('Downloading : ' + file_name)\n        r = requests.get(link, stream=True)\n        with open(file_name, 'wb') as f:\n            total_length = int(r.headers.get('content-length'))\n            for chunk in progress.bar(r.iter_content(chunk_size=1024), expected_size=total_length / 1024 + 1):\n                if chunk:\n                    f.write(chunk)\n                    f.flush()\n        print(file_name + ' Downloaded ;)')\n"]]}
{"hexsha": "f175033c687cadc33b77cae0272891c7cab454f5", "ext": "py", "lang": "Python", "content": "@given(st.lists(subtitles()))\ndef test_compose_and_parse_strict(input_subs):\n    composed = srt.compose(input_subs, reindex=False)\n    reparsed_subs = srt.parse(composed)\n    subs_eq(reparsed_subs, input_subs)", "fn_id": 4, "class_fn": false, "repo": "survos/transcribe", "file": "python/script.py", "last_update_at": "2018-10-16T20:54:30+00:00", "question_id": "f175033c687cadc33b77cae0272891c7cab454f5_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@given(st.lists(subtitles()))\ndef test_compose_and_parse_strict(input_subs):\n    composed = srt.compose(input_subs, reindex=False)\n    reparsed_subs = srt.parse(composed)\n"]]}
{"hexsha": "608ad476dcddc19b5eeda58febe9d10c1af35542", "ext": "py", "lang": "Python", "content": "def _reshape_chisqr(\n    grid_ref: dict[str, np.ndarray], grid_result: GridResult\n) -> np.ndarray:\n    keys = list(grid_result.grid)\n    order = [keys.index(key) for key in grid_ref if key in keys]\n    axes_to_reduce = tuple(sorted(set(range(len(keys))) - set(order)))\n    order.extend(axes_to_reduce)\n\n    # After transpose, axes are shuffled\n    axes_to_reduce = tuple(order.index(index) for index in axes_to_reduce)\n\n    chisqr_final = grid_result.chisqr.transpose(order)\n    chisqr_final = np.minimum.reduce(chisqr_final, axis=axes_to_reduce)\n\n    shape = tuple(\n        len(grid_ref[key]) if key in grid_result.grid else 1 for key in grid_ref\n    )\n    chisqr_final = chisqr_final.reshape(shape)\n    return chisqr_final", "fn_id": 1, "class_fn": false, "repo": "gbouvignies/chemex", "file": "chemex/optimize/gridding.py", "last_update_at": "2018-09-17T08:43:58+00:00", "question_id": "608ad476dcddc19b5eeda58febe9d10c1af35542_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _reshape_chisqr(grid_ref: dict[str, np.ndarray], grid_result: GridResult) -> np.ndarray:\n    keys = list(grid_result.grid)\n    order = [keys.index(key) for key in grid_ref if key in keys]\n    axes_to_reduce = tuple(sorted(set(range(len(keys))) - set(order)))\n    order.extend(axes_to_reduce)\n    axes_to_reduce = tuple((order.index(index) for index in axes_to_reduce))\n    chisqr_final = grid_result.chisqr.transpose(order)\n    chisqr_final = np.minimum.reduce(chisqr_final, axis=axes_to_reduce)\n    shape = tuple((len(grid_ref[key]) if key in grid_result.grid else 1 for key in grid_ref))\n    chisqr_final = chisqr_final.reshape(shape)\n"]]}
{"hexsha": "670556a64036e6dc9b05da2a7fa0dd9dd60c6184", "ext": "py", "lang": "Python", "content": "def launch(env, logdir, n_epochs, num_cpu, seed, replay_strategy, policy_save_interval, clip_return,\n           override_params=None, save_policies=True):\n    \"\"\"\n    launch training with mpi\n\n    :param env: (str) environment ID\n    :param logdir: (str) the log directory\n    :param n_epochs: (int) the number of training epochs\n    :param num_cpu: (int) the number of CPUs to run on\n    :param seed: (int) the initial random seed\n    :param replay_strategy: (str) the type of replay strategy ('future' or 'none')\n    :param policy_save_interval: (int) the interval with which policy pickles are saved.\n        If set to 0, only the best and latest policy will be pickled.\n    :param clip_return: (float): clip returns to be in [-clip_return, clip_return]\n    :param override_params: (dict) override any parameter for training\n    :param save_policies: (bool) whether or not to save the policies\n    \"\"\"\n\n    if override_params is None:\n        override_params = {}\n    # Fork for multi-CPU MPI implementation.\n    if num_cpu > 1:\n        try:\n            whoami = mpi_fork(num_cpu, ['--bind-to', 'core'])\n        except CalledProcessError:\n            # fancy version of mpi call failed, try simple version\n            whoami = mpi_fork(num_cpu)\n\n        if whoami == 'parent':\n            sys.exit(0)\n        tf_util.single_threaded_session().__enter__()\n    rank = MPI.COMM_WORLD.Get_rank()\n\n    # Configure logging\n    if rank == 0:\n        if logdir or logger.get_dir() is None:\n            logger.configure(folder=logdir)\n    else:\n        logger.configure()\n    logdir = logger.get_dir()\n    assert logdir is not None\n    os.makedirs(logdir, exist_ok=True)\n\n    # Seed everything.\n    rank_seed = seed + 1000000 * rank\n    set_global_seeds(rank_seed)\n\n    # Prepare params.\n    params = config.DEFAULT_PARAMS\n    params['env_name'] = env\n    params['replay_strategy'] = replay_strategy\n    if env in config.DEFAULT_ENV_PARAMS:\n        params.update(config.DEFAULT_ENV_PARAMS[env])  # merge env-specific parameters in\n    params.update(**override_params)  # makes it possible to override any parameter\n    with open(os.path.join(logger.get_dir(), 'params.json'), 'w') as file_handler:\n        json.dump(params, file_handler)\n    params = config.prepare_params(params)\n    config.log_params(params, logger_input=logger)\n\n    if num_cpu == 1:\n        logger.warn()\n        logger.warn('*** Warning ***')\n        logger.warn(\n            'You are running HER with just a single MPI worker. This will work, but the ' +\n            'experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) ' +\n            'were obtained with --num_cpu 19. This makes a significant difference and if you ' +\n            'are looking to reproduce those results, be aware of this. Please also refer to ' +\n            'https://github.com/openai/stable_baselines/issues/314 for further details.')\n        logger.warn('****************')\n        logger.warn()\n\n    dims = config.configure_dims(params)\n    policy = config.configure_ddpg(dims=dims, params=params, clip_return=clip_return)\n\n    rollout_params = {\n        'exploit': False,\n        'use_target_net': False,\n        # 'use_demo_states': True,\n        'compute_q': False,\n        'time_horizon': params['time_horizon'],\n    }\n\n    eval_params = {\n        'exploit': True,\n        'use_target_net': params['test_with_polyak'],\n        # 'use_demo_states': False,\n        'compute_q': True,\n        'time_horizon': params['time_horizon'],\n    }\n\n    for name in ['time_horizon', 'rollout_batch_size', 'noise_eps', 'random_eps']:\n        rollout_params[name] = params[name]\n        eval_params[name] = params[name]\n\n    rollout_worker = RolloutWorker(params['make_env'], policy, dims, logger, **rollout_params)\n    rollout_worker.seed(rank_seed)\n\n    evaluator = RolloutWorker(params['make_env'], policy, dims, logger, **eval_params)\n    evaluator.seed(rank_seed)\n\n    train(\n        policy=policy, rollout_worker=rollout_worker,\n        evaluator=evaluator, n_epochs=n_epochs, n_test_rollouts=params['n_test_rollouts'],\n        n_cycles=params['n_cycles'], n_batches=params['n_batches'],\n        policy_save_interval=policy_save_interval, save_policies=save_policies)", "fn_id": 2, "class_fn": false, "repo": "spitis/stable-baselines", "file": "stable_baselines/her/experiment/train.py", "last_update_at": "2018-11-15T00:06:40+00:00", "question_id": "670556a64036e6dc9b05da2a7fa0dd9dd60c6184_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def launch(env, logdir, n_epochs, num_cpu, seed, replay_strategy, policy_save_interval, clip_return, override_params=None, save_policies=True):\n    \"\"\"\n    launch training with mpi\n\n    :param env: (str) environment ID\n    :param logdir: (str) the log directory\n    :param n_epochs: (int) the number of training epochs\n    :param num_cpu: (int) the number of CPUs to run on\n    :param seed: (int) the initial random seed\n    :param replay_strategy: (str) the type of replay strategy ('future' or 'none')\n    :param policy_save_interval: (int) the interval with which policy pickles are saved.\n        If set to 0, only the best and latest policy will be pickled.\n    :param clip_return: (float): clip returns to be in [-clip_return, clip_return]\n    :param override_params: (dict) override any parameter for training\n    :param save_policies: (bool) whether or not to save the policies\n    \"\"\"\n    if override_params is None:\n        override_params = {}\n    if num_cpu > 1:\n        try:\n            whoami = mpi_fork(num_cpu, ['--bind-to', 'core'])\n        except CalledProcessError:\n            whoami = mpi_fork(num_cpu)\n        if whoami == 'parent':\n            sys.exit(0)\n        tf_util.single_threaded_session().__enter__()\n    rank = MPI.COMM_WORLD.Get_rank()\n    if rank == 0:\n        if logdir or logger.get_dir() is None:\n            logger.configure(folder=logdir)\n    else:\n        logger.configure()\n    logdir = logger.get_dir()\n    assert logdir is not None\n    os.makedirs(logdir, exist_ok=True)\n    rank_seed = seed + 1000000 * rank\n    set_global_seeds(rank_seed)\n    params = config.DEFAULT_PARAMS\n    params['env_name'] = env\n    params['replay_strategy'] = replay_strategy\n    if env in config.DEFAULT_ENV_PARAMS:\n        params.update(config.DEFAULT_ENV_PARAMS[env])\n    params.update(**override_params)\n    with open(os.path.join(logger.get_dir(), 'params.json'), 'w') as file_handler:\n        json.dump(params, file_handler)\n    params = config.prepare_params(params)\n    config.log_params(params, logger_input=logger)\n    if num_cpu == 1:\n        logger.warn()\n        logger.warn('*** Warning ***')\n        logger.warn('You are running HER with just a single MPI worker. This will work, but the ' + 'experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) ' + 'were obtained with --num_cpu 19. This makes a significant difference and if you ' + 'are looking to reproduce those results, be aware of this. Please also refer to ' + 'https://github.com/openai/stable_baselines/issues/314 for further details.')\n        logger.warn('****************')\n        logger.warn()\n    dims = config.configure_dims(params)\n    policy = config.configure_ddpg(dims=dims, params=params, clip_return=clip_return)\n    rollout_params = {'exploit': False, 'use_target_net': False, 'compute_q': False, 'time_horizon': params['time_horizon']}\n    eval_params = {'exploit': True, 'use_target_net': params['test_with_polyak'], 'compute_q': True, 'time_horizon': params['time_horizon']}\n    for name in ['time_horizon', 'rollout_batch_size', 'noise_eps', 'random_eps']:\n        rollout_params[name] = params[name]\n        eval_params[name] = params[name]\n    rollout_worker = RolloutWorker(params['make_env'], policy, dims, logger, **rollout_params)\n    rollout_worker.seed(rank_seed)\n    evaluator = RolloutWorker(params['make_env'], policy, dims, logger, **eval_params)\n    evaluator.seed(rank_seed)\n"]]}
{"hexsha": "924dfff69c54a76ea37a4817b208c91d811542c6", "ext": "py", "lang": "Python", "content": "@csrf_exempt\ndef post_idea(request, owner, repository, full_repository_name):\n    \"\"\"\n    Create issue using the user's account if connected with github, otherwise jucybot\n    Return the issue HTML object.\n    \"\"\"\n    if not request.user.is_authenticated() or request.method != 'POST' or 'title' not in request.POST:\n        raise HttpResponseBadRequest()\n    try:\n        github = GithubWrapper(request)\n    except ObjectDoesNotExist:\n        github = jucybot.from_config()\n    database_repository = get_object_or_404(models.Repository, owner=owner, name=repository)\n    issue = github.create_issue(owner, repository, request.POST['title'], request.POST['content'] if 'content' in request.POST and request.POST['content'] else None, labels=['jucy'])\n    idea = models.Idea.objects.create(repository=database_repository, number=issue['number'])\n    idea.subscribers.add(request.user)\n    idea.save()\n    issue['total_subscribers'] = 1\n    issue['subscribed'] = True\n    return render(request, 'include/idea.html', {\n        'issue': issue,\n        'is_collaborator': github.is_collaborator_on_repo(owner, repository),\n        'full_repository_name': full_repository_name,\n    })", "fn_id": 4, "class_fn": false, "repo": "Jucyio/Jucy", "file": "api/views.py", "last_update_at": "2018-04-04T21:47:32+00:00", "question_id": "924dfff69c54a76ea37a4817b208c91d811542c6_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@csrf_exempt\ndef post_idea(request, owner, repository, full_repository_name):\n    \"\"\"\n    Create issue using the user's account if connected with github, otherwise jucybot\n    Return the issue HTML object.\n    \"\"\"\n    if not request.user.is_authenticated() or request.method != 'POST' or 'title' not in request.POST:\n        raise HttpResponseBadRequest()\n    try:\n        github = GithubWrapper(request)\n    except ObjectDoesNotExist:\n        github = jucybot.from_config()\n    database_repository = get_object_or_404(models.Repository, owner=owner, name=repository)\n    issue = github.create_issue(owner, repository, request.POST['title'], request.POST['content'] if 'content' in request.POST and request.POST['content'] else None, labels=['jucy'])\n    idea = models.Idea.objects.create(repository=database_repository, number=issue['number'])\n    idea.subscribers.add(request.user)\n    idea.save()\n    issue['total_subscribers'] = 1\n    issue['subscribed'] = True\n"]]}
{"hexsha": "345df7bf91ff226dd9bde7abb29abec23aeb04fc", "ext": "py", "lang": "Python", "content": "def vars_extractor(node):\n    def selectVarsEmptyClass(source_ref):\n        return makeExpressionBuiltinLocals(\n            provider   = node.getParentVariableProvider(),\n            source_ref = source_ref\n        )\n\n    return BuiltinParameterSpecs.extractBuiltinArgs(\n        node                = node,\n        builtin_class       = ExpressionBuiltinVars,\n        builtin_spec        = BuiltinParameterSpecs.builtin_vars_spec,\n        empty_special_class = selectVarsEmptyClass\n    )", "fn_id": 1, "class_fn": false, "repo": "Mortal/Nuitka", "file": "nuitka/optimizations/OptimizeBuiltinCalls.py", "last_update_at": "2018-12-16T23:51:18+00:00", "question_id": "345df7bf91ff226dd9bde7abb29abec23aeb04fc_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def vars_extractor(node):\n\n    def selectVarsEmptyClass(source_ref):\n        return makeExpressionBuiltinLocals(provider=node.getParentVariableProvider(), source_ref=source_ref)\n"]]}
{"hexsha": "5735a96ac41e608432d4d92639ff18c16d737c54", "ext": "py", "lang": "Python", "content": "def nwctrl_policy_exists(handle, name, parent_dn=\"org-root\", **kwargs):\n    \"\"\"\n    Checks if the given Network Control Policy already exists with the\n    same params\n\n    Args:\n        handle (UcscHandle)\n        name (string) : Network Control Policy Name\n        parent_dn (string) : Org Dn or Domain_group Dn\n        **kwargs: key-value pair of managed object(MO) property and value, Use\n                  'print(ucsccoreutils.get_meta_info(<classid>).config_props)'\n                  to get all configurable properties of class\n    Returns:\n        (True/False, MO/None)\n    Example:\n        bool_var = nwctrl_policy_exists(handle, \"sample_nwcontrol_policy\",\n                                        \"enabled\", \"all-host-vlans\",\n                                        \"link-down\", \"allow\", \"disabled\",\n                                        \"disabled\")\n    \"\"\"\n    mo = nwctrl_policy_get(handle, name, parent_dn)\n    if not mo:\n        return (False, None)\n\n    if \"forge\" in kwargs:\n        mo_1_dn = mo.dn + \"/mac-sec\"\n        mo_1 = handle.query_dn(mo_1_dn)\n        if not mo_1:\n            raise UcscOperationError(\"nwctrl_policy_exists\",\n                                     \"Mac secure object does not exist\")\n\n        args = {'forge': kwargs['forge']}\n        if not mo.check_prop_match(**args):\n            return (False, None)\n\n        kwargs.pop('forge', None)\n\n    mo_exists = mo.check_prop_match(**kwargs)\n    return (mo_exists, mo if mo_exists else None)", "fn_id": 2, "class_fn": false, "repo": "scottwedge/ucsc_apis", "file": "ucsc_apis/network/nwctrl_policy.py", "last_update_at": "2018-08-15T15:13:43+00:00", "question_id": "5735a96ac41e608432d4d92639ff18c16d737c54_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def nwctrl_policy_exists(handle, name, parent_dn='org-root', **kwargs):\n    \"\"\"\n    Checks if the given Network Control Policy already exists with the\n    same params\n\n    Args:\n        handle (UcscHandle)\n        name (string) : Network Control Policy Name\n        parent_dn (string) : Org Dn or Domain_group Dn\n        **kwargs: key-value pair of managed object(MO) property and value, Use\n                  'print(ucsccoreutils.get_meta_info(<classid>).config_props)'\n                  to get all configurable properties of class\n    Returns:\n        (True/False, MO/None)\n    Example:\n        bool_var = nwctrl_policy_exists(handle, \"sample_nwcontrol_policy\",\n                                        \"enabled\", \"all-host-vlans\",\n                                        \"link-down\", \"allow\", \"disabled\",\n                                        \"disabled\")\n    \"\"\"\n    mo = nwctrl_policy_get(handle, name, parent_dn)\n    if not mo:\n        return (False, None)\n    if 'forge' in kwargs:\n        mo_1_dn = mo.dn + '/mac-sec'\n        mo_1 = handle.query_dn(mo_1_dn)\n        if not mo_1:\n            raise UcscOperationError('nwctrl_policy_exists', 'Mac secure object does not exist')\n        args = {'forge': kwargs['forge']}\n        if not mo.check_prop_match(**args):\n            return (False, None)\n        kwargs.pop('forge', None)\n    mo_exists = mo.check_prop_match(**kwargs)\n"]]}
{"hexsha": "876cbc39df07ecc0f70543e3329ef1e8cd54713d", "ext": "py", "lang": "Python", "content": "def get_or_create_tag(datasource, tag_name, tag_type, units=None):\n    if tag_type == \"Numeric\":\n        current_tag_db, was_new = TagNumeric.objects.get_or_create(data_source=datasource, name=tag_name)\n        if was_new and units is not None:\n            current_tag_db.units = units\n            current_tag_db.save\n    elif tag_type == \"Discrete\":\n        current_tag_db, was_new = TagDiscrete.objects.get_or_create(data_source=datasource, name=tag_name)\n    else:\n        current_tag_db, was_new = TagText.objects.get_or_create(data_source=datasource, name=tag_name)\n    return current_tag_db", "fn_id": 1, "class_fn": false, "repo": "orangefrg/datacon", "file": "django/receiver/receiver.py", "last_update_at": "2018-10-06T22:11:12+00:00", "question_id": "876cbc39df07ecc0f70543e3329ef1e8cd54713d_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_or_create_tag(datasource, tag_name, tag_type, units=None):\n    if tag_type == 'Numeric':\n        current_tag_db, was_new = TagNumeric.objects.get_or_create(data_source=datasource, name=tag_name)\n        if was_new and units is not None:\n            current_tag_db.units = units\n            current_tag_db.save\n    elif tag_type == 'Discrete':\n        current_tag_db, was_new = TagDiscrete.objects.get_or_create(data_source=datasource, name=tag_name)\n    else:\n        current_tag_db, was_new = TagText.objects.get_or_create(data_source=datasource, name=tag_name)\n"]]}
{"hexsha": "c93a7e4315cb9aefb80e8a3c0276d57af40d59a0", "ext": "py", "lang": "Python", "content": "def tab_jams(raw_data):\n    if ('jams' not in raw_data) or (raw_data.jams.iloc[0] is np.nan):\n        print(\"No jams in this data file.\")\n        return\n\n    col_dict = {\n                'blockingAlertUuid': \"blocking_alert_id\",\n                'startNode': \"start_node\",\n                 'endNode': \"end_node\",\n                 'pubMillis': \"pub_millis\",\n                 'roadType': \"road_type\",\n                 'speedKMH': \"speed_kmh\",\n                 'turnType': \"turn_type\",\n                 }\n\n    other_cols = ['id','city', 'country','delay', 'length',\n                  'uuid', 'street', 'level', 'line', 'pub_utc_date']\n    col_list = list(col_dict.values())\n    col_list = col_list + other_cols\n\n    df_jams = sep_aji_records(raw_data, \"jams\")\n    df_jams = (df_jams\n               .rename(columns=col_dict)\n               .pipe(align_all_columns, col_list=col_list)\n               .assign(pub_utc_date=lambda x: pd.to_datetime(x[\"pub_millis\"], unit='ms'),\n                       id=df_jams[\"rec\"].apply(hash_raw_aji)\n                      )\n              )\n    df_jams = df_jams[col_list]\n\n    return df_jams", "fn_id": 4, "class_fn": false, "repo": "joinvalle/Joinville-Smart-Mobility", "file": "src/data/store_data_file.py", "last_update_at": "2018-07-26T01:22:52+00:00", "question_id": "c93a7e4315cb9aefb80e8a3c0276d57af40d59a0_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def tab_jams(raw_data):\n    if 'jams' not in raw_data or raw_data.jams.iloc[0] is np.nan:\n        print('No jams in this data file.')\n        return\n    col_dict = {'blockingAlertUuid': 'blocking_alert_id', 'startNode': 'start_node', 'endNode': 'end_node', 'pubMillis': 'pub_millis', 'roadType': 'road_type', 'speedKMH': 'speed_kmh', 'turnType': 'turn_type'}\n    other_cols = ['id', 'city', 'country', 'delay', 'length', 'uuid', 'street', 'level', 'line', 'pub_utc_date']\n    col_list = list(col_dict.values())\n    col_list = col_list + other_cols\n    df_jams = sep_aji_records(raw_data, 'jams')\n    df_jams = df_jams.rename(columns=col_dict).pipe(align_all_columns, col_list=col_list).assign(pub_utc_date=lambda x: pd.to_datetime(x['pub_millis'], unit='ms'), id=df_jams['rec'].apply(hash_raw_aji))\n    df_jams = df_jams[col_list]\n"]]}
{"hexsha": "6770c4f3dbff2ad3e1b3908d11f1c10abd6cada9", "ext": "py", "lang": "Python", "content": "def _has_any_component(durationstr, components):\n    #Given a duration string, and a list of components, returns True\n    #if any of the listed components are present, False otherwise.\n    #\n    #For instance:\n    #durationstr = 'P1Y'\n    #components = ['Y', 'M']\n    #\n    #returns True\n    #\n    #durationstr = 'P1Y'\n    #components = ['M', 'D']\n    #\n    #returns False\n\n    for component in components:\n        if durationstr.find(component) != -1:\n            return True\n\n    return False", "fn_id": 6, "class_fn": false, "repo": "ddell003/python-server-vuejs-client", "file": "flask/lib/python2.7/site-packages/aniso8601/duration.py", "last_update_at": "2018-03-11T20:04:04+00:00", "question_id": "6770c4f3dbff2ad3e1b3908d11f1c10abd6cada9_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _has_any_component(durationstr, components):\n    for component in components:\n        if durationstr.find(component) != -1:\n            return True\n"]]}
{"hexsha": "17870da4921bac8774076b766611ff5de08b7172", "ext": "py", "lang": "Python", "content": "def create_actor_with_or_without_sso_account(\n    context: Context, actor_aliases: str, has_or_does_not_have: str\n):\n    actor_aliases = [alias.strip() for alias in actor_aliases.split(\",\")]\n    for actor_alias in actor_aliases:\n        if has_or_does_not_have in [\"has\", \"have\"]:\n            actor = get_actor(context, actor_alias)\n            account = Account(\"verified Individual\")\n            profile_enrol_individual(context, actor, account=account)\n        else:\n            supplier = unauthenticated_supplier(actor_alias)\n            add_actor(context, supplier)", "fn_id": 8, "class_fn": false, "repo": "mayank-sfdc/directory-tests", "file": "tests/functional/steps/when_impl.py", "last_update_at": "2018-01-25T19:06:12+00:00", "question_id": "17870da4921bac8774076b766611ff5de08b7172_8", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def create_actor_with_or_without_sso_account(context: Context, actor_aliases: str, has_or_does_not_have: str):\n    actor_aliases = [alias.strip() for alias in actor_aliases.split(',')]\n    for actor_alias in actor_aliases:\n        if has_or_does_not_have in ['has', 'have']:\n            actor = get_actor(context, actor_alias)\n            account = Account('verified Individual')\n            profile_enrol_individual(context, actor, account=account)\n        else:\n            supplier = unauthenticated_supplier(actor_alias)\n"]]}
{"hexsha": "da9621b3c4280533739732c91ba549470843b191", "ext": "py", "lang": "Python", "content": "def batch_iter(data, batch_size, num_epochs, shuffle=True):\n    \"\"\"\n    Generates a batch iterator for a dataset.\n    \"\"\"\n    data = np.array(data)\n    data_size = len(data)\n    num_batches_per_epoch = int((len(data)-1)/batch_size) + 1\n    for epoch in range(num_epochs):\n        # Shuffle the data at each epoch\n        if shuffle:\n            shuffle_indices = np.random.permutation(np.arange(data_size))\n            shuffled_data = data[shuffle_indices]\n        else:\n            shuffled_data = data\n        for batch_num in range(num_batches_per_epoch):\n            start_index = batch_num * batch_size\n            end_index = min((batch_num + 1) * batch_size, data_size)\n            yield shuffled_data[start_index:end_index]", "fn_id": 2, "class_fn": false, "repo": "indranildchandra/UltimateCryptoChallenge2018", "file": "ml_layer/sentiment/data_helpers.py", "last_update_at": "2018-06-10T10:47:27+00:00", "question_id": "da9621b3c4280533739732c91ba549470843b191_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def batch_iter(data, batch_size, num_epochs, shuffle=True):\n    \"\"\"\n    Generates a batch iterator for a dataset.\n    \"\"\"\n    data = np.array(data)\n    data_size = len(data)\n    num_batches_per_epoch = int((len(data) - 1) / batch_size) + 1\n    for epoch in range(num_epochs):\n        if shuffle:\n            shuffle_indices = np.random.permutation(np.arange(data_size))\n            shuffled_data = data[shuffle_indices]\n        else:\n            shuffled_data = data\n        for batch_num in range(num_batches_per_epoch):\n            start_index = batch_num * batch_size\n            end_index = min((batch_num + 1) * batch_size, data_size)\n"]]}
{"hexsha": "71df144473af483112b363980909e14e73842e5c", "ext": "py", "lang": "Python", "content": "def test_adddockerfile_todest(tmpdir, docker_tasker):  # noqa\n    df_content = \"\"\"\nFROM fedora\nRUN yum install -y python-django\nCMD blabla\"\"\"\n    df = df_parser(str(tmpdir))\n    df.content = df_content\n\n    workflow = DockerBuildWorkflow(MOCK_SOURCE, 'test-image')\n    workflow.builder = X\n    workflow.builder.df_path = df.dockerfile_path\n    workflow.builder.df_dir = str(tmpdir)\n\n    runner = PreBuildPluginsRunner(\n        docker_tasker,\n        workflow,\n        [{\n            'name': AddDockerfilePlugin.key,\n            'args': {'nvr': 'jboss-eap-6-docker-6.4-77',\n                     'destdir': '/usr/share/doc/'}\n        }]\n    )\n    runner.run()\n    assert AddDockerfilePlugin.key is not None\n\n    expected_output = \"\"\"\nFROM fedora\nRUN yum install -y python-django\nADD Dockerfile-jboss-eap-6-docker-6.4-77 /usr/share/doc/Dockerfile-jboss-eap-6-docker-6.4-77\nCMD blabla\"\"\"\n    assert df.content == expected_output", "fn_id": 1, "class_fn": false, "repo": "jcajka/atomic-reactor", "file": "tests/plugins/test_add_dockerfile.py", "last_update_at": "2018-04-29T20:31:00+00:00", "question_id": "71df144473af483112b363980909e14e73842e5c_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_adddockerfile_todest(tmpdir, docker_tasker):\n    df_content = '\\nFROM fedora\\nRUN yum install -y python-django\\nCMD blabla'\n    df = df_parser(str(tmpdir))\n    df.content = df_content\n    workflow = DockerBuildWorkflow(MOCK_SOURCE, 'test-image')\n    workflow.builder = X\n    workflow.builder.df_path = df.dockerfile_path\n    workflow.builder.df_dir = str(tmpdir)\n    runner = PreBuildPluginsRunner(docker_tasker, workflow, [{'name': AddDockerfilePlugin.key, 'args': {'nvr': 'jboss-eap-6-docker-6.4-77', 'destdir': '/usr/share/doc/'}}])\n    runner.run()\n    assert AddDockerfilePlugin.key is not None\n    expected_output = '\\nFROM fedora\\nRUN yum install -y python-django\\nADD Dockerfile-jboss-eap-6-docker-6.4-77 /usr/share/doc/Dockerfile-jboss-eap-6-docker-6.4-77\\nCMD blabla'\n"]]}
{"hexsha": "84f7c24f7cafb3a118bd48ccf37435e4063f8d79", "ext": "py", "lang": "Python", "content": "def connect_db():\n    \"\"\"Connects to the specific database.\"\"\"\n    # TODO: Configuration\n    rv = sqlite3.connect('the.db')\n    rv.row_factory = sqlite3.Row\n    return rv", "fn_id": 1, "class_fn": false, "repo": "RBEGamer/RWTH_HACK_2018", "file": "src/backend_api/app.py", "last_update_at": "2018-05-07T11:35:35+00:00", "question_id": "84f7c24f7cafb3a118bd48ccf37435e4063f8d79_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def connect_db():\n    \"\"\"Connects to the specific database.\"\"\"\n    rv = sqlite3.connect('the.db')\n    rv.row_factory = sqlite3.Row\n"]]}
{"hexsha": "22736bbda1d169aac567567dd0013574d0991d3d", "ext": "py", "lang": "Python", "content": "def doc(*args):\n    '''\n    Return the docstrings for all modules. Optionally, specify a module or a\n    function to narrow the selection.\n\n    The strings are aggregated into a single document on the master for easy\n    reading.\n\n    Multiple modules/functions can be specified.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' sys.doc\n        salt '*' sys.doc sys\n        salt '*' sys.doc sys.doc\n        salt '*' sys.doc network.traceroute user.info\n    '''\n    docs = {}\n    if not args:\n        for fun in __salt__:\n            docs[fun] = __salt__[fun].__doc__\n        return _strip_rst(docs)\n\n    for module in args:\n        if module:\n            # allow both \"sys\" and \"sys.\" to match sys, without also matching\n            # sysctl\n            target_mod = module + '.' if not module.endswith('.') else module\n        else:\n            target_mod = ''\n        for fun in __salt__:\n            if fun == module or fun.startswith(target_mod):\n                docs[fun] = __salt__[fun].__doc__\n    return _strip_rst(docs)", "fn_id": 1, "class_fn": false, "repo": "wt/salt", "file": "salt/modules/sysmod.py", "last_update_at": "2018-09-18T05:45:43+00:00", "question_id": "22736bbda1d169aac567567dd0013574d0991d3d_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def doc(*args):\n    \"\"\"\n    Return the docstrings for all modules. Optionally, specify a module or a\n    function to narrow the selection.\n\n    The strings are aggregated into a single document on the master for easy\n    reading.\n\n    Multiple modules/functions can be specified.\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' sys.doc\n        salt '*' sys.doc sys\n        salt '*' sys.doc sys.doc\n        salt '*' sys.doc network.traceroute user.info\n    \"\"\"\n    docs = {}\n    if not args:\n        for fun in __salt__:\n            docs[fun] = __salt__[fun].__doc__\n        return _strip_rst(docs)\n    for module in args:\n        if module:\n            target_mod = module + '.' if not module.endswith('.') else module\n        else:\n            target_mod = ''\n        for fun in __salt__:\n            if fun == module or fun.startswith(target_mod):\n                docs[fun] = __salt__[fun].__doc__\n"]]}
{"hexsha": "66a05b4333837a57f5f32f3533c1867f2d117f04", "ext": "py", "lang": "Python", "content": "def splice(image, frame_width, frame_height, margin_x=0, margin_y=0):\n    # Arguments: image is of pygame.Surface\n    x = 0\n    y = 0\n\n    sub_images = []\n\n    src_width, src_height = image.get_size()\n\n    while x + frame_width <= src_width and y + frame_height <= src_height:\n        crop = Surface((frame_width, frame_height), flags=pygame.SRCALPHA)\n        crop.blit(image, (0, 0), (x, y, frame_width, frame_height))\n\n        sub_images.append(crop)\n\n        x += frame_width + margin_x\n        if x + frame_width > src_width:\n            x = 0\n            y += frame_height + margin_y\n\n    return sub_images", "fn_id": 16, "class_fn": false, "repo": "shelsoloa/Peachy", "file": "peachy/graphics.py", "last_update_at": "2018-08-12T20:06:24+00:00", "question_id": "66a05b4333837a57f5f32f3533c1867f2d117f04_16", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def splice(image, frame_width, frame_height, margin_x=0, margin_y=0):\n    x = 0\n    y = 0\n    sub_images = []\n    src_width, src_height = image.get_size()\n    while x + frame_width <= src_width and y + frame_height <= src_height:\n        crop = Surface((frame_width, frame_height), flags=pygame.SRCALPHA)\n        crop.blit(image, (0, 0), (x, y, frame_width, frame_height))\n        sub_images.append(crop)\n        x += frame_width + margin_x\n        if x + frame_width > src_width:\n            x = 0\n            y += frame_height + margin_y\n"]]}
{"hexsha": "863c1598e480b1daf740339d36af7ac540aeacb2", "ext": "py", "lang": "Python", "content": "def get_ip(request):\n    x_forwarded_for = request.META.get('HTTP_X_FORWARDED_FOR')\n    if x_forwarded_for:\n        ip = x_forwarded_for.split(',')[0]\n    else:\n        ip = request.META.get('REMOTE_ADDR')\n    return ip", "fn_id": 1, "class_fn": false, "repo": "liutianfang/skill-dev-platform", "file": "sdp/jdskill/views.py", "last_update_at": "2018-12-23T23:59:23+00:00", "question_id": "863c1598e480b1daf740339d36af7ac540aeacb2_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_ip(request):\n    x_forwarded_for = request.META.get('HTTP_X_FORWARDED_FOR')\n    if x_forwarded_for:\n        ip = x_forwarded_for.split(',')[0]\n    else:\n        ip = request.META.get('REMOTE_ADDR')\n"]]}
{"hexsha": "1a149f07f2eaafc186c0e87bc7ff51f7599bb1d3", "ext": "py", "lang": "Python", "content": "def blink():\n    while True:\n        GPIO.output(23,GPIO.HIGH)\n        time.sleep(0.5)\n        GPIO.output(23,GPIO.LOW)\n        time.sleep(0.5)", "fn_id": 1, "class_fn": false, "repo": "andriassundskard/raspberrypi-watermeter", "file": "scripts/blink.py", "last_update_at": "2018-04-05T21:25:45+00:00", "question_id": "1a149f07f2eaafc186c0e87bc7ff51f7599bb1d3_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def blink():\n    while True:\n        GPIO.output(23, GPIO.HIGH)\n        time.sleep(0.5)\n        GPIO.output(23, GPIO.LOW)\n"]]}
{"hexsha": "79a23532d268dd0df8b614168b35cdbf71f2bdef", "ext": "py", "lang": "Python", "content": "def getVerticeMenorDistancia(distancia, flaggedVertices):\n    \n    verticesDistanciasNaoVisitados = []\n    vetorIntermediario = []\n\n    for i in range(len(flaggedVertices)):\n        if (flaggedVertices[i] == False):\n            vetorIntermediario.append(distancia[i])\n            vetorIntermediario.append(i)\n            verticesDistanciasNaoVisitados.append(vetorIntermediario)\n            vetorIntermediario = []\n\n    if (len(verticesDistanciasNaoVisitados)>0):\n        menor = min(verticesDistanciasNaoVisitados)\n        indiceMenor = menor[1]\n        return indiceMenor\n    else:\n        return 99999", "fn_id": 2, "class_fn": false, "repo": "tassioferenzini/PAA-2017-T1", "file": "question1a.py", "last_update_at": "2018-10-23T16:00:53+00:00", "question_id": "79a23532d268dd0df8b614168b35cdbf71f2bdef_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def getVerticeMenorDistancia(distancia, flaggedVertices):\n    verticesDistanciasNaoVisitados = []\n    vetorIntermediario = []\n    for i in range(len(flaggedVertices)):\n        if flaggedVertices[i] == False:\n            vetorIntermediario.append(distancia[i])\n            vetorIntermediario.append(i)\n            verticesDistanciasNaoVisitados.append(vetorIntermediario)\n            vetorIntermediario = []\n    if len(verticesDistanciasNaoVisitados) > 0:\n        menor = min(verticesDistanciasNaoVisitados)\n        indiceMenor = menor[1]\n        return indiceMenor\n    else:\n"]]}
{"hexsha": "ee587123466829408959f7abd5c847ce5a4d61fb", "ext": "py", "lang": "Python", "content": "@app.route(\"/<board>/\")\ndef board_index(board):\n    row = get_board_id( board )\n\n    if row == None:\n        abort(404)\n\n    threads = get_board_threads( row[0] )\n    posts   = [summarize_thread( get_thread_posts(x[\"id\"]))\n                      for x in threads]\n\n    boardsum = [{\"thread\" : x[0], \"posts\" : x[1][0], \"omitted\" : x[1][1]}\n                    for x in zip(threads, posts)]\n\n    return render_template('board_index.html',\n            board            = board,\n            boardsum         = boardsum,\n            time             = time )", "fn_id": 0, "class_fn": false, "repo": "mushrom/crapchan", "file": "main.py", "last_update_at": "2018-02-28T01:42:48+00:00", "question_id": "ee587123466829408959f7abd5c847ce5a4d61fb_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@app.route('/<board>/')\ndef board_index(board):\n    row = get_board_id(board)\n    if row == None:\n        abort(404)\n    threads = get_board_threads(row[0])\n    posts = [summarize_thread(get_thread_posts(x['id'])) for x in threads]\n    boardsum = [{'thread': x[0], 'posts': x[1][0], 'omitted': x[1][1]} for x in zip(threads, posts)]\n"]]}
{"hexsha": "e1e31b439b140e38beb320a6acf73637a8c241ba", "ext": "py", "lang": "Python", "content": "def checkTouchVSide(x, y, w, h, maxW, maxH, tolerance):\n    if x <= 0:\n        return True\n    elif y - tolerance <= 0:\n        return True\n    elif x + w >= maxW:\n        return True\n    elif y + h + tolerance >= maxH:\n        return True\n    else:\n        return False", "fn_id": 1, "class_fn": false, "repo": "xavialex/OpenCV-Tutorials", "file": "People Counter/complete_people_counter.py", "last_update_at": "2018-04-02T15:41:41+00:00", "question_id": "e1e31b439b140e38beb320a6acf73637a8c241ba_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def checkTouchVSide(x, y, w, h, maxW, maxH, tolerance):\n    if x <= 0:\n        return True\n    elif y - tolerance <= 0:\n        return True\n    elif x + w >= maxW:\n        return True\n    elif y + h + tolerance >= maxH:\n        return True\n    else:\n"]]}
{"hexsha": "f6d281e3a449003cb559ce98389d32a9d539c8da", "ext": "py", "lang": "Python", "content": "def truncate_string_right(s, N, suff=' [..]'):\n    if len(s) > N:\n        s = s[:N-len(suff)] + suff\n    return s", "fn_id": 2, "class_fn": false, "repo": "yxiao1996/dev", "file": "catkin_ws/src/00-infrastructure/duckietown/include/duckietown_utils/text_utils.py", "last_update_at": "2018-06-25T02:51:27+00:00", "question_id": "f6d281e3a449003cb559ce98389d32a9d539c8da_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def truncate_string_right(s, N, suff=' [..]'):\n    if len(s) > N:\n        s = s[:N - len(suff)] + suff\n"]]}
{"hexsha": "aa6c4544883b12bb9db3b8af141a9ca74517d178", "ext": "py", "lang": "Python", "content": "def test_create_project_without_gitlab_ci(tmpfolder):\n    # Given options without the GitLab extension,\n    opts = dict(project_path=\"proj\")\n\n    # when the project is created,\n    create_project(opts)\n\n    # then GitLab files should not exist\n    assert not path_exists(\"proj/.gitlab-ci.yml\")", "fn_id": 1, "class_fn": false, "repo": "Bing1012/3", "file": "tests/extensions/test_gitlab_ci.py", "last_update_at": "2018-09-26T10:53:38+00:00", "question_id": "aa6c4544883b12bb9db3b8af141a9ca74517d178_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_create_project_without_gitlab_ci(tmpfolder):\n    opts = dict(project_path='proj')\n    create_project(opts)\n"]]}
{"hexsha": "1fd1ae443ba6add1efcda27b28909db98171de84", "ext": "py", "lang": "Python", "content": "def kmeans():\n    X = np.array([[1, 2], [1, 4], [1, 0], [4, 2], [4, 4], [4, 0]])\n    kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n    kmeans.labels_\n    # array([0, 0, 0, 1, 1, 1], dtype=int32)\n    kmeans.predict([[0, 0], [4, 4]])\n    # array([0, 1], dtype=int32)\n    kmeans.cluster_centers_", "fn_id": 0, "class_fn": false, "repo": "yanshengjia/nlp", "file": "kmeans/src/kmeans.py", "last_update_at": "2018-04-12T07:48:10+00:00", "question_id": "1fd1ae443ba6add1efcda27b28909db98171de84_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def kmeans():\n    X = np.array([[1, 2], [1, 4], [1, 0], [4, 2], [4, 4], [4, 0]])\n    kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n    kmeans.labels_\n    kmeans.predict([[0, 0], [4, 4]])\n"]]}
{"hexsha": "4387826def52741beff368d6355d43a7716ebfd5", "ext": "py", "lang": "Python", "content": "def run_yolov2(args):\n\n    implot = {'rand': False, 'count': 0}\n    if args.implot_seq and args.implot_seq > 0:\n        imgplot['count'] = args.implot_seq\n    elif args.implot_rand and args.implot_seq > 0:\n        imgplot['rand'] = True\n        imgplot['count'] = args.implot_seq\n    else:\n        implot = None\n\n    flow_eval = DarkflowEvalPTI01(args.gtpath, args.loadfrom, args.impath, metric=args.metric, limit=args.limit, plot=args.plot, implot=implot)\n    flow_eval.eval()", "fn_id": 1, "class_fn": false, "repo": "gustavovaliati/masters_evaluations", "file": "eval.py", "last_update_at": "2018-03-21T19:52:08+00:00", "question_id": "4387826def52741beff368d6355d43a7716ebfd5_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def run_yolov2(args):\n    implot = {'rand': False, 'count': 0}\n    if args.implot_seq and args.implot_seq > 0:\n        imgplot['count'] = args.implot_seq\n    elif args.implot_rand and args.implot_seq > 0:\n        imgplot['rand'] = True\n        imgplot['count'] = args.implot_seq\n    else:\n        implot = None\n    flow_eval = DarkflowEvalPTI01(args.gtpath, args.loadfrom, args.impath, metric=args.metric, limit=args.limit, plot=args.plot, implot=implot)\n"]]}
{"hexsha": "bfa9f34ddf9a750adb3d5f51986d19392d63904a", "ext": "py", "lang": "Python", "content": "def test_delete_processor(regress_nifi, fix_proc):\n    f_p1 = fix_proc.generate()\n    r1 = canvas.delete_processor(f_p1)\n    assert r1.status is None\n    assert isinstance(r1, nifi.ProcessorEntity)\n    # try to delete processor twice\n    with pytest.raises(ValueError):\n        _ = canvas.delete_processor(f_p1)\n    # try to delete running processor\n    f_p2 = fix_proc.generate()\n    canvas.schedule_processor(f_p2, True)\n    with pytest.raises(ValueError):\n        _ = canvas.delete_processor(f_p2)\n    # and once more with feeling, er, force\n    r2 = canvas.delete_processor(f_p2, force=True)\n    assert r2.status is None", "fn_id": 14, "class_fn": false, "repo": "Paul-Verardi/nipyapi", "file": "tests/test_canvas.py", "last_update_at": "2018-11-13T21:01:33+00:00", "question_id": "bfa9f34ddf9a750adb3d5f51986d19392d63904a_14", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_delete_processor(regress_nifi, fix_proc):\n    f_p1 = fix_proc.generate()\n    r1 = canvas.delete_processor(f_p1)\n    assert r1.status is None\n    assert isinstance(r1, nifi.ProcessorEntity)\n    with pytest.raises(ValueError):\n        _ = canvas.delete_processor(f_p1)\n    f_p2 = fix_proc.generate()\n    canvas.schedule_processor(f_p2, True)\n    with pytest.raises(ValueError):\n        _ = canvas.delete_processor(f_p2)\n    r2 = canvas.delete_processor(f_p2, force=True)\n"]]}
{"hexsha": "ac0edbd146e8c4a09a7099dda01e52ac7cfcbefd", "ext": "py", "lang": "Python", "content": "def class_factory(card_name, card_type, card_scheme=None, card_tag=None, card_padding=None):\n\n    def get_grids_factory(card_scheme):\n        fields_info = [(index, field_info) for index, field_info in enumerate(card_scheme) if\n                       field_info.update_grid or\n                       field_info.subscheme and any(x.update_grid for x in field_info.subscheme.scheme)]\n\n        def wrapped(self):\n            grids = set()\n\n            for index, field_info in fields_info:\n\n                if field_info.seq_type:\n\n                    if field_info.subscheme:\n\n                        for subfield in self.fields[index]:\n\n                            for subsubfield, subsubfield_info in zip(subfield, field_info.subscheme.scheme):\n\n                                if subsubfield_info.update_grid:\n\n                                    if subsubfield_info.seq_type:\n                                        grids |= set(subsubfield)\n                                    else:\n                                        grids.add(subsubfield)\n                    else:\n\n                        if field_info.update_grid:\n                            grids |= set(self.fields[index])\n                else:\n\n                    if field_info.subscheme:\n\n                        for subfield, subfield_info in zip(field, field_info.subscheme.scheme):\n\n                            if subfield_info.update_grid:\n\n                                if subfield_info.seq_type:\n                                    grids |= set(subfield)\n                                else:\n                                    grids.add(subfield)\n                    else:\n\n                        if field_info.update_grid:\n                            grids.add(self.fields[index])\n\n            return grids\n\n        return wrapped\n\n    def get_field_factory(index, field_info, alternate_name=False):\n\n        if field_info.seq_type == 'vector':\n\n            if field_info.type == 'grid':\n\n                def wrapped(self):\n                    vector = self.fields[index]\n\n                    if alternate_name:\n\n                        if not vector is None and isinstance(vector[0], (int, Card)):\n                            vector = vector[0]\n                        else:\n                            vector = None\n                    else:\n\n                        if vector is None:\n                            vector = np.array([0.0, 0.0, 0.0])\n                        elif isinstance(vector[0], Card):\n                            vector = None\n\n                    return vector\n            else:\n\n                def wrapped(self):\n                    vector = self.fields[index]\n\n                    if vector is None:\n                        vector = np.array([0.0, 0.0, 0.0])\n\n                    return vector\n        else:\n\n            def wrapped(self):\n                return self.fields[index]\n\n        return wrapped\n\n    def set_field_factory(index, field_info, is_subfield=False, alternate_name=False):\n\n        if field_info.type:\n\n            if field_info.seq_type:\n\n                if field_info.seq_type == 'vector':\n\n                    def wrapped(self, value):\n                        old_value = self.fields[index]\n\n                        if is_subfield:\n                            card = self.card\n                        else:\n                            card = self\n\n                        try:\n                            old_value[0]._unsubscribe(card)\n\n                            if field_info.update_grid:\n                                old_value[0].elems.remove(card)\n                        except (TypeError, AttributeError):\n                            pass\n\n                        if value is None:\n                            self.fields[index] = None\n                        else:\n                            vector = value\n\n                            try:\n                                value._subscribe(card)\n                                vector = [value, None, None]\n\n                                if field_info.update_grid:\n                                    value.elems.add(card)\n                            except AttributeError:\n                                pass\n\n                            self.fields[index] = np.array(vector)\n                else:\n\n                    def wrapped(self, value):\n                        raise AttributeError(\"can't set attribute\")\n\n            else:\n\n                def wrapped(self, value):\n                    old_value = self.fields[index]\n\n                    if not value is old_value:\n\n                        if is_subfield:\n                            card = self.card\n                        else:\n                            card = self\n\n                        try:\n                            old_value._unsubscribe(card)\n\n                            if field_info.update_grid:\n                                old_value.elems.remove(card)\n                        except AttributeError:\n                            pass\n\n                        try:\n                            value._subscribe(card)\n\n                            if field_info.update_grid:\n                                value.elems.add(card)\n                        except AttributeError:\n                            pass\n\n                        self.fields[index] = value\n        else:\n\n            def wrapped(self, value):\n                self.fields[index] = value\n\n        return wrapped\n\n    def add_subscheme_factory(index, field_info):\n\n        def wrapped(self, *args, **kwargs):\n\n            if kwargs:\n                args = list()\n\n                for subfield_info in field_info.subscheme.scheme:\n\n                    try:\n                        args.append(kwargs[subfield_info.name])\n                    except KeyError:\n                        args.append(None)\n\n            subscheme = field_info.subscheme(args, self)\n\n            if field_info.seq_type == 'list':\n                self.fields[index].append(subscheme)\n            elif field_info.seq_type == 'set':\n                self.fields[index].add(subscheme)\n\n        return wrapped\n\n    if card_name in ('FORCE', 'MOMENT'):\n        cls_parents = (SetCard, VectorCard,)\n    elif card_type in ('mpc', 'spc', 'load'):\n        cls_parents = (SetCard,)\n    elif card_type == 'coord':\n        cls_parents = (CoordCard,)\n    elif card_type == 'elem':\n        cls_parents = (ElemCard,)\n    elif card_type == 'grid':\n        cls_parents = (GridCard,)\n    elif card_type == 'include':\n        cls_parents = (IncludeCard,)\n    else:\n        cls_parents = (Card,)\n\n    cls = type(card_name, cls_parents, {})\n    cls.type = card_type\n    cls.tag = card_tag\n    cls._scheme = card_scheme\n\n    if card_scheme:\n        cls._optional_scheme = {field_info.name: (index, field_info) for\n                               index, field_info in enumerate(card_scheme) if\n                               field_info.optional}\n\n    cls._padding = card_padding\n\n    if cls._optional_scheme and not cls._padding:\n        cls._padding = Padding()\n\n    if card_scheme:\n\n        for index, field_info in enumerate(card_scheme):\n\n            if field_info.subscheme:\n                subscheme_cls = type('{}_{}'.format(card_name, field_info.name), (Subscheme,), {})\n                subscheme_cls.scheme = field_info.subscheme\n                field_info.subscheme = subscheme_cls\n\n                if field_info.seq_type:\n                    setattr(cls, 'add_{}'.format(get_singular(field_info.name)),\n                            add_subscheme_factory(index, field_info))\n\n                for subindex, subfield_info in enumerate(field_info.subscheme.scheme):\n\n                    if subfield_info.name:\n                        setattr(field_info.subscheme, subfield_info.name,\n                                property(get_field_factory(subindex, subfield_info),\n                                         set_field_factory(subindex, subfield_info,\n                                                           is_subfield=True)))\n\n            if field_info.name and not hasattr(cls, field_info.name):\n                setattr(cls, field_info.name,\n                        property(get_field_factory(index, field_info),\n                                 set_field_factory(index, field_info)))\n\n            if field_info.alternate_name and not hasattr(cls, field_info.alternate_name):\n                setattr(cls, field_info.alternate_name,\n                        property(get_field_factory(index, field_info, alternate_name=True),\n                                 set_field_factory(index, field_info, alternate_name=True)))\n\n        if card_type == 'elem' and not 'grids' in [x.name for x in card_scheme]:\n            setattr(cls, 'grids', property(get_grids_factory(card_scheme)))\n\n    if card_name in card_interfaces_additional:\n\n        for method_name, (function, is_property) in card_interfaces_additional[card_name].items():\n\n            if is_property:\n                setattr(cls, method_name, property(function))\n            else:\n                setattr(cls, method_name, function)\n\n    return cls", "fn_id": 0, "class_fn": false, "repo": "alvarosanz/nastranpy", "file": "nastranpy/bdf/cards/class_factory.py", "last_update_at": "2018-03-27T13:30:19+00:00", "question_id": "ac0edbd146e8c4a09a7099dda01e52ac7cfcbefd_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def class_factory(card_name, card_type, card_scheme=None, card_tag=None, card_padding=None):\n\n    def get_grids_factory(card_scheme):\n        fields_info = [(index, field_info) for index, field_info in enumerate(card_scheme) if field_info.update_grid or (field_info.subscheme and any((x.update_grid for x in field_info.subscheme.scheme)))]\n\n        def wrapped(self):\n            grids = set()\n            for index, field_info in fields_info:\n                if field_info.seq_type:\n                    if field_info.subscheme:\n                        for subfield in self.fields[index]:\n                            for subsubfield, subsubfield_info in zip(subfield, field_info.subscheme.scheme):\n                                if subsubfield_info.update_grid:\n                                    if subsubfield_info.seq_type:\n                                        grids |= set(subsubfield)\n                                    else:\n                                        grids.add(subsubfield)\n                    elif field_info.update_grid:\n                        grids |= set(self.fields[index])\n                elif field_info.subscheme:\n                    for subfield, subfield_info in zip(field, field_info.subscheme.scheme):\n                        if subfield_info.update_grid:\n                            if subfield_info.seq_type:\n                                grids |= set(subfield)\n                            else:\n                                grids.add(subfield)\n                elif field_info.update_grid:\n                    grids.add(self.fields[index])\n            return grids\n        return wrapped\n\n    def get_field_factory(index, field_info, alternate_name=False):\n        if field_info.seq_type == 'vector':\n            if field_info.type == 'grid':\n\n                def wrapped(self):\n                    vector = self.fields[index]\n                    if alternate_name:\n                        if not vector is None and isinstance(vector[0], (int, Card)):\n                            vector = vector[0]\n                        else:\n                            vector = None\n                    elif vector is None:\n                        vector = np.array([0.0, 0.0, 0.0])\n                    elif isinstance(vector[0], Card):\n                        vector = None\n                    return vector\n            else:\n\n                def wrapped(self):\n                    vector = self.fields[index]\n                    if vector is None:\n                        vector = np.array([0.0, 0.0, 0.0])\n                    return vector\n        else:\n\n            def wrapped(self):\n                return self.fields[index]\n        return wrapped\n\n    def set_field_factory(index, field_info, is_subfield=False, alternate_name=False):\n        if field_info.type:\n            if field_info.seq_type:\n                if field_info.seq_type == 'vector':\n\n                    def wrapped(self, value):\n                        old_value = self.fields[index]\n                        if is_subfield:\n                            card = self.card\n                        else:\n                            card = self\n                        try:\n                            old_value[0]._unsubscribe(card)\n                            if field_info.update_grid:\n                                old_value[0].elems.remove(card)\n                        except (TypeError, AttributeError):\n                            pass\n                        if value is None:\n                            self.fields[index] = None\n                        else:\n                            vector = value\n                            try:\n                                value._subscribe(card)\n                                vector = [value, None, None]\n                                if field_info.update_grid:\n                                    value.elems.add(card)\n                            except AttributeError:\n                                pass\n                            self.fields[index] = np.array(vector)\n                else:\n\n                    def wrapped(self, value):\n                        raise AttributeError(\"can't set attribute\")\n            else:\n\n                def wrapped(self, value):\n                    old_value = self.fields[index]\n                    if not value is old_value:\n                        if is_subfield:\n                            card = self.card\n                        else:\n                            card = self\n                        try:\n                            old_value._unsubscribe(card)\n                            if field_info.update_grid:\n                                old_value.elems.remove(card)\n                        except AttributeError:\n                            pass\n                        try:\n                            value._subscribe(card)\n                            if field_info.update_grid:\n                                value.elems.add(card)\n                        except AttributeError:\n                            pass\n                        self.fields[index] = value\n        else:\n\n            def wrapped(self, value):\n                self.fields[index] = value\n        return wrapped\n\n    def add_subscheme_factory(index, field_info):\n\n        def wrapped(self, *args, **kwargs):\n            if kwargs:\n                args = list()\n                for subfield_info in field_info.subscheme.scheme:\n                    try:\n                        args.append(kwargs[subfield_info.name])\n                    except KeyError:\n                        args.append(None)\n            subscheme = field_info.subscheme(args, self)\n            if field_info.seq_type == 'list':\n                self.fields[index].append(subscheme)\n            elif field_info.seq_type == 'set':\n                self.fields[index].add(subscheme)\n        return wrapped\n    if card_name in ('FORCE', 'MOMENT'):\n        cls_parents = (SetCard, VectorCard)\n    elif card_type in ('mpc', 'spc', 'load'):\n        cls_parents = (SetCard,)\n    elif card_type == 'coord':\n        cls_parents = (CoordCard,)\n    elif card_type == 'elem':\n        cls_parents = (ElemCard,)\n    elif card_type == 'grid':\n        cls_parents = (GridCard,)\n    elif card_type == 'include':\n        cls_parents = (IncludeCard,)\n    else:\n        cls_parents = (Card,)\n    cls = type(card_name, cls_parents, {})\n    cls.type = card_type\n    cls.tag = card_tag\n    cls._scheme = card_scheme\n    if card_scheme:\n        cls._optional_scheme = {field_info.name: (index, field_info) for index, field_info in enumerate(card_scheme) if field_info.optional}\n    cls._padding = card_padding\n    if cls._optional_scheme and (not cls._padding):\n        cls._padding = Padding()\n    if card_scheme:\n        for index, field_info in enumerate(card_scheme):\n            if field_info.subscheme:\n                subscheme_cls = type('{}_{}'.format(card_name, field_info.name), (Subscheme,), {})\n                subscheme_cls.scheme = field_info.subscheme\n                field_info.subscheme = subscheme_cls\n                if field_info.seq_type:\n                    setattr(cls, 'add_{}'.format(get_singular(field_info.name)), add_subscheme_factory(index, field_info))\n                for subindex, subfield_info in enumerate(field_info.subscheme.scheme):\n                    if subfield_info.name:\n                        setattr(field_info.subscheme, subfield_info.name, property(get_field_factory(subindex, subfield_info), set_field_factory(subindex, subfield_info, is_subfield=True)))\n            if field_info.name and (not hasattr(cls, field_info.name)):\n                setattr(cls, field_info.name, property(get_field_factory(index, field_info), set_field_factory(index, field_info)))\n            if field_info.alternate_name and (not hasattr(cls, field_info.alternate_name)):\n                setattr(cls, field_info.alternate_name, property(get_field_factory(index, field_info, alternate_name=True), set_field_factory(index, field_info, alternate_name=True)))\n        if card_type == 'elem' and (not 'grids' in [x.name for x in card_scheme]):\n            setattr(cls, 'grids', property(get_grids_factory(card_scheme)))\n    if card_name in card_interfaces_additional:\n        for method_name, (function, is_property) in card_interfaces_additional[card_name].items():\n            if is_property:\n                setattr(cls, method_name, property(function))\n            else:\n                setattr(cls, method_name, function)\n"]]}
{"hexsha": "7128a296797722bcd64be5dc83a5dd4d8a6a968b", "ext": "py", "lang": "Python", "content": "def getEpicListByStart(startTime_iso,proj=\"K2\"):\n    \"\"\"\n    Filtered Query of Mast for a specific project\n    with observations within .25 days of a known start time\n    Intended for finding observations of one K2 campaign.\n    Returns a list of epic ids\n    \"\"\"\n\n\n    t=Time(startTime_iso,format='iso', scale='utc')\n    tmjd=t.mjd\n    \n    requestFilters = [\n                             {\"paramName\":\"project\",\n                              \"values\":[proj],\n                              \"separator\":\";\"\n                             },\n                             {\"paramName\":\"t_min\",\n                              \"values\":[{\"min\":tmjd-.5 , \"max\":tmjd+.5}]\n                              },\n                         ]\n    \n    mashupRequest = {\"service\":\"Mast.Caom.Filtered\",\n                     \"format\":\"json\",\n                     \"params\":{\n                         #\"columns\":\"COUNT_BIG(*)\",\n                         \"columns\":\"*\",\n                         \"filters\":requestFilters\n                         }}\n    \n    headers,outString = api.mastQuery(mashupRequest)\n    countData = json.loads(outString)\n    pdata=p.DataFrame.from_dict(countData['data'])\n    \n    epicids=list(map(lambda x: x[4:13], pdata['obs_id']))\n    \n    return epicids", "fn_id": 0, "class_fn": false, "repo": "mustaric/MASTTools", "file": "maststats/k2MultiMission.py", "last_update_at": "2018-11-26T20:38:19+00:00", "question_id": "7128a296797722bcd64be5dc83a5dd4d8a6a968b_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def getEpicListByStart(startTime_iso, proj='K2'):\n    \"\"\"\n    Filtered Query of Mast for a specific project\n    with observations within .25 days of a known start time\n    Intended for finding observations of one K2 campaign.\n    Returns a list of epic ids\n    \"\"\"\n    t = Time(startTime_iso, format='iso', scale='utc')\n    tmjd = t.mjd\n    requestFilters = [{'paramName': 'project', 'values': [proj], 'separator': ';'}, {'paramName': 't_min', 'values': [{'min': tmjd - 0.5, 'max': tmjd + 0.5}]}]\n    mashupRequest = {'service': 'Mast.Caom.Filtered', 'format': 'json', 'params': {'columns': '*', 'filters': requestFilters}}\n    headers, outString = api.mastQuery(mashupRequest)\n    countData = json.loads(outString)\n    pdata = p.DataFrame.from_dict(countData['data'])\n    epicids = list(map(lambda x: x[4:13], pdata['obs_id']))\n"]]}
{"hexsha": "21cd10ec0c43a2a5245ac89b17664c6b6824fc20", "ext": "py", "lang": "Python", "content": "def template_to_filepath(template, metadata, template_patterns=None):\n\t\"\"\"Create directory structure and file name based on metadata template.\n\n\tParameters:\n\t\ttemplate (str): A filepath which can include template patterns as defined by :param template_patterns:.\n\n\t\tmetadata (dict): A metadata dict.\n\n\t\ttemplate_patterns (dict): A dict of ``pattern: field`` pairs used to replace patterns with metadata field values.\n\t\t\tDefault: :const TEMPLATE_PATTERNS:\n\n\tReturns:\n\t\tA filepath.\n\t\"\"\"\n\n\tif template_patterns is None:\n\t\ttemplate_patterns = TEMPLATE_PATTERNS\n\n\tmetadata = metadata if isinstance(metadata, dict) else _mutagen_fields_to_single_value(metadata)\n\tassert isinstance(metadata, dict)\n\n\tsuggested_filename = get_suggested_filename(metadata).replace('.mp3', '')\n\n\tif template == os.getcwd() or template == '%suggested%':\n\t\tfilepath = suggested_filename\n\telse:\n\t\tt = template.replace('%suggested%', suggested_filename)\n\t\tfilepath = _replace_template_patterns(t, metadata, template_patterns)\n\n\treturn filepath", "fn_id": 13, "class_fn": false, "repo": "dmoebius/gmusicapi-wrapper", "file": "gmusicapi_wrapper/utils.py", "last_update_at": "2018-09-29T06:16:15+00:00", "question_id": "21cd10ec0c43a2a5245ac89b17664c6b6824fc20_13", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def template_to_filepath(template, metadata, template_patterns=None):\n    \"\"\"Create directory structure and file name based on metadata template.\n\n\tParameters:\n\t\ttemplate (str): A filepath which can include template patterns as defined by :param template_patterns:.\n\n\t\tmetadata (dict): A metadata dict.\n\n\t\ttemplate_patterns (dict): A dict of ``pattern: field`` pairs used to replace patterns with metadata field values.\n\t\t\tDefault: :const TEMPLATE_PATTERNS:\n\n\tReturns:\n\t\tA filepath.\n\t\"\"\"\n    if template_patterns is None:\n        template_patterns = TEMPLATE_PATTERNS\n    metadata = metadata if isinstance(metadata, dict) else _mutagen_fields_to_single_value(metadata)\n    assert isinstance(metadata, dict)\n    suggested_filename = get_suggested_filename(metadata).replace('.mp3', '')\n    if template == os.getcwd() or template == '%suggested%':\n        filepath = suggested_filename\n    else:\n        t = template.replace('%suggested%', suggested_filename)\n        filepath = _replace_template_patterns(t, metadata, template_patterns)\n"]]}
{"hexsha": "3ced3da168b0c4d5fb8345ab35a6e8f79cade777", "ext": "py", "lang": "Python", "content": "@WebGLDescriptorGenerator.register_handler(SplitAxis)\ndef split_axis(op: SplitAxis) -> List[Kernel]:\n    x = op.inputs[\"x\"]\n    ys = [op.outputs[f\"y{i}\"] for i in range(len(op.outputs))]\n    sections = [0] + op.sections\n    axis = op.axis\n\n    kernels = []\n\n    for i, y in enumerate(ys):\n        assert x.order.check_same_axes(y.order)\n        assert ChannelMode.get(x) == ChannelMode.get(y) == ChannelModeEnum.R\n\n        name_injector = KernelNameInjector(op)\n        uniform_injector = UniformInjector()\n\n        offset = [sections[i] if a == axis else 0 for a in y.order.axes]\n        uniform_injector.register({\n            \"sampler_x\": x,\n\n            \"texture_stride_y\": texture_stride(y),\n            \"variable_shape_y\": _pad_to_4d(y.shape),\n            \"variable_stride_y\": _pad_to_4d(y.stride),\n\n            \"texture_shape_x\": texture_shape(x),\n            \"texture_stride_x\": texture_stride(x),\n            \"variable_shape_x\": _pad_to_4d([x.shape_dict[a] for a in y.order.axes]),\n            \"variable_stride_x\": _pad_to_4d([x.stride_dict[a] for a in y.order.axes]),\n\n            \"offset\": _pad_to_4d(offset, 0)\n        })\n\n        source = template\n        source = uniform_injector.inject(source)\n        source = name_injector.inject(source)\n        kernel = Kernel(\n            source,\n            name_injector.name,\n            uniform_injector.samplers,\n            uniform_injector.uniforms,\n            y\n        )\n        kernels.append(kernel)\n\n    return kernels", "fn_id": 1, "class_fn": false, "repo": "gunpowder78/webdnn", "file": "src/graph_transpiler/webdnn/backend/webgl/kernels/split_axis.py", "last_update_at": "2018-07-26T13:52:21+00:00", "question_id": "3ced3da168b0c4d5fb8345ab35a6e8f79cade777_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@WebGLDescriptorGenerator.register_handler(SplitAxis)\ndef split_axis(op: SplitAxis) -> List[Kernel]:\n    x = op.inputs['x']\n    ys = [op.outputs[f'y{i}'] for i in range(len(op.outputs))]\n    sections = [0] + op.sections\n    axis = op.axis\n    kernels = []\n    for i, y in enumerate(ys):\n        assert x.order.check_same_axes(y.order)\n        assert ChannelMode.get(x) == ChannelMode.get(y) == ChannelModeEnum.R\n        name_injector = KernelNameInjector(op)\n        uniform_injector = UniformInjector()\n        offset = [sections[i] if a == axis else 0 for a in y.order.axes]\n        uniform_injector.register({'sampler_x': x, 'texture_stride_y': texture_stride(y), 'variable_shape_y': _pad_to_4d(y.shape), 'variable_stride_y': _pad_to_4d(y.stride), 'texture_shape_x': texture_shape(x), 'texture_stride_x': texture_stride(x), 'variable_shape_x': _pad_to_4d([x.shape_dict[a] for a in y.order.axes]), 'variable_stride_x': _pad_to_4d([x.stride_dict[a] for a in y.order.axes]), 'offset': _pad_to_4d(offset, 0)})\n        source = template\n        source = uniform_injector.inject(source)\n        source = name_injector.inject(source)\n        kernel = Kernel(source, name_injector.name, uniform_injector.samplers, uniform_injector.uniforms, y)\n        kernels.append(kernel)\n"]]}
{"hexsha": "b5f59b4df875ffe640240adcba1fb3213170554f", "ext": "py", "lang": "Python", "content": "def find_harris_conrners(image, block_size=2, ksize=5, k=0.04):\n    if len(image.shape) > 2:\n        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    else:\n        gray = image\n        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n    gray = np.float32(gray)\n    dst = cv2.cornerHarris(src=gray, blockSize=block_size, ksize=ksize, k=k)\n    dst = cv2.dilate(dst, None)\n    image[dst > 0.01 * dst.max()] = [0, 0, 255]\n    return image", "fn_id": 0, "class_fn": false, "repo": "jerry-le/computer-vision", "file": "src/feature_detection/harris_corner_detection.py", "last_update_at": "2018-10-14T02:05:58+00:00", "question_id": "b5f59b4df875ffe640240adcba1fb3213170554f_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def find_harris_conrners(image, block_size=2, ksize=5, k=0.04):\n    if len(image.shape) > 2:\n        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    else:\n        gray = image\n        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n    gray = np.float32(gray)\n    dst = cv2.cornerHarris(src=gray, blockSize=block_size, ksize=ksize, k=k)\n    dst = cv2.dilate(dst, None)\n    image[dst > 0.01 * dst.max()] = [0, 0, 255]\n"]]}
{"hexsha": "f04d43d82ea8ea1bb7ad46bfa134e3179aa1625b", "ext": "py", "lang": "Python", "content": "def test_unexpected_datetime_column_handled_without_errors():\n    df_titanic_train, df_titanic_test = utils.get_titanic_binary_classification_dataset()\n\n    column_descriptions = {\n        'survived': 'output'\n        , 'sex': 'categorical'\n        , 'embarked': 'categorical'\n        , 'pclass': 'categorical'\n    }\n\n    ml_predictor = Predictor(type_of_estimator='classifier', column_descriptions=column_descriptions)\n\n    ml_predictor.train(df_titanic_train)\n\n    test_dict = df_titanic_test.sample(frac=0.1).to_dict('records')[0]\n\n    test_dict['unexpected_column'] = datetime.date.today()\n    test_dict['anoter_unexpected_column'] = datetime.datetime.today()\n\n    ml_predictor.predict(test_dict)\n\n    # We want to make sure the above does not throw an error\n    assert True", "fn_id": 7, "class_fn": false, "repo": "kngo107/testing", "file": "tests/user_logging_tests.py", "last_update_at": "2018-03-05T06:57:36+00:00", "question_id": "f04d43d82ea8ea1bb7ad46bfa134e3179aa1625b_7", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_unexpected_datetime_column_handled_without_errors():\n    df_titanic_train, df_titanic_test = utils.get_titanic_binary_classification_dataset()\n    column_descriptions = {'survived': 'output', 'sex': 'categorical', 'embarked': 'categorical', 'pclass': 'categorical'}\n    ml_predictor = Predictor(type_of_estimator='classifier', column_descriptions=column_descriptions)\n    ml_predictor.train(df_titanic_train)\n    test_dict = df_titanic_test.sample(frac=0.1).to_dict('records')[0]\n    test_dict['unexpected_column'] = datetime.date.today()\n    test_dict['anoter_unexpected_column'] = datetime.datetime.today()\n    ml_predictor.predict(test_dict)\n"]]}
{"hexsha": "4f09f6de9b9d647c930fa411ca5ad7349fe99a13", "ext": "py", "lang": "Python", "content": "def ConvertFromAbsolutePosition(map, absolute_x, absolute_y):\n    tile_width = map.tiles[(0, 0)].width # accesses tile (0,0) (Which will ALWAYS exist in a non-malformed map) to get its height and width\n    tile_height = map.tiles[(0, 0)].height\n    \n    tile_location = (absolute_x // tile_width, absolute_y // tile_height)\n    sub_location = [absolute_x - (tile_width * tile_location[0]), absolute_y - (tile_height * tile_location[0])]\n\n    return tile_location, sub_location", "fn_id": 5, "class_fn": false, "repo": "cruxicheiros/tyche_alpha", "file": "MainGame.py", "last_update_at": "2018-02-12T21:26:30+00:00", "question_id": "4f09f6de9b9d647c930fa411ca5ad7349fe99a13_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def ConvertFromAbsolutePosition(map, absolute_x, absolute_y):\n    tile_width = map.tiles[0, 0].width\n    tile_height = map.tiles[0, 0].height\n    tile_location = (absolute_x // tile_width, absolute_y // tile_height)\n    sub_location = [absolute_x - tile_width * tile_location[0], absolute_y - tile_height * tile_location[0]]\n"]]}
{"hexsha": "ec2cfd42183da10de05b778fc2c9b56540e4c700", "ext": "py", "lang": "Python", "content": "def test_empty_file():\n    with pytest.raises(fcmcmp.UsageError) as exc_info:\n        fcmcmp.load_experiments(dummy_data / 'empty_file.yml')\n    assert \"is empty\" in str(exc_info.value)", "fn_id": 1, "class_fn": false, "repo": "kalekundert/fcmcmp", "file": "tests/test_experiments.py", "last_update_at": "2018-08-30T15:56:40+00:00", "question_id": "ec2cfd42183da10de05b778fc2c9b56540e4c700_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_empty_file():\n    with pytest.raises(fcmcmp.UsageError) as exc_info:\n        fcmcmp.load_experiments(dummy_data / 'empty_file.yml')\n"]]}
{"hexsha": "c2f181d318d1c95b5c4ad17b3e56ea0f34900001", "ext": "py", "lang": "Python", "content": "def make_phrase_from(obj):\n    if type(obj) == type(()):\n        if len(obj) == 1:\n            if obj[0].__class__ == Should:\n                return obj[0]\n            else:\n                obj = obj[0]\n        if len(obj) == 2:\n            return Verify(*obj)\n        else:\n            return Phrase(obj[0], obj[1], obj[2:])\n    else:\n        return obj", "fn_id": 0, "class_fn": false, "repo": "Kazark/pyfreeverse", "file": "freeverse/freeverse.py", "last_update_at": "2018-03-03T16:06:54+00:00", "question_id": "c2f181d318d1c95b5c4ad17b3e56ea0f34900001_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def make_phrase_from(obj):\n    if type(obj) == type(()):\n        if len(obj) == 1:\n            if obj[0].__class__ == Should:\n                return obj[0]\n            else:\n                obj = obj[0]\n        if len(obj) == 2:\n            return Verify(*obj)\n        else:\n            return Phrase(obj[0], obj[1], obj[2:])\n    else:\n"]]}
{"hexsha": "9eef3bd9a681da15a892495231745f91dc75f4f3", "ext": "py", "lang": "Python", "content": "def main():\n    for tc in range(int(input())):\n        N, ans = int(input()), -1\n        for a in range(1,N//2):\n            b = (N*(2*a-N))//(2*(a-N))\n            c = N-a-b\n            if a+b+c==N and a*a+b*b==c*c:\n                ans = max(ans,a*b*c)\n        print(ans)", "fn_id": 0, "class_fn": false, "repo": "TISparta/competitive-programming-solutions", "file": "HackerRank/ProjectEuler+/p009.py", "last_update_at": "2018-01-30T13:21:30+00:00", "question_id": "9eef3bd9a681da15a892495231745f91dc75f4f3_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main():\n    for tc in range(int(input())):\n        N, ans = (int(input()), -1)\n        for a in range(1, N // 2):\n            b = N * (2 * a - N) // (2 * (a - N))\n            c = N - a - b\n            if a + b + c == N and a * a + b * b == c * c:\n                ans = max(ans, a * b * c)\n"]]}
{"hexsha": "4a1193ffcf4f587b2ebcb0b48dd91207ccdf45e4", "ext": "py", "lang": "Python", "content": "def getTopRigs(conn, limit):\n\tcursor = conn.cursor()\n\tquery = 'SELECT extra_data, Count(*) AS total FROM blockchain GROUP BY extra_data ORDER BY total DESC LIMIT %s'\n\tcursor.execute(query,limit)\n\tdata = cursor.fetchall()\n\tcursor.close()\n\treturn data", "fn_id": 22, "class_fn": false, "repo": "scavicchio/easyWaltonTracker", "file": "app/databaseFuctions.py", "last_update_at": "2018-05-10T04:50:13+00:00", "question_id": "4a1193ffcf4f587b2ebcb0b48dd91207ccdf45e4_22", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def getTopRigs(conn, limit):\n    cursor = conn.cursor()\n    query = 'SELECT extra_data, Count(*) AS total FROM blockchain GROUP BY extra_data ORDER BY total DESC LIMIT %s'\n    cursor.execute(query, limit)\n    data = cursor.fetchall()\n    cursor.close()\n"]]}
{"hexsha": "a4ce892062d387b5973accb20a658592f680c02e", "ext": "py", "lang": "Python", "content": "def test_read_one(address_source_params, one_address_result_session):\n    source = DatabaseSource(**address_source_params)\n    with patch('pyramid_oereb.core.adapter.DatabaseAdapter.get_session', return_value=one_address_result_session()):  # noqa: E501\n        source.read(Parameter('xml'), 'teststreet', 4050, '99a')\n        assert len(source.records) == 1\n        assert isinstance(source.records[0], AddressRecord)\n        assert source.records[0].street_name == 'teststreet'\n        assert source.records[0].street_number == '99a'\n        assert source.records[0].zip_code == 4050\n        assert source.records[0].geom.coords[0] == (1.0, 1.0)", "fn_id": 2, "class_fn": false, "repo": "pyramidoereb/pyramid_oereb", "file": "tests/contrib.data_sources.standard/sources/test_adress.py", "last_update_at": "2018-01-26T06:27:29+00:00", "question_id": "a4ce892062d387b5973accb20a658592f680c02e_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_read_one(address_source_params, one_address_result_session):\n    source = DatabaseSource(**address_source_params)\n    with patch('pyramid_oereb.core.adapter.DatabaseAdapter.get_session', return_value=one_address_result_session()):\n        source.read(Parameter('xml'), 'teststreet', 4050, '99a')\n        assert len(source.records) == 1\n        assert isinstance(source.records[0], AddressRecord)\n        assert source.records[0].street_name == 'teststreet'\n        assert source.records[0].street_number == '99a'\n        assert source.records[0].zip_code == 4050\n"]]}
{"hexsha": "24e907c82bd6ae35b2a2c5fe4a6a8f9847e18cde", "ext": "py", "lang": "Python", "content": "def part_one(target):\n    \"\"\"Return the answer to part one of this day\n        Expectation is that the answer is in the\n        correct format\"\"\"\n\n    '''presume each spiral is a box, the box has a\n    length and a max digit value which would be the\n    length ** 2 in the bottom right corner'''\n    def box_len(index):\n        return 1 + 2*(index - 1)\n    def box_max(index):\n        return box_len(index) ** 2\n\n    '''find the box which contains our target\n    value by counting upward from 1 and checking\n    if the output is less than the target. If so,\n    then the box we're looking at is not the box\n    containing our target. Halt when greater or\n    equal to the target'''\n    rank_of_box = 1\n    while box_max(rank_of_box) < target:\n        rank_of_box += 1\n\n    '''get the side length of the box\n    containing the target value'''\n    length = box_len(rank_of_box)\n\n    '''take the diff of the target and the max\n    value of the preceeding box, mod by the length\n    of the current box to find the distance from the\n    center'''\n    distance_to_mid = (target - box_max(rank_of_box - 1)) % length\n\n    '''correct for approaching from the left or right of mid'''\n    if distance_to_mid > (length - 1) / 2:\n        distance_to_mid -= int((length - 1) / 2)\n\n    return distance_to_mid + rank_of_box", "fn_id": 2, "class_fn": false, "repo": "stenbein/AdventOfCode", "file": "2017/day03/main.py", "last_update_at": "2018-12-06T02:37:23+00:00", "question_id": "24e907c82bd6ae35b2a2c5fe4a6a8f9847e18cde_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def part_one(target):\n    \"\"\"Return the answer to part one of this day\n        Expectation is that the answer is in the\n        correct format\"\"\"\n    'presume each spiral is a box, the box has a\\n    length and a max digit value which would be the\\n    length ** 2 in the bottom right corner'\n\n    def box_len(index):\n        return 1 + 2 * (index - 1)\n\n    def box_max(index):\n        return box_len(index) ** 2\n    \"find the box which contains our target\\n    value by counting upward from 1 and checking\\n    if the output is less than the target. If so,\\n    then the box we're looking at is not the box\\n    containing our target. Halt when greater or\\n    equal to the target\"\n    rank_of_box = 1\n    while box_max(rank_of_box) < target:\n        rank_of_box += 1\n    'get the side length of the box\\n    containing the target value'\n    length = box_len(rank_of_box)\n    'take the diff of the target and the max\\n    value of the preceeding box, mod by the length\\n    of the current box to find the distance from the\\n    center'\n    distance_to_mid = (target - box_max(rank_of_box - 1)) % length\n    'correct for approaching from the left or right of mid'\n    if distance_to_mid > (length - 1) / 2:\n        distance_to_mid -= int((length - 1) / 2)\n"]]}
{"hexsha": "fef2ede203995b63901f96d6524c945990ee8ba9", "ext": "py", "lang": "Python", "content": "def count(s):\n    moves=1\n    a=s[0]\n    b=0\n    while(b!=s[2]and s[2]!=a):\n        po=min(s[1]-b,a)\n        b+=po\n        a-=po\n        moves+=1\n        if(a==[s2] or b==s[2]):break\n        if(b==s[1]):\n            moves+=1\n            b=0\n        elif a==0:\n            moves+=1\n            a=s[0]\n    return moves", "fn_id": 0, "class_fn": false, "repo": "wasi0013/Python-CodeBase", "file": "ACM-Solution/POUR.py", "last_update_at": "2018-07-18T10:16:42+00:00", "question_id": "fef2ede203995b63901f96d6524c945990ee8ba9_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def count(s):\n    moves = 1\n    a = s[0]\n    b = 0\n    while b != s[2] and s[2] != a:\n        po = min(s[1] - b, a)\n        b += po\n        a -= po\n        moves += 1\n        if a == [s2] or b == s[2]:\n            break\n        if b == s[1]:\n            moves += 1\n            b = 0\n        elif a == 0:\n            moves += 1\n            a = s[0]\n"]]}
{"hexsha": "cde243e8eb7a9479473ffccc06e6d83a5603d6a2", "ext": "py", "lang": "Python", "content": "def get_dividend(url):\n    html_doc = requests.get(url)\n    soup = BeautifulSoup(html_doc.text, 'html.parser')\n    table = soup.find('table', {'id': 'divCapGainsTable'})\n    thead = [\n        'distribution-type',\n        'distribution',\n        'record-date',\n        'ex-dividend-date',\n        'payable-date',\n        'distribution-yield',\n        'sec-yield'\n    ]\n\n    ex_dividend_list = []\n\n    for tr in table.find_all('tr')[1:]:\n        ex_dividend_dict = {}\n        for index, td in enumerate(tr.find_all('td')):\n            ex_dividend_dict[thead[index]] = td.text\n        ex_dividend_list.append(ex_dividend_dict)\n\n    for record in ex_dividend_list:\n        if record['ex-dividend-date'] == today:\n            message = textwrap.dedent(\"\"\"\\\n            <table border=\"0\" style=\"font-family: Verdana\">\n                <tr>\n                    <td>\n                        <h3>Today is {} Ex-Dividend Date</h3>\n                    </td>\n                </tr>\n                <tr>\n                    <td>\n                        <ul>\n                            <li>Type: {}</li>\n                            <li>Distribution: {}</li>\n                            <li>Payable Date: {}</li>\n                        </ul>\n                    </td>\n                </tr>\n            </table>\n            \"\"\".format(\n                symbol,\n                record['distribution-type'],\n                record['distribution'],\n                record['payable-date'])\n            )\n            send_email(message)", "fn_id": 0, "class_fn": false, "repo": "tsoliangwu0130/ex-dividend-date-notification", "file": "app.py", "last_update_at": "2018-03-13T15:05:52+00:00", "question_id": "cde243e8eb7a9479473ffccc06e6d83a5603d6a2_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_dividend(url):\n    html_doc = requests.get(url)\n    soup = BeautifulSoup(html_doc.text, 'html.parser')\n    table = soup.find('table', {'id': 'divCapGainsTable'})\n    thead = ['distribution-type', 'distribution', 'record-date', 'ex-dividend-date', 'payable-date', 'distribution-yield', 'sec-yield']\n    ex_dividend_list = []\n    for tr in table.find_all('tr')[1:]:\n        ex_dividend_dict = {}\n        for index, td in enumerate(tr.find_all('td')):\n            ex_dividend_dict[thead[index]] = td.text\n        ex_dividend_list.append(ex_dividend_dict)\n    for record in ex_dividend_list:\n        if record['ex-dividend-date'] == today:\n            message = textwrap.dedent('            <table border=\"0\" style=\"font-family: Verdana\">\\n                <tr>\\n                    <td>\\n                        <h3>Today is {} Ex-Dividend Date</h3>\\n                    </td>\\n                </tr>\\n                <tr>\\n                    <td>\\n                        <ul>\\n                            <li>Type: {}</li>\\n                            <li>Distribution: {}</li>\\n                            <li>Payable Date: {}</li>\\n                        </ul>\\n                    </td>\\n                </tr>\\n            </table>\\n            '.format(symbol, record['distribution-type'], record['distribution'], record['payable-date']))\n"]]}
{"hexsha": "4f0a291cfbfe239a46d45fb7bffcee4e0979aaea", "ext": "py", "lang": "Python", "content": "def prep_H(conn):\n    q = Qubit(conn)\n    q.H()\n    return q", "fn_id": 5, "class_fn": false, "repo": "WrathfulSpatula/SimulaQron", "file": "tests/slow/sdk/test_single_qubit.py", "last_update_at": "2018-07-31T19:02:19+00:00", "question_id": "4f0a291cfbfe239a46d45fb7bffcee4e0979aaea_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def prep_H(conn):\n    q = Qubit(conn)\n    q.H()\n"]]}
{"hexsha": "5d465ffbed86fda15f5be978f767e4c9543847ba", "ext": "py", "lang": "Python", "content": "def test_location_event():\n    message = parse_user_msg(\"\"\"\n    <xml>\n        <ToUserName><![CDATA[toUser]]></ToUserName>\n        <FromUserName><![CDATA[fromUser]]></FromUserName>\n        <CreateTime>123456789</CreateTime>\n        <MsgType><![CDATA[event]]></MsgType>\n        <Event><![CDATA[LOCATION]]></Event>\n        <Latitude>23.137466</Latitude>\n        <Longitude>113.352425</Longitude>\n        <Precision>119.385040</Precision>\n    </xml>\n    \"\"\")\n    assert message.target == \"toUser\"\n    assert message.source == \"fromUser\"\n    assert message.time == 123456789\n    assert message.type == \"location_event\"\n    assert message.latitude == 23.137466\n    assert message.longitude == 113.352425\n    assert message.precision == 119.385040", "fn_id": 30, "class_fn": false, "repo": "lilac/WeRobot", "file": "tests/test_parser.py", "last_update_at": "2018-06-03T16:32:10+00:00", "question_id": "5d465ffbed86fda15f5be978f767e4c9543847ba_30", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_location_event():\n    message = parse_user_msg('\\n    <xml>\\n        <ToUserName><![CDATA[toUser]]></ToUserName>\\n        <FromUserName><![CDATA[fromUser]]></FromUserName>\\n        <CreateTime>123456789</CreateTime>\\n        <MsgType><![CDATA[event]]></MsgType>\\n        <Event><![CDATA[LOCATION]]></Event>\\n        <Latitude>23.137466</Latitude>\\n        <Longitude>113.352425</Longitude>\\n        <Precision>119.385040</Precision>\\n    </xml>\\n    ')\n    assert message.target == 'toUser'\n    assert message.source == 'fromUser'\n    assert message.time == 123456789\n    assert message.type == 'location_event'\n    assert message.latitude == 23.137466\n    assert message.longitude == 113.352425\n"]]}
{"hexsha": "3b096e61336f791b46468ea40a30af4348efd0c3", "ext": "py", "lang": "Python", "content": "def graph_from_sif (filename, force_undirected = False):\n\t\"\"\" Import a Cytoscape SIF-formatted graph as a NetworkX directed graph (DiGraph object)\n\n\t\targuments:\n\t\t\tfilename (mandatory) - name of a SIF-formatted file\n\t\t\tforce_undirected (optional; default: False) - if True, will return\n\t\t\t\tan undirected (Graph object) rather than a directed graph (DiGraph object)\n\n\t\tSee http://wiki.cytoscape.org/Cytoscape_User_Manual/Network_Formats\n\t\"\"\"\n\tg = networkx.DiGraph()\n\tfh = open(filename, \"rU\")\n\n\twhile True:\n\t\tline = fh.readline()\n\t\tif (line == ''):\n\t\t\tbreak\n\n\t\tline = line.strip()\n\t\tif (line == ''):\n\t\t\tcontinue\n\n\t\t# according to the SIF format documentation, a tab character present in a line\n\t\t# means the elements of this line must be separated with a tab, and not spaces\n\t\tif ('\\t' in line):\n\t\t\telements = line.split('\\t')\n\t\telse:\n\t\t\telements = line.split(' ')\n\n\t\tif (len(elements) != 3):\n\t\t\traise ValueError(\"invalid line '%s'\" % line)\n\n\t\tnode_a, edge_type, node_b = elements\n\t\tg.add_edge(node_a, node_b, type = edge_type)\n\n\tif (force_undirected):\n\t\treturn g.to_undirected()\n\telse:\n\t\treturn g", "fn_id": 0, "class_fn": false, "repo": "ajmazurie/biofabric", "file": "lib/biofabric/utils.py", "last_update_at": "2018-11-01T21:02:29+00:00", "question_id": "3b096e61336f791b46468ea40a30af4348efd0c3_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def graph_from_sif(filename, force_undirected=False):\n    \"\"\" Import a Cytoscape SIF-formatted graph as a NetworkX directed graph (DiGraph object)\n\n\t\targuments:\n\t\t\tfilename (mandatory) - name of a SIF-formatted file\n\t\t\tforce_undirected (optional; default: False) - if True, will return\n\t\t\t\tan undirected (Graph object) rather than a directed graph (DiGraph object)\n\n\t\tSee http://wiki.cytoscape.org/Cytoscape_User_Manual/Network_Formats\n\t\"\"\"\n    g = networkx.DiGraph()\n    fh = open(filename, 'rU')\n    while True:\n        line = fh.readline()\n        if line == '':\n            break\n        line = line.strip()\n        if line == '':\n            continue\n        if '\\t' in line:\n            elements = line.split('\\t')\n        else:\n            elements = line.split(' ')\n        if len(elements) != 3:\n            raise ValueError(\"invalid line '%s'\" % line)\n        node_a, edge_type, node_b = elements\n        g.add_edge(node_a, node_b, type=edge_type)\n    if force_undirected:\n        return g.to_undirected()\n    else:\n"]]}
{"hexsha": "538eedad8191a365da10e9b7023b9960d180637a", "ext": "py", "lang": "Python", "content": "def __update_template_path():\n    # Sometimes, when caching templates bottle doesn't clear the faulty\n    # templates and the error persists even upon restarting the app.\n    # The solution is to clear the templates explicitly with this statement:\n    TEMPLATES.clear()\n\n    for m in registered_methods:\n        method_path = unicode('./{0}/{1}/'.format(config.FP_SUBDIR, m.subdir))\n        if method_path not in TEMPLATE_PATH:\n            TEMPLATE_PATH.insert(0, method_path)\n\n    logger.info('updated TEMPLATE_PATH')", "fn_id": 3, "class_fn": false, "repo": "vanja/browserentropy", "file": "resources.py", "last_update_at": "2018-03-05T12:53:57+00:00", "question_id": "538eedad8191a365da10e9b7023b9960d180637a_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def __update_template_path():\n    TEMPLATES.clear()\n    for m in registered_methods:\n        method_path = unicode('./{0}/{1}/'.format(config.FP_SUBDIR, m.subdir))\n        if method_path not in TEMPLATE_PATH:\n            TEMPLATE_PATH.insert(0, method_path)\n"]]}
{"hexsha": "983d53cab55783ca6f9037de1063a9f3a9151399", "ext": "py", "lang": "Python", "content": "def server_stats_restarts():\n    cur.execute(\"SELECT restarts FROM server_stats;\")\n    sqlresult = cur.fetchone()\n    return str(sqlresult[0])", "fn_id": 44, "class_fn": false, "repo": "AudioVisuaali/audiobot", "file": "mysqlfiles/mysqlfiles.py", "last_update_at": "2018-02-01T21:06:56+00:00", "question_id": "983d53cab55783ca6f9037de1063a9f3a9151399_44", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def server_stats_restarts():\n    cur.execute('SELECT restarts FROM server_stats;')\n    sqlresult = cur.fetchone()\n"]]}
{"hexsha": "0bf992a42d350a6bdf5fe8e1f0e2fc0b740a73e3", "ext": "py", "lang": "Python", "content": "def distanz(id1, id2):\n    x1, y1 = hole_koord(id1)\n    x2, y2 = hole_koord(id2)\n    return sqrt((x2 -x1) ** 2 + (y2 - y1) ** 2)", "fn_id": 27, "class_fn": false, "repo": "ClPa/Mario", "file": "MarioBros(1).py", "last_update_at": "2018-06-18T16:11:03+00:00", "question_id": "0bf992a42d350a6bdf5fe8e1f0e2fc0b740a73e3_27", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def distanz(id1, id2):\n    x1, y1 = hole_koord(id1)\n    x2, y2 = hole_koord(id2)\n"]]}
{"hexsha": "14e94fa93cb2b7733c73bd1992a949013297b9d3", "ext": "py", "lang": "Python", "content": "def test_set_positive_charges():\n    mol = Chem.RWMol()\n    mol.AddAtom(Chem.Atom('O'))\n    mol.AddAtom(Chem.Atom('H'))\n    mol.AddAtom(Chem.Atom('H'))\n    mol.AddAtom(Chem.Atom('H'))\n\n    mol.AddBond(0, 1, Chem.BondType.SINGLE)\n    mol.AddBond(0, 2, Chem.BondType.SINGLE)\n    mol.AddBond(0, 3, Chem.BondType.SINGLE)\n\n    for atom in mol.GetAtoms():\n        atom.SetNoImplicit(True)\n\n    set_positive_charges(mol)\n\n    assert mol.GetAtomWithIdx(0).GetFormalCharge() == 1,\\\n        \"Oxygen must have a positive charge.\"\n    return", "fn_id": 3, "class_fn": false, "repo": "ldgibson/mdreactions", "file": "mdstates/tests/test_molecules.py", "last_update_at": "2018-03-23T19:55:02+00:00", "question_id": "14e94fa93cb2b7733c73bd1992a949013297b9d3_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_set_positive_charges():\n    mol = Chem.RWMol()\n    mol.AddAtom(Chem.Atom('O'))\n    mol.AddAtom(Chem.Atom('H'))\n    mol.AddAtom(Chem.Atom('H'))\n    mol.AddAtom(Chem.Atom('H'))\n    mol.AddBond(0, 1, Chem.BondType.SINGLE)\n    mol.AddBond(0, 2, Chem.BondType.SINGLE)\n    mol.AddBond(0, 3, Chem.BondType.SINGLE)\n    for atom in mol.GetAtoms():\n        atom.SetNoImplicit(True)\n    set_positive_charges(mol)\n    assert mol.GetAtomWithIdx(0).GetFormalCharge() == 1, 'Oxygen must have a positive charge.'\n"]]}
{"hexsha": "426f8b7ee439ef81a41d42973ec077ef34881137", "ext": "py", "lang": "Python", "content": "def get_class(class_name):\n    \"\"\"\n    Returns the class corresponding to a string\n    :param class_name: the given string pointing to the class from the working directory\n    :return: the class as an object\n    \"\"\"\n    parts = class_name.split('.')\n    class_module = \".\".join(parts[:-1])\n    m = __import__(class_module)\n    for comp in parts[1:]:\n        m = getattr(m, comp)\n    return m", "fn_id": 10, "class_fn": false, "repo": "Xaxetrov/OSCAR", "file": "oscar/hiearchy_factory.py", "last_update_at": "2018-06-11T09:23:03+00:00", "question_id": "426f8b7ee439ef81a41d42973ec077ef34881137_10", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_class(class_name):\n    \"\"\"\n    Returns the class corresponding to a string\n    :param class_name: the given string pointing to the class from the working directory\n    :return: the class as an object\n    \"\"\"\n    parts = class_name.split('.')\n    class_module = '.'.join(parts[:-1])\n    m = __import__(class_module)\n    for comp in parts[1:]:\n        m = getattr(m, comp)\n"]]}
{"hexsha": "a1dbe188d4233759a02c189d1a6e59e0d05a4336", "ext": "py", "lang": "Python", "content": "@magicWord(category=CATEGORY_ADMINISTRATOR, types=[str, str, int])\ndef accessLevel(accessLevel, storage='PERSISTENT', showGM=1):\n    \"\"\"\n    Modify the target's access level.\n    \"\"\"\n    accessName2Id = {\n        'user': CATEGORY_USER.defaultAccess,\n        'u': CATEGORY_USER.defaultAccess,\n        'communitymanager': CATEGORY_COMMUNITY_MANAGER.defaultAccess,\n        'community': CATEGORY_COMMUNITY_MANAGER.defaultAccess,\n        'c': CATEGORY_COMMUNITY_MANAGER.defaultAccess,\n        'moderator': CATEGORY_MODERATOR.defaultAccess,\n        'mod': CATEGORY_MODERATOR.defaultAccess,\n        'm': CATEGORY_MODERATOR.defaultAccess,\n        'creative': CATEGORY_CREATIVE.defaultAccess,\n        'creativity': CATEGORY_CREATIVE.defaultAccess,\n        'c': CATEGORY_CREATIVE.defaultAccess,\n        'programmer': CATEGORY_PROGRAMMER.defaultAccess,\n        'coder': CATEGORY_PROGRAMMER.defaultAccess,\n        'p': CATEGORY_PROGRAMMER.defaultAccess,\n        'administrator': CATEGORY_ADMINISTRATOR.defaultAccess,\n        'admin': CATEGORY_ADMINISTRATOR.defaultAccess,\n        'a': CATEGORY_ADMINISTRATOR.defaultAccess,\n        'systemadministrator': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess,\n        'systemadmin': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess,\n        'sysadministrator': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess,\n        'sysadmin': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess,\n        'system': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess,\n        'sys': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess,\n        's': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess\n    }\n    try:\n        accessLevel = int(accessLevel)\n    except:\n        if accessLevel not in accessName2Id:\n            return 'Invalid access level!'\n        accessLevel = accessName2Id[accessLevel]\n    if accessLevel not in accessName2Id.values():\n        return 'Invalid access level!'\n    target = spellbook.getTarget()\n    invoker = spellbook.getInvoker()\n    if invoker == target:\n        return \"You can't set your own access level!\"\n    if not accessLevel < invoker.getAdminAccess():\n        return \"The target's access level must be lower than yours!\"\n    if target.getAdminAccess() == accessLevel:\n        return \"%s's access level is already %d!\" % (target.getName(), accessLevel)\n    target.b_setAdminAccess(accessLevel)\n    if showGM:\n        target.b_setGM(accessLevel)\n    temporary = storage.upper() in ('SESSION', 'TEMP', 'TEMPORARY')\n    if not temporary:\n        target.air.dbInterface.updateObject(\n            target.air.dbId,\n            target.getDISLid(),\n            target.air.dclassesByName['AccountAI'],\n            {'ADMIN_ACCESS': accessLevel})\n    if not temporary:\n        target.d_setSystemMessage(0, '%s set your access level to %d!' % (invoker.getName(), accessLevel))\n        return \"%s's access level has been set to %d.\" % (target.getName(), accessLevel)\n    else:\n        target.d_setSystemMessage(0, '%s set your access level to %d temporarily!' % (invoker.getName(), accessLevel))\n        return \"%s's access level has been set to %d temporarily.\" % (target.getName(), accessLevel)", "fn_id": 3, "class_fn": false, "repo": "LittleNed/toontown-stride", "file": "otp/avatar/DistributedPlayerAI.py", "last_update_at": "2018-06-16T23:06:38+00:00", "question_id": "a1dbe188d4233759a02c189d1a6e59e0d05a4336_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@magicWord(category=CATEGORY_ADMINISTRATOR, types=[str, str, int])\ndef accessLevel(accessLevel, storage='PERSISTENT', showGM=1):\n    \"\"\"\n    Modify the target's access level.\n    \"\"\"\n    accessName2Id = {'user': CATEGORY_USER.defaultAccess, 'u': CATEGORY_USER.defaultAccess, 'communitymanager': CATEGORY_COMMUNITY_MANAGER.defaultAccess, 'community': CATEGORY_COMMUNITY_MANAGER.defaultAccess, 'c': CATEGORY_COMMUNITY_MANAGER.defaultAccess, 'moderator': CATEGORY_MODERATOR.defaultAccess, 'mod': CATEGORY_MODERATOR.defaultAccess, 'm': CATEGORY_MODERATOR.defaultAccess, 'creative': CATEGORY_CREATIVE.defaultAccess, 'creativity': CATEGORY_CREATIVE.defaultAccess, 'c': CATEGORY_CREATIVE.defaultAccess, 'programmer': CATEGORY_PROGRAMMER.defaultAccess, 'coder': CATEGORY_PROGRAMMER.defaultAccess, 'p': CATEGORY_PROGRAMMER.defaultAccess, 'administrator': CATEGORY_ADMINISTRATOR.defaultAccess, 'admin': CATEGORY_ADMINISTRATOR.defaultAccess, 'a': CATEGORY_ADMINISTRATOR.defaultAccess, 'systemadministrator': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess, 'systemadmin': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess, 'sysadministrator': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess, 'sysadmin': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess, 'system': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess, 'sys': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess, 's': CATEGORY_SYSTEM_ADMINISTRATOR.defaultAccess}\n    try:\n        accessLevel = int(accessLevel)\n    except:\n        if accessLevel not in accessName2Id:\n            return 'Invalid access level!'\n        accessLevel = accessName2Id[accessLevel]\n    if accessLevel not in accessName2Id.values():\n        return 'Invalid access level!'\n    target = spellbook.getTarget()\n    invoker = spellbook.getInvoker()\n    if invoker == target:\n        return \"You can't set your own access level!\"\n    if not accessLevel < invoker.getAdminAccess():\n        return \"The target's access level must be lower than yours!\"\n    if target.getAdminAccess() == accessLevel:\n        return \"%s's access level is already %d!\" % (target.getName(), accessLevel)\n    target.b_setAdminAccess(accessLevel)\n    if showGM:\n        target.b_setGM(accessLevel)\n    temporary = storage.upper() in ('SESSION', 'TEMP', 'TEMPORARY')\n    if not temporary:\n        target.air.dbInterface.updateObject(target.air.dbId, target.getDISLid(), target.air.dclassesByName['AccountAI'], {'ADMIN_ACCESS': accessLevel})\n    if not temporary:\n        target.d_setSystemMessage(0, '%s set your access level to %d!' % (invoker.getName(), accessLevel))\n        return \"%s's access level has been set to %d.\" % (target.getName(), accessLevel)\n    else:\n        target.d_setSystemMessage(0, '%s set your access level to %d temporarily!' % (invoker.getName(), accessLevel))\n"]]}
{"hexsha": "78e91249c82c500bcea7e9536046e7cb366ad21f", "ext": "py", "lang": "Python", "content": "def VonMises_dQ (Y, sigm, dsbar, theta):\n    dQ_dsigm = 0.0\n    dQ_dJ2 = 1.5/dsbar\n    dQ_dJ3 = 0.0\n    return (dQ_dsigm, dQ_dJ2, dQ_dJ3)", "fn_id": 12, "class_fn": false, "repo": "Numerics88/n88tools", "file": "n88tools/finiteelement.py", "last_update_at": "2018-01-29T03:27:52+00:00", "question_id": "78e91249c82c500bcea7e9536046e7cb366ad21f_12", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def VonMises_dQ(Y, sigm, dsbar, theta):\n    dQ_dsigm = 0.0\n    dQ_dJ2 = 1.5 / dsbar\n    dQ_dJ3 = 0.0\n"]]}
{"hexsha": "a874b8b7c27634c424254598b209bd69c6360f31", "ext": "py", "lang": "Python", "content": "def dset_to_binary_file(data_set, out_file, chan_list=None, chunk_size=8000000):\n    \"\"\"\n    :param data_set: a table from an h5 file to write to a binary. has to be daughter of a rec\n    :param out_file: binary file - has to be open in 'w' mode.\n    :param chan_list: list of channels (must be list or tuple). Default (None) will do the whole table\n    :param chunk_size: size in samples of the chunk\n    :return:\n    \"\"\"\n    samples_data = data_set.shape[0]\n    channels_data = data_set.shape[1]\n    data_type = data_set.dtype\n    logging.info('Ripping dataset from {}'.format(data_set.parent.name))\n    if chan_list is None:\n        logging.debug('Counting channels')\n        chan_list = range(channels_data)\n    logging.info('Channel list: {}'.format(chan_list))\n\n    samples_chunk = min(chunk_size, samples_data)\n    channels_chunk = len(chan_list)\n\n    chunk_buffer = np.empty((samples_chunk, channels_chunk), dtype=np.dtype(data_type))\n    chunk_starts = np.arange(0, samples_data, samples_chunk)\n    n_chunks = chunk_starts.size\n\n    logging.info('About to store {} entire chunks'.format(n_chunks - 1))\n    for start in chunk_starts:\n        logging.info('Chunk start: {0}'.format(start))\n        end = min(start + samples_chunk, samples_data)\n        chunk_buffer[0: end - start, :] = load_table_slice(data_set,\n                                                           np.arange(start, end),\n                                                           chan_list)\n        out_file.write(chunk_buffer[0: end - start].astype(np.dtype(data_type)).tostring())\n\n    stored = n_chunks * chunk_buffer.size + chunk_buffer[0: end - start, :].size\n    logging.info('{} elements written'.format(stored))\n    return stored", "fn_id": 4, "class_fn": false, "repo": "gentnerlab/klusta-pipeline", "file": "klusta_pipeline/h5_util.py", "last_update_at": "2018-08-21T16:17:13+00:00", "question_id": "a874b8b7c27634c424254598b209bd69c6360f31_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def dset_to_binary_file(data_set, out_file, chan_list=None, chunk_size=8000000):\n    \"\"\"\n    :param data_set: a table from an h5 file to write to a binary. has to be daughter of a rec\n    :param out_file: binary file - has to be open in 'w' mode.\n    :param chan_list: list of channels (must be list or tuple). Default (None) will do the whole table\n    :param chunk_size: size in samples of the chunk\n    :return:\n    \"\"\"\n    samples_data = data_set.shape[0]\n    channels_data = data_set.shape[1]\n    data_type = data_set.dtype\n    logging.info('Ripping dataset from {}'.format(data_set.parent.name))\n    if chan_list is None:\n        logging.debug('Counting channels')\n        chan_list = range(channels_data)\n    logging.info('Channel list: {}'.format(chan_list))\n    samples_chunk = min(chunk_size, samples_data)\n    channels_chunk = len(chan_list)\n    chunk_buffer = np.empty((samples_chunk, channels_chunk), dtype=np.dtype(data_type))\n    chunk_starts = np.arange(0, samples_data, samples_chunk)\n    n_chunks = chunk_starts.size\n    logging.info('About to store {} entire chunks'.format(n_chunks - 1))\n    for start in chunk_starts:\n        logging.info('Chunk start: {0}'.format(start))\n        end = min(start + samples_chunk, samples_data)\n        chunk_buffer[0:end - start, :] = load_table_slice(data_set, np.arange(start, end), chan_list)\n        out_file.write(chunk_buffer[0:end - start].astype(np.dtype(data_type)).tostring())\n    stored = n_chunks * chunk_buffer.size + chunk_buffer[0:end - start, :].size\n    logging.info('{} elements written'.format(stored))\n"]]}
{"hexsha": "7b1dbade1c2965786e5ac5e4ee395dfa28cd7ce9", "ext": "py", "lang": "Python", "content": "def plot_ensembl_logo(self, fname=None, ic=True, title=True, letters=True, height=2):\n    \"\"\"Plot motif logo.\n\n    This is an implementation of the logo presented here:\n    http://www.ensembl.info/2018/10/15/new-ensembl-motif-features/\n\n    Parameters\n    ----------\n    fname : str, optional\n        If fname is set, the plot will be saved with fname as filename.\n    ic : bool, optional\n        Use the bit score. If this is set to False, the frequency\n        will be used.\n    title : bool, optional\n        Plot the motif id as the title.\n    letters : bool, optional\n        Plot the nucleotides in the bars.\n    height : float, optional\n        Height of the plot.\n    \"\"\"\n    width = 0.94\n\n    ppm = self.ppm\n    nucs = np.array([\"A\", \"C\", \"G\", \"T\"])\n\n    neg_matrix = np.zeros((len(ppm), 4))\n\n    pos_matrix = []\n    nuc_ppm = []\n    for row in ppm:\n        if ic:\n            ylabel = \"bits\"\n            ic_row = []\n            y_max = 2\n            for p in row:\n                if p < 0.25:\n                    ic_row.append(0)\n                else:\n                    ic_row.append(p * np.log2((p) / 0.25))\n\n        else:\n            ic_row = row\n            ylabel = \"frequency\"\n            y_max = 1\n        idx = np.argsort(ic_row)\n        pos_matrix.append(np.array(ic_row)[idx])\n        nuc_ppm.append(nucs[idx])\n\n    colors = {\n        \"A\": (0.308, 0.709, 0.280),\n        \"C\": (0.145, 0.362, 0.6),\n        \"G\": (0.969, 0.702, 0.172),\n        \"T\": (0.841, 0.158, 0.224),\n    }\n\n    # x_max = np.max([np.sum(row) for row in pos_matrix])\n    # x_min = -np.min([np.sum(row) for row in neg_matrix])\n    # neg_matrix = neg_matrix / x_min * x_max\n\n    plt.figure(figsize=(len(ppm) * 0.3, height))\n    for (sign, matrix) in [(1, pos_matrix), (-1, neg_matrix)]:\n        minbottom = np.zeros(len(matrix))\n        alpha = 1\n        if sign == -1:\n            minbottom = np.array([np.sum(row) for row in matrix])\n            alpha = 0.5\n\n        # Print the bars\n        for i in range(0, len(ppm[0])):\n\n            pheight = [abs(r[i]) for r in matrix]\n            bottom = minbottom + [sum(np.abs(r[:i])) for r in matrix]\n\n            c = [colors[r[i]] for r in nuc_ppm]\n            plt.bar(\n                range(1, len(ppm) + 1),\n                width=width,\n                height=pheight,\n                bottom=bottom,\n                color=c,\n                alpha=alpha,\n            )\n\n        if letters:\n            # Print the letters\n            for i in range(len(ppm)):\n                for n in range(4):\n                    x = i + 1\n                    y = matrix[i][n] / 2 + sum(matrix[i][:n])\n                    nuc = nuc_ppm[i][n]\n                    c = \"white\"\n                    if abs(matrix[i][n]) * height >= 0.5:\n                        plt.text(\n                            x,\n                            y,\n                            nuc,\n                            horizontalalignment=\"center\",\n                            verticalalignment=\"center\",\n                            fontsize=8 + 10 * (matrix[i][n] / y_max),\n                            color=c,\n                        )\n\n    # Remove axis lines\n    ax = plt.gca()\n    for spine in ax.spines.values():\n        spine.set_color(\"none\")\n\n    if title:\n        plt.title(self.id)\n    plt.xlim(0.47, len(self) + 0.5)\n    plt.xticks(range(1, len(ppm) + 1))\n    plt.ylabel(ylabel)\n\n    if fname:\n        plt.savefig(fname, dpi=300)\n        plt.close()\n    else:\n        return ax", "fn_id": 1, "class_fn": false, "repo": "simonvh/gimmemotifs", "file": "gimmemotifs/motif/_plotting.py", "last_update_at": "2018-07-24T15:41:58+00:00", "question_id": "7b1dbade1c2965786e5ac5e4ee395dfa28cd7ce9_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def plot_ensembl_logo(self, fname=None, ic=True, title=True, letters=True, height=2):\n    \"\"\"Plot motif logo.\n\n    This is an implementation of the logo presented here:\n    http://www.ensembl.info/2018/10/15/new-ensembl-motif-features/\n\n    Parameters\n    ----------\n    fname : str, optional\n        If fname is set, the plot will be saved with fname as filename.\n    ic : bool, optional\n        Use the bit score. If this is set to False, the frequency\n        will be used.\n    title : bool, optional\n        Plot the motif id as the title.\n    letters : bool, optional\n        Plot the nucleotides in the bars.\n    height : float, optional\n        Height of the plot.\n    \"\"\"\n    width = 0.94\n    ppm = self.ppm\n    nucs = np.array(['A', 'C', 'G', 'T'])\n    neg_matrix = np.zeros((len(ppm), 4))\n    pos_matrix = []\n    nuc_ppm = []\n    for row in ppm:\n        if ic:\n            ylabel = 'bits'\n            ic_row = []\n            y_max = 2\n            for p in row:\n                if p < 0.25:\n                    ic_row.append(0)\n                else:\n                    ic_row.append(p * np.log2(p / 0.25))\n        else:\n            ic_row = row\n            ylabel = 'frequency'\n            y_max = 1\n        idx = np.argsort(ic_row)\n        pos_matrix.append(np.array(ic_row)[idx])\n        nuc_ppm.append(nucs[idx])\n    colors = {'A': (0.308, 0.709, 0.28), 'C': (0.145, 0.362, 0.6), 'G': (0.969, 0.702, 0.172), 'T': (0.841, 0.158, 0.224)}\n    plt.figure(figsize=(len(ppm) * 0.3, height))\n    for sign, matrix in [(1, pos_matrix), (-1, neg_matrix)]:\n        minbottom = np.zeros(len(matrix))\n        alpha = 1\n        if sign == -1:\n            minbottom = np.array([np.sum(row) for row in matrix])\n            alpha = 0.5\n        for i in range(0, len(ppm[0])):\n            pheight = [abs(r[i]) for r in matrix]\n            bottom = minbottom + [sum(np.abs(r[:i])) for r in matrix]\n            c = [colors[r[i]] for r in nuc_ppm]\n            plt.bar(range(1, len(ppm) + 1), width=width, height=pheight, bottom=bottom, color=c, alpha=alpha)\n        if letters:\n            for i in range(len(ppm)):\n                for n in range(4):\n                    x = i + 1\n                    y = matrix[i][n] / 2 + sum(matrix[i][:n])\n                    nuc = nuc_ppm[i][n]\n                    c = 'white'\n                    if abs(matrix[i][n]) * height >= 0.5:\n                        plt.text(x, y, nuc, horizontalalignment='center', verticalalignment='center', fontsize=8 + 10 * (matrix[i][n] / y_max), color=c)\n    ax = plt.gca()\n    for spine in ax.spines.values():\n        spine.set_color('none')\n    if title:\n        plt.title(self.id)\n    plt.xlim(0.47, len(self) + 0.5)\n    plt.xticks(range(1, len(ppm) + 1))\n    plt.ylabel(ylabel)\n    if fname:\n        plt.savefig(fname, dpi=300)\n        plt.close()\n    else:\n"]]}
{"hexsha": "0d2bf0fdee0f33905ae357656cd830d99f221b96", "ext": "py", "lang": "Python", "content": "def calc_graph(analysis_fields, data_frame, substation_plot_flag):\n    # calculate graph\n    graph = []\n    # format demand values\n    data = data_frame[0].fillna(value=0)\n    data = pd.DataFrame(data.sum(axis=0), columns=[analysis_fields[0]])\n    if not substation_plot_flag:\n        data1 = data_frame[1].fillna(value=0)\n        data1 = pd.DataFrame(data1.sum(axis=0), columns=[analysis_fields[1]])\n        # calculate total\n        total = pd.DataFrame(data.values + data1.values, index=data1.index, columns=['total'])\n        # join dataframes\n        data = data.join(data1)\n        data_frame = data.join(total)\n        data_frame = data_frame.sort_values(by='total', ascending=False)  # this will get the maximum value to the left\n    else:\n        data_frame = data.sort_values(by=analysis_fields[0], ascending=False)\n    # iterate through data to plot\n    for field in analysis_fields:\n        if not substation_plot_flag:\n            total_perc = (data_frame[field].values.reshape(1, len(total.index)) / data_frame['total'].values.reshape(1, len(\n                total.index)) * 100).round(2)[0]\n            total_perc_txt = [\"(\" + str(x) + \" %)\" for x in total_perc]\n            trace = go.Bar(x=data_frame.index, y=data_frame[field].values, name=NAMING[field],\n                           text=total_perc_txt,\n                           orientation='v',\n                           marker=dict(color=COLOR[field]))\n        else:\n            trace = go.Bar(x=data_frame.index, y=data_frame[field].values, name=NAMING[field],\n                           orientation='v',\n                           marker=dict(color=COLOR[field]))\n        graph.append(trace)\n\n    return graph", "fn_id": 2, "class_fn": false, "repo": "pajotca/CityEnergyAnalyst", "file": "cea/plots/thermal_networks/energy_loss_bar.py", "last_update_at": "2018-08-16T14:34:23+00:00", "question_id": "0d2bf0fdee0f33905ae357656cd830d99f221b96_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def calc_graph(analysis_fields, data_frame, substation_plot_flag):\n    graph = []\n    data = data_frame[0].fillna(value=0)\n    data = pd.DataFrame(data.sum(axis=0), columns=[analysis_fields[0]])\n    if not substation_plot_flag:\n        data1 = data_frame[1].fillna(value=0)\n        data1 = pd.DataFrame(data1.sum(axis=0), columns=[analysis_fields[1]])\n        total = pd.DataFrame(data.values + data1.values, index=data1.index, columns=['total'])\n        data = data.join(data1)\n        data_frame = data.join(total)\n        data_frame = data_frame.sort_values(by='total', ascending=False)\n    else:\n        data_frame = data.sort_values(by=analysis_fields[0], ascending=False)\n    for field in analysis_fields:\n        if not substation_plot_flag:\n            total_perc = (data_frame[field].values.reshape(1, len(total.index)) / data_frame['total'].values.reshape(1, len(total.index)) * 100).round(2)[0]\n            total_perc_txt = ['(' + str(x) + ' %)' for x in total_perc]\n            trace = go.Bar(x=data_frame.index, y=data_frame[field].values, name=NAMING[field], text=total_perc_txt, orientation='v', marker=dict(color=COLOR[field]))\n        else:\n            trace = go.Bar(x=data_frame.index, y=data_frame[field].values, name=NAMING[field], orientation='v', marker=dict(color=COLOR[field]))\n        graph.append(trace)\n"]]}
{"hexsha": "d87d304d48acdb1ed1538ab797886261c63b61d5", "ext": "py", "lang": "Python", "content": "def psf_iteration_compare(kwargs_psf, **kwargs):\n    \"\"\"\n\n    :param kwargs_psf:\n    :param kwargs: kwargs to send to matplotlib.pyplot.matshow()\n    :return:\n    \"\"\"\n    psf_out = kwargs_psf['kernel_point_source']\n    psf_in = kwargs_psf['kernel_point_source_init']\n    n_kernel = len(psf_in)\n    delta_x = n_kernel/20.\n    delta_y = n_kernel/10.\n\n    if not 'cmap' in kwargs:\n        kwargs['cmap'] = 'seismic'\n\n    f, axes = plt.subplots(1, 3, figsize=(15, 5))\n    ax = axes[0]\n    im = ax.matshow(np.log10(psf_in), origin='lower', **kwargs)\n    v_min, v_max = im.get_clim()\n    if not 'vmin' in kwargs:\n        kwargs['vmin'] = v_min\n    if not 'vmax' in kwargs:\n        kwargs['vmax'] = v_max\n    divider = make_axes_locatable(ax)\n    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n    plt.colorbar(im, cax=cax)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    ax.text(delta_x, n_kernel-delta_y, \"stacked stars\", color=\"k\", fontsize=20, backgroundcolor='w')\n\n    ax = axes[1]\n    im = ax.matshow(np.log10(psf_out), origin='lower', **kwargs)\n    divider = make_axes_locatable(ax)\n    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n    plt.colorbar(im, cax=cax)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    ax.text(delta_x, n_kernel-delta_y, \"iterative reconstruction\", color=\"k\", fontsize=20, backgroundcolor='w')\n\n    ax = axes[2]\n    kwargs_new = copy.deepcopy(kwargs)\n    try:\n        del kwargs_new['vmin']\n        del kwargs_new['vmax']\n    except:\n        pass\n    im = ax.matshow(psf_out-psf_in, origin='lower', vmin=-10**-3, vmax=10**-3, **kwargs_new)\n    divider = make_axes_locatable(ax)\n    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n    plt.colorbar(im, cax=cax)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    ax.text(delta_x, n_kernel-delta_y, \"difference\", color=\"k\", fontsize=20, backgroundcolor='w')\n    f.tight_layout()\n    return f, axes", "fn_id": 10, "class_fn": false, "repo": "guoxiaowhu/lenstronomy", "file": "lenstronomy/Plots/output_plots.py", "last_update_at": "2018-11-08T12:33:26+00:00", "question_id": "d87d304d48acdb1ed1538ab797886261c63b61d5_10", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def psf_iteration_compare(kwargs_psf, **kwargs):\n    \"\"\"\n\n    :param kwargs_psf:\n    :param kwargs: kwargs to send to matplotlib.pyplot.matshow()\n    :return:\n    \"\"\"\n    psf_out = kwargs_psf['kernel_point_source']\n    psf_in = kwargs_psf['kernel_point_source_init']\n    n_kernel = len(psf_in)\n    delta_x = n_kernel / 20.0\n    delta_y = n_kernel / 10.0\n    if not 'cmap' in kwargs:\n        kwargs['cmap'] = 'seismic'\n    f, axes = plt.subplots(1, 3, figsize=(15, 5))\n    ax = axes[0]\n    im = ax.matshow(np.log10(psf_in), origin='lower', **kwargs)\n    v_min, v_max = im.get_clim()\n    if not 'vmin' in kwargs:\n        kwargs['vmin'] = v_min\n    if not 'vmax' in kwargs:\n        kwargs['vmax'] = v_max\n    divider = make_axes_locatable(ax)\n    cax = divider.append_axes('right', size='5%', pad=0.05)\n    plt.colorbar(im, cax=cax)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    ax.text(delta_x, n_kernel - delta_y, 'stacked stars', color='k', fontsize=20, backgroundcolor='w')\n    ax = axes[1]\n    im = ax.matshow(np.log10(psf_out), origin='lower', **kwargs)\n    divider = make_axes_locatable(ax)\n    cax = divider.append_axes('right', size='5%', pad=0.05)\n    plt.colorbar(im, cax=cax)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    ax.text(delta_x, n_kernel - delta_y, 'iterative reconstruction', color='k', fontsize=20, backgroundcolor='w')\n    ax = axes[2]\n    kwargs_new = copy.deepcopy(kwargs)\n    try:\n        del kwargs_new['vmin']\n        del kwargs_new['vmax']\n    except:\n        pass\n    im = ax.matshow(psf_out - psf_in, origin='lower', vmin=-10 ** (-3), vmax=10 ** (-3), **kwargs_new)\n    divider = make_axes_locatable(ax)\n    cax = divider.append_axes('right', size='5%', pad=0.05)\n    plt.colorbar(im, cax=cax)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    ax.text(delta_x, n_kernel - delta_y, 'difference', color='k', fontsize=20, backgroundcolor='w')\n    f.tight_layout()\n"]]}
{"hexsha": "db1870fa35799b9026517c24a66b55fd6be52186", "ext": "py", "lang": "Python", "content": "def test_test_simple_passed(runner):\n    with mock.patch('easyci.commands.test.load_user_config') as mocked:\n        mocked.return_value = {\n            'tests': ['true', 'true'],\n            'history_limit': 1,\n            'collect_results': [],\n        }\n        result = runner.invoke(cli, ['test'])\n    assert result.exit_code == exit_codes.SUCCESS\n    assert 'Passed' in result.output\n    assert 'Failed' not in result.output", "fn_id": 4, "class_fn": false, "repo": "naphatkrit/easyci", "file": "tests/easyci/commands/test_test.py", "last_update_at": "2018-07-08T16:57:58+00:00", "question_id": "db1870fa35799b9026517c24a66b55fd6be52186_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_test_simple_passed(runner):\n    with mock.patch('easyci.commands.test.load_user_config') as mocked:\n        mocked.return_value = {'tests': ['true', 'true'], 'history_limit': 1, 'collect_results': []}\n        result = runner.invoke(cli, ['test'])\n    assert result.exit_code == exit_codes.SUCCESS\n    assert 'Passed' in result.output\n"]]}
{"hexsha": "495cfdfe0cf21298881ddfe6ecb70dadde1e1e2d", "ext": "py", "lang": "Python", "content": "def find_posts(path):\n    def root_to_directory_name(root):\n        x = os.path.join(root, \"\") # Forces a trailing \\ or / depending on the OS\n        return os.path.basename(os.path.dirname(x)) \n\n    def process_folder(root, files):\n        if root.endswith(\"thumbnails\"): \n            return None\n\n        images = []\n        for image in files:\n            full_path = os.path.join(root, image)\n            images.append(full_path)\n\n        return images\n        \n\n    posts = {}\n    for root, dirs, files in os.walk(path):\n        images = process_folder(root, files)\n\n        if images:\n            relative_folder = root_to_directory_name(root)\n            posts[relative_folder] = images\n    return posts", "fn_id": 1, "class_fn": false, "repo": "jquintus/jquintus.github.io", "file": "generate_images.py", "last_update_at": "2018-04-14T12:59:09+00:00", "question_id": "495cfdfe0cf21298881ddfe6ecb70dadde1e1e2d_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def find_posts(path):\n\n    def root_to_directory_name(root):\n        x = os.path.join(root, '')\n        return os.path.basename(os.path.dirname(x))\n\n    def process_folder(root, files):\n        if root.endswith('thumbnails'):\n            return None\n        images = []\n        for image in files:\n            full_path = os.path.join(root, image)\n            images.append(full_path)\n        return images\n    posts = {}\n    for root, dirs, files in os.walk(path):\n        images = process_folder(root, files)\n        if images:\n            relative_folder = root_to_directory_name(root)\n            posts[relative_folder] = images\n"]]}
{"hexsha": "b2c6ee12faa5f6701e61eda71d9198494de49f15", "ext": "py", "lang": "Python", "content": "def ccmUnred(wave, flux, EBV, R_V=3.1):\n\n    flux = np.array(flux)\n    x = 10000. / wave                # Convert to inverse microns\n    npts = len(x)\n    a = np.zeros(npts)\n    b = np.zeros(npts)\n\n    good = np.where((x > 0.3) & (x < 1.1))[0]       # Infrared\n    if len(good) > 0:\n        a[good] = 0.574 * x[good] ** (1.61)\n        b[good] = -0.527 * x[good] ** (1.61)\n\n    good = np.where((x >= 1.1) & (x < 3.3))        # Optical/NIR\n    if len(good[0]) > 0:\n        y = x[good] - 1.82\n        c1 = np.array([1., 0.104, -0.609, 0.701, 1.137, -1.718, -0.827,\n                       1.647, -0.505])   # From O'Donnell (1994)\n        c2 = np.array([0., 1.952, 2.908, -3.989, -7.985, 11.102,\n                       5.491, -10.805, 3.347])\n\n        a[good] = np.polyval(c1[::-1], y)\n        b[good] = np.polyval(c2[::-1], y)\n\n    good = np.where((x >= 3.3) & (x < 8))[0]           # Mid-UV\n    if len(good) > 0:\n        y = x[good]\n        F_a = np.zeros(len(good))\n        F_b = np.zeros(len(good))\n\n        good1 = np.where(y > 5.9)\n        if len(good1) > 0:\n            y1 = y[good1] - 5.9\n            F_a[good1] = -0.04473 * y1 ** 2 - 0.009779 * y1 ** 3\n            F_b[good1] = 0.2130 * y1 ** 2 + 0.1207 * y1 ** 3\n\n        a[good] = 1.752 - 0.316 * y - (0.104 / ((y - 4.67)**2 + 0.341)) + F_a\n        b[good] = -3.090 + 1.825 * y + (1.206 / ((y - 4.62)**2 + 0.263)) + F_b\n\n    good = np.where((x >= 8) & (x <= 11))[0]         # Far-UV\n    if len(good) > 0:\n        y = x[good] - 8.\n        c1 = np.array([-1.073, -0.628, 0.137, -0.070])\n        c2 = np.array([13.670, 4.257, -0.420, 0.374])\n\n        a[good] = np.polyval(c1[::-1], y)\n        b[good] = np.polyval(c2[::-1], y)\n\n    A_V = R_V * EBV\n    A_lambda = A_V * (a + b / R_V)\n\n    funred = flux * 10. ** (0.4 * A_lambda)\n\n    return funred", "fn_id": 0, "class_fn": false, "repo": "sdss/Totoro", "file": "Totoro/utils/ccm_unred.py", "last_update_at": "2018-08-22T00:34:30+00:00", "question_id": "b2c6ee12faa5f6701e61eda71d9198494de49f15_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def ccmUnred(wave, flux, EBV, R_V=3.1):\n    flux = np.array(flux)\n    x = 10000.0 / wave\n    npts = len(x)\n    a = np.zeros(npts)\n    b = np.zeros(npts)\n    good = np.where((x > 0.3) & (x < 1.1))[0]\n    if len(good) > 0:\n        a[good] = 0.574 * x[good] ** 1.61\n        b[good] = -0.527 * x[good] ** 1.61\n    good = np.where((x >= 1.1) & (x < 3.3))\n    if len(good[0]) > 0:\n        y = x[good] - 1.82\n        c1 = np.array([1.0, 0.104, -0.609, 0.701, 1.137, -1.718, -0.827, 1.647, -0.505])\n        c2 = np.array([0.0, 1.952, 2.908, -3.989, -7.985, 11.102, 5.491, -10.805, 3.347])\n        a[good] = np.polyval(c1[::-1], y)\n        b[good] = np.polyval(c2[::-1], y)\n    good = np.where((x >= 3.3) & (x < 8))[0]\n    if len(good) > 0:\n        y = x[good]\n        F_a = np.zeros(len(good))\n        F_b = np.zeros(len(good))\n        good1 = np.where(y > 5.9)\n        if len(good1) > 0:\n            y1 = y[good1] - 5.9\n            F_a[good1] = -0.04473 * y1 ** 2 - 0.009779 * y1 ** 3\n            F_b[good1] = 0.213 * y1 ** 2 + 0.1207 * y1 ** 3\n        a[good] = 1.752 - 0.316 * y - 0.104 / ((y - 4.67) ** 2 + 0.341) + F_a\n        b[good] = -3.09 + 1.825 * y + 1.206 / ((y - 4.62) ** 2 + 0.263) + F_b\n    good = np.where((x >= 8) & (x <= 11))[0]\n    if len(good) > 0:\n        y = x[good] - 8.0\n        c1 = np.array([-1.073, -0.628, 0.137, -0.07])\n        c2 = np.array([13.67, 4.257, -0.42, 0.374])\n        a[good] = np.polyval(c1[::-1], y)\n        b[good] = np.polyval(c2[::-1], y)\n    A_V = R_V * EBV\n    A_lambda = A_V * (a + b / R_V)\n    funred = flux * 10.0 ** (0.4 * A_lambda)\n"]]}
{"hexsha": "cfcf75474e5dcdd262c7b2b5f09cb4c25b966506", "ext": "py", "lang": "Python", "content": "def include_version(global_root: str, version_obj: models.Version, hardlink: bool = True):\n    \"\"\"Include files in existing bundle version.\n\n    Including a file means to link them into a folder in the root directory\n    \"\"\"\n    LOG.info(\"Use global root path %s\", global_root)\n    global_root_dir = Path(global_root)\n    if version_obj.included_at:\n        raise VersionIncludedError(f\"version included on {version_obj.included_at}\")\n\n    # generate root directory\n    version_root_dir = global_root_dir / version_obj.relative_root_dir\n    version_root_dir.mkdir(parents=True, exist_ok=True)\n    LOG.info(\"created new bundle version dir: %s\", version_root_dir)\n\n    for file_obj in version_obj.files:\n        # hardlink file to the internal structure\n        file_obj_path = Path(file_obj.path)\n        new_path = version_root_dir / file_obj_path.name\n        link_file(file_path=file_obj_path, new_path=new_path, hardlink=hardlink)\n        file_obj.path = str(new_path).replace(f\"{global_root_dir}/\", EMPTY_STR, 1)", "fn_id": 1, "class_fn": false, "repo": "Clinical-Genomics/housekeeper", "file": "housekeeper/include.py", "last_update_at": "2018-12-21T12:16:59+00:00", "question_id": "cfcf75474e5dcdd262c7b2b5f09cb4c25b966506_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def include_version(global_root: str, version_obj: models.Version, hardlink: bool=True):\n    \"\"\"Include files in existing bundle version.\n\n    Including a file means to link them into a folder in the root directory\n    \"\"\"\n    LOG.info('Use global root path %s', global_root)\n    global_root_dir = Path(global_root)\n    if version_obj.included_at:\n        raise VersionIncludedError(f'version included on {version_obj.included_at}')\n    version_root_dir = global_root_dir / version_obj.relative_root_dir\n    version_root_dir.mkdir(parents=True, exist_ok=True)\n    LOG.info('created new bundle version dir: %s', version_root_dir)\n    for file_obj in version_obj.files:\n        file_obj_path = Path(file_obj.path)\n        new_path = version_root_dir / file_obj_path.name\n        link_file(file_path=file_obj_path, new_path=new_path, hardlink=hardlink)\n"]]}
{"hexsha": "b78cbc595a45779867f5678a43f9716bb8fc4c7e", "ext": "py", "lang": "Python", "content": "def delete_note(request, note_id):\n    project = Project.objects.get(user=request.user)\n    project.note_set.get(pk=note_id).delete()\n    return redirect('members')", "fn_id": 8, "class_fn": false, "repo": "OpenHumans/oh-proj-management", "file": "project_admin/views.py", "last_update_at": "2018-09-01T16:03:46+00:00", "question_id": "b78cbc595a45779867f5678a43f9716bb8fc4c7e_8", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def delete_note(request, note_id):\n    project = Project.objects.get(user=request.user)\n    project.note_set.get(pk=note_id).delete()\n"]]}
{"hexsha": "ff164fc6af0d809157aa358291edbde4193822a6", "ext": "py", "lang": "Python", "content": "def index(request):\n    c = {}\n    c.update(csrf(request))\n    #print(c)\n    if request.method == 'POST':\n        username = request.POST['username']\n        password = request.POST['password']\n        #print(request.POST)\n        if \"button_click\" in request.POST:\n            #print(username, password)\n            user = authenticate(username=username, password=password)\n            if user is not None:\n                print('Testing')\n                login(request, user)\n                return redirect('/homeapp')\n            else:\n                messages.error(request, \"Wrong email and password combination\")\n    return render(request, 'loginapp/base.html', c)", "fn_id": 0, "class_fn": false, "repo": "naveenpiedy/104-CSyllabus-International-Computer-Science-Syllabi-Repository", "file": "mainsite/loginapp/views.py", "last_update_at": "2018-04-10T02:33:15+00:00", "question_id": "ff164fc6af0d809157aa358291edbde4193822a6_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def index(request):\n    c = {}\n    c.update(csrf(request))\n    if request.method == 'POST':\n        username = request.POST['username']\n        password = request.POST['password']\n        if 'button_click' in request.POST:\n            user = authenticate(username=username, password=password)\n            if user is not None:\n                print('Testing')\n                login(request, user)\n                return redirect('/homeapp')\n            else:\n                messages.error(request, 'Wrong email and password combination')\n"]]}
{"hexsha": "c478fd461ccb3296545e71b836f66e0cd6f99257", "ext": "py", "lang": "Python", "content": "def _find_type_from_comment_hint(context, node, varlist, name):\n    index = None\n    if varlist.type in (\"testlist_star_expr\", \"exprlist\"):\n        # something like \"a, b = 1, 2\"\n        index = 0\n        for child in varlist.children:\n            if child == name:\n                break\n            if child.type == \"operator\":\n                continue\n            index += 1\n        else:\n            return []\n\n    comment = node.get_following_comment_same_line()\n    if comment is None:\n        return []\n    match = re.match(r\"^#\\s*type:\\s*([^#]*)\", comment)\n    if not match:\n        return []\n    annotation = tree.String(\n        repr(str(match.group(1).strip())),\n        node.start_pos)\n    annotation.parent = node.parent\n    return _evaluate_for_annotation(context, annotation, index)", "fn_id": 8, "class_fn": false, "repo": "space-scl/emacs.d", "file": "anaconda-mode/0.1.7/jedi-0.10.2-py3.5.egg/jedi/evaluate/pep0484.py", "last_update_at": "2018-01-24T00:06:42+00:00", "question_id": "c478fd461ccb3296545e71b836f66e0cd6f99257_8", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _find_type_from_comment_hint(context, node, varlist, name):\n    index = None\n    if varlist.type in ('testlist_star_expr', 'exprlist'):\n        index = 0\n        for child in varlist.children:\n            if child == name:\n                break\n            if child.type == 'operator':\n                continue\n            index += 1\n        else:\n            return []\n    comment = node.get_following_comment_same_line()\n    if comment is None:\n        return []\n    match = re.match('^#\\\\s*type:\\\\s*([^#]*)', comment)\n    if not match:\n        return []\n    annotation = tree.String(repr(str(match.group(1).strip())), node.start_pos)\n    annotation.parent = node.parent\n"]]}
{"hexsha": "3c6e7f9bfd20d96d7c2999dfcee6ceb737fa9a79", "ext": "py", "lang": "Python", "content": "def printAnswerGraph(answer, headers, meta):\n\t\"\"\"\n\tprintAnswerGraph(answer, headers, meta): Print up a graph of our answer\n\t\"\"\"\n\n\trddata = answer[\"rddata\"]\n\n\tprint(\"                                1  1  1  1  1  1\")\n\tprint(\"     0  1  2  3  4  5  6  7  8  9  0  1  2  3  4  5\")\n\tprint(\"   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+\")\n    \n\tprint(\"   |  NAME     : %-40s    |\" % (rddata[\"question_text\"]))\n\n\tfor row in rddata[\"question_meta\"][\"data_decoded\"]:\n\n\t\tif \"length\" in row:\n\n\t\t\tkey = row[\"length\"]\n\t\t\tvalue = \"(nil)\"\n\t\t\tif row[\"length\"]:\n\t\t\t\tvalue = row[\"string\"]\n\t\t\tprint(\"   |        len: %3d  value: %-30s  |\" % (key, value))\n\n\t\telif \"pointer\" in row:\n\t\t\tkey = row[\"pointer\"]\n\t\t\tvalue = row[\"target\"]\n\t\t\tprint(\"   |    pointer: %3d target: %-30s  |\" % (key, value))\n\n\t\telse:\n\n\t\t\tprint(\"   |    UNKNOWN: %25s |\" % (row))\n\n\t#\n\t# If the header was set to a negative very (or a very high positive value!)\n\t# for debugging, ensure the number is negative and the text indicates that\n\t# debugging is happening.\n\t#\n\tif headers[\"ttl\"] >= 4294967293:\n\t\tlogger.debug(\"TTL is over 2**32-3, so subtract 2**32\")\n\t\theaders[\"ttl\"] -= pow(2,32)\n\n\tif headers[\"ttl\"] < 0:\n\t\theaders[\"ttl_text\"] = \"DEBUGGING\"\n\n\tprint(\"   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+\")\n\tprint(\"   |  TYPE:  %3d - %-38s    |\" % (headers[\"type\"], headers[\"type_text\"]))\n\tprint(\"   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+\")\n\tprint(\"   | CLASS: %3d - %-39s    |\" % (headers[\"class\"], headers[\"class_text\"]))\n\tprint(\"   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+\")\n\tprint(\"   |   TTL: %10d - %-33s   |\" % (headers[\"ttl\"], headers[\"ttl_text\"]))\n\tprint(\"   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+\")\n\tprint(\"   |   RDLENGTH: %3d                                         |\" % (headers[\"rdlength\"]))\n\tprint(\"   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+\")\n\tprint(\"   |     RDDATA: %-40s    |\" % (answer[\"rddata_text\"]))\n\tif \"meta\" in rddata:\n\t\tfor row in rddata[\"meta\"][\"data_decoded\"]:\n\n\t\t\tif \"length\" in row:\n\n\t\t\t\tkey = row[\"length\"]\n\t\t\t\tvalue = \"(nil)\"\n\t\t\t\tif row[\"length\"]:\n\t\t\t\t\tvalue = row[\"string\"]\n\t\t\t\tprint(\"   |        len: %3d  value: %-30s  |\" % (key, value))\n\n\t\t\telif \"pointer\" in row:\n\t\t\t\tkey = row[\"pointer\"]\n\t\t\t\tvalue = row[\"target\"]\n\t\t\t\tprint(\"   |    pointer: %3d target: %-30s  |\" % (key, value))\n\n\t\t\telse:\n\n\t\t\t\tprint(\"   |    UNKNOWN: %35s |\" % (row))\n\tprint(\"   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+\")", "fn_id": 6, "class_fn": false, "repo": "dmuth/dns-tool", "file": "lib/output.py", "last_update_at": "2018-09-16T03:32:10+00:00", "question_id": "3c6e7f9bfd20d96d7c2999dfcee6ceb737fa9a79_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def printAnswerGraph(answer, headers, meta):\n    \"\"\"\n\tprintAnswerGraph(answer, headers, meta): Print up a graph of our answer\n\t\"\"\"\n    rddata = answer['rddata']\n    print('                                1  1  1  1  1  1')\n    print('     0  1  2  3  4  5  6  7  8  9  0  1  2  3  4  5')\n    print('   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+')\n    print('   |  NAME     : %-40s    |' % rddata['question_text'])\n    for row in rddata['question_meta']['data_decoded']:\n        if 'length' in row:\n            key = row['length']\n            value = '(nil)'\n            if row['length']:\n                value = row['string']\n            print('   |        len: %3d  value: %-30s  |' % (key, value))\n        elif 'pointer' in row:\n            key = row['pointer']\n            value = row['target']\n            print('   |    pointer: %3d target: %-30s  |' % (key, value))\n        else:\n            print('   |    UNKNOWN: %25s |' % row)\n    if headers['ttl'] >= 4294967293:\n        logger.debug('TTL is over 2**32-3, so subtract 2**32')\n        headers['ttl'] -= pow(2, 32)\n    if headers['ttl'] < 0:\n        headers['ttl_text'] = 'DEBUGGING'\n    print('   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+')\n    print('   |  TYPE:  %3d - %-38s    |' % (headers['type'], headers['type_text']))\n    print('   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+')\n    print('   | CLASS: %3d - %-39s    |' % (headers['class'], headers['class_text']))\n    print('   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+')\n    print('   |   TTL: %10d - %-33s   |' % (headers['ttl'], headers['ttl_text']))\n    print('   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+')\n    print('   |   RDLENGTH: %3d                                         |' % headers['rdlength'])\n    print('   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+------------+')\n    print('   |     RDDATA: %-40s    |' % answer['rddata_text'])\n    if 'meta' in rddata:\n        for row in rddata['meta']['data_decoded']:\n            if 'length' in row:\n                key = row['length']\n                value = '(nil)'\n                if row['length']:\n                    value = row['string']\n                print('   |        len: %3d  value: %-30s  |' % (key, value))\n            elif 'pointer' in row:\n                key = row['pointer']\n                value = row['target']\n                print('   |    pointer: %3d target: %-30s  |' % (key, value))\n            else:\n                print('   |    UNKNOWN: %35s |' % row)\n"]]}
{"hexsha": "d9e3428e2966176db989cf7f03ab1258cb971577", "ext": "py", "lang": "Python", "content": "def friendly_time(last_update):\n    minutes = last_update / 60\n    seconds = last_update % 60\n\n    friendly_time = []\n    if minutes > 0:\n        friendly_time.append(ungettext(\n                '%(minutes)i minute',\n                '%(minutes)i minutes',\n                minutes\n        ) % {'minutes': minutes })\n    if seconds > 0:\n        friendly_time.append(ungettext(\n                '%(seconds)i second',\n                '%(seconds)i seconds',\n                seconds\n        ) % {'seconds': seconds })\n\n    return friendly_time or 0", "fn_id": 2, "class_fn": false, "repo": "letam/django-tracking", "file": "tracking/views.py", "last_update_at": "2018-03-19T15:19:02+00:00", "question_id": "d9e3428e2966176db989cf7f03ab1258cb971577_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def friendly_time(last_update):\n    minutes = last_update / 60\n    seconds = last_update % 60\n    friendly_time = []\n    if minutes > 0:\n        friendly_time.append(ungettext('%(minutes)i minute', '%(minutes)i minutes', minutes) % {'minutes': minutes})\n    if seconds > 0:\n        friendly_time.append(ungettext('%(seconds)i second', '%(seconds)i seconds', seconds) % {'seconds': seconds})\n"]]}
{"hexsha": "ca8086bde315c42a3b27cd777fe492722e528038", "ext": "py", "lang": "Python", "content": "def isValidString(strBytes):\n\t# 1st check: no invalid characters\n\tfor index in range(0, len(strBytes)):\n\t\tif (strBytes[index] < 0x20 and strBytes[index] != 0x0D and strBytes[index] != 0x0A and strBytes[index] != 0x09):\n\t\t\treturn False\n\t# 2nd check: needs at least one SJIS japanese symbol (why TL otherwise?)\n\tfor index in range(0, len(strBytes)):\n\t\tif strBytes[index] >= 0x81 and strBytes[index] <= 0xEF and strBytes[index] != 0xA0:\n\t\t\treturn True\n\t# no SJIS symbol found\n\treturn False", "fn_id": 1, "class_fn": false, "repo": "TPDPTranslationTeam/TPDP_Translation_Team", "file": "utilities/ExeStringTranslation/NewExeTranslator.py", "last_update_at": "2018-09-28T21:32:40+00:00", "question_id": "ca8086bde315c42a3b27cd777fe492722e528038_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def isValidString(strBytes):\n    for index in range(0, len(strBytes)):\n        if strBytes[index] < 32 and strBytes[index] != 13 and (strBytes[index] != 10) and (strBytes[index] != 9):\n            return False\n    for index in range(0, len(strBytes)):\n        if strBytes[index] >= 129 and strBytes[index] <= 239 and (strBytes[index] != 160):\n            return True\n"]]}
{"hexsha": "04985fa76afb07ef54a2fc2d1b68301480b22e88", "ext": "py", "lang": "Python", "content": "def api_get_doc_by_hl_id(request):\n    response = {}\n    context = {}\n    forum = Forum.objects.get(id=request.session['forum_id'])\n    # retrieve docs in a folder\n    hl_id = request.REQUEST.get(\"hl_id\")\n    hl = Highlight.objects.get(id = hl_id)\n    sec = DocSection.objects.get(id=hl.context.id)\n    doc = sec.doc\n    context['doc_name'] = doc.title\n    context['sections'] = []\n    context['doc_id'] = doc.id\n    ordered_sections = doc.sections.filter(order__isnull=False).order_by('order')\n    for section in ordered_sections:\n        context['sections'].append(section.getAttr(forum))\n    unordered_sections = doc.sections.filter(order__isnull=True).order_by('updated_at')\n    for section in unordered_sections:\n        context['sections'].append(section.getAttr(forum))\n    response['workbench_document'] = render_to_string(\"workbench-document.html\", context)\n    response['doc_id'] = doc.id\n    return HttpResponse(json.dumps(response), mimetype='application/json')", "fn_id": 6, "class_fn": false, "repo": "xsunfeng/cir", "file": "cir/phase1.py", "last_update_at": "2018-06-23T21:11:53+00:00", "question_id": "04985fa76afb07ef54a2fc2d1b68301480b22e88_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def api_get_doc_by_hl_id(request):\n    response = {}\n    context = {}\n    forum = Forum.objects.get(id=request.session['forum_id'])\n    hl_id = request.REQUEST.get('hl_id')\n    hl = Highlight.objects.get(id=hl_id)\n    sec = DocSection.objects.get(id=hl.context.id)\n    doc = sec.doc\n    context['doc_name'] = doc.title\n    context['sections'] = []\n    context['doc_id'] = doc.id\n    ordered_sections = doc.sections.filter(order__isnull=False).order_by('order')\n    for section in ordered_sections:\n        context['sections'].append(section.getAttr(forum))\n    unordered_sections = doc.sections.filter(order__isnull=True).order_by('updated_at')\n    for section in unordered_sections:\n        context['sections'].append(section.getAttr(forum))\n    response['workbench_document'] = render_to_string('workbench-document.html', context)\n    response['doc_id'] = doc.id\n"]]}
{"hexsha": "c826db6970532e15b43d7ec1037d00e74c3995a8", "ext": "py", "lang": "Python", "content": "def weight_matrix(training_filename, get_scale=False, delim=','):\n    \"\"\"\n    Returns the weight matrix built from the data in the file\n    at the filename given as the first argument, scaled according to\n    the values in the file.\n    \"\"\"\n    training_scale = scale(training_filename, delim)\n    with open(training_filename, 'r') as training_file:\n        for line in training_file:\n            x_i, y_i = parse_vectors(line, training_scale, delim)\n            try:\n                sum_xi += x_i * x_i.T\n                sum_yi += x_i * y_i.T\n            except NameError:\n                sum_xi = x_i * x_i.T\n                sum_yi = x_i * y_i.T\n            except ValueError: # row has differing number of attributes\n                if sum_xi.shape[0] < x_i.shape[0]:\n                    # more attributes, use this as the standard\n                    sum_xi = x_i * x_i.T\n                    sum_yi = x_i * y_i.T\n                else:\n                    # less attributes, ignore it\n                    pass\n    try:\n        W = sum_xi.I * sum_yi # will raise exception if no inverse\n    except linalg.LinAlgError:\n        W = (sum_xi + 0.00001*identity(sum_xi.shape[0])).I * sum_yi\n    if get_scale:\n        return W, training_scale\n    return W", "fn_id": 2, "class_fn": false, "repo": "kylelin47/linear-regression", "file": "linear-regression/regress.py", "last_update_at": "2018-09-24T15:27:18+00:00", "question_id": "c826db6970532e15b43d7ec1037d00e74c3995a8_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def weight_matrix(training_filename, get_scale=False, delim=','):\n    \"\"\"\n    Returns the weight matrix built from the data in the file\n    at the filename given as the first argument, scaled according to\n    the values in the file.\n    \"\"\"\n    training_scale = scale(training_filename, delim)\n    with open(training_filename, 'r') as training_file:\n        for line in training_file:\n            x_i, y_i = parse_vectors(line, training_scale, delim)\n            try:\n                sum_xi += x_i * x_i.T\n                sum_yi += x_i * y_i.T\n            except NameError:\n                sum_xi = x_i * x_i.T\n                sum_yi = x_i * y_i.T\n            except ValueError:\n                if sum_xi.shape[0] < x_i.shape[0]:\n                    sum_xi = x_i * x_i.T\n                    sum_yi = x_i * y_i.T\n                else:\n                    pass\n    try:\n        W = sum_xi.I * sum_yi\n    except linalg.LinAlgError:\n        W = (sum_xi + 1e-05 * identity(sum_xi.shape[0])).I * sum_yi\n    if get_scale:\n        return (W, training_scale)\n"]]}
{"hexsha": "ce225d5eef0ece22880f86f9a252c0b10ca8a724", "ext": "py", "lang": "Python", "content": "@pytest.mark.django_db()\ndef test_safe_navigation():\n    position = mommy.make('position.Position')\n\n    assert safe_navigation(position, \"post\") is None\n\n    position.post = mommy.make('organization.Post')\n    position.save()\n\n    assert safe_navigation(position, \"post\") is not None\n    assert safe_navigation(position, \"post.location\") is None\n\n    position.post.location = mommy.make('organization.Location')\n    position.save()\n\n    assert safe_navigation(position, \"post.location\") is not None", "fn_id": 3, "class_fn": false, "repo": "18F/State-TalentMAP-API", "file": "talentmap_api/common/tests/test_common_helpers.py", "last_update_at": "2018-05-14T13:44:06+00:00", "question_id": "ce225d5eef0ece22880f86f9a252c0b10ca8a724_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.mark.django_db()\ndef test_safe_navigation():\n    position = mommy.make('position.Position')\n    assert safe_navigation(position, 'post') is None\n    position.post = mommy.make('organization.Post')\n    position.save()\n    assert safe_navigation(position, 'post') is not None\n    assert safe_navigation(position, 'post.location') is None\n    position.post.location = mommy.make('organization.Location')\n    position.save()\n"]]}
{"hexsha": "218d136505d79730039ed6eaeaedc8ce0b3c6f09", "ext": "py", "lang": "Python", "content": "def test_duplicate_axis():\n    a = ng.make_axis(name='X')\n    b = ng.make_axis(name='X')\n    with pytest.raises(ValueError):\n        ng.make_axes([a, b])", "fn_id": 0, "class_fn": false, "repo": "rsumner31/ngraph", "file": "tests/test_axes.py", "last_update_at": "2018-11-21T11:38:14+00:00", "question_id": "218d136505d79730039ed6eaeaedc8ce0b3c6f09_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_duplicate_axis():\n    a = ng.make_axis(name='X')\n    b = ng.make_axis(name='X')\n    with pytest.raises(ValueError):\n"]]}
{"hexsha": "a3dfb069e512b715ce960b986c0367d328ad5c7b", "ext": "py", "lang": "Python", "content": "def test_Extract_inputs():\n    input_map = dict(\n        args=dict(argstr='%s', ),\n        count=dict(\n            argstr='-count %s',\n            sep=',',\n        ),\n        environ=dict(\n            nohash=True,\n            usedefault=True,\n        ),\n        flip_any_direction=dict(\n            argstr='-any_direction',\n            xor=('flip_positive_direction', 'flip_negative_direction',\n                 'flip_any_direction'),\n        ),\n        flip_negative_direction=dict(\n            argstr='-negative_direction',\n            xor=('flip_positive_direction', 'flip_negative_direction',\n                 'flip_any_direction'),\n        ),\n        flip_positive_direction=dict(\n            argstr='-positive_direction',\n            xor=('flip_positive_direction', 'flip_negative_direction',\n                 'flip_any_direction'),\n        ),\n        flip_x_any=dict(\n            argstr='-xanydirection',\n            xor=('flip_x_positive', 'flip_x_negative', 'flip_x_any'),\n        ),\n        flip_x_negative=dict(\n            argstr='-xdirection',\n            xor=('flip_x_positive', 'flip_x_negative', 'flip_x_any'),\n        ),\n        flip_x_positive=dict(\n            argstr='+xdirection',\n            xor=('flip_x_positive', 'flip_x_negative', 'flip_x_any'),\n        ),\n        flip_y_any=dict(\n            argstr='-yanydirection',\n            xor=('flip_y_positive', 'flip_y_negative', 'flip_y_any'),\n        ),\n        flip_y_negative=dict(\n            argstr='-ydirection',\n            xor=('flip_y_positive', 'flip_y_negative', 'flip_y_any'),\n        ),\n        flip_y_positive=dict(\n            argstr='+ydirection',\n            xor=('flip_y_positive', 'flip_y_negative', 'flip_y_any'),\n        ),\n        flip_z_any=dict(\n            argstr='-zanydirection',\n            xor=('flip_z_positive', 'flip_z_negative', 'flip_z_any'),\n        ),\n        flip_z_negative=dict(\n            argstr='-zdirection',\n            xor=('flip_z_positive', 'flip_z_negative', 'flip_z_any'),\n        ),\n        flip_z_positive=dict(\n            argstr='+zdirection',\n            xor=('flip_z_positive', 'flip_z_negative', 'flip_z_any'),\n        ),\n        image_maximum=dict(argstr='-image_maximum %s', ),\n        image_minimum=dict(argstr='-image_minimum %s', ),\n        image_range=dict(argstr='-image_range %s %s', ),\n        input_file=dict(\n            argstr='%s',\n            extensions=None,\n            mandatory=True,\n            position=-2,\n        ),\n        nonormalize=dict(\n            argstr='-nonormalize',\n            xor=('normalize', 'nonormalize'),\n        ),\n        normalize=dict(\n            argstr='-normalize',\n            xor=('normalize', 'nonormalize'),\n        ),\n        out_file=dict(\n            argstr='> %s',\n            extensions=None,\n            genfile=True,\n            position=-1,\n        ),\n        output_file=dict(\n            extensions=None,\n            hash_files=False,\n            keep_extension=False,\n            name_source=['input_file'],\n            name_template='%s.raw',\n            position=-1,\n        ),\n        start=dict(\n            argstr='-start %s',\n            sep=',',\n        ),\n        write_ascii=dict(\n            argstr='-ascii',\n            xor=('write_ascii', 'write_ascii', 'write_byte', 'write_short',\n                 'write_int', 'write_long', 'write_float', 'write_double',\n                 'write_signed', 'write_unsigned'),\n        ),\n        write_byte=dict(\n            argstr='-byte',\n            xor=('write_ascii', 'write_ascii', 'write_byte', 'write_short',\n                 'write_int', 'write_long', 'write_float', 'write_double',\n                 'write_signed', 'write_unsigned'),\n        ),\n        write_double=dict(\n            argstr='-double',\n            xor=('write_ascii', 'write_ascii', 'write_byte', 'write_short',\n                 'write_int', 'write_long', 'write_float', 'write_double',\n                 'write_signed', 'write_unsigned'),\n        ),\n        write_float=dict(\n            argstr='-float',\n            xor=('write_ascii', 'write_ascii', 'write_byte', 'write_short',\n                 'write_int', 'write_long', 'write_float', 'write_double',\n                 'write_signed', 'write_unsigned'),\n        ),\n        write_int=dict(\n            argstr='-int',\n            xor=('write_ascii', 'write_ascii', 'write_byte', 'write_short',\n                 'write_int', 'write_long', 'write_float', 'write_double',\n                 'write_signed', 'write_unsigned'),\n        ),\n        write_long=dict(\n            argstr='-long',\n            xor=('write_ascii', 'write_ascii', 'write_byte', 'write_short',\n                 'write_int', 'write_long', 'write_float', 'write_double',\n                 'write_signed', 'write_unsigned'),\n        ),\n        write_range=dict(argstr='-range %s %s', ),\n        write_short=dict(\n            argstr='-short',\n            xor=('write_ascii', 'write_ascii', 'write_byte', 'write_short',\n                 'write_int', 'write_long', 'write_float', 'write_double',\n                 'write_signed', 'write_unsigned'),\n        ),\n        write_signed=dict(\n            argstr='-signed',\n            xor=('write_signed', 'write_unsigned'),\n        ),\n        write_unsigned=dict(\n            argstr='-unsigned',\n            xor=('write_signed', 'write_unsigned'),\n        ),\n    )\n    inputs = Extract.input_spec()\n\n    for key, metadata in list(input_map.items()):\n        for metakey, value in list(metadata.items()):\n            assert getattr(inputs.traits()[key], metakey) == value\n", "fn_id": 0, "class_fn": false, "repo": "PAmcconnell/nipype", "file": "nipype/interfaces/minc/tests/test_auto_Extract.py", "last_update_at": "2018-04-27T06:36:49+00:00", "question_id": "a3dfb069e512b715ce960b986c0367d328ad5c7b_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_Extract_inputs():\n    input_map = dict(args=dict(argstr='%s'), count=dict(argstr='-count %s', sep=','), environ=dict(nohash=True, usedefault=True), flip_any_direction=dict(argstr='-any_direction', xor=('flip_positive_direction', 'flip_negative_direction', 'flip_any_direction')), flip_negative_direction=dict(argstr='-negative_direction', xor=('flip_positive_direction', 'flip_negative_direction', 'flip_any_direction')), flip_positive_direction=dict(argstr='-positive_direction', xor=('flip_positive_direction', 'flip_negative_direction', 'flip_any_direction')), flip_x_any=dict(argstr='-xanydirection', xor=('flip_x_positive', 'flip_x_negative', 'flip_x_any')), flip_x_negative=dict(argstr='-xdirection', xor=('flip_x_positive', 'flip_x_negative', 'flip_x_any')), flip_x_positive=dict(argstr='+xdirection', xor=('flip_x_positive', 'flip_x_negative', 'flip_x_any')), flip_y_any=dict(argstr='-yanydirection', xor=('flip_y_positive', 'flip_y_negative', 'flip_y_any')), flip_y_negative=dict(argstr='-ydirection', xor=('flip_y_positive', 'flip_y_negative', 'flip_y_any')), flip_y_positive=dict(argstr='+ydirection', xor=('flip_y_positive', 'flip_y_negative', 'flip_y_any')), flip_z_any=dict(argstr='-zanydirection', xor=('flip_z_positive', 'flip_z_negative', 'flip_z_any')), flip_z_negative=dict(argstr='-zdirection', xor=('flip_z_positive', 'flip_z_negative', 'flip_z_any')), flip_z_positive=dict(argstr='+zdirection', xor=('flip_z_positive', 'flip_z_negative', 'flip_z_any')), image_maximum=dict(argstr='-image_maximum %s'), image_minimum=dict(argstr='-image_minimum %s'), image_range=dict(argstr='-image_range %s %s'), input_file=dict(argstr='%s', extensions=None, mandatory=True, position=-2), nonormalize=dict(argstr='-nonormalize', xor=('normalize', 'nonormalize')), normalize=dict(argstr='-normalize', xor=('normalize', 'nonormalize')), out_file=dict(argstr='> %s', extensions=None, genfile=True, position=-1), output_file=dict(extensions=None, hash_files=False, keep_extension=False, name_source=['input_file'], name_template='%s.raw', position=-1), start=dict(argstr='-start %s', sep=','), write_ascii=dict(argstr='-ascii', xor=('write_ascii', 'write_ascii', 'write_byte', 'write_short', 'write_int', 'write_long', 'write_float', 'write_double', 'write_signed', 'write_unsigned')), write_byte=dict(argstr='-byte', xor=('write_ascii', 'write_ascii', 'write_byte', 'write_short', 'write_int', 'write_long', 'write_float', 'write_double', 'write_signed', 'write_unsigned')), write_double=dict(argstr='-double', xor=('write_ascii', 'write_ascii', 'write_byte', 'write_short', 'write_int', 'write_long', 'write_float', 'write_double', 'write_signed', 'write_unsigned')), write_float=dict(argstr='-float', xor=('write_ascii', 'write_ascii', 'write_byte', 'write_short', 'write_int', 'write_long', 'write_float', 'write_double', 'write_signed', 'write_unsigned')), write_int=dict(argstr='-int', xor=('write_ascii', 'write_ascii', 'write_byte', 'write_short', 'write_int', 'write_long', 'write_float', 'write_double', 'write_signed', 'write_unsigned')), write_long=dict(argstr='-long', xor=('write_ascii', 'write_ascii', 'write_byte', 'write_short', 'write_int', 'write_long', 'write_float', 'write_double', 'write_signed', 'write_unsigned')), write_range=dict(argstr='-range %s %s'), write_short=dict(argstr='-short', xor=('write_ascii', 'write_ascii', 'write_byte', 'write_short', 'write_int', 'write_long', 'write_float', 'write_double', 'write_signed', 'write_unsigned')), write_signed=dict(argstr='-signed', xor=('write_signed', 'write_unsigned')), write_unsigned=dict(argstr='-unsigned', xor=('write_signed', 'write_unsigned')))\n    inputs = Extract.input_spec()\n    for key, metadata in list(input_map.items()):\n        for metakey, value in list(metadata.items()):\n"]]}
{"hexsha": "307c6094661be4ed4c6c1a79d64411f905fb1eda", "ext": "py", "lang": "Python", "content": "@mock.patch(\"tt.task.get\")\n@mock.patch(\"tt.task.update\")\ndef test_describe_invalid_task(update, get, task_service, mocker):\n    get.side_effect = NoResultFound\n\n    with pytest.raises(BadRequest):\n        task_service.describe(\"some task\", \"description\")\n\n    get.assert_called_once_with(name=\"some task\")\n    assert not update.called", "fn_id": 8, "class_fn": false, "repo": "anthonyoteri/timetrack2", "file": "tt/test/test_service.py", "last_update_at": "2018-05-02T16:08:08+00:00", "question_id": "307c6094661be4ed4c6c1a79d64411f905fb1eda_8", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@mock.patch('tt.task.get')\n@mock.patch('tt.task.update')\ndef test_describe_invalid_task(update, get, task_service, mocker):\n    get.side_effect = NoResultFound\n    with pytest.raises(BadRequest):\n        task_service.describe('some task', 'description')\n    get.assert_called_once_with(name='some task')\n"]]}
{"hexsha": "4e419e25f5bf7447b19908801f30f84deced2394", "ext": "py", "lang": "Python", "content": "def load_data_and_labels(positive_data_file, negative_data_file):\n    \"\"\"\n    Loads MR polarity data from files, splits the data into words and generates labels.\n    Returns split sentences and labels.\n    \"\"\"\n    # Load data from files\n    positive_examples = list(open(positive_data_file, \"r\").readlines())\n    positive_examples = [s.strip() for s in positive_examples]\n    negative_examples = list(open(negative_data_file, \"r\").readlines())\n    negative_examples = [s.strip() for s in negative_examples]\n    # Split by words\n    x_text = positive_examples + negative_examples\n    x_text = [clean_str(sent) for sent in x_text]\n    # Generate labels\n    positive_labels = [[0, 1] for _ in positive_examples]\n    negative_labels = [[1, 0] for _ in negative_examples]\n    y = np.concatenate([positive_labels, negative_labels], 0)\n    return [x_text, y]", "fn_id": 1, "class_fn": false, "repo": "dream-catcher/deep_cnn_text_classifier", "file": "cnn_1layer/data_helpers.py", "last_update_at": "2018-03-14T06:29:08+00:00", "question_id": "4e419e25f5bf7447b19908801f30f84deced2394_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def load_data_and_labels(positive_data_file, negative_data_file):\n    \"\"\"\n    Loads MR polarity data from files, splits the data into words and generates labels.\n    Returns split sentences and labels.\n    \"\"\"\n    positive_examples = list(open(positive_data_file, 'r').readlines())\n    positive_examples = [s.strip() for s in positive_examples]\n    negative_examples = list(open(negative_data_file, 'r').readlines())\n    negative_examples = [s.strip() for s in negative_examples]\n    x_text = positive_examples + negative_examples\n    x_text = [clean_str(sent) for sent in x_text]\n    positive_labels = [[0, 1] for _ in positive_examples]\n    negative_labels = [[1, 0] for _ in negative_examples]\n    y = np.concatenate([positive_labels, negative_labels], 0)\n"]]}
{"hexsha": "a6f83601c8b553a2f1d6b3e593f62fdfefa0bb7d", "ext": "py", "lang": "Python", "content": "def validate_feedcode_chars(feedcode):\n    \"\"\"Raise an exception if we contain unapproved characters.\"\"\"\n    for c in feedcode:\n        if c not in settings.VALID_CHARS:\n            raise ValidationError(u\"{} is not a valid character.\".format(c))", "fn_id": 0, "class_fn": false, "repo": "HvZWAT/claremontHvZ", "file": "hvz/main/validators.py", "last_update_at": "2018-04-23T04:48:43+00:00", "question_id": "a6f83601c8b553a2f1d6b3e593f62fdfefa0bb7d_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def validate_feedcode_chars(feedcode):\n    \"\"\"Raise an exception if we contain unapproved characters.\"\"\"\n    for c in feedcode:\n        if c not in settings.VALID_CHARS:\n"]]}
{"hexsha": "2efc0051df1c6a001fe11757a856aeeebbb1e79c", "ext": "py", "lang": "Python", "content": "@app.route(\"/set-ip/<string:ip>\",methods=['GET'])\ndef set_ip(ip):\n    global server_list\n    server_list = ['http://' + ip + ':6001/',\n               'http://' + ip + ':6002/',\n               'http://' + ip + ':6003/',\n               'http://' + ip + ':6004/',]\n    return '', 200", "fn_id": 2, "class_fn": false, "repo": "SilvaMatteus/IAsperathos-plugin", "file": "adapted-load-balancer/load_balancer.py", "last_update_at": "2018-08-03T20:11:56+00:00", "question_id": "2efc0051df1c6a001fe11757a856aeeebbb1e79c_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@app.route('/set-ip/<string:ip>', methods=['GET'])\ndef set_ip(ip):\n    global server_list\n    server_list = ['http://' + ip + ':6001/', 'http://' + ip + ':6002/', 'http://' + ip + ':6003/', 'http://' + ip + ':6004/']\n"]]}
{"hexsha": "74334800222db36105559125b406dbe04a585da0", "ext": "py", "lang": "Python", "content": "def error_022_category_with_spaces(text):\n    \"\"\"Fix the error and return (new_text, replacements_count) tuple.\"\"\"\n    correct = len(re.findall(r\"\\[\\[\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f:[^ ]\", text))\n    (text, fixed) = re.subn(r\"\\[\\[\\s*\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f\\s*:\", \"[[\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f:\", text, flags=re.I)\n    count1 = fixed - correct\n\n    (text, count2) = re.subn(r\"(\\[\\[\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f:[^\\[\\]|]+?)\\s+([\\]|])\", \"\\\\1\\\\2\", text, flags=re.I)\n    return (text, count1 + count2)", "fn_id": 16, "class_fn": false, "repo": "Facenapalm/NapalmBot", "file": "scripts/checkwiki.py", "last_update_at": "2018-09-24T18:43:03+00:00", "question_id": "74334800222db36105559125b406dbe04a585da0_16", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def error_022_category_with_spaces(text):\n    \"\"\"Fix the error and return (new_text, replacements_count) tuple.\"\"\"\n    correct = len(re.findall('\\\\[\\\\[\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f:[^ ]', text))\n    text, fixed = re.subn('\\\\[\\\\[\\\\s*\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f\\\\s*:', '[[\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f:', text, flags=re.I)\n    count1 = fixed - correct\n    text, count2 = re.subn('(\\\\[\\\\[\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f:[^\\\\[\\\\]|]+?)\\\\s+([\\\\]|])', '\\\\1\\\\2', text, flags=re.I)\n"]]}
{"hexsha": "dda09ac234d6ae788fe90c15b694d23cc60fef40", "ext": "py", "lang": "Python", "content": "def getBandSongs(artist):\n    \"\"\"Given the Artist you will get all the songs from all the albums and EPs\n\n    Args: Artist\n\n    Return: A List with all the songs\n    \"\"\"\n    artist = artist.lower()\n    if artist.startswith(\"the \"):\n        artist = artist[3:]\n\n    artist = re.sub('[^A-Za-z0-9]+', \"\", artist)\n\n    url = \"http://www.azlyrics.com/\"+artist[0]+\"/\"+artist+\".html\"\n\n    try:\n        content = UrlReq.urlopen(url).read()\n        soup = BS(content, 'html.parser')\n        songs = []\n        songsBackbone = str(soup)\n        songsBackbone = songsBackbone.split('songlist')[1]\n        songsBackbone = songsBackbone.split('var res')[0]\n        for i in range(len(songsBackbone))[1::]:\n            try:\n                passValue = songsBackbone.split(\"s:\")[i]\n                passValue = passValue.split('\", h:')[0]\n                songs.append(passValue.split('\"')[1])\n            except IndexError:\n                break\n        return songs \n    except Exception as e:\n        return \"Exception occurred \\n\" + str(e)", "fn_id": 1, "class_fn": false, "repo": "arthurharrison/SongScrapper", "file": "WebScrapper.py", "last_update_at": "2018-08-29T14:36:59+00:00", "question_id": "dda09ac234d6ae788fe90c15b694d23cc60fef40_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def getBandSongs(artist):\n    \"\"\"Given the Artist you will get all the songs from all the albums and EPs\n\n    Args: Artist\n\n    Return: A List with all the songs\n    \"\"\"\n    artist = artist.lower()\n    if artist.startswith('the '):\n        artist = artist[3:]\n    artist = re.sub('[^A-Za-z0-9]+', '', artist)\n    url = 'http://www.azlyrics.com/' + artist[0] + '/' + artist + '.html'\n    try:\n        content = UrlReq.urlopen(url).read()\n        soup = BS(content, 'html.parser')\n        songs = []\n        songsBackbone = str(soup)\n        songsBackbone = songsBackbone.split('songlist')[1]\n        songsBackbone = songsBackbone.split('var res')[0]\n        for i in range(len(songsBackbone))[1:]:\n            try:\n                passValue = songsBackbone.split('s:')[i]\n                passValue = passValue.split('\", h:')[0]\n                songs.append(passValue.split('\"')[1])\n            except IndexError:\n                break\n        return songs\n    except Exception as e:\n"]]}
{"hexsha": "563c8fb82d218639c28cd03716c63d9198272fba", "ext": "py", "lang": "Python", "content": "def add_generatedby_to_tree(xmldocu,treeroot,skipel,uuid):\n    # skipel is None or perhaps the lip:process element we have been creating\n    # so that we don't list dependence on that\n\n    for descendent in iterelementsbutskip(treeroot,skipel): #  iterate through descendents, but ignore the provenance tag structure we just created. \n        # print \"descendent=%s\" % (str(descendent))\n        oldwgb=\"\"\n        if LIP+\"wasgeneratedby\" in descendent.attrib:\n            oldwgb=descendent.attrib[LIP+\"wasgeneratedby\"]\n            pass\n        \n        descendent.attrib[LIP+\"wasgeneratedby\"]=oldwgb + \"uuid=\"+uuid+\";\"\n        pass\n    pass", "fn_id": 11, "class_fn": false, "repo": "nscheirer/limatix", "file": "limatix/provenance.py", "last_update_at": "2018-07-09T18:33:00+00:00", "question_id": "563c8fb82d218639c28cd03716c63d9198272fba_11", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def add_generatedby_to_tree(xmldocu, treeroot, skipel, uuid):\n    for descendent in iterelementsbutskip(treeroot, skipel):\n        oldwgb = ''\n        if LIP + 'wasgeneratedby' in descendent.attrib:\n            oldwgb = descendent.attrib[LIP + 'wasgeneratedby']\n            pass\n        descendent.attrib[LIP + 'wasgeneratedby'] = oldwgb + 'uuid=' + uuid + ';'\n        pass\n"]]}
{"hexsha": "5b2e1ce6d66d773df80f4ca163042513cf4342b7", "ext": "py", "lang": "Python", "content": "@aiohttp_jinja2.template('index.html')\nasync def root(request):\n    print(request)\n    agent = request.app['agent']\n    agent.offer_endpoint = request.url.scheme + '://' + request.url.host\n    print(agent.offer_endpoint)\n    agent.endpoint = request.url.scheme + '://' + request.url.host\n    if request.url.port is not None:\n        agent.endpoint += ':' + str(request.url.port) + '/indy'\n        agent.offer_endpoint += ':' + str(request.url.port) + '/offer'\n    else:\n        agent.endpoint += '/indy'\n        agent.offer_endpoint += '/offer'\n    return {'ui_token': agent.ui_token}", "fn_id": 0, "class_fn": false, "repo": "unveil-social/indy-agent", "file": "python/modules/admin.py", "last_update_at": "2018-09-07T07:36:51+00:00", "question_id": "5b2e1ce6d66d773df80f4ca163042513cf4342b7_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@aiohttp_jinja2.template('index.html')\nasync def root(request):\n    print(request)\n    agent = request.app['agent']\n    agent.offer_endpoint = request.url.scheme + '://' + request.url.host\n    print(agent.offer_endpoint)\n    agent.endpoint = request.url.scheme + '://' + request.url.host\n    if request.url.port is not None:\n        agent.endpoint += ':' + str(request.url.port) + '/indy'\n        agent.offer_endpoint += ':' + str(request.url.port) + '/offer'\n    else:\n        agent.endpoint += '/indy'\n        agent.offer_endpoint += '/offer'\n"]]}
{"hexsha": "e587239959d45e22a6d7ce4487f4fb1c425fc866", "ext": "py", "lang": "Python", "content": "def bq_to_gcs(table, blob):  # type: (bigquery.TableReference, storage.Blob) -> None\n    bq = bigquery.Client()\n    extract_job = bq.extract_table(table, gcs_path(blob))\n    extract_job.result()", "fn_id": 0, "class_fn": false, "repo": "orisano/bqgcs", "file": "bqgcs/bq.py", "last_update_at": "2018-02-28T08:11:05+00:00", "question_id": "e587239959d45e22a6d7ce4487f4fb1c425fc866_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def bq_to_gcs(table, blob):\n    bq = bigquery.Client()\n    extract_job = bq.extract_table(table, gcs_path(blob))\n"]]}
{"hexsha": "8a34957e7780f695319c738019d5856b172ee9c5", "ext": "py", "lang": "Python", "content": "def load_data(nb_classes, PL, gParameters):\n    train_path=gParameters['train_path']\n    test_path=gParameters['test_path'] \n    outdir = gParameters['output_dir']\n    df_train = (pd.read_csv(train_path,header=None).values).astype('float32')\n    df_test = (pd.read_csv(test_path,header=None).values).astype('float32')\n\n    print('df_train shape:', df_train.shape)\n    print('df_test shape:', df_test.shape)\n\n    df_y_train = df_train[:,0].astype('int')\n    df_y_test = df_test[:,0].astype('int')\n\n    Y_train = np_utils.to_categorical(df_y_train,nb_classes)\n    train_classes = np.argmax(Y_train, axis=1)\n    np.savetxt(outdir+\"/train_classes.csv\", train_classes, delimiter=\",\", fmt=\"%d\")\n    \n    Y_test = np_utils.to_categorical(df_y_test,nb_classes)\n    test_classes = np.argmax(Y_test, axis=1)\n    np.savetxt(outdir+\"/test_classes.csv\", test_classes, delimiter=\",\", fmt=\"%d\")\n              \n    df_x_train = df_train[:, 1:PL].astype(np.float32)\n    df_x_test = df_test[:, 1:PL].astype(np.float32)\n            \n    # not sure the extra variable is needed, and is this a copy or reference\n    X_train = df_x_train\n    X_test = df_x_test\n            \n    scaler = MaxAbsScaler()\n    mat = np.concatenate((X_train, X_test), axis=0)\n    mat = scaler.fit_transform(mat)\n       \n    X_train = mat[:X_train.shape[0], :]\n    X_test = mat[X_train.shape[0]:, :]\n        \n    return X_train, Y_train, X_test, Y_test", "fn_id": 1, "class_fn": false, "repo": "brettin/candle_tutorials", "file": "Topics/1_migrating_your_DNN_to_candle/cc_t29res.py", "last_update_at": "2018-11-08T22:32:10+00:00", "question_id": "8a34957e7780f695319c738019d5856b172ee9c5_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def load_data(nb_classes, PL, gParameters):\n    train_path = gParameters['train_path']\n    test_path = gParameters['test_path']\n    outdir = gParameters['output_dir']\n    df_train = pd.read_csv(train_path, header=None).values.astype('float32')\n    df_test = pd.read_csv(test_path, header=None).values.astype('float32')\n    print('df_train shape:', df_train.shape)\n    print('df_test shape:', df_test.shape)\n    df_y_train = df_train[:, 0].astype('int')\n    df_y_test = df_test[:, 0].astype('int')\n    Y_train = np_utils.to_categorical(df_y_train, nb_classes)\n    train_classes = np.argmax(Y_train, axis=1)\n    np.savetxt(outdir + '/train_classes.csv', train_classes, delimiter=',', fmt='%d')\n    Y_test = np_utils.to_categorical(df_y_test, nb_classes)\n    test_classes = np.argmax(Y_test, axis=1)\n    np.savetxt(outdir + '/test_classes.csv', test_classes, delimiter=',', fmt='%d')\n    df_x_train = df_train[:, 1:PL].astype(np.float32)\n    df_x_test = df_test[:, 1:PL].astype(np.float32)\n    X_train = df_x_train\n    X_test = df_x_test\n    scaler = MaxAbsScaler()\n    mat = np.concatenate((X_train, X_test), axis=0)\n    mat = scaler.fit_transform(mat)\n    X_train = mat[:X_train.shape[0], :]\n    X_test = mat[X_train.shape[0]:, :]\n"]]}
{"hexsha": "7c5bbb49679574a12c70037527b70d8e9a56695f", "ext": "py", "lang": "Python", "content": "@unix\ndef test_popen_2():\n    command = Popen(['ls', '-la'])\n\n    assert command.communicate()[0] == run('ls -la').stdout", "fn_id": 3, "class_fn": false, "repo": "textioHQ/subprocess.run", "file": "tests.py", "last_update_at": "2018-03-13T23:03:17+00:00", "question_id": "7c5bbb49679574a12c70037527b70d8e9a56695f_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@unix\ndef test_popen_2():\n    command = Popen(['ls', '-la'])\n"]]}
{"hexsha": "54a89802d87fea559c56f88830b6e2a6e36c25e8", "ext": "py", "lang": "Python", "content": "def get_method_user_init():\n    User = get_user_model()\n    method_original = User.__init__\n\n    def method_init(self, *args, **kwargs):\n        _instance_extra_data = kwargs.pop('_instance_extra_data', {})\n        result = method_original(self, *args, **kwargs)\n        for key, value in _instance_extra_data.items():\n            setattr(self, key, value)\n\n        return result\n\n    return method_init", "fn_id": 4, "class_fn": false, "repo": "atitaya1412/Mayan-EDMS", "file": "mayan/apps/user_management/methods.py", "last_update_at": "2018-12-10T19:07:48+00:00", "question_id": "54a89802d87fea559c56f88830b6e2a6e36c25e8_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_method_user_init():\n    User = get_user_model()\n    method_original = User.__init__\n\n    def method_init(self, *args, **kwargs):\n        _instance_extra_data = kwargs.pop('_instance_extra_data', {})\n        result = method_original(self, *args, **kwargs)\n        for key, value in _instance_extra_data.items():\n            setattr(self, key, value)\n        return result\n"]]}
{"hexsha": "b15ca009ea22fb9c3447d2709388472b417f2fe8", "ext": "py", "lang": "Python", "content": "def main():\n    \"\"\"\n    Steps if script is run directly\n    \"\"\"\n    args = parse_args()\n\n    # Change log level if using verbose\n    if args.verbose:\n        logging.basicConfig(\n            format=\"%(levelname)s: %(message)s\",\n            level=logging.DEBUG)\n        logging.info(\"Verbose logging.\")\n        logging.debug(\"Supplied Arguments: %s\", args)\n        logging.debug(\"Version: %s\", VERINFO)\n    else:\n        logging.basicConfig(format=\"%(message)s\", level=logging.INFO)\n\n    lc_results = find_asg_using_amis(args.ami_ids)\n    ec2_results = find_ec2_using_amis(args.ami_ids)\n\n    output = {}\n    for ami_id in args.ami_ids:\n        output[ami_id] = {\n            'lcs': lc_results[ami_id],\n            'ec2': ec2_results[ami_id],\n            }\n    print(json.dumps(output))", "fn_id": 5, "class_fn": false, "repo": "rcuza/init", "file": "devops/awstools/miflow/mifind.py", "last_update_at": "2018-09-12T13:33:38+00:00", "question_id": "b15ca009ea22fb9c3447d2709388472b417f2fe8_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main():\n    \"\"\"\n    Steps if script is run directly\n    \"\"\"\n    args = parse_args()\n    if args.verbose:\n        logging.basicConfig(format='%(levelname)s: %(message)s', level=logging.DEBUG)\n        logging.info('Verbose logging.')\n        logging.debug('Supplied Arguments: %s', args)\n        logging.debug('Version: %s', VERINFO)\n    else:\n        logging.basicConfig(format='%(message)s', level=logging.INFO)\n    lc_results = find_asg_using_amis(args.ami_ids)\n    ec2_results = find_ec2_using_amis(args.ami_ids)\n    output = {}\n    for ami_id in args.ami_ids:\n        output[ami_id] = {'lcs': lc_results[ami_id], 'ec2': ec2_results[ami_id]}\n"]]}
{"hexsha": "38df47c9261a14b27353688a69c605924a32c6e3", "ext": "py", "lang": "Python", "content": "@_endpoint_route('/annotations/delete-paraphrase-question')\n@respond_with_json\n@requires_auth\ndef _delete_paraphrase_question(request):\n    question_id = required_parameter(request, 'questionId')\n    return {'questionId': question_id}", "fn_id": 36, "class_fn": false, "repo": "edwardmjackson/cape-frontend", "file": "cape_frontend/webapp/mocks/full/full_core.py", "last_update_at": "2018-08-15T14:19:58+00:00", "question_id": "38df47c9261a14b27353688a69c605924a32c6e3_36", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@_endpoint_route('/annotations/delete-paraphrase-question')\n@respond_with_json\n@requires_auth\ndef _delete_paraphrase_question(request):\n    question_id = required_parameter(request, 'questionId')\n"]]}
{"hexsha": "00a96ebd907765e144a48d9ec002f49b9336588e", "ext": "py", "lang": "Python", "content": "def update():\n    line_renderer.model.vertices = [e.position for e in points]\n    line_renderer.model.generate()\n    mover_2.look_at_2d(mover)\n    # mover_2.position += mover_2.up * mover_2.speed * time.dt\n    mover_2.position = lerp(mover_2.position, mover.position, time.dt*2)", "fn_id": 0, "class_fn": false, "repo": "MrBlueBlobGuy/ursina", "file": "samples/move_along_path.py", "last_update_at": "2018-05-17T20:06:04+00:00", "question_id": "00a96ebd907765e144a48d9ec002f49b9336588e_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def update():\n    line_renderer.model.vertices = [e.position for e in points]\n    line_renderer.model.generate()\n    mover_2.look_at_2d(mover)\n"]]}
{"hexsha": "9cf092a926a285d817b4ecc99e01425ac70af0b8", "ext": "py", "lang": "Python", "content": "def has_permission(permission):\n    def predicate(ctx):\n        if ctx.guild is None:\n            return False\n        if ctx.author.id == ctx.guild.owner_id:\n            return True\n        if ctx.author.id in config.admins:\n            return True\n        return has_permission_member(ctx.guild.id, ctx.author, permission)\n    return commands.check(predicate)", "fn_id": 5, "class_fn": false, "repo": "AEnterprise/kanelbulle", "file": "bot/utils/permissions.py", "last_update_at": "2018-10-31T19:07:53+00:00", "question_id": "9cf092a926a285d817b4ecc99e01425ac70af0b8_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def has_permission(permission):\n\n    def predicate(ctx):\n        if ctx.guild is None:\n            return False\n        if ctx.author.id == ctx.guild.owner_id:\n            return True\n        if ctx.author.id in config.admins:\n            return True\n        return has_permission_member(ctx.guild.id, ctx.author, permission)\n"]]}
{"hexsha": "84a2893af711539b1cd601c448f8e3a443d5c48d", "ext": "py", "lang": "Python", "content": "def strip_parens(text: str) -> str:\n    \"\"\" Remove any parentheses blocks. \"\"\"\n\n    stripped = text\n\n    # note that we search for paren blocks but only use the matches to find a starting position\n    # since parens can be nested inside other parens, we have to manually count opening and\n    # closing parens to find the entire block that we want to strip\n    pattern = re.compile(r'\\(.*?\\)', re.DOTALL)  # paren blocks can span more than one line\n\n    match = pattern.search(stripped)\n\n    while match is not None:\n        starting = match.start()\n        ending = starting\n\n        depth_count = 0\n\n        for c in text[starting:]:\n            if c == '(':\n                depth_count += 1\n            elif c == ')':\n                depth_count -= 1\n\n            ending += 1\n\n            if depth_count == 0:\n                break\n\n        block = text[starting:ending]\n        replacement = blanked(block)\n\n        stripped = stripped[:starting] + replacement + stripped[ending:]\n\n        match = pattern.search(stripped)\n\n    return stripped", "fn_id": 5, "class_fn": false, "repo": "jhauberg/comply", "file": "comply/util/stripping.py", "last_update_at": "2018-11-02T11:55:12+00:00", "question_id": "84a2893af711539b1cd601c448f8e3a443d5c48d_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def strip_parens(text: str) -> str:\n    \"\"\" Remove any parentheses blocks. \"\"\"\n    stripped = text\n    pattern = re.compile('\\\\(.*?\\\\)', re.DOTALL)\n    match = pattern.search(stripped)\n    while match is not None:\n        starting = match.start()\n        ending = starting\n        depth_count = 0\n        for c in text[starting:]:\n            if c == '(':\n                depth_count += 1\n            elif c == ')':\n                depth_count -= 1\n            ending += 1\n            if depth_count == 0:\n                break\n        block = text[starting:ending]\n        replacement = blanked(block)\n        stripped = stripped[:starting] + replacement + stripped[ending:]\n        match = pattern.search(stripped)\n"]]}
{"hexsha": "624d01d94f701f5e51d7157f58b97ca40947585f", "ext": "py", "lang": "Python", "content": "def _structured_value_screen(self, key, val):\n    '''A function for use as the screen method of a class built by :class:`StructuredValue`.\n\n       If `key` is not a supported field, raise :class:`KeyError`.\n       If `val` is not a supported lexical value type for field, raise :class:`TypeError`.\n       If `val` is not a supported lexical value for field, raise :class:`ValueError`.\n       Otherwise, return the canonical value for field from lexical value `val`.\n    '''\n    try:\n        return self.fields[key](val)\n    except KeyError:\n        raise KeyError('unsupported field for {}: {}'.format(self.name, key))\n    except ValueError:\n        raise ValueError('bad value for {} field {}: {}'.format(self.name, key, val))\n    except TypeError:\n        raise TypeError('bad value for {} field {}: {}'.format(self.name, key, val))", "fn_id": 2, "class_fn": false, "repo": "kot-begemot-uk/opx-dhcp", "file": "inocybe_dhcp/types.py", "last_update_at": "2018-09-14T07:15:17+00:00", "question_id": "624d01d94f701f5e51d7157f58b97ca40947585f_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _structured_value_screen(self, key, val):\n    \"\"\"A function for use as the screen method of a class built by :class:`StructuredValue`.\n\n       If `key` is not a supported field, raise :class:`KeyError`.\n       If `val` is not a supported lexical value type for field, raise :class:`TypeError`.\n       If `val` is not a supported lexical value for field, raise :class:`ValueError`.\n       Otherwise, return the canonical value for field from lexical value `val`.\n    \"\"\"\n    try:\n        return self.fields[key](val)\n    except KeyError:\n        raise KeyError('unsupported field for {}: {}'.format(self.name, key))\n    except ValueError:\n        raise ValueError('bad value for {} field {}: {}'.format(self.name, key, val))\n    except TypeError:\n"]]}
{"hexsha": "39b95e7b310ef689457c0d8b33b5bab26c2ec666", "ext": "py", "lang": "Python", "content": "@bp.route(\"/edit_recipe\", methods=[\"POST\"])\n@utils.gatekeeper()\ndef edit_recpie():\n    \"\"\"Edit a recipe that already exists in the data base.\"\"\"\n    try:\n        data = request.form.to_dict()\n        data = utils.deserialize(data)\n        data[\"user\"] = session.get(\"uid\")  # Store info about which user edited last\n        data[\"published\"] = False if data.get(\"published\", True).lower() == \"false\" else True\n        url = utils.make_url(data[\"title\"], data[\"id\"])\n        data[\"url\"] = url\n        image_file = request.files.get(\"image\")\n        if not image_file and not data[\"image\"]:\n            recipe = recipemodel.Recipe.get(recipemodel.Recipe.id == data[\"id\"])\n            if recipe.image:\n                try:\n                    utils.remove_file(utils.remove_file(os.path.join(current_app.config.get(\"IMAGE_PATH\"), recipe.image)))\n                except OSError:\n                    current_app.logger.warning(traceback.format_exc())\n        else:\n            save_image(data, data[\"id\"], image_file)\n        recipemodel.edit_recipe(data[\"id\"], data)\n        tagmodel.add_tags(data, data[\"id\"])\n        return utils.success_response(msg=\"Recipe saved\", url=url)\n\n    except Exception as e:\n        current_app.logger.error(traceback.format_exc())\n        return utils.error_response(f\"Failed to save data: {e}\"), 400", "fn_id": 8, "class_fn": false, "repo": "anne17/receptsida-backend", "file": "recapi/views/recipe_data.py", "last_update_at": "2018-12-09T20:39:33+00:00", "question_id": "39b95e7b310ef689457c0d8b33b5bab26c2ec666_8", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@bp.route('/edit_recipe', methods=['POST'])\n@utils.gatekeeper()\ndef edit_recpie():\n    \"\"\"Edit a recipe that already exists in the data base.\"\"\"\n    try:\n        data = request.form.to_dict()\n        data = utils.deserialize(data)\n        data['user'] = session.get('uid')\n        data['published'] = False if data.get('published', True).lower() == 'false' else True\n        url = utils.make_url(data['title'], data['id'])\n        data['url'] = url\n        image_file = request.files.get('image')\n        if not image_file and (not data['image']):\n            recipe = recipemodel.Recipe.get(recipemodel.Recipe.id == data['id'])\n            if recipe.image:\n                try:\n                    utils.remove_file(utils.remove_file(os.path.join(current_app.config.get('IMAGE_PATH'), recipe.image)))\n                except OSError:\n                    current_app.logger.warning(traceback.format_exc())\n        else:\n            save_image(data, data['id'], image_file)\n        recipemodel.edit_recipe(data['id'], data)\n        tagmodel.add_tags(data, data['id'])\n        return utils.success_response(msg='Recipe saved', url=url)\n    except Exception as e:\n        current_app.logger.error(traceback.format_exc())\n"]]}
{"hexsha": "309ccd53e1e00c54829cda0b87d065c0ada74854", "ext": "py", "lang": "Python", "content": "def t_COLON(t):\n    r\":\"\n    t.value = \":\"\n    return t", "fn_id": 3, "class_fn": false, "repo": "movermeyer/mt940", "file": "src/mt940/parser.py", "last_update_at": "2018-08-05T01:09:28+00:00", "question_id": "309ccd53e1e00c54829cda0b87d065c0ada74854_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def t_COLON(t):\n    \"\"\":\"\"\"\n    t.value = ':'\n"]]}
{"hexsha": "e4f1f10e63f81cf4c3b16e852831294914278b82", "ext": "py", "lang": "Python", "content": "def pick_dat(cols, initdir='RDAT', title=\"Select file\"):\n    \"\"\"\n    Data reader that is called within many other functions.\n    :param initdir: This is the directory that the function will open by default to look for the data (.csv or .h5).\n    :param title: The message to display at the top of the dialogue box.\n    :param cols: Headers to give to the data.\n    :return: Pandas DataFrame with headers that contains the selected data.\n    \"\"\"\n    root = Tk()\n    root.filename = filedialog.askopenfilename(initialdir=\"C:\\\\Users\\Josh\\IdeaProjects\\PulsedNMR\\{}\".format(initdir),\n                                               title=title)\n    filename_parts = root.filename.split('/')[-1]\n    if 'csv' in root.filename:\n        data = read_csv(root.filename, names=cols, engine='c')\n        return data, filename_parts\n    elif 'h5' in root.filename:\n        data = read_hdf(root.filename, 'table', names=cols, engine='c')\n        return data, filename_parts\n    else:\n        print('Unexpected file type. Choose either a .csv or .h5 file.')", "fn_id": 0, "class_fn": false, "repo": "JCCPort/PulsedNMR", "file": "main.py", "last_update_at": "2018-04-03T17:07:54+00:00", "question_id": "e4f1f10e63f81cf4c3b16e852831294914278b82_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def pick_dat(cols, initdir='RDAT', title='Select file'):\n    \"\"\"\n    Data reader that is called within many other functions.\n    :param initdir: This is the directory that the function will open by default to look for the data (.csv or .h5).\n    :param title: The message to display at the top of the dialogue box.\n    :param cols: Headers to give to the data.\n    :return: Pandas DataFrame with headers that contains the selected data.\n    \"\"\"\n    root = Tk()\n    root.filename = filedialog.askopenfilename(initialdir='C:\\\\Users\\\\Josh\\\\IdeaProjects\\\\PulsedNMR\\\\{}'.format(initdir), title=title)\n    filename_parts = root.filename.split('/')[-1]\n    if 'csv' in root.filename:\n        data = read_csv(root.filename, names=cols, engine='c')\n        return (data, filename_parts)\n    elif 'h5' in root.filename:\n        data = read_hdf(root.filename, 'table', names=cols, engine='c')\n        return (data, filename_parts)\n    else:\n"]]}
{"hexsha": "ab1453923530e269def244db6932ea0cea4bd9ab", "ext": "py", "lang": "Python", "content": "def read_struct_array(fd, endian, header):\n    \"\"\"Read a struct array.\n    Returns a dict with fields of the struct array.\n    \"\"\"\n    # read field name length (unused, as strings are null terminated)\n    field_name_length = read_elements(fd, endian, ['miINT32'])\n    if field_name_length > 32:\n        raise ParseError('Unexpected field name length: {}'.format(\n                         field_name_length))\n\n    # read field names\n    fields = read_elements(fd, endian, ['miINT8'], is_name=True)\n    if isinstance(fields, basestring):\n        fields = [fields]\n\n    # read rows and columns of each field\n    empty = lambda: [list() for i in range(header['dims'][0])]\n    array = {}\n    for row in range(header['dims'][0]):\n        for col in range(header['dims'][1]):\n            for field in fields:\n                # read the matrix header and array\n                vheader, next_pos, fd_var = read_var_header(fd, endian)\n                data = read_var_array(fd_var, endian, vheader)\n                if field not in array:\n                    array[field] = empty()\n                array[field][row].append(data)\n                # move on to next field\n                fd.seek(next_pos)\n    # pack the nested arrays\n    for field in fields:\n        rows = array[field]\n        for i in range(header['dims'][0]):\n            rows[i] = squeeze(rows[i])\n        array[field] = squeeze(array[field])\n    return array", "fn_id": 10, "class_fn": false, "repo": "sinodanish/mat4py", "file": "mat4py/loadmat.py", "last_update_at": "2018-08-14T11:39:09+00:00", "question_id": "ab1453923530e269def244db6932ea0cea4bd9ab_10", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def read_struct_array(fd, endian, header):\n    \"\"\"Read a struct array.\n    Returns a dict with fields of the struct array.\n    \"\"\"\n    field_name_length = read_elements(fd, endian, ['miINT32'])\n    if field_name_length > 32:\n        raise ParseError('Unexpected field name length: {}'.format(field_name_length))\n    fields = read_elements(fd, endian, ['miINT8'], is_name=True)\n    if isinstance(fields, basestring):\n        fields = [fields]\n    empty = lambda: [list() for i in range(header['dims'][0])]\n    array = {}\n    for row in range(header['dims'][0]):\n        for col in range(header['dims'][1]):\n            for field in fields:\n                vheader, next_pos, fd_var = read_var_header(fd, endian)\n                data = read_var_array(fd_var, endian, vheader)\n                if field not in array:\n                    array[field] = empty()\n                array[field][row].append(data)\n                fd.seek(next_pos)\n    for field in fields:\n        rows = array[field]\n        for i in range(header['dims'][0]):\n            rows[i] = squeeze(rows[i])\n        array[field] = squeeze(array[field])\n"]]}
{"hexsha": "828f5d89780c8fc50eda7c3391de3cc5e5055367", "ext": "py", "lang": "Python", "content": "def filter_candidates(candidates, select_variant_types):\n  \"\"\"Yields the candidate variants whose type is one of select_variant_types.\n\n  This function iterates through candidates and yield each candidate in order\n  if it satisfies any of the type constraints implied by select_variant_types.\n  For example, if select_variant_types = ['snps'] this function will yield\n  candidates that are bi-allelic SNPs only. Multiple select types are treated\n  as OR'd together, so ['snps', 'indels'] yields candidates that are bi-allelic\n  SNPs or indels.\n\n  Args:\n    candidates: Iterable of Variant protos. The candidates we want to select\n      from.\n    select_variant_types: List of str. The names of the variant type selectors\n      we want to use to keep/remove variants. Each string must be part of\n      VARIANT_TYPE_SELECTORS or an error will be raised.\n\n  Raises:\n    ValueError: if any str in select_variant_types isn't present in\n      VARIANT_TYPE_SELECTORS.\n\n  Yields:\n    Candidates in order.\n  \"\"\"\n  if not all(s in VARIANT_TYPE_SELECTORS for s in select_variant_types):\n    raise ValueError('Unexpected select variant type', select_variant_types)\n\n  for candidate in candidates:\n    v = candidate.variant\n    for select_type in select_variant_types:\n      selector = VARIANT_TYPE_SELECTORS[select_type]\n      if selector(v):\n        yield candidate\n        break", "fn_id": 16, "class_fn": false, "repo": "serge2016/deepvariant", "file": "deepvariant/make_examples_core.py", "last_update_at": "2018-10-11T22:40:22+00:00", "question_id": "828f5d89780c8fc50eda7c3391de3cc5e5055367_16", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def filter_candidates(candidates, select_variant_types):\n    \"\"\"Yields the candidate variants whose type is one of select_variant_types.\n\n  This function iterates through candidates and yield each candidate in order\n  if it satisfies any of the type constraints implied by select_variant_types.\n  For example, if select_variant_types = ['snps'] this function will yield\n  candidates that are bi-allelic SNPs only. Multiple select types are treated\n  as OR'd together, so ['snps', 'indels'] yields candidates that are bi-allelic\n  SNPs or indels.\n\n  Args:\n    candidates: Iterable of Variant protos. The candidates we want to select\n      from.\n    select_variant_types: List of str. The names of the variant type selectors\n      we want to use to keep/remove variants. Each string must be part of\n      VARIANT_TYPE_SELECTORS or an error will be raised.\n\n  Raises:\n    ValueError: if any str in select_variant_types isn't present in\n      VARIANT_TYPE_SELECTORS.\n\n  Yields:\n    Candidates in order.\n  \"\"\"\n    if not all((s in VARIANT_TYPE_SELECTORS for s in select_variant_types)):\n        raise ValueError('Unexpected select variant type', select_variant_types)\n    for candidate in candidates:\n        v = candidate.variant\n        for select_type in select_variant_types:\n            selector = VARIANT_TYPE_SELECTORS[select_type]\n            if selector(v):\n                yield candidate\n"]]}
{"hexsha": "aa3a4fa744b7067b924e6a35d22ff8d6899b4410", "ext": "py", "lang": "Python", "content": "@add_.register(nd.NDArray)\ndef _(x , a, y):\n    if a is 0: return\n    if a is 1: x[:] += y\n    else: x[:] += a*y", "fn_id": 12, "class_fn": false, "repo": "davidcpage/gamma", "file": "gamma/mxnet.py", "last_update_at": "2018-02-05T17:32:39+00:00", "question_id": "aa3a4fa744b7067b924e6a35d22ff8d6899b4410_12", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@add_.register(nd.NDArray)\ndef _(x, a, y):\n    if a is 0:\n        return\n    if a is 1:\n        x[:] += y\n    else:\n"]]}
{"hexsha": "a81c57f6681f6f3b6919557e9362fc190809d5a0", "ext": "py", "lang": "Python", "content": "def process_rows(db_url, sql, uuid_dict):\n    connection = make_db_connection(db_url)\n    try:\n        cursor = connection.cursor()\n        cursor.execute(sql)\n        with tqdm(desc=sql) as pbar:\n            row = cursor.fetchone()\n            pbar.update()\n            while row:\n                (key, uuid, size) = row\n                uuid_dict[uuid] = (key, size)\n                row = cursor.fetchone()\n                pbar.update()\n    finally:\n        connection.close()", "fn_id": 0, "class_fn": false, "repo": "PLOS/content-repo", "file": "gcsmigrate/check-versions.py", "last_update_at": "2018-10-30T20:50:32+00:00", "question_id": "a81c57f6681f6f3b6919557e9362fc190809d5a0_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def process_rows(db_url, sql, uuid_dict):\n    connection = make_db_connection(db_url)\n    try:\n        cursor = connection.cursor()\n        cursor.execute(sql)\n        with tqdm(desc=sql) as pbar:\n            row = cursor.fetchone()\n            pbar.update()\n            while row:\n                key, uuid, size = row\n                uuid_dict[uuid] = (key, size)\n                row = cursor.fetchone()\n                pbar.update()\n    finally:\n"]]}
{"hexsha": "f37cafaf66bf50f3beea539655b834171e43f9f3", "ext": "py", "lang": "Python", "content": "def test_insertShiftArray_length():\n    \"\"\"Checks for length aftering inserting value into array\"\"\"\n    arr = shift_array.insertShiftArray(testArray, 100)\n    assert len(arr) == 5", "fn_id": 1, "class_fn": false, "repo": "GeorgeCloud/data-structures-and-algorithms", "file": "challenges/shift_array/test_shift_array.py", "last_update_at": "2018-05-01T06:40:26+00:00", "question_id": "f37cafaf66bf50f3beea539655b834171e43f9f3_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_insertShiftArray_length():\n    \"\"\"Checks for length aftering inserting value into array\"\"\"\n    arr = shift_array.insertShiftArray(testArray, 100)\n"]]}
{"hexsha": "8875c72c11f22dea78b588ad39cb3064d09651fa", "ext": "py", "lang": "Python", "content": "def test_add_label(session):\n    #Add a node with type disease\n    create_node(session)\n    #Now, have the same identifier, but a subclass\n    node = KNode(TEST_ID, node_types.GENETIC_CONDITION)\n    #export, and pull the node\n    export_node(node,session)\n    rounder = get_node(TEST_ID,session)\n    assert len(rounder.labels) == 2\n    assert node_types.DISEASE in rounder.labels\n    assert node_types.GENETIC_CONDITION in rounder.labels", "fn_id": 4, "class_fn": false, "repo": "NCATS-Gamma/protocop", "file": "builder/test/test_graphdb_update.py", "last_update_at": "2018-11-05T07:37:10+00:00", "question_id": "8875c72c11f22dea78b588ad39cb3064d09651fa_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_add_label(session):\n    create_node(session)\n    node = KNode(TEST_ID, node_types.GENETIC_CONDITION)\n    export_node(node, session)\n    rounder = get_node(TEST_ID, session)\n    assert len(rounder.labels) == 2\n    assert node_types.DISEASE in rounder.labels\n"]]}
{"hexsha": "0ecb8aaf798556d79dff55a03c6528ada755164d", "ext": "py", "lang": "Python", "content": "@pytest.mark.parametrize(\n    \"model_args,expected\",\n    test_data,\n    ids=[\"scalar\", \"vector\", \"matrix\", \"3D array\"],\n)\ndef test_get_cons(model_args, expected):\n    # Test consumption calculation\n    r, w, b, b_splus1, n, bq, net_tax, tau_c, p = model_args\n    test_value = household.get_cons(\n        r, w, b, b_splus1, n, bq, net_tax, p.e, tau_c, p\n    )\n\n    assert np.allclose(test_value, expected)", "fn_id": 4, "class_fn": false, "repo": "open-source-economics/OG-USA", "file": "tests/test_household.py", "last_update_at": "2018-11-28T13:43:51+00:00", "question_id": "0ecb8aaf798556d79dff55a03c6528ada755164d_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.mark.parametrize('model_args,expected', test_data, ids=['scalar', 'vector', 'matrix', '3D array'])\ndef test_get_cons(model_args, expected):\n    r, w, b, b_splus1, n, bq, net_tax, tau_c, p = model_args\n    test_value = household.get_cons(r, w, b, b_splus1, n, bq, net_tax, p.e, tau_c, p)\n"]]}
{"hexsha": "2de2428529b8f22f30f1acb09075bf5cad5f0428", "ext": "py", "lang": "Python", "content": "def gauss_kl_white_diag(q_mu, q_sqrt, num_latent):\n    \"\"\"\n    Compute the KL divergence from \n\n          q(x) = N(q_mu, q_sqrt^2)\n    to \n          p(x) = N(0, I)\n\n    We assume num_latent independent distributions, given by the columns of\n    q_mu and q_sqrt. \n\n    q_mu is a matrix, each column contains a mean\n\n    q_sqrt is a matrix, each columnt represents the diagonal of a square-root\n        matrix of the covariance. \n\n    num_latent is an integer: the number of independent distributions (equal to\n        the columns of q_mu and q_sqrt). \n    \"\"\"\n \n    KL = 0.5*tf.reduce_sum(tf.square(q_mu)) #Mahalanobis term\n    KL += -0.5*tf.cast(tf.shape(q_sqrt)[0]*num_latent, tf.float64) #Constant term.\n    KL += -0.5*tf.reduce_sum(tf.log(tf.square(q_sqrt)))#Log determinant of q covariance.\n    KL += 0.5*tf.reduce_sum(tf.square(q_sqrt)) # Trace term\n    return KL", "fn_id": 1, "class_fn": false, "repo": "ShuaiW/GPflow", "file": "GPflow/kullback_leiblers.py", "last_update_at": "2018-03-31T06:56:45+00:00", "question_id": "2de2428529b8f22f30f1acb09075bf5cad5f0428_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def gauss_kl_white_diag(q_mu, q_sqrt, num_latent):\n    \"\"\"\n    Compute the KL divergence from \n\n          q(x) = N(q_mu, q_sqrt^2)\n    to \n          p(x) = N(0, I)\n\n    We assume num_latent independent distributions, given by the columns of\n    q_mu and q_sqrt. \n\n    q_mu is a matrix, each column contains a mean\n\n    q_sqrt is a matrix, each columnt represents the diagonal of a square-root\n        matrix of the covariance. \n\n    num_latent is an integer: the number of independent distributions (equal to\n        the columns of q_mu and q_sqrt). \n    \"\"\"\n    KL = 0.5 * tf.reduce_sum(tf.square(q_mu))\n    KL += -0.5 * tf.cast(tf.shape(q_sqrt)[0] * num_latent, tf.float64)\n    KL += -0.5 * tf.reduce_sum(tf.log(tf.square(q_sqrt)))\n    KL += 0.5 * tf.reduce_sum(tf.square(q_sqrt))\n"]]}
{"hexsha": "bf0522d34b8ae7d7fdc3e3249a39882fc2a58087", "ext": "py", "lang": "Python", "content": "@blueprint.get('/<uuid:user_id>/unsuspend')\n@permission_required('user.administrate')\n@templated\ndef unsuspend_account_form(user_id, erroneous_form=None):\n    \"\"\"Show form to unsuspend the user account.\"\"\"\n    user = _get_user_for_admin_or_404(user_id)\n\n    if not user.suspended:\n        flash_error(\n            gettext(\n                \"User '%(screen_name)s' is not suspended.\",\n                screen_name=user.screen_name,\n            )\n        )\n        return redirect_to('.view', user_id=user.id)\n\n    form = erroneous_form if erroneous_form else SuspendAccountForm()\n\n    return {\n        'profile_user': user,\n        'user': user,\n        'form': form,\n    }", "fn_id": 8, "class_fn": false, "repo": "homeworkprod/byceps", "file": "byceps/blueprints/admin/user/views.py", "last_update_at": "2018-12-12T20:11:45+00:00", "question_id": "bf0522d34b8ae7d7fdc3e3249a39882fc2a58087_8", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@blueprint.get('/<uuid:user_id>/unsuspend')\n@permission_required('user.administrate')\n@templated\ndef unsuspend_account_form(user_id, erroneous_form=None):\n    \"\"\"Show form to unsuspend the user account.\"\"\"\n    user = _get_user_for_admin_or_404(user_id)\n    if not user.suspended:\n        flash_error(gettext(\"User '%(screen_name)s' is not suspended.\", screen_name=user.screen_name))\n        return redirect_to('.view', user_id=user.id)\n    form = erroneous_form if erroneous_form else SuspendAccountForm()\n"]]}
{"hexsha": "52f79f12acb6e6b69ab5c09a6d8066d3316782da", "ext": "py", "lang": "Python", "content": "def load_quandl_tickers(tickers_path):\n    df = pd.read_csv(tickers_path, header=None)\n    df.columns = ['Ticker','Name']\n    df = df[df.Name.str.contains(\"\\(EQ(.+)\\) Unadjusted\")]\n    tickers = [re.search(\"\\(EQ(.+)\\) Unadjusted\",s).group(1) for s in df.Name.tolist()]\n    names = [s.split(' (EQ'+tickers[i])[0] for i,s in enumerate(df.Name.tolist())]\n    names = [s.split(\"Ltd\")[0].strip() for s in names]\n    quandl_tickers = df.Ticker.tolist()\n    df_dict = {'symbol':tickers,'qsymbol':quandl_tickers, 'name':names}\n    tickers = pd.DataFrame(df_dict,columns=['symbol','qsymbol','name'])\n    return tickers", "fn_id": 1, "class_fn": false, "repo": "prodipta/zipline", "file": "zipline/data/bundles/xnse_ingest_loop.py", "last_update_at": "2018-04-27T04:40:12+00:00", "question_id": "52f79f12acb6e6b69ab5c09a6d8066d3316782da_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def load_quandl_tickers(tickers_path):\n    df = pd.read_csv(tickers_path, header=None)\n    df.columns = ['Ticker', 'Name']\n    df = df[df.Name.str.contains('\\\\(EQ(.+)\\\\) Unadjusted')]\n    tickers = [re.search('\\\\(EQ(.+)\\\\) Unadjusted', s).group(1) for s in df.Name.tolist()]\n    names = [s.split(' (EQ' + tickers[i])[0] for i, s in enumerate(df.Name.tolist())]\n    names = [s.split('Ltd')[0].strip() for s in names]\n    quandl_tickers = df.Ticker.tolist()\n    df_dict = {'symbol': tickers, 'qsymbol': quandl_tickers, 'name': names}\n    tickers = pd.DataFrame(df_dict, columns=['symbol', 'qsymbol', 'name'])\n"]]}
{"hexsha": "70adbf8b9fdaae431948c68fd9cf7d35b7eaa6c4", "ext": "py", "lang": "Python", "content": "def query_for_exptimes(targname, proposid, filt, dateobs=''):\n    \"\"\"Queries FileInfo for exposure times. Assumes querying either by \n    proposid or dateobs. If Dateobs, will query in a range of 30 days.\n\n    Parameters:\n        targname : string\n            Name of the target cluster.\n        proposid : string\n            Proposal number. If equals '', then query by just filter.\n        filt : string\n            Name of the filter.\n        dateobs : float\n            MJD date of observation. If equals '', then query just by \n            proposal number.\n\n    Returns:\n        exptimes : list of floats\n            Exposure times.\n\n    Outputs:\n        nothing\n    \"\"\"\n    FileInfo, Master, Phot, Results = return_tables(targname) \n\n    if proposid == '':\n        query = session.query(FileInfo.exptime)\\\n           .filter(FileInfo.filter == filt).all()\n    elif proposid != '' and dateobs == '':\n        query = session.query(FileInfo.exptime)\\\n                .filter(FileInfo.proposid == proposid)\\\n                .filter(FileInfo.filter == filt).all()\n\n    elif dateobs != '':\n        query = session.query(FileInfo.exptime)\\\n                .filter(FileInfo.filter == filt)\\\n                .filter(FileInfo.dateobs <= dateobs+30.)\\\n                .filter(FileInfo.dateobs >= dateobs-30.).all()\n\n    exptimes = [result[0] for result in query]\n\n    return exptimes", "fn_id": 3, "class_fn": false, "repo": "cgosmeyer/wfc3_cte_monitor", "file": "wfc3_cte_monitor/database_queries.py", "last_update_at": "2018-07-17T20:00:20+00:00", "question_id": "70adbf8b9fdaae431948c68fd9cf7d35b7eaa6c4_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def query_for_exptimes(targname, proposid, filt, dateobs=''):\n    \"\"\"Queries FileInfo for exposure times. Assumes querying either by \n    proposid or dateobs. If Dateobs, will query in a range of 30 days.\n\n    Parameters:\n        targname : string\n            Name of the target cluster.\n        proposid : string\n            Proposal number. If equals '', then query by just filter.\n        filt : string\n            Name of the filter.\n        dateobs : float\n            MJD date of observation. If equals '', then query just by \n            proposal number.\n\n    Returns:\n        exptimes : list of floats\n            Exposure times.\n\n    Outputs:\n        nothing\n    \"\"\"\n    FileInfo, Master, Phot, Results = return_tables(targname)\n    if proposid == '':\n        query = session.query(FileInfo.exptime).filter(FileInfo.filter == filt).all()\n    elif proposid != '' and dateobs == '':\n        query = session.query(FileInfo.exptime).filter(FileInfo.proposid == proposid).filter(FileInfo.filter == filt).all()\n    elif dateobs != '':\n        query = session.query(FileInfo.exptime).filter(FileInfo.filter == filt).filter(FileInfo.dateobs <= dateobs + 30.0).filter(FileInfo.dateobs >= dateobs - 30.0).all()\n    exptimes = [result[0] for result in query]\n"]]}
{"hexsha": "b1cbd1c9e79eba860e76bd0bb1560ecd424ba8d7", "ext": "py", "lang": "Python", "content": "def create_fake_random_string(length: int) -> str:\n    assert length > 0\n\n    md5_list = [get_md5(create_guid().encode(\"utf-8\")) for _ in range(math.ceil(length / 30) + 1)]\n\n    return \"\".join(md5_list)[:length]", "fn_id": 0, "class_fn": false, "repo": "frkhit/pyxtools", "file": "pyxtools/basic_tools/md5_tools.py", "last_update_at": "2018-11-24T12:36:03+00:00", "question_id": "b1cbd1c9e79eba860e76bd0bb1560ecd424ba8d7_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def create_fake_random_string(length: int) -> str:\n    assert length > 0\n    md5_list = [get_md5(create_guid().encode('utf-8')) for _ in range(math.ceil(length / 30) + 1)]\n"]]}
{"hexsha": "98b02d7ee5a90de461996e55891fb796e6e7e795", "ext": "py", "lang": "Python", "content": "def _get_families(req):\n    families = [f for f in req.params.get('family', '').split(',') if f]\n    if families:\n        return DBSession.query(Languoid).filter(Languoid.id.in_(families)).all()\n    return []", "fn_id": 3, "class_fn": false, "repo": "uwblueprint/glottolog3", "file": "glottolog3/langdocstatus.py", "last_update_at": "2018-04-18T02:07:04+00:00", "question_id": "98b02d7ee5a90de461996e55891fb796e6e7e795_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _get_families(req):\n    families = [f for f in req.params.get('family', '').split(',') if f]\n    if families:\n        return DBSession.query(Languoid).filter(Languoid.id.in_(families)).all()\n"]]}
{"hexsha": "d4cb0cc6d7a63e94ae40b4bd4009e81ad2f8c88c", "ext": "py", "lang": "Python", "content": "def checkarguments():\n    global lval\n\n    if len(sys.argv) != 2:\n        return\n\n    if sys.argv[1] == \"debug\":\n        run_test()\n        time.sleep(2)\n        sensors.stop()\n        webserver.stop()\n        log.info(\"main\", \"exit (debug)\")\n        GPIO.cleanup()\n        exit()\n    if sys.argv[1] == \"fakeval\":\n        analyze(\"$1;1;;10,1;20,2;30,3;40,4;50,5;60,6;70,7;80,8;90,9;10,1;11,2;12,3;13,4;14,5;15,6;16,7\")\n        lval = list(values)\n        lval[0] = \"8.8\"\n        lval[1] = \"22.5\"\n        once_a_hour()\n        once_a_day(0)\n        analyze(\"$1;1;;10,1;20,2;30,3;40,4;50,5;60,6;70,7;80,8;90,9;10,1;11,2;12,3;13,4;14,5;15,6;16,7\")\n\n    return", "fn_id": 8, "class_fn": false, "repo": "lapis133/Decoding-USB-WDE1-2", "file": "serialmon_01.py", "last_update_at": "2018-05-20T10:33:36+00:00", "question_id": "d4cb0cc6d7a63e94ae40b4bd4009e81ad2f8c88c_8", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def checkarguments():\n    global lval\n    if len(sys.argv) != 2:\n        return\n    if sys.argv[1] == 'debug':\n        run_test()\n        time.sleep(2)\n        sensors.stop()\n        webserver.stop()\n        log.info('main', 'exit (debug)')\n        GPIO.cleanup()\n        exit()\n    if sys.argv[1] == 'fakeval':\n        analyze('$1;1;;10,1;20,2;30,3;40,4;50,5;60,6;70,7;80,8;90,9;10,1;11,2;12,3;13,4;14,5;15,6;16,7')\n        lval = list(values)\n        lval[0] = '8.8'\n        lval[1] = '22.5'\n        once_a_hour()\n        once_a_day(0)\n        analyze('$1;1;;10,1;20,2;30,3;40,4;50,5;60,6;70,7;80,8;90,9;10,1;11,2;12,3;13,4;14,5;15,6;16,7')\n"]]}
{"hexsha": "b729daa5f12ea230cfe0dff6099efd889b2bedff", "ext": "py", "lang": "Python", "content": "def analyze_variational_sampling(autoencoder: vae.VariationalAutoEncoder, shape: [int], low: float, high: float, savedir: str, ndims: int, frequencies: [float], times: [float]) -> None:\n    \"\"\"\n    If a Variational AE, this samples from latent space and plots a swathe of spectrograms.\n    \"\"\"\n    if ndims < 3:\n        testvae._plot_samples_from_latent_space(autoencoder, shape, savedir, frequencies, times, ndims)\n        testvae._plot_topographic_swathe(autoencoder, shape, low, high, savedir, frequencies, times, ndims)", "fn_id": 3, "class_fn": false, "repo": "MaxStrange/ArtieInfant", "file": "Artie/experiment/analysis/ae.py", "last_update_at": "2018-04-28T16:55:05+00:00", "question_id": "b729daa5f12ea230cfe0dff6099efd889b2bedff_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def analyze_variational_sampling(autoencoder: vae.VariationalAutoEncoder, shape: [int], low: float, high: float, savedir: str, ndims: int, frequencies: [float], times: [float]) -> None:\n    \"\"\"\n    If a Variational AE, this samples from latent space and plots a swathe of spectrograms.\n    \"\"\"\n    if ndims < 3:\n        testvae._plot_samples_from_latent_space(autoencoder, shape, savedir, frequencies, times, ndims)\n"]]}
{"hexsha": "08d2f5a01d17227166db812376a83627a485d222", "ext": "py", "lang": "Python", "content": "def test_predictWoolf_f1fOREST():\n\tclassifierType = 'fOREST'\n\tscalerString = 'None'\n\tcvFolds = 5\n\tscoringM = 'accuracy'\n\tnNhrs = range(15,20)\n\tnTrs = range(1,15,2)\n\tminL = range(10,30,3)\n\tinputCSV = classBDtable\n\n\tmodel = woolfClassifier.buildWoolf(classifierType, scalerString, cvFolds, scoringM, nNhrs, nTrs, minL)\n\twoolfClassifier.trainModel(model, inputCSV)\n\tresultsDict, score = woolfClassifier.predictWoolf(model, inputCSV)\n\tassert model.best_score_ == 0.9777777777777779\n\tassert resultsDict['AAM63403.1'] == 1\n\tassert score == 1", "fn_id": 6, "class_fn": false, "repo": "kescobo/Woolf", "file": "tests/test_woolfClassifier.py", "last_update_at": "2018-11-01T14:50:55+00:00", "question_id": "08d2f5a01d17227166db812376a83627a485d222_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_predictWoolf_f1fOREST():\n    classifierType = 'fOREST'\n    scalerString = 'None'\n    cvFolds = 5\n    scoringM = 'accuracy'\n    nNhrs = range(15, 20)\n    nTrs = range(1, 15, 2)\n    minL = range(10, 30, 3)\n    inputCSV = classBDtable\n    model = woolfClassifier.buildWoolf(classifierType, scalerString, cvFolds, scoringM, nNhrs, nTrs, minL)\n    woolfClassifier.trainModel(model, inputCSV)\n    resultsDict, score = woolfClassifier.predictWoolf(model, inputCSV)\n    assert model.best_score_ == 0.9777777777777779\n    assert resultsDict['AAM63403.1'] == 1\n"]]}
{"hexsha": "84534447ea7ed77ef1df250535cfd0fadca4a84d", "ext": "py", "lang": "Python", "content": "def OnImportHdf(event):\n\tpath_temp=''\n\tpath_temp='python '+path+'proc_hdf_in.py'\n\twx.Execute(path_temp, False)", "fn_id": 3, "class_fn": false, "repo": "YannChemin/wxGIPE", "file": "gipe_tools.py", "last_update_at": "2018-11-12T02:46:11+00:00", "question_id": "84534447ea7ed77ef1df250535cfd0fadca4a84d_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def OnImportHdf(event):\n    path_temp = ''\n    path_temp = 'python ' + path + 'proc_hdf_in.py'\n"]]}
{"hexsha": "553f2162c7f843d98b3a831692120442cf00ce2a", "ext": "py", "lang": "Python", "content": "def add_local_dep(confspec):\n    \"Add local project relative paths.\"\n\n    links = confspec['links']\n    links['include/math'] = \"../../../tksrc/src/math\"\n    links['include/models'] = \"../../../tksrc/src/models\"\n    links['include/utils'] = \"../../../tksrc/src/utils\"\n\n    so_suffix = confspec['so-suffix']\n    for module in ('Math', 'Models', 'Utils'):\n        lib_so = 'libfmtk%s.%s' % (module, so_suffix)\n        subdir = module.lower()\n        links['lib/' + lib_so] = \"../../../src/%s/%s\" % (subdir, lib_so)", "fn_id": 2, "class_fn": false, "repo": "kwan0xfff/fmtk", "file": "tools/lib/quickstart/fmtk.py", "last_update_at": "2018-10-02T03:16:07+00:00", "question_id": "553f2162c7f843d98b3a831692120442cf00ce2a_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def add_local_dep(confspec):\n    \"\"\"Add local project relative paths.\"\"\"\n    links = confspec['links']\n    links['include/math'] = '../../../tksrc/src/math'\n    links['include/models'] = '../../../tksrc/src/models'\n    links['include/utils'] = '../../../tksrc/src/utils'\n    so_suffix = confspec['so-suffix']\n    for module in ('Math', 'Models', 'Utils'):\n        lib_so = 'libfmtk%s.%s' % (module, so_suffix)\n        subdir = module.lower()\n"]]}
{"hexsha": "312c418a2503ed30629cb40e75e01138460f851f", "ext": "py", "lang": "Python", "content": "@pytest.fixture(scope=\"session\")\ndef session_dir(request):\n    # Temporary directory that gets deleted at the session\n    # pytest tmpdir doesn't support a non-function scoped temporary directory\n    session_dir = Path(tempfile.mkdtemp())\n    request.addfinalizer(lambda: rmtree(session_dir))\n    return session_dir", "fn_id": 1, "class_fn": false, "repo": "rohitagarwal0910/vvp-cnf-validation-scripts", "file": "ice_validator/app_tests/preload_tests/test_vnfapi.py", "last_update_at": "2018-08-29T19:33:22+00:00", "question_id": "312c418a2503ed30629cb40e75e01138460f851f_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.fixture(scope='session')\ndef session_dir(request):\n    session_dir = Path(tempfile.mkdtemp())\n    request.addfinalizer(lambda: rmtree(session_dir))\n"]]}
{"hexsha": "a1eba867e80691245a78e1eced9a5e14863b5e36", "ext": "py", "lang": "Python", "content": "def init( i ):\n    xparser.parse_file( i )\n    \n    # To make sure the necessary folders exist.\n    os.system(\"mkdir -p \" + config.output_folder + \" >/dev/null\")\n    os.system(\"mkdir -p \" + config.presets_folder + \" >/dev/null\")\n\n    # Python's file operations do not support tilde (~), so they can be replaced with the users home directory ($HOME).\n    config.presets_folder = config.presets_folder.replace( \"~\", os.path.expanduser(\"~\") )\n    config.output_folder = config.output_folder.replace( \"~\", os.path.expanduser(\"~\") )\n\n    for i in os.listdir( os.path.join( xparser.cwd, config.presets_folder ) ):\n        handle_file( i )", "fn_id": 1, "class_fn": false, "repo": "madstk1/cg", "file": "cg.py", "last_update_at": "2018-12-10T19:04:03+00:00", "question_id": "a1eba867e80691245a78e1eced9a5e14863b5e36_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def init(i):\n    xparser.parse_file(i)\n    os.system('mkdir -p ' + config.output_folder + ' >/dev/null')\n    os.system('mkdir -p ' + config.presets_folder + ' >/dev/null')\n    config.presets_folder = config.presets_folder.replace('~', os.path.expanduser('~'))\n    config.output_folder = config.output_folder.replace('~', os.path.expanduser('~'))\n    for i in os.listdir(os.path.join(xparser.cwd, config.presets_folder)):\n"]]}
{"hexsha": "ec1cc5b117d52708295b3193208fc2c8a9d02fe7", "ext": "py", "lang": "Python", "content": "def send_file(sftp, target_file, source_path):\n    \"\"\"\n    Upload @source_path to @target_dir through @sftp\n    \"\"\"\n    with open(source_path, 'rb') as fSource:\n        with sftp.file(target_file, 'wb') as fTarget:\n            while True:\n                copy_buffer = fSource.read(4096)\n                if not copy_buffer:\n                    break\n                fTarget.write(copy_buffer)", "fn_id": 6, "class_fn": false, "repo": "tomsik68/distribench", "file": "distribute_benchmarks.py", "last_update_at": "2018-09-12T06:35:35+00:00", "question_id": "ec1cc5b117d52708295b3193208fc2c8a9d02fe7_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def send_file(sftp, target_file, source_path):\n    \"\"\"\n    Upload @source_path to @target_dir through @sftp\n    \"\"\"\n    with open(source_path, 'rb') as fSource:\n        with sftp.file(target_file, 'wb') as fTarget:\n            while True:\n                copy_buffer = fSource.read(4096)\n                if not copy_buffer:\n                    break\n"]]}
{"hexsha": "da8a9ba0fab63b56e2c89a36aa0cdd84854970ce", "ext": "py", "lang": "Python", "content": "def get_hostname():\n    \"\"\"\n    Gets the hostname of the system\n    \"\"\"\n    return {'HOSTNAME': socket.getfqdn()}", "fn_id": 2, "class_fn": false, "repo": "abidaan/metrics-monitor", "file": "src/sys_info.py", "last_update_at": "2018-04-26T15:57:51+00:00", "question_id": "da8a9ba0fab63b56e2c89a36aa0cdd84854970ce_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_hostname():\n    \"\"\"\n    Gets the hostname of the system\n    \"\"\"\n"]]}
{"hexsha": "843939e1080a3e1d6989a28073c7853ea42c9d1e", "ext": "py", "lang": "Python", "content": "def evalVertLocations(ob):    \n    verts = {}\n    for v in ob.data.vertices:\n        verts[v.index] = v.co.copy()\n    for skey in ob.data.shape_keys.key_blocks:\n        if skey.name == \"Basis\":\n            continue       \n        for n,v in enumerate(skey.data):\n            bv = ob.data.vertices[n]\n            vec = v.co - bv.co\n            verts[n] += skey.value*vec\n    return verts            ", "fn_id": 3, "class_fn": false, "repo": "teddydragoone/makehuman1.0.0alpha7", "file": "tools/blender26x/maketarget/maketarget.py", "last_update_at": "2018-02-13T04:18:23+00:00", "question_id": "843939e1080a3e1d6989a28073c7853ea42c9d1e_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def evalVertLocations(ob):\n    verts = {}\n    for v in ob.data.vertices:\n        verts[v.index] = v.co.copy()\n    for skey in ob.data.shape_keys.key_blocks:\n        if skey.name == 'Basis':\n            continue\n        for n, v in enumerate(skey.data):\n            bv = ob.data.vertices[n]\n            vec = v.co - bv.co\n            verts[n] += skey.value * vec\n"]]}
{"hexsha": "2b053e5ce8173dec6b079e08e571935d22125f2f", "ext": "py", "lang": "Python", "content": "@FFF_POST.route('/api/v1/orders', methods=['POST'])\ndef place_order():\n    \"\"\"\n     method to create new order and apend to the existing list\n    \"\"\"\n    if request.method == 'POST':\n        data = request.get_json()\n        if not data.get('order_number'):\n            return FeedbackResponse.display(\"set order number please\", 406)\n        if not data.get('order_description'):\n            return FeedbackResponse.display(\"set description please\", 406)\n        if not data.get('size'):\n            return FeedbackResponse.display(\"set size please \", 406)\n        if not data.get('order_price'):\n            return FeedbackResponse.display(\"set price please\", 406)\n        order_number = data.get('order_number')\n        order_description = data.get('order_description')\n        order_price = data.get('order_price')\n        size = data.get('size')\n\n        new_order = Order(order_number, order_description,\n                          order_price, size)\n\n        customer_orders.place_order(new_order)\n        return FeedbackResponse.display(\n            \"order number \" +\n            order_number +\n            \" successfully placed\",\n            200)", "fn_id": 0, "class_fn": false, "repo": "Gfreedoms/Fast-Food-Fast", "file": "app/api/views/place_order.py", "last_update_at": "2018-09-29T10:59:00+00:00", "question_id": "2b053e5ce8173dec6b079e08e571935d22125f2f_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@FFF_POST.route('/api/v1/orders', methods=['POST'])\ndef place_order():\n    \"\"\"\n     method to create new order and apend to the existing list\n    \"\"\"\n    if request.method == 'POST':\n        data = request.get_json()\n        if not data.get('order_number'):\n            return FeedbackResponse.display('set order number please', 406)\n        if not data.get('order_description'):\n            return FeedbackResponse.display('set description please', 406)\n        if not data.get('size'):\n            return FeedbackResponse.display('set size please ', 406)\n        if not data.get('order_price'):\n            return FeedbackResponse.display('set price please', 406)\n        order_number = data.get('order_number')\n        order_description = data.get('order_description')\n        order_price = data.get('order_price')\n        size = data.get('size')\n        new_order = Order(order_number, order_description, order_price, size)\n        customer_orders.place_order(new_order)\n"]]}
{"hexsha": "22217d3a519e212ebef80b36b4a5516f4fca76a4", "ext": "py", "lang": "Python", "content": "def GetKeyIdx(i, isWhite=True):\n    a = int(i / 7)\n    b = i % 7\n    b *= 2\n    if b > 4:\n        b -= 1\n    key_idx = a*12+b\n    if not isWhite:\n        key_idx += 1\n    return key_idx", "fn_id": 5, "class_fn": false, "repo": "functionadvanced/Cyan", "file": "UI.py", "last_update_at": "2018-10-04T21:04:30+00:00", "question_id": "22217d3a519e212ebef80b36b4a5516f4fca76a4_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def GetKeyIdx(i, isWhite=True):\n    a = int(i / 7)\n    b = i % 7\n    b *= 2\n    if b > 4:\n        b -= 1\n    key_idx = a * 12 + b\n    if not isWhite:\n        key_idx += 1\n"]]}
{"hexsha": "3e587af21fe036f73f1170717fd90b954485b43d", "ext": "py", "lang": "Python", "content": "def download_sstable_to_path(\n    config,\n    path,\n    objects,\n    sstable_context,\n    mutable_mtime\n):\n    if (path / 'data').exists():\n        \"\"\"Note that we use the existence of a directory named 'data' to\n        inhibit downloads. This stands in contrast to uploads, which we inhibit\n        with separate marker files.\n\n        The practical upshot is that, if we are going to put a directory called\n        'data' in place, it had better contain valid data.\n        \"\"\"\n        return\n\n    provider_args = {\n        config['encryption']['provider']: config['encryption']['args']\n    }\n\n    uploaded_dir = path / 'uploaded'\n    uploaded_dir.mkdir()\n\n    with MovingTemporaryDirectory(path / 'data') as temp:\n        for (marker_name, s3_object) in objects:\n            context = dict(sstable_context)\n            context.update(config['context'])\n            context['component'] = marker_name\n            context['continuity'] = continuity_code\n            if marker_name == 'mutable':\n                context['timestamp'] = mutable_mtime\n\n            marker_path = uploaded_dir / marker_name\n            download_to_path(\n                marker_path,\n                s3_object,\n                temp.path,\n                provider_args,\n                context,\n            )\n\n        temp.finalize()", "fn_id": 3, "class_fn": false, "repo": "hashbrowncipher/cassandra-mirror", "file": "cassandra_mirror/restore.py", "last_update_at": "2018-09-01T03:36:23+00:00", "question_id": "3e587af21fe036f73f1170717fd90b954485b43d_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def download_sstable_to_path(config, path, objects, sstable_context, mutable_mtime):\n    if (path / 'data').exists():\n        \"Note that we use the existence of a directory named 'data' to\\n        inhibit downloads. This stands in contrast to uploads, which we inhibit\\n        with separate marker files.\\n\\n        The practical upshot is that, if we are going to put a directory called\\n        'data' in place, it had better contain valid data.\\n        \"\n        return\n    provider_args = {config['encryption']['provider']: config['encryption']['args']}\n    uploaded_dir = path / 'uploaded'\n    uploaded_dir.mkdir()\n    with MovingTemporaryDirectory(path / 'data') as temp:\n        for marker_name, s3_object in objects:\n            context = dict(sstable_context)\n            context.update(config['context'])\n            context['component'] = marker_name\n            context['continuity'] = continuity_code\n            if marker_name == 'mutable':\n                context['timestamp'] = mutable_mtime\n            marker_path = uploaded_dir / marker_name\n            download_to_path(marker_path, s3_object, temp.path, provider_args, context)\n"]]}
{"hexsha": "dae114589dc9b5d7656022e074c5f0eb58b326c1", "ext": "py", "lang": "Python", "content": "def get_base_connectors(tiles):\n    \"\"\"\n    Places basic connectors for rooms,\n    single door or double door, using the middle\n    :param tiles: The tiles to evaluate\n    :return: The Connector Dict\n    \"\"\"\n    height = len(tiles) - 1\n    width = max((len(row) for row in tiles)) - 1\n    center_width = int(width / 2)\n    center_height = int(height / 2)\n    return {\n        Direction.North: (\n            connectors.DungeonSingleDoor((center_width, 0)),\n            connectors.DungeonDoubleDoor(\n                (center_width, 0),\n                (center_width + 1, 0)\n            ),\n        ),\n        Direction.South: (\n            connectors.DungeonSingleDoor((center_width, height)),\n            connectors.DungeonDoubleDoor(\n                (center_width, height),\n                (center_width + 1, height)\n            ),\n        ),\n        Direction.East: (\n            connectors.DungeonSingleDoor((width, center_height)),\n            connectors.DungeonDoubleDoor(\n                (width, center_height),\n                (width + 1, center_height),\n            ),\n        ),\n        Direction.West: (\n            connectors.DungeonSingleDoor((0, center_height)),\n            connectors.DungeonDoubleDoor(\n                (0, center_height),\n                (0, center_height),\n            ),\n        )\n    }", "fn_id": 0, "class_fn": false, "repo": "ChrisLR/BasicDungeonRL", "file": "bfgame/maps/skeletoncrypt/rooms.py", "last_update_at": "2018-09-12T09:47:00+00:00", "question_id": "dae114589dc9b5d7656022e074c5f0eb58b326c1_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_base_connectors(tiles):\n    \"\"\"\n    Places basic connectors for rooms,\n    single door or double door, using the middle\n    :param tiles: The tiles to evaluate\n    :return: The Connector Dict\n    \"\"\"\n    height = len(tiles) - 1\n    width = max((len(row) for row in tiles)) - 1\n    center_width = int(width / 2)\n    center_height = int(height / 2)\n"]]}
{"hexsha": "9cfde3110ba8c9d509b9cdc3a55a2dbc1342ffb1", "ext": "py", "lang": "Python", "content": "def build_generator_resnet_9blocks_tf(inputgen, name=\"generator\", skip=False):\n    with tf.variable_scope(name):\n        f = 7\n        ks = 3\n        padding = \"REFLECT\"\n\n        pad_input = tf.pad(inputgen, [[0, 0], [ks, ks], [\n            ks, ks], [0, 0]], padding)\n        o_c1 = layers.general_conv2d(\n            pad_input, ngf, f, f, 1, 1, 0.02, name=\"c1\")\n        o_c2 = layers.general_conv2d(\n            o_c1, ngf * 2, ks, ks, 2, 2, 0.02, \"SAME\", \"c2\")\n        o_c3 = layers.general_conv2d(\n            o_c2, ngf * 4, ks, ks, 2, 2, 0.02, \"SAME\", \"c3\")\n\n        o_r1 = build_resnet_block(o_c3, ngf * 4, \"r1\", padding)\n        o_r2 = build_resnet_block(o_r1, ngf * 4, \"r2\", padding)\n        o_r3 = build_resnet_block(o_r2, ngf * 4, \"r3\", padding)\n        o_r4 = build_resnet_block(o_r3, ngf * 4, \"r4\", padding)\n        o_r5 = build_resnet_block(o_r4, ngf * 4, \"r5\", padding)\n        o_r6 = build_resnet_block(o_r5, ngf * 4, \"r6\", padding)\n        o_r7 = build_resnet_block(o_r6, ngf * 4, \"r7\", padding)\n        o_r8 = build_resnet_block(o_r7, ngf * 4, \"r8\", padding)\n        o_r9 = build_resnet_block(o_r8, ngf * 4, \"r9\", padding)\n\n        o_c4 = layers.general_deconv2d(\n            o_r9, [BATCH_SIZE, 128, 128, ngf * 2], ngf * 2, ks, ks, 2, 2, 0.02,\n            \"SAME\", \"c4\")\n        o_c5 = layers.general_deconv2d(\n            o_c4, [BATCH_SIZE, 256, 256, ngf], ngf, ks, ks, 2, 2, 0.02,\n            \"SAME\", \"c5\")\n        o_c6 = layers.general_conv2d(o_c5, IMG_CHANNELS, f, f, 1, 1,\n                                     0.02, \"SAME\", \"c6\",\n                                     do_norm=False, do_relu=False)\n\n        if skip is True:\n            out_gen = tf.nn.tanh(inputgen + o_c6, \"t1\")\n        else:\n            out_gen = tf.nn.tanh(o_c6, \"t1\")\n\n        return out_gen", "fn_id": 2, "class_fn": false, "repo": "sagars729/cyclegan-1", "file": "model.py", "last_update_at": "2018-07-30T12:11:55+00:00", "question_id": "9cfde3110ba8c9d509b9cdc3a55a2dbc1342ffb1_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def build_generator_resnet_9blocks_tf(inputgen, name='generator', skip=False):\n    with tf.variable_scope(name):\n        f = 7\n        ks = 3\n        padding = 'REFLECT'\n        pad_input = tf.pad(inputgen, [[0, 0], [ks, ks], [ks, ks], [0, 0]], padding)\n        o_c1 = layers.general_conv2d(pad_input, ngf, f, f, 1, 1, 0.02, name='c1')\n        o_c2 = layers.general_conv2d(o_c1, ngf * 2, ks, ks, 2, 2, 0.02, 'SAME', 'c2')\n        o_c3 = layers.general_conv2d(o_c2, ngf * 4, ks, ks, 2, 2, 0.02, 'SAME', 'c3')\n        o_r1 = build_resnet_block(o_c3, ngf * 4, 'r1', padding)\n        o_r2 = build_resnet_block(o_r1, ngf * 4, 'r2', padding)\n        o_r3 = build_resnet_block(o_r2, ngf * 4, 'r3', padding)\n        o_r4 = build_resnet_block(o_r3, ngf * 4, 'r4', padding)\n        o_r5 = build_resnet_block(o_r4, ngf * 4, 'r5', padding)\n        o_r6 = build_resnet_block(o_r5, ngf * 4, 'r6', padding)\n        o_r7 = build_resnet_block(o_r6, ngf * 4, 'r7', padding)\n        o_r8 = build_resnet_block(o_r7, ngf * 4, 'r8', padding)\n        o_r9 = build_resnet_block(o_r8, ngf * 4, 'r9', padding)\n        o_c4 = layers.general_deconv2d(o_r9, [BATCH_SIZE, 128, 128, ngf * 2], ngf * 2, ks, ks, 2, 2, 0.02, 'SAME', 'c4')\n        o_c5 = layers.general_deconv2d(o_c4, [BATCH_SIZE, 256, 256, ngf], ngf, ks, ks, 2, 2, 0.02, 'SAME', 'c5')\n        o_c6 = layers.general_conv2d(o_c5, IMG_CHANNELS, f, f, 1, 1, 0.02, 'SAME', 'c6', do_norm=False, do_relu=False)\n        if skip is True:\n            out_gen = tf.nn.tanh(inputgen + o_c6, 't1')\n        else:\n            out_gen = tf.nn.tanh(o_c6, 't1')\n"]]}
{"hexsha": "f3e572c7d77ef35ad25253d0adfa09f6260c2cb7", "ext": "py", "lang": "Python", "content": "def display_capital(investment_length, added_yearly, initial_capital):\n    total_capital = round(initial_capital + (investment_length*added_yearly))\n    formatted_capital = str(format(total_capital, \",d\"))\n    results_string = (\"Total Invesment Capital: $\" + formatted_capital)\n    CAPITAL_VAR.set(results_string)", "fn_id": 4, "class_fn": false, "repo": "JoshHumpherey/Financial_Calculators", "file": "investment_growth.py", "last_update_at": "2018-07-30T16:21:48+00:00", "question_id": "f3e572c7d77ef35ad25253d0adfa09f6260c2cb7_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def display_capital(investment_length, added_yearly, initial_capital):\n    total_capital = round(initial_capital + investment_length * added_yearly)\n    formatted_capital = str(format(total_capital, ',d'))\n    results_string = 'Total Invesment Capital: $' + formatted_capital\n"]]}
{"hexsha": "25c2f4653f0eab1dafaca3c11771959ae8bd21b1", "ext": "py", "lang": "Python", "content": "def reject_assignment(conn, assignment_id, message = None):\n    assn = conn.get_assignment(AssignmentId = assignment_id)\n    status = assn[\"Assignment\"][\"AssignmentStatus\"]\n    if status == \"Approved\":\n        raise MTurkInvalidStatus(\"Assignment {} has already been approved!\".format(assignment_id))\n    elif status == \"Rejected\":\n        return False\n    elif status != \"Submitted\":\n        raise MTurkInvalidStatus(\"Assignment should have status {}, but has status {}\".format(\"Submitted\", status))\n\n    conn.reject_assignment(AssignmentId = assignment_id, message = message)\n    return True", "fn_id": 20, "class_fn": false, "repo": "arunchaganty/kbp-online", "file": "src/kbpo/turk.py", "last_update_at": "2018-12-25T01:34:23+00:00", "question_id": "25c2f4653f0eab1dafaca3c11771959ae8bd21b1_20", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def reject_assignment(conn, assignment_id, message=None):\n    assn = conn.get_assignment(AssignmentId=assignment_id)\n    status = assn['Assignment']['AssignmentStatus']\n    if status == 'Approved':\n        raise MTurkInvalidStatus('Assignment {} has already been approved!'.format(assignment_id))\n    elif status == 'Rejected':\n        return False\n    elif status != 'Submitted':\n        raise MTurkInvalidStatus('Assignment should have status {}, but has status {}'.format('Submitted', status))\n    conn.reject_assignment(AssignmentId=assignment_id, message=message)\n"]]}
{"hexsha": "b25d39264152bccb91042dddeb344b4d1c887ff7", "ext": "py", "lang": "Python", "content": "def entry():\n  current_dir = os.path.dirname(os.path.realpath(__file__))\n\n  path_files_includes=[\n            'lua.h',\n            #'lua.hpp', # 20180212 \u5947\u602a GitHub \u4e0a\u7684 repo \u6ca1\u6709\u8fd9\u4e2a\u6587\u4ef6\n            'luaconf.h',\n            'lualib.h',\n            'lauxlib.h',\n  ]\n\n  f = lambda v: os.path.join(current_dir,'..','lua',v)\n  path_files_includes = list(map(f,path_files_includes))\n\n  p = os.path.join(current_dir,'include','lua')\n  if os.path.exists(p):\n    shutil.rmtree(p)\n  os.makedirs(p)\n  for v in path_files_includes:\n    shutil.copy(v,p)\n    print('[+] copy {0} to {1}'.format(v,p))\n\n  print('[+] all done')", "fn_id": 0, "class_fn": false, "repo": "fooofei/cpp_static_embeded_lua", "file": "lua_dirty/make_includes.py", "last_update_at": "2018-08-29T13:16:26+00:00", "question_id": "b25d39264152bccb91042dddeb344b4d1c887ff7_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def entry():\n    current_dir = os.path.dirname(os.path.realpath(__file__))\n    path_files_includes = ['lua.h', 'luaconf.h', 'lualib.h', 'lauxlib.h']\n    f = lambda v: os.path.join(current_dir, '..', 'lua', v)\n    path_files_includes = list(map(f, path_files_includes))\n    p = os.path.join(current_dir, 'include', 'lua')\n    if os.path.exists(p):\n        shutil.rmtree(p)\n    os.makedirs(p)\n    for v in path_files_includes:\n        shutil.copy(v, p)\n        print('[+] copy {0} to {1}'.format(v, p))\n"]]}
{"hexsha": "bf2ad86e797c921b9ad0d196307756a1b5568545", "ext": "py", "lang": "Python", "content": "def get_interventi():\n    with get_cursor() as cur:\n        cur.execute(\"SELECT id, titolo FROM INTERVENTO\")\n        return list(cur)", "fn_id": 1, "class_fn": false, "repo": "vladbragoi/db_lab_exams", "file": "Esame16022018/src/Main.py", "last_update_at": "2018-08-30T09:15:51+00:00", "question_id": "bf2ad86e797c921b9ad0d196307756a1b5568545_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_interventi():\n    with get_cursor() as cur:\n        cur.execute('SELECT id, titolo FROM INTERVENTO')\n"]]}
{"hexsha": "9a4e8312a8b2593027b6224a3d1ea116e2b47859", "ext": "py", "lang": "Python", "content": "def findCorrectClasses(y_values):\n    y_classes = []\n    for classes in y_values:\n        for i, class_values in enumerate(classes):\n            if class_values == 1:\n                y_classes.append(i)\n                break\n    return y_classes", "fn_id": 0, "class_fn": false, "repo": "Augus-top/Deep-Tweet-Analysis", "file": "test.py", "last_update_at": "2018-03-13T17:04:45+00:00", "question_id": "9a4e8312a8b2593027b6224a3d1ea116e2b47859_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def findCorrectClasses(y_values):\n    y_classes = []\n    for classes in y_values:\n        for i, class_values in enumerate(classes):\n            if class_values == 1:\n                y_classes.append(i)\n                break\n"]]}
{"hexsha": "f1deaea00c463f5a30b99f5a3f1ed7ef887b84a9", "ext": "py", "lang": "Python", "content": "def send_mail(send_from, send_to, subject, message):\n\tusername = \"support@zepko.com\"\n\tpassword = \"a5mGxYTYWo\"\n\tserver=\"smtp.office365.com\"\n\tport=587\n\tmsg = MIMEMultipart('related')\n\tmsg['From'] = send_from\n\tmsg['To'] = send_to \n\tmsg['Subject'] = subject\n\tmsg.attach( MIMEText(text, 'plain') )\n\tsmtp = smtplib.SMTP(server, port)\n\tsmtp.login(username, password)\n\tsmtp.sendmail(send_from, send_to, msg.as_string())\n\tsmtp.close()\n\treturn True", "fn_id": 1, "class_fn": false, "repo": "OpenC2-org/ReactorRelay", "file": "reactor_relay/profiles/email_send_office365_email.py", "last_update_at": "2018-12-17T12:20:41+00:00", "question_id": "f1deaea00c463f5a30b99f5a3f1ed7ef887b84a9_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def send_mail(send_from, send_to, subject, message):\n    username = 'support@zepko.com'\n    password = 'a5mGxYTYWo'\n    server = 'smtp.office365.com'\n    port = 587\n    msg = MIMEMultipart('related')\n    msg['From'] = send_from\n    msg['To'] = send_to\n    msg['Subject'] = subject\n    msg.attach(MIMEText(text, 'plain'))\n    smtp = smtplib.SMTP(server, port)\n    smtp.login(username, password)\n    smtp.sendmail(send_from, send_to, msg.as_string())\n    smtp.close()\n"]]}
{"hexsha": "78e91249c82c500bcea7e9536046e7cb366ad21f", "ext": "py", "lang": "Python", "content": "def calculate_body_load (strain, mat_D, g_mat, g_num, a, nn):\n    ndim = 3\n    nod = 8\n    nels = g_mat.shape[0]\n    deriv = shape_der_hexahedron(a, a/2)\n    B = beemat(deriv)\n    body_load = zeros((nn,ndim), float64)\n    for iel in range(nels):\n        eload = product(a) * dot(transpose(B),\n                  dot(mat_D[g_mat[iel]], strain[iel]))\n        body_load[g_num[iel,:],:] += eload.reshape((nod,ndim))\n    return body_load", "fn_id": 21, "class_fn": false, "repo": "Numerics88/n88tools", "file": "n88tools/finiteelement.py", "last_update_at": "2018-01-29T03:27:52+00:00", "question_id": "78e91249c82c500bcea7e9536046e7cb366ad21f_21", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def calculate_body_load(strain, mat_D, g_mat, g_num, a, nn):\n    ndim = 3\n    nod = 8\n    nels = g_mat.shape[0]\n    deriv = shape_der_hexahedron(a, a / 2)\n    B = beemat(deriv)\n    body_load = zeros((nn, ndim), float64)\n    for iel in range(nels):\n        eload = product(a) * dot(transpose(B), dot(mat_D[g_mat[iel]], strain[iel]))\n        body_load[g_num[iel, :], :] += eload.reshape((nod, ndim))\n"]]}
{"hexsha": "5094acb72a162e0540c044d769e1eb38915e0331", "ext": "py", "lang": "Python", "content": "def get_models_from_table_names(table_names, force=None):\n    \"\"\"\n    Convert list of table names to table model classes.\n    \"\"\"\n    models = []\n    errors = []\n    for table_name in table_names:\n        try:\n            models.append(\n                get_model_from_table_name(table_name)\n            )\n        except (\n            IncorrectTableNameException,\n            ModelDoesNotExistException\n        ) as exc:\n            if not force:\n                raise exc\n            errors.append(exc.args)\n    return models, errors", "fn_id": 0, "class_fn": false, "repo": "kula1922/kfusiontables", "file": "kfusiontables/kft/utils/convert.py", "last_update_at": "2018-10-12T13:45:25+00:00", "question_id": "5094acb72a162e0540c044d769e1eb38915e0331_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_models_from_table_names(table_names, force=None):\n    \"\"\"\n    Convert list of table names to table model classes.\n    \"\"\"\n    models = []\n    errors = []\n    for table_name in table_names:\n        try:\n            models.append(get_model_from_table_name(table_name))\n        except (IncorrectTableNameException, ModelDoesNotExistException) as exc:\n            if not force:\n                raise exc\n            errors.append(exc.args)\n"]]}
{"hexsha": "0ac5ccb450a98c3002fb86acb68bef39e0d57096", "ext": "py", "lang": "Python", "content": "def cache():\n    \"\"\"Tests that a value can be retrieved from cache.\n\n    :returns: Dictionary indicating results. {'status': True}\n    :rtype: dict\n    \"\"\"\n    key = 'test_cache_key'\n    val = 'test_cache_val'\n    result = dict(status=None)\n    try:\n        django_cache.add(key, val, 3600)\n        cache_val = django_cache.get(key)\n        if cache_val == val:\n            result['status'] = True\n    except Exception as e:\n        result['status'] = False\n    return result", "fn_id": 0, "class_fn": false, "repo": "rcbops/FleetDeploymentReporting", "file": "web/api/status.py", "last_update_at": "2018-07-11T20:20:21+00:00", "question_id": "0ac5ccb450a98c3002fb86acb68bef39e0d57096_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def cache():\n    \"\"\"Tests that a value can be retrieved from cache.\n\n    :returns: Dictionary indicating results. {'status': True}\n    :rtype: dict\n    \"\"\"\n    key = 'test_cache_key'\n    val = 'test_cache_val'\n    result = dict(status=None)\n    try:\n        django_cache.add(key, val, 3600)\n        cache_val = django_cache.get(key)\n        if cache_val == val:\n            result['status'] = True\n    except Exception as e:\n        result['status'] = False\n"]]}
{"hexsha": "30dd6dfae915ed34007eec1da2366e5dfe9619da", "ext": "py", "lang": "Python", "content": "@register.filter\ndef generate_price(amount):\n    \"\"\" Processes decimal prices into strings. \"\"\"\n    if amount == Decimal('0.0'):\n        return \"Free\"\n    elif amount == Decimal('-1.0'):\n        return \"??\"\n    else:\n        return \"$\" + str(amount)", "fn_id": 2, "class_fn": false, "repo": "stuart-bradley/steam_lan_game_finder", "file": "game_finder/templatetags/game_extras.py", "last_update_at": "2018-01-09T11:44:54+00:00", "question_id": "30dd6dfae915ed34007eec1da2366e5dfe9619da_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@register.filter\ndef generate_price(amount):\n    \"\"\" Processes decimal prices into strings. \"\"\"\n    if amount == Decimal('0.0'):\n        return 'Free'\n    elif amount == Decimal('-1.0'):\n        return '??'\n    else:\n"]]}
{"hexsha": "0a645f40829eca8e6b6ba9afcf05b228df692160", "ext": "py", "lang": "Python", "content": "def __pieMissLerpCallback(t, missDict):\n    pie = missDict['pie']\n    newPos = missDict['startPos'] * (1.0 - t) + missDict['endPos'] * t\n    if t < tPieShrink:\n        tScale = 0.0001\n    else:\n        tScale = (t - tPieShrink) / (1.0 - tPieShrink)\n    newScale = missDict['startScale'] * max(1.0 - tScale, 0.01)\n    pie.setPos(newPos)\n    pie.setScale(newScale)", "fn_id": 9, "class_fn": false, "repo": "LittleNed/toontown-stride", "file": "toontown/battle/MovieFire.py", "last_update_at": "2018-06-16T23:06:38+00:00", "question_id": "0a645f40829eca8e6b6ba9afcf05b228df692160_9", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def __pieMissLerpCallback(t, missDict):\n    pie = missDict['pie']\n    newPos = missDict['startPos'] * (1.0 - t) + missDict['endPos'] * t\n    if t < tPieShrink:\n        tScale = 0.0001\n    else:\n        tScale = (t - tPieShrink) / (1.0 - tPieShrink)\n    newScale = missDict['startScale'] * max(1.0 - tScale, 0.01)\n    pie.setPos(newPos)\n"]]}
{"hexsha": "586625de5a994cf06a894c3ba33fcdbb23b4b66f", "ext": "py", "lang": "Python", "content": "def get_all_csindex(only_china=True):\n    all_index = []\n    page_size = 50\n    page_cnt = 1\n\n    curr_page = 1\n    while curr_page <= page_cnt:\n        url = 'http://www.csindex.com.cn/zh-CN/indices/index?page={curr_page}&page_size={page_size}&by=desc&order=\u6307\u6570\u4ee3\u7801&data_type=json'.format(**locals())\n        if only_china:\n            url += '&class_7=7'\n        resp = requests.get(url)\n        ret = resp.json()\n        page_cnt = ret['total_page']\n        all_index.extend(ret['list'])\n        curr_page += 1\n\n    return all_index", "fn_id": 0, "class_fn": false, "repo": "qytz/cn_stock_daily", "file": "csdaily/index/utils/csindex.py", "last_update_at": "2018-05-29T09:13:05+00:00", "question_id": "586625de5a994cf06a894c3ba33fcdbb23b4b66f_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_all_csindex(only_china=True):\n    all_index = []\n    page_size = 50\n    page_cnt = 1\n    curr_page = 1\n    while curr_page <= page_cnt:\n        url = 'http://www.csindex.com.cn/zh-CN/indices/index?page={curr_page}&page_size={page_size}&by=desc&order=\u6307\u6570\u4ee3\u7801&data_type=json'.format(**locals())\n        if only_china:\n            url += '&class_7=7'\n        resp = requests.get(url)\n        ret = resp.json()\n        page_cnt = ret['total_page']\n        all_index.extend(ret['list'])\n        curr_page += 1\n"]]}
{"hexsha": "6be19c45758d540b1ce3cd61658649f47a2b1f38", "ext": "py", "lang": "Python", "content": "def mrr_score(ranks):\n    '''Calculates the mrr for a list of ranks. Remarks: Ranks can also be zero.'''\n    Q = len(ranks)\n    sum = 0.0\n\n    for rank in ranks:\n        if rank != 0:\n            sum += 1 / float(rank)\n\n    mrr_score = 1.0 / Q * sum\n\n    return mrr_score", "fn_id": 0, "class_fn": false, "repo": "stefantaubert/life", "file": "geo/metrics/mrr.py", "last_update_at": "2018-12-25T08:58:26+00:00", "question_id": "6be19c45758d540b1ce3cd61658649f47a2b1f38_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def mrr_score(ranks):\n    \"\"\"Calculates the mrr for a list of ranks. Remarks: Ranks can also be zero.\"\"\"\n    Q = len(ranks)\n    sum = 0.0\n    for rank in ranks:\n        if rank != 0:\n            sum += 1 / float(rank)\n    mrr_score = 1.0 / Q * sum\n"]]}
{"hexsha": "75db92e8c119cf6edfaf274c7b4632092e0a99d9", "ext": "py", "lang": "Python", "content": "def validate_when(value):\n    \"\"\"Used to convert between pendulum and other types of datetime.\"\"\"\n    if isinstance(value, datetime.datetime):\n        value = pendulum.from_timestamp(value.timestamp(), tz='UTC')\n    elif not isinstance(value, pendulum.DateTime):\n        value = pendulum.parse(value)\n\n    value = value.in_tz('UTC')\n\n    return value", "fn_id": 0, "class_fn": false, "repo": "diefans/zeitig", "file": "src/zeitig/events.py", "last_update_at": "2018-05-22T10:07:18+00:00", "question_id": "75db92e8c119cf6edfaf274c7b4632092e0a99d9_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def validate_when(value):\n    \"\"\"Used to convert between pendulum and other types of datetime.\"\"\"\n    if isinstance(value, datetime.datetime):\n        value = pendulum.from_timestamp(value.timestamp(), tz='UTC')\n    elif not isinstance(value, pendulum.DateTime):\n        value = pendulum.parse(value)\n    value = value.in_tz('UTC')\n"]]}
{"hexsha": "b8d67363e898f17fe8aab28f24eca8aad0fc2d1b", "ext": "py", "lang": "Python", "content": "@pytest.fixture(scope=\"function\")\ndef memoized_mock(mocker):\n    func = mocker.MagicMock()\n\n    memoized_func = si.utils.memoize(func)\n\n    return func, memoized_func", "fn_id": 0, "class_fn": false, "repo": "JoshKarpel/simulacra", "file": "tests/utils/test_memoize.py", "last_update_at": "2018-05-24T08:01:26+00:00", "question_id": "b8d67363e898f17fe8aab28f24eca8aad0fc2d1b_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.fixture(scope='function')\ndef memoized_mock(mocker):\n    func = mocker.MagicMock()\n    memoized_func = si.utils.memoize(func)\n"]]}
{"hexsha": "d4df4e73f5b436e575c01ebed35f2973cdf71f3f", "ext": "py", "lang": "Python", "content": "def _batch_op_init_for_opdef_default_optimizer(opdef, S):\n    assert not S.batch_op\n    S.batch_op = Operation()\n    optdef = util.find_apply(\n        [\n            lambda: opdef.default_optimizer,\n            lambda: _default_optimizer(opdef),\n        ]\n    )\n    _op_init_for_optimizer(optdef, S.batch_op)", "fn_id": 81, "class_fn": false, "repo": "guildai/guild", "file": "guild/commands/run_impl.py", "last_update_at": "2018-08-21T08:38:36+00:00", "question_id": "d4df4e73f5b436e575c01ebed35f2973cdf71f3f_81", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _batch_op_init_for_opdef_default_optimizer(opdef, S):\n    assert not S.batch_op\n    S.batch_op = Operation()\n    optdef = util.find_apply([lambda: opdef.default_optimizer, lambda: _default_optimizer(opdef)])\n"]]}
{"hexsha": "beff5a19b7d3a52d3518535dabf124e51e12f614", "ext": "py", "lang": "Python", "content": "def generate_string_to_sign(date, region, canonical_request):\n    \"\"\"\n    Generate string to sign.\n\n    :param date: Date is input from :meth:`datetime.datetime`\n    :param region: Region should be set to bucket region.\n    :param canonical_request: Canonical request generated previously.\n    \"\"\"\n    formatted_date_time = date.strftime(\"%Y%m%dT%H%M%SZ\")\n\n    canonical_request_hasher = hashlib.sha256()\n    canonical_request_hasher.update(canonical_request.encode('utf-8'))\n    canonical_request_sha256 = canonical_request_hasher.hexdigest()\n    scope = generate_scope_string(date, region)\n\n    return '\\n'.join([_SIGN_V4_ALGORITHM,\n                      formatted_date_time,\n                      scope,\n                      canonical_request_sha256])", "fn_id": 5, "class_fn": false, "repo": "cheungpat/minio-py", "file": "minio/signer.py", "last_update_at": "2018-07-12T19:31:42+00:00", "question_id": "beff5a19b7d3a52d3518535dabf124e51e12f614_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def generate_string_to_sign(date, region, canonical_request):\n    \"\"\"\n    Generate string to sign.\n\n    :param date: Date is input from :meth:`datetime.datetime`\n    :param region: Region should be set to bucket region.\n    :param canonical_request: Canonical request generated previously.\n    \"\"\"\n    formatted_date_time = date.strftime('%Y%m%dT%H%M%SZ')\n    canonical_request_hasher = hashlib.sha256()\n    canonical_request_hasher.update(canonical_request.encode('utf-8'))\n    canonical_request_sha256 = canonical_request_hasher.hexdigest()\n    scope = generate_scope_string(date, region)\n"]]}
{"hexsha": "f2009f7fd850dbd721b9c039c9c30e5358e18cb6", "ext": "py", "lang": "Python", "content": "@app.route('/dashboard', methods=['GET', 'POST'])\n@is_logged_in\ndef dashboard():\n    if category_data:\n        email = session['email']\n        try:\n            return render_template('dashboard.html', category_list=category_data[email], email=email)\n        except KeyError:\n            flash('Create a Recipe Category', 'red')\n            return render_template('dashboard.html')\n\n    else:\n        flash('Create a Recipe Category', 'red')\n        return render_template('dashboard.html')", "fn_id": 5, "class_fn": false, "repo": "Yahy3z/YummyApp", "file": "app/views.py", "last_update_at": "2018-04-13T20:05:28+00:00", "question_id": "f2009f7fd850dbd721b9c039c9c30e5358e18cb6_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@app.route('/dashboard', methods=['GET', 'POST'])\n@is_logged_in\ndef dashboard():\n    if category_data:\n        email = session['email']\n        try:\n            return render_template('dashboard.html', category_list=category_data[email], email=email)\n        except KeyError:\n            flash('Create a Recipe Category', 'red')\n            return render_template('dashboard.html')\n    else:\n        flash('Create a Recipe Category', 'red')\n"]]}
{"hexsha": "224f8466d20ea6fbfbf0bcf76d5ef3cc0013b18c", "ext": "py", "lang": "Python", "content": "def Reject(request):\n    f=Friend.objects.get(id=request.GET.get(\"id\"))\n    f.status=2\n    f.save()\n    res = redirect(\"Welcome\")\n    return res", "fn_id": 5, "class_fn": false, "repo": "shivani-saxena/myfacebook", "file": "facebook/fb/views.py", "last_update_at": "2018-07-28T10:36:57+00:00", "question_id": "224f8466d20ea6fbfbf0bcf76d5ef3cc0013b18c_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def Reject(request):\n    f = Friend.objects.get(id=request.GET.get('id'))\n    f.status = 2\n    f.save()\n    res = redirect('Welcome')\n"]]}
{"hexsha": "3e7fcca0fd6e6c0e725d6cce7ae6b5f93aec761e", "ext": "py", "lang": "Python", "content": "def installopenjdk():\n    hookenv.log('Installing OpenJDK')\n    conf = hookenv.config()\n    install_type = conf['install-type']\n    java_major = conf['java-major']\n    #openjdk 8 is not included in ubuntu repos\n    if java_major == '8':\n        charms.apt.add_source('ppa:openjdk-r/ppa')\n    charms.apt.queue_install(['openjdk-%s-jre-headless' % java_major]) # pylint: disable=e1101\n    if install_type == 'full':\n        charms.apt.queue_install(['openjdk-%s-jdk' % java_major])# pylint: disable=e1101\n        # return 'openjdk-%s-jdk' % java_major\n    #TODO remove when reactive fixed\n    return 'openjdk-%s-jre-headless' % java_major", "fn_id": 0, "class_fn": false, "repo": "tengu-team/java", "file": "lib/openjdk.py", "last_update_at": "2018-01-31T11:54:55+00:00", "question_id": "3e7fcca0fd6e6c0e725d6cce7ae6b5f93aec761e_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def installopenjdk():\n    hookenv.log('Installing OpenJDK')\n    conf = hookenv.config()\n    install_type = conf['install-type']\n    java_major = conf['java-major']\n    if java_major == '8':\n        charms.apt.add_source('ppa:openjdk-r/ppa')\n    charms.apt.queue_install(['openjdk-%s-jre-headless' % java_major])\n    if install_type == 'full':\n        charms.apt.queue_install(['openjdk-%s-jdk' % java_major])\n"]]}
{"hexsha": "aa66a49476a0b4505dcdb47e193eb599e909f699", "ext": "py", "lang": "Python", "content": "def dnw_4_normal(input_text):\n    \"\"\"\n    \u6e90\u4ee3\u7801\u57fa\u4e8e http://spaces.ac.cn/archives/3491/\n    \u539f\u7406\u57fa\u4e8e http://www.matrix67.com/blog/archives/5044\n    :param input_text:\n    :return:\n    \"\"\"\n    # \u5b9a\u4e49\u8981\u53bb\u6389\u7684\u6807\u70b9\u5b57\n    drop_dict = [u'\uff0c', u'\\n', u'\u3002', u'\u3001', u'\uff1a', u'(', u')',\n                 u'[', u']', u'.', u',', u' ', u'\\u3000', u'\u201d', u'\u201c', u'\uff1f',\n                 u'?',\n                 u'\uff01', u'\u2018', u'\u2019', u'\u2026']\n    for i in drop_dict:  # \u53bb\u6389\u6807\u70b9\u5b57\n        input_text = input_text.replace(i, '')\n\n    min_count = 2  # \u5f55\u53d6\u8bcd\u8bed\u6700\u5c0f\u51fa\u73b0\u6b21\u6570\n    min_support = 4  # \u5f55\u53d6\u8bcd\u8bed\u6700\u4f4e\u652f\u6301\u5ea6\uff0c1\u4ee3\u8868\u7740\u968f\u673a\u7ec4\u5408\n    min_s = 2  # \u5f55\u53d6\u8bcd\u8bed\u6700\u4f4e\u4fe1\u606f\u71b5\uff0c\u8d8a\u5927\u8bf4\u660e\u8d8a\u6709\u53ef\u80fd\u72ec\u7acb\u6210\u8bcd\n    max_sep = 20  # \u5019\u9009\u8bcd\u8bed\u7684\u6700\u5927\u5b57\u6570\n\n    # \u4e3a\u4e86\u65b9\u4fbf\u8c03\u7528\uff0c\u81ea\u5b9a\u4e49\u4e86\u4e00\u4e2a\u6b63\u5219\u8868\u8fbe\u5f0f\u7684\u8bcd\u5178\n    regexes = {}\n    for i in range(2, max_sep + 1):\n        k = i\n        v = '(' + '.' * i + ')'\n        regexes[k] = v\n\n    t = [pd.Series(list(input_text)).value_counts()]  # \u4fdd\u5b58\u7ed3\u679c\u7528\u3002\n\n    tsum = t[0].sum()  # \u7edf\u8ba1\u603b\u5b57\u6570\n    rt = []  # \u4fdd\u5b58\u7ed3\u679c\u7528\n\n    for m in range(2, max_sep + 1):\n        print(u'\u6b63\u5728\u751f\u6210%s\u5b57\u8bcd...' % m)\n        t.append([])\n        for i in range(m):  # \u751f\u6210\u6240\u6709\u53ef\u80fd\u7684m\u5b57\u8bcd\n            t[m - 1] = t[m - 1] + re.findall(regexes[m], input_text[i:])\n\n        t[m - 1] = pd.Series(t[m - 1]).value_counts()  # \u9010\u8bcd\u7edf\u8ba1\n        t[m - 1] = t[m - 1][t[m - 1] > min_count]  # \u6700\u5c0f\u6b21\u6570\u7b5b\u9009\n        tt = t[m - 1][:]\n        for k in range(m - 1):\n            qq = np.array(list(map(lambda ms: tsum * t[m - 1][ms] / t[m - 2 - k][ms[:m - 1 - k]] / t[k][ms[m - 1 - k:]],  # noqa\n                                   tt.index))) > min_support  # \u6700\u5c0f\u652f\u6301\u5ea6\u7b5b\u9009\u3002\n            tt = tt[qq]\n        rt.append(tt.index)\n\n    def cal_S(sl):  # \u4fe1\u606f\u71b5\u8ba1\u7b97\u51fd\u6570\n        from math import log\n        return -((sl / sl.sum()).apply(log) * sl / sl.sum()).sum()\n\n    for i in range(2, max_sep + 1):\n        print(u'\u6b63\u5728\u8fdb\u884c%s\u5b57\u8bcd\u7684\u6700\u5927\u71b5\u7b5b\u9009(%s)...' % (i, len(rt[i - 2])))\n        pp = []  # \u4fdd\u5b58\u6240\u6709\u7684\u5de6\u53f3\u90bb\u7ed3\u679c\n        for j in range(i):\n            pp = pp + re.findall('(.)%s(.)' % regexes[i], input_text[j:])\n        pp = pd.DataFrame(pp).set_index(1).sort_index()  # \u5148\u6392\u5e8f\uff0c\u8fd9\u4e2a\u5f88\u91cd\u8981\uff0c\u53ef\u4ee5\u52a0\u5feb\u68c0\u7d22\u901f\u5ea6\n        index = np.sort(np.intersect1d(rt[i - 2], pp.index))  # \u4f5c\u4ea4\u96c6\n        # \u4e0b\u9762\u4e24\u53e5\u5206\u522b\u662f\u5de6\u90bb\u548c\u53f3\u90bb\u4fe1\u606f\u71b5\u7b5b\u9009\n        index = index[np.array(\n            list(map(lambda s: cal_S(pd.Series(pp[0][s]).value_counts()), index))) > min_s]  # noqa\n        rt[i - 2] = index[np.array(\n            list(map(lambda s: cal_S(pd.Series(pp[2][s]).value_counts()), index))) > min_s]  # noqa\n\n    # \u4e0b\u9762\u90fd\u662f\u8f93\u51fa\u524d\u5904\u7406\n    for i in range(len(rt)):\n        t[i + 1] = t[i + 1][rt[i]]\n        t[i + 1].sort(ascending=False)\n\n    # \u4fdd\u5b58\u7ed3\u679c\u5e76\u8f93\u51fa\n    return pd.DataFrame(pd.concat(t[1:]))", "fn_id": 0, "class_fn": false, "repo": "twocucao/YaPyLib", "file": "yapylib/helpers/string/dnw_utils.py", "last_update_at": "2018-02-23T15:35:14+00:00", "question_id": "aa66a49476a0b4505dcdb47e193eb599e909f699_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def dnw_4_normal(input_text):\n    \"\"\"\n    \u6e90\u4ee3\u7801\u57fa\u4e8e http://spaces.ac.cn/archives/3491/\n    \u539f\u7406\u57fa\u4e8e http://www.matrix67.com/blog/archives/5044\n    :param input_text:\n    :return:\n    \"\"\"\n    drop_dict = [u'\uff0c', u'\\n', u'\u3002', u'\u3001', u'\uff1a', u'(', u')', u'[', u']', u'.', u',', u' ', u'\\u3000', u'\u201d', u'\u201c', u'\uff1f', u'?', u'\uff01', u'\u2018', u'\u2019', u'\u2026']\n    for i in drop_dict:\n        input_text = input_text.replace(i, '')\n    min_count = 2\n    min_support = 4\n    min_s = 2\n    max_sep = 20\n    regexes = {}\n    for i in range(2, max_sep + 1):\n        k = i\n        v = '(' + '.' * i + ')'\n        regexes[k] = v\n    t = [pd.Series(list(input_text)).value_counts()]\n    tsum = t[0].sum()\n    rt = []\n    for m in range(2, max_sep + 1):\n        print(u'\u6b63\u5728\u751f\u6210%s\u5b57\u8bcd...' % m)\n        t.append([])\n        for i in range(m):\n            t[m - 1] = t[m - 1] + re.findall(regexes[m], input_text[i:])\n        t[m - 1] = pd.Series(t[m - 1]).value_counts()\n        t[m - 1] = t[m - 1][t[m - 1] > min_count]\n        tt = t[m - 1][:]\n        for k in range(m - 1):\n            qq = np.array(list(map(lambda ms: tsum * t[m - 1][ms] / t[m - 2 - k][ms[:m - 1 - k]] / t[k][ms[m - 1 - k:]], tt.index))) > min_support\n            tt = tt[qq]\n        rt.append(tt.index)\n\n    def cal_S(sl):\n        from math import log\n        return -((sl / sl.sum()).apply(log) * sl / sl.sum()).sum()\n    for i in range(2, max_sep + 1):\n        print(u'\u6b63\u5728\u8fdb\u884c%s\u5b57\u8bcd\u7684\u6700\u5927\u71b5\u7b5b\u9009(%s)...' % (i, len(rt[i - 2])))\n        pp = []\n        for j in range(i):\n            pp = pp + re.findall('(.)%s(.)' % regexes[i], input_text[j:])\n        pp = pd.DataFrame(pp).set_index(1).sort_index()\n        index = np.sort(np.intersect1d(rt[i - 2], pp.index))\n        index = index[np.array(list(map(lambda s: cal_S(pd.Series(pp[0][s]).value_counts()), index))) > min_s]\n        rt[i - 2] = index[np.array(list(map(lambda s: cal_S(pd.Series(pp[2][s]).value_counts()), index))) > min_s]\n    for i in range(len(rt)):\n        t[i + 1] = t[i + 1][rt[i]]\n        t[i + 1].sort(ascending=False)\n"]]}
{"hexsha": "741823f78624eaea0ad9e096224c532974649085", "ext": "py", "lang": "Python", "content": "def test_verify_wal_starts_at_bof():\n    with TemporaryFile(\"w+b\") as tmp_file:\n        tmp_file.write(WAL_HEADER_95 + b\"XXX\" * 100)\n        tmp_file.seek(10)\n        wal.verify_wal(wal_name=\"0000002F000000110000009C\", fileobj=tmp_file)", "fn_id": 7, "class_fn": false, "repo": "st3fan/sphinx-automation-experiment", "file": "test/test_wal.py", "last_update_at": "2018-05-15T15:10:50+00:00", "question_id": "741823f78624eaea0ad9e096224c532974649085_7", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_verify_wal_starts_at_bof():\n    with TemporaryFile('w+b') as tmp_file:\n        tmp_file.write(WAL_HEADER_95 + b'XXX' * 100)\n        tmp_file.seek(10)\n"]]}
{"hexsha": "241fee9df6a2648ce6bff61320bbfc470557e17a", "ext": "py", "lang": "Python", "content": "@app.route('/login' , methods=['POST'])\ndef login():\n    username = request.get_json(force=True)['username']\n    password = request.get_json(force=True)['password']\n\n    user = next(iter([user for user in users if user.name == username]), None) \n\n    if user != None and user.password == password:\n        print('Logged in user %s' % (user.name))\n        login_user(user)\n        return 'Success', 200\n    else:\n       return 'Error: incorrect credentials', 401", "fn_id": 7, "class_fn": false, "repo": "Sebx/blockchain_wallet", "file": "app.py", "last_update_at": "2018-12-11T09:02:58+00:00", "question_id": "241fee9df6a2648ce6bff61320bbfc470557e17a_7", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@app.route('/login', methods=['POST'])\ndef login():\n    username = request.get_json(force=True)['username']\n    password = request.get_json(force=True)['password']\n    user = next(iter([user for user in users if user.name == username]), None)\n    if user != None and user.password == password:\n        print('Logged in user %s' % user.name)\n        login_user(user)\n        return ('Success', 200)\n    else:\n"]]}
{"hexsha": "92e133c01edbde47beda7f549525f67aa77057b1", "ext": "py", "lang": "Python", "content": "@mock.patch(\n    \"cumulusci.core.dependencies.dependencies.install_package_by_namespace_version\"\n)\ndef test_install_dependency_installs_managed_package(\n    install_package_by_namespace_version,\n):\n    task = create_task(\n        UpdateDependencies,\n        {\n            \"dependencies\": [\n                {\n                    \"namespace\": \"ns\",\n                    \"version\": \"1.0\",\n                }\n            ]\n        },\n    )\n    task.org_config = mock.Mock()\n    task.org_config.installed_packages = {}\n    task.org_config.has_minimum_package_version.return_value = False\n\n    task._install_dependency(task.dependencies[0])\n    install_package_by_namespace_version.assert_called_once_with(\n        task.project_config,\n        task.org_config,\n        \"ns\",\n        \"1.0\",\n        mock.ANY,\n        retry_options=mock.ANY,  # Ignore the options\n    )", "fn_id": 8, "class_fn": false, "repo": "davisagli/CumulusCI", "file": "cumulusci/tasks/salesforce/tests/test_update_dependencies.py", "last_update_at": "2018-08-31T12:12:39+00:00", "question_id": "92e133c01edbde47beda7f549525f67aa77057b1_8", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@mock.patch('cumulusci.core.dependencies.dependencies.install_package_by_namespace_version')\ndef test_install_dependency_installs_managed_package(install_package_by_namespace_version):\n    task = create_task(UpdateDependencies, {'dependencies': [{'namespace': 'ns', 'version': '1.0'}]})\n    task.org_config = mock.Mock()\n    task.org_config.installed_packages = {}\n    task.org_config.has_minimum_package_version.return_value = False\n    task._install_dependency(task.dependencies[0])\n"]]}
{"hexsha": "849ce5b6aa5ae2d8c179b69639be0fe0ff21cf6a", "ext": "py", "lang": "Python", "content": "def confirm_order(ident):\n    try:\n        log.info(\"confirm order status: %s\" %run_casper(confirm_js,[ident]))\n    except Exception as e:\n        log.error(\"could not confirm order %s\"%ident)\n        log.error(e)\n        raise", "fn_id": 2, "class_fn": false, "repo": "makefu/ali-orders", "file": "ali/ali/__init__.py", "last_update_at": "2018-09-15T15:53:01+00:00", "question_id": "849ce5b6aa5ae2d8c179b69639be0fe0ff21cf6a_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def confirm_order(ident):\n    try:\n        log.info('confirm order status: %s' % run_casper(confirm_js, [ident]))\n    except Exception as e:\n        log.error('could not confirm order %s' % ident)\n        log.error(e)\n"]]}
{"hexsha": "10d8af270631cf45c1e1bdca2e88d6528cfd84cf", "ext": "py", "lang": "Python", "content": "def test_Cluster_inputs():\n    input_map = dict(\n        args=dict(argstr='%s', ),\n        connectivity=dict(argstr='--connectivity=%d', ),\n        cope_file=dict(\n            argstr='--cope=%s',\n            extensions=None,\n        ),\n        dlh=dict(argstr='--dlh=%.10f', ),\n        environ=dict(\n            nohash=True,\n            usedefault=True,\n        ),\n        find_min=dict(\n            argstr='--min',\n            usedefault=True,\n        ),\n        fractional=dict(\n            argstr='--fractional',\n            usedefault=True,\n        ),\n        in_file=dict(\n            argstr='--in=%s',\n            extensions=None,\n            mandatory=True,\n        ),\n        minclustersize=dict(\n            argstr='--minclustersize',\n            usedefault=True,\n        ),\n        no_table=dict(\n            argstr='--no_table',\n            usedefault=True,\n        ),\n        num_maxima=dict(argstr='--num=%d', ),\n        out_index_file=dict(\n            argstr='--oindex=%s',\n            hash_files=False,\n        ),\n        out_localmax_txt_file=dict(\n            argstr='--olmax=%s',\n            hash_files=False,\n        ),\n        out_localmax_vol_file=dict(\n            argstr='--olmaxim=%s',\n            hash_files=False,\n        ),\n        out_max_file=dict(\n            argstr='--omax=%s',\n            hash_files=False,\n        ),\n        out_mean_file=dict(\n            argstr='--omean=%s',\n            hash_files=False,\n        ),\n        out_pval_file=dict(\n            argstr='--opvals=%s',\n            hash_files=False,\n        ),\n        out_size_file=dict(\n            argstr='--osize=%s',\n            hash_files=False,\n        ),\n        out_threshold_file=dict(\n            argstr='--othresh=%s',\n            hash_files=False,\n        ),\n        output_type=dict(),\n        peak_distance=dict(argstr='--peakdist=%.10f', ),\n        pthreshold=dict(\n            argstr='--pthresh=%.10f',\n            requires=['dlh', 'volume'],\n        ),\n        std_space_file=dict(\n            argstr='--stdvol=%s',\n            extensions=None,\n        ),\n        threshold=dict(\n            argstr='--thresh=%.10f',\n            mandatory=True,\n        ),\n        use_mm=dict(\n            argstr='--mm',\n            usedefault=True,\n        ),\n        volume=dict(argstr='--volume=%d', ),\n        warpfield_file=dict(\n            argstr='--warpvol=%s',\n            extensions=None,\n        ),\n        xfm_file=dict(\n            argstr='--xfm=%s',\n            extensions=None,\n        ),\n    )\n    inputs = Cluster.input_spec()\n\n    for key, metadata in list(input_map.items()):\n        for metakey, value in list(metadata.items()):\n            assert getattr(inputs.traits()[key], metakey) == value\n", "fn_id": 0, "class_fn": false, "repo": "PAmcconnell/nipype", "file": "nipype/interfaces/fsl/tests/test_auto_Cluster.py", "last_update_at": "2018-04-27T06:36:49+00:00", "question_id": "10d8af270631cf45c1e1bdca2e88d6528cfd84cf_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_Cluster_inputs():\n    input_map = dict(args=dict(argstr='%s'), connectivity=dict(argstr='--connectivity=%d'), cope_file=dict(argstr='--cope=%s', extensions=None), dlh=dict(argstr='--dlh=%.10f'), environ=dict(nohash=True, usedefault=True), find_min=dict(argstr='--min', usedefault=True), fractional=dict(argstr='--fractional', usedefault=True), in_file=dict(argstr='--in=%s', extensions=None, mandatory=True), minclustersize=dict(argstr='--minclustersize', usedefault=True), no_table=dict(argstr='--no_table', usedefault=True), num_maxima=dict(argstr='--num=%d'), out_index_file=dict(argstr='--oindex=%s', hash_files=False), out_localmax_txt_file=dict(argstr='--olmax=%s', hash_files=False), out_localmax_vol_file=dict(argstr='--olmaxim=%s', hash_files=False), out_max_file=dict(argstr='--omax=%s', hash_files=False), out_mean_file=dict(argstr='--omean=%s', hash_files=False), out_pval_file=dict(argstr='--opvals=%s', hash_files=False), out_size_file=dict(argstr='--osize=%s', hash_files=False), out_threshold_file=dict(argstr='--othresh=%s', hash_files=False), output_type=dict(), peak_distance=dict(argstr='--peakdist=%.10f'), pthreshold=dict(argstr='--pthresh=%.10f', requires=['dlh', 'volume']), std_space_file=dict(argstr='--stdvol=%s', extensions=None), threshold=dict(argstr='--thresh=%.10f', mandatory=True), use_mm=dict(argstr='--mm', usedefault=True), volume=dict(argstr='--volume=%d'), warpfield_file=dict(argstr='--warpvol=%s', extensions=None), xfm_file=dict(argstr='--xfm=%s', extensions=None))\n    inputs = Cluster.input_spec()\n    for key, metadata in list(input_map.items()):\n        for metakey, value in list(metadata.items()):\n"]]}
{"hexsha": "8a408f5613a018c669ff52f4bb2e33a522789493", "ext": "py", "lang": "Python", "content": "def makePanel(nper=None):\n    with warnings.catch_warnings(record=True):\n        warnings.filterwarnings(\"ignore\", \"\\\\nPanel\", FutureWarning)\n        cols = ['Item' + c for c in string.ascii_uppercase[:K - 1]]\n        data = {c: makeTimeDataFrame(nper) for c in cols}\n        return Panel.fromDict(data)", "fn_id": 64, "class_fn": false, "repo": "kokes/pandas", "file": "pandas/util/testing.py", "last_update_at": "2018-12-19T09:09:37+00:00", "question_id": "8a408f5613a018c669ff52f4bb2e33a522789493_64", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def makePanel(nper=None):\n    with warnings.catch_warnings(record=True):\n        warnings.filterwarnings('ignore', '\\\\nPanel', FutureWarning)\n        cols = ['Item' + c for c in string.ascii_uppercase[:K - 1]]\n        data = {c: makeTimeDataFrame(nper) for c in cols}\n"]]}
{"hexsha": "656d68b76888d9319c0b9be481f9b0478ac4314c", "ext": "py", "lang": "Python", "content": "def _iris_data_input_fn():\n  # Converts iris data to a logistic regression problem.\n  iris = base.load_iris()\n  ids = np.where((iris.target == 0) | (iris.target == 1))\n  features = constant_op.constant(iris.data[ids], dtype=dtypes.float32)\n  labels = constant_op.constant(iris.target[ids], dtype=dtypes.float32)\n  labels = array_ops.reshape(labels, labels.get_shape().concatenate(1))\n  return features, labels", "fn_id": 0, "class_fn": false, "repo": "harunpehlivan/tensorflow", "file": "tensorflow/contrib/learn/python/learn/estimators/logistic_regressor_test.py", "last_update_at": "2018-07-05T01:00:28+00:00", "question_id": "656d68b76888d9319c0b9be481f9b0478ac4314c_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _iris_data_input_fn():\n    iris = base.load_iris()\n    ids = np.where((iris.target == 0) | (iris.target == 1))\n    features = constant_op.constant(iris.data[ids], dtype=dtypes.float32)\n    labels = constant_op.constant(iris.target[ids], dtype=dtypes.float32)\n    labels = array_ops.reshape(labels, labels.get_shape().concatenate(1))\n"]]}
{"hexsha": "8282b7c9525f4039a97c0b515ce586b7a0996f57", "ext": "py", "lang": "Python", "content": "def world_configuration(world_width, world_height):\n    world = VisualWorld(width=world_width, height=world_height)\n    world.set_engine(Engine(world))  # TODO: Smelly design\n\n    lines = [\n        Line(start=(0, 0.2), end=(world_width, 0.2)),\n        Line(start=(0, world_height / 2), end=(world_width, world_height / 2), discontinuous=True, color='y'),\n        Line(start=(0, world_height - 0.2), end=(world_width, world_height - 0.2))\n    ]\n    lines_visuals = [\n        LinePyplot(line=lines[0], width=LANE_WIDTH),\n        # LinePyplot(line=lines[1], width=LANE_WIDTH),\n        LinePyplot(line=lines[2], width=LANE_WIDTH),\n    ]\n\n    lanes = [\n        Lane(lines[0], lines[1], direction=LaneDirection.START_TO_END),\n        Lane(lines[1], lines[2], direction=LaneDirection.END_TO_START)\n    ]\n\n    signs = [\n        SenseFloorSign(lanes[0]),\n        SenseFloorSign(lanes[1])\n    ]\n    signs_visuals = [\n        DirectionSignPyplot(floor_sign=signs[0], scale=ARROWS_SCALE),\n        DirectionSignPyplot(floor_sign=signs[1], scale=ARROWS_SCALE),\n    ]\n\n    world.semantics.extend(lines)\n    world.visuals.extend(lines_visuals)\n\n    world.semantics.extend(lanes)\n\n    world.semantics.extend(signs)\n    world.visuals.extend(signs_visuals)\n\n    return world, lanes", "fn_id": 0, "class_fn": false, "repo": "takeitallsource/pac-simulator", "file": "src/driving_curriculum/tasks/lane_following/scenarios/two_lanes_two_ways.py", "last_update_at": "2018-07-14T07:09:23+00:00", "question_id": "8282b7c9525f4039a97c0b515ce586b7a0996f57_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def world_configuration(world_width, world_height):\n    world = VisualWorld(width=world_width, height=world_height)\n    world.set_engine(Engine(world))\n    lines = [Line(start=(0, 0.2), end=(world_width, 0.2)), Line(start=(0, world_height / 2), end=(world_width, world_height / 2), discontinuous=True, color='y'), Line(start=(0, world_height - 0.2), end=(world_width, world_height - 0.2))]\n    lines_visuals = [LinePyplot(line=lines[0], width=LANE_WIDTH), LinePyplot(line=lines[2], width=LANE_WIDTH)]\n    lanes = [Lane(lines[0], lines[1], direction=LaneDirection.START_TO_END), Lane(lines[1], lines[2], direction=LaneDirection.END_TO_START)]\n    signs = [SenseFloorSign(lanes[0]), SenseFloorSign(lanes[1])]\n    signs_visuals = [DirectionSignPyplot(floor_sign=signs[0], scale=ARROWS_SCALE), DirectionSignPyplot(floor_sign=signs[1], scale=ARROWS_SCALE)]\n    world.semantics.extend(lines)\n    world.visuals.extend(lines_visuals)\n    world.semantics.extend(lanes)\n    world.semantics.extend(signs)\n    world.visuals.extend(signs_visuals)\n"]]}
{"hexsha": "83d0fd24c824480938c493ec8afd0bfbc45d9062", "ext": "py", "lang": "Python", "content": "def load_data(shuffle=True, n_cols=None):\n    train_path = get_p1_file('http://ftp.mcs.anl.gov/pub/candle/public/benchmarks/P1B1/P1B1.train.csv')\n    test_path = get_p1_file('http://ftp.mcs.anl.gov/pub/candle/public/benchmarks/P1B1/P1B1.test.csv')\n\n    usecols = list(range(n_cols)) if n_cols else None\n\n    df_train = pd.read_csv(train_path, engine='c', usecols=usecols)\n    df_test = pd.read_csv(test_path, engine='c', usecols=usecols)\n\n    df_train = df_train.drop('case_id', 1).astype(np.float32)\n    df_test = df_test.drop('case_id', 1).astype(np.float32)\n\n    if shuffle:\n        df_train = df_train.sample(frac=1, random_state=seed)\n        df_test = df_test.sample(frac=1, random_state=seed)\n\n    X_train = df_train.as_matrix()\n    X_test = df_test.as_matrix()\n\n    scaler = MaxAbsScaler()\n    mat = np.concatenate((X_train, X_test), axis=0)\n    mat = scaler.fit_transform(mat)\n\n    X_train = mat[:X_train.shape[0], :]\n    X_test = mat[X_train.shape[0]:, :]\n\n    return X_train, X_test", "fn_id": 0, "class_fn": false, "repo": "pkarande/Benchmarks-1", "file": "Pilot1/P1B1/p1b1.py", "last_update_at": "2018-12-04T04:13:05+00:00", "question_id": "83d0fd24c824480938c493ec8afd0bfbc45d9062_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def load_data(shuffle=True, n_cols=None):\n    train_path = get_p1_file('http://ftp.mcs.anl.gov/pub/candle/public/benchmarks/P1B1/P1B1.train.csv')\n    test_path = get_p1_file('http://ftp.mcs.anl.gov/pub/candle/public/benchmarks/P1B1/P1B1.test.csv')\n    usecols = list(range(n_cols)) if n_cols else None\n    df_train = pd.read_csv(train_path, engine='c', usecols=usecols)\n    df_test = pd.read_csv(test_path, engine='c', usecols=usecols)\n    df_train = df_train.drop('case_id', 1).astype(np.float32)\n    df_test = df_test.drop('case_id', 1).astype(np.float32)\n    if shuffle:\n        df_train = df_train.sample(frac=1, random_state=seed)\n        df_test = df_test.sample(frac=1, random_state=seed)\n    X_train = df_train.as_matrix()\n    X_test = df_test.as_matrix()\n    scaler = MaxAbsScaler()\n    mat = np.concatenate((X_train, X_test), axis=0)\n    mat = scaler.fit_transform(mat)\n    X_train = mat[:X_train.shape[0], :]\n    X_test = mat[X_train.shape[0]:, :]\n"]]}
{"hexsha": "3b6e1c7678354b11c31463fa6993eb5863c91a8e", "ext": "py", "lang": "Python", "content": "def get_dataset_input_from_database(customer):\n    rows = [];\n    try:\n        conn = get_connection()\n        cur = conn.cursor()\n        cur.execute(' SELECT '\n                    '     example_value.value '\n                    ' FROM '\n                    '     example_values example_value '\n                    '     INNER JOIN examples example ON example.id = example_value.example_id '\n                    '     INNER JOIN fields field ON example_value.field_id = field.id '\n                    ' WHERE '\n                    '     example.customer = %s '\n                    '     AND field.type = \\'input\\' '\n                    '     AND field.customer = %s '\n                    ' ORDER BY '\n                    '     example_value.example_id , '\n                    '     field.name ', [customer, customer])\n        rows = cur.fetchall()\n        cur.close()\n    except (Exception, psycopg2.DatabaseError) as error:\n        print(error)\n    finally:\n        if conn is not None:\n            conn.close()\n            return join_rows(customer, rows)", "fn_id": 1, "class_fn": false, "repo": "vinigomes/intellead-classification", "file": "service.py", "last_update_at": "2018-01-29T20:27:03+00:00", "question_id": "3b6e1c7678354b11c31463fa6993eb5863c91a8e_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_dataset_input_from_database(customer):\n    rows = []\n    try:\n        conn = get_connection()\n        cur = conn.cursor()\n        cur.execute(\" SELECT      example_value.value  FROM      example_values example_value      INNER JOIN examples example ON example.id = example_value.example_id      INNER JOIN fields field ON example_value.field_id = field.id  WHERE      example.customer = %s      AND field.type = 'input'      AND field.customer = %s  ORDER BY      example_value.example_id ,      field.name \", [customer, customer])\n        rows = cur.fetchall()\n        cur.close()\n    except (Exception, psycopg2.DatabaseError) as error:\n        print(error)\n    finally:\n        if conn is not None:\n            conn.close()\n"]]}
{"hexsha": "8246eeb2f76437680073f3d376dbef3bc6cf0df9", "ext": "py", "lang": "Python", "content": "def grab_latest_content():\n    json_dict = {}\n    for i in SESSIONS:\n        r = requests.get('{1}/Session{0}/session_{0}_problems.md'.format(i, ROOT_URL)).text\n        key = 'session_{0}'.format(i)\n        json_dict[key] = markdown.markdown(r, extensions=EXTENTIONS)\n    return json_dict", "fn_id": 1, "class_fn": false, "repo": "pathespe/MarkerBot", "file": "views/views.py", "last_update_at": "2018-03-21T00:40:33+00:00", "question_id": "8246eeb2f76437680073f3d376dbef3bc6cf0df9_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def grab_latest_content():\n    json_dict = {}\n    for i in SESSIONS:\n        r = requests.get('{1}/Session{0}/session_{0}_problems.md'.format(i, ROOT_URL)).text\n        key = 'session_{0}'.format(i)\n        json_dict[key] = markdown.markdown(r, extensions=EXTENTIONS)\n"]]}
{"hexsha": "b113786163b690375e45a351d4ca53cd2e4c5754", "ext": "py", "lang": "Python", "content": "def calculate_stride(var: Variable, axis: Axis) -> Union[int, Placeholder]:\n    \"\"\"\n    calculate stride for specified dimension of specified variable.\n\n    :param var: variable\n    :param axis: axis\n    :return: \n    \"\"\"\n    return mul(var.shape[var.order.axes_dict[axis] + 1:])", "fn_id": 0, "class_fn": false, "repo": "gunpowder78/webdnn", "file": "src/graph_transpiler/webdnn/backend/fallback/kernels/util.py", "last_update_at": "2018-07-26T13:52:21+00:00", "question_id": "b113786163b690375e45a351d4ca53cd2e4c5754_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def calculate_stride(var: Variable, axis: Axis) -> Union[int, Placeholder]:\n    \"\"\"\n    calculate stride for specified dimension of specified variable.\n\n    :param var: variable\n    :param axis: axis\n    :return: \n    \"\"\"\n"]]}
{"hexsha": "918ab2735794b082c2165714e70722c28913def1", "ext": "py", "lang": "Python", "content": "def get_rep_frags(frags, loci, loci_ids, num_reps=4, no_cache=False):\n    \"\"\"Get a number of representatives for each cluster\n\n    [description]\n\n    Arguments:\n        frags {list} -- List of numpy arrays representing the fragment\n        num_reps {int} -- Number of representatives\n    \"\"\"\n    num_frags = len(frags)\n\n    if num_frags < 5:\n        sizes = np.zeros([num_frags])\n\n        for i, frag in enumerate(frags):\n            sizes[i] = np.prod(frag.shape[0:2])\n\n        idx = np.argsort(sizes).astype(np.uint8)[::-1]\n\n        return [frags[i] for i in idx], idx\n\n    out, _, _ = get_scale_frags_to_same_size(\n        frags, loci_ids, 32, no_cache\n    )\n\n    # Get largest frag based on world coords\n    largest_a = 0\n    for i, locus in enumerate(loci):\n        a = abs(locus[1] - locus[0]) * abs(locus[3] - locus[2])\n        if a > largest_a:\n            largest_a = a\n            largest_frag_idx = i\n\n    mean_frag = np.nanmean(out, axis=0)\n    diff_mean_frags = out - mean_frag\n\n    # Sum each x,y and c (channel) value up per f (fragment) and take the\n    # sqaure root to get the L2 norm\n    dist_to_mean = np.sqrt(\n        np.einsum('fxyc,fxyc->f', diff_mean_frags, diff_mean_frags)\n    )\n\n    # Get the fragment closest to the mean\n    # Get the index of the i-th smallest value i=0 == smallest value\n    closest_mean_frag_idx = np.argpartition(dist_to_mean, 0)[0]\n    if closest_mean_frag_idx == largest_frag_idx:\n        closest_mean_frag_idx = np.argpartition(dist_to_mean, 1)[1]\n\n    # Get the frag farthest away from\n    for i in range(len(dist_to_mean) - 1, -1, -1):\n        farthest_mean_frag_idx = np.argpartition(dist_to_mean, i)[i]\n        if (\n            farthest_mean_frag_idx != largest_frag_idx and\n            farthest_mean_frag_idx != closest_mean_frag_idx\n        ):\n            break\n\n    # Distance to farthest away frag\n    diff_farthest_frags = out - out[np.argmax(dist_to_mean)]\n    dist_to_farthest = np.sqrt(\n        np.einsum('fxyc,fxyc->f', diff_farthest_frags, diff_farthest_frags)\n    )\n\n    # Get the frag farthest away from the frag farthest away from the mean\n    for i in range(len(dist_to_farthest) - 1, -1, -1):\n        farthest_farthest_frag_idx = np.argpartition(dist_to_farthest, i)[i]\n        if (\n            farthest_farthest_frag_idx != largest_frag_idx and\n            farthest_farthest_frag_idx != closest_mean_frag_idx and\n            farthest_farthest_frag_idx != farthest_mean_frag_idx\n        ):\n            break\n\n    frags = [\n        frags[largest_frag_idx],\n        frags[closest_mean_frag_idx],\n        frags[farthest_mean_frag_idx],\n        frags[farthest_farthest_frag_idx]\n    ]\n\n    idx = [\n        largest_frag_idx,\n        closest_mean_frag_idx,\n        farthest_mean_frag_idx,\n        farthest_farthest_frag_idx\n    ]\n\n    return frags, idx", "fn_id": 11, "class_fn": false, "repo": "alexpreynolds/higlass-server", "file": "fragments/utils.py", "last_update_at": "2018-11-17T22:14:21+00:00", "question_id": "918ab2735794b082c2165714e70722c28913def1_11", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_rep_frags(frags, loci, loci_ids, num_reps=4, no_cache=False):\n    \"\"\"Get a number of representatives for each cluster\n\n    [description]\n\n    Arguments:\n        frags {list} -- List of numpy arrays representing the fragment\n        num_reps {int} -- Number of representatives\n    \"\"\"\n    num_frags = len(frags)\n    if num_frags < 5:\n        sizes = np.zeros([num_frags])\n        for i, frag in enumerate(frags):\n            sizes[i] = np.prod(frag.shape[0:2])\n        idx = np.argsort(sizes).astype(np.uint8)[::-1]\n        return ([frags[i] for i in idx], idx)\n    out, _, _ = get_scale_frags_to_same_size(frags, loci_ids, 32, no_cache)\n    largest_a = 0\n    for i, locus in enumerate(loci):\n        a = abs(locus[1] - locus[0]) * abs(locus[3] - locus[2])\n        if a > largest_a:\n            largest_a = a\n            largest_frag_idx = i\n    mean_frag = np.nanmean(out, axis=0)\n    diff_mean_frags = out - mean_frag\n    dist_to_mean = np.sqrt(np.einsum('fxyc,fxyc->f', diff_mean_frags, diff_mean_frags))\n    closest_mean_frag_idx = np.argpartition(dist_to_mean, 0)[0]\n    if closest_mean_frag_idx == largest_frag_idx:\n        closest_mean_frag_idx = np.argpartition(dist_to_mean, 1)[1]\n    for i in range(len(dist_to_mean) - 1, -1, -1):\n        farthest_mean_frag_idx = np.argpartition(dist_to_mean, i)[i]\n        if farthest_mean_frag_idx != largest_frag_idx and farthest_mean_frag_idx != closest_mean_frag_idx:\n            break\n    diff_farthest_frags = out - out[np.argmax(dist_to_mean)]\n    dist_to_farthest = np.sqrt(np.einsum('fxyc,fxyc->f', diff_farthest_frags, diff_farthest_frags))\n    for i in range(len(dist_to_farthest) - 1, -1, -1):\n        farthest_farthest_frag_idx = np.argpartition(dist_to_farthest, i)[i]\n        if farthest_farthest_frag_idx != largest_frag_idx and farthest_farthest_frag_idx != closest_mean_frag_idx and (farthest_farthest_frag_idx != farthest_mean_frag_idx):\n            break\n    frags = [frags[largest_frag_idx], frags[closest_mean_frag_idx], frags[farthest_mean_frag_idx], frags[farthest_farthest_frag_idx]]\n    idx = [largest_frag_idx, closest_mean_frag_idx, farthest_mean_frag_idx, farthest_farthest_frag_idx]\n"]]}
{"hexsha": "297acdd5259eadc3a4d3639a0e498a4f05e5c74a", "ext": "py", "lang": "Python", "content": "def mypca(X):\n  \"\"\"  Principal Component Analysis\n    input: X, matrix with training data stored as flattened arrays in rows\n    return: projection matrix (with important dimensions first), variance\n    and mean.\"\"\"\n\n  # get dimensions\n  num_data,dim = X.shape\n\n  # center data\n  mean_X = X.mean(axis=0)\n  B = X - mean_X\n\n  \n  S = dot(B,B.T)/3# covariance matrix\n  print(\"S\")\n  print(S)\n  e,EV = linalg.eigh(S) # eigenvalues and eigenvectors\n  e=e[::-1]\n  print(\"e\")\n  print(e)\n  EV=fliplr(EV)\n  print(\"EV\")\n  print(EV)\n  y0 = dot(EV.T,B) # this is the compact trick\n  \n  S = sqrt(e)\n  print(\"S\")\n  print(S)\n  \n\n  # return the projection matrix, the variance and the mean\n  return y0,mean_X", "fn_id": 0, "class_fn": false, "repo": "pacificblue/Machine-Learning-and-Data-Analysis", "file": "1 Unsupervised_Learning/MyPca.py", "last_update_at": "2018-11-07T15:17:46+00:00", "question_id": "297acdd5259eadc3a4d3639a0e498a4f05e5c74a_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def mypca(X):\n    \"\"\"  Principal Component Analysis\n    input: X, matrix with training data stored as flattened arrays in rows\n    return: projection matrix (with important dimensions first), variance\n    and mean.\"\"\"\n    num_data, dim = X.shape\n    mean_X = X.mean(axis=0)\n    B = X - mean_X\n    S = dot(B, B.T) / 3\n    print('S')\n    print(S)\n    e, EV = linalg.eigh(S)\n    e = e[::-1]\n    print('e')\n    print(e)\n    EV = fliplr(EV)\n    print('EV')\n    print(EV)\n    y0 = dot(EV.T, B)\n    S = sqrt(e)\n    print('S')\n    print(S)\n"]]}
{"hexsha": "28940e8c7f57d81965cbf8c93980e4b344c4c828", "ext": "py", "lang": "Python", "content": "def fake_city():\n    \"\"\" Fake repartition (Random Generator) \"\"\"\n    # [\"A\"][1] not random on purpose\n    city = {\"A\":{1:0, 2:17, 3:7},\n            \"B\":{1:11, 2:1, 3:8},\n            \"C\":{1:9, 2:16, 3:2}}\n    return city", "fn_id": 2, "class_fn": false, "repo": "scities/segregatown", "file": "marble/tests/test_dissimilarity.py", "last_update_at": "2018-02-19T16:36:56+00:00", "question_id": "28940e8c7f57d81965cbf8c93980e4b344c4c828_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def fake_city():\n    \"\"\" Fake repartition (Random Generator) \"\"\"\n    city = {'A': {1: 0, 2: 17, 3: 7}, 'B': {1: 11, 2: 1, 3: 8}, 'C': {1: 9, 2: 16, 3: 2}}\n"]]}
{"hexsha": "02dc3296d27288660daaaaf7bc5adc5c4fce8b50", "ext": "py", "lang": "Python", "content": "def py2_encode(s, encoding='utf-8'):\n   \"\"\"\n   Encode Python 2 ``unicode`` to ``str``\n\n   In Python 3 the string is not changed.   \n   \"\"\"\n   if PY2 and isinstance(s, unicode):\n       s = s.encode(encoding)\n   return s", "fn_id": 0, "class_fn": false, "repo": "YeaSoft/plugin.video.mediathekview", "file": "resources/lib/mvutils.py", "last_update_at": "2018-01-08T20:33:08+00:00", "question_id": "02dc3296d27288660daaaaf7bc5adc5c4fce8b50_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def py2_encode(s, encoding='utf-8'):\n    \"\"\"\n   Encode Python 2 ``unicode`` to ``str``\n\n   In Python 3 the string is not changed.   \n   \"\"\"\n    if PY2 and isinstance(s, unicode):\n        s = s.encode(encoding)\n"]]}
{"hexsha": "466a8269775df60cf80920230c95c8e3a32ee9a9", "ext": "py", "lang": "Python", "content": "@server.register_function()\nasync def testcorogen(a, b):\n    for i in range(10):\n        await asyncio.sleep(0.1)\n        yield i + a + b", "fn_id": 2, "class_fn": false, "repo": "Basic-Components/msgpack-rpc", "file": "python/test_server.py", "last_update_at": "2018-03-30T17:26:21+00:00", "question_id": "466a8269775df60cf80920230c95c8e3a32ee9a9_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@server.register_function()\nasync def testcorogen(a, b):\n    for i in range(10):\n        await asyncio.sleep(0.1)\n"]]}
{"hexsha": "3f25d260589201e7baec25d76562efa134dffc59", "ext": "py", "lang": "Python", "content": "def get_cookbook_url(config, tmpdir):\n    if config.args.custom_ami_cookbook is not None:\n        return config.args.custom_ami_cookbook\n    else:\n        cookbook_version = get_cookbook_version(config, tmpdir)\n        if config.region == 'us-gov-west-1':\n            return ('https://s3-%s.amazonaws.com/%s-aws-parallelcluster/cookbooks/%s.tgz'\n                         % (config.region, config.region, cookbook_version))\n        elif config.region == 'us-east-1':\n            return ('https://s3.amazonaws.com/%s-aws-parallelcluster/cookbooks/%s.tgz'\n                         % (config.region, cookbook_version))\n        else:\n            return ('https://s3.%s.amazonaws.com/%s-aws-parallelcluster/cookbooks/%s.tgz'\n                         % (config.region, config.region, cookbook_version))", "fn_id": 18, "class_fn": false, "repo": "cfncluster-ami-bot/aws-parallelcluster", "file": "cli/pcluster/pcluster.py", "last_update_at": "2018-11-21T02:58:58+00:00", "question_id": "3f25d260589201e7baec25d76562efa134dffc59_18", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_cookbook_url(config, tmpdir):\n    if config.args.custom_ami_cookbook is not None:\n        return config.args.custom_ami_cookbook\n    else:\n        cookbook_version = get_cookbook_version(config, tmpdir)\n        if config.region == 'us-gov-west-1':\n            return 'https://s3-%s.amazonaws.com/%s-aws-parallelcluster/cookbooks/%s.tgz' % (config.region, config.region, cookbook_version)\n        elif config.region == 'us-east-1':\n            return 'https://s3.amazonaws.com/%s-aws-parallelcluster/cookbooks/%s.tgz' % (config.region, cookbook_version)\n        else:\n"]]}
{"hexsha": "ee784383ede5373c25eb9885e4451ddd04836b26", "ext": "py", "lang": "Python", "content": "def test_string_values():\n    x = dict(a='a', b='b')\n\n    with no_mutations(x):\n        test = x['a']\n    assert test == 'a'\n\n    with pytest.raises(MutationError):\n        with no_mutations(x):\n            x['c'] = 'c'\n    assert 'c' in x", "fn_id": 8, "class_fn": false, "repo": "fastats/privates", "file": "tests/test_mutations.py", "last_update_at": "2018-10-02T20:32:12+00:00", "question_id": "ee784383ede5373c25eb9885e4451ddd04836b26_8", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_string_values():\n    x = dict(a='a', b='b')\n    with no_mutations(x):\n        test = x['a']\n    assert test == 'a'\n    with pytest.raises(MutationError):\n        with no_mutations(x):\n            x['c'] = 'c'\n"]]}
{"hexsha": "5b84f1d6a2df7b3cfcbfe1a31e05024eb40a3ee4", "ext": "py", "lang": "Python", "content": "def b58check_unpack(b58_s):\n    \"\"\" Takes in a base 58 check string and returns: the version byte, the\n        original encoded binary string, and the checksum.\n    \"\"\"\n    num_leading_zeros = len(re.match(r'^1*', b58_s).group(0))\n    # convert from b58 to b16\n    hex_s = change_charset(b58_s, B58_KEYSPACE, HEX_KEYSPACE)\n    # if an odd number of hex characters are present, add a zero to the front\n    if len(hex_s) % 2 == 1:\n        hex_s = \"0\" + hex_s\n    # convert from b16 to b2\n    bin_s = binascii.unhexlify(hex_s)\n    # add in the leading zeros\n    bin_s = '\\x00' * num_leading_zeros + bin_s\n    # make sure the newly calculated checksum equals the embedded checksum\n    newly_calculated_checksum = bin_checksum(bin_s[:-4])\n    embedded_checksum = bin_s[-4:]\n    if not (newly_calculated_checksum == embedded_checksum):\n        raise ValueError('b58check value has an invalid checksum')\n    # return values\n    version_byte = bin_s[:1]\n    encoded_value = bin_s[1:-4]\n    checksum = bin_s[-4:]\n    return version_byte, encoded_value, checksum", "fn_id": 7, "class_fn": false, "repo": "UlordChain/uwallet-client-pro", "file": "lib/privatekey.py", "last_update_at": "2018-08-21T06:59:07+00:00", "question_id": "5b84f1d6a2df7b3cfcbfe1a31e05024eb40a3ee4_7", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def b58check_unpack(b58_s):\n    \"\"\" Takes in a base 58 check string and returns: the version byte, the\n        original encoded binary string, and the checksum.\n    \"\"\"\n    num_leading_zeros = len(re.match('^1*', b58_s).group(0))\n    hex_s = change_charset(b58_s, B58_KEYSPACE, HEX_KEYSPACE)\n    if len(hex_s) % 2 == 1:\n        hex_s = '0' + hex_s\n    bin_s = binascii.unhexlify(hex_s)\n    bin_s = '\\x00' * num_leading_zeros + bin_s\n    newly_calculated_checksum = bin_checksum(bin_s[:-4])\n    embedded_checksum = bin_s[-4:]\n    if not newly_calculated_checksum == embedded_checksum:\n        raise ValueError('b58check value has an invalid checksum')\n    version_byte = bin_s[:1]\n    encoded_value = bin_s[1:-4]\n    checksum = bin_s[-4:]\n"]]}
{"hexsha": "0f595c3e546e8f2d5186f0ef90499cb20eba8fbe", "ext": "py", "lang": "Python", "content": "def includeme(config):\n    LOGGER.info(\"init audit-request plugin\")\n    config.set_authentication_policy(\n        AuthenticationPolicy(config.registry.settings[\"auth.file\"])\n    )\n    add_design()\n    config.add_subscriber(set_logging_context, ContextFound)\n    config.add_request_method(extract_request, \"request\", reify=True)\n    config.add_request_method(request_from_data)\n    config.scan(\"openprocurement.audit.request.views\")", "fn_id": 0, "class_fn": false, "repo": "ProzorroUKR/openprocurement.audit.api", "file": "openprocurement/audit/request/__init__.py", "last_update_at": "2018-05-21T08:14:55+00:00", "question_id": "0f595c3e546e8f2d5186f0ef90499cb20eba8fbe_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def includeme(config):\n    LOGGER.info('init audit-request plugin')\n    config.set_authentication_policy(AuthenticationPolicy(config.registry.settings['auth.file']))\n    add_design()\n    config.add_subscriber(set_logging_context, ContextFound)\n    config.add_request_method(extract_request, 'request', reify=True)\n    config.add_request_method(request_from_data)\n"]]}
{"hexsha": "dbf3f28def60bd4f9849e7b28bedaee9ac70ae92", "ext": "py", "lang": "Python", "content": "def create_custom_exception(exc_type, exc_val, exc_tb, strategy_filename):\n    try:\n        msg = str(exc_val)\n    except:\n        msg = \"\"\n\n    error = CustomError()\n    error.set_msg(msg)\n    error.set_exc(exc_type, exc_val, exc_tb)\n\n    import linecache\n\n    filename = ''\n    tb = exc_tb\n    while tb:\n        co = tb.tb_frame.f_code\n        filename = co.co_filename\n        if filename != strategy_filename:\n            tb = tb.tb_next\n            continue\n        lineno = tb.tb_lineno\n        func_name = co.co_name\n        code = linecache.getline(filename, lineno).strip()\n        error.add_stack_info(filename, lineno, func_name, code, tb.tb_frame.f_locals)\n        tb = tb.tb_next\n\n    if filename == strategy_filename:\n        error.error_type = EXC_TYPE.USER_EXC\n\n    user_exc = CustomException(error)\n    return user_exc", "fn_id": 2, "class_fn": false, "repo": "luhouxiang/byrobot", "file": "bwtougu/utils/__init__.py", "last_update_at": "2018-09-28T08:59:38+00:00", "question_id": "dbf3f28def60bd4f9849e7b28bedaee9ac70ae92_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def create_custom_exception(exc_type, exc_val, exc_tb, strategy_filename):\n    try:\n        msg = str(exc_val)\n    except:\n        msg = ''\n    error = CustomError()\n    error.set_msg(msg)\n    error.set_exc(exc_type, exc_val, exc_tb)\n    import linecache\n    filename = ''\n    tb = exc_tb\n    while tb:\n        co = tb.tb_frame.f_code\n        filename = co.co_filename\n        if filename != strategy_filename:\n            tb = tb.tb_next\n            continue\n        lineno = tb.tb_lineno\n        func_name = co.co_name\n        code = linecache.getline(filename, lineno).strip()\n        error.add_stack_info(filename, lineno, func_name, code, tb.tb_frame.f_locals)\n        tb = tb.tb_next\n    if filename == strategy_filename:\n        error.error_type = EXC_TYPE.USER_EXC\n    user_exc = CustomException(error)\n"]]}
{"hexsha": "995b14d4a719784262369151c0522ea38ea5464e", "ext": "py", "lang": "Python", "content": "def only_with_neutron_extension(extension):\n    def decorator(func):\n        @wraps(func)\n        def wrapper(self, *args, **kwargs):\n            if self.has_neutron_extension(extension):\n                return func(self, *args, **kwargs)\n            else:\n                self.class_logger.error(('Function %s called that expects neutron extension '\n                                         '%s which is not installed.'), func.__name__, extension)\n        return wrapper\n    return decorator", "fn_id": 0, "class_fn": false, "repo": "stepanandr/taf", "file": "taf/testlib/virtual_env.py", "last_update_at": "2018-10-30T17:48:25+00:00", "question_id": "995b14d4a719784262369151c0522ea38ea5464e_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def only_with_neutron_extension(extension):\n\n    def decorator(func):\n\n        @wraps(func)\n        def wrapper(self, *args, **kwargs):\n            if self.has_neutron_extension(extension):\n                return func(self, *args, **kwargs)\n            else:\n                self.class_logger.error('Function %s called that expects neutron extension %s which is not installed.', func.__name__, extension)\n        return wrapper\n"]]}
{"hexsha": "ec87d86573c9d0408b7099b2894f05355039e762", "ext": "py", "lang": "Python", "content": "def MvNormalLogp():\n    \"\"\"Compute the log pdf of a multivariate normal distribution.\n\n    This should be used in MvNormal.logp once Theano#5908 is released.\n\n    Parameters\n    ----------\n    cov : tt.matrix\n        The covariance matrix.\n    delta : tt.matrix\n        Array of deviations from the mean.\n    \"\"\"\n    cov = tt.matrix('cov')\n    cov.tag.test_value = floatX(np.eye(3))\n    delta = tt.matrix('delta')\n    delta.tag.test_value = floatX(np.zeros((2, 3)))\n\n    solve_lower = tt.slinalg.Solve(A_structure='lower_triangular')\n    solve_upper = tt.slinalg.Solve(A_structure='upper_triangular')\n    cholesky = Cholesky(lower=True, on_error='nan')\n\n    n, k = delta.shape\n    n, k = f(n), f(k)\n    chol_cov = cholesky(cov)\n    diag = tt.nlinalg.diag(chol_cov)\n    ok = tt.all(diag > 0)\n\n    chol_cov = tt.switch(ok, chol_cov, tt.fill(chol_cov, 1))\n    delta_trans = solve_lower(chol_cov, delta.T).T\n\n    result = n * k * tt.log(f(2) * np.pi)\n    result += f(2) * n * tt.sum(tt.log(diag))\n    result += (delta_trans ** f(2)).sum()\n    result = f(-.5) * result\n    logp = tt.switch(ok, result, -np.inf)\n\n    def dlogp(inputs, gradients):\n        g_logp, = gradients\n        cov, delta = inputs\n\n        g_logp.tag.test_value = floatX(1.)\n        n, k = delta.shape\n\n        chol_cov = cholesky(cov)\n        diag = tt.nlinalg.diag(chol_cov)\n        ok = tt.all(diag > 0)\n\n        chol_cov = tt.switch(ok, chol_cov, tt.fill(chol_cov, 1))\n        delta_trans = solve_lower(chol_cov, delta.T).T\n\n        inner = n * tt.eye(k) - tt.dot(delta_trans.T, delta_trans)\n        g_cov = solve_upper(chol_cov.T, inner)\n        g_cov = solve_upper(chol_cov.T, g_cov.T)\n\n        tau_delta = solve_upper(chol_cov.T, delta_trans.T)\n        g_delta = tau_delta.T\n\n        g_cov = tt.switch(ok, g_cov, -np.nan)\n        g_delta = tt.switch(ok, g_delta, -np.nan)\n\n        return [-0.5 * g_cov * g_logp, -g_delta * g_logp]\n\n    return theano.OpFromGraph(\n        [cov, delta], [logp], grad_overrides=dlogp, inline=True)", "fn_id": 8, "class_fn": false, "repo": "canyon289/pymc", "file": "pymc3/distributions/dist_math.py", "last_update_at": "2018-06-11T03:13:00+00:00", "question_id": "ec87d86573c9d0408b7099b2894f05355039e762_8", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def MvNormalLogp():\n    \"\"\"Compute the log pdf of a multivariate normal distribution.\n\n    This should be used in MvNormal.logp once Theano#5908 is released.\n\n    Parameters\n    ----------\n    cov : tt.matrix\n        The covariance matrix.\n    delta : tt.matrix\n        Array of deviations from the mean.\n    \"\"\"\n    cov = tt.matrix('cov')\n    cov.tag.test_value = floatX(np.eye(3))\n    delta = tt.matrix('delta')\n    delta.tag.test_value = floatX(np.zeros((2, 3)))\n    solve_lower = tt.slinalg.Solve(A_structure='lower_triangular')\n    solve_upper = tt.slinalg.Solve(A_structure='upper_triangular')\n    cholesky = Cholesky(lower=True, on_error='nan')\n    n, k = delta.shape\n    n, k = (f(n), f(k))\n    chol_cov = cholesky(cov)\n    diag = tt.nlinalg.diag(chol_cov)\n    ok = tt.all(diag > 0)\n    chol_cov = tt.switch(ok, chol_cov, tt.fill(chol_cov, 1))\n    delta_trans = solve_lower(chol_cov, delta.T).T\n    result = n * k * tt.log(f(2) * np.pi)\n    result += f(2) * n * tt.sum(tt.log(diag))\n    result += (delta_trans ** f(2)).sum()\n    result = f(-0.5) * result\n    logp = tt.switch(ok, result, -np.inf)\n\n    def dlogp(inputs, gradients):\n        g_logp, = gradients\n        cov, delta = inputs\n        g_logp.tag.test_value = floatX(1.0)\n        n, k = delta.shape\n        chol_cov = cholesky(cov)\n        diag = tt.nlinalg.diag(chol_cov)\n        ok = tt.all(diag > 0)\n        chol_cov = tt.switch(ok, chol_cov, tt.fill(chol_cov, 1))\n        delta_trans = solve_lower(chol_cov, delta.T).T\n        inner = n * tt.eye(k) - tt.dot(delta_trans.T, delta_trans)\n        g_cov = solve_upper(chol_cov.T, inner)\n        g_cov = solve_upper(chol_cov.T, g_cov.T)\n        tau_delta = solve_upper(chol_cov.T, delta_trans.T)\n        g_delta = tau_delta.T\n        g_cov = tt.switch(ok, g_cov, -np.nan)\n        g_delta = tt.switch(ok, g_delta, -np.nan)\n        return [-0.5 * g_cov * g_logp, -g_delta * g_logp]\n"]]}
{"hexsha": "c1f5f70ec491155a8d91b27953e2928c89b71a7a", "ext": "py", "lang": "Python", "content": "def get_quantiles_summary(cds_cai_dat,num_of_quantiles,R20_vec_compare,vec_cost):\n    # we can use this 'qcut' function from pandas to divide our proteins by the quantiles ...\n    category,bins = pd.qcut(cds_cai_dat['CAI'],q=num_of_quantiles,retbins=True,labels=False)\n    # then we could iterate over proteins/cDNAs in these categories ...\n    fivywrel_cat, r20_cat, cost_cat = [],[],[]\n    for cat in range(num_of_quantiles):\n        cds_cai_category = cds_cai_dat[category==cat]\n        protein_length_distro = cds_cai_category['protein'].str.len()\n        # average protein length per quantile as a stability measure ...\n        average_length = protein_length_distro.mean()\n        # total proteins length in quantile for AA freqs calculations ...\n        total_length = protein_length_distro.sum()\n        IVYWREL = sum(cds_cai_category['protein'].str.count(aa).sum() for aa in list('IVYWREL'))\n        # IVYWREL = cds_cai_category['protein'].str.count('|'.join(\"IVYWREL\")).sum() # tiny bit slower ...\n        f_IVYWREL = float(IVYWREL)/float(total_length)\n        # 20-vector for of amino acid composition ...\n        aa_freq_20 = np.true_divide([cds_cai_category['protein'].str.count(aa).sum() for aa in aacids],float(total_length))\n        # slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n        _1,_2,R20,_4,_5 = stats.linregress(aa_freq_20, R20_vec_compare)\n        # Akashi ...\n        cost = np.dot(aa_freq_20,vec_cost)\n        # storing info ...\n        fivywrel_cat.append(f_IVYWREL)\n        r20_cat.append(R20)\n        cost_cat.append(cost)\n    #returning ...\n    return (fivywrel_cat,r20_cat,cost_cat)", "fn_id": 1, "class_fn": false, "repo": "sergpolly/Thermal_adapt_scripts", "file": "BOOTSTRAPS/Cherry_composition_analysis_Thermo_Rnd_PUB_EXPERIMENTAL.py", "last_update_at": "2018-12-05T07:43:42+00:00", "question_id": "c1f5f70ec491155a8d91b27953e2928c89b71a7a_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_quantiles_summary(cds_cai_dat, num_of_quantiles, R20_vec_compare, vec_cost):\n    category, bins = pd.qcut(cds_cai_dat['CAI'], q=num_of_quantiles, retbins=True, labels=False)\n    fivywrel_cat, r20_cat, cost_cat = ([], [], [])\n    for cat in range(num_of_quantiles):\n        cds_cai_category = cds_cai_dat[category == cat]\n        protein_length_distro = cds_cai_category['protein'].str.len()\n        average_length = protein_length_distro.mean()\n        total_length = protein_length_distro.sum()\n        IVYWREL = sum((cds_cai_category['protein'].str.count(aa).sum() for aa in list('IVYWREL')))\n        f_IVYWREL = float(IVYWREL) / float(total_length)\n        aa_freq_20 = np.true_divide([cds_cai_category['protein'].str.count(aa).sum() for aa in aacids], float(total_length))\n        _1, _2, R20, _4, _5 = stats.linregress(aa_freq_20, R20_vec_compare)\n        cost = np.dot(aa_freq_20, vec_cost)\n        fivywrel_cat.append(f_IVYWREL)\n        r20_cat.append(R20)\n        cost_cat.append(cost)\n"]]}
{"hexsha": "41a117bd1c9bb6acbb54ee9487d1923bfc39cda0", "ext": "py", "lang": "Python", "content": "def read_json_content(filename):\n  json_content = {}\n  with codecs.open(filename, encoding=\"utf-8\") as f:\n    json_content = json.loads(f.read())\n  if not json_content:\n    print(\"ERROR: No content found in \", filename)\n  return json_content", "fn_id": 0, "class_fn": false, "repo": "clementhk/outline-client", "file": "scripts/l10n/validate_localized_keys.py", "last_update_at": "2018-09-16T21:31:44+00:00", "question_id": "41a117bd1c9bb6acbb54ee9487d1923bfc39cda0_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def read_json_content(filename):\n    json_content = {}\n    with codecs.open(filename, encoding='utf-8') as f:\n        json_content = json.loads(f.read())\n    if not json_content:\n        print('ERROR: No content found in ', filename)\n"]]}
{"hexsha": "e7d3606bac6fcead226a24baebb27cda88f01438", "ext": "py", "lang": "Python", "content": "def group_covmtx(rho_intra, rho_inter, num_groups, num_objects):\n    ''' create a covarince matrix with groups\n    \n    create covariance matrix for num_groups*num_objects variables \n    in each group are num_objects with a covariance of rho_intra. \n    objects between groups have a covariance of rho_intra \n    '''\n\n    intra_mtx_size = int((num_objects ** 2 - num_objects) / 2)\n    intra_cov = 1 - squareform([1 - rho_intra] * intra_mtx_size)\n\n    cov = rho_inter * np.ones((num_groups * num_objects, num_groups * num_objects))\n    for group_num in range(num_groups):\n        cov[group_num * num_objects:(group_num + 1) * num_objects,\n            group_num * num_objects:(group_num + 1) * num_objects] = intra_cov\n    return cov", "fn_id": 1, "class_fn": false, "repo": "sesutton93/FUImaging", "file": "regnmf/datamaker.py", "last_update_at": "2018-09-05T11:32:36+00:00", "question_id": "e7d3606bac6fcead226a24baebb27cda88f01438_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def group_covmtx(rho_intra, rho_inter, num_groups, num_objects):\n    \"\"\" create a covarince matrix with groups\n    \n    create covariance matrix for num_groups*num_objects variables \n    in each group are num_objects with a covariance of rho_intra. \n    objects between groups have a covariance of rho_intra \n    \"\"\"\n    intra_mtx_size = int((num_objects ** 2 - num_objects) / 2)\n    intra_cov = 1 - squareform([1 - rho_intra] * intra_mtx_size)\n    cov = rho_inter * np.ones((num_groups * num_objects, num_groups * num_objects))\n    for group_num in range(num_groups):\n        cov[group_num * num_objects:(group_num + 1) * num_objects, group_num * num_objects:(group_num + 1) * num_objects] = intra_cov\n"]]}
{"hexsha": "b9605f2be3730f95c4dd922e6faea910daf36f76", "ext": "py", "lang": "Python", "content": "@raises(ValueError)\ndef test_fill_option_not_found():\n    browser.open('/form/select')\n    browser.document.forms[0].fill({'sel': 'unexisting'})", "fn_id": 22, "class_fn": false, "repo": "idealist/Alfajor", "file": "tests/browser/test_forms.py", "last_update_at": "2018-02-15T15:54:30+00:00", "question_id": "b9605f2be3730f95c4dd922e6faea910daf36f76_22", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@raises(ValueError)\ndef test_fill_option_not_found():\n    browser.open('/form/select')\n"]]}
{"hexsha": "2fa5d7e276ad3f742196d6271ee2753812425e18", "ext": "py", "lang": "Python", "content": "def active_status(senseHat):\n    \"\"\"\n    A function to update the LED matrix regularly\n    to show that the experiment is progressing\n    \"\"\"\n    # a list with all possible rotation values\n    orientation = [0,90,270,180]\n    # pick one at random\n    rot = random.choice(orientation)\n    # set the rotation\n    senseHat.set_rotation(rot)\n    senseHat.set_pixels(img1)", "fn_id": 2, "class_fn": false, "repo": "coderdojo-banbridge/astro-pi", "file": "2019/AquaQuotient/dataRecorder.py", "last_update_at": "2018-02-07T12:35:31+00:00", "question_id": "2fa5d7e276ad3f742196d6271ee2753812425e18_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def active_status(senseHat):\n    \"\"\"\n    A function to update the LED matrix regularly\n    to show that the experiment is progressing\n    \"\"\"\n    orientation = [0, 90, 270, 180]\n    rot = random.choice(orientation)\n    senseHat.set_rotation(rot)\n"]]}
{"hexsha": "33e95d7df122e5f2ed7af5b12ccad246a89b63bb", "ext": "py", "lang": "Python", "content": "def test(test_data, test_labels, batch_size, model, test_batch_num):\n    accuracy = 0.0\n    keep_probs_values = [1.0 for i in range(len(model.keep_probs_values))]\n    for batch in iterate_minibatches(inputs=test_data, targets=test_labels, batchsize=batch_size):\n        test_in, test_target = batch\n        # test_in = test_in[:,np.newaxis,:,np.newaxis]\n        # print model.sess.run(tf.reduce_sum(tf.equal(tf.argmax(model.output_layer,1), tf.argmax(model.y, 1))) ,\n        #                            feed_dict={model.x:test_in, model.y:test_target})\n        accuracy += model.sess.run(\n            tf.reduce_mean(tf.cast(tf.equal(tf.argmax(model.output_layer, 1), tf.argmax(model._y, 1)), tf.float32)),\n            feed_dict={model._x: test_in, model._y: test_target, model.keep_probs: keep_probs_values})\n    print('accuracy: {}'.format(accuracy / test_batch_num))\n    return accuracy / test_batch_num", "fn_id": 2, "class_fn": false, "repo": "mrjiao2018/LearningGroupStructure", "file": "encoder_decoder_model/res_encoder_jinglin.py", "last_update_at": "2018-12-07T14:36:13+00:00", "question_id": "33e95d7df122e5f2ed7af5b12ccad246a89b63bb_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test(test_data, test_labels, batch_size, model, test_batch_num):\n    accuracy = 0.0\n    keep_probs_values = [1.0 for i in range(len(model.keep_probs_values))]\n    for batch in iterate_minibatches(inputs=test_data, targets=test_labels, batchsize=batch_size):\n        test_in, test_target = batch\n        accuracy += model.sess.run(tf.reduce_mean(tf.cast(tf.equal(tf.argmax(model.output_layer, 1), tf.argmax(model._y, 1)), tf.float32)), feed_dict={model._x: test_in, model._y: test_target, model.keep_probs: keep_probs_values})\n    print('accuracy: {}'.format(accuracy / test_batch_num))\n"]]}
{"hexsha": "7f9756bd198259f4ec9807dfa37dfe4657ea08af", "ext": "py", "lang": "Python", "content": "def get_valid_array_idx(idx, last_idx):  # type: (int, int) -> int\n    \"\"\"Return valid array index value within range [0, last_idx].\n\n    Negative values are interpreted such that it represent number of elements before the array end.\n    If `idx` is greater than `last_idx` then it is interpreted as `last_idx` value.\n\n    :param idx: The value of index we would like to get.\n    :param last_idx: The maximum available index value.\n    :return: Valid index value.\n    \"\"\"\n    if idx >= 0:\n        return min(idx, last_idx)\n    else:\n        return max(0, last_idx + idx)", "fn_id": 4, "class_fn": false, "repo": "ddokupil/ngraph-onnx", "file": "ngraph_onnx/onnx_importer/utils/reshape.py", "last_update_at": "2018-06-04T14:05:47+00:00", "question_id": "7f9756bd198259f4ec9807dfa37dfe4657ea08af_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_valid_array_idx(idx, last_idx):\n    \"\"\"Return valid array index value within range [0, last_idx].\n\n    Negative values are interpreted such that it represent number of elements before the array end.\n    If `idx` is greater than `last_idx` then it is interpreted as `last_idx` value.\n\n    :param idx: The value of index we would like to get.\n    :param last_idx: The maximum available index value.\n    :return: Valid index value.\n    \"\"\"\n    if idx >= 0:\n        return min(idx, last_idx)\n    else:\n"]]}
{"hexsha": "55c4aae866f4552991cfbca3a77d5e6e8d16167b", "ext": "py", "lang": "Python", "content": "def init_inputs(num=1, seq_len=4, shape=(1, 2)):\n    inputs = list()\n    for i in range(num):\n        # i*seq_len+(k+1)\n        inputs.append([(i+1)*torch.ones(shape) for k in range(seq_len)])\n    return inputs", "fn_id": 0, "class_fn": false, "repo": "ksopyla/pytorch_tut", "file": "lstm_input.py", "last_update_at": "2018-07-09T09:49:40+00:00", "question_id": "55c4aae866f4552991cfbca3a77d5e6e8d16167b_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def init_inputs(num=1, seq_len=4, shape=(1, 2)):\n    inputs = list()\n    for i in range(num):\n        inputs.append([(i + 1) * torch.ones(shape) for k in range(seq_len)])\n"]]}
{"hexsha": "695ce0583333dbe567a3599e2a959f8a1ebf3dd9", "ext": "py", "lang": "Python", "content": "def a_pool(layer_input, input_shp, poolsize, stride=(1, 1), padding=(0, 0),\n           mode=\"max\"):\n    \"\"\"Returns estimated activation of pool layer.\n\n    :param Numlike layer_input: Numlike input in input_shp format\n    :param tuple of 3 integers input_shp: input shape in format (n_channels,\n                                          height, width)\n    :param pair of integers poolsize: pool size in format (height, width)\n    :param pair of integers stride: stride of max pool\n    :param pair of integers padding: padding of pool, non-trivial padding is\n                                     not allowed for 'max\" mode\n    :param mode: specifies whether it is max pool or average pool\n    :type mode: 'max' or 'avg'\n    :rtype: Numlike\n    \"\"\"\n    assert_numlike(layer_input)\n    if mode not in [\"max\", \"avg\"]:\n        raise ValueError(\"pool mode should be 'max' or 'avg'\")\n    is_max = mode == \"max\"\n    # n_in, h, w - number of input channels, image height, image width\n    n_in, h, w = input_shp\n    n_out = n_in\n\n    # padding\n    pad_h, pad_w = padding\n    if padding != (0, 0):\n        layer_input = layer_input.reshape_for_padding((1, n_in, h, w), padding)\n        h += 2 * pad_h\n        w += 2 * pad_w\n    else:\n        layer_input = layer_input.reshape((1, n_in, h, w))\n\n    # fh, fw - pool height, pool width\n    fh, fw = poolsize\n    stride_h, stride_w = stride\n    output_h = (h - fh) / stride_h + 1\n    output_w = (w - fw) / stride_w + 1\n    output_shp = (n_out, output_h, output_w)\n    result = layer_input.from_shape(output_shp, neutral=True)\n    for at_h in xrange(0, h - fh + 1, stride_h):\n        # at_out_h - height of output corresponding to pool at position at_h\n        at_out_h = at_h / stride_h\n        for at_w in xrange(0, w - fw + 1, stride_w):\n            # at_out_w - height of output corresponding to pool at\n            # position at_w\n            at_out_w = at_w / stride_w\n            input_slice = layer_input[:, :, at_h:(at_h + fh), at_w:(at_w + fw)]\n            if is_max:\n                pool_res = input_slice.amax(axis=(0, 2, 3), keepdims=False)\n            else:\n                pool_res = input_slice.sum(axis=(0, 2, 3), keepdims=False) \\\n                    / float(fh * fw)\n            result[:, at_out_h, at_out_w] = pool_res\n    return result", "fn_id": 0, "class_fn": false, "repo": "heurezjusz/Athena", "file": "athenet/algorithm/derest/layers/pool.py", "last_update_at": "2018-03-29T17:17:11+00:00", "question_id": "695ce0583333dbe567a3599e2a959f8a1ebf3dd9_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def a_pool(layer_input, input_shp, poolsize, stride=(1, 1), padding=(0, 0), mode='max'):\n    \"\"\"Returns estimated activation of pool layer.\n\n    :param Numlike layer_input: Numlike input in input_shp format\n    :param tuple of 3 integers input_shp: input shape in format (n_channels,\n                                          height, width)\n    :param pair of integers poolsize: pool size in format (height, width)\n    :param pair of integers stride: stride of max pool\n    :param pair of integers padding: padding of pool, non-trivial padding is\n                                     not allowed for 'max\" mode\n    :param mode: specifies whether it is max pool or average pool\n    :type mode: 'max' or 'avg'\n    :rtype: Numlike\n    \"\"\"\n    assert_numlike(layer_input)\n    if mode not in ['max', 'avg']:\n        raise ValueError(\"pool mode should be 'max' or 'avg'\")\n    is_max = mode == 'max'\n    n_in, h, w = input_shp\n    n_out = n_in\n    pad_h, pad_w = padding\n    if padding != (0, 0):\n        layer_input = layer_input.reshape_for_padding((1, n_in, h, w), padding)\n        h += 2 * pad_h\n        w += 2 * pad_w\n    else:\n        layer_input = layer_input.reshape((1, n_in, h, w))\n    fh, fw = poolsize\n    stride_h, stride_w = stride\n    output_h = (h - fh) / stride_h + 1\n    output_w = (w - fw) / stride_w + 1\n    output_shp = (n_out, output_h, output_w)\n    result = layer_input.from_shape(output_shp, neutral=True)\n    for at_h in xrange(0, h - fh + 1, stride_h):\n        at_out_h = at_h / stride_h\n        for at_w in xrange(0, w - fw + 1, stride_w):\n            at_out_w = at_w / stride_w\n            input_slice = layer_input[:, :, at_h:at_h + fh, at_w:at_w + fw]\n            if is_max:\n                pool_res = input_slice.amax(axis=(0, 2, 3), keepdims=False)\n            else:\n                pool_res = input_slice.sum(axis=(0, 2, 3), keepdims=False) / float(fh * fw)\n            result[:, at_out_h, at_out_w] = pool_res\n"]]}
{"hexsha": "44428a69cc518f2445275546933662907b58a396", "ext": "py", "lang": "Python", "content": "def populate_users():\n    for i in range(1, 171):\n        user_list = []\n        page = requests.get(RANKLIST_URL + str(i))\n        page = BeautifulSoup(page.text)\n        ranklist = page.find_all(class_=\"ratingsDatatable\")\n        users = ranklist[0].find_all('td')\n        for i in range(1, 800, 4):\n            username = users[i].text.split()[0]\n            rating = int(users[i+2].text)\n            user_list.append(str(tuple((str(username), int(rating)))))\n        user_list = \", \".join(user_list)\n        query = \"\"\"\n            INSERT INTO \"user_table\"(handle, rating)\n                 VALUES {}\n        \"\"\".format(user_list)\n        with engine.connect() as connection:\n            connection.execute(sqlalchemy.text(query))", "fn_id": 0, "class_fn": false, "repo": "Code-AI/code-ai", "file": "populate_db.py", "last_update_at": "2018-10-26T12:32:41+00:00", "question_id": "44428a69cc518f2445275546933662907b58a396_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def populate_users():\n    for i in range(1, 171):\n        user_list = []\n        page = requests.get(RANKLIST_URL + str(i))\n        page = BeautifulSoup(page.text)\n        ranklist = page.find_all(class_='ratingsDatatable')\n        users = ranklist[0].find_all('td')\n        for i in range(1, 800, 4):\n            username = users[i].text.split()[0]\n            rating = int(users[i + 2].text)\n            user_list.append(str(tuple((str(username), int(rating)))))\n        user_list = ', '.join(user_list)\n        query = '\\n            INSERT INTO \"user_table\"(handle, rating)\\n                 VALUES {}\\n        '.format(user_list)\n        with engine.connect() as connection:\n"]]}
{"hexsha": "9aaf68766526eab088a45acee5974261d7ebd3aa", "ext": "py", "lang": "Python", "content": "def test_send_reminder_emails(reminder_email_subscriber_factory):\n    sub = reminder_email_subscriber_factory()\n\n    command = Command()\n    sub.user.primary_email.email = \"test@knowme.works\"\n    sent = command.send_reminder_email(sub)\n\n    assert sent", "fn_id": 0, "class_fn": false, "repo": "knowmetools/km-api", "file": "km_api/know_me/tests/management/commands/test_sendreminderemails.py", "last_update_at": "2018-11-06T03:32:32+00:00", "question_id": "9aaf68766526eab088a45acee5974261d7ebd3aa_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_send_reminder_emails(reminder_email_subscriber_factory):\n    sub = reminder_email_subscriber_factory()\n    command = Command()\n    sub.user.primary_email.email = 'test@knowme.works'\n    sent = command.send_reminder_email(sub)\n"]]}
{"hexsha": "6871d242a87563196769668b49bf737e1f7830fb", "ext": "py", "lang": "Python", "content": "def _build_spin_matrices(basis: Basis) -> dict[str, np.ndarray]:\n    size = len(basis) * len(model.states)\n    matrices: dict[str, np.ndarray] = defaultdict(lambda: np.zeros((size, size)))\n    for transition_name, state in product(_TRANSITIONS, model.states):\n        if not basis.type.endswith(\"_diff\") and transition_name.startswith(\"d_\"):\n            continue\n        name = transition_name.format(state=state)\n        indices, values = _get_indices(basis, transition_name, state)\n        if values:\n            matrices[name][indices] = values\n    return matrices", "fn_id": 2, "class_fn": false, "repo": "gbouvignies/chemex", "file": "chemex/nmr/basis.py", "last_update_at": "2018-09-17T08:43:58+00:00", "question_id": "6871d242a87563196769668b49bf737e1f7830fb_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _build_spin_matrices(basis: Basis) -> dict[str, np.ndarray]:\n    size = len(basis) * len(model.states)\n    matrices: dict[str, np.ndarray] = defaultdict(lambda: np.zeros((size, size)))\n    for transition_name, state in product(_TRANSITIONS, model.states):\n        if not basis.type.endswith('_diff') and transition_name.startswith('d_'):\n            continue\n        name = transition_name.format(state=state)\n        indices, values = _get_indices(basis, transition_name, state)\n        if values:\n            matrices[name][indices] = values\n"]]}
{"hexsha": "be10fad1a82c3d77b9214d5fb02e516227b5fbc7", "ext": "py", "lang": "Python", "content": "def up(interface, iface_type=None):  # pylint: disable=invalid-name,unused-argument\n    '''\n    Enable the specified interface\n\n    Change adapter mode to TCP/IP. If previous adapter mode was EtherCAT, the target will need reboot.\n\n    :param str interface: interface label\n    :return: True if the service was enabled, otherwise an exception will be thrown.\n    :rtype: bool\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' ip.up interface-label\n    '''\n    return _change_state(interface, 'up')", "fn_id": 25, "class_fn": false, "repo": "Tracerneo/salt", "file": "salt/modules/nilrt_ip.py", "last_update_at": "2018-09-21T05:06:03+00:00", "question_id": "be10fad1a82c3d77b9214d5fb02e516227b5fbc7_25", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def up(interface, iface_type=None):\n    \"\"\"\n    Enable the specified interface\n\n    Change adapter mode to TCP/IP. If previous adapter mode was EtherCAT, the target will need reboot.\n\n    :param str interface: interface label\n    :return: True if the service was enabled, otherwise an exception will be thrown.\n    :rtype: bool\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' ip.up interface-label\n    \"\"\"\n"]]}
{"hexsha": "f1a2db0b85a7a5ad6c5e1de5eabd127688ba3c22", "ext": "py", "lang": "Python", "content": "async def watchCompetition(competition: Competition, serverName: str,unified_channel = None,role = None ,category = None):\n    \"\"\"\n    Adds a compeitition to be monitored. Also updates matches and competitions accordingly.\n    :param competition: Competition to be monitored.\n    :param serverName: Name of the discord server\n    \"\"\"\n    logger.info(f\"Start watching competition {competition} on {serverName}\")\n\n    season = Season.objects.filter(competition=competition).order_by('start_date').last()\n    if season == None:\n        getAndSaveData(getAllSeasons, idCompetitions=competition.id)\n        season = Season.objects.filter(competition=competition).order_by('start_date').last()\n    server = DiscordServer(name=serverName)\n    server.save()\n\n    updateMatchesSingleCompetition(competition=competition, season=season)\n\n    compWatcher = CompetitionWatcher(competition=competition,\n                                     current_season=season, applicable_server=server, current_matchday=1,role=role,category=category)\n    if unified_channel is not None:\n        compWatcher.unified_channel = unified_channel\n\n    compWatcher.save()\n    Scheduler.addCompetition(compWatcher)", "fn_id": 6, "class_fn": false, "repo": "MarcoMuellner/soccerbot", "file": "discord_handler/handler.py", "last_update_at": "2018-09-24T16:29:17+00:00", "question_id": "f1a2db0b85a7a5ad6c5e1de5eabd127688ba3c22_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["async def watchCompetition(competition: Competition, serverName: str, unified_channel=None, role=None, category=None):\n    \"\"\"\n    Adds a compeitition to be monitored. Also updates matches and competitions accordingly.\n    :param competition: Competition to be monitored.\n    :param serverName: Name of the discord server\n    \"\"\"\n    logger.info(f'Start watching competition {competition} on {serverName}')\n    season = Season.objects.filter(competition=competition).order_by('start_date').last()\n    if season == None:\n        getAndSaveData(getAllSeasons, idCompetitions=competition.id)\n        season = Season.objects.filter(competition=competition).order_by('start_date').last()\n    server = DiscordServer(name=serverName)\n    server.save()\n    updateMatchesSingleCompetition(competition=competition, season=season)\n    compWatcher = CompetitionWatcher(competition=competition, current_season=season, applicable_server=server, current_matchday=1, role=role, category=category)\n    if unified_channel is not None:\n        compWatcher.unified_channel = unified_channel\n    compWatcher.save()\n"]]}
{"hexsha": "1a2ee45e0d3505c7a62e3d84edae917cc0417cd5", "ext": "py", "lang": "Python", "content": "def parse_requirements(filename):\n    \"\"\" load requirements from a pip requirements file \"\"\"\n    lineiter = (line.strip() for line in open(filename))\n    return [line for line in lineiter if line and not line.startswith(\"#\")]", "fn_id": 0, "class_fn": false, "repo": "rw-meta/meta-app-script-py-sdk", "file": "setup.py", "last_update_at": "2018-05-22T07:25:56+00:00", "question_id": "1a2ee45e0d3505c7a62e3d84edae917cc0417cd5_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def parse_requirements(filename):\n    \"\"\" load requirements from a pip requirements file \"\"\"\n    lineiter = (line.strip() for line in open(filename))\n"]]}
{"hexsha": "a434b6b354a6d5d7005c5c262a075319e18701d6", "ext": "py", "lang": "Python", "content": "def transform_into_boolean_list(stream_data, indexed_rules, request):\n    '''\n    Converts a stream field of strings and rules into a list\n    of booleans (evaluated rule evaluations), strings and nested lists\n\n    Sample Input:\n    [\n        {u'type': u'Rule', u'value': u'UserIsLoggedInRule_0'},\n        {u'type': u'Operator', u'value': u'and'},\n        {u'type': u'NestedLogic', u'value': {\n            u'operator': u'or',\n            u'rule_1': u'TimeRule_0',\n            u'rule_2': u'TimeRule_1'}\n        }\n    ]\n\n    Output:\n    [True, 'and', [False, 'or', True]]\n    '''\n    return_value = []\n    for block in stream_data:\n        if block['type'] == 'Rule':\n            rule = get_rule(block['value'], indexed_rules)\n            return_value.append(rule.test_user(request))\n        elif block['type'] == 'Operator':\n            return_value.append(block['value'])\n        elif block['type'] == 'NestedLogic':\n            values = block['value']\n            rule_1 = get_rule(values['rule_1'], indexed_rules)\n            rule_2 = get_rule(values['rule_2'], indexed_rules)\n            return_value.append([\n                rule_1.test_user(request),\n                values['operator'],\n                rule_2.test_user(request)\n            ])\n\n    return return_value", "fn_id": 1, "class_fn": false, "repo": "praekelt/molo.surveys", "file": "molo/surveys/adapters.py", "last_update_at": "2018-09-21T07:33:58+00:00", "question_id": "a434b6b354a6d5d7005c5c262a075319e18701d6_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def transform_into_boolean_list(stream_data, indexed_rules, request):\n    \"\"\"\n    Converts a stream field of strings and rules into a list\n    of booleans (evaluated rule evaluations), strings and nested lists\n\n    Sample Input:\n    [\n        {u'type': u'Rule', u'value': u'UserIsLoggedInRule_0'},\n        {u'type': u'Operator', u'value': u'and'},\n        {u'type': u'NestedLogic', u'value': {\n            u'operator': u'or',\n            u'rule_1': u'TimeRule_0',\n            u'rule_2': u'TimeRule_1'}\n        }\n    ]\n\n    Output:\n    [True, 'and', [False, 'or', True]]\n    \"\"\"\n    return_value = []\n    for block in stream_data:\n        if block['type'] == 'Rule':\n            rule = get_rule(block['value'], indexed_rules)\n            return_value.append(rule.test_user(request))\n        elif block['type'] == 'Operator':\n            return_value.append(block['value'])\n        elif block['type'] == 'NestedLogic':\n            values = block['value']\n            rule_1 = get_rule(values['rule_1'], indexed_rules)\n            rule_2 = get_rule(values['rule_2'], indexed_rules)\n            return_value.append([rule_1.test_user(request), values['operator'], rule_2.test_user(request)])\n"]]}
{"hexsha": "f79f4efbf73553d718a1d08b005b37e6f035abe7", "ext": "py", "lang": "Python", "content": "def main():\n    \"\"\"\n    Runs data processing scripts to turn raw data from (../raw) into\n    cleaned data ready to be analyzed (saved in ../processed).\n    \"\"\"\n    logger = logging.getLogger(__name__)\n\n    if os.path.exists(processed_filepath):\n        logger.info('remove existing processed dataset')\n        os.remove(processed_filepath)\n\n    manager = Manager(get_data_file())\n    logger.info('creating tables')\n    manager.create_tables()\n    logger.info('populating the database')\n    manager.populate_tables()\n    logger.info('recording metrics')\n    manager.write_metrics()\n\n    logger.info('modifying database')\n    modifier = DatabaseModifier()\n\n    logger.info('dataset generation complete')", "fn_id": 12, "class_fn": false, "repo": "idinwoodie/pdbs", "file": "src/data/make_dataset.py", "last_update_at": "2018-10-09T03:33:16+00:00", "question_id": "f79f4efbf73553d718a1d08b005b37e6f035abe7_12", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main():\n    \"\"\"\n    Runs data processing scripts to turn raw data from (../raw) into\n    cleaned data ready to be analyzed (saved in ../processed).\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    if os.path.exists(processed_filepath):\n        logger.info('remove existing processed dataset')\n        os.remove(processed_filepath)\n    manager = Manager(get_data_file())\n    logger.info('creating tables')\n    manager.create_tables()\n    logger.info('populating the database')\n    manager.populate_tables()\n    logger.info('recording metrics')\n    manager.write_metrics()\n    logger.info('modifying database')\n    modifier = DatabaseModifier()\n"]]}
{"hexsha": "1d137ae8cf1fa460376a3d8f64d5ac93171b952d", "ext": "py", "lang": "Python", "content": "def _validate_subscription_batch_creation(order, collection, timeslot):\n    start, end = utilities.get_subscription_duration(order, collection)\n    if order.status in (Order.SUBMITTED, Order.CANCELLED, Order.TERMINATED):\n        logger.error(\"Order {!r} has a {!r} status. Cannot create new \"\n                     \"batches\".format(order.id, order.status))\n        raise errors.InvalidOrderIdentifierError()\n    elif not (start <= timeslot <= end):\n        logger.debug(\"Requested timeslot is outside of subscription's \"\n                     \"temporal range. Cannot create new batch\")\n        raise errors.InvalidOrderIdentifierError()", "fn_id": 16, "class_fn": false, "repo": "pyoseo/oseoserver", "file": "oseoserver/requestprocessor.py", "last_update_at": "2018-04-05T10:05:01+00:00", "question_id": "1d137ae8cf1fa460376a3d8f64d5ac93171b952d_16", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _validate_subscription_batch_creation(order, collection, timeslot):\n    start, end = utilities.get_subscription_duration(order, collection)\n    if order.status in (Order.SUBMITTED, Order.CANCELLED, Order.TERMINATED):\n        logger.error('Order {!r} has a {!r} status. Cannot create new batches'.format(order.id, order.status))\n        raise errors.InvalidOrderIdentifierError()\n    elif not start <= timeslot <= end:\n        logger.debug(\"Requested timeslot is outside of subscription's temporal range. Cannot create new batch\")\n"]]}
{"hexsha": "8689bbb1e745aba7506d2f433d9b6475e3278f84", "ext": "py", "lang": "Python", "content": "def _make_query_response(\n        entity_pbs, cursor_as_bytes, more_results_enum, skipped_results):\n    from google.cloud.datastore_v1.proto import datastore_pb2\n    from google.cloud.datastore_v1.proto import query_pb2\n\n    return datastore_pb2.RunQueryResponse(\n        batch=query_pb2.QueryResultBatch(\n            skipped_results=skipped_results,\n            end_cursor=cursor_as_bytes,\n            more_results=more_results_enum,\n            entity_results=[\n                query_pb2.EntityResult(entity=entity)\n                for entity in entity_pbs\n            ],\n        ),\n    )", "fn_id": 1, "class_fn": false, "repo": "deryrahman/google-cloud-python", "file": "datastore/tests/unit/test_query.py", "last_update_at": "2018-06-29T17:53:28+00:00", "question_id": "8689bbb1e745aba7506d2f433d9b6475e3278f84_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _make_query_response(entity_pbs, cursor_as_bytes, more_results_enum, skipped_results):\n    from google.cloud.datastore_v1.proto import datastore_pb2\n    from google.cloud.datastore_v1.proto import query_pb2\n"]]}
{"hexsha": "59ffcf0a499658edb4bd910b1c895224c8574a99", "ext": "py", "lang": "Python", "content": "def route(*methods):\n    \"\"\"\n    Method decorator to route HTTP methods to a method.  Called with\n    an optional list of method strings (which will be canonicalized to\n    uppercase).  If no methods are specified, all otherwise undefined\n    methods will be routed to the decorated method.  This decorator is\n    designed to work both with and without arguments--that is,\n    ``@obj.route`` is equivalent to ``@obj.route()``.\n\n    This decorator attaches a list of ``Method`` objects to the\n    decorated function; these will be added to the controller class's\n    root object appropriately by the metaclass.\n\n    :returns: Either the appropriately decorated method, or a\n              decorator for a method.\n    \"\"\"\n\n    def decorator(func):\n        meth_list = []\n\n        # Construct the new Method objects\n        seen = set()\n        if methods:\n            for meth_str in methods:\n                if meth_str in seen:\n                    continue\n                seen.add(meth_str)\n\n                meth = Method(meth_str, func)\n                meth_list.append(meth)\n        else:\n            meth = Method(None, func)\n            meth_list.append(meth)\n\n        # Attach the method list to the function; this will be picked\n        # up by the metaclass\n        func._micropath_methods = meth_list\n\n        # Mark the function as a handler\n        func._micropath_handler = True\n\n        # Pre-compute its want signature\n        injector.WantSignature.from_func(func)\n\n        return func\n\n    # Check if methods consists of a single callable element\n    if len(methods) == 1 and callable(methods[0]):\n        func = methods[0]\n        methods = ()\n        return decorator(func)\n\n    return decorator", "fn_id": 2, "class_fn": false, "repo": "klmitch/micropath", "file": "micropath/elements.py", "last_update_at": "2018-06-07T22:17:14+00:00", "question_id": "59ffcf0a499658edb4bd910b1c895224c8574a99_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def route(*methods):\n    \"\"\"\n    Method decorator to route HTTP methods to a method.  Called with\n    an optional list of method strings (which will be canonicalized to\n    uppercase).  If no methods are specified, all otherwise undefined\n    methods will be routed to the decorated method.  This decorator is\n    designed to work both with and without arguments--that is,\n    ``@obj.route`` is equivalent to ``@obj.route()``.\n\n    This decorator attaches a list of ``Method`` objects to the\n    decorated function; these will be added to the controller class's\n    root object appropriately by the metaclass.\n\n    :returns: Either the appropriately decorated method, or a\n              decorator for a method.\n    \"\"\"\n\n    def decorator(func):\n        meth_list = []\n        seen = set()\n        if methods:\n            for meth_str in methods:\n                if meth_str in seen:\n                    continue\n                seen.add(meth_str)\n                meth = Method(meth_str, func)\n                meth_list.append(meth)\n        else:\n            meth = Method(None, func)\n            meth_list.append(meth)\n        func._micropath_methods = meth_list\n        func._micropath_handler = True\n        injector.WantSignature.from_func(func)\n        return func\n    if len(methods) == 1 and callable(methods[0]):\n        func = methods[0]\n        methods = ()\n        return decorator(func)\n"]]}
{"hexsha": "3caae1436844f7aab10709883f2a9ec0b05df2a7", "ext": "py", "lang": "Python", "content": "def encode_path(file_path, encoder_name=DEFAULT_CODEC_NAME):\n    \"\"\"\n    Encode file path\n    \"\"\"\n\n    return encode(read_image(file_path), encoder_name)", "fn_id": 3, "class_fn": false, "repo": "ajaniv/python-basic-utils", "file": "python_core_utils/image.py", "last_update_at": "2018-08-30T19:31:31+00:00", "question_id": "3caae1436844f7aab10709883f2a9ec0b05df2a7_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def encode_path(file_path, encoder_name=DEFAULT_CODEC_NAME):\n    \"\"\"\n    Encode file path\n    \"\"\"\n"]]}
{"hexsha": "860274e394e7aeec502f7c490666c2395635f468", "ext": "py", "lang": "Python", "content": "def getTargetMap():\n    maps =getMapList()\n    map_counts = len(maps)\n    dice = random.randrange(map_counts)\n    target_map_name = maps['map'][dice]\n    target_map_path = maps['filepath'][dice]\n    return target_map_name, target_map_path", "fn_id": 1, "class_fn": false, "repo": "sxnxhxrxkx/nonamechan", "file": "matchbattle/map.py", "last_update_at": "2018-11-04T14:19:14+00:00", "question_id": "860274e394e7aeec502f7c490666c2395635f468_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def getTargetMap():\n    maps = getMapList()\n    map_counts = len(maps)\n    dice = random.randrange(map_counts)\n    target_map_name = maps['map'][dice]\n    target_map_path = maps['filepath'][dice]\n"]]}
{"hexsha": "b74c22a548eea2d8fd026e1d0f5f5426a57d4274", "ext": "py", "lang": "Python", "content": "def test_parse_pbo_nlc():\n    input_text = \"*zorro!\\nmin: -40 x1 3 x2 ~x3 \\n\" + input_text_nlc\n    input_file = StringIO.StringIO(input_text)\n    instance = borg.domains.pb.opb.parse_opb_file(input_file)\n\n    nose.tools.assert_equal(len(instance.constraints), 4)\n    nose.tools.assert_equal(instance.objective, [(-40, [1]), (3, [2, -3])])", "fn_id": 3, "class_fn": false, "repo": "borg-project/borg", "file": "borg/domains/pb/test/test_opb.py", "last_update_at": "2018-02-23T10:35:46+00:00", "question_id": "b74c22a548eea2d8fd026e1d0f5f5426a57d4274_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_parse_pbo_nlc():\n    input_text = '*zorro!\\nmin: -40 x1 3 x2 ~x3 \\n' + input_text_nlc\n    input_file = StringIO.StringIO(input_text)\n    instance = borg.domains.pb.opb.parse_opb_file(input_file)\n    nose.tools.assert_equal(len(instance.constraints), 4)\n"]]}
{"hexsha": "5aa39826b0ba3d16cc815957fb5bbd5f31dce53e", "ext": "py", "lang": "Python", "content": "async def ex(message, client):\n    if len(list(message.mentions)) > 0:\n        member = message.mentions[0]\n        xp = level_system.get_xp(member)\n        level = int(int(xp) / 1000)\n        progress = (int(xp) % 1000) / 1000\n        progress_bar = \"[\" + \"====================\"[:int(progress * 20)] + \"                    \"[int(progress * 20):] + \"]\\n\\n   \" + str(int(progress * 100)) + \"% to next LVL\"\n        await client.send_message(message.channel, embed=Embed(color=discord.Color.gold(),\n                                                               title=member.name + \"'s Level\",\n                                                               description=(\"**[LVL %s]**  `%s XP`\\n```\\n%s\\n```\" % (level, xp, progress_bar))))\n\n    else:\n        gettedtable = level_system.get_table()\n        temptable = dict([(k, gettedtable[k]) for k in sorted(gettedtable, key=gettedtable.get, reverse=True)])\n        table = {}\n        if len(temptable.keys()) <= 20:\n            table = temptable\n        else:\n            _count = 0\n            for k in temptable:\n                table[k] = temptable.get(k)\n                _count += 1\n                if _count >= 20:\n                    break\n        out = \"\"\n        _count = 0\n        for memb_id in table:\n            try:\n                _count += 1\n                out += \"%s. - **%s:**  **`%s XP`** \\n\" % (_count, discord.utils.get(message.server.members, id=memb_id).name, table[memb_id])\n            except:\n                pass\n        await client.send_message(message.channel, \"**XP LIST**\\n\\n\" + out[:1980])", "fn_id": 0, "class_fn": false, "repo": "Serbirial/regiusBot", "file": "commands/cmd_xp.py", "last_update_at": "2018-03-29T12:52:54+00:00", "question_id": "5aa39826b0ba3d16cc815957fb5bbd5f31dce53e_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["async def ex(message, client):\n    if len(list(message.mentions)) > 0:\n        member = message.mentions[0]\n        xp = level_system.get_xp(member)\n        level = int(int(xp) / 1000)\n        progress = int(xp) % 1000 / 1000\n        progress_bar = '[' + '===================='[:int(progress * 20)] + '                    '[int(progress * 20):] + ']\\n\\n   ' + str(int(progress * 100)) + '% to next LVL'\n        await client.send_message(message.channel, embed=Embed(color=discord.Color.gold(), title=member.name + \"'s Level\", description='**[LVL %s]**  `%s XP`\\n```\\n%s\\n```' % (level, xp, progress_bar)))\n    else:\n        gettedtable = level_system.get_table()\n        temptable = dict([(k, gettedtable[k]) for k in sorted(gettedtable, key=gettedtable.get, reverse=True)])\n        table = {}\n        if len(temptable.keys()) <= 20:\n            table = temptable\n        else:\n            _count = 0\n            for k in temptable:\n                table[k] = temptable.get(k)\n                _count += 1\n                if _count >= 20:\n                    break\n        out = ''\n        _count = 0\n        for memb_id in table:\n            try:\n                _count += 1\n                out += '%s. - **%s:**  **`%s XP`** \\n' % (_count, discord.utils.get(message.server.members, id=memb_id).name, table[memb_id])\n            except:\n                pass\n"]]}
{"hexsha": "20d0c59ae01438b38d34599bae71e44fd9ae656a", "ext": "py", "lang": "Python", "content": "def SetIntersectionIndex (backend=\"numpy\",\n                          max_sets=2**32,\n                          max_symbols=2**16,\n                          init_bucket_size=16,\n                          support_most_frequent=True,\n                          support_find_similar=True):\n        \"\"\"\n        Create a new index for finding intersecting sets.\n        \n        Keyword arguments:\n        \n        backend (default: \"numpy\")\n            Specific implementation of a set intersection index to use.\n            Currently only \"numpy\" is supported.\n        \n        max_sets (default: 2**32, min: 1, max: 2**64)\n            Maximum number of sets that this index should be able to handle, note that this doesn't mean unique sets,\n            but rather all calls to .add().\n            The implementation is free to choose a different number at least as high as the given one.\n        \n        max_symbols (default: 2**16, min: 1, max: 2**64)\n            Maximum number of unique symbols (set items) the index should be able to handle.\n            The implementation is free to choose a different number at least as high as the given one.\n            Currently, max_symbols should not be greater than max_sets.\n        \n        init_bucket_size (default: 16, min: 4)\n            Initial number of elements in arrays holding (set, symbol) mappings, when they are first allocated.\n            (The arrays grow automatically.)\n        \n        support_most_frequent (default: True)\n            Boolean indicating whether additional data allowing the determination of most frequently occurring symbols\n            should be kept. Required by the .most_frequent() method.\n        \n        support_find_similar (default: True)\n            Boolean indicating whether the size of each added set should be remembered, for calculating normalized\n            similarities between sets by the .find_similar() method.\n        \"\"\"\n        \n        module = _BACKENDS[backend] = _BACKENDS.get (backend, False) or import_backend (backend)\n        return module.SetIntersectionIndex (max_sets=max_sets,\n                                            max_symbols=max_symbols,\n                                            init_bucket_size=init_bucket_size,\n                                            support_most_frequent=support_most_frequent,\n                                            support_find_similar=support_find_similar)", "fn_id": 1, "class_fn": false, "repo": "dustymugs/python-setix", "file": "setix/__init__.py", "last_update_at": "2018-08-02T01:43:39+00:00", "question_id": "20d0c59ae01438b38d34599bae71e44fd9ae656a_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def SetIntersectionIndex(backend='numpy', max_sets=2 ** 32, max_symbols=2 ** 16, init_bucket_size=16, support_most_frequent=True, support_find_similar=True):\n    \"\"\"\n        Create a new index for finding intersecting sets.\n        \n        Keyword arguments:\n        \n        backend (default: \"numpy\")\n            Specific implementation of a set intersection index to use.\n            Currently only \"numpy\" is supported.\n        \n        max_sets (default: 2**32, min: 1, max: 2**64)\n            Maximum number of sets that this index should be able to handle, note that this doesn't mean unique sets,\n            but rather all calls to .add().\n            The implementation is free to choose a different number at least as high as the given one.\n        \n        max_symbols (default: 2**16, min: 1, max: 2**64)\n            Maximum number of unique symbols (set items) the index should be able to handle.\n            The implementation is free to choose a different number at least as high as the given one.\n            Currently, max_symbols should not be greater than max_sets.\n        \n        init_bucket_size (default: 16, min: 4)\n            Initial number of elements in arrays holding (set, symbol) mappings, when they are first allocated.\n            (The arrays grow automatically.)\n        \n        support_most_frequent (default: True)\n            Boolean indicating whether additional data allowing the determination of most frequently occurring symbols\n            should be kept. Required by the .most_frequent() method.\n        \n        support_find_similar (default: True)\n            Boolean indicating whether the size of each added set should be remembered, for calculating normalized\n            similarities between sets by the .find_similar() method.\n        \"\"\"\n    module = _BACKENDS[backend] = _BACKENDS.get(backend, False) or import_backend(backend)\n"]]}
{"hexsha": "6fe7e0b26af6a6ead0ebd871ebcc5206fb1fcece", "ext": "py", "lang": "Python", "content": "@bot.command(pass_context=True)\nasync def dog(ctx):\n    '''Check out a random cute or funny dog!\\nUsage: !dog\\nAliases: None\\nPermissions: None'''\n    r = requests.get(f'https://api.thedogapi.co.uk/v2/dog.php/')\n    json = r.json()\n    if r.status_code == 200:\n        sdog = discord.Embed(title='Dog', description='A random cute dog!', color=0x00FF00)\n        sdog.set_author(name=f'{ctx.message.author.display_name}', icon_url=f'{ctx.message.author.avatar_url}')\n        sdog.set_image(url=json['data'][0]['url'])\n        sdog.set_footer(text='Dogs by http://thedogapi.co.uk/!')\n        return await bot.say(embed=sdog)\n    else:\n        rdog = discord.Embed(title='Error', description='I could not access the API! Direct Message Pointless#1278 so this can be fixed! (You will be credited for finding it out!)', color=0xFF0000)\n        rdog.set_author(name=f'{ctx.message.author.display_name}', icon_url=f'{ctx.message.author.avatar_url}')\n        return await bot.say(embed=rdog)", "fn_id": 13, "class_fn": false, "repo": "P01nt-Less/Botless", "file": "bot.py", "last_update_at": "2018-07-02T20:34:59+00:00", "question_id": "6fe7e0b26af6a6ead0ebd871ebcc5206fb1fcece_13", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@bot.command(pass_context=True)\nasync def dog(ctx):\n    \"\"\"Check out a random cute or funny dog!\nUsage: !dog\nAliases: None\nPermissions: None\"\"\"\n    r = requests.get(f'https://api.thedogapi.co.uk/v2/dog.php/')\n    json = r.json()\n    if r.status_code == 200:\n        sdog = discord.Embed(title='Dog', description='A random cute dog!', color=65280)\n        sdog.set_author(name=f'{ctx.message.author.display_name}', icon_url=f'{ctx.message.author.avatar_url}')\n        sdog.set_image(url=json['data'][0]['url'])\n        sdog.set_footer(text='Dogs by http://thedogapi.co.uk/!')\n        return await bot.say(embed=sdog)\n    else:\n        rdog = discord.Embed(title='Error', description='I could not access the API! Direct Message Pointless#1278 so this can be fixed! (You will be credited for finding it out!)', color=16711680)\n        rdog.set_author(name=f'{ctx.message.author.display_name}', icon_url=f'{ctx.message.author.avatar_url}')\n"]]}
{"hexsha": "622c1a885856c432caebf0f02b52153443e2833e", "ext": "py", "lang": "Python", "content": "def extract_parent_folder_id(html):\n    soup = BeautifulSoup(html, 'lxml')\n    folder_ids = soup.find_all(attrs={\"name\": \"parent_folder_id\"})\n\n    if len(folder_ids) != 1:\n        raise ParserError(\"Could not find parent folder ID\")\n\n    return folder_ids.pop().attrs.get(\"value\", \"\")", "fn_id": 3, "class_fn": false, "repo": "chaosprite/studip-sync", "file": "studip_sync/parsers.py", "last_update_at": "2018-11-20T13:18:49+00:00", "question_id": "622c1a885856c432caebf0f02b52153443e2833e_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def extract_parent_folder_id(html):\n    soup = BeautifulSoup(html, 'lxml')\n    folder_ids = soup.find_all(attrs={'name': 'parent_folder_id'})\n    if len(folder_ids) != 1:\n        raise ParserError('Could not find parent folder ID')\n"]]}
{"hexsha": "6c128b492f71ce909275b5e6645bcedcce4f03aa", "ext": "py", "lang": "Python", "content": "def ex1_met1(x):\n    \"Pas a pas\"\n\n    print(\"Avec x= \",x)\n    a = x + 1\n    b = a * 2\n    c = b - 3\n\n    print(\"-------------> Le resultat est : \",c)", "fn_id": 0, "class_fn": false, "repo": "homeostasie/annees-precedentes", "file": "2014.d/seconde-generale.d/stage-sti2d.d/2-algo/exo-1.py", "last_update_at": "2018-12-29T12:46:51+00:00", "question_id": "6c128b492f71ce909275b5e6645bcedcce4f03aa_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def ex1_met1(x):\n    \"\"\"Pas a pas\"\"\"\n    print('Avec x= ', x)\n    a = x + 1\n    b = a * 2\n    c = b - 3\n"]]}
{"hexsha": "e7af35546ac1defd4e29dcd7edcc6de7d041f11a", "ext": "py", "lang": "Python", "content": "def id_convert(inp):\n    id = int(inp)\n    # Assume is_strictly_sorted(src_issues) and src_issues[0] >= 1\n    if id not in src_issues:\n        print(\"WARNING: %d doesn't belong in %s\" % (id, src_issues))\n        return 0  # dummy value\n    already_imported = 0\n    for cur in src_issues:\n        if id == cur:\n            return existing_issues + already_imported + 1\n        else:\n            already_imported += 1\n    print(\"ERROR: In id_convert(%d): unexpected error\" % id)\n    exit(2)", "fn_id": 1, "class_fn": false, "repo": "erikmd/github-issues-import-api-tools", "file": "json2github.py", "last_update_at": "2018-09-07T11:43:09+00:00", "question_id": "e7af35546ac1defd4e29dcd7edcc6de7d041f11a_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def id_convert(inp):\n    id = int(inp)\n    if id not in src_issues:\n        print(\"WARNING: %d doesn't belong in %s\" % (id, src_issues))\n        return 0\n    already_imported = 0\n    for cur in src_issues:\n        if id == cur:\n            return existing_issues + already_imported + 1\n        else:\n            already_imported += 1\n    print('ERROR: In id_convert(%d): unexpected error' % id)\n"]]}
{"hexsha": "aca7b839e586cbe4b05be2d1afaa21cbad2cff67", "ext": "py", "lang": "Python", "content": "def __query_json(west=-122.2981,north=37.8790,east=-122.2547,south=37.8594,exclude_tertiary=True):\n\n    infrastructure = 'way[\"highway\"]'\n    timeout = 180\n    osm_filter = '[\"area\"!~\"yes\"][\"motor_vehicle\"!~\"no\"][\"motorcar\"!~\"no\"][\"access\"!~\"private\"][\"service\"!~\"parking|parking_aisle|driveway|private|emergency_access\"]'\n\n    if exclude_tertiary:\n        osm_filter = osm_filter + '[\"highway\"!~\"footway|bridleway|steps|path|living_street|service|pedestrian|track|bus_guideway|escape|raceway|cycleway|proposed|construction|bus_stop|crossing|elevator|emergency_access_point|give_way|mini_roundabout|motorway_junction|passing_place|rest_area|speed_camera|street_lamp|services|corridor|abandoned|platform|tertiary|unclassified|residential|tertiary_link\"]'\n    else:\n        osm_filter = osm_filter + '[\"highway\"!~\"footway|bridleway|steps|path|living_street|service|pedestrian|track|bus_guideway|escape|raceway|cycleway|proposed|construction|bus_stop|crossing|elevator|emergency_access_point|give_way|mini_roundabout|motorway_junction|passing_place|rest_area|speed_camera|street_lamp|services|corridor|abandoned|platform\"]'\n\n    maxsize = ''\n\n    # turn bbox into a polygon and project to local UTM\n    polygon = Polygon([(west, south), (east, south), (east, north), (west, north)])\n    geometry, crs_proj = __project_geometry(polygon)\n\n    if isinstance(geometry, Polygon):\n        geometry_proj_consolidated_subdivided = MultiPolygon([geometry])\n\n    geometry, _ = __project_geometry(geometry_proj_consolidated_subdivided, crs=crs_proj, to_latlong=True)\n\n    response_jsons = []\n\n    for poly in geometry:\n\n        west, south, east, north = poly.bounds\n        query_template = '[out:json][timeout:{timeout}]{maxsize};({infrastructure}{filters}({south:.6f},{west:.6f},{north:.6f},{east:.6f});>;);out;'\n        query_str = query_template.format(north=north, south=south,\n                                          east=east, west=west,\n                                          infrastructure=infrastructure,\n                                          filters=osm_filter,\n                                          timeout=timeout, maxsize=maxsize)\n        response_json = __overpass_request(data={'data': query_str}, timeout=timeout)\n        response_jsons.append(response_json)\n\n    return response_jsons", "fn_id": 1, "class_fn": false, "repo": "bkmgit/otm-tools", "file": "python/pyotm/osm_query.py", "last_update_at": "2018-10-17T00:52:02+00:00", "question_id": "aca7b839e586cbe4b05be2d1afaa21cbad2cff67_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def __query_json(west=-122.2981, north=37.879, east=-122.2547, south=37.8594, exclude_tertiary=True):\n    infrastructure = 'way[\"highway\"]'\n    timeout = 180\n    osm_filter = '[\"area\"!~\"yes\"][\"motor_vehicle\"!~\"no\"][\"motorcar\"!~\"no\"][\"access\"!~\"private\"][\"service\"!~\"parking|parking_aisle|driveway|private|emergency_access\"]'\n    if exclude_tertiary:\n        osm_filter = osm_filter + '[\"highway\"!~\"footway|bridleway|steps|path|living_street|service|pedestrian|track|bus_guideway|escape|raceway|cycleway|proposed|construction|bus_stop|crossing|elevator|emergency_access_point|give_way|mini_roundabout|motorway_junction|passing_place|rest_area|speed_camera|street_lamp|services|corridor|abandoned|platform|tertiary|unclassified|residential|tertiary_link\"]'\n    else:\n        osm_filter = osm_filter + '[\"highway\"!~\"footway|bridleway|steps|path|living_street|service|pedestrian|track|bus_guideway|escape|raceway|cycleway|proposed|construction|bus_stop|crossing|elevator|emergency_access_point|give_way|mini_roundabout|motorway_junction|passing_place|rest_area|speed_camera|street_lamp|services|corridor|abandoned|platform\"]'\n    maxsize = ''\n    polygon = Polygon([(west, south), (east, south), (east, north), (west, north)])\n    geometry, crs_proj = __project_geometry(polygon)\n    if isinstance(geometry, Polygon):\n        geometry_proj_consolidated_subdivided = MultiPolygon([geometry])\n    geometry, _ = __project_geometry(geometry_proj_consolidated_subdivided, crs=crs_proj, to_latlong=True)\n    response_jsons = []\n    for poly in geometry:\n        west, south, east, north = poly.bounds\n        query_template = '[out:json][timeout:{timeout}]{maxsize};({infrastructure}{filters}({south:.6f},{west:.6f},{north:.6f},{east:.6f});>;);out;'\n        query_str = query_template.format(north=north, south=south, east=east, west=west, infrastructure=infrastructure, filters=osm_filter, timeout=timeout, maxsize=maxsize)\n        response_json = __overpass_request(data={'data': query_str}, timeout=timeout)\n        response_jsons.append(response_json)\n"]]}
{"hexsha": "f6152f39e24bb9dd54ca82ec028f1d08a4de483f", "ext": "py", "lang": "Python", "content": "def get_config_drive_configuration(session, vdiuuid):\n    log.info(\"get_config_drive_configuration from vdi %s\" % (vdiuuid))\n    tempdir = None\n    umountrequired = False\n    filename = api_helper.export_disk(session, vdiuuid)\n    try:\n        tempdir = tempfile.mkdtemp()\n        cmd = ['mount', '-o', 'loop', '-t', 'iso9660', filename, tempdir]\n        util.runlocal(cmd)\n        umountrequired = True\n        userdatapath_template = os.path.join(\n            tempdir, 'openstack', 'latest', 'user_data.template')\n        content = util.read_file(userdatapath_template)\n    finally:\n        os.remove(filename)\n        if umountrequired:\n            cmd = ['umount', tempdir]\n            util.runlocal(cmd)\n        if tempdir:\n            os.rmdir(tempdir)\n    return content", "fn_id": 13, "class_fn": false, "repo": "dalrrard/xscontainer", "file": "src/xscontainer/coreos.py", "last_update_at": "2018-12-16T21:16:16+00:00", "question_id": "f6152f39e24bb9dd54ca82ec028f1d08a4de483f_13", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_config_drive_configuration(session, vdiuuid):\n    log.info('get_config_drive_configuration from vdi %s' % vdiuuid)\n    tempdir = None\n    umountrequired = False\n    filename = api_helper.export_disk(session, vdiuuid)\n    try:\n        tempdir = tempfile.mkdtemp()\n        cmd = ['mount', '-o', 'loop', '-t', 'iso9660', filename, tempdir]\n        util.runlocal(cmd)\n        umountrequired = True\n        userdatapath_template = os.path.join(tempdir, 'openstack', 'latest', 'user_data.template')\n        content = util.read_file(userdatapath_template)\n    finally:\n        os.remove(filename)\n        if umountrequired:\n            cmd = ['umount', tempdir]\n            util.runlocal(cmd)\n        if tempdir:\n            os.rmdir(tempdir)\n"]]}
{"hexsha": "19eb7fbf79f25eacd4df46f0592f124449e650f7", "ext": "py", "lang": "Python", "content": "def primes(n):\n    ans = set()\n    for i in range(2, n):\n        prime = True\n        for p in ans:\n            if i % p == 0:\n                prime = False\n                break\n        if prime:\n            ans.add(i)\n    return ans", "fn_id": 4, "class_fn": false, "repo": "cromero/fidi", "file": "numbers.py", "last_update_at": "2018-06-11T12:46:07+00:00", "question_id": "19eb7fbf79f25eacd4df46f0592f124449e650f7_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def primes(n):\n    ans = set()\n    for i in range(2, n):\n        prime = True\n        for p in ans:\n            if i % p == 0:\n                prime = False\n                break\n        if prime:\n            ans.add(i)\n"]]}
{"hexsha": "9960509163541c33ee25ff4bb44842a269538709", "ext": "py", "lang": "Python", "content": "def _host_make_bigfile(self: Host, path: str, mount_point: str) -> None:\n    output = self.check_output('df --output=size,used %s | tail -n 1' % mount_point)\n    # Sizes in kiB\n    size = int(output.split()[0])\n    used = int(output.split()[1])\n    # Want to get it up to 92% full\n    needed = int(0.92 * size) - used\n    self.check_output('dd if=/dev/zero of=%s bs=1M count=%d' % (path, int(needed / 1024)))", "fn_id": 1, "class_fn": false, "repo": "calliecameron/pi-server", "file": "zz-vm-testing/conftest.py", "last_update_at": "2018-01-23T23:24:02+00:00", "question_id": "9960509163541c33ee25ff4bb44842a269538709_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _host_make_bigfile(self: Host, path: str, mount_point: str) -> None:\n    output = self.check_output('df --output=size,used %s | tail -n 1' % mount_point)\n    size = int(output.split()[0])\n    used = int(output.split()[1])\n    needed = int(0.92 * size) - used\n"]]}
{"hexsha": "9f1f41c8e7ab08d3fbdaaf94146c28d7acdf55a7", "ext": "py", "lang": "Python", "content": "def main():\n    args = parse_args()\n\n    set_up_logging(args.log)\n\n    if args.hmac_file_secret:\n        hmac_secret = get_secret_from_temp_file(args.hmac_file_secret)\n        handlers.app.config['jedihttp.hmac_secret'] = b64decode(hmac_secret)\n        handlers.app.install(HmacPlugin())\n\n    handlers.app.install(WatchdogPlugin(args.idle_suicide_seconds,\n                                        args.check_interval_seconds))\n\n    handlers.wsgi_server = StoppableWSGIServer(handlers.app,\n                                               host=args.host,\n                                               port=args.port)\n    handlers.wsgi_server.start()", "fn_id": 3, "class_fn": false, "repo": "vheon/jedihttp", "file": "jedihttp/__main__.py", "last_update_at": "2018-07-30T18:17:32+00:00", "question_id": "9f1f41c8e7ab08d3fbdaaf94146c28d7acdf55a7_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main():\n    args = parse_args()\n    set_up_logging(args.log)\n    if args.hmac_file_secret:\n        hmac_secret = get_secret_from_temp_file(args.hmac_file_secret)\n        handlers.app.config['jedihttp.hmac_secret'] = b64decode(hmac_secret)\n        handlers.app.install(HmacPlugin())\n    handlers.app.install(WatchdogPlugin(args.idle_suicide_seconds, args.check_interval_seconds))\n    handlers.wsgi_server = StoppableWSGIServer(handlers.app, host=args.host, port=args.port)\n"]]}
{"hexsha": "57c643192d592d35df1b3836680cc57d0a7af84d", "ext": "py", "lang": "Python", "content": "def test_type_respects_inheritance():\n    bl = BusList()\n    assert type(bl) == BusList\n    assert type(bl) != Iterable\n    assert type(bl) != VehicleList", "fn_id": 0, "class_fn": false, "repo": "tyleragreen/python-interface", "file": "tests/test_inheritance.py", "last_update_at": "2018-12-09T08:43:21+00:00", "question_id": "57c643192d592d35df1b3836680cc57d0a7af84d_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_type_respects_inheritance():\n    bl = BusList()\n    assert type(bl) == BusList\n    assert type(bl) != Iterable\n"]]}
{"hexsha": "b0f11662cf6307bdcf8e8cfc5d2b6a52da5ec243", "ext": "py", "lang": "Python", "content": "def CBIR(query_image, image_set, method):\n    comp_method = [cv2.cv.CV_COMP_CORREL, cv2.cv.CV_COMP_INTERSECT, \\\n        cv2.cv.CV_COMP_CHISQR, cv2.cv.CV_COMP_BHATTACHARYYA]\n    if method < 12:\n        return compare_hist(query_image, image_set, method // 4, comp_method[method % 4])\n    elif method == 12:\n        from ccv import CCV\n        ccv = CCV(query_image).get_vector()\n        ccv_set = [CCV(i).get_vector() for i in image_set]\n        l1_distance = [L1_distance(ccv, i) for i in ccv_set]\n        return np.argmin(l1_distance)\n    elif method == 13:\n        from crh import CRH\n        crh = CRH(query_image).get_vector()\n        crh_set = [CRH(i).get_vector() for i in image_set]\n        l1_distance = [L1_distance(crh, i) for i in crh_set]\n        return np.argmin(l1_distance)\n    elif method == 14:\n        from ccdr import CCDR\n        ccdr = CCDR(query_image).get_vector()\n        ccdr_set = [CCDR(i).get_vector() for i in image_set]\n        l1_distance = [L1_distance(ccdr, i) for i in ccdr_set]\n        return np.argmin(l1_distance)\n    return 0", "fn_id": 13, "class_fn": false, "repo": "lijiancheng0614/cv_homework", "file": "hw1/hw1.py", "last_update_at": "2018-05-20T03:49:16+00:00", "question_id": "b0f11662cf6307bdcf8e8cfc5d2b6a52da5ec243_13", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def CBIR(query_image, image_set, method):\n    comp_method = [cv2.cv.CV_COMP_CORREL, cv2.cv.CV_COMP_INTERSECT, cv2.cv.CV_COMP_CHISQR, cv2.cv.CV_COMP_BHATTACHARYYA]\n    if method < 12:\n        return compare_hist(query_image, image_set, method // 4, comp_method[method % 4])\n    elif method == 12:\n        from ccv import CCV\n        ccv = CCV(query_image).get_vector()\n        ccv_set = [CCV(i).get_vector() for i in image_set]\n        l1_distance = [L1_distance(ccv, i) for i in ccv_set]\n        return np.argmin(l1_distance)\n    elif method == 13:\n        from crh import CRH\n        crh = CRH(query_image).get_vector()\n        crh_set = [CRH(i).get_vector() for i in image_set]\n        l1_distance = [L1_distance(crh, i) for i in crh_set]\n        return np.argmin(l1_distance)\n    elif method == 14:\n        from ccdr import CCDR\n        ccdr = CCDR(query_image).get_vector()\n        ccdr_set = [CCDR(i).get_vector() for i in image_set]\n        l1_distance = [L1_distance(ccdr, i) for i in ccdr_set]\n        return np.argmin(l1_distance)\n"]]}
{"hexsha": "c2da72d079646a1532ba05583af48c016a830e2c", "ext": "py", "lang": "Python", "content": "def genData(n, start=0, end=10):\n    x = np.linspace(start, end, n)\n    y = np.sin(10*x) - x*x\n    return y", "fn_id": 0, "class_fn": false, "repo": "Raphael-C-Almeida/Wireless-Sensor-Network", "file": "Data Fusion Test/Kalman Com Taxa de Erro.py", "last_update_at": "2018-11-25T20:08:48+00:00", "question_id": "c2da72d079646a1532ba05583af48c016a830e2c_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def genData(n, start=0, end=10):\n    x = np.linspace(start, end, n)\n    y = np.sin(10 * x) - x * x\n"]]}
{"hexsha": "8a813722604b7fd00175edf26752abe8321303f8", "ext": "py", "lang": "Python", "content": "def includeme(config):\n    \"\"\" Activate the switchboard; usually called via\n    ``config.include('pyramid_switchboard')`` instead of being invoked\n    directly. \"\"\"\n    settings = config.registry.settings\n    # By setting nested to True, we're only looking for switchboard.* settings.\n    configure(settings, nested=True)\n\n    # Create the new application using the updated settings.\n    switchboard = SwitchboardMiddleware(app)\n    config.add_route('switchboard', '/_switchboard/*subpath')\n    permission = settings.get('switchboard.permission', 'admin')\n    config.add_view(wsgiapp2(switchboard), route_name='switchboard',\n                    permission=permission)", "fn_id": 0, "class_fn": false, "repo": "kadams54/pyramid_switchboard", "file": "pyramid_switchboard/__init__.py", "last_update_at": "2018-11-17T13:18:36+00:00", "question_id": "8a813722604b7fd00175edf26752abe8321303f8_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def includeme(config):\n    \"\"\" Activate the switchboard; usually called via\n    ``config.include('pyramid_switchboard')`` instead of being invoked\n    directly. \"\"\"\n    settings = config.registry.settings\n    configure(settings, nested=True)\n    switchboard = SwitchboardMiddleware(app)\n    config.add_route('switchboard', '/_switchboard/*subpath')\n    permission = settings.get('switchboard.permission', 'admin')\n"]]}
{"hexsha": "164c656c8ecce496596587b9af4549e57bc15ed3", "ext": "py", "lang": "Python", "content": "def reload_working_set():\n    \"\"\"\n    Reinitialize the working set\n    \"\"\"\n    WS.initialize(db)", "fn_id": 1, "class_fn": false, "repo": "cilki/super-palm-tree", "file": "data/main/cache.py", "last_update_at": "2018-05-07T01:26:54+00:00", "question_id": "164c656c8ecce496596587b9af4549e57bc15ed3_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def reload_working_set():\n    \"\"\"\n    Reinitialize the working set\n    \"\"\"\n"]]}
{"hexsha": "d6aec1e46549a733a6ef78b43069d013e75b09e1", "ext": "py", "lang": "Python", "content": "def main():\n    module = AnsibleModule(\n        argument_spec=dict(\n            device=dict(),\n            ardana_host_info=dict()\n        )\n    )\n    device = module.params['device']\n    ardana_host_info = json.loads(module.params['ardana_host_info'])\n\n    if not device and not ardana_host_info:\n        module.fail_json(rc=256, msg=\"No device or Ardana host info specified\")\n\n    ardana_disk_models = ardana_host_info['my_disk_models'] \\\n        if 'my_disk_models' in ardana_host_info else dict()\n    ardana_device_groups = ardana_host_info['my_device_groups'] \\\n        if 'my_device_groups' in ardana_host_info else dict()\n\n    if ardana_host_info:\n        rc_cumulative = 0\n        err_cumulative = \"\"\n        wwids = dict()\n\n        if ardana_disk_models:\n            for volume_group in ardana_disk_models['volume_groups']:\n                if 'multipath' in volume_group\\\n                    and volume_group['multipath'] == True:\n                    continue\n                for physical_volume in volume_group['physical_volumes']:\n                    physical_volume = physical_volume.replace('_root', '')\n                    # Not a scsi disk skip\n                    if not os.path.exists(\"/sys/block/%s/device/scsi_disk\"\n                                          % (os.path.basename(physical_volume))):\n                        continue\n                    wwid_command = '/lib/udev/scsi_id -g %s' % physical_volume\n                    rc, out, err = module.run_command(wwid_command)\n                    rc_cumulative += rc\n                    err_cumulative += err\n                    wwids[physical_volume] = '' if out is None \\\n                        else out.rstrip(\"\\r\\n\")\n\n        if ardana_device_groups:\n            for device_group in ardana_device_groups:\n                for entry in ardana_device_groups[device_group]:\n                    if  'multipath' in entry\\\n                        and entry['multipath'] == True:\n                        continue\n                    for dev in entry['devices']:\n                        # Not a scsi disk skip\n                        if not os.path.exists(\"/sys/block/%s/device/scsi_disk\"\n                                              % (os.path.basename(dev['name']))):\n                            continue\n                        wwid_command = '/lib/udev/scsi_id -g %s' % dev['name']\n                        rc, out, err = module.run_command(wwid_command)\n                        rc_cumulative += rc\n                        err_cumulative += err\n                        wwids[dev['name']] = '' if out is None \\\n                            else out.rstrip(\"\\r\\n\")\n\n        module.exit_json(\n            hostname=ardana_host_info['vars']['my_network_name'],\n            wwid=wwids,\n            rc=rc_cumulative,\n            stderr=err_cumulative,\n            changed=True\n        )\n\n    if device:\n        wwid_command = '/lib/udev/scsi_id -g %s' % device\n        rc, out, err = module.run_command(wwid_command)\n\n        module.exit_json(\n            disk=wwid_command,\n            wwid='' if out is None else out.rstrip(\"\\r\\n\"),\n            stderr='' if err is None else err.rstrip(\"\\r\\n\"),\n            rc=rc,\n            changed=True\n        )", "fn_id": 0, "class_fn": false, "repo": "ArdanaCLM/osconfig-ansible", "file": "roles/multipath/library/get_wwid.py", "last_update_at": "2018-06-05T13:19:58+00:00", "question_id": "d6aec1e46549a733a6ef78b43069d013e75b09e1_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main():\n    module = AnsibleModule(argument_spec=dict(device=dict(), ardana_host_info=dict()))\n    device = module.params['device']\n    ardana_host_info = json.loads(module.params['ardana_host_info'])\n    if not device and (not ardana_host_info):\n        module.fail_json(rc=256, msg='No device or Ardana host info specified')\n    ardana_disk_models = ardana_host_info['my_disk_models'] if 'my_disk_models' in ardana_host_info else dict()\n    ardana_device_groups = ardana_host_info['my_device_groups'] if 'my_device_groups' in ardana_host_info else dict()\n    if ardana_host_info:\n        rc_cumulative = 0\n        err_cumulative = ''\n        wwids = dict()\n        if ardana_disk_models:\n            for volume_group in ardana_disk_models['volume_groups']:\n                if 'multipath' in volume_group and volume_group['multipath'] == True:\n                    continue\n                for physical_volume in volume_group['physical_volumes']:\n                    physical_volume = physical_volume.replace('_root', '')\n                    if not os.path.exists('/sys/block/%s/device/scsi_disk' % os.path.basename(physical_volume)):\n                        continue\n                    wwid_command = '/lib/udev/scsi_id -g %s' % physical_volume\n                    rc, out, err = module.run_command(wwid_command)\n                    rc_cumulative += rc\n                    err_cumulative += err\n                    wwids[physical_volume] = '' if out is None else out.rstrip('\\r\\n')\n        if ardana_device_groups:\n            for device_group in ardana_device_groups:\n                for entry in ardana_device_groups[device_group]:\n                    if 'multipath' in entry and entry['multipath'] == True:\n                        continue\n                    for dev in entry['devices']:\n                        if not os.path.exists('/sys/block/%s/device/scsi_disk' % os.path.basename(dev['name'])):\n                            continue\n                        wwid_command = '/lib/udev/scsi_id -g %s' % dev['name']\n                        rc, out, err = module.run_command(wwid_command)\n                        rc_cumulative += rc\n                        err_cumulative += err\n                        wwids[dev['name']] = '' if out is None else out.rstrip('\\r\\n')\n        module.exit_json(hostname=ardana_host_info['vars']['my_network_name'], wwid=wwids, rc=rc_cumulative, stderr=err_cumulative, changed=True)\n    if device:\n        wwid_command = '/lib/udev/scsi_id -g %s' % device\n        rc, out, err = module.run_command(wwid_command)\n"]]}
{"hexsha": "c4a3e2bd55619ba48cb984724f3222c423a71af9", "ext": "py", "lang": "Python", "content": "def test_QHsmTst_dispatch(qutest_noreset):\n    qutest = qutest_noreset # name change\n\n    qutest.dispatch(\"A_SIG\")\n    qutest.expect(\"%timestamp Disp===> Obj=the_hsm,Sig=A_SIG,State=s211\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s211\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s21\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s21\")\n    qutest.expect(\"===RTC===> St-Init  Obj=the_hsm,State=s21->s211\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s211\")\n    qutest.expect(\"%timestamp ===>Tran Obj=the_hsm,Sig=A_SIG,State=s21->s211\")\n    qutest.expect(\"%timestamp Trg-Done QS_RX_EVENT\")\n\n    qutest.dispatch(\"B_SIG\")\n    qutest.expect(\"%timestamp Disp===> Obj=the_hsm,Sig=B_SIG,State=s211\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s211\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s211\")\n    qutest.expect(\"%timestamp ===>Tran Obj=the_hsm,Sig=B_SIG,State=s21->s211\")\n    qutest.expect(\"%timestamp Trg-Done QS_RX_EVENT\")\n\n    qutest.dispatch(\"D_SIG\")\n    qutest.expect(\"%timestamp Disp===> Obj=the_hsm,Sig=D_SIG,State=s211\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s211\")\n    qutest.expect(\"===RTC===> St-Init  Obj=the_hsm,State=s21->s211\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s211\")\n    qutest.expect(\"%timestamp ===>Tran Obj=the_hsm,Sig=D_SIG,State=s211->s211\")\n    qutest.expect(\"%timestamp Trg-Done QS_RX_EVENT\")\n\n    qutest.dispatch(\"E_SIG\")\n    qutest.expect(\"%timestamp Disp===> Obj=the_hsm,Sig=E_SIG,State=s211\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s211\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s21\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s2\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s1\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s11\")\n    qutest.expect(\"%timestamp ===>Tran Obj=the_hsm,Sig=E_SIG,State=s->s11\")\n    qutest.expect(\"%timestamp Trg-Done QS_RX_EVENT\")\n\n    qutest.dispatch(\"I_SIG\")\n    qutest.expect(\"%timestamp Disp===> Obj=the_hsm,Sig=I_SIG,State=s11\")\n    qutest.expect(\"%timestamp =>Intern Obj=the_hsm,Sig=I_SIG,State=s1\")\n    qutest.expect(\"%timestamp Trg-Done QS_RX_EVENT\")\n\n    qutest.dispatch(\"F_SIG\")\n    qutest.expect(\"%timestamp Disp===> Obj=the_hsm,Sig=F_SIG,State=s11\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s11\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s1\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s2\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s21\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s211\")\n    qutest.expect(\"%timestamp ===>Tran Obj=the_hsm,Sig=F_SIG,State=s1->s211\")\n    qutest.expect(\"%timestamp Trg-Done QS_RX_EVENT\")\n\n    qutest.dispatch(\"I_SIG\")\n    qutest.expect(\"%timestamp Disp===> Obj=the_hsm,Sig=I_SIG,State=s211\")\n    qutest.expect(\"%timestamp =>Intern Obj=the_hsm,Sig=I_SIG,State=s2\")\n    qutest.expect(\"%timestamp Trg-Done QS_RX_EVENT\")\n\n    qutest.dispatch(\"I_SIG\")\n    qutest.expect(\"%timestamp Disp===> Obj=the_hsm,Sig=I_SIG,State=s211\")\n    qutest.expect(\"===RTC===> St-Unhnd Obj=the_hsm,Sig=I_SIG,State=s2\")\n    qutest.expect(\"%timestamp =>Intern Obj=the_hsm,Sig=I_SIG,State=s\")\n    qutest.expect(\"%timestamp Trg-Done QS_RX_EVENT\")\n\n    qutest.dispatch(\"F_SIG\")\n    qutest.expect(\"%timestamp Disp===> Obj=the_hsm,Sig=F_SIG,State=s211\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s211\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s21\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s2\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s1\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s11\")\n    qutest.expect(\"%timestamp ===>Tran Obj=the_hsm,Sig=F_SIG,State=s2->s11\")\n    qutest.expect(\"%timestamp Trg-Done QS_RX_EVENT\")\n\n    qutest.dispatch(\"A_SIG\")\n    qutest.expect(\"%timestamp Disp===> Obj=the_hsm,Sig=A_SIG,State=s11\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s11\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s1\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s1\")\n    qutest.expect(\"===RTC===> St-Init  Obj=the_hsm,State=s1->s11\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s11\")\n    qutest.expect(\"%timestamp ===>Tran Obj=the_hsm,Sig=A_SIG,State=s1->s11\")\n    qutest.expect(\"%timestamp Trg-Done QS_RX_EVENT\")\n\n    qutest.dispatch(\"B_SIG\")\n    qutest.expect(\"%timestamp Disp===> Obj=the_hsm,Sig=B_SIG,State=s11\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s11\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s11\")\n    qutest.expect(\"%timestamp ===>Tran Obj=the_hsm,Sig=B_SIG,State=s1->s11\")\n    qutest.expect(\"%timestamp Trg-Done QS_RX_EVENT\")\n\n    qutest.dispatch(\"D_SIG\")\n    qutest.expect(\"%timestamp Disp===> Obj=the_hsm,Sig=D_SIG,State=s11\")\n    qutest.expect(\"===RTC===> St-Unhnd Obj=the_hsm,Sig=D_SIG,State=s11\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s11\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s1\")\n    qutest.expect(\"===RTC===> St-Init  Obj=the_hsm,State=s->s11\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s1\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s11\")\n    qutest.expect(\"%timestamp ===>Tran Obj=the_hsm,Sig=D_SIG,State=s1->s11\")\n    qutest.expect(\"%timestamp Trg-Done QS_RX_EVENT\")\n\n    qutest.dispatch(\"D_SIG\")\n    qutest.expect(\"%timestamp Disp===> Obj=the_hsm,Sig=D_SIG,State=s11\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s11\")\n    qutest.expect(\"===RTC===> St-Init  Obj=the_hsm,State=s1->s11\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s11\")\n    qutest.expect(\"%timestamp ===>Tran Obj=the_hsm,Sig=D_SIG,State=s11->s11\")\n    qutest.expect(\"%timestamp Trg-Done QS_RX_EVENT\")\n\n    qutest.dispatch(\"E_SIG\")\n    qutest.expect(\"%timestamp Disp===> Obj=the_hsm,Sig=E_SIG,State=s11\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s11\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s1\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s1\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s11\")\n    qutest.expect(\"%timestamp ===>Tran Obj=the_hsm,Sig=E_SIG,State=s->s11\")\n    qutest.expect(\"%timestamp Trg-Done QS_RX_EVENT\")\n\n    qutest.dispatch(\"G_SIG\")\n    qutest.expect(\"%timestamp Disp===> Obj=the_hsm,Sig=G_SIG,State=s11\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s11\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s1\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s2\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s21\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s211\")\n    qutest.expect(\"%timestamp ===>Tran Obj=the_hsm,Sig=G_SIG,State=s11->s211\")\n    qutest.expect(\"%timestamp Trg-Done QS_RX_EVENT\")\n\n    qutest.dispatch(\"H_SIG\")\n    qutest.expect(\"%timestamp Disp===> Obj=the_hsm,Sig=H_SIG,State=s211\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s211\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s21\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s2\")\n    qutest.expect(\"===RTC===> St-Init  Obj=the_hsm,State=s->s11\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s1\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s11\")\n    qutest.expect(\"%timestamp ===>Tran Obj=the_hsm,Sig=H_SIG,State=s211->s11\")\n    qutest.expect(\"%timestamp Trg-Done QS_RX_EVENT\")\n\n    qutest.dispatch(\"H_SIG\")\n    qutest.expect(\"%timestamp Disp===> Obj=the_hsm,Sig=H_SIG,State=s11\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s11\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s1\")\n    qutest.expect(\"===RTC===> St-Init  Obj=the_hsm,State=s->s11\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s1\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s11\")\n    qutest.expect(\"%timestamp ===>Tran Obj=the_hsm,Sig=H_SIG,State=s11->s11\")\n    qutest.expect(\"%timestamp Trg-Done QS_RX_EVENT\")\n\n    qutest.dispatch(\"C_SIG\")\n    qutest.expect(\"%timestamp Disp===> Obj=the_hsm,Sig=C_SIG,State=s11\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s11\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s1\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s2\")\n    qutest.expect(\"===RTC===> St-Init  Obj=the_hsm,State=s2->s211\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s21\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s211\")\n    qutest.expect(\"%timestamp ===>Tran Obj=the_hsm,Sig=C_SIG,State=s1->s211\")\n    qutest.expect(\"%timestamp Trg-Done QS_RX_EVENT\")\n\n    qutest.dispatch(\"G_SIG\")\n    qutest.expect(\"%timestamp Disp===> Obj=the_hsm,Sig=G_SIG,State=s211\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s211\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s21\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s2\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s1\")\n    qutest.expect(\"===RTC===> St-Init  Obj=the_hsm,State=s1->s11\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s11\")\n    qutest.expect(\"%timestamp ===>Tran Obj=the_hsm,Sig=G_SIG,State=s21->s11\")\n    qutest.expect(\"%timestamp Trg-Done QS_RX_EVENT\")\n\n    qutest.dispatch(\"C_SIG\")\n    qutest.expect(\"%timestamp Disp===> Obj=the_hsm,Sig=C_SIG,State=s11\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s11\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s1\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s2\")\n    qutest.expect(\"===RTC===> St-Init  Obj=the_hsm,State=s2->s211\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s21\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s211\")\n    qutest.expect(\"%timestamp ===>Tran Obj=the_hsm,Sig=C_SIG,State=s1->s211\")\n    qutest.expect(\"%timestamp Trg-Done QS_RX_EVENT\")\n\n    qutest.dispatch(\"C_SIG\")\n    qutest.expect(\"%timestamp Disp===> Obj=the_hsm,Sig=C_SIG,State=s211\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s211\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s21\")\n    qutest.expect(\"===RTC===> St-Exit  Obj=the_hsm,State=s2\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s1\")\n    qutest.expect(\"===RTC===> St-Init  Obj=the_hsm,State=s1->s11\")\n    qutest.expect(\"===RTC===> St-Entry Obj=the_hsm,State=s11\")\n    qutest.expect(\"%timestamp ===>Tran Obj=the_hsm,Sig=C_SIG,State=s2->s11\")\n    qutest.expect(\"%timestamp Trg-Done QS_RX_EVENT\")", "fn_id": 1, "class_fn": false, "repo": "LotusEngineering/qp-plus", "file": "qspypy/tests/test_qhsm-struct.py", "last_update_at": "2018-09-18T15:40:17+00:00", "question_id": "c4a3e2bd55619ba48cb984724f3222c423a71af9_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_QHsmTst_dispatch(qutest_noreset):\n    qutest = qutest_noreset\n    qutest.dispatch('A_SIG')\n    qutest.expect('%timestamp Disp===> Obj=the_hsm,Sig=A_SIG,State=s211')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s211')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s21')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s21')\n    qutest.expect('===RTC===> St-Init  Obj=the_hsm,State=s21->s211')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s211')\n    qutest.expect('%timestamp ===>Tran Obj=the_hsm,Sig=A_SIG,State=s21->s211')\n    qutest.expect('%timestamp Trg-Done QS_RX_EVENT')\n    qutest.dispatch('B_SIG')\n    qutest.expect('%timestamp Disp===> Obj=the_hsm,Sig=B_SIG,State=s211')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s211')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s211')\n    qutest.expect('%timestamp ===>Tran Obj=the_hsm,Sig=B_SIG,State=s21->s211')\n    qutest.expect('%timestamp Trg-Done QS_RX_EVENT')\n    qutest.dispatch('D_SIG')\n    qutest.expect('%timestamp Disp===> Obj=the_hsm,Sig=D_SIG,State=s211')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s211')\n    qutest.expect('===RTC===> St-Init  Obj=the_hsm,State=s21->s211')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s211')\n    qutest.expect('%timestamp ===>Tran Obj=the_hsm,Sig=D_SIG,State=s211->s211')\n    qutest.expect('%timestamp Trg-Done QS_RX_EVENT')\n    qutest.dispatch('E_SIG')\n    qutest.expect('%timestamp Disp===> Obj=the_hsm,Sig=E_SIG,State=s211')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s211')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s21')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s2')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s1')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s11')\n    qutest.expect('%timestamp ===>Tran Obj=the_hsm,Sig=E_SIG,State=s->s11')\n    qutest.expect('%timestamp Trg-Done QS_RX_EVENT')\n    qutest.dispatch('I_SIG')\n    qutest.expect('%timestamp Disp===> Obj=the_hsm,Sig=I_SIG,State=s11')\n    qutest.expect('%timestamp =>Intern Obj=the_hsm,Sig=I_SIG,State=s1')\n    qutest.expect('%timestamp Trg-Done QS_RX_EVENT')\n    qutest.dispatch('F_SIG')\n    qutest.expect('%timestamp Disp===> Obj=the_hsm,Sig=F_SIG,State=s11')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s11')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s1')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s2')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s21')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s211')\n    qutest.expect('%timestamp ===>Tran Obj=the_hsm,Sig=F_SIG,State=s1->s211')\n    qutest.expect('%timestamp Trg-Done QS_RX_EVENT')\n    qutest.dispatch('I_SIG')\n    qutest.expect('%timestamp Disp===> Obj=the_hsm,Sig=I_SIG,State=s211')\n    qutest.expect('%timestamp =>Intern Obj=the_hsm,Sig=I_SIG,State=s2')\n    qutest.expect('%timestamp Trg-Done QS_RX_EVENT')\n    qutest.dispatch('I_SIG')\n    qutest.expect('%timestamp Disp===> Obj=the_hsm,Sig=I_SIG,State=s211')\n    qutest.expect('===RTC===> St-Unhnd Obj=the_hsm,Sig=I_SIG,State=s2')\n    qutest.expect('%timestamp =>Intern Obj=the_hsm,Sig=I_SIG,State=s')\n    qutest.expect('%timestamp Trg-Done QS_RX_EVENT')\n    qutest.dispatch('F_SIG')\n    qutest.expect('%timestamp Disp===> Obj=the_hsm,Sig=F_SIG,State=s211')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s211')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s21')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s2')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s1')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s11')\n    qutest.expect('%timestamp ===>Tran Obj=the_hsm,Sig=F_SIG,State=s2->s11')\n    qutest.expect('%timestamp Trg-Done QS_RX_EVENT')\n    qutest.dispatch('A_SIG')\n    qutest.expect('%timestamp Disp===> Obj=the_hsm,Sig=A_SIG,State=s11')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s11')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s1')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s1')\n    qutest.expect('===RTC===> St-Init  Obj=the_hsm,State=s1->s11')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s11')\n    qutest.expect('%timestamp ===>Tran Obj=the_hsm,Sig=A_SIG,State=s1->s11')\n    qutest.expect('%timestamp Trg-Done QS_RX_EVENT')\n    qutest.dispatch('B_SIG')\n    qutest.expect('%timestamp Disp===> Obj=the_hsm,Sig=B_SIG,State=s11')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s11')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s11')\n    qutest.expect('%timestamp ===>Tran Obj=the_hsm,Sig=B_SIG,State=s1->s11')\n    qutest.expect('%timestamp Trg-Done QS_RX_EVENT')\n    qutest.dispatch('D_SIG')\n    qutest.expect('%timestamp Disp===> Obj=the_hsm,Sig=D_SIG,State=s11')\n    qutest.expect('===RTC===> St-Unhnd Obj=the_hsm,Sig=D_SIG,State=s11')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s11')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s1')\n    qutest.expect('===RTC===> St-Init  Obj=the_hsm,State=s->s11')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s1')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s11')\n    qutest.expect('%timestamp ===>Tran Obj=the_hsm,Sig=D_SIG,State=s1->s11')\n    qutest.expect('%timestamp Trg-Done QS_RX_EVENT')\n    qutest.dispatch('D_SIG')\n    qutest.expect('%timestamp Disp===> Obj=the_hsm,Sig=D_SIG,State=s11')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s11')\n    qutest.expect('===RTC===> St-Init  Obj=the_hsm,State=s1->s11')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s11')\n    qutest.expect('%timestamp ===>Tran Obj=the_hsm,Sig=D_SIG,State=s11->s11')\n    qutest.expect('%timestamp Trg-Done QS_RX_EVENT')\n    qutest.dispatch('E_SIG')\n    qutest.expect('%timestamp Disp===> Obj=the_hsm,Sig=E_SIG,State=s11')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s11')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s1')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s1')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s11')\n    qutest.expect('%timestamp ===>Tran Obj=the_hsm,Sig=E_SIG,State=s->s11')\n    qutest.expect('%timestamp Trg-Done QS_RX_EVENT')\n    qutest.dispatch('G_SIG')\n    qutest.expect('%timestamp Disp===> Obj=the_hsm,Sig=G_SIG,State=s11')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s11')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s1')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s2')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s21')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s211')\n    qutest.expect('%timestamp ===>Tran Obj=the_hsm,Sig=G_SIG,State=s11->s211')\n    qutest.expect('%timestamp Trg-Done QS_RX_EVENT')\n    qutest.dispatch('H_SIG')\n    qutest.expect('%timestamp Disp===> Obj=the_hsm,Sig=H_SIG,State=s211')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s211')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s21')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s2')\n    qutest.expect('===RTC===> St-Init  Obj=the_hsm,State=s->s11')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s1')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s11')\n    qutest.expect('%timestamp ===>Tran Obj=the_hsm,Sig=H_SIG,State=s211->s11')\n    qutest.expect('%timestamp Trg-Done QS_RX_EVENT')\n    qutest.dispatch('H_SIG')\n    qutest.expect('%timestamp Disp===> Obj=the_hsm,Sig=H_SIG,State=s11')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s11')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s1')\n    qutest.expect('===RTC===> St-Init  Obj=the_hsm,State=s->s11')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s1')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s11')\n    qutest.expect('%timestamp ===>Tran Obj=the_hsm,Sig=H_SIG,State=s11->s11')\n    qutest.expect('%timestamp Trg-Done QS_RX_EVENT')\n    qutest.dispatch('C_SIG')\n    qutest.expect('%timestamp Disp===> Obj=the_hsm,Sig=C_SIG,State=s11')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s11')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s1')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s2')\n    qutest.expect('===RTC===> St-Init  Obj=the_hsm,State=s2->s211')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s21')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s211')\n    qutest.expect('%timestamp ===>Tran Obj=the_hsm,Sig=C_SIG,State=s1->s211')\n    qutest.expect('%timestamp Trg-Done QS_RX_EVENT')\n    qutest.dispatch('G_SIG')\n    qutest.expect('%timestamp Disp===> Obj=the_hsm,Sig=G_SIG,State=s211')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s211')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s21')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s2')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s1')\n    qutest.expect('===RTC===> St-Init  Obj=the_hsm,State=s1->s11')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s11')\n    qutest.expect('%timestamp ===>Tran Obj=the_hsm,Sig=G_SIG,State=s21->s11')\n    qutest.expect('%timestamp Trg-Done QS_RX_EVENT')\n    qutest.dispatch('C_SIG')\n    qutest.expect('%timestamp Disp===> Obj=the_hsm,Sig=C_SIG,State=s11')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s11')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s1')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s2')\n    qutest.expect('===RTC===> St-Init  Obj=the_hsm,State=s2->s211')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s21')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s211')\n    qutest.expect('%timestamp ===>Tran Obj=the_hsm,Sig=C_SIG,State=s1->s211')\n    qutest.expect('%timestamp Trg-Done QS_RX_EVENT')\n    qutest.dispatch('C_SIG')\n    qutest.expect('%timestamp Disp===> Obj=the_hsm,Sig=C_SIG,State=s211')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s211')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s21')\n    qutest.expect('===RTC===> St-Exit  Obj=the_hsm,State=s2')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s1')\n    qutest.expect('===RTC===> St-Init  Obj=the_hsm,State=s1->s11')\n    qutest.expect('===RTC===> St-Entry Obj=the_hsm,State=s11')\n    qutest.expect('%timestamp ===>Tran Obj=the_hsm,Sig=C_SIG,State=s2->s11')\n"]]}
{"hexsha": "fe9c8b90029c8526e886a9efc289c0719645fbfe", "ext": "py", "lang": "Python", "content": "def test_pattern_match_none():\n    data = pd.Series([\"foo\", \"bar\"])\n    values = [\"baz\"]\n\n    obs = utils.pattern_match(data, values)\n    assert (obs == [False, False]).all()", "fn_id": 0, "class_fn": false, "repo": "mabudz/pyam", "file": "tests/test_utils.py", "last_update_at": "2018-03-05T09:09:42+00:00", "question_id": "fe9c8b90029c8526e886a9efc289c0719645fbfe_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_pattern_match_none():\n    data = pd.Series(['foo', 'bar'])\n    values = ['baz']\n    obs = utils.pattern_match(data, values)\n"]]}
{"hexsha": "c52f7eda0c1f7bb5409abea39e8d1e8797d1155a", "ext": "py", "lang": "Python", "content": "def history_log(event: str) -> Tuple[bool, str]:\n    try:\n        with open(HISTORY_LOG_FILE, \"a\") as file_:\n            file_.write(event)\n        return True, event\n    except Exception as e:\n        return False, str(e)", "fn_id": 1, "class_fn": false, "repo": "ip-exchange/ipsx-windows-proxy-demo", "file": "util.py", "last_update_at": "2018-03-30T13:34:09+00:00", "question_id": "c52f7eda0c1f7bb5409abea39e8d1e8797d1155a_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def history_log(event: str) -> Tuple[bool, str]:\n    try:\n        with open(HISTORY_LOG_FILE, 'a') as file_:\n            file_.write(event)\n        return (True, event)\n    except Exception as e:\n"]]}
{"hexsha": "b05d4c763dce74af14b2e274a94368cfa50e03ab", "ext": "py", "lang": "Python", "content": "def expand_env_variables(self, env, string_to_process):\n        \"\"\"\n        \u0440\u0430\u0437\u0432\u0435\u0440\u043d\u0443\u0442\u044c \u0432 \u0441\u0442\u0440\u043e\u043a\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435 \u043e\u043a\u0440\u0443\u0436\u0435\u043d\u0438\u044f zoo\n        \u043f\u043e\u0438\u0441\u043a\u0430\u0442\u044c \u0432 \u0441\u0442\u0440\u043e\u043a\u0435 '%KEY%' \u0435\u0441\u043b\u0438 \u0435\u0441\u0442\u044c \u0442\u043e \u0437\u0430\u043c\u0435\u043d\u0438\u0442\u044c \u043d\u0430 \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0432\u0443\u044e\u0449\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0438\u0437 \u0441\u043b\u043e\u0432\u0430\u0440\u044f\n        \u0438 \u0442\u0430\u043a \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043a\u043b\u044e\u0447\u0430 \u0432 \u0441\u043b\u043e\u0432\u0430\u0440\u0435\n\n        :param string_to_process:\n        :return:\n        \"\"\"\n        result = string_to_process\n        for (key, value) in env.items():\n            if string_to_process.lower() != key.lower():\n                result = result.lower().replace(\"%\" + key.lower() + \"%\", value)\n\n        if result.lower().find(\"%\") != -1:\n            #repeat if nested expand needed\n            for (key, value) in env.items():\n                if string_to_process.lower() != key.lower():\n                    result = result.lower().replace(\"%\" + key.lower() + \"%\", value)\n\n\n        if result.lower() != string_to_process.lower():\n            logging.debug(\"expand_zoo_variables > {0} --> {1}\".format( string_to_process, result.lower()))\n        return result.lower()", "fn_id": 6, "class_fn": false, "repo": "helicontech/zoo", "file": "Zoocmd/core/helpers/common.py", "last_update_at": "2018-04-12T13:36:03+00:00", "question_id": "b05d4c763dce74af14b2e274a94368cfa50e03ab_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def expand_env_variables(self, env, string_to_process):\n    \"\"\"\n        \u0440\u0430\u0437\u0432\u0435\u0440\u043d\u0443\u0442\u044c \u0432 \u0441\u0442\u0440\u043e\u043a\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435 \u043e\u043a\u0440\u0443\u0436\u0435\u043d\u0438\u044f zoo\n        \u043f\u043e\u0438\u0441\u043a\u0430\u0442\u044c \u0432 \u0441\u0442\u0440\u043e\u043a\u0435 '%KEY%' \u0435\u0441\u043b\u0438 \u0435\u0441\u0442\u044c \u0442\u043e \u0437\u0430\u043c\u0435\u043d\u0438\u0442\u044c \u043d\u0430 \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0432\u0443\u044e\u0449\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0438\u0437 \u0441\u043b\u043e\u0432\u0430\u0440\u044f\n        \u0438 \u0442\u0430\u043a \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043a\u043b\u044e\u0447\u0430 \u0432 \u0441\u043b\u043e\u0432\u0430\u0440\u0435\n\n        :param string_to_process:\n        :return:\n        \"\"\"\n    result = string_to_process\n    for key, value in env.items():\n        if string_to_process.lower() != key.lower():\n            result = result.lower().replace('%' + key.lower() + '%', value)\n    if result.lower().find('%') != -1:\n        for key, value in env.items():\n            if string_to_process.lower() != key.lower():\n                result = result.lower().replace('%' + key.lower() + '%', value)\n    if result.lower() != string_to_process.lower():\n        logging.debug('expand_zoo_variables > {0} --> {1}'.format(string_to_process, result.lower()))\n"]]}
{"hexsha": "d86669715093918ca78ec99c89eefc422ff594e0", "ext": "py", "lang": "Python", "content": "def _norm_input_labels_index(input, labels=None, index=None):\n    \"\"\"\n    Normalize arguments to a standard form.\n    \"\"\"\n\n    input = _compat._asarray(input)\n\n    if labels is None:\n        labels = dask.array.ones(input.shape, dtype=int, chunks=input.chunks)\n        index = dask.array.ones(tuple(), dtype=int, chunks=tuple())\n    elif index is None:\n        labels = (labels > 0).astype(int)\n        index = dask.array.ones(tuple(), dtype=int, chunks=tuple())\n\n    labels = _compat._asarray(labels)\n    index = _compat._asarray(index)\n\n    if index.ndim > 1:\n        warnings.warn(\n            \"Having index with dimensionality greater than 1 is undefined.\",\n            FutureWarning\n        )\n\n    if input.shape != labels.shape:\n        raise ValueError(\"The input and labels arrays must be the same shape.\")\n\n    return (input, labels, index)", "fn_id": 0, "class_fn": false, "repo": "dask-image/dask-ndmeasure", "file": "dask_ndmeasure/_utils.py", "last_update_at": "2018-05-24T13:52:58+00:00", "question_id": "d86669715093918ca78ec99c89eefc422ff594e0_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _norm_input_labels_index(input, labels=None, index=None):\n    \"\"\"\n    Normalize arguments to a standard form.\n    \"\"\"\n    input = _compat._asarray(input)\n    if labels is None:\n        labels = dask.array.ones(input.shape, dtype=int, chunks=input.chunks)\n        index = dask.array.ones(tuple(), dtype=int, chunks=tuple())\n    elif index is None:\n        labels = (labels > 0).astype(int)\n        index = dask.array.ones(tuple(), dtype=int, chunks=tuple())\n    labels = _compat._asarray(labels)\n    index = _compat._asarray(index)\n    if index.ndim > 1:\n        warnings.warn('Having index with dimensionality greater than 1 is undefined.', FutureWarning)\n    if input.shape != labels.shape:\n        raise ValueError('The input and labels arrays must be the same shape.')\n"]]}
{"hexsha": "c694ec0cb531e0a4637de6993f900eb0609c3342", "ext": "py", "lang": "Python", "content": "@_retry.with_exponential_backoff(initial_delay_secs=1.0, num_retries=10)\ndef _copy(gcs_path, model_dir, path_to_gsutil):\n  \"\"\"Copy files from gcs to a local path.\n\n  Behaves similar to the linux cp command.\n  Sample behavior:\n  dir1/\n    file1\n    file2\n    dir2/\n      file3\n\n  _copy(\"dir1\", \"/tmp\", path_to_gsutil)\n  After copy:\n  tmp/\n    dir1/\n      file1\n      ...\n\n  _copy(\"dir1/\", \"/tmp\", path_to_gsutil)\n  After copy:\n  tmp/\n    file1\n    file2\n    dir2/\n      file3\n\n  Args:\n    gcs_path: Source GCS path that we're copying from.\n    model_dir: Destination local path that we're copying to.\n    path_to_gsutil: Location of gsutil executable.\n\n  Raises:\n    Exception: If gsutil is not found.\n  \"\"\"\n  copy_start_time = time.time()\n  logging.debug(\"Starting to copy files from %s to %s\", gcs_path, model_dir)\n  if not os.path.exists(model_dir):\n    os.makedirs(model_dir)\n  # Simulate behavior of the linux cp command, where if the source is a\n  # directory ending in \"/\", files and directories in source are copied to the\n  # destination without the parent directory structure.\n  if gcs_path.endswith(\"/\"):\n    gcs_path = os.path.join(gcs_path, \"*\")\n  path_to_gsutil = path_to_gsutil or os.environ.get(\"PATH_TO_GSUTIL\") or \"\"\n  if not path_to_gsutil:\n    raise Exception(\"File copy failed: gsutil not found.\")\n  logging.debug(\"Using gsutil on path %s to perform file copy\",\n                path_to_gsutil)\n  try:\n    # Removed parallel downloads (\"-m\") because it was not working well in\n    # gVisor (b/37269226).\n    subprocess.check_call([\n        path_to_gsutil, \"-o\", \"GoogleCompute:service_account=default\",\n        \"cp\", \"-R\", gcs_path, model_dir], stdin=subprocess.PIPE)\n  except subprocess.CalledProcessError as e:\n    logging.error(str(e))\n    raise\n  logging.debug(\"Files copied from %s to %s: took %f seconds\", gcs_path,\n                model_dir, time.time() - copy_start_time)", "fn_id": 1, "class_fn": false, "repo": "rhaertel80/model_server", "file": "server/prediction_server_lib.py", "last_update_at": "2018-10-21T11:50:44+00:00", "question_id": "c694ec0cb531e0a4637de6993f900eb0609c3342_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@_retry.with_exponential_backoff(initial_delay_secs=1.0, num_retries=10)\ndef _copy(gcs_path, model_dir, path_to_gsutil):\n    \"\"\"Copy files from gcs to a local path.\n\n  Behaves similar to the linux cp command.\n  Sample behavior:\n  dir1/\n    file1\n    file2\n    dir2/\n      file3\n\n  _copy(\"dir1\", \"/tmp\", path_to_gsutil)\n  After copy:\n  tmp/\n    dir1/\n      file1\n      ...\n\n  _copy(\"dir1/\", \"/tmp\", path_to_gsutil)\n  After copy:\n  tmp/\n    file1\n    file2\n    dir2/\n      file3\n\n  Args:\n    gcs_path: Source GCS path that we're copying from.\n    model_dir: Destination local path that we're copying to.\n    path_to_gsutil: Location of gsutil executable.\n\n  Raises:\n    Exception: If gsutil is not found.\n  \"\"\"\n    copy_start_time = time.time()\n    logging.debug('Starting to copy files from %s to %s', gcs_path, model_dir)\n    if not os.path.exists(model_dir):\n        os.makedirs(model_dir)\n    if gcs_path.endswith('/'):\n        gcs_path = os.path.join(gcs_path, '*')\n    path_to_gsutil = path_to_gsutil or os.environ.get('PATH_TO_GSUTIL') or ''\n    if not path_to_gsutil:\n        raise Exception('File copy failed: gsutil not found.')\n    logging.debug('Using gsutil on path %s to perform file copy', path_to_gsutil)\n    try:\n        subprocess.check_call([path_to_gsutil, '-o', 'GoogleCompute:service_account=default', 'cp', '-R', gcs_path, model_dir], stdin=subprocess.PIPE)\n    except subprocess.CalledProcessError as e:\n        logging.error(str(e))\n        raise\n"]]}
{"hexsha": "6e7ed1813d85027d3fe7e7447861410b7ff150a4", "ext": "py", "lang": "Python", "content": "def print_ok(message):\n    \"\"\"Install python module using pip3.\n\n    Args:\n        module: module to install\n\n    Returns:\n        None\n\n    \"\"\"\n    # Print message\n    print('OK - {}'.format(message))", "fn_id": 1, "class_fn": false, "repo": "PalisadoesFoundation/switchmap-ng", "file": "maintenance/setup.py", "last_update_at": "2018-03-03T16:04:44+00:00", "question_id": "6e7ed1813d85027d3fe7e7447861410b7ff150a4_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def print_ok(message):\n    \"\"\"Install python module using pip3.\n\n    Args:\n        module: module to install\n\n    Returns:\n        None\n\n    \"\"\"\n"]]}
{"hexsha": "9a7ce1cf4d5eaf6ad19181b37c1636128e793f30", "ext": "py", "lang": "Python", "content": "def check_users():\n    users = User.select()\n    if not users.exists():\n        create_user()", "fn_id": 3, "class_fn": false, "repo": "malejandromorenov/passman", "file": "passman/passman.py", "last_update_at": "2018-06-27T01:43:41+00:00", "question_id": "9a7ce1cf4d5eaf6ad19181b37c1636128e793f30_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def check_users():\n    users = User.select()\n    if not users.exists():\n"]]}
{"hexsha": "263abdc55241644f3988aed23d8d9bdecca25e2d", "ext": "py", "lang": "Python", "content": "def banr(regs: Sequence[int], a: int, b: int, c: int) -> List[int]:\n    result = list(regs)\n    result[c] = result[a] & result[b]\n    return result", "fn_id": 4, "class_fn": false, "repo": "bob-white/advent_2018", "file": "day_16.py", "last_update_at": "2018-12-02T05:41:56+00:00", "question_id": "263abdc55241644f3988aed23d8d9bdecca25e2d_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def banr(regs: Sequence[int], a: int, b: int, c: int) -> List[int]:\n    result = list(regs)\n    result[c] = result[a] & result[b]\n"]]}
{"hexsha": "b162d0a08c962dc7fe541b326ece9bb04c1eca83", "ext": "py", "lang": "Python", "content": "def connect():\n\tconn = None;\n\ttry:\n\t\tconn = MySQLdb.connect(host = config.mysql.host, user = config.mysql.user, passwd = config.mysql.pwd, db = config.mysql.db, port = config.mysql.port);\n\t\tcur = conn.cursor()\n\t\tcur.execute(\"set names \" + config.mysql.charset +\";\");\n\t\tcur.close();\n\texcept MySQLdb.Error as e:\n\t\tstd.log.warn(\"Mysql Connect Error %d: %s\" % (e.args[0], e.args[1]));\n\t#endtry\n\t\n\treturn conn;\t", "fn_id": 0, "class_fn": false, "repo": "linex-cd/puf", "file": "lib/database/mysql2.py", "last_update_at": "2018-05-01T16:01:01+00:00", "question_id": "b162d0a08c962dc7fe541b326ece9bb04c1eca83_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def connect():\n    conn = None\n    try:\n        conn = MySQLdb.connect(host=config.mysql.host, user=config.mysql.user, passwd=config.mysql.pwd, db=config.mysql.db, port=config.mysql.port)\n        cur = conn.cursor()\n        cur.execute('set names ' + config.mysql.charset + ';')\n        cur.close()\n    except MySQLdb.Error as e:\n        std.log.warn('Mysql Connect Error %d: %s' % (e.args[0], e.args[1]))\n"]]}
{"hexsha": "830cae5925482d7554e655183f954ad29a1497d2", "ext": "py", "lang": "Python", "content": "def SideBySide(*plots,**kw):\n    n = len(plots)\n    iso = kw.get('iso')\n    if iso:\n        return Vppen(plots,'size=r vpstyle=n gridnum=%d,1' % n)\n    else:\n        return Vppen(plots,'yscale=%d vpstyle=n gridnum=%d,1' % (n,n))", "fn_id": 3, "class_fn": false, "repo": "kschleicher/seg_ww_2018", "file": "m8r.py", "last_update_at": "2018-09-25T13:02:40+00:00", "question_id": "830cae5925482d7554e655183f954ad29a1497d2_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def SideBySide(*plots, **kw):\n    n = len(plots)\n    iso = kw.get('iso')\n    if iso:\n        return Vppen(plots, 'size=r vpstyle=n gridnum=%d,1' % n)\n    else:\n"]]}
{"hexsha": "77ddde3673bb0c6e02fa532ee8ea3566c180a568", "ext": "py", "lang": "Python", "content": "def perm():\n    for i in range(start, end):\n        cube = str(i**3)\n        perms = permutations(cube)\n        perms = list(set(perms))\n        #perms = map(perm_to_float, perms)\n        #perms = list(filter(is_cube, perms))\n        perms = list(filter(is_cube_perm, perms))\n        print(i)\n        if len(perms) >= 3:\n            print(i, len(perms))", "fn_id": 3, "class_fn": false, "repo": "anokata/pythonPetProjects", "file": "exercises/euler62.py", "last_update_at": "2018-02-03T06:02:11+00:00", "question_id": "77ddde3673bb0c6e02fa532ee8ea3566c180a568_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def perm():\n    for i in range(start, end):\n        cube = str(i ** 3)\n        perms = permutations(cube)\n        perms = list(set(perms))\n        perms = list(filter(is_cube_perm, perms))\n        print(i)\n        if len(perms) >= 3:\n"]]}
{"hexsha": "e25842941d48d41714f3658be3a09747ddafaa6a", "ext": "py", "lang": "Python", "content": "def parse_setting_args():\n    ''' \u89e3\u6790\u4f20\u5165\u5230 POST \u7684 body \u53c2\u6570'''\n    parser = reqparse.RequestParser()\n    parser.add_argument('name', type=str, required=True, location='json')\n    parser.add_argument('value', default='', location='json')\n    args = parser.parse_args()\n    return args", "fn_id": 2, "class_fn": false, "repo": "xiaojieluo/undefined", "file": "calla/api/setting.py", "last_update_at": "2018-02-25T03:13:11+00:00", "question_id": "e25842941d48d41714f3658be3a09747ddafaa6a_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def parse_setting_args():\n    \"\"\" \u89e3\u6790\u4f20\u5165\u5230 POST \u7684 body \u53c2\u6570\"\"\"\n    parser = reqparse.RequestParser()\n    parser.add_argument('name', type=str, required=True, location='json')\n    parser.add_argument('value', default='', location='json')\n    args = parser.parse_args()\n"]]}
{"hexsha": "b60542abca54e8108b59116374b00bad6cc0b57c", "ext": "py", "lang": "Python", "content": "def write_common_mapping(gids, mapping, output):\n\n    cell_count = len(gids)\n    counts_per_cell = mapping.num_compartments\n\n    out_mapping = output.create_group(\"mapping\")\n\n    out_mapping.create_dataset(\"gids\", data=gids, dtype=\"u4\")\n\n    # Number of values per cell\n    num_values = numpy.zeros((cell_count), dtype=\"u4\")\n    for i in range(cell_count):\n        num_values[i] = counts_per_cell(i)\n    out_mapping.create_dataset(\"num_values\", data=num_values, dtype=\"u4\")\n\n    # Per cell mapping data\n    index = mapping.index\n    mapping_data = index.view(dtype=\"u4\").reshape((index.shape[0], 2))[:, 1]\n    out_mapping.create_dataset(\"data\", data=mapping_data, dtype=\"u4\")\n\n    return out_mapping", "fn_id": 1, "class_fn": false, "repo": "BlueBrain/sonata", "file": "reporting/reporting/writers.py", "last_update_at": "2018-04-28T12:48:55+00:00", "question_id": "b60542abca54e8108b59116374b00bad6cc0b57c_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def write_common_mapping(gids, mapping, output):\n    cell_count = len(gids)\n    counts_per_cell = mapping.num_compartments\n    out_mapping = output.create_group('mapping')\n    out_mapping.create_dataset('gids', data=gids, dtype='u4')\n    num_values = numpy.zeros(cell_count, dtype='u4')\n    for i in range(cell_count):\n        num_values[i] = counts_per_cell(i)\n    out_mapping.create_dataset('num_values', data=num_values, dtype='u4')\n    index = mapping.index\n    mapping_data = index.view(dtype='u4').reshape((index.shape[0], 2))[:, 1]\n    out_mapping.create_dataset('data', data=mapping_data, dtype='u4')\n"]]}
{"hexsha": "a4f974d6fd908df5e0278126e6ccef0c91fd9c8a", "ext": "py", "lang": "Python", "content": "def getDataSets():\n    dirList = os.listdir(dataDir)\n    #print(dirList)\n    dataSets = {}\n    #goes through all pickled objects in the bin folder\n    for i in dirList:\n        num,trash = i.split(\".\")\n        trash,num = num.split(\"test\")\n        dataSets[num] = createFeatureDict(dio.getDataBin(dataDir + \"\\\\\" + i,cwd = False))\n    return dataSets ", "fn_id": 2, "class_fn": false, "repo": "rjweld21/prostheticClinic", "file": "Pervious Work/testScript2.py", "last_update_at": "2018-12-13T22:19:55+00:00", "question_id": "a4f974d6fd908df5e0278126e6ccef0c91fd9c8a_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def getDataSets():\n    dirList = os.listdir(dataDir)\n    dataSets = {}\n    for i in dirList:\n        num, trash = i.split('.')\n        trash, num = num.split('test')\n        dataSets[num] = createFeatureDict(dio.getDataBin(dataDir + '\\\\' + i, cwd=False))\n"]]}
{"hexsha": "0f52dba356db45cc2f7bfa252ba3ac7775d838c8", "ext": "py", "lang": "Python", "content": "@my_decorator3\ndef greet4(message):\n    \"\"\"\n    greet4\n    :param message:\n    :return:\n    \"\"\"\n    print(message)", "fn_id": 10, "class_fn": false, "repo": "ftconan/python3", "file": "python_core/decorator_demo.py", "last_update_at": "2018-12-19T22:07:56+00:00", "question_id": "0f52dba356db45cc2f7bfa252ba3ac7775d838c8_10", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@my_decorator3\ndef greet4(message):\n    \"\"\"\n    greet4\n    :param message:\n    :return:\n    \"\"\"\n"]]}
{"hexsha": "8a3632eafece6174d58590f4f03eef72b734a964", "ext": "py", "lang": "Python", "content": "def test_get_vals(clargs):\n\n    infer_vars, config = forward_pass(clargs)\n\n    programs = []\n    a1s,a2s,b1s,b2s,prob_Ys  = [],[],[],[],[]\n    for prog_id in sorted(list(infer_vars.keys())):\n       a1s += [infer_vars[prog_id]['a1']]\n       a2s += [infer_vars[prog_id]['a2']]\n       b1s += [list(infer_vars[prog_id]['b1'])]\n       b2s += [list(infer_vars[prog_id]['b2'])]\n       prob_Ys += [infer_vars[prog_id]['ProbY']]\n\n\n    return a1s, b1s, a2s, b2s, prob_Ys", "fn_id": 1, "class_fn": false, "repo": "rohan2606/bayou", "file": "src/main/python/bayou/models/low_level_evidences/test.py", "last_update_at": "2018-02-19T21:48:06+00:00", "question_id": "8a3632eafece6174d58590f4f03eef72b734a964_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_get_vals(clargs):\n    infer_vars, config = forward_pass(clargs)\n    programs = []\n    a1s, a2s, b1s, b2s, prob_Ys = ([], [], [], [], [])\n    for prog_id in sorted(list(infer_vars.keys())):\n        a1s += [infer_vars[prog_id]['a1']]\n        a2s += [infer_vars[prog_id]['a2']]\n        b1s += [list(infer_vars[prog_id]['b1'])]\n        b2s += [list(infer_vars[prog_id]['b2'])]\n        prob_Ys += [infer_vars[prog_id]['ProbY']]\n"]]}
{"hexsha": "7176d48aa3e455abf69479e0f3bb1398c4b23650", "ext": "py", "lang": "Python", "content": "def p_more_sub_struct(p):\n  '''more_sub_struct : more_sub_struct sub_struct_operator sub_struct_body\n                     | empty'''\n  pass", "fn_id": 77, "class_fn": false, "repo": "JorgeRubio96/grease-lang", "file": "grease/parser.py", "last_update_at": "2018-10-09T22:57:34+00:00", "question_id": "7176d48aa3e455abf69479e0f3bb1398c4b23650_77", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def p_more_sub_struct(p):\n    \"\"\"more_sub_struct : more_sub_struct sub_struct_operator sub_struct_body\n                     | empty\"\"\"\n"]]}
{"hexsha": "90350a12c6bbab1041e72554c0000f43e3f679b0", "ext": "py", "lang": "Python", "content": "def calc_sum(A, x):\n    ret = 0\n    for i, a in enumerate(A):\n        ret += abs(x - i) * a\n    return ret", "fn_id": 1, "class_fn": false, "repo": "knuu/competitive-programming", "file": "atcoder/corp/nikkei2019_final_c.py", "last_update_at": "2018-11-12T15:18:55+00:00", "question_id": "90350a12c6bbab1041e72554c0000f43e3f679b0_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def calc_sum(A, x):\n    ret = 0\n    for i, a in enumerate(A):\n        ret += abs(x - i) * a\n"]]}
{"hexsha": "4314aac00eaeeabab48a847e52fe1c44fe584df9", "ext": "py", "lang": "Python", "content": "def do_something(logf):\n    ### This does the \"work\" of the daemon\n\n    logger = logging.getLogger('eg_daemon')\n    logger.setLevel(logging.INFO)\n\n    fh = logging.FileHandler(logf)\n    fh.setLevel(logging.INFO)\n\n    formatstr = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n    formatter = logging.Formatter(formatstr)\n\n    fh.setFormatter(formatter)\n\n    logger.addHandler(fh)\n\n    while True:\n        logger.debug(\"this is a DEBUG message\")\n        logger.info(\"this is an INFO message\")\n        logger.error(\"this is an ERROR message\")\n        time.sleep(5)\n\n        sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n        print('starting up on {}'.format(server_address))\n        sock.bind(server_address)\n\n        # Listen for incoming connections\n        sock.listen(1)\n\n        while True:\n            # Wait for a connection\n            print('waiting for a connection')\n            connection, client_address = sock.accept()\n            try:\n                print('connection from', client_address)\n\n                # Receive the data in small chunks and retransmit it\n                while True:\n                    data = connection.recv(16)\n                    print('received {!r}'.format(data))\n                    if data:\n                        print('sending data back to the client')\n                        connection.sendall(data)\n                    else:\n                        print('no data from', client_address)\n                        break\n\n            finally:\n                # Clean up the connection\n                connection.close()", "fn_id": 0, "class_fn": false, "repo": "hulkabob/opid", "file": "example_daemon.py", "last_update_at": "2018-07-15T21:49:45+00:00", "question_id": "4314aac00eaeeabab48a847e52fe1c44fe584df9_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def do_something(logf):\n    logger = logging.getLogger('eg_daemon')\n    logger.setLevel(logging.INFO)\n    fh = logging.FileHandler(logf)\n    fh.setLevel(logging.INFO)\n    formatstr = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n    formatter = logging.Formatter(formatstr)\n    fh.setFormatter(formatter)\n    logger.addHandler(fh)\n    while True:\n        logger.debug('this is a DEBUG message')\n        logger.info('this is an INFO message')\n        logger.error('this is an ERROR message')\n        time.sleep(5)\n        sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n        print('starting up on {}'.format(server_address))\n        sock.bind(server_address)\n        sock.listen(1)\n        while True:\n            print('waiting for a connection')\n            connection, client_address = sock.accept()\n            try:\n                print('connection from', client_address)\n                while True:\n                    data = connection.recv(16)\n                    print('received {!r}'.format(data))\n                    if data:\n                        print('sending data back to the client')\n                        connection.sendall(data)\n                    else:\n                        print('no data from', client_address)\n                        break\n            finally:\n"]]}
{"hexsha": "ce4c9032abe8b95d9d76a67f5262faff20fc1f26", "ext": "py", "lang": "Python", "content": "def clone_or_reset(pkgname, freeworldname, *, rffree):\n    SCM.mkdir(exist_ok=True)\n    repo = SCM / freeworldname\n    if not repo.exists():\n        with cd(SCM):\n            rfpkg_clone(freeworldname, free=rffree)\n    with cd(repo):\n        setup_remotes(pkgname, freeworldname)\n        git('fetch', '--all')\n        git('checkout', 'master')\n        git('reset', '--hard', 'origin/master')\n        git('clean', '-f')", "fn_id": 1, "class_fn": false, "repo": "hroncok/freeworld-syncer", "file": "syncer/git.py", "last_update_at": "2018-09-27T19:35:01+00:00", "question_id": "ce4c9032abe8b95d9d76a67f5262faff20fc1f26_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def clone_or_reset(pkgname, freeworldname, *, rffree):\n    SCM.mkdir(exist_ok=True)\n    repo = SCM / freeworldname\n    if not repo.exists():\n        with cd(SCM):\n            rfpkg_clone(freeworldname, free=rffree)\n    with cd(repo):\n        setup_remotes(pkgname, freeworldname)\n        git('fetch', '--all')\n        git('checkout', 'master')\n        git('reset', '--hard', 'origin/master')\n"]]}
{"hexsha": "310eadaec8c5992bd946709947ef3fb84083991f", "ext": "py", "lang": "Python", "content": "def choose_img(picture_path,name_mask):\n  picture_file_name = name_mask[:-8]+\".jpg\"\n  full_path = os.path.join(picture_path,picture_file_name)\n  return(full_path)", "fn_id": 2, "class_fn": false, "repo": "victorherbemontagne/models", "file": "research/object_detection/conversion_script_to_tf.py", "last_update_at": "2018-10-30T08:47:51+00:00", "question_id": "310eadaec8c5992bd946709947ef3fb84083991f_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def choose_img(picture_path, name_mask):\n    picture_file_name = name_mask[:-8] + '.jpg'\n    full_path = os.path.join(picture_path, picture_file_name)\n"]]}
{"hexsha": "69d259d599fbb8035a16997abad356c12bd44c46", "ext": "py", "lang": "Python", "content": "@mod_technologies.route('/', methods=['GET'])\n@login_required\ndef get_technologies():\n    \"\"\"Get a list of all the technologies in the system\"\"\"\n\n    technology_schema = TechnologySchema()\n\n    return jsonify( [technology_schema.dump(v) for v in Technology.query.all()] )", "fn_id": 0, "class_fn": false, "repo": "bodastage/bts-ce-api", "file": "btsapi/modules/technologies/controllers.py", "last_update_at": "2018-06-27T22:08:08+00:00", "question_id": "69d259d599fbb8035a16997abad356c12bd44c46_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@mod_technologies.route('/', methods=['GET'])\n@login_required\ndef get_technologies():\n    \"\"\"Get a list of all the technologies in the system\"\"\"\n    technology_schema = TechnologySchema()\n"]]}
{"hexsha": "e4cae06a012c9d8b1998883efa4e87912ce8ece2", "ext": "py", "lang": "Python", "content": "def keywordp(scope, x):\n    if x.evaluate(scope).__class__ == Keyword:\n        return t\n    return nil", "fn_id": 27, "class_fn": false, "repo": "programble/lispy", "file": "core.py", "last_update_at": "2018-01-24T19:47:20+00:00", "question_id": "e4cae06a012c9d8b1998883efa4e87912ce8ece2_27", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def keywordp(scope, x):\n    if x.evaluate(scope).__class__ == Keyword:\n        return t\n"]]}
{"hexsha": "bdc58343ec72b669720d01178a52386e3869bda8", "ext": "py", "lang": "Python", "content": "def extract_evidence(clargs):\n    # clargsinputFile = 'DATA-Licensed_test.json'\n\n    sentences = extract_jD(clargs.input_file[0])\n\n    # sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n    # \t\t\t['this', 'is', 'the', 'second', 'sentence'],\n    # \t\t\t['yet', 'another', 'sentence'],\n    # \t\t\t['one', 'more', 'sentence'],\n    # \t\t\t['and', 'the', 'final', 'sentence']]\n\n    # train model\n    model = Word2Vec(sentences, min_count=5, size=256)\n    # fit a 2d PCA model to the vectors\n    X = model[model.wv.vocab]\n    pca = PCA(n_components=2)\n    result = pca.fit_transform(X)\n    # create a scatter plot of the projection\n    pyplot.scatter(result[:, 0], result[:, 1])\n    words = list(model.wv.vocab)\n    for i, word in enumerate(words):\n    \tpyplot.annotate(word, xy=(result[i, 0], result[i, 1]))\n    # pyplot.show()\n    pyplot.savefig(os.path.join(os.getcwd(), log + \"jDocEmb.jpeg\"), bbox_inches='tight')\n\n    model.save(log + 'model.bin')", "fn_id": 0, "class_fn": false, "repo": "rohan2606/bayou", "file": "src/main/python/bayou/experiments/javaDocExtract/runEmbedding.py", "last_update_at": "2018-02-19T21:48:06+00:00", "question_id": "bdc58343ec72b669720d01178a52386e3869bda8_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def extract_evidence(clargs):\n    sentences = extract_jD(clargs.input_file[0])\n    model = Word2Vec(sentences, min_count=5, size=256)\n    X = model[model.wv.vocab]\n    pca = PCA(n_components=2)\n    result = pca.fit_transform(X)\n    pyplot.scatter(result[:, 0], result[:, 1])\n    words = list(model.wv.vocab)\n    for i, word in enumerate(words):\n        pyplot.annotate(word, xy=(result[i, 0], result[i, 1]))\n    pyplot.savefig(os.path.join(os.getcwd(), log + 'jDocEmb.jpeg'), bbox_inches='tight')\n"]]}
{"hexsha": "234b198cddf1b31d8b371a6149352f5430c0e929", "ext": "py", "lang": "Python", "content": "def complete_linkage_dist(nodes, cluster_a, cluster_b, distance_function=euclidean_dist):\n    dist = -np.inf\n\n    for a in cluster_a:\n        for b in cluster_b:\n            dist = max(dist, distance_function(nodes[a], nodes[b]))\n\n    return dist", "fn_id": 2, "class_fn": false, "repo": "candrahesen/clustering-algorithm", "file": "commons/linkage.py", "last_update_at": "2018-12-06T18:53:56+00:00", "question_id": "234b198cddf1b31d8b371a6149352f5430c0e929_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def complete_linkage_dist(nodes, cluster_a, cluster_b, distance_function=euclidean_dist):\n    dist = -np.inf\n    for a in cluster_a:\n        for b in cluster_b:\n            dist = max(dist, distance_function(nodes[a], nodes[b]))\n"]]}
{"hexsha": "0b03a1493e6c7828ba6a88636633e53bdfc3dcc0", "ext": "py", "lang": "Python", "content": "def __readRawcStream(f):\n    vertexes = []\n    faces = []\n    for line in f.readlines():\n        lnarr = line.strip().split(' ')\n        lenlarr = len(lnarr)\n        if lenlarr == 2:\n            # number of vertexes and number of faces\n            pass\n        elif lenlarr == 6:\n            vertex = [\n                float(lnarr[0]),\n                float(lnarr[1]),\n                float(lnarr[2])\n            ]\n            vertexes.append(vertex)\n        elif lenlarr == 3:\n            face = [\n                int(lnarr[0]),\n                int(lnarr[2]),\n                int(lnarr[1])\n            ]\n            faces.append(face)\n\n    return vertexes, faces", "fn_id": 4, "class_fn": false, "repo": "gilyclem/larVolumeToObj", "file": "larVolumeToObjG/computation/fileio.py", "last_update_at": "2018-05-14T10:33:20+00:00", "question_id": "0b03a1493e6c7828ba6a88636633e53bdfc3dcc0_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def __readRawcStream(f):\n    vertexes = []\n    faces = []\n    for line in f.readlines():\n        lnarr = line.strip().split(' ')\n        lenlarr = len(lnarr)\n        if lenlarr == 2:\n            pass\n        elif lenlarr == 6:\n            vertex = [float(lnarr[0]), float(lnarr[1]), float(lnarr[2])]\n            vertexes.append(vertex)\n        elif lenlarr == 3:\n            face = [int(lnarr[0]), int(lnarr[2]), int(lnarr[1])]\n            faces.append(face)\n"]]}
{"hexsha": "4557b927561edc09b1bb7c16bba141cc3ad465e3", "ext": "py", "lang": "Python", "content": "def goodData(filename):\n    \"\"\"\n    Analizes the input CSV file accordingly with correct values and counts null and error values.\n    \n    The first iteration shows all titles on header and waits for user answer about which\n    title must be used for a dictionary key and which ones for respective values.\n    \n    Returns a dictionary on the form {key:[values]}.\n    \"\"\"\n    key, values = urChoice(filename)\n\n    dBuild = {}\n    countNull = {'nC':[], 'nH':[], 'nA':[], 'n3':[]}\n    highIssues = {'neg':[], 'pos':[], 'eq':[]}\n    count_Errors = 0\n\n    with open(filename, 'r') as csvfile:\n        ROWS = csv.reader(csvfile, delimiter=',')\n        for r in 0:#ROWS:\n\n            # checking blank data\n            if r[5] == '':\n                countNull['nC'].append(r[0])\n            if r[4] == '':\n                countNull['nH'].append(r[0])\n            if r[10] == '':\n                countNull['nA'].append(r[0])\n            if (r[4] == '') and (r[5] == '') and (r[10] == ''):\n                countNull['n3'].append(r[0])\n\n            try:\n                key = int(r[5])\n\n                if r[4] == '':\n                    # check if 'base' > 'topo' --> raise ValueError if convertion to float doesn't work --> but WHY?\n                    if float(r[2]) > float(r[3]):\n                        highIssues['neg'].append(r[0])\n                    elif float(r[2]) < float(r[3]):\n                        highIssues['pos'].append(r[0])\n                    else:\n                        highIssues['eq'].append(r[0])\n                    height = 0\n\n                else: height = float(r[4])\n\n                if r[10] == '': area = 0\n                else: area = float(r[10])\n\n                dBuild[ key ] = [ height, area ]\n\n            except ValueError:\n                # values that we don't care\n                # if r[5], r[4] or r[10] is the header\n                # if r[5] is empty\n                count_Errors += 1\n                pass\n\n    if True: # fast trick to pass print\n        print(\"# of blank values:\")\n        for k in countNull: print(\"\\t\" + str(k) + \":\", len(countNull[k]))\n        print('# of height \"blank\" values:')\n        for k in highIssues: print(\"\\t\" + str(k) + \":\", len(highIssues[k]))\n        print(\"# of errors:\", count_Errors, \"\\nsize of dataset:\", len(dBuild))\n\n        x = 5\n        for k in dBuild:\n            if x == 5: break\n            x += 1\n            print(k, \":\", dBuild[k])\n\n    return dBuild", "fn_id": 2, "class_fn": false, "repo": "yurigabrich/probest", "file": "stat.py", "last_update_at": "2018-05-18T18:33:44+00:00", "question_id": "4557b927561edc09b1bb7c16bba141cc3ad465e3_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def goodData(filename):\n    \"\"\"\n    Analizes the input CSV file accordingly with correct values and counts null and error values.\n    \n    The first iteration shows all titles on header and waits for user answer about which\n    title must be used for a dictionary key and which ones for respective values.\n    \n    Returns a dictionary on the form {key:[values]}.\n    \"\"\"\n    key, values = urChoice(filename)\n    dBuild = {}\n    countNull = {'nC': [], 'nH': [], 'nA': [], 'n3': []}\n    highIssues = {'neg': [], 'pos': [], 'eq': []}\n    count_Errors = 0\n    with open(filename, 'r') as csvfile:\n        ROWS = csv.reader(csvfile, delimiter=',')\n        for r in 0:\n            if r[5] == '':\n                countNull['nC'].append(r[0])\n            if r[4] == '':\n                countNull['nH'].append(r[0])\n            if r[10] == '':\n                countNull['nA'].append(r[0])\n            if r[4] == '' and r[5] == '' and (r[10] == ''):\n                countNull['n3'].append(r[0])\n            try:\n                key = int(r[5])\n                if r[4] == '':\n                    if float(r[2]) > float(r[3]):\n                        highIssues['neg'].append(r[0])\n                    elif float(r[2]) < float(r[3]):\n                        highIssues['pos'].append(r[0])\n                    else:\n                        highIssues['eq'].append(r[0])\n                    height = 0\n                else:\n                    height = float(r[4])\n                if r[10] == '':\n                    area = 0\n                else:\n                    area = float(r[10])\n                dBuild[key] = [height, area]\n            except ValueError:\n                count_Errors += 1\n                pass\n    if True:\n        print('# of blank values:')\n        for k in countNull:\n            print('\\t' + str(k) + ':', len(countNull[k]))\n        print('# of height \"blank\" values:')\n        for k in highIssues:\n            print('\\t' + str(k) + ':', len(highIssues[k]))\n        print('# of errors:', count_Errors, '\\nsize of dataset:', len(dBuild))\n        x = 5\n        for k in dBuild:\n            if x == 5:\n                break\n            x += 1\n            print(k, ':', dBuild[k])\n"]]}
{"hexsha": "5a0401160161daaf1d5839730d210622bdac0137", "ext": "py", "lang": "Python", "content": "def generate_analysis_target_id(analysis_target, name):\n    # this function generates 'machine-id's for analysis target's that\n    # might not be hosts.\n    #\n    # 'machine_id' is what Insights uses to uniquely identify\n    # the thing-to-be-analysed.  Primarily it determines when two uploads\n    # are for the 'same thing', and so the latest upload should update the\n    # later one Up till now that has only been hosts (machines), and so a\n    # random uuid (uuid4) machine-id was generated for the host as its machine-id,\n    # and written to a file on the host, and reused for all insights\n    # uploads for that host.\n    #\n    # For docker images and containers, it will be difficult to impossible\n    # to save their machine id's anywhere.  Also, while containers change\n    # over time just like hosts, images don't change over time, though they\n    # can be rebuilt.  So for images we want the 'machine-id' for an 'image'\n    # to follow the rebuilt image, not change every time the image is rebuilt.\n    # Typically when an image is rebuilt, the rebuilt image will have the same\n    # name as its predicessor, but a different version (tag).\n    #\n    # So for images and containers, instead of random uuids, we use namespace uuids\n    # (uuid5's).  This generates a new uuid based on a combination of another\n    # uuid, and a name (a character string).  This will always generate the\n    # same uuid for the same given base uuid and name.  This saves us from\n    # having to save the image's uuid anywhere, and lets us control the created uuid\n    # by controlling the name used to generate it.  Keep the name and base uuid) the\n    # same, we get the same uuid.\n    #\n    # For the base uuid we use the uuid of the host we are running on.\n    # For containers this is the obvious choice, for images it is less obviously\n    # what base uuid is correct.  For now we will just go with the host's uuid also.\n    #\n    # For the name, we leave that outside this function, but in general it should\n    # be the name of the container or the name of the image, and if you want to\n    # replace the results on the insights server, you have to use the same name\n\n    if analysis_target == \"host\":\n        return generate_machine_id()\n    elif (analysis_target == \"docker_image\" or\n            analysis_target == \"docker_container\" or\n            analysis_target == \"compressed_file\" or\n            analysis_target == \"mountpoint\"):\n        return generate_container_id(name)\n    else:\n        raise ValueError(\"Unknown analysis target: %s\" % analysis_target)", "fn_id": 4, "class_fn": false, "repo": "sagaraivale/insights-core", "file": "insights/client/utilities.py", "last_update_at": "2018-03-26T12:59:24+00:00", "question_id": "5a0401160161daaf1d5839730d210622bdac0137_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def generate_analysis_target_id(analysis_target, name):\n    if analysis_target == 'host':\n        return generate_machine_id()\n    elif analysis_target == 'docker_image' or analysis_target == 'docker_container' or analysis_target == 'compressed_file' or (analysis_target == 'mountpoint'):\n        return generate_container_id(name)\n    else:\n"]]}
{"hexsha": "fa4628fb553045029e402bf1c9c87b1266a99438", "ext": "py", "lang": "Python", "content": "def submitRequests(client, wallet, op):\n    req = wallet.signOp(op)\n    # TODO: This looks boilerplate\n    wallet.pendRequest(req)\n    reqs = wallet.preparePending()\n    return client.submitReqs(*reqs)[0]", "fn_id": 7, "class_fn": false, "repo": "pysingh09/indy-node", "file": "indy_node/test/validator_info/test_validator_info.py", "last_update_at": "2018-07-05T19:34:29+00:00", "question_id": "fa4628fb553045029e402bf1c9c87b1266a99438_7", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def submitRequests(client, wallet, op):\n    req = wallet.signOp(op)\n    wallet.pendRequest(req)\n    reqs = wallet.preparePending()\n"]]}
{"hexsha": "717e4f6a4a61e96e0f81647e2663fd06afc02356", "ext": "py", "lang": "Python", "content": "def test_tensorget_disconnect(env):\n    con = get_connection(env, 't_FLOAT')\n    ret = con.execute_command('AI.TENSORSET', 't_FLOAT', 'FLOAT', 2, 'VALUES', 2, 3)\n    env.assertEqual(ret, b'OK')\n    ret = send_and_disconnect(('AI.TENSORGET', 't_FLOAT', 'META'), con)\n    env.assertEqual(ret, None)", "fn_id": 7, "class_fn": false, "repo": "RedisDL/RedisDL", "file": "tests/flow/tests_common.py", "last_update_at": "2018-12-02T19:54:59+00:00", "question_id": "717e4f6a4a61e96e0f81647e2663fd06afc02356_7", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_tensorget_disconnect(env):\n    con = get_connection(env, 't_FLOAT')\n    ret = con.execute_command('AI.TENSORSET', 't_FLOAT', 'FLOAT', 2, 'VALUES', 2, 3)\n    env.assertEqual(ret, b'OK')\n    ret = send_and_disconnect(('AI.TENSORGET', 't_FLOAT', 'META'), con)\n"]]}
{"hexsha": "a8fe82ce71a4845dcf222f6cdbdf250abebb61ac", "ext": "py", "lang": "Python", "content": "def size(device):\n    \"\"\" return the size of the device in bytes\n\n        This is fastest most efficient method as os.lseek() calls just\n        set the fd->offset, and os.SEEK_END asks the kernel for the\n        end of the device \"\"\"\n    fd = os.open(device, os.O_RDONLY)\n    try:\n        return os.lseek(fd, 0, os.SEEK_END)\n    finally:\n        os.close(fd)", "fn_id": 1, "class_fn": false, "repo": "PythonGirlSam/lunr", "file": "lunr/storage/helper/utils/directio.py", "last_update_at": "2018-04-05T14:27:35+00:00", "question_id": "a8fe82ce71a4845dcf222f6cdbdf250abebb61ac_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def size(device):\n    \"\"\" return the size of the device in bytes\n\n        This is fastest most efficient method as os.lseek() calls just\n        set the fd->offset, and os.SEEK_END asks the kernel for the\n        end of the device \"\"\"\n    fd = os.open(device, os.O_RDONLY)\n    try:\n        return os.lseek(fd, 0, os.SEEK_END)\n    finally:\n"]]}
{"hexsha": "9cd0547f799989e2a5c180be4c8e2872327b6d35", "ext": "py", "lang": "Python", "content": "@registry.register_hparams\ndef attention_lm_moe_large():\n  \"\"\"Large model for distributed training.\n\n  Over 1B parameters, so requires multi-gpu training due to memory\n   requirements.\n\n  Returns:\n    an hparams object.\n  \"\"\"\n  hparams = attention_lm_moe_base()\n  hparams.num_hidden_layers = 5\n  hparams.moe_layers = \"3\"\n  hparams.hidden_size = 1024\n  hparams.num_heads = 16\n  hparams.filter_size = 4096\n  hparams.moe_hidden_size = 4096\n  hparams.moe_n1 = 128\n  hparams.residual_dropout = 0.2\n  return hparams", "fn_id": 3, "class_fn": false, "repo": "anishsingh20/tensor2tensor", "file": "tensor2tensor/models/attention_lm_moe.py", "last_update_at": "2018-08-14T06:36:57+00:00", "question_id": "9cd0547f799989e2a5c180be4c8e2872327b6d35_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@registry.register_hparams\ndef attention_lm_moe_large():\n    \"\"\"Large model for distributed training.\n\n  Over 1B parameters, so requires multi-gpu training due to memory\n   requirements.\n\n  Returns:\n    an hparams object.\n  \"\"\"\n    hparams = attention_lm_moe_base()\n    hparams.num_hidden_layers = 5\n    hparams.moe_layers = '3'\n    hparams.hidden_size = 1024\n    hparams.num_heads = 16\n    hparams.filter_size = 4096\n    hparams.moe_hidden_size = 4096\n    hparams.moe_n1 = 128\n    hparams.residual_dropout = 0.2\n"]]}
{"hexsha": "c351ca5a80af848418394800af518555cda4dd74", "ext": "py", "lang": "Python", "content": "def post_case_event(case_id, category, description):\n    logger.debug('Posting case event', case_id=case_id, category=category)\n\n    url = f'{Config.CASE_SERVICE}/cases/{case_id}/events'\n    payload = {\n        'description': description,\n        'category': category,\n        'createdBy': 'TESTS'\n    }\n    response = requests.post(url, json=payload, auth=Config.BASIC_AUTH)\n    if response.status_code != 201:\n        logger.error('Failed to post case event', status=response.status_code)\n\n    logger.debug('Successfully posted case event',\n                 case_id=case_id, category=category)\n    return response.json()", "fn_id": 1, "class_fn": false, "repo": "ONSdigital/rasrm-acceptance-tests", "file": "controllers/case_controller.py", "last_update_at": "2018-05-04T15:28:55+00:00", "question_id": "c351ca5a80af848418394800af518555cda4dd74_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def post_case_event(case_id, category, description):\n    logger.debug('Posting case event', case_id=case_id, category=category)\n    url = f'{Config.CASE_SERVICE}/cases/{case_id}/events'\n    payload = {'description': description, 'category': category, 'createdBy': 'TESTS'}\n    response = requests.post(url, json=payload, auth=Config.BASIC_AUTH)\n    if response.status_code != 201:\n        logger.error('Failed to post case event', status=response.status_code)\n    logger.debug('Successfully posted case event', case_id=case_id, category=category)\n"]]}
{"hexsha": "453b0cfe1fea3102dce6c2fd9c13911e161ca3ce", "ext": "py", "lang": "Python", "content": "@gradient(4.0, 5.0, backend=backend_all)\ndef test_simple_closure(a, b):\n    \"\"\"Test some trivial closures.\"\"\"\n\n    def f():\n        return a + 1.0\n\n    def g():\n        return b + 2.0\n\n    return f() * g()", "fn_id": 13, "class_fn": false, "repo": "strint/myia", "file": "tests/test_grad.py", "last_update_at": "2018-03-16T04:56:31+00:00", "question_id": "453b0cfe1fea3102dce6c2fd9c13911e161ca3ce_13", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@gradient(4.0, 5.0, backend=backend_all)\ndef test_simple_closure(a, b):\n    \"\"\"Test some trivial closures.\"\"\"\n\n    def f():\n        return a + 1.0\n\n    def g():\n        return b + 2.0\n"]]}
{"hexsha": "e5973cef9d44cbbe65c8ccb8276e1dbd664147e1", "ext": "py", "lang": "Python", "content": "def norm_layer(data, out_dtype):\n    \"\"\"\n        Compute data rescaled using the bounds of the output type.\n\n        Args:\n            data(array):        Dask Array of image data\n            out_dtype(type):    type of the data to output\n\n        Returns:\n            Dask Array:         Adjusted harmonic mean projection\n    \"\"\"\n\n    out = data.astype(float)\n    out_dtype = numpy.dtype(out_dtype)\n\n    data_min = data.min()\n    data_max = data.max()\n\n    out_nan = float(\"nan\")\n    out_min = float(0)\n    out_max = float(1)\n    if issubclass(out_dtype.type, numbers.Integral):\n        out_dtype_info = numpy.iinfo(out_dtype.type)\n\n        out_nan = float(0)\n        out_min = float(out_dtype_info.min)\n        out_max = float(out_dtype_info.max)\n\n    scale = (out_max - out_min) / (data_max - data_min)\n\n    out -= data_min\n    out *= scale\n    out += out_min\n\n    out = dask.array.clip(out, out_min, out_max)\n\n    out_isnan = dask.array.isnan(out)\n    out_isinf = dask.array.isinf(out)\n    out_sign = dask.array.sign(out)\n\n    out[out_isinf & (out_sign == -1)] = out_min\n    out[out_isinf & (out_sign == 1)] = out_max\n\n    out[out_isnan] = out_nan\n\n    out = out.astype(out_dtype)\n\n    return out", "fn_id": 5, "class_fn": false, "repo": "DudLab/nanshe_workflow", "file": "nanshe_workflow/proj.py", "last_update_at": "2018-10-18T18:08:36+00:00", "question_id": "e5973cef9d44cbbe65c8ccb8276e1dbd664147e1_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def norm_layer(data, out_dtype):\n    \"\"\"\n        Compute data rescaled using the bounds of the output type.\n\n        Args:\n            data(array):        Dask Array of image data\n            out_dtype(type):    type of the data to output\n\n        Returns:\n            Dask Array:         Adjusted harmonic mean projection\n    \"\"\"\n    out = data.astype(float)\n    out_dtype = numpy.dtype(out_dtype)\n    data_min = data.min()\n    data_max = data.max()\n    out_nan = float('nan')\n    out_min = float(0)\n    out_max = float(1)\n    if issubclass(out_dtype.type, numbers.Integral):\n        out_dtype_info = numpy.iinfo(out_dtype.type)\n        out_nan = float(0)\n        out_min = float(out_dtype_info.min)\n        out_max = float(out_dtype_info.max)\n    scale = (out_max - out_min) / (data_max - data_min)\n    out -= data_min\n    out *= scale\n    out += out_min\n    out = dask.array.clip(out, out_min, out_max)\n    out_isnan = dask.array.isnan(out)\n    out_isinf = dask.array.isinf(out)\n    out_sign = dask.array.sign(out)\n    out[out_isinf & (out_sign == -1)] = out_min\n    out[out_isinf & (out_sign == 1)] = out_max\n    out[out_isnan] = out_nan\n    out = out.astype(out_dtype)\n"]]}
{"hexsha": "49bdc86bb744fcdbd9a57a823d2581cb7ce538ca", "ext": "py", "lang": "Python", "content": "def is_interactive():\n    \"\"\"\n    Check if is in an interactive shell (python or ipython).\n\n    Returns\n    -------\n    bool\n\n    \"\"\"\n    ipython = False\n    try:\n        cls_name = get_ipython().__class__.__name__\n\n        if cls_name in ('InteractiveShellEmbed', 'TerminalInteractiveShell'):\n            ipython = True\n    except NameError:\n        pass\n\n    import __main__ as main\n\n    return not hasattr(main, '__file__') or ipython", "fn_id": 3, "class_fn": false, "repo": "cuihantao/Andes", "file": "andes/utils/misc.py", "last_update_at": "2018-08-18T08:52:27+00:00", "question_id": "49bdc86bb744fcdbd9a57a823d2581cb7ce538ca_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def is_interactive():\n    \"\"\"\n    Check if is in an interactive shell (python or ipython).\n\n    Returns\n    -------\n    bool\n\n    \"\"\"\n    ipython = False\n    try:\n        cls_name = get_ipython().__class__.__name__\n        if cls_name in ('InteractiveShellEmbed', 'TerminalInteractiveShell'):\n            ipython = True\n    except NameError:\n        pass\n    import __main__ as main\n"]]}
{"hexsha": "053ae384f11b6fdb22643bfae8e5b0e0d8d4af29", "ext": "py", "lang": "Python", "content": "def loadtxt(filename):\n    file = np.loadtxt(filename, delimiter='\\t')\n    nm = file[1:, 0]\n    time = file[0, 1:]\n    data = file[1:, 1:]\n    \n    return nm, time, data", "fn_id": 0, "class_fn": false, "repo": "liud16/capstone18", "file": "code_dev/Peak-Evaluation/plot_kinetic.py", "last_update_at": "2018-06-28T20:57:47+00:00", "question_id": "053ae384f11b6fdb22643bfae8e5b0e0d8d4af29_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def loadtxt(filename):\n    file = np.loadtxt(filename, delimiter='\\t')\n    nm = file[1:, 0]\n    time = file[0, 1:]\n    data = file[1:, 1:]\n"]]}
{"hexsha": "18a9c07a4f52c6aca1030058e12b8543cff475cc", "ext": "py", "lang": "Python", "content": "@task\n@suggest_localhost\ndef powerline_shell():\n    '''Install or update and set up powerline-shell prompt.\n\n    powerline-shell (https://github.com/b-ryan/powerline-shell) is a beautiful\n    and useful prompt for your shell.\n\n    More infos:\n     * https://github.com/b-ryan/powerline-shell\n     * https://askubuntu.com/questions/283908/how-can-i-install-and-use-powerline-plugin\n\n    Touched files, dirs, and installed packages:\n\n        ~/.config/powerline-shell/config.json\n        pip install powerline-shell\n    '''\n    assert env.host == 'localhost', 'This task cannot run on a remote host'\n    setup_fonts_for_powerline_shell()\n    install_pip_package()\n    install_config()\n    install_bash_enabler()", "fn_id": 2, "class_fn": false, "repo": "theno/fabsetup-theno-powerline-shell", "file": "fabsetup_theno_powerline_shell/__init__.py", "last_update_at": "2018-10-02T04:53:21+00:00", "question_id": "18a9c07a4f52c6aca1030058e12b8543cff475cc_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@task\n@suggest_localhost\ndef powerline_shell():\n    \"\"\"Install or update and set up powerline-shell prompt.\n\n    powerline-shell (https://github.com/b-ryan/powerline-shell) is a beautiful\n    and useful prompt for your shell.\n\n    More infos:\n     * https://github.com/b-ryan/powerline-shell\n     * https://askubuntu.com/questions/283908/how-can-i-install-and-use-powerline-plugin\n\n    Touched files, dirs, and installed packages:\n\n        ~/.config/powerline-shell/config.json\n        pip install powerline-shell\n    \"\"\"\n    assert env.host == 'localhost', 'This task cannot run on a remote host'\n    setup_fonts_for_powerline_shell()\n    install_pip_package()\n    install_config()\n"]]}
{"hexsha": "c84b5d3f6cf6b459dd29dc38116560721d195f3a", "ext": "py", "lang": "Python", "content": "def ShuffleOMES(sequences, times=10000, cutoff=0.2, core=0, output=1, cluster=0, save=False):\n    '''It is a function to calculate the p value for shuffled OMES.\n    Given the sequences in a list with no format.\n    times is the shuffle times.\n    cutoff is the lower cutoff. (Haven't finished yet. Calc all now.)\n    core is the process number to run.\n    output is a mark for output.'''\n    import os\n    from os import path\n    from mbio.Application import job_organization as jo\n    scriptfile = path.join(_path__, '..', 'Scripts', 'omes_mpi.c')\n    jobnumber = jo.AskJobNumber()\n    f = open(path.join(_path__, '..', '.Cache', jobnumber + '.fasta'), 'w')\n    f.write('\\n'.join(sequences))\n    f.close()\n    jo.MkdirResult()\n    f = open(scriptfile, 'r')\n    script = f.read()\n    f.close()\n    output = '1' if output else '0'\n    jo.Writejob(jobnumber, script.replace\n               ('#define seqnum', '#define seqnum ' + str(len(sequences)))\n                .replace\n               ('#define lennum', '#define lennum ' +\n                str(len(sequences[0]) + 1))\n                .replace\n               ('file.fasta', path.join(\n                _path__, '..', '.Cache', jobnumber + '.fasta'))\n                .replace\n               ('#define OUTPUT', '#define OUTPUT ' + str(output))\n                .replace\n               ('#define times', '#define times ' + str(times))\n                .replace\n               ('#define cutoff', '#define cutoff ' + str(1 - cutoff))\n                .replace\n               (\"OMESsave.save\", path.join(\n                _path__, '..', '.Result', jobnumber + '-omes.save'))\n                .replace\n               (\"Psave.save\", path.join(_path__, '..', '.Result', jobnumber + '-p.save')))\n    jo.SubShufflejob(jobnumber, cluster, core)\n    if path.exists(path.join(_path__, '..', '.Result', jobnumber + '-omes.save')):\n        from mbio.IO import matrix\n        m = matrix.ReadMatrix(path.join(\n            _path__, '..', '.Result', jobnumber + '-omes.save'), 'd', len(sequences[0]))\n        if save:\n            import shutil\n            shutil.copy(path.join(\n                _path__, '..', '.Result', jobnumber + '-omes.save'),  './')\n            os.rename(path.join('.', jobnumber + '-omes.save'), './omes.save')\n    else:\n        return None\n    if path.exists(path.join(_path__, '..', '.Result', jobnumber + '-p.save')):\n        from mbio.IO import matrix\n        p = matrix.ReadMatrix(path.join(\n            _path__, '..', '.Result', jobnumber + '-p.save'), 'i', len(sequences[0]))\n        if save:\n            import shutil\n            shutil.copy(path.join(\n                _path__, '..', '.Result', jobnumber + '-p.save'),  './')\n            os.rename(path.join('.', jobnumber + '-p.save'), './p.save')\n    else:\n        return None\n    jo.Clearjob(jobnumber)\n    return p", "fn_id": 1, "class_fn": false, "repo": "wzmao/mbio", "file": ".old/shuffle.py", "last_update_at": "2018-05-25T14:01:17+00:00", "question_id": "c84b5d3f6cf6b459dd29dc38116560721d195f3a_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def ShuffleOMES(sequences, times=10000, cutoff=0.2, core=0, output=1, cluster=0, save=False):\n    \"\"\"It is a function to calculate the p value for shuffled OMES.\n    Given the sequences in a list with no format.\n    times is the shuffle times.\n    cutoff is the lower cutoff. (Haven't finished yet. Calc all now.)\n    core is the process number to run.\n    output is a mark for output.\"\"\"\n    import os\n    from os import path\n    from mbio.Application import job_organization as jo\n    scriptfile = path.join(_path__, '..', 'Scripts', 'omes_mpi.c')\n    jobnumber = jo.AskJobNumber()\n    f = open(path.join(_path__, '..', '.Cache', jobnumber + '.fasta'), 'w')\n    f.write('\\n'.join(sequences))\n    f.close()\n    jo.MkdirResult()\n    f = open(scriptfile, 'r')\n    script = f.read()\n    f.close()\n    output = '1' if output else '0'\n    jo.Writejob(jobnumber, script.replace('#define seqnum', '#define seqnum ' + str(len(sequences))).replace('#define lennum', '#define lennum ' + str(len(sequences[0]) + 1)).replace('file.fasta', path.join(_path__, '..', '.Cache', jobnumber + '.fasta')).replace('#define OUTPUT', '#define OUTPUT ' + str(output)).replace('#define times', '#define times ' + str(times)).replace('#define cutoff', '#define cutoff ' + str(1 - cutoff)).replace('OMESsave.save', path.join(_path__, '..', '.Result', jobnumber + '-omes.save')).replace('Psave.save', path.join(_path__, '..', '.Result', jobnumber + '-p.save')))\n    jo.SubShufflejob(jobnumber, cluster, core)\n    if path.exists(path.join(_path__, '..', '.Result', jobnumber + '-omes.save')):\n        from mbio.IO import matrix\n        m = matrix.ReadMatrix(path.join(_path__, '..', '.Result', jobnumber + '-omes.save'), 'd', len(sequences[0]))\n        if save:\n            import shutil\n            shutil.copy(path.join(_path__, '..', '.Result', jobnumber + '-omes.save'), './')\n            os.rename(path.join('.', jobnumber + '-omes.save'), './omes.save')\n    else:\n        return None\n    if path.exists(path.join(_path__, '..', '.Result', jobnumber + '-p.save')):\n        from mbio.IO import matrix\n        p = matrix.ReadMatrix(path.join(_path__, '..', '.Result', jobnumber + '-p.save'), 'i', len(sequences[0]))\n        if save:\n            import shutil\n            shutil.copy(path.join(_path__, '..', '.Result', jobnumber + '-p.save'), './')\n            os.rename(path.join('.', jobnumber + '-p.save'), './p.save')\n    else:\n        return None\n    jo.Clearjob(jobnumber)\n"]]}
{"hexsha": "e6f51f4eea05df238f553a0d9a0d19499c5001c1", "ext": "py", "lang": "Python", "content": "def test_service_connect__no_name_given():\n    runtime = BaseCumulusCI(\n        config={\n            \"services\": {\"test-type\": {\"attributes\": {\"attr\": {\"required\": False}}}}\n        }\n    )\n\n    result = run_cli_command(\"service\", \"connect\", \"test-type\", runtime=runtime)\n\n    # service_name is None, so the alias when setting the service should be 'default'\n    assert (\n        \"No service name specified. Using 'default' as the service name.\"\n        in result.output\n    )\n    assert \"default\" in runtime.keychain.list_services()[\"test-type\"]", "fn_id": 10, "class_fn": false, "repo": "SalesforceFoundation/CumulusCI", "file": "cumulusci/cli/tests/test_service.py", "last_update_at": "2018-08-31T12:12:39+00:00", "question_id": "e6f51f4eea05df238f553a0d9a0d19499c5001c1_10", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_service_connect__no_name_given():\n    runtime = BaseCumulusCI(config={'services': {'test-type': {'attributes': {'attr': {'required': False}}}}})\n    result = run_cli_command('service', 'connect', 'test-type', runtime=runtime)\n    assert \"No service name specified. Using 'default' as the service name.\" in result.output\n"]]}
{"hexsha": "dacc161b4f5ccec815fbafc9482e0ca6b5ec3fa4", "ext": "py", "lang": "Python", "content": "@pytest.mark.parametrize(\n    \"base_tpi,base_params,reform_tpi, reform_params,ineq_measure,\"\n    + \"pctiles,plot_type\",\n    [\n        (base_tpi, base_params, None, None, \"gini\", None, \"levels\"),\n        (\n            base_tpi,\n            base_params,\n            reform_tpi,\n            reform_params,\n            \"gini\",\n            None,\n            \"levels\",\n        ),\n        (\n            base_tpi,\n            base_params,\n            reform_tpi,\n            reform_params,\n            \"var_of_logs\",\n            None,\n            \"diff\",\n        ),\n        (\n            base_tpi,\n            base_params,\n            reform_tpi,\n            reform_params,\n            \"pct_ratio\",\n            (0.9, 0.1),\n            \"levels\",\n        ),\n        (\n            base_tpi,\n            base_params,\n            reform_tpi,\n            reform_params,\n            \"top_share\",\n            (0.01),\n            \"pct_diff\",\n        ),\n    ],\n    ids=[\n        \"Just baseline\",\n        \"Baseline + Reform\",\n        \"Base + Refore, var logs, diff\",\n        \"Base + Refore, pct ratios\",\n        \"Base + Refore, top share, pct diff\",\n    ],\n)\ndef test_inequality_plot(\n    base_tpi,\n    base_params,\n    reform_tpi,\n    reform_params,\n    ineq_measure,\n    pctiles,\n    plot_type,\n):\n    fig = output_plots.inequality_plot(\n        base_tpi,\n        base_params,\n        reform_tpi=reform_tpi,\n        reform_params=reform_params,\n        ineq_measure=ineq_measure,\n        pctiles=pctiles,\n        plot_type=plot_type,\n    )\n    assert fig\n", "fn_id": 11, "class_fn": false, "repo": "open-source-economics/OG-USA", "file": "tests/test_output_plots.py", "last_update_at": "2018-11-28T13:43:51+00:00", "question_id": "dacc161b4f5ccec815fbafc9482e0ca6b5ec3fa4_11", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.mark.parametrize('base_tpi,base_params,reform_tpi, reform_params,ineq_measure,' + 'pctiles,plot_type', [(base_tpi, base_params, None, None, 'gini', None, 'levels'), (base_tpi, base_params, reform_tpi, reform_params, 'gini', None, 'levels'), (base_tpi, base_params, reform_tpi, reform_params, 'var_of_logs', None, 'diff'), (base_tpi, base_params, reform_tpi, reform_params, 'pct_ratio', (0.9, 0.1), 'levels'), (base_tpi, base_params, reform_tpi, reform_params, 'top_share', 0.01, 'pct_diff')], ids=['Just baseline', 'Baseline + Reform', 'Base + Refore, var logs, diff', 'Base + Refore, pct ratios', 'Base + Refore, top share, pct diff'])\ndef test_inequality_plot(base_tpi, base_params, reform_tpi, reform_params, ineq_measure, pctiles, plot_type):\n    fig = output_plots.inequality_plot(base_tpi, base_params, reform_tpi=reform_tpi, reform_params=reform_params, ineq_measure=ineq_measure, pctiles=pctiles, plot_type=plot_type)\n"]]}
{"hexsha": "1214f067051da2f3fd1fe670843072482b2bc04e", "ext": "py", "lang": "Python", "content": "def logsDirectory():\n    \"\"\" logsDirectory creates logs directory for dumping logs when there is an error or exception. \"\"\"\n    if not os.path.exists(LOGS_DIRECTORY):\n        os.mkdir(LOGS_DIRECTORY)", "fn_id": 1, "class_fn": false, "repo": "gosaliajigar/YSP", "file": "library.py", "last_update_at": "2018-05-09T04:38:06+00:00", "question_id": "1214f067051da2f3fd1fe670843072482b2bc04e_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def logsDirectory():\n    \"\"\" logsDirectory creates logs directory for dumping logs when there is an error or exception. \"\"\"\n    if not os.path.exists(LOGS_DIRECTORY):\n"]]}
{"hexsha": "eba211ec623ebe87dd4049f9d60b910827efdef1", "ext": "py", "lang": "Python", "content": "def test_mod_get() :\n    '''\n    >>> test_mod_get()\n    Initialization.\n    Module: <<multiagent.Module memory_size=0>>\n    Position: None\n    Angle: None\n    Velocity: None\n    Angular Velocity: None\n    Force: None\n    Color: None\n    Radio In Messages: []\n    Radio Out Message: None\n    Radar Detect: []\n    Radar Distance: None\n    '''\n    print(\"Initialization.\")\n    mod = Module()\n    print(\"Module: %s\" % mod.info())\n    print(\"Position: %s\" % mod.get_pos())\n    print(\"Angle: %s\" % mod.get_angle())\n    print(\"Velocity: %s\" % mod.get_vel())\n    print(\"Angular Velocity: %s\" % mod.get_avel())\n    print(\"Force: %s\" % mod.get_force())\n    print(\"Color: %s\" % mod.get_color())\n    print(\"Radio In Messages: %s\" % mod.get_radio_in_msgs())\n    print(\"Radio Out Message: %s\" % mod.get_radio_out_msg())\n    print(\"Radar Detect: %s\" % mod.get_radar_detect())\n    print(\"Radar Distance: %s\" % mod.get_radar_dist())", "fn_id": 1, "class_fn": false, "repo": "csningli/MultiAgent", "file": "tests/test_module.py", "last_update_at": "2018-03-21T02:17:01+00:00", "question_id": "eba211ec623ebe87dd4049f9d60b910827efdef1_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_mod_get():\n    \"\"\"\n    >>> test_mod_get()\n    Initialization.\n    Module: <<multiagent.Module memory_size=0>>\n    Position: None\n    Angle: None\n    Velocity: None\n    Angular Velocity: None\n    Force: None\n    Color: None\n    Radio In Messages: []\n    Radio Out Message: None\n    Radar Detect: []\n    Radar Distance: None\n    \"\"\"\n    print('Initialization.')\n    mod = Module()\n    print('Module: %s' % mod.info())\n    print('Position: %s' % mod.get_pos())\n    print('Angle: %s' % mod.get_angle())\n    print('Velocity: %s' % mod.get_vel())\n    print('Angular Velocity: %s' % mod.get_avel())\n    print('Force: %s' % mod.get_force())\n    print('Color: %s' % mod.get_color())\n    print('Radio In Messages: %s' % mod.get_radio_in_msgs())\n    print('Radio Out Message: %s' % mod.get_radio_out_msg())\n    print('Radar Detect: %s' % mod.get_radar_detect())\n"]]}
{"hexsha": "c3b98756f25895baff7dda02e966999c7ad4a8be", "ext": "py", "lang": "Python", "content": "def test_check_single_model_access(mock, tmpdir, test_data_path):\n    mock.when(\n        'POST /login'\n    ).reply(\n        '\"security-token\"',\n        headers={'Content-Type': 'application/json'},\n        times=FOREVER)\n    mock.when(\n        'POST /access/list',\n        body=\".+\\\"test_user\\\".+\",\n        headers={'Authorization': 'Bearer security-token'}\n    ).reply('[true]',\n            headers={'Content-Type': 'application/json'},\n            times=FOREVER)\n    mock.when(\n        'POST /access/list',\n        body=\".+\\\"non_granted_user\\\".+\",\n        headers={'Authorization': 'Bearer security-token'}\n    ).reply(\n        '[false]',\n        headers={'Content-Type': 'application/json'},\n        times=FOREVER)\n    test_props = create_local_testdb(db_path=tmpdir,\n                                     data_path=test_data_path / 'testdb',\n                                     auth_url=mock.pretend_url)\n\n    mp = ixmp.Platform(dbprops=test_props)\n    mp.set_log_level('DEBUG')\n\n    granted = mp.check_access('test_user', 'test_model')\n    assert granted\n\n    granted = mp.check_access('non_granted_user', 'test_model')\n    assert not granted\n\n    granted = mp.check_access('non_existing_user', 'test_model')\n    assert not granted", "fn_id": 2, "class_fn": false, "repo": "gidden/ixmp", "file": "tests/test_access.py", "last_update_at": "2018-01-26T15:21:52+00:00", "question_id": "c3b98756f25895baff7dda02e966999c7ad4a8be_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_check_single_model_access(mock, tmpdir, test_data_path):\n    mock.when('POST /login').reply('\"security-token\"', headers={'Content-Type': 'application/json'}, times=FOREVER)\n    mock.when('POST /access/list', body='.+\"test_user\".+', headers={'Authorization': 'Bearer security-token'}).reply('[true]', headers={'Content-Type': 'application/json'}, times=FOREVER)\n    mock.when('POST /access/list', body='.+\"non_granted_user\".+', headers={'Authorization': 'Bearer security-token'}).reply('[false]', headers={'Content-Type': 'application/json'}, times=FOREVER)\n    test_props = create_local_testdb(db_path=tmpdir, data_path=test_data_path / 'testdb', auth_url=mock.pretend_url)\n    mp = ixmp.Platform(dbprops=test_props)\n    mp.set_log_level('DEBUG')\n    granted = mp.check_access('test_user', 'test_model')\n    assert granted\n    granted = mp.check_access('non_granted_user', 'test_model')\n    assert not granted\n    granted = mp.check_access('non_existing_user', 'test_model')\n"]]}
{"hexsha": "93bd61e3346a462733e580f8a7da1cd20aa9edf5", "ext": "py", "lang": "Python", "content": "def broadcast_to_peers(req_method, url, **kwargs):\n\t\t\"\"\"\n\t\tBroadcast some information to all nodes in peer network\n\t\t\"\"\"\n\n\t\tpeers = get_all_peers()\n\n\t\tfor peer in peers:\n\t\t\t\trequests.request(req_method, peer + url, **kwargs)", "fn_id": 2, "class_fn": false, "repo": "kush-josh/smart-content", "file": "libs/peers_utils.py", "last_update_at": "2018-02-23T11:56:18+00:00", "question_id": "93bd61e3346a462733e580f8a7da1cd20aa9edf5_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def broadcast_to_peers(req_method, url, **kwargs):\n    \"\"\"\n\t\tBroadcast some information to all nodes in peer network\n\t\t\"\"\"\n    peers = get_all_peers()\n    for peer in peers:\n"]]}
{"hexsha": "6859cb5b8630fc59b4f1eee81a4bc2cc6bd8303b", "ext": "py", "lang": "Python", "content": "def poly_lr_scheduler(optimizer, init_lr, iter, lr_decay_iter=1, max_iter=30000, power=0.9,):\n    \"\"\"Polynomial decay of learning rate\n        :param init_lr is base learning rate\n        :param iter is a current iteration\n        :param lr_decay_iter how frequently decay occurs, default is 1\n        :param max_iter is number of maximum iterations\n        :param power is a polymomial power\n\n    \"\"\"\n    if iter % lr_decay_iter or iter > max_iter:\n        return optimizer\n\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = init_lr*(1 - iter/max_iter)**power", "fn_id": 0, "class_fn": false, "repo": "flixpar/SemSeg", "file": "lr_scheduling.py", "last_update_at": "2018-12-25T15:57:03+00:00", "question_id": "6859cb5b8630fc59b4f1eee81a4bc2cc6bd8303b_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def poly_lr_scheduler(optimizer, init_lr, iter, lr_decay_iter=1, max_iter=30000, power=0.9):\n    \"\"\"Polynomial decay of learning rate\n        :param init_lr is base learning rate\n        :param iter is a current iteration\n        :param lr_decay_iter how frequently decay occurs, default is 1\n        :param max_iter is number of maximum iterations\n        :param power is a polymomial power\n\n    \"\"\"\n    if iter % lr_decay_iter or iter > max_iter:\n        return optimizer\n    for param_group in optimizer.param_groups:\n"]]}
{"hexsha": "90d94790d1781c24778a10f0e097bd70bbc88c3d", "ext": "py", "lang": "Python", "content": "async def lastraid(message, bot_channel, client, player):\n    await client.delete_message(message)\n    parameters = message.content.split()\n    if len(parameters) < 2:\n        await client.send_message(bot_channel, \"USAGE: !lastraidplayer [player name] or !lastraidguild [guild name]\")\n        return\n\n    name = \" \".join(parameters[1:])\n    if not name.isalpha():\n        await client.send_message(bot_channel, \"Sorry, but the {} name can only contain letters.\".format(\"player\" if player else \"guild\"))\n        return\n\n    name = name.lower().capitalize()\n    if player:\n        try:\n            player_url, player_info = await get_player_url(message, bot_channel, client, name)\n        except:\n            return\n\n        player_overview_url = \"http://realmplayers.com/RaidStats/PlayerOverview.aspx?realm={}&player={}\".format(\n            player_info[0], player_info[1])\n\n        # Get raid stats url from the player\n        @get_session(player_overview_url)\n        async def get_raid_url(message, bot_channel, client, resp):\n            player_doc = await resp.text()\n            pattern = '<h2>Attended raids</h2><a href=\\\"(.+?)\\\">'\n            return re.search(pattern, player_doc)\n\n        try:\n            match = await get_raid_url(message, bot_channel, client)\n        except:\n            return\n\n        if match:\n            # Get character info to find out if horde or alliance\n            @get_session(player_url)\n            async def get_player_doc(message, bot_channel, client, resp):\n                return await resp.text()\n\n            try:\n                player_doc = await get_player_doc(message, bot_channel, client)\n            except:\n                return\n\n            is_alliance = re.search('alliance_bg', player_doc)\n            if is_alliance:\n                player_race_icon = race_icons[\"alliance\"]\n            else:\n                player_race_icon = race_icons[\"horde\"]\n\n            server = re.search(\"<span class='divider'>/</span>(.+?)</li>\", player_doc)\n            if not server:\n                await client.send_message(bot_channel,\n                                          \"Sorry, the web site has been changed and the bot needs an update.\\n\"\n                                          \"Please notify the developer.\")\n                return\n\n            raid_stats = \"http://realmplayers.com/RaidStats/{}\"\n\n            # Get raid info to get full title and time\n            @get_session(raid_stats.format(match.group(1)))\n            async def get_raid_doc(message, bot_channel, client, resp):\n                return await resp.text()\n\n            try:\n                raid_doc = await get_raid_doc(message, bot_channel, client)\n            except:\n                return\n\n            raid_info = re.search(\"<a href='(RaidList\\.aspx\\?Guild=.+?&realm=.+?)'>(.+?)</a></li>\"\n                                  \"<li class='active'><span class='divider'>/</span>(.+?)</li>\", raid_doc)\n            times = re.search(\"between (\\d{4}(?:-\\d{1,2}){2} (?:\\d{2}:){2}\\d{2}) and \"\n                              \"(\\d{4}(?:-\\d{1,2}){2} (?:\\d{2}:){2}\\d{2})\", raid_doc)\n            if not raid_info or not times:\n                await client.send_message(bot_channel,\n                                          \"Sorry, the web site has been changed and the bot needs an update.\\n\"\n                                          \"Please notify the developer.\")\n                return\n\n            embed = discord.Embed()\n            embed.set_author(name=raid_info.group(2), url=raid_stats.format(raid_info.group(1)),\n                             icon_url=player_race_icon)\n            embed.set_thumbnail(url=raid_icons[re.sub(\"\\(.+?\\)\", '', raid_info.group(3))])\n            embed.colour = discord.Colour.dark_blue()\n            embed.title = raid_info.group(3).strip(\" \")\n            embed.url = raid_stats.format(match.group(1))\n            embed.description = \"Last recorded raid for **[{}]({})**\\n\".format(player_info[1], player_url)\n            embed.description += \"On server {}\".format(server.group(1).strip(\" \"))\n            embed.add_field(name=\"Start\", value=times.group(1)).add_field(name=\"End\", value=times.group(2))\n            await client.send_message(bot_channel, embed=embed)\n        else:\n            await client.send_message(bot_channel, \"The given player doesn't seem to have any raids on record.\")\n\n    else:\n        # Get guild url from searching after the guild\n        @get_session(\"http://realmplayers.com/CharacterList.aspx?search={}\".format(name))\n        async def get_guild_url(message, bot_channel, client, resp):\n            search_doc = await resp.text()\n            pattern = 'realm=(\\w+?)&guild=({})\\\">&lt;.+?&gt;<\\/a></td><td>.*?</td><td>.*?</td><td>.*?</td><td>.*?</td><td>(.+?)</td>'.format(name)\n            return re.findall(pattern, search_doc)\n\n        try:\n            matches = await get_guild_url(message, bot_channel, client)\n        except:\n            return\n\n        if len(matches) < 1:\n            await client.send_message(bot_channel, 'Sorry, could not find any guild with name \"{}\".'.format(name))\n            return\n\n        guild_tuple = matches[0]\n        response = await prompt_user(message, bot_channel, client, name, matches)\n        if response:\n            await client.delete_message(response)\n            guild_tuple = matches[int(response.content) - 1]\n\n        raid_link = \"http://realmplayers.com/RaidStats/RaidList.aspx?realm={}&guild={}\".format(guild_tuple[0], guild_tuple[1])\n\n        # Get raid link\n        @get_session(raid_link)\n        async def get_last_raid_url(message, bot_channel, client, resp):\n            search_doc = await resp.text()\n            pattern = '<a href=\"(.+?)\"><img src=\"(.+?)\"\\/>(.+?)<\\/a><\\/td><td><a href=\"(.+?)\">' \\\n                      '<img src=\"(.+?)\"\\/>(.+?)<\\/a><\\/td><td>(.+?)<\\/td><td>(.+?)<\\/td><td>(.+?)<\\/td><\\/tr>'\n            return re.search(pattern, search_doc)\n\n        try:\n            match = await get_last_raid_url(message, bot_channel, client)\n        except:\n            return\n\n        if match:\n            embed = discord.Embed()\n            raid_stats = \"http://realmplayers.com/RaidStats/{}\"\n            embed.set_author(name=match.group(3), url=raid_stats.format(match.group(1)), icon_url=raid_stats.format(match.group(2)))\n            embed.set_thumbnail(url=raid_stats.format(match.group(5)))\n            embed.colour = discord.Colour.dark_blue()\n            embed.title = match.group(6).strip(\" \")\n            embed.url = raid_stats.format(match.group(4))\n            embed.description = \"On server {}\".format(match.group(9))\n            embed.add_field(name=\"Start\", value=match.group(7)).add_field(name=\"End\", value=match.group(8))\n            await client.send_message(bot_channel, embed=embed)\n        else:\n            await client.send_message(bot_channel,\n                                      \"There doesn't seem to be any raids recorded for this guild.\")", "fn_id": 4, "class_fn": false, "repo": "Borgli/Ohminator", "file": "plugins/wow.py", "last_update_at": "2018-03-25T20:41:30+00:00", "question_id": "90d94790d1781c24778a10f0e097bd70bbc88c3d_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["async def lastraid(message, bot_channel, client, player):\n    await client.delete_message(message)\n    parameters = message.content.split()\n    if len(parameters) < 2:\n        await client.send_message(bot_channel, 'USAGE: !lastraidplayer [player name] or !lastraidguild [guild name]')\n        return\n    name = ' '.join(parameters[1:])\n    if not name.isalpha():\n        await client.send_message(bot_channel, 'Sorry, but the {} name can only contain letters.'.format('player' if player else 'guild'))\n        return\n    name = name.lower().capitalize()\n    if player:\n        try:\n            player_url, player_info = await get_player_url(message, bot_channel, client, name)\n        except:\n            return\n        player_overview_url = 'http://realmplayers.com/RaidStats/PlayerOverview.aspx?realm={}&player={}'.format(player_info[0], player_info[1])\n\n        @get_session(player_overview_url)\n        async def get_raid_url(message, bot_channel, client, resp):\n            player_doc = await resp.text()\n            pattern = '<h2>Attended raids</h2><a href=\"(.+?)\">'\n            return re.search(pattern, player_doc)\n        try:\n            match = await get_raid_url(message, bot_channel, client)\n        except:\n            return\n        if match:\n\n            @get_session(player_url)\n            async def get_player_doc(message, bot_channel, client, resp):\n                return await resp.text()\n            try:\n                player_doc = await get_player_doc(message, bot_channel, client)\n            except:\n                return\n            is_alliance = re.search('alliance_bg', player_doc)\n            if is_alliance:\n                player_race_icon = race_icons['alliance']\n            else:\n                player_race_icon = race_icons['horde']\n            server = re.search(\"<span class='divider'>/</span>(.+?)</li>\", player_doc)\n            if not server:\n                await client.send_message(bot_channel, 'Sorry, the web site has been changed and the bot needs an update.\\nPlease notify the developer.')\n                return\n            raid_stats = 'http://realmplayers.com/RaidStats/{}'\n\n            @get_session(raid_stats.format(match.group(1)))\n            async def get_raid_doc(message, bot_channel, client, resp):\n                return await resp.text()\n            try:\n                raid_doc = await get_raid_doc(message, bot_channel, client)\n            except:\n                return\n            raid_info = re.search(\"<a href='(RaidList\\\\.aspx\\\\?Guild=.+?&realm=.+?)'>(.+?)</a></li><li class='active'><span class='divider'>/</span>(.+?)</li>\", raid_doc)\n            times = re.search('between (\\\\d{4}(?:-\\\\d{1,2}){2} (?:\\\\d{2}:){2}\\\\d{2}) and (\\\\d{4}(?:-\\\\d{1,2}){2} (?:\\\\d{2}:){2}\\\\d{2})', raid_doc)\n            if not raid_info or not times:\n                await client.send_message(bot_channel, 'Sorry, the web site has been changed and the bot needs an update.\\nPlease notify the developer.')\n                return\n            embed = discord.Embed()\n            embed.set_author(name=raid_info.group(2), url=raid_stats.format(raid_info.group(1)), icon_url=player_race_icon)\n            embed.set_thumbnail(url=raid_icons[re.sub('\\\\(.+?\\\\)', '', raid_info.group(3))])\n            embed.colour = discord.Colour.dark_blue()\n            embed.title = raid_info.group(3).strip(' ')\n            embed.url = raid_stats.format(match.group(1))\n            embed.description = 'Last recorded raid for **[{}]({})**\\n'.format(player_info[1], player_url)\n            embed.description += 'On server {}'.format(server.group(1).strip(' '))\n            embed.add_field(name='Start', value=times.group(1)).add_field(name='End', value=times.group(2))\n            await client.send_message(bot_channel, embed=embed)\n        else:\n            await client.send_message(bot_channel, \"The given player doesn't seem to have any raids on record.\")\n    else:\n\n        @get_session('http://realmplayers.com/CharacterList.aspx?search={}'.format(name))\n        async def get_guild_url(message, bot_channel, client, resp):\n            search_doc = await resp.text()\n            pattern = 'realm=(\\\\w+?)&guild=({})\">&lt;.+?&gt;<\\\\/a></td><td>.*?</td><td>.*?</td><td>.*?</td><td>.*?</td><td>(.+?)</td>'.format(name)\n            return re.findall(pattern, search_doc)\n        try:\n            matches = await get_guild_url(message, bot_channel, client)\n        except:\n            return\n        if len(matches) < 1:\n            await client.send_message(bot_channel, 'Sorry, could not find any guild with name \"{}\".'.format(name))\n            return\n        guild_tuple = matches[0]\n        response = await prompt_user(message, bot_channel, client, name, matches)\n        if response:\n            await client.delete_message(response)\n            guild_tuple = matches[int(response.content) - 1]\n        raid_link = 'http://realmplayers.com/RaidStats/RaidList.aspx?realm={}&guild={}'.format(guild_tuple[0], guild_tuple[1])\n\n        @get_session(raid_link)\n        async def get_last_raid_url(message, bot_channel, client, resp):\n            search_doc = await resp.text()\n            pattern = '<a href=\"(.+?)\"><img src=\"(.+?)\"\\\\/>(.+?)<\\\\/a><\\\\/td><td><a href=\"(.+?)\"><img src=\"(.+?)\"\\\\/>(.+?)<\\\\/a><\\\\/td><td>(.+?)<\\\\/td><td>(.+?)<\\\\/td><td>(.+?)<\\\\/td><\\\\/tr>'\n            return re.search(pattern, search_doc)\n        try:\n            match = await get_last_raid_url(message, bot_channel, client)\n        except:\n            return\n        if match:\n            embed = discord.Embed()\n            raid_stats = 'http://realmplayers.com/RaidStats/{}'\n            embed.set_author(name=match.group(3), url=raid_stats.format(match.group(1)), icon_url=raid_stats.format(match.group(2)))\n            embed.set_thumbnail(url=raid_stats.format(match.group(5)))\n            embed.colour = discord.Colour.dark_blue()\n            embed.title = match.group(6).strip(' ')\n            embed.url = raid_stats.format(match.group(4))\n            embed.description = 'On server {}'.format(match.group(9))\n            embed.add_field(name='Start', value=match.group(7)).add_field(name='End', value=match.group(8))\n            await client.send_message(bot_channel, embed=embed)\n        else:\n"]]}
{"hexsha": "0443e73ee7d41587d26b2bc3e017b0aef2cec36e", "ext": "py", "lang": "Python", "content": "def load_SL_data(City, path):\n\n    ########################  loading data and graph #######################\n    edges = pd.read_table(\"data/\" + City.location + \"Graph.txt\",\n                          sep=\" \",\n                          header=None,\n                          names=['vx', 'vy', 'weight'])\n\n    graph = nx.from_pandas_edgelist(edges, 'vx', 'vy', 'weight')\n\n    temp1 = np.load(os.path.join(\n        path, City.location + \"DistanceMatrix0.dat\"))\n    temp2 = np.load(os.path.join(\n        path, City.location + \"DistanceMatrix1.dat\"))\n    test_distance_matrix = np.concatenate((temp1, temp2), axis=0)\n    distance_matrix = np.load(os.path.join(\n        path, City.location + \"LandmarkDistanceMatrix.dat\"))\n    print(\"Matrix is loaded\")\n\n    ######################## preprocessing data #######################\n    max_distance = np.amax(test_distance_matrix)\n    distance_matrix = distance_matrix / max_distance\n    test_distance_matrix = test_distance_matrix / max_distance\n\n    return (distance_matrix, test_distance_matrix, max_distance)", "fn_id": 7, "class_fn": false, "repo": "justinxutianyu/DNN_Estimation", "file": "script/util.py", "last_update_at": "2018-03-28T05:38:33+00:00", "question_id": "0443e73ee7d41587d26b2bc3e017b0aef2cec36e_7", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def load_SL_data(City, path):\n    edges = pd.read_table('data/' + City.location + 'Graph.txt', sep=' ', header=None, names=['vx', 'vy', 'weight'])\n    graph = nx.from_pandas_edgelist(edges, 'vx', 'vy', 'weight')\n    temp1 = np.load(os.path.join(path, City.location + 'DistanceMatrix0.dat'))\n    temp2 = np.load(os.path.join(path, City.location + 'DistanceMatrix1.dat'))\n    test_distance_matrix = np.concatenate((temp1, temp2), axis=0)\n    distance_matrix = np.load(os.path.join(path, City.location + 'LandmarkDistanceMatrix.dat'))\n    print('Matrix is loaded')\n    max_distance = np.amax(test_distance_matrix)\n    distance_matrix = distance_matrix / max_distance\n    test_distance_matrix = test_distance_matrix / max_distance\n"]]}
{"hexsha": "19ce5ff6fe21bd6c01fbb0e5b1a0d665ab576091", "ext": "py", "lang": "Python", "content": "def mean_similarity(sent1, sent2):\n    sent1 = sent1.strip().split(\" \")\n    sent2 = sent2.strip().split(\" \")\n\n    hypothesis_dict = {}\n    sent22 = [word2.lower() for word2 in sent2 if word2.lower() in model.vocab]\n    sent11 = [word1.lower() for word1 in sent1 if word1.lower() in model.vocab]\n\n    for word2 in sent22:\n        sim = 0\n        for word1 in sent11:\n            currsim = model.similarity(word2, word1)\n            if currsim > sim:\n                sim = currsim\n                hypothesis_dict[word2] = (word1, currsim)\n\n    sum = 0\n    for k, (v1, v2) in hypothesis_dict.items():\n        sum += v2\n    if len(hypothesis_dict.items()) > 0:\n        return sum/len(hypothesis_dict.items()) # normalize sum\n    else:\n        return 0", "fn_id": 3, "class_fn": false, "repo": "recski/semantic_parsing_szte_bme", "file": "nli_baselines/Vanda/baseline_vanda.py", "last_update_at": "2018-04-05T16:57:00+00:00", "question_id": "19ce5ff6fe21bd6c01fbb0e5b1a0d665ab576091_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def mean_similarity(sent1, sent2):\n    sent1 = sent1.strip().split(' ')\n    sent2 = sent2.strip().split(' ')\n    hypothesis_dict = {}\n    sent22 = [word2.lower() for word2 in sent2 if word2.lower() in model.vocab]\n    sent11 = [word1.lower() for word1 in sent1 if word1.lower() in model.vocab]\n    for word2 in sent22:\n        sim = 0\n        for word1 in sent11:\n            currsim = model.similarity(word2, word1)\n            if currsim > sim:\n                sim = currsim\n                hypothesis_dict[word2] = (word1, currsim)\n    sum = 0\n    for k, (v1, v2) in hypothesis_dict.items():\n        sum += v2\n    if len(hypothesis_dict.items()) > 0:\n        return sum / len(hypothesis_dict.items())\n    else:\n"]]}
{"hexsha": "0e3673cfaa673d345b3809f10269b823db00628a", "ext": "py", "lang": "Python", "content": "def encode(*stuff):\n\t\"\"\"Encode components into a proper EDIComm string.\n\n\tThe proper look for the parameters is:\n\t\tedicomm.encode(\"TLA\", \"parameter\", [\"list\", \"parameter\"], ('tuples are', 'also okay'))\n\tWhich should create the EDIComm string:\n\t\t\"TLA parameter list,parameter tuples\\ are,also\\ okay\"\n\t\"\"\"\n\n\tret = ''\n\n\tfor i in stuff:\n\t\tif isinstance(i, basestring):\n\t\t\ti = i.replace(',', '\\\\,')\n\t\t\tret += i.replace(' ', '\\\\ ') + ' '\n\t\telif hasattr(i, '__iter__'):\n\t\t\tlstr = ''\n\n\t\t\tfor x in i:\n\t\t\t\tif isinstance(x, basestring):\n\t\t\t\t\tx = x.replace(',', '\\\\,')\n\t\t\t\t\tx = x.replace(' ', '\\\\ ')\n\n\t\t\t\tlstr += str(x) + ','\n\n\t\t\tlstr = lstr.rstrip(',')\n\t\t\tret += lstr + ' '\n\t\telif i == None:\n\t\t\tpass # --Gandalf\n\t\telse:\n\t\t\tret += str(i) + ' '\n\n\tret = ret.rstrip(' ')\n\n\treturn ret", "fn_id": 1, "class_fn": false, "repo": "bullseyestudio/guns-game", "file": "modules/edicomm.py", "last_update_at": "2018-11-21T04:50:57+00:00", "question_id": "0e3673cfaa673d345b3809f10269b823db00628a_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def encode(*stuff):\n    \"\"\"Encode components into a proper EDIComm string.\n\n\tThe proper look for the parameters is:\n\t\tedicomm.encode(\"TLA\", \"parameter\", [\"list\", \"parameter\"], ('tuples are', 'also okay'))\n\tWhich should create the EDIComm string:\n\t\t\"TLA parameter list,parameter tuples\\\\ are,also\\\\ okay\"\n\t\"\"\"\n    ret = ''\n    for i in stuff:\n        if isinstance(i, basestring):\n            i = i.replace(',', '\\\\,')\n            ret += i.replace(' ', '\\\\ ') + ' '\n        elif hasattr(i, '__iter__'):\n            lstr = ''\n            for x in i:\n                if isinstance(x, basestring):\n                    x = x.replace(',', '\\\\,')\n                    x = x.replace(' ', '\\\\ ')\n                lstr += str(x) + ','\n            lstr = lstr.rstrip(',')\n            ret += lstr + ' '\n        elif i == None:\n            pass\n        else:\n            ret += str(i) + ' '\n    ret = ret.rstrip(' ')\n"]]}
{"hexsha": "3d0692dbf1a0c505a61abcc3814a663a56da7d5f", "ext": "py", "lang": "Python", "content": "def set_params(n_rules = 2, n_out = 2, n_steps = 200, coherences=[.5], stim_noise = 0, rec_noise = 0, L1_rec = 0, L2_firing_rate = 0,\n                    sample_size = 128, epochs = 100, N_rec = 50, dale_ratio=0.8, tau=100.0, dt = 10.0, biases = True,\n               task='n_back', rt_version=False):\n    params = dict()\n    params['N_in']             = n_rules*2 \n    params['N_out']            = n_out\n    params['N_batch']          = sample_size\n    params['N_steps']          = n_steps\n    params['N_rules']          = n_rules\n    params['stim_noise']       = stim_noise\n    params['rec_noise']        = rec_noise\n    params['sample_size']      = sample_size\n    params['epochs']           = epochs\n    params['N_rec']            = N_rec\n    params['dale_ratio']       = dale_ratio\n    params['tau']              = tau\n    params['dt']               = dt\n    params['alpha']            = dt/tau\n    params['task']             = task\n    params['L1_rec']           = L1_rec\n    params['L2_firing_rate']   = L2_firing_rate\n    params['biases']           = biases\n    params['coherences']       = coherences\n    params['rt_version']       = rt_version\n\n    return params", "fn_id": 0, "class_fn": false, "repo": "dbehrlich/sisyphus2", "file": "tasks/rule_dependent_rdm.py", "last_update_at": "2018-09-13T21:09:11+00:00", "question_id": "3d0692dbf1a0c505a61abcc3814a663a56da7d5f_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def set_params(n_rules=2, n_out=2, n_steps=200, coherences=[0.5], stim_noise=0, rec_noise=0, L1_rec=0, L2_firing_rate=0, sample_size=128, epochs=100, N_rec=50, dale_ratio=0.8, tau=100.0, dt=10.0, biases=True, task='n_back', rt_version=False):\n    params = dict()\n    params['N_in'] = n_rules * 2\n    params['N_out'] = n_out\n    params['N_batch'] = sample_size\n    params['N_steps'] = n_steps\n    params['N_rules'] = n_rules\n    params['stim_noise'] = stim_noise\n    params['rec_noise'] = rec_noise\n    params['sample_size'] = sample_size\n    params['epochs'] = epochs\n    params['N_rec'] = N_rec\n    params['dale_ratio'] = dale_ratio\n    params['tau'] = tau\n    params['dt'] = dt\n    params['alpha'] = dt / tau\n    params['task'] = task\n    params['L1_rec'] = L1_rec\n    params['L2_firing_rate'] = L2_firing_rate\n    params['biases'] = biases\n    params['coherences'] = coherences\n    params['rt_version'] = rt_version\n"]]}
{"hexsha": "3f17b296fc27a7736813d1a434ca813e7b65c5cf", "ext": "py", "lang": "Python", "content": "def format_line(line, max_width=90):\n    ''' Ensures that lines of text terminate reasonably even if document has no newlines '''\n    line = line.split()\n    while len(line) > 0:\n        out = line[0]\n        line = line[1:]\n        while len(line) > 0 and len(out) + len(line[0]) + 1 < max_width:\n            out = \" \".join([out, line[0]])\n            line = line[1:]\n        yield out", "fn_id": 0, "class_fn": false, "repo": "rgasper/RHCR", "file": "synthetic_data_generation/get_all_characters.py", "last_update_at": "2018-12-30T19:51:04+00:00", "question_id": "3f17b296fc27a7736813d1a434ca813e7b65c5cf_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def format_line(line, max_width=90):\n    \"\"\" Ensures that lines of text terminate reasonably even if document has no newlines \"\"\"\n    line = line.split()\n    while len(line) > 0:\n        out = line[0]\n        line = line[1:]\n        while len(line) > 0 and len(out) + len(line[0]) + 1 < max_width:\n            out = ' '.join([out, line[0]])\n            line = line[1:]\n"]]}
{"hexsha": "0af90ad7836c0460c70f2e6cc90a31a37fb93734", "ext": "py", "lang": "Python", "content": "@asyncio.coroutine\ndef test_setup_component_test_servcie_stop(hass):\n    \"\"\"Setup ffmpeg component test service stop.\"\"\"\n    with assert_setup_component(2):\n        yield from async_setup_component(\n            hass, ffmpeg.DOMAIN, {ffmpeg.DOMAIN: {}})\n\n    ffmpeg_dev = MockFFmpegDev(hass, False)\n    yield from ffmpeg_dev.async_added_to_hass()\n\n    ffmpeg.async_stop(hass)\n    yield from hass.async_block_till_done()\n\n    assert ffmpeg_dev.called_stop", "fn_id": 3, "class_fn": false, "repo": "milaq/home-assistant", "file": "tests/components/test_ffmpeg.py", "last_update_at": "2018-11-04T18:18:12+00:00", "question_id": "0af90ad7836c0460c70f2e6cc90a31a37fb93734_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@asyncio.coroutine\ndef test_setup_component_test_servcie_stop(hass):\n    \"\"\"Setup ffmpeg component test service stop.\"\"\"\n    with assert_setup_component(2):\n        yield from async_setup_component(hass, ffmpeg.DOMAIN, {ffmpeg.DOMAIN: {}})\n    ffmpeg_dev = MockFFmpegDev(hass, False)\n    yield from ffmpeg_dev.async_added_to_hass()\n    ffmpeg.async_stop(hass)\n    yield from hass.async_block_till_done()\n"]]}
{"hexsha": "08d449c0712e896bbf5e1bfd27f30e8b29e31227", "ext": "py", "lang": "Python", "content": "def _sa_bind_mastery():\n    global Mastery\n\n    @cassiopeia.type.core.common.inheritdocs\n    class Mastery(Mastery, cassiopeia.type.dto.common.BaseDB):\n        __tablename__ = \"MasterySlot\"\n        id = sqlalchemy.Column(sqlalchemy.Integer)\n        rank = sqlalchemy.Column(sqlalchemy.Integer)\n        _id = sqlalchemy.Column(sqlalchemy.Integer, primary_key=True)\n        _page_id = sqlalchemy.Column(sqlalchemy.Integer, sqlalchemy.ForeignKey(\"MasteryPage.id\", ondelete=\"CASCADE\"))", "fn_id": 3, "class_fn": false, "repo": "BubblegumDiscord/LoLTrivia", "file": "cassiopeia/type/dto/summoner.py", "last_update_at": "2018-05-06T15:49:33+00:00", "question_id": "08d449c0712e896bbf5e1bfd27f30e8b29e31227_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _sa_bind_mastery():\n    global Mastery\n\n    @cassiopeia.type.core.common.inheritdocs\n    class Mastery(Mastery, cassiopeia.type.dto.common.BaseDB):\n        __tablename__ = 'MasterySlot'\n        id = sqlalchemy.Column(sqlalchemy.Integer)\n        rank = sqlalchemy.Column(sqlalchemy.Integer)\n        _id = sqlalchemy.Column(sqlalchemy.Integer, primary_key=True)\n"]]}
{"hexsha": "84e4d96cb329175c11d2e08a06406e840cc45dbf", "ext": "py", "lang": "Python", "content": "def add_missing_fields(*fields):\n\t\"\"\"\n\t@param do_redirect: throws exception on None, redirects to login on True, redirects to register of False\n\t@type do_redirect: bool\n\t\"\"\"\n\tdef method_wrapper(f):\n\t\tdef wrap(*args, **kwargs):\n\t\t\t\tfor k in fields:\n\t\t\t\t\tif k not in kwargs:\n\t\t\t\t\t\tkwargs[k] = None\n\t\t\t\treturn f(*args, **kwargs)\n\t\twrap.__doc__ = f.__doc__\n\t\twrap.__name__ = f.__name__\n\t\treturn wrap\n\treturn method_wrapper", "fn_id": 0, "class_fn": false, "repo": "Deathangel908/djangochat", "file": "backend/chat/tornado/method_dispatcher.py", "last_update_at": "2018-01-14T20:53:03+00:00", "question_id": "84e4d96cb329175c11d2e08a06406e840cc45dbf_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def add_missing_fields(*fields):\n    \"\"\"\n\t@param do_redirect: throws exception on None, redirects to login on True, redirects to register of False\n\t@type do_redirect: bool\n\t\"\"\"\n\n    def method_wrapper(f):\n\n        def wrap(*args, **kwargs):\n            for k in fields:\n                if k not in kwargs:\n                    kwargs[k] = None\n            return f(*args, **kwargs)\n        wrap.__doc__ = f.__doc__\n        wrap.__name__ = f.__name__\n        return wrap\n"]]}
{"hexsha": "0ed777d146310fec6eba351a6a399a91663445a5", "ext": "py", "lang": "Python", "content": "def test_action_defer_3():\n    # GIVEN\n    expected = [\n        fluent_initiate('a', [], 0),\n        action('p1a', [2], (1, 2)),\n        action('p2a', [1], (1, 2)),\n        action('p1a', [2], (2, 3)),\n        action('p2a', [1], (2, 3)),\n    ]\n\n    # WHEN\n    actual = run_pylps_test_program('misc', 'action_defer_3')\n\n    # THEN\n    assert actual == expected", "fn_id": 2, "class_fn": false, "repo": "astraldawn/pylps", "file": "tests/test_misc.py", "last_update_at": "2018-05-19T18:28:12+00:00", "question_id": "0ed777d146310fec6eba351a6a399a91663445a5_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_action_defer_3():\n    expected = [fluent_initiate('a', [], 0), action('p1a', [2], (1, 2)), action('p2a', [1], (1, 2)), action('p1a', [2], (2, 3)), action('p2a', [1], (2, 3))]\n    actual = run_pylps_test_program('misc', 'action_defer_3')\n"]]}
{"hexsha": "c1260a861035781f39ed776ff6f4f5ae51270c55", "ext": "py", "lang": "Python", "content": "def _netbsd_balloon_stat(label):\n    \"\"\"Returns the value for the named label, or None if an error occurs.\"\"\"\n\n    import commands\n\n    xend2netbsd_labels = { 'current'      : 'kern.xen.balloon.current',\n                           'target'       : 'kern.xen.balloon.target',\n                           'low-balloon'  : None,\n                           'high-balloon' : None,\n                           'limit'        : None }\n\n    cmdarg = xend2netbsd_labels[label]\n    if cmdarg is None:\n        return None\n    cmd = \"/sbin/sysctl \" + cmdarg\n    sysctloutput = commands.getoutput(cmd)\n    (name, value) = sysctloutput.split('=')\n    return int(value)", "fn_id": 3, "class_fn": false, "repo": "zhiming-shen/Xen-Blanket-NG", "file": "xen/xen-4.2.2/tools/python/xen/xend/osdep.py", "last_update_at": "2018-02-02T00:15:26+00:00", "question_id": "c1260a861035781f39ed776ff6f4f5ae51270c55_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _netbsd_balloon_stat(label):\n    \"\"\"Returns the value for the named label, or None if an error occurs.\"\"\"\n    import commands\n    xend2netbsd_labels = {'current': 'kern.xen.balloon.current', 'target': 'kern.xen.balloon.target', 'low-balloon': None, 'high-balloon': None, 'limit': None}\n    cmdarg = xend2netbsd_labels[label]\n    if cmdarg is None:\n        return None\n    cmd = '/sbin/sysctl ' + cmdarg\n    sysctloutput = commands.getoutput(cmd)\n    name, value = sysctloutput.split('=')\n"]]}
{"hexsha": "2b79d969415fd169a171e0d4ec07c0f23e0b6f98", "ext": "py", "lang": "Python", "content": "def _decoding_base_info(encoded_info):\n    \"\"\"\n    Decode base info\n\n    Args:\n        encoded_info(list or dict): encoded base info\n    \"\"\"\n    if isinstance(encoded_info, dict):\n        return encoded_info\n    base_info = dict()\n    for item in encoded_info:\n        base_info[item['symbol']] = item['base']\n    return base_info", "fn_id": 1, "class_fn": false, "repo": "myron0330/metatrade", "file": "lib/core/schema.py", "last_update_at": "2018-06-28T09:49:08+00:00", "question_id": "2b79d969415fd169a171e0d4ec07c0f23e0b6f98_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _decoding_base_info(encoded_info):\n    \"\"\"\n    Decode base info\n\n    Args:\n        encoded_info(list or dict): encoded base info\n    \"\"\"\n    if isinstance(encoded_info, dict):\n        return encoded_info\n    base_info = dict()\n    for item in encoded_info:\n        base_info[item['symbol']] = item['base']\n"]]}
{"hexsha": "f07be9c18ba9de55a8e23ff331fe6a38e916c333", "ext": "py", "lang": "Python", "content": "@blueprint.get('/roles/<role_id>')\n@permission_required('role.view')\n@templated\ndef role_view(role_id):\n    \"\"\"View role details.\"\"\"\n    role = authorization_service.find_role(role_id)\n\n    if role is None:\n        abort(404)\n\n    all_permissions = permission_registry.get_registered_permissions()\n\n    role_permission_ids = authorization_service.get_permission_ids_for_role(\n        role.id\n    )\n\n    permissions = {\n        permission\n        for permission in all_permissions\n        if permission.id in role_permission_ids\n    }\n\n    user_ids = authorization_service.find_user_ids_for_role(role.id)\n    users = user_service.get_users(user_ids, include_avatars=True)\n\n    return {\n        'role': role,\n        'permissions': permissions,\n        'users': users,\n    }", "fn_id": 2, "class_fn": false, "repo": "homeworkprod/byceps", "file": "byceps/blueprints/admin/authorization/views.py", "last_update_at": "2018-12-12T20:11:45+00:00", "question_id": "f07be9c18ba9de55a8e23ff331fe6a38e916c333_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@blueprint.get('/roles/<role_id>')\n@permission_required('role.view')\n@templated\ndef role_view(role_id):\n    \"\"\"View role details.\"\"\"\n    role = authorization_service.find_role(role_id)\n    if role is None:\n        abort(404)\n    all_permissions = permission_registry.get_registered_permissions()\n    role_permission_ids = authorization_service.get_permission_ids_for_role(role.id)\n    permissions = {permission for permission in all_permissions if permission.id in role_permission_ids}\n    user_ids = authorization_service.find_user_ids_for_role(role.id)\n    users = user_service.get_users(user_ids, include_avatars=True)\n"]]}
{"hexsha": "214dcf86580adc11e3dab76c3a77e8e0f350eebd", "ext": "py", "lang": "Python", "content": "def navigator(years, current):\n    \"\"\"`years` is an iterable of :class:`BloggerYear` instances.\n    \"\"\"\n    if len(years) < 2:\n        return \"\"\n    chunks = []\n    for y in years:\n        if y == current:\n            chunks.append(str(y.year))\n        else:\n            chunks.append(\n                \":doc:`{0} <{1}>`\".format(y.year, year2docname(y)))\n    old = ' '.join(chunks)\n    return \"\\n\\n{0}\\n\\n\".format(old)", "fn_id": 1, "class_fn": false, "repo": "lsaffre/atelier", "file": "atelier/sphinxconf/blog.py", "last_update_at": "2018-09-20T12:49:51+00:00", "question_id": "214dcf86580adc11e3dab76c3a77e8e0f350eebd_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def navigator(years, current):\n    \"\"\"`years` is an iterable of :class:`BloggerYear` instances.\n    \"\"\"\n    if len(years) < 2:\n        return ''\n    chunks = []\n    for y in years:\n        if y == current:\n            chunks.append(str(y.year))\n        else:\n            chunks.append(':doc:`{0} <{1}>`'.format(y.year, year2docname(y)))\n    old = ' '.join(chunks)\n"]]}
{"hexsha": "8f4a2bd629b69e0fdd1ee52758e0d8fce11f8c51", "ext": "py", "lang": "Python", "content": "def searchImage(searchName): # \ud0dc\uadf8\ub098 \ud30c\uc77c\uba85\uc5d0 searchName\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\ub294 \ud30c\uc77c \ub9ac\uc2a4\ud2b8\ub97c \uac80\uc0c9\ud558\ub294 \ud568\uc218\n    taglist = getTagList(); # \ud0dc\uadf8 \uba3c\uc800 \uac80\uc0c9\n    result = [] # \uac80\uc0c9\uacb0\uacfc\ub97c \uc800\uc7a5\ud560 \ubc30\uc5f4\n    for item in taglist:\n        f = open(item, 'r')\n        data = f.read()\n        f.close()\n        if (searchName not in data)==False: # \uac80\uc0c9\ub300\uc0c1\uc774 \ubc1c\uacac\ub41c \ud56d\ubaa9\n            result.append(item)\n    for i in range(0, len(result)):\n        result[i] = result[i].replace('_tag.txt', '.jpg')\n        print(result[i])\n    imagelist = getImageList() # \uc774\uc81c \uc774\ubbf8\uc9c0 \ucc28\ub840\n    for item in imagelist:\n        if (searchName not in item)==False: # \uac80\uc0c9\ub300\uc0c1\uc774 \ubc1c\uacac\ub41c \ud56d\ubaa9\n            if item not in result:\n                result.append(item)\n    return result", "fn_id": 7, "class_fn": false, "repo": "JunhoYeo/15th-Appjam", "file": "WebApp/starbucks.py", "last_update_at": "2018-04-04T07:28:13+00:00", "question_id": "8f4a2bd629b69e0fdd1ee52758e0d8fce11f8c51_7", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def searchImage(searchName):\n    taglist = getTagList()\n    result = []\n    for item in taglist:\n        f = open(item, 'r')\n        data = f.read()\n        f.close()\n        if (searchName not in data) == False:\n            result.append(item)\n    for i in range(0, len(result)):\n        result[i] = result[i].replace('_tag.txt', '.jpg')\n        print(result[i])\n    imagelist = getImageList()\n    for item in imagelist:\n        if (searchName not in item) == False:\n            if item not in result:\n                result.append(item)\n"]]}
{"hexsha": "15512953e72a4d547bc8d97d82ec169af2d846f4", "ext": "py", "lang": "Python", "content": "def test_7():\n    \"\"\"Testing the synthesis of a Python program.\"\"\"\n    code = \"\"\"\na = HOLE\nif x != 5:\n    a = a + 1\nelse:\n    a = a - 1\n    \"\"\"\n    vars = contract.ProgramVars({'x': 'Int', 'y': 'Int'}, {'a': 'Int'})\n    code_pre = 'x >= 1 and y >= 1'\n    code_post = 'a == 6*x + y'\n\n    grammar_spec = \"\"\"\n(\n    ( Start Int\n        ( ( Constant Int ) x y (+ Start Start) (* ( Constant Int ) Start) )\n    )\n)\n    \"\"\"\n    import pysv.templates\n    grammar = pysv.templates.load_gramar_from_SYGUS_spec(grammar_spec)\n    hole = pysv.smt_synthesis.HoleDecl('HOLE', grammar, {'x': 'Int', 'y': 'Int'}, True, max_depth=3)\n    holes_defs = {hole.id: hole}\n\n    res = pysv.smt_synthesis.synthesize(code, code_pre, code_post, vars, holes_defs)\n\n    # Printing result\n    print('******** Z3 RESULT ********')\n    print(res.text)\n    print('--------------------------\\n')\n    print('SYNTHESIZED PYTHON CODE:')\n    print(res.final_code)", "fn_id": 6, "class_fn": false, "repo": "iwob/pysv", "file": "manual_tests.py", "last_update_at": "2018-06-11T17:28:55+00:00", "question_id": "15512953e72a4d547bc8d97d82ec169af2d846f4_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_7():\n    \"\"\"Testing the synthesis of a Python program.\"\"\"\n    code = '\\na = HOLE\\nif x != 5:\\n    a = a + 1\\nelse:\\n    a = a - 1\\n    '\n    vars = contract.ProgramVars({'x': 'Int', 'y': 'Int'}, {'a': 'Int'})\n    code_pre = 'x >= 1 and y >= 1'\n    code_post = 'a == 6*x + y'\n    grammar_spec = '\\n(\\n    ( Start Int\\n        ( ( Constant Int ) x y (+ Start Start) (* ( Constant Int ) Start) )\\n    )\\n)\\n    '\n    import pysv.templates\n    grammar = pysv.templates.load_gramar_from_SYGUS_spec(grammar_spec)\n    hole = pysv.smt_synthesis.HoleDecl('HOLE', grammar, {'x': 'Int', 'y': 'Int'}, True, max_depth=3)\n    holes_defs = {hole.id: hole}\n    res = pysv.smt_synthesis.synthesize(code, code_pre, code_post, vars, holes_defs)\n    print('******** Z3 RESULT ********')\n    print(res.text)\n    print('--------------------------\\n')\n    print('SYNTHESIZED PYTHON CODE:')\n"]]}
{"hexsha": "3e15b7f3f0991a77263001ed74033e3b858aa94f", "ext": "py", "lang": "Python", "content": "def reverse_dns(ip):\n\tif ip is not None:\n\t\ttry:\n\t\t\treturn socket.gethostbyaddr(ip)[0]\n\t\texcept socket.herror:\n\t\t\treturn None\n\telse:\n\t\treturn None", "fn_id": 1, "class_fn": false, "repo": "gossrock/the_watcher", "file": "network_tools.py", "last_update_at": "2018-06-11T18:00:29+00:00", "question_id": "3e15b7f3f0991a77263001ed74033e3b858aa94f_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def reverse_dns(ip):\n    if ip is not None:\n        try:\n            return socket.gethostbyaddr(ip)[0]\n        except socket.herror:\n            return None\n    else:\n"]]}
{"hexsha": "847c4570f6262623053abb03128f8be995e0c7a6", "ext": "py", "lang": "Python", "content": "def execute_query(queries, db_name, processed_dir=cn.DB_DIR):\n    db_file = os.path.join(processed_dir, db_name + '.db')\n    conn = sqlite3.connect(db_file)\n    cur = conn.cursor()\n    if type(queries) is list:\n        for query in queries:\n            cur.execute(query)\n    else:\n        cur.execute(queries)\n    conn.commit()\n    conn.close()", "fn_id": 1, "class_fn": false, "repo": "amandalynne/Seattle-Mobility-Index", "file": "seamo/support/data_accessor.py", "last_update_at": "2018-10-02T23:41:52+00:00", "question_id": "847c4570f6262623053abb03128f8be995e0c7a6_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def execute_query(queries, db_name, processed_dir=cn.DB_DIR):\n    db_file = os.path.join(processed_dir, db_name + '.db')\n    conn = sqlite3.connect(db_file)\n    cur = conn.cursor()\n    if type(queries) is list:\n        for query in queries:\n            cur.execute(query)\n    else:\n        cur.execute(queries)\n    conn.commit()\n"]]}
{"hexsha": "8a990c53227e57f5486eec784e7182db31b2d07f", "ext": "py", "lang": "Python", "content": "def _height_fit_fun(parameters,\n                    names,\n                    heights_dict,  # in um\n                    radius,  # in um\n                    data_dict=None,  # in units [1, nm/mV, pN/nm]\n                    errors_dict=None,  # in units [1, nm/mV, pN/nm]\n                    lateral_dict=None,\n                    method='viscosity',\n                    return_fit_dict=False,\n                    fit_dissens_osci=False,\n                    dissens_fun_kw={}):\n    \"\"\"\n    Calculate the residuals of the height-dependent fit.\n\n    If no data is given the function returns the evaluated function for the\n    given parameters.\n\n    Arguments\n    ---------\n    parameters : lmfit.Parameters\n        Parameters object holding the lmfit.Parameter objects: beta_, mbeta_,\n        kappa_, mkappa_, focal_shift, corr and h0, where \"_\" referes to the\n        names of the axes.\n    names : list of str\n        List holding the names of the axes.\n    height_dict : OrderedDict\n        Dictionary holding the height vectors for the different axes and the\n        height vector for the \"rel_drag\" to be fitted. So the following key\n        names are expected: 'kappa_x_pc', 'beta_x_pc' etc.\n    radius : float\n        Specified radius of the microsphere in micrometers\n    focal_shift : float\n    data_dict : OrderedDict\n        Dictionary of the data to be fitted with same keys as height_dict.\n    errors_dict : OrderedDict\n        Dictionary of the errors of the data to be fitted with same keys as\n        height_dict.\n    lateral : OrderedDict\n        Dictionary with same keys as height_dict refering to whether the\n        axis is in the lateral or axial direction. E.g. for 'x', 'y', 'z' and\n        'rel_drag' as names for the three axes and the drag:\n         lateral_dict = {'x': True, 'y': True, 'z': False}\n    method : str\n        Either 'viscosity' or 'radius', referes to the fitting routine used,\n        where the drag is either calculated by:\n         drag = 6 * pi * corr * eta * r * Faxen(r)\n        or\n         drag = 6 * pi * eta * corr * r * Faxen(corr * r).\n    return_fit_dict : bool\n        Return a dictionary (True) or a flattened array (False)\n    fit_dissens_osci : bool\n        Whether to try to fit oscillations on the displacement sensitivity. If\n        True, the fit will have an additional summand of the shape:\n        A * exp(d * heights) * sin( 4 * pi / (n * wavelength) * focal_shift *\n        heigths + phi).\n    dissens_fun_kw : dict\n        If fit_dissens_osci is True, this dictionary needs to be provided. It\n        holds the following key-value pairs:\n\n         - ref_ind -- refractive index\n         - wavelength -- wavelegth of the detection (trapping) laser in vacuum\n\n\n    Returns\n    -------\n    residuals : array or dict\n    \"\"\"\n    p = parameters.valuesdict()\n\n    beta_ = OrderedDict()    # value at true surface\n    mbeta_ = OrderedDict()   # slope with respect to apparent distance\n    kappa_ = OrderedDict()   # value at true surface\n    mkappa_ = OrderedDict()  # slope with respect to apparent distance\n\n    for name in names:\n        beta_[name] = p['beta_' + name]\n        mbeta_[name] = p['mbeta_' + name]\n        kappa_[name] = p['kappa_' + name]\n        mkappa_[name] = p['mkappa_' + name]\n\n    if fit_dissens_osci:\n        A_ = OrderedDict()\n        d_ = OrderedDict()\n        phi_ = OrderedDict()\n        for name in names:\n            A_[name] = p['A_' + name]\n            d_[name] = p['d_' + name]\n            phi_[name] = p['phi_' + name]\n\n    rel_drag = _rel_drag_fit_fun(parameters,\n                                 heights_dict['rel_drag'],\n                                 radius,\n                                 lateral=lateral_dict['rel_drag'],\n                                 method=method)\n\n    model_ = [list(rel_drag)]\n    model_dict = OrderedDict()\n    model_dict['rel_drag'] = rel_drag\n\n    for name in names:\n        if fit_dissens_osci:\n            dissens_fun_kw['A'] = A_[name]\n            dissens_fun_kw['d'] = d_[name]\n            dissens_fun_kw['phi'] = phi_[name]\n\n        dissens = _dissens_fit_fun(parameters,\n                                   heights_dict['beta_' + name + '_pc'],\n                                   beta_[name],\n                                   mbeta_[name],\n                                   radius,\n                                   lateral=lateral_dict[name],\n                                   method=method,\n                                   fit_osci=fit_dissens_osci,\n                                   fun_kw=dissens_fun_kw)\n        model_.append(dissens)\n        model_dict['beta_' + name + '_pc'] = dissens\n\n        kappa = _kappa_fit_fun(parameters,\n                               heights_dict['kappa_' + name + '_pc'],\n                               kappa_[name],\n                               mkappa_[name],\n                               radius,\n                               lateral=lateral_dict[name],\n                               method=method)\n        model_.append(kappa)\n        model_dict['kappa_' + name + '_pc'] = kappa\n\n    result_flat = array(list(flatten_list(model_)))\n\n    if not return_fit_dict:\n        if data_dict is None:\n            return result_flat\n\n        data_ = [data_dict['rel_drag']]\n        for name in names:\n            data_.append(data_dict['beta_' + name + '_pc'])\n            data_.append(data_dict['kappa_' + name + '_pc'])\n        data_flat = array(list(flatten_list(data_)))\n\n        if errors_dict is None:\n            return (data_flat - result_flat)\n        else:\n            err_ = [errors_dict['rel_drag']]\n            for name in names:\n                err_.append(errors_dict['beta_' + name + '_pc'])\n                err_.append(errors_dict['kappa_' + name + '_pc'])\n            err_flat = array(list(flatten_list(err_)))\n            return ((data_flat - result_flat) / err_flat)\n    else:\n        if data_dict is None:\n            return model_dict\n\n        result = OrderedDict()\n        if errors_dict is None:\n            for k, data in data_dict.items():\n                result[k] = data - model_dict[k]\n            return result\n        else:\n            for k, data in data_dict.items():\n                result[k] = ((data - model_dict[k]) / errors_dict[k])\n            return result", "fn_id": 6, "class_fn": false, "repo": "cellular-nanoscience/pyotic", "file": "pyotc/height_calibration.py", "last_update_at": "2018-06-12T11:46:54+00:00", "question_id": "8a990c53227e57f5486eec784e7182db31b2d07f_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _height_fit_fun(parameters, names, heights_dict, radius, data_dict=None, errors_dict=None, lateral_dict=None, method='viscosity', return_fit_dict=False, fit_dissens_osci=False, dissens_fun_kw={}):\n    \"\"\"\n    Calculate the residuals of the height-dependent fit.\n\n    If no data is given the function returns the evaluated function for the\n    given parameters.\n\n    Arguments\n    ---------\n    parameters : lmfit.Parameters\n        Parameters object holding the lmfit.Parameter objects: beta_, mbeta_,\n        kappa_, mkappa_, focal_shift, corr and h0, where \"_\" referes to the\n        names of the axes.\n    names : list of str\n        List holding the names of the axes.\n    height_dict : OrderedDict\n        Dictionary holding the height vectors for the different axes and the\n        height vector for the \"rel_drag\" to be fitted. So the following key\n        names are expected: 'kappa_x_pc', 'beta_x_pc' etc.\n    radius : float\n        Specified radius of the microsphere in micrometers\n    focal_shift : float\n    data_dict : OrderedDict\n        Dictionary of the data to be fitted with same keys as height_dict.\n    errors_dict : OrderedDict\n        Dictionary of the errors of the data to be fitted with same keys as\n        height_dict.\n    lateral : OrderedDict\n        Dictionary with same keys as height_dict refering to whether the\n        axis is in the lateral or axial direction. E.g. for 'x', 'y', 'z' and\n        'rel_drag' as names for the three axes and the drag:\n         lateral_dict = {'x': True, 'y': True, 'z': False}\n    method : str\n        Either 'viscosity' or 'radius', referes to the fitting routine used,\n        where the drag is either calculated by:\n         drag = 6 * pi * corr * eta * r * Faxen(r)\n        or\n         drag = 6 * pi * eta * corr * r * Faxen(corr * r).\n    return_fit_dict : bool\n        Return a dictionary (True) or a flattened array (False)\n    fit_dissens_osci : bool\n        Whether to try to fit oscillations on the displacement sensitivity. If\n        True, the fit will have an additional summand of the shape:\n        A * exp(d * heights) * sin( 4 * pi / (n * wavelength) * focal_shift *\n        heigths + phi).\n    dissens_fun_kw : dict\n        If fit_dissens_osci is True, this dictionary needs to be provided. It\n        holds the following key-value pairs:\n\n         - ref_ind -- refractive index\n         - wavelength -- wavelegth of the detection (trapping) laser in vacuum\n\n\n    Returns\n    -------\n    residuals : array or dict\n    \"\"\"\n    p = parameters.valuesdict()\n    beta_ = OrderedDict()\n    mbeta_ = OrderedDict()\n    kappa_ = OrderedDict()\n    mkappa_ = OrderedDict()\n    for name in names:\n        beta_[name] = p['beta_' + name]\n        mbeta_[name] = p['mbeta_' + name]\n        kappa_[name] = p['kappa_' + name]\n        mkappa_[name] = p['mkappa_' + name]\n    if fit_dissens_osci:\n        A_ = OrderedDict()\n        d_ = OrderedDict()\n        phi_ = OrderedDict()\n        for name in names:\n            A_[name] = p['A_' + name]\n            d_[name] = p['d_' + name]\n            phi_[name] = p['phi_' + name]\n    rel_drag = _rel_drag_fit_fun(parameters, heights_dict['rel_drag'], radius, lateral=lateral_dict['rel_drag'], method=method)\n    model_ = [list(rel_drag)]\n    model_dict = OrderedDict()\n    model_dict['rel_drag'] = rel_drag\n    for name in names:\n        if fit_dissens_osci:\n            dissens_fun_kw['A'] = A_[name]\n            dissens_fun_kw['d'] = d_[name]\n            dissens_fun_kw['phi'] = phi_[name]\n        dissens = _dissens_fit_fun(parameters, heights_dict['beta_' + name + '_pc'], beta_[name], mbeta_[name], radius, lateral=lateral_dict[name], method=method, fit_osci=fit_dissens_osci, fun_kw=dissens_fun_kw)\n        model_.append(dissens)\n        model_dict['beta_' + name + '_pc'] = dissens\n        kappa = _kappa_fit_fun(parameters, heights_dict['kappa_' + name + '_pc'], kappa_[name], mkappa_[name], radius, lateral=lateral_dict[name], method=method)\n        model_.append(kappa)\n        model_dict['kappa_' + name + '_pc'] = kappa\n    result_flat = array(list(flatten_list(model_)))\n    if not return_fit_dict:\n        if data_dict is None:\n            return result_flat\n        data_ = [data_dict['rel_drag']]\n        for name in names:\n            data_.append(data_dict['beta_' + name + '_pc'])\n            data_.append(data_dict['kappa_' + name + '_pc'])\n        data_flat = array(list(flatten_list(data_)))\n        if errors_dict is None:\n            return data_flat - result_flat\n        else:\n            err_ = [errors_dict['rel_drag']]\n            for name in names:\n                err_.append(errors_dict['beta_' + name + '_pc'])\n                err_.append(errors_dict['kappa_' + name + '_pc'])\n            err_flat = array(list(flatten_list(err_)))\n            return (data_flat - result_flat) / err_flat\n    else:\n        if data_dict is None:\n            return model_dict\n        result = OrderedDict()\n        if errors_dict is None:\n            for k, data in data_dict.items():\n                result[k] = data - model_dict[k]\n            return result\n        else:\n            for k, data in data_dict.items():\n                result[k] = (data - model_dict[k]) / errors_dict[k]\n"]]}
{"hexsha": "78cf1de4bc0b30f7af3b0ec998ebcd26ffff3102", "ext": "py", "lang": "Python", "content": "@app.route('/upload', methods=['GET', 'POST'])\ndef upload_file():\n\t# curl -F \"filename=@/tmp/abc.txt\" http://127.0.0.1:5000/upload\n    if request.method == 'POST':\n        f = request.files['filename']\n        f.save('/tmp/' + secure_filename(f.filename))", "fn_id": 0, "class_fn": false, "repo": "all3g/pieces", "file": "flask/flask-File_Uploads.py", "last_update_at": "2018-11-08T14:33:13+00:00", "question_id": "78cf1de4bc0b30f7af3b0ec998ebcd26ffff3102_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@app.route('/upload', methods=['GET', 'POST'])\ndef upload_file():\n    if request.method == 'POST':\n        f = request.files['filename']\n"]]}
{"hexsha": "2e35e9946a5e52b471300f5be0dd7b5ee6330705", "ext": "py", "lang": "Python", "content": "def crosscorr1(img, refim, shrange, dsh=(1,1)):\n\t\"\"\"\n\tCalculate cross-correlation for only 1 image. See crosscorr() for \n\tdetails.\n\t\"\"\"\n\n\tif (img.shape != refim.shape):\n\t\traise ValueError(\"<refim> should be same size as <img>\")\n\n\tsh0, sh1 = shrange\n\tdsh0, dsh1 = dsh\n\timsz0, imsz1 = img.shape\n\n\t# Shift ranges need to be larger than 0\n\tif (sh0 < 1 or sh1 < 1):\n\t\traise ValueError(\"<shrange> should be larger than 0\")\n\n\t# We need a crop window to allow for image shifting\n\tsm_crop = [slice(sh0, -sh0), slice(sh1, -sh1)]\n\n\t# Calculate correlation for img with <refim>\n\txcorr = np.r_[ [[\n\t\tnp.sum(refim[sh0+shi:imsz0-sh0+shi, sh1+shj:imsz1-sh1+shj] * img[sm_crop])\n\t\tfor shj in xrange(-sh1, sh1+1, dsh1)]\n\t\t\tfor shi in xrange(-sh0, sh0+1, dsh0)]\n\t\t\t\t] # // np.r_\n\n\treturn xcorr", "fn_id": 1, "class_fn": false, "repo": "jmilou/image_utilities", "file": "xcorr.py", "last_update_at": "2018-01-08T19:24:32+00:00", "question_id": "2e35e9946a5e52b471300f5be0dd7b5ee6330705_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def crosscorr1(img, refim, shrange, dsh=(1, 1)):\n    \"\"\"\n\tCalculate cross-correlation for only 1 image. See crosscorr() for \n\tdetails.\n\t\"\"\"\n    if img.shape != refim.shape:\n        raise ValueError('<refim> should be same size as <img>')\n    sh0, sh1 = shrange\n    dsh0, dsh1 = dsh\n    imsz0, imsz1 = img.shape\n    if sh0 < 1 or sh1 < 1:\n        raise ValueError('<shrange> should be larger than 0')\n    sm_crop = [slice(sh0, -sh0), slice(sh1, -sh1)]\n    xcorr = np.r_[[[np.sum(refim[sh0 + shi:imsz0 - sh0 + shi, sh1 + shj:imsz1 - sh1 + shj] * img[sm_crop]) for shj in xrange(-sh1, sh1 + 1, dsh1)] for shi in xrange(-sh0, sh0 + 1, dsh0)]]\n"]]}
{"hexsha": "3ef0fddaaa76a4ae827f0e7576220719084d5b5a", "ext": "py", "lang": "Python", "content": "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n    abs_sobelx = np.absolute(sobelx)\n    abs_sobely = np.absolute(sobely)\n    absgraddir = np.arctan2(abs_sobely, abs_sobelx)\n    binary_output = np.zeros_like(absgraddir)\n    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n    return binary_output", "fn_id": 11, "class_fn": false, "repo": "rajeshb/SelfDrivingCar", "file": "T1P4-Advanced-Lane-Lines/image_functions.py", "last_update_at": "2018-02-18T13:04:16+00:00", "question_id": "3ef0fddaaa76a4ae827f0e7576220719084d5b5a_11", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi / 2)):\n    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n    abs_sobelx = np.absolute(sobelx)\n    abs_sobely = np.absolute(sobely)\n    absgraddir = np.arctan2(abs_sobely, abs_sobelx)\n    binary_output = np.zeros_like(absgraddir)\n    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n"]]}
{"hexsha": "21bf5be63116fa725f3351ed4123e8717c4be72c", "ext": "py", "lang": "Python", "content": "def shuffle(x):\n    x = list(x)\n    random.shuffle(x)\n    return x", "fn_id": 4, "class_fn": false, "repo": "kamei86i/rnn-classifier-tf", "file": "train.py", "last_update_at": "2018-07-27T00:05:22+00:00", "question_id": "21bf5be63116fa725f3351ed4123e8717c4be72c_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def shuffle(x):\n    x = list(x)\n    random.shuffle(x)\n"]]}
{"hexsha": "4a9ac355e66dc0b60f30842b6284cbe1ced8a8c1", "ext": "py", "lang": "Python", "content": "def get_stats(df):\n    statDF = pd.DataFrame(index=[0])\n    statDF[\"totalNumberCBGValues\"] = df.mg_dL.count()\n\n    statDF[\"mean_mgdL\"] = df.mg_dL.mean()\n    statDF[\"std_mgdL\"] = df.mg_dL.std()\n    statDF[\"cov_mgdL\"] = statDF[\"std_mgdL\"] / statDF[\"mean_mgdL\"]\n\n    statDF[\"totalBelow54\"] = sum(df.mg_dL < 54)\n    statDF[\"totalBelow70\"] = sum(df.mg_dL < 70)\n    statDF[\"total54to70\"] = sum((df.mg_dL >= 54) & (df.mg_dL < 70))\n    statDF[\"total70to140\"] = sum((df.mg_dL >= 70) & (df.mg_dL <= 140))\n    statDF[\"total70to180\"] = sum((df.mg_dL >= 70) & (df.mg_dL <= 180))\n    statDF[\"total180to250\"] = sum((df.mg_dL > 180) & (df.mg_dL <= 250))\n    statDF[\"totalAbove180\"] = sum(df.mg_dL > 180)\n    statDF[\"totalAbove250\"] = sum(df.mg_dL > 250)\n\n    statDF[\"percentBelow54\"] = statDF[\"totalBelow54\"] / statDF[\"totalNumberCBGValues\"]\n    statDF[\"percentBelow70\"] = statDF[\"totalBelow70\"] / statDF[\"totalNumberCBGValues\"]\n    statDF[\"percent70to140\"] = statDF[\"total70to140\"] / statDF[\"totalNumberCBGValues\"]\n    statDF[\"percent70to180\"] = statDF[\"total70to180\"] / statDF[\"totalNumberCBGValues\"]\n    statDF[\"percentAbove180\"] = statDF[\"totalAbove180\"] / statDF[\"totalNumberCBGValues\"]\n    statDF[\"percentAbove250\"] = statDF[\"totalAbove250\"]  / statDF[\"totalNumberCBGValues\"]\n\n    statDF[\"min_mgdL\"] = df.mg_dL.min()\n    statDF[\"median_mgdL\"] = df.mg_dL.describe()[\"50%\"]\n    statDF[\"max_mgdL\"] = df.mg_dL.max()\n\n    # calculate the start and end time of the cbg data\n    startTime = df[\"localTime\"].min()\n    statDF[\"startTime\"] = startTime\n    endTime = df[\"localTime\"].max()\n    statDF[\"endTime\"] = endTime\n    statDF[\"totalNumberPossibleCBGvalues\"] = len(pd.date_range(startTime, endTime, freq=\"5min\"))\n\n    # feedback criteria\n    # A.  incomplete dataset\n    statDF[\"percentOfExpectedData\"] = \\\n        (((endTime - startTime).days * 86400) +\n         ((endTime - startTime).seconds)) / (86400 - (5*60))\n\n    if statDF.loc[0, \"percentOfExpectedData\"] < 0.834:  # greater than 4 hours of expected data\n        statDF[\"GTE4hoursNoCgmSignal\"] = \"NA\"\n        statDF[\"incompleteDataset\"] = \"FLAG (\" + \\\n            str(round(statDF.loc[0, \"percentOfExpectedData\"] * 100, 1)) + \"%)\"\n    else:\n        statDF[\"incompleteDataset\"] = np.nan\n\n        # 1.  >=4 hours without CGM signal\n        missingCgm = statDF[\"totalNumberPossibleCBGvalues\"] - statDF[\"totalNumberCBGValues\"]\n        if missingCgm[0] > (4 * 60 / 5):\n            statDF[\"GTE4hoursNoCgmSignal\"] = \"FLAG\"\n        else:\n            statDF[\"GTE4hoursNoCgmSignal\"] = np.nan\n\n    # 2.  >= 2 hours 54 <= BG < 70 mg/dl\n    if statDF.loc[0, \"total54to70\"] > (2 * 60 / 5):\n        statDF[\"GTE2hoursBetween54to70\"] = \\\n            \"FLAG (\" + str(round(statDF.loc[0, \"total54to70\"] * 5)) + \"min)\"\n    else:\n        statDF[\"GTE2hoursBetween54to70\"] = np.nan\n\n    # 3.  >= 15 minutes < 54 mg/dl\"\n    if statDF.loc[0, \"totalBelow54\"] > (15 / 5):\n        statDF[\"GTE15minBelow54\"] = \"FLAG (\" + str(round(statDF.loc[0, \"totalBelow54\"] * 5)) + \"min)\"\n    else:\n        statDF[\"GTE15minBelow54\"] = np.nan\n\n    return statDF", "fn_id": 0, "class_fn": false, "repo": "usf-mshi/data-analytics", "file": "projects/clinician-insights/daily-feedback.py", "last_update_at": "2018-12-04T22:02:06+00:00", "question_id": "4a9ac355e66dc0b60f30842b6284cbe1ced8a8c1_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_stats(df):\n    statDF = pd.DataFrame(index=[0])\n    statDF['totalNumberCBGValues'] = df.mg_dL.count()\n    statDF['mean_mgdL'] = df.mg_dL.mean()\n    statDF['std_mgdL'] = df.mg_dL.std()\n    statDF['cov_mgdL'] = statDF['std_mgdL'] / statDF['mean_mgdL']\n    statDF['totalBelow54'] = sum(df.mg_dL < 54)\n    statDF['totalBelow70'] = sum(df.mg_dL < 70)\n    statDF['total54to70'] = sum((df.mg_dL >= 54) & (df.mg_dL < 70))\n    statDF['total70to140'] = sum((df.mg_dL >= 70) & (df.mg_dL <= 140))\n    statDF['total70to180'] = sum((df.mg_dL >= 70) & (df.mg_dL <= 180))\n    statDF['total180to250'] = sum((df.mg_dL > 180) & (df.mg_dL <= 250))\n    statDF['totalAbove180'] = sum(df.mg_dL > 180)\n    statDF['totalAbove250'] = sum(df.mg_dL > 250)\n    statDF['percentBelow54'] = statDF['totalBelow54'] / statDF['totalNumberCBGValues']\n    statDF['percentBelow70'] = statDF['totalBelow70'] / statDF['totalNumberCBGValues']\n    statDF['percent70to140'] = statDF['total70to140'] / statDF['totalNumberCBGValues']\n    statDF['percent70to180'] = statDF['total70to180'] / statDF['totalNumberCBGValues']\n    statDF['percentAbove180'] = statDF['totalAbove180'] / statDF['totalNumberCBGValues']\n    statDF['percentAbove250'] = statDF['totalAbove250'] / statDF['totalNumberCBGValues']\n    statDF['min_mgdL'] = df.mg_dL.min()\n    statDF['median_mgdL'] = df.mg_dL.describe()['50%']\n    statDF['max_mgdL'] = df.mg_dL.max()\n    startTime = df['localTime'].min()\n    statDF['startTime'] = startTime\n    endTime = df['localTime'].max()\n    statDF['endTime'] = endTime\n    statDF['totalNumberPossibleCBGvalues'] = len(pd.date_range(startTime, endTime, freq='5min'))\n    statDF['percentOfExpectedData'] = ((endTime - startTime).days * 86400 + (endTime - startTime).seconds) / (86400 - 5 * 60)\n    if statDF.loc[0, 'percentOfExpectedData'] < 0.834:\n        statDF['GTE4hoursNoCgmSignal'] = 'NA'\n        statDF['incompleteDataset'] = 'FLAG (' + str(round(statDF.loc[0, 'percentOfExpectedData'] * 100, 1)) + '%)'\n    else:\n        statDF['incompleteDataset'] = np.nan\n        missingCgm = statDF['totalNumberPossibleCBGvalues'] - statDF['totalNumberCBGValues']\n        if missingCgm[0] > 4 * 60 / 5:\n            statDF['GTE4hoursNoCgmSignal'] = 'FLAG'\n        else:\n            statDF['GTE4hoursNoCgmSignal'] = np.nan\n    if statDF.loc[0, 'total54to70'] > 2 * 60 / 5:\n        statDF['GTE2hoursBetween54to70'] = 'FLAG (' + str(round(statDF.loc[0, 'total54to70'] * 5)) + 'min)'\n    else:\n        statDF['GTE2hoursBetween54to70'] = np.nan\n    if statDF.loc[0, 'totalBelow54'] > 15 / 5:\n        statDF['GTE15minBelow54'] = 'FLAG (' + str(round(statDF.loc[0, 'totalBelow54'] * 5)) + 'min)'\n    else:\n        statDF['GTE15minBelow54'] = np.nan\n"]]}
{"hexsha": "04f0cac2861b26994ed2dd31f456ed53f4772036", "ext": "py", "lang": "Python", "content": "def s3_copy(target_bucket, source, region):\n    \"\"\"\n    Executes S3 copy operation.\n\n    Args:\n        target_bucket (str): Name of S3 bucket.\n        source (dict): Identify source cuboid, keys: 'Bucket', 'Key'.\n        region (str): AWS region.\n    \"\"\"\n\n    # Append version (always 0 particularly since we're copying to a new\n    # channel.\n    versioned_key = '{}&0'.format(source['Key'])\n\n    s3 = boto3.client('s3', region_name=region)\n    s3.copy_object(\n        Bucket=target_bucket,\n        CopySource=source,\n        Key=versioned_key\n    )", "fn_id": 2, "class_fn": false, "repo": "jhuapl-boss/boss-tools", "file": "lambda/cuboid_import_lambda.py", "last_update_at": "2018-08-04T21:57:34+00:00", "question_id": "04f0cac2861b26994ed2dd31f456ed53f4772036_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def s3_copy(target_bucket, source, region):\n    \"\"\"\n    Executes S3 copy operation.\n\n    Args:\n        target_bucket (str): Name of S3 bucket.\n        source (dict): Identify source cuboid, keys: 'Bucket', 'Key'.\n        region (str): AWS region.\n    \"\"\"\n    versioned_key = '{}&0'.format(source['Key'])\n    s3 = boto3.client('s3', region_name=region)\n"]]}
{"hexsha": "6e4673b7d92e5792fda28b6efd0785c3de795621", "ext": "py", "lang": "Python", "content": "def xenstore_list(path, client):\n    result = []\n    if client is None:\n        p = Popen(\n            ['xenstore-ls', path],\n            stdout=PIPE,\n            stderr=PIPE\n        )\n        out, _ = p.communicate()\n        if p.returncode == 0:\n            decoded_out = out.decode('utf-8').split('\\n')\n            result = [\n                item.split(' = ')[0] for item in decoded_out if item\n            ]\n    else:\n        for item in client.list(path):\n            result.append(item.decode('utf-8').strip())\n\n    return result", "fn_id": 1, "class_fn": false, "repo": "JourdanClark/nova-agent", "file": "novaagent/xenstore/xenstore.py", "last_update_at": "2018-01-24T21:40:15+00:00", "question_id": "6e4673b7d92e5792fda28b6efd0785c3de795621_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def xenstore_list(path, client):\n    result = []\n    if client is None:\n        p = Popen(['xenstore-ls', path], stdout=PIPE, stderr=PIPE)\n        out, _ = p.communicate()\n        if p.returncode == 0:\n            decoded_out = out.decode('utf-8').split('\\n')\n            result = [item.split(' = ')[0] for item in decoded_out if item]\n    else:\n        for item in client.list(path):\n            result.append(item.decode('utf-8').strip())\n"]]}
{"hexsha": "4ecb5eff00676edae80b7e1b8c995053e5236cf4", "ext": "py", "lang": "Python", "content": "def _write_header(path,H):\n    f=open(path,\"wb\")\n    try:\n        _write_int32(f,H.dt_code)\n        _write_int32(f,H.num_bytes_per_entry)\n        if H.uses64bitdims:\n            _write_int32(f,-H.num_dims)\n            for j in range(0,H.num_dims):\n                _write_int64(f,H.dims[j])\n        else:\n            _write_int32(f,H.num_dims)\n            for j in range(0,H.num_dims):\n                _write_int32(f,H.dims[j])\n        f.close()\n        return True\n    except Exception as e: # catch *all* exceptions\n        print (e)\n        f.close()\n        return False", "fn_id": 4, "class_fn": false, "repo": "gentnerlab/klusta-pipeline", "file": "klusta_pipeline/mdaio.py", "last_update_at": "2018-08-21T16:17:13+00:00", "question_id": "4ecb5eff00676edae80b7e1b8c995053e5236cf4_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _write_header(path, H):\n    f = open(path, 'wb')\n    try:\n        _write_int32(f, H.dt_code)\n        _write_int32(f, H.num_bytes_per_entry)\n        if H.uses64bitdims:\n            _write_int32(f, -H.num_dims)\n            for j in range(0, H.num_dims):\n                _write_int64(f, H.dims[j])\n        else:\n            _write_int32(f, H.num_dims)\n            for j in range(0, H.num_dims):\n                _write_int32(f, H.dims[j])\n        f.close()\n        return True\n    except Exception as e:\n        print(e)\n        f.close()\n"]]}
{"hexsha": "c36f8c525a000406e0290ecf19216cdc6f1d20b7", "ext": "py", "lang": "Python", "content": "def jsonResponse(f):\n    \"\"\"\n    Decorator that converts a route() return value into a JSON-formatted\n    string and sets the appropriate content-type and other request values (if\n    necessary).\n    If f returns a deferred, return a deferred.\n    \"\"\"\n    @wraps(f)\n    def wrapper(self, request, *a, **kw):\n        request.setHeader(\"Content-Type\", \"application/json\")\n        request.setHeader(\"Expires\", \"-1\") # IE caches way too much\n        payload = request.content.read()\n        if payload:\n            request.payload = json.loads(payload)\n        d = defer.maybeDeferred(f, self, request, *a, **kw)\n        d.addCallback(json.dumps, indent=2)\n        return d\n    return wrapper", "fn_id": 0, "class_fn": false, "repo": "corydodt/SupperFeed", "file": "supperfeed/server.py", "last_update_at": "2018-02-27T12:39:54+00:00", "question_id": "c36f8c525a000406e0290ecf19216cdc6f1d20b7_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def jsonResponse(f):\n    \"\"\"\n    Decorator that converts a route() return value into a JSON-formatted\n    string and sets the appropriate content-type and other request values (if\n    necessary).\n    If f returns a deferred, return a deferred.\n    \"\"\"\n\n    @wraps(f)\n    def wrapper(self, request, *a, **kw):\n        request.setHeader('Content-Type', 'application/json')\n        request.setHeader('Expires', '-1')\n        payload = request.content.read()\n        if payload:\n            request.payload = json.loads(payload)\n        d = defer.maybeDeferred(f, self, request, *a, **kw)\n        d.addCallback(json.dumps, indent=2)\n        return d\n"]]}
{"hexsha": "aba991ef9af9032eec6e066ebc3aa37ebcf824df", "ext": "py", "lang": "Python", "content": "def _get_ambient_temps(temps: List[float]) -> Dict[subsystems.TecUnit, float]:\n    \"\"\"Get (and judge) ambient temp readings for TEC operation.\n\n    :returns: Dict of two temperatures to use for SHGs and MIOB. VHBG has no \"ambient\".\n    :raises ConnectionError: Temperature readings are not consistent.\n    :raises ValueError: At least one ambient temp is out of safe bounds for the\n                respective component.\n    \"\"\"\n    assert len(temps) == len(subsystems.AuxTemp)\n    ambient = {}  # type: Dict[subsystems.TecUnit, float]\n\n    # MiOB\n    candidate = temps[subsystems.AuxTemp.HEATSINK_A]\n    second = temps[subsystems.AuxTemp.HEATSINK_B]\n    if abs(candidate - second) > cs.TEMP_LASER_TRAY_DELTA:\n        raise ConnectionError(\"Erroneous laser tray temp reading {}.\".format(candidate))\n    if (candidate < cs.TEMP_HEATSINK_RANGE_LASER[0]\n            or candidate > cs.TEMP_HEATSINK_RANGE_LASER[1]):\n        raise ValueError(\"Laser tray temperature {} out of safe range.\".format(candidate))\n    ambient[subsystems.TecUnit.MIOB] = candidate\n\n    # SHGs\n    candidate = temps[subsystems.AuxTemp.SHG]\n    second = temps[subsystems.AuxTemp.CELL]\n    if abs(candidate - second) > cs.TEMP_SPEC_TRAY_DELTA:\n        raise ConnectionError(\"Erroneous spec tray temp reading {}\".format(candidate))\n    if (candidate < cs.TEMP_HEATSINK_RANGE_SPEC[0]\n            or candidate > cs.TEMP_HEATSINK_RANGE_SPEC[1]):\n        raise ValueError(\"Spec tray temperature {} out of safe range.\".format(candidate))\n    ambient[subsystems.TecUnit.SHGA] = candidate\n    ambient[subsystems.TecUnit.SHGB] = candidate\n\n    return ambient", "fn_id": 16, "class_fn": false, "repo": "trimitri/jokarus", "file": "pyodine/controller/procedures.py", "last_update_at": "2018-10-29T00:18:50+00:00", "question_id": "aba991ef9af9032eec6e066ebc3aa37ebcf824df_16", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _get_ambient_temps(temps: List[float]) -> Dict[subsystems.TecUnit, float]:\n    \"\"\"Get (and judge) ambient temp readings for TEC operation.\n\n    :returns: Dict of two temperatures to use for SHGs and MIOB. VHBG has no \"ambient\".\n    :raises ConnectionError: Temperature readings are not consistent.\n    :raises ValueError: At least one ambient temp is out of safe bounds for the\n                respective component.\n    \"\"\"\n    assert len(temps) == len(subsystems.AuxTemp)\n    ambient = {}\n    candidate = temps[subsystems.AuxTemp.HEATSINK_A]\n    second = temps[subsystems.AuxTemp.HEATSINK_B]\n    if abs(candidate - second) > cs.TEMP_LASER_TRAY_DELTA:\n        raise ConnectionError('Erroneous laser tray temp reading {}.'.format(candidate))\n    if candidate < cs.TEMP_HEATSINK_RANGE_LASER[0] or candidate > cs.TEMP_HEATSINK_RANGE_LASER[1]:\n        raise ValueError('Laser tray temperature {} out of safe range.'.format(candidate))\n    ambient[subsystems.TecUnit.MIOB] = candidate\n    candidate = temps[subsystems.AuxTemp.SHG]\n    second = temps[subsystems.AuxTemp.CELL]\n    if abs(candidate - second) > cs.TEMP_SPEC_TRAY_DELTA:\n        raise ConnectionError('Erroneous spec tray temp reading {}'.format(candidate))\n    if candidate < cs.TEMP_HEATSINK_RANGE_SPEC[0] or candidate > cs.TEMP_HEATSINK_RANGE_SPEC[1]:\n        raise ValueError('Spec tray temperature {} out of safe range.'.format(candidate))\n    ambient[subsystems.TecUnit.SHGA] = candidate\n    ambient[subsystems.TecUnit.SHGB] = candidate\n"]]}
{"hexsha": "229479105143b94f443c7ad689bedda1c1ec27e1", "ext": "py", "lang": "Python", "content": "def powerlaw_sequence(n,exponent=2.0):\n    \"\"\"\n    Return sample sequence of length n from a power law distribution.\n    \"\"\"\n    return [random.paretovariate(exponent-1) for i in range(n)]", "fn_id": 2, "class_fn": false, "repo": "tempcyc/networkx", "file": "networkx/utils/random_sequence.py", "last_update_at": "2018-08-09T14:29:43+00:00", "question_id": "229479105143b94f443c7ad689bedda1c1ec27e1_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def powerlaw_sequence(n, exponent=2.0):\n    \"\"\"\n    Return sample sequence of length n from a power law distribution.\n    \"\"\"\n"]]}
{"hexsha": "4dcd098102ec7daa0dcea3fff0f2d244b5d66970", "ext": "py", "lang": "Python", "content": "@pytest.mark.parametrize(\n    \"encoding, mapping\",\n    (\n        (b\"\\x00\\xc0\", {0: 0}),\n        (\n            b\"\\x00\\xce\\xcd\\x83\\x13\\x88\\xf9\\x88\\x1b\\xc1mgN\\xc8\\x00\\x00\",\n            {0: 0, token_id_encode(\"QETH\"): int(2e18)},\n        ),\n        (\n            b\"\\x00\\xcf\\xce\\x83\\x13\\x88\\xf9\\x89\\x1e?\\xce;\\x96\\xdb\\xf8\\x00\\x00\",\n            {0: 0, token_id_encode(\"QETH\"): int(558e18), token_id_encode(\"QETC\"): 0},\n        ),\n        (\n            b\"\\x00\\xce\\xcd\\x83\\x13\\x88\\xf9\\x88)\\xa2$\\x1a\\xf6,\\x00\\x00\",\n            {\n                0: 0,\n                token_id_encode(\"QETH\"): int(3e18),\n                token_id_encode(\"QETC\"): 0,\n                token_id_encode(\"QA\"): 0,\n                token_id_encode(\"QB\"): 0,\n                token_id_encode(\"QC\"): 0,\n                token_id_encode(\"QD\"): 0,\n                token_id_encode(\"QE\"): 0,\n                token_id_encode(\"QF\"): 0,\n                token_id_encode(\"QG\"): 0,\n                token_id_encode(\"QH\"): 0,\n                token_id_encode(\"QI\"): 0,\n                token_id_encode(\"QJ\"): 0,\n                token_id_encode(\"QK\"): 0,\n                token_id_encode(\"QL\"): 0,\n                token_id_encode(\"QM\"): 0,\n            },\n        ),\n    ),\n)\ndef test_encode_zero_balance(encoding, mapping):\n    # starting from blank account\n    b0 = TokenBalances(b\"\", InMemoryDb())\n    for k, v in mapping.items():\n        b0.balances[k] = v\n    assert b0.balances == mapping\n    assert b0.serialize() == encoding\n\n    # starting from RLP encoding\n    b1 = TokenBalances(encoding, InMemoryDb())\n    assert b1.balances == {k: v for k, v in mapping.items() if v != 0}\n    if b1.balances:\n        assert b1.serialize() == encoding\n    else:\n        assert b1.serialize() == b\"\"", "fn_id": 2, "class_fn": false, "repo": "HAOYUatHZ/pyquarkchain", "file": "quarkchain/evm/tests/test_token_balances.py", "last_update_at": "2018-10-23T05:48:42+00:00", "question_id": "4dcd098102ec7daa0dcea3fff0f2d244b5d66970_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.mark.parametrize('encoding, mapping', ((b'\\x00\\xc0', {0: 0}), (b'\\x00\\xce\\xcd\\x83\\x13\\x88\\xf9\\x88\\x1b\\xc1mgN\\xc8\\x00\\x00', {0: 0, token_id_encode('QETH'): int(2e+18)}), (b'\\x00\\xcf\\xce\\x83\\x13\\x88\\xf9\\x89\\x1e?\\xce;\\x96\\xdb\\xf8\\x00\\x00', {0: 0, token_id_encode('QETH'): int(5.58e+20), token_id_encode('QETC'): 0}), (b'\\x00\\xce\\xcd\\x83\\x13\\x88\\xf9\\x88)\\xa2$\\x1a\\xf6,\\x00\\x00', {0: 0, token_id_encode('QETH'): int(3e+18), token_id_encode('QETC'): 0, token_id_encode('QA'): 0, token_id_encode('QB'): 0, token_id_encode('QC'): 0, token_id_encode('QD'): 0, token_id_encode('QE'): 0, token_id_encode('QF'): 0, token_id_encode('QG'): 0, token_id_encode('QH'): 0, token_id_encode('QI'): 0, token_id_encode('QJ'): 0, token_id_encode('QK'): 0, token_id_encode('QL'): 0, token_id_encode('QM'): 0})))\ndef test_encode_zero_balance(encoding, mapping):\n    b0 = TokenBalances(b'', InMemoryDb())\n    for k, v in mapping.items():\n        b0.balances[k] = v\n    assert b0.balances == mapping\n    assert b0.serialize() == encoding\n    b1 = TokenBalances(encoding, InMemoryDb())\n    assert b1.balances == {k: v for k, v in mapping.items() if v != 0}\n    if b1.balances:\n        assert b1.serialize() == encoding\n    else:\n"]]}
{"hexsha": "ecfde9906977a8aed79ef1b62e6ce752015cdf56", "ext": "py", "lang": "Python", "content": "def gcm_send_message(device, message, data=None, collapse_key=None, delay_while_idle=False, time_to_live=0):\n    \"\"\"\n    Sends a GCM notification to a single registration_id.\n\n    This will send the notification as form data if possible, otherwise it will\n    fall back to json data.\n    \"\"\"\n    data[\"message\"] = message\n    args = data, collapse_key, delay_while_idle, time_to_live\n    try:\n        return _gcm_send_plain(device, *args)\n    except GCMError:\n        # TODO: check error and maybe deactivate user\n        return False", "fn_id": 2, "class_fn": false, "repo": "wasimafser/universal_notifications", "file": "universal_notifications/backends/push/gcm.py", "last_update_at": "2018-11-02T18:16:32+00:00", "question_id": "ecfde9906977a8aed79ef1b62e6ce752015cdf56_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def gcm_send_message(device, message, data=None, collapse_key=None, delay_while_idle=False, time_to_live=0):\n    \"\"\"\n    Sends a GCM notification to a single registration_id.\n\n    This will send the notification as form data if possible, otherwise it will\n    fall back to json data.\n    \"\"\"\n    data['message'] = message\n    args = (data, collapse_key, delay_while_idle, time_to_live)\n    try:\n        return _gcm_send_plain(device, *args)\n    except GCMError:\n"]]}
{"hexsha": "56690d670f8e3cc5abf9235f44543bab55462b75", "ext": "py", "lang": "Python", "content": "def _read_template(template_name):\n    \"\"\"\n    Open a template file, read the definition, and translate it into the format expected by boto.\n    If log_location is supplied, insert it into the template definition before returning it.\n    \"\"\"\n    with open_normalized(DataPipelineConsts.TEMPLATE_DIR, template_name + \".json\") as f:\n        template_data = json.load(f)\n    boto_objects, boto_params = template_to_boto(template_data)\n    return boto_objects, boto_params", "fn_id": 4, "class_fn": false, "repo": "amplifylitco/asiaq", "file": "disco_aws_automation/disco_datapipeline.py", "last_update_at": "2018-11-26T06:33:25+00:00", "question_id": "56690d670f8e3cc5abf9235f44543bab55462b75_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _read_template(template_name):\n    \"\"\"\n    Open a template file, read the definition, and translate it into the format expected by boto.\n    If log_location is supplied, insert it into the template definition before returning it.\n    \"\"\"\n    with open_normalized(DataPipelineConsts.TEMPLATE_DIR, template_name + '.json') as f:\n        template_data = json.load(f)\n    boto_objects, boto_params = template_to_boto(template_data)\n"]]}
{"hexsha": "8598044e62a6a62f45c02f4ff506e417d6d1df1c", "ext": "py", "lang": "Python", "content": "def write(base, db_url, output):\n    output = Path(output)\n    for fixed in fixed_queries(Path(base)):\n        fixed.write_to(output)\n\n    for query in generate_queries(db_url):\n        query.write_to(output)", "fn_id": 3, "class_fn": false, "repo": "RNAcentral/rnacentral-import-pipeline", "file": "rnacentral_pipeline/rnacentral/search_export/queries.py", "last_update_at": "2018-08-09T14:41:16+00:00", "question_id": "8598044e62a6a62f45c02f4ff506e417d6d1df1c_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def write(base, db_url, output):\n    output = Path(output)\n    for fixed in fixed_queries(Path(base)):\n        fixed.write_to(output)\n    for query in generate_queries(db_url):\n"]]}
{"hexsha": "88cb11ce0d8029c1308187723c316cf051086fad", "ext": "py", "lang": "Python", "content": "def toString(recipes):\n    \"\"\"Return a string representation of the recipes given in `recipes` in\n    Recipe-compliant format.\"\"\"\n    recipeStrings = []\n\n    for recipe in recipes:\n        output = '] {}\\n\\n'.format(recipe[TITLE_KEY])\n\n        for ingredient in recipe[INGREDIENTS_KEY]:\n            output += '{} {} {}'.format(\n                ingredient[INGREDIENT_AMOUNT_KEY],\n                ingredient[INGREDIENT_UNIT_KEY],\n                ingredient[INGREDIENT_NAME_KEY])\n\n            if ingredient[INGREDIENT_PREPARATION_KEY]:\n                output += ', {}'.format(ingredient[INGREDIENT_PREPARATION_KEY])\n\n            if ingredient[INGREDIENT_NOTE_KEY]:\n                output += ' ({})'.format(ingredient[INGREDIENT_NOTE_KEY])\n\n            output += '\\n'\n\n        output += '\\n'\n\n        recipeStrings.append(output + '\\n\\n'.join(recipe[DIRECTIONS_KEY]))\n\n    return '\\n'.join(recipeStrings)", "fn_id": 7, "class_fn": false, "repo": "akiraheid/Recipe", "file": "recipe.py", "last_update_at": "2018-08-19T16:02:04+00:00", "question_id": "88cb11ce0d8029c1308187723c316cf051086fad_7", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def toString(recipes):\n    \"\"\"Return a string representation of the recipes given in `recipes` in\n    Recipe-compliant format.\"\"\"\n    recipeStrings = []\n    for recipe in recipes:\n        output = '] {}\\n\\n'.format(recipe[TITLE_KEY])\n        for ingredient in recipe[INGREDIENTS_KEY]:\n            output += '{} {} {}'.format(ingredient[INGREDIENT_AMOUNT_KEY], ingredient[INGREDIENT_UNIT_KEY], ingredient[INGREDIENT_NAME_KEY])\n            if ingredient[INGREDIENT_PREPARATION_KEY]:\n                output += ', {}'.format(ingredient[INGREDIENT_PREPARATION_KEY])\n            if ingredient[INGREDIENT_NOTE_KEY]:\n                output += ' ({})'.format(ingredient[INGREDIENT_NOTE_KEY])\n            output += '\\n'\n        output += '\\n'\n        recipeStrings.append(output + '\\n\\n'.join(recipe[DIRECTIONS_KEY]))\n"]]}
{"hexsha": "9039120ed823476f5b8e71cb295b3c259f35f137", "ext": "py", "lang": "Python", "content": "def detect_objects(image_np, sess, detection_graph):\n    # Expand dimensions since the model expects images to have shape: [mscoco_label_map.pbtxt, None, None, 3]\n    image_np_expanded = np.expand_dims(image_np, axis=0)\n    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n\n    # Each box represents a part of the image where a particular object was detected.\n    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n\n    # Each score represent how level of confidence for each of the objects.\n    # Score is shown on the result image, together with the class label.\n    scores = detection_graph.get_tensor_by_name('detection_scores:0')\n    classes = detection_graph.get_tensor_by_name('detection_classes:0')\n    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n\n    # Actual detection.\n    (boxes, scores, classes, num_detections) = sess.run(\n        [boxes, scores, classes, num_detections],\n        feed_dict={image_tensor: image_np_expanded})\n\n    # Visualization of the results of a detection.\n    vis_util.visualize_boxes_and_labels_on_image_array(\n        image_np,\n        np.squeeze(boxes),\n        np.squeeze(classes).astype(np.int32),\n        np.squeeze(scores),\n        category_index,\n        use_normalized_coordinates=True,\n        line_thickness=8)\n    return image_np", "fn_id": 0, "class_fn": false, "repo": "48d90782/Tensorflow-Object-Detector-with-website", "file": "mainWorker.py", "last_update_at": "2018-07-20T20:53:11+00:00", "question_id": "9039120ed823476f5b8e71cb295b3c259f35f137_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def detect_objects(image_np, sess, detection_graph):\n    image_np_expanded = np.expand_dims(image_np, axis=0)\n    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n    scores = detection_graph.get_tensor_by_name('detection_scores:0')\n    classes = detection_graph.get_tensor_by_name('detection_classes:0')\n    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n    boxes, scores, classes, num_detections = sess.run([boxes, scores, classes, num_detections], feed_dict={image_tensor: image_np_expanded})\n    vis_util.visualize_boxes_and_labels_on_image_array(image_np, np.squeeze(boxes), np.squeeze(classes).astype(np.int32), np.squeeze(scores), category_index, use_normalized_coordinates=True, line_thickness=8)\n"]]}
{"hexsha": "a9651422a5c14480fc7b5698510f7b7b9bd1137c", "ext": "py", "lang": "Python", "content": "def form_parser() -> argparse.ArgumentParser:\n    parser = argparse.ArgumentParser(description='Ingest jsonl data into an Elasticsearch instance.')\n\n    parser.add_argument(\"-e\",\"--host\",help=\"ip address of Elasticsearch host. Defaults to localhost:9200\",default=None)\n    parser.add_argument(\"-a\",\"--aws\",help=\"Using Amazon Web Services: requires boto3\",action=\"store_true\")\n    parser.add_argument(\"-r\",\"--aws_region\",help=\"AWS region of Elasticsearch instance\",default=\"us-east-2\")\n    parser.add_argument(\"index\",help=\"Elasticsearch index to be used.\")\n    return parser", "fn_id": 1, "class_fn": false, "repo": "blachlylab/mucor3", "file": "filtering/elasticsearch/indexer.py", "last_update_at": "2018-07-11T15:59:58+00:00", "question_id": "a9651422a5c14480fc7b5698510f7b7b9bd1137c_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def form_parser() -> argparse.ArgumentParser:\n    parser = argparse.ArgumentParser(description='Ingest jsonl data into an Elasticsearch instance.')\n    parser.add_argument('-e', '--host', help='ip address of Elasticsearch host. Defaults to localhost:9200', default=None)\n    parser.add_argument('-a', '--aws', help='Using Amazon Web Services: requires boto3', action='store_true')\n    parser.add_argument('-r', '--aws_region', help='AWS region of Elasticsearch instance', default='us-east-2')\n    parser.add_argument('index', help='Elasticsearch index to be used.')\n"]]}
{"hexsha": "2afbf2da74a7aae7b5940213796c628982250aa7", "ext": "py", "lang": "Python", "content": "def print_experiment_record_argtable(records):\n    \"\"\"\n    Print a table comparing experiment arguments and their results.\n    \"\"\"\n    funtion_names = [record.info.get_field(ExpInfoFields.FUNCTION) for record in records]\n    args = [record.info.get_field(ExpInfoFields.ARGS) for record in records]\n    results = [record.get_result(err_if_none=False) for record in records]\n\n    common_args, different_args = separate_common_items(args)\n\n    record_ids = [record.get_id() for record in records]\n\n    def lookup_fcn(record_id, column):\n        index = record_ids.index(record_id)\n        if column=='Function':\n            return funtion_names[index]\n        elif column=='Run Time':\n            return records[index].info.get_field_text(ExpInfoFields.RUNTIME)\n        elif column=='Common Args':\n            return ', '.join('{}={}'.format(k, v) for k, v in common_args)\n        elif column=='Different Args':\n            return ', '.join('{}={}'.format(k, v) for k, v in different_args[index])\n        elif column=='Result':\n            return get_oneline_result_string(records[index])\n        else:\n            bad_value(column)\n\n    rows = build_table(lookup_fcn,\n        row_categories=record_ids,\n        column_categories=['Function', 'Run Time', 'Common Args', 'Different Args', 'Result'],\n        prettify_labels=False\n        )\n\n    print(tabulate(rows))", "fn_id": 7, "class_fn": false, "repo": "wouterkool/artemis", "file": "artemis/experiments/experiment_record_view.py", "last_update_at": "2018-11-25T12:48:03+00:00", "question_id": "2afbf2da74a7aae7b5940213796c628982250aa7_7", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def print_experiment_record_argtable(records):\n    \"\"\"\n    Print a table comparing experiment arguments and their results.\n    \"\"\"\n    funtion_names = [record.info.get_field(ExpInfoFields.FUNCTION) for record in records]\n    args = [record.info.get_field(ExpInfoFields.ARGS) for record in records]\n    results = [record.get_result(err_if_none=False) for record in records]\n    common_args, different_args = separate_common_items(args)\n    record_ids = [record.get_id() for record in records]\n\n    def lookup_fcn(record_id, column):\n        index = record_ids.index(record_id)\n        if column == 'Function':\n            return funtion_names[index]\n        elif column == 'Run Time':\n            return records[index].info.get_field_text(ExpInfoFields.RUNTIME)\n        elif column == 'Common Args':\n            return ', '.join(('{}={}'.format(k, v) for k, v in common_args))\n        elif column == 'Different Args':\n            return ', '.join(('{}={}'.format(k, v) for k, v in different_args[index]))\n        elif column == 'Result':\n            return get_oneline_result_string(records[index])\n        else:\n            bad_value(column)\n    rows = build_table(lookup_fcn, row_categories=record_ids, column_categories=['Function', 'Run Time', 'Common Args', 'Different Args', 'Result'], prettify_labels=False)\n"]]}
{"hexsha": "73f0f69e41eed1defaaac2561403c7d961b60598", "ext": "py", "lang": "Python", "content": "def find_K_means(k):\n\tcentroids = np.random.choice(np.arange(17), k*64, replace=1).reshape(k, 64)\t\t# Randomly initialize k cluster centers\n\twhile True:\n\t\tidx_cluster = find_nearest_centre(centroids, X_train, k)\t\t\t# Seperate data into clusters by finding nearest center\n\t\tk_means = []\n\t\tfor i in range(k):\t\t\t\t\t\t\t\t# Do for all clusters:\n\t\t\tif (len(idx_cluster[i]) != 0):\t\t\t\t\t\t# If the cluster is not empty\n\t\t\t\tk_means.append(np.mean(X_train[idx_cluster[i], :], axis=0))\t# Move the center to the mean of all vectors in the cluster\n\t\t\telse:\t\t\t\t\t\t# Otherwise\n\t\t\t\tk_means.append(centroids[i, :])\t\t# Keep center at its place\n\t\tif (np.sum(abs(centroids - k_means)) == 0):\t\t# If there is no change in any of the centers\n\t\t\tbreak\t\t\t\t\t\t# Stop moving the centers and exit loop\n\t\tcentroids = np.asarray(k_means)\t\t\t\t# Otherwise repeat with new set of centers\n\n#\tCompute Errors :\n\tMSE = []\n\tfor i in range(k):\n\t\tMSE.append(np.nan_to_num(np.divide(np.sum(np.power(X_train[idx_cluster[i], :] - k_means[i], 2)), len(idx_cluster[i]))))\n\tAvg_MSE = np.divide(np.sum(MSE), np.count_nonzero(idx_cluster))\n\tSq_Sep = 0\n\tfor i in range(k):\n\t\tfor j in range(i+1, k):\n\t\t\tSq_Sep += np.sum(np.power(k_means[i] - k_means[j], 2))\n\tMSS = (2*Sq_Sep)/(k*(k-1))\n\treturn np.asarray(k_means)[np.nonzero(idx_cluster)[0], :], MSE, Avg_MSE, MSS, np.asarray(idx_cluster)[np.nonzero(idx_cluster)[0]]", "fn_id": 1, "class_fn": false, "repo": "Nandini-K/Machine-Learning", "file": "K-Means Clustering.py", "last_update_at": "2018-01-27T11:53:55+00:00", "question_id": "73f0f69e41eed1defaaac2561403c7d961b60598_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def find_K_means(k):\n    centroids = np.random.choice(np.arange(17), k * 64, replace=1).reshape(k, 64)\n    while True:\n        idx_cluster = find_nearest_centre(centroids, X_train, k)\n        k_means = []\n        for i in range(k):\n            if len(idx_cluster[i]) != 0:\n                k_means.append(np.mean(X_train[idx_cluster[i], :], axis=0))\n            else:\n                k_means.append(centroids[i, :])\n        if np.sum(abs(centroids - k_means)) == 0:\n            break\n        centroids = np.asarray(k_means)\n    MSE = []\n    for i in range(k):\n        MSE.append(np.nan_to_num(np.divide(np.sum(np.power(X_train[idx_cluster[i], :] - k_means[i], 2)), len(idx_cluster[i]))))\n    Avg_MSE = np.divide(np.sum(MSE), np.count_nonzero(idx_cluster))\n    Sq_Sep = 0\n    for i in range(k):\n        for j in range(i + 1, k):\n            Sq_Sep += np.sum(np.power(k_means[i] - k_means[j], 2))\n    MSS = 2 * Sq_Sep / (k * (k - 1))\n"]]}
{"hexsha": "4a48f9b0a5fc8a0a948ea48ef5a05d386b879425", "ext": "py", "lang": "Python", "content": "def _input(prompt=None):\n    \"\"\"Wrap input() and raw_input() on Python 3 and 2 respectively.\n\n    :param prompt: Optional[str]\n    :return: str\n    \"\"\"\n    try:\n        return raw_input(prompt)\n    except NameError:\n        return input(prompt)", "fn_id": 0, "class_fn": false, "repo": "bartfeenstra/backuppy", "file": "backuppy/cli/input.py", "last_update_at": "2018-07-14T12:08:51+00:00", "question_id": "4a48f9b0a5fc8a0a948ea48ef5a05d386b879425_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _input(prompt=None):\n    \"\"\"Wrap input() and raw_input() on Python 3 and 2 respectively.\n\n    :param prompt: Optional[str]\n    :return: str\n    \"\"\"\n    try:\n        return raw_input(prompt)\n    except NameError:\n"]]}
{"hexsha": "e43b3a1fe43de5f1d5d6e3356c571467f39ad036", "ext": "py", "lang": "Python", "content": "def tick():\n    input_noise = simulation_config[\"input_noise\"]\n    energy_input = simulation_config[\"energy_input\"] + \\\n        random.randint(-input_noise, input_noise)\n\n    print(\"Energy outcome: \" + str(energy_input) + \"kWh\")\n    if energy_input > 0:\n        sell_energy(energy_input)\n    elif energy_input < 0:\n        consume_energy(-energy_input)", "fn_id": 1, "class_fn": false, "repo": "levex/group-project", "file": "simulation/meter.py", "last_update_at": "2018-01-06T12:38:45+00:00", "question_id": "e43b3a1fe43de5f1d5d6e3356c571467f39ad036_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def tick():\n    input_noise = simulation_config['input_noise']\n    energy_input = simulation_config['energy_input'] + random.randint(-input_noise, input_noise)\n    print('Energy outcome: ' + str(energy_input) + 'kWh')\n    if energy_input > 0:\n        sell_energy(energy_input)\n    elif energy_input < 0:\n"]]}
{"hexsha": "81fe826519dffc4a279b13276c37745c436038e7", "ext": "py", "lang": "Python", "content": "@pytest.mark.parametrize('number_of_nodes', [2])\n@pytest.mark.parametrize('channels_per_node', [1])\ndef test_receive_directtransfer_invalidsender(raiden_network, deposit, token_addresses):\n    app0, app1 = raiden_network\n    token_address = token_addresses[0]\n    other_key, other_address = make_privkey_address()\n    token_network_identifier = views.get_token_network_identifier_by_token_address(\n        views.state_from_app(app0),\n        app0.raiden.default_registry.address,\n        token_address,\n    )\n\n    channel0 = get_channelstate(app0, app1, token_network_identifier)\n    channel_identifier = channel0.identifier\n    message_identifier = random.randint(0, UINT64_MAX)\n\n    direct_transfer_message = DirectTransfer(\n        chain_id=UNIT_CHAIN_ID,\n        message_identifier=message_identifier,\n        payment_identifier=1,\n        nonce=1,\n        token_network_address=token_network_identifier,\n        token=token_address,\n        channel_identifier=channel_identifier,\n        transferred_amount=10,\n        locked_amount=0,\n        recipient=app0.raiden.address,\n        locksroot=EMPTY_MERKLE_ROOT,\n    )\n\n    sign_and_inject(\n        direct_transfer_message,\n        other_key,\n        other_address,\n        app0,\n    )\n\n    assert_synched_channel_state(\n        token_network_identifier,\n        app0, deposit, [],\n        app1, deposit, [],\n    )", "fn_id": 3, "class_fn": false, "repo": "litexnetwork/raiden", "file": "raiden/tests/integration/transfer/test_directransfer_invalid.py", "last_update_at": "2018-11-26T01:40:37+00:00", "question_id": "81fe826519dffc4a279b13276c37745c436038e7_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.mark.parametrize('number_of_nodes', [2])\n@pytest.mark.parametrize('channels_per_node', [1])\ndef test_receive_directtransfer_invalidsender(raiden_network, deposit, token_addresses):\n    app0, app1 = raiden_network\n    token_address = token_addresses[0]\n    other_key, other_address = make_privkey_address()\n    token_network_identifier = views.get_token_network_identifier_by_token_address(views.state_from_app(app0), app0.raiden.default_registry.address, token_address)\n    channel0 = get_channelstate(app0, app1, token_network_identifier)\n    channel_identifier = channel0.identifier\n    message_identifier = random.randint(0, UINT64_MAX)\n    direct_transfer_message = DirectTransfer(chain_id=UNIT_CHAIN_ID, message_identifier=message_identifier, payment_identifier=1, nonce=1, token_network_address=token_network_identifier, token=token_address, channel_identifier=channel_identifier, transferred_amount=10, locked_amount=0, recipient=app0.raiden.address, locksroot=EMPTY_MERKLE_ROOT)\n    sign_and_inject(direct_transfer_message, other_key, other_address, app0)\n"]]}
{"hexsha": "867b6c69d51ee9e64e7ce6aa45c08165f2f9aeea", "ext": "py", "lang": "Python", "content": "@auth.requires(auth.has_membership('Faculty') or auth.has_membership('Administrators'))\ndef GetImportPermissionStatus(account_id):\n    ret = \"True\"\n    auth = current.auth # Grab the current auth object\n    \n    if (auth.has_membership(role='Import', user_id=account_id) == True):\n        ret = \"True\"\n    else:\n        ret = \"False\"\n    \n    return ret", "fn_id": 15, "class_fn": false, "repo": "aduckworth1969/smc", "file": "web2py/applications/smc/controllers/faculty.py", "last_update_at": "2018-04-19T05:09:06+00:00", "question_id": "867b6c69d51ee9e64e7ce6aa45c08165f2f9aeea_15", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@auth.requires(auth.has_membership('Faculty') or auth.has_membership('Administrators'))\ndef GetImportPermissionStatus(account_id):\n    ret = 'True'\n    auth = current.auth\n    if auth.has_membership(role='Import', user_id=account_id) == True:\n        ret = 'True'\n    else:\n        ret = 'False'\n"]]}
{"hexsha": "9cf0448ac4d589d7b40f2636a8a339e0094cee15", "ext": "py", "lang": "Python", "content": "def best_bet(team_stat, file_value):\n\n    max_pct = 0\n    max_teams = \"\"\n\n    for mt in team_stat:\n        if mt[\"prob\"] > max_pct:\n            max_pct = mt[\"prob\"]\n            max_teams = mt[\"teams\"]\n\n    print(\"\")\n    print(\"-------------------------------------------------------------------------------------------\")\n    print(\"Best Bet: \", max_teams, '{0:.2f}'.format(max_pct * 100) + \"% to win\")\n    print(\"-------------------------------------------------------------------------------------------\")\n    print(\"\")\n\n    file_value.write(\"\\r\\n\")\n    file_value.write(\"-------------------------------------------------------------------------------------------\\r\\n\")\n    file_value.write(\"Best Bet:  \" + max_teams + \"  \" + '{0:.2f}'.format(max_pct * 100) + \"% to win\" + \"\\r\\n\")\n    file_value.write(\"-------------------------------------------------------------------------------------------\\r\\n\")\n    file_value.write(\"\\r\\n\")", "fn_id": 13, "class_fn": false, "repo": "Jared1989/Free-Style", "file": "app/MyBaseball7.py", "last_update_at": "2018-06-18T14:54:35+00:00", "question_id": "9cf0448ac4d589d7b40f2636a8a339e0094cee15_13", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def best_bet(team_stat, file_value):\n    max_pct = 0\n    max_teams = ''\n    for mt in team_stat:\n        if mt['prob'] > max_pct:\n            max_pct = mt['prob']\n            max_teams = mt['teams']\n    print('')\n    print('-------------------------------------------------------------------------------------------')\n    print('Best Bet: ', max_teams, '{0:.2f}'.format(max_pct * 100) + '% to win')\n    print('-------------------------------------------------------------------------------------------')\n    print('')\n    file_value.write('\\r\\n')\n    file_value.write('-------------------------------------------------------------------------------------------\\r\\n')\n    file_value.write('Best Bet:  ' + max_teams + '  ' + '{0:.2f}'.format(max_pct * 100) + '% to win' + '\\r\\n')\n    file_value.write('-------------------------------------------------------------------------------------------\\r\\n')\n"]]}
{"hexsha": "1455f9173559a159403d491702b38de8f0f2948a", "ext": "py", "lang": "Python", "content": "def grouper(iterable, n, fillvalue=None):\n    \"Collect data into fixed-length chunks or blocks\"\n    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\"\n    args = [iter(iterable)] * n\n    return zip_longest(*args, fillvalue=fillvalue)", "fn_id": 0, "class_fn": false, "repo": "hurwitzlab/viral-learning", "file": "vl/data.py", "last_update_at": "2018-02-23T16:49:30+00:00", "question_id": "1455f9173559a159403d491702b38de8f0f2948a_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def grouper(iterable, n, fillvalue=None):\n    \"\"\"Collect data into fixed-length chunks or blocks\"\"\"\n    args = [iter(iterable)] * n\n"]]}
{"hexsha": "0e53e23550de4108c21d59ae7b69046bae03b85c", "ext": "py", "lang": "Python", "content": "def schedule_menu_button():\n    tomorrow_hyb_button = [{\n        \"action\": {\n            \"type\": \"text\",\n            \"payload\": \"{\\\"button\\\":\\\"tomorrow_hyb_button\\\"}\",\n            \"label\": \"\u0420\u0430\u0441\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u0441 \u0437\u0430\u043c\u0435\u043d\u0430\u043c\u0438 \u043d\u0430 \u0437\u0430\u0432\u0442\u0440\u0430\"\n        },\n        \"color\": action_button_color\n    }]\n    today_hyb_button = [{\n        \"action\": {\n            \"type\": \"text\",\n            \"payload\": \"{\\\"button\\\":\\\"today_hyb_button\\\"}\",\n            \"label\": \"\u0420\u0430\u0441\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u0441 \u0437\u0430\u043c\u0435\u043d\u0430\u043c\u0438 \u043d\u0430 \u0441\u0435\u0433\u043e\u0434\u043d\u044f\"\n        },\n        \"color\": action_button_color\n    }]\n\n    tomorrow_sch_button = [{\n        \"action\": {\n            \"type\": \"text\",\n            \"payload\": \"{\\\"button\\\":\\\"tomorrow_sch_button\\\"}\",\n            \"label\": \"\u0420\u0430\u0441\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u0431\u0435\u0437 \u0437\u0430\u043c\u0435\u043d \u043d\u0430 \u0437\u0430\u0432\u0442\u0440\u0430\"\n        },\n        \"color\": action_button_color\n    }]\n    today_sch_button = [{\n        \"action\": {\n            \"type\": \"text\",\n            \"payload\": \"{\\\"button\\\":\\\"today_sch_button\\\"}\",\n            \"label\": \"\u0420\u0430\u0441\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u0431\u0435\u0437 \u0437\u0430\u043c\u0435\u043d \u043d\u0430 \u0441\u0435\u0433\u043e\u0434\u043d\u044f\"\n        },\n        \"color\": action_button_color\n    }]\n\n    back_button = [{\n        \"action\": {\n            \"type\": \"text\",\n            \"payload\": \"{\\\"button\\\":\\\"main_menu\\\"}\",\n            \"label\": \"\u041d\u0430\u0437\u0430\u0434\"\n        },\n        \"color\": sub_menu_button_color\n    }]\n\n    return [\n        tomorrow_hyb_button, today_hyb_button, tomorrow_sch_button,\n        today_sch_button, back_button\n    ]", "fn_id": 1, "class_fn": false, "repo": "PDmatrix/VkBot", "file": "src/vkapi.py", "last_update_at": "2018-11-15T18:51:20+00:00", "question_id": "0e53e23550de4108c21d59ae7b69046bae03b85c_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def schedule_menu_button():\n    tomorrow_hyb_button = [{'action': {'type': 'text', 'payload': '{\"button\":\"tomorrow_hyb_button\"}', 'label': '\u0420\u0430\u0441\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u0441 \u0437\u0430\u043c\u0435\u043d\u0430\u043c\u0438 \u043d\u0430 \u0437\u0430\u0432\u0442\u0440\u0430'}, 'color': action_button_color}]\n    today_hyb_button = [{'action': {'type': 'text', 'payload': '{\"button\":\"today_hyb_button\"}', 'label': '\u0420\u0430\u0441\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u0441 \u0437\u0430\u043c\u0435\u043d\u0430\u043c\u0438 \u043d\u0430 \u0441\u0435\u0433\u043e\u0434\u043d\u044f'}, 'color': action_button_color}]\n    tomorrow_sch_button = [{'action': {'type': 'text', 'payload': '{\"button\":\"tomorrow_sch_button\"}', 'label': '\u0420\u0430\u0441\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u0431\u0435\u0437 \u0437\u0430\u043c\u0435\u043d \u043d\u0430 \u0437\u0430\u0432\u0442\u0440\u0430'}, 'color': action_button_color}]\n    today_sch_button = [{'action': {'type': 'text', 'payload': '{\"button\":\"today_sch_button\"}', 'label': '\u0420\u0430\u0441\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u0431\u0435\u0437 \u0437\u0430\u043c\u0435\u043d \u043d\u0430 \u0441\u0435\u0433\u043e\u0434\u043d\u044f'}, 'color': action_button_color}]\n    back_button = [{'action': {'type': 'text', 'payload': '{\"button\":\"main_menu\"}', 'label': '\u041d\u0430\u0437\u0430\u0434'}, 'color': sub_menu_button_color}]\n"]]}
{"hexsha": "7a960a00d0a13229af7e7e6d54c95f137034bee8", "ext": "py", "lang": "Python", "content": "def test_peek_after_push_diff_type(one_nine_stack):\n    \"\"\"\n    tests for expected repsonse after str type is pushed to\n    array\n    \"\"\"\n    one_nine_stack.push('a')\n    one_nine_stack.peek().val = 'a'", "fn_id": 12, "class_fn": false, "repo": "tyler-fishbone/data-structures-and-algorithms", "file": "data_structures/stack-dir/test_stack.py", "last_update_at": "2018-04-11T00:35:26+00:00", "question_id": "7a960a00d0a13229af7e7e6d54c95f137034bee8_12", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_peek_after_push_diff_type(one_nine_stack):\n    \"\"\"\n    tests for expected repsonse after str type is pushed to\n    array\n    \"\"\"\n    one_nine_stack.push('a')\n"]]}
{"hexsha": "8711225fd68c0db2834cf8b69da4b3bfbfbce313", "ext": "py", "lang": "Python", "content": "def escritor(id):\n    sleep(random())\n    print(\"   Escritor %d iniciando\" % id)\n    torniquete.acquire()\n    print(\"   Escritor %d: En el torniquete\" % id)\n    cuarto_vacio.acquire()\n    print(\"   Escritor %d: El cuarto es m\u00edo!\" % id)\n    escribe(id)\n    cuarto_vacio.release()\n    torniquete.release()\n    print(\"   Escritor %d se fue\" % id)", "fn_id": 0, "class_fn": false, "repo": "Guadalupe-Moreno/sistop-2019-1", "file": "ejemplos_en_clase/2_adm_procesos/lect_escr.py", "last_update_at": "2018-09-27T09:39:26+00:00", "question_id": "8711225fd68c0db2834cf8b69da4b3bfbfbce313_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def escritor(id):\n    sleep(random())\n    print('   Escritor %d iniciando' % id)\n    torniquete.acquire()\n    print('   Escritor %d: En el torniquete' % id)\n    cuarto_vacio.acquire()\n    print('   Escritor %d: El cuarto es m\u00edo!' % id)\n    escribe(id)\n    cuarto_vacio.release()\n    torniquete.release()\n"]]}
{"hexsha": "8a0f208cf50b13168ae5ac7f2e2b0971910ec1a2", "ext": "py", "lang": "Python", "content": "def get_key(timeout=None):\n    init_terminal()\n    with terminal.cbreak():\n        return terminal.inkey(timeout=timeout)", "fn_id": 10, "class_fn": false, "repo": "zwachtel11/fruitful-backend", "file": "venv/lib/python2.7/site-packages/ebcli/display/term.py", "last_update_at": "2018-12-19T14:06:22+00:00", "question_id": "8a0f208cf50b13168ae5ac7f2e2b0971910ec1a2_10", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_key(timeout=None):\n    init_terminal()\n    with terminal.cbreak():\n"]]}
{"hexsha": "0877893c370d92ee2ddd760abdbfb2edf5011099", "ext": "py", "lang": "Python", "content": "def compute_confusion_matrix(real, pred, normalization=None):\n    \"Compute confusion matrix.\"\n    if real.shape == pred.shape:\n        conf_mat = confusion_matrix(real, pred)\n    else:\n        conf_mat = confusion_matrix_probs(pred, real)\n    return conf_mat", "fn_id": 4, "class_fn": false, "repo": "tgquintela/pySpatialTools", "file": "pySpatialTools/Testers/check_features.py", "last_update_at": "2018-06-12T18:22:52+00:00", "question_id": "0877893c370d92ee2ddd760abdbfb2edf5011099_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def compute_confusion_matrix(real, pred, normalization=None):\n    \"\"\"Compute confusion matrix.\"\"\"\n    if real.shape == pred.shape:\n        conf_mat = confusion_matrix(real, pred)\n    else:\n        conf_mat = confusion_matrix_probs(pred, real)\n"]]}
{"hexsha": "bef0998ea7e8196a7098198c75eeeec8b7332c57", "ext": "py", "lang": "Python", "content": "def anneal(t=1.0):\n    \"\"\"\n    Transitions Governor from SA to CB state and inserts annealer\n    \n    Requirements\n    ------------\n    * Governor in SA state\n    \n    Parameters\n    ----------\n    t: Time to insert annealer paddle. default = 1.0 [s]\n              \n    Examples\n    --------\n    anneal()\n    anneal(t=5)\n    \n    \"\"\"\n    if not govStatusGet('SA'):\n        print('Not in Governor state SA, exiting')\n        return -1\n    \n    govStateSet('CB')\n    \n    annealer.air.put(1)\n    \n    while not annealer.inStatus.get():\n        #print(annealer.inStatus.get())\n        time.sleep(0.1)\n    \n    time.sleep(t)\n    annealer.air.put(0)\n    \n    while not annealer.outStatus.get():\n        #print(annealer.outStatus.get())\n        time.sleep(0.1)\n    \n    govStateSet('SA')\n    \n    return", "fn_id": 3, "class_fn": false, "repo": "NSLS-II-FMX/profile_collection", "file": "startup/99-macros.py", "last_update_at": "2018-02-18T14:50:59+00:00", "question_id": "bef0998ea7e8196a7098198c75eeeec8b7332c57_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def anneal(t=1.0):\n    \"\"\"\n    Transitions Governor from SA to CB state and inserts annealer\n    \n    Requirements\n    ------------\n    * Governor in SA state\n    \n    Parameters\n    ----------\n    t: Time to insert annealer paddle. default = 1.0 [s]\n              \n    Examples\n    --------\n    anneal()\n    anneal(t=5)\n    \n    \"\"\"\n    if not govStatusGet('SA'):\n        print('Not in Governor state SA, exiting')\n        return -1\n    govStateSet('CB')\n    annealer.air.put(1)\n    while not annealer.inStatus.get():\n        time.sleep(0.1)\n    time.sleep(t)\n    annealer.air.put(0)\n    while not annealer.outStatus.get():\n        time.sleep(0.1)\n    govStateSet('SA')\n"]]}
{"hexsha": "6d039c7bbc47a6d65a19e61994249628981e4472", "ext": "py", "lang": "Python", "content": "def main():\n    logging.config.fileConfig('logging.conf')\n    logger = logging.getLogger('exampleApp')\n\n    logger.info('progress started')\n    result = otherMod2.add(7, 8)\n    logger.info('done!')", "fn_id": 0, "class_fn": false, "repo": "bismog/leetcode", "file": "python/logging/log_with_config.py", "last_update_at": "2018-08-17T07:07:15+00:00", "question_id": "6d039c7bbc47a6d65a19e61994249628981e4472_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main():\n    logging.config.fileConfig('logging.conf')\n    logger = logging.getLogger('exampleApp')\n    logger.info('progress started')\n    result = otherMod2.add(7, 8)\n"]]}
{"hexsha": "5d761a0e13f37bc08d17a89dfe42bab545b7a800", "ext": "py", "lang": "Python", "content": "def lastfm(data):\n    \"\"\"\n    This parser restructures the LastFM API response to\n    both eliminate unneeded data and to be more human parsable.\n\n    For more obscure tracks, an album cover may not be available\n    so we just provide our own placeholder from the static folder.\n\n    :param data: A serialised JSON string.\n    :return: A dictionary object.\n    \"\"\"\n    Song.objects.all().delete()\n    tracks = data['recenttracks']['track']\n    for item in tracks:\n        name = item['name']\n        if not item['image'][3]['#text']:\n            image = '/static/img/no_cover.png'\n        else:\n            image = item['image'][3]['#text']\n        link = item['url']\n        artist = item['artist']['#text']\n\n        Song.objects.create(name=name, image=image,\n                            link=link, artist=artist)", "fn_id": 2, "class_fn": false, "repo": "marcus-crane/site", "file": "site/stats/parsers.py", "last_update_at": "2018-05-06T20:12:31+00:00", "question_id": "5d761a0e13f37bc08d17a89dfe42bab545b7a800_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def lastfm(data):\n    \"\"\"\n    This parser restructures the LastFM API response to\n    both eliminate unneeded data and to be more human parsable.\n\n    For more obscure tracks, an album cover may not be available\n    so we just provide our own placeholder from the static folder.\n\n    :param data: A serialised JSON string.\n    :return: A dictionary object.\n    \"\"\"\n    Song.objects.all().delete()\n    tracks = data['recenttracks']['track']\n    for item in tracks:\n        name = item['name']\n        if not item['image'][3]['#text']:\n            image = '/static/img/no_cover.png'\n        else:\n            image = item['image'][3]['#text']\n        link = item['url']\n        artist = item['artist']['#text']\n"]]}
{"hexsha": "06c034cd372e536a6116c1b023c17467b282dc84", "ext": "py", "lang": "Python", "content": "@app.route('/api', methods=['POST', 'GET'])\ndef api():\n    if request.method == \"GET\":\n        q = request.args.get('q', '')\n    elif request.method == \"POST\":\n        q = request.form.get('q', '')\n\n    q, vs = process_query(q)\n\n    embedding_sample, low_dim_embedding_sample, label_sample = sample_embedding()\n\n    inx_embedding = vs[EMBEDDING]\n    inx_low_dim_embedding = vs[LOW_DIM_EMBEDDING]\n\n    idx, _ = calc_n_cosine_neighbor(\n        inx_embedding[np.newaxis, :], embedding_sample, N_NEIGHBOR)\n    labels = [label_sample[i] for i in idx]\n\n    # if query does not exist, it is hard to know it's low_dim_embedding coordinates\n    # assume it locates in the cloest neighbor\n    info = q\n    if inx_low_dim_embedding is None:\n        inx_low_dim_embedding = low_dim_embedding_sample[idx[-1], :]\n        info = \"Nonexistent word: \" + q\n\n    fig = plot_interactive_scatter(\n        low_dim_embedding_sample[idx, :], labels, inx_low_dim_embedding[np.newaxis, :], q, info)\n\n    return mpld3.fig_to_html(fig)", "fn_id": 3, "class_fn": false, "repo": "guyao/hashtag_twitter", "file": "app/views.py", "last_update_at": "2018-02-06T21:16:19+00:00", "question_id": "06c034cd372e536a6116c1b023c17467b282dc84_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@app.route('/api', methods=['POST', 'GET'])\ndef api():\n    if request.method == 'GET':\n        q = request.args.get('q', '')\n    elif request.method == 'POST':\n        q = request.form.get('q', '')\n    q, vs = process_query(q)\n    embedding_sample, low_dim_embedding_sample, label_sample = sample_embedding()\n    inx_embedding = vs[EMBEDDING]\n    inx_low_dim_embedding = vs[LOW_DIM_EMBEDDING]\n    idx, _ = calc_n_cosine_neighbor(inx_embedding[np.newaxis, :], embedding_sample, N_NEIGHBOR)\n    labels = [label_sample[i] for i in idx]\n    info = q\n    if inx_low_dim_embedding is None:\n        inx_low_dim_embedding = low_dim_embedding_sample[idx[-1], :]\n        info = 'Nonexistent word: ' + q\n    fig = plot_interactive_scatter(low_dim_embedding_sample[idx, :], labels, inx_low_dim_embedding[np.newaxis, :], q, info)\n"]]}
{"hexsha": "23d0435f0ab0a1ac950c9194bbb0e5d8f6fdf62f", "ext": "py", "lang": "Python", "content": "def add_groups_item_to_dict(init_json, df, nestcol, newcolname):\n    \"\"\"\n    init_json: Initial Json Array of Objects\n    df: Dataframe to add group items\n    nestcol: Name of columns that will be nested (thrown into a list)\n    newcolname: Name of new column\n\n    Matches on guid\n\n    Adds a specific column (nestcol) with name (newcolname) from\n    Pandas dataframe (df) to the array (init_json)\n    \"\"\"\n\n    new_dict = uf.nest_for_json(\n        prune_dataframe(df, ['guid', nestcol]),\n        'guid',\n        nestcol,\n        newcolname\n    ).to_dict('r')\n\n    for init_item in init_json:\n        for new_item in new_dict:\n            # Matches on guid between the two items\n            if init_item['guid'] == new_item['guid']:\n                init_item[newcolname] = new_item[newcolname]", "fn_id": 2, "class_fn": false, "repo": "Lavoiec/Project-Overlay-Data-Process", "file": "ToJson.py", "last_update_at": "2018-06-14T13:47:49+00:00", "question_id": "23d0435f0ab0a1ac950c9194bbb0e5d8f6fdf62f_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def add_groups_item_to_dict(init_json, df, nestcol, newcolname):\n    \"\"\"\n    init_json: Initial Json Array of Objects\n    df: Dataframe to add group items\n    nestcol: Name of columns that will be nested (thrown into a list)\n    newcolname: Name of new column\n\n    Matches on guid\n\n    Adds a specific column (nestcol) with name (newcolname) from\n    Pandas dataframe (df) to the array (init_json)\n    \"\"\"\n    new_dict = uf.nest_for_json(prune_dataframe(df, ['guid', nestcol]), 'guid', nestcol, newcolname).to_dict('r')\n    for init_item in init_json:\n        for new_item in new_dict:\n            if init_item['guid'] == new_item['guid']:\n"]]}
{"hexsha": "753d190a89a43e55aa47e1b2e59fd721228a02a9", "ext": "py", "lang": "Python", "content": "def password_strength_check(handle, descr=None, **kwargs):\n    \"\"\"\n    Check password strength for locally authenticated user\n\n    Args:\n        handle (UcscHandle)\n        descr (string): description\n        **kwargs: Any additional key-value pair of managed object(MO)'s\n                  property and value, which are not part of regular args.\n                  This should be used for future version compatibility.\n    Returns:\n        AaaUserEp: Managed Object\n\n    Example:\n        password_strength_check(handle)\n    \"\"\"\n\n    mo = handle.query_dn(ucsc_base_dn + \"/pwd-profile\")\n    mo.pwd_strength_check = \"yes\"\n    mo.descr = descr\n\n    mo.set_prop_multiple(**kwargs)\n\n    handle.set_mo(mo)\n    handle.commit()\n    return mo", "fn_id": 13, "class_fn": false, "repo": "scottwedge/ucsc_apis", "file": "ucsc_apis/admin/user.py", "last_update_at": "2018-08-15T15:13:43+00:00", "question_id": "753d190a89a43e55aa47e1b2e59fd721228a02a9_13", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def password_strength_check(handle, descr=None, **kwargs):\n    \"\"\"\n    Check password strength for locally authenticated user\n\n    Args:\n        handle (UcscHandle)\n        descr (string): description\n        **kwargs: Any additional key-value pair of managed object(MO)'s\n                  property and value, which are not part of regular args.\n                  This should be used for future version compatibility.\n    Returns:\n        AaaUserEp: Managed Object\n\n    Example:\n        password_strength_check(handle)\n    \"\"\"\n    mo = handle.query_dn(ucsc_base_dn + '/pwd-profile')\n    mo.pwd_strength_check = 'yes'\n    mo.descr = descr\n    mo.set_prop_multiple(**kwargs)\n    handle.set_mo(mo)\n    handle.commit()\n"]]}
{"hexsha": "db06d0b14e9aad2ae963b334510ce8660f791696", "ext": "py", "lang": "Python", "content": "@app.route('/user/<int:user_id>')\ndef user(user_id):\n    u = User()\n    return render_template('user.html', user=u.getUser(user_id))", "fn_id": 4, "class_fn": false, "repo": "gabfl/sample-flask", "file": "app.py", "last_update_at": "2018-03-27T07:08:41+00:00", "question_id": "db06d0b14e9aad2ae963b334510ce8660f791696_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@app.route('/user/<int:user_id>')\ndef user(user_id):\n    u = User()\n"]]}
{"hexsha": "e56b0c31d2a5bc7ffc2720650061bdfef0a46562", "ext": "py", "lang": "Python", "content": "def setup_platform(hass, config, add_devices, discovery_info=None):\n    \"\"\"Set up the Alpha Vantage sensor.\"\"\"\n    from alpha_vantage.timeseries import TimeSeries\n\n    api_key = config.get(CONF_API_KEY)\n    symbols = config.get(CONF_SYMBOLS)\n\n    timeseries = TimeSeries(key=api_key)\n\n    dev = []\n    for symbol in symbols:\n        try:\n            timeseries.get_intraday(symbol)\n        except ValueError:\n            _LOGGER.error(\n                \"API Key is not valid or symbol '%s' not known\", symbol)\n            return\n        dev.append(AlphaVantageSensor(timeseries, symbol))\n\n    add_devices(dev, True)", "fn_id": 0, "class_fn": false, "repo": "da-anda/home-assistant", "file": "homeassistant/components/sensor/alpha_vantage.py", "last_update_at": "2018-12-01T02:09:25+00:00", "question_id": "e56b0c31d2a5bc7ffc2720650061bdfef0a46562_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def setup_platform(hass, config, add_devices, discovery_info=None):\n    \"\"\"Set up the Alpha Vantage sensor.\"\"\"\n    from alpha_vantage.timeseries import TimeSeries\n    api_key = config.get(CONF_API_KEY)\n    symbols = config.get(CONF_SYMBOLS)\n    timeseries = TimeSeries(key=api_key)\n    dev = []\n    for symbol in symbols:\n        try:\n            timeseries.get_intraday(symbol)\n        except ValueError:\n            _LOGGER.error(\"API Key is not valid or symbol '%s' not known\", symbol)\n            return\n        dev.append(AlphaVantageSensor(timeseries, symbol))\n"]]}
{"hexsha": "ed57d9b3d5c189b14f763887cc109fe1deb8b0e7", "ext": "py", "lang": "Python", "content": "def step(model, sentence, choices, verbose=0):\n    vec = w2v(sentence)\n    idx = len(sentence) - 1# with just <start>, len is 1. we want post over start, so subtract 1\n    probs = model.model.predict(vec)[0,idx,:]\n    best = 0.\n    best_word = \"\"\n    best_idx = -1\n    decisions = []\n    for i, word in enumerate(choices):\n        word_val = probs[model.igor.vocabs.words[word]]\n        decisions.append((word, word_val))\n        if word_val > best:\n            best = word_val\n            best_word = word\n            best_idx = i\n    #if verbose:\n    #    print(\"selecting {}\".format(best_word))\n    #    print(\"-------\")\n    return sentence + [best_word], best_idx, decisions", "fn_id": 1, "class_fn": false, "repo": "braingineer/neural_tree_grammar", "file": "fergus/algorithms/linearizer/decode.py", "last_update_at": "2018-09-11T03:39:35+00:00", "question_id": "ed57d9b3d5c189b14f763887cc109fe1deb8b0e7_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def step(model, sentence, choices, verbose=0):\n    vec = w2v(sentence)\n    idx = len(sentence) - 1\n    probs = model.model.predict(vec)[0, idx, :]\n    best = 0.0\n    best_word = ''\n    best_idx = -1\n    decisions = []\n    for i, word in enumerate(choices):\n        word_val = probs[model.igor.vocabs.words[word]]\n        decisions.append((word, word_val))\n        if word_val > best:\n            best = word_val\n            best_word = word\n            best_idx = i\n"]]}
{"hexsha": "1361759f484b66b307f8c5a3d31a2b5a9c67f540", "ext": "py", "lang": "Python", "content": "def draw_lines(img, lines, color=[255, 0, 0], thickness=10):\n\t\"\"\"\n\tNOTE: this is the function you might want to use as a starting point once you want to\n\taverage/extrapolate the line segments you detect to map out the full\n\textent of the lane (going from the result shown in raw-lines-example.mp4\n\tto that shown in P1_example.mp4).\n\n\tThink about things like separating line segments by their\n\tslope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n\tline vs. the right line.  Then, you can average the position of each of\n\tthe lines and extrapolate to the top and bottom of the lane.\n\n\tThis function draws `lines` with `color` and `thickness`.\n\tLines are drawn on the image inplace (mutates the image).\n\tIf you want to make the lines semi-transparent, think about combining\n\tthis function with the weighted_img() function below\n\t\"\"\"\n\t# In case of error, don't draw the line(s)\n\tif lines is None:\n\t\treturn\n\tif len(lines) == 0:\n\t\treturn\n\tdraw_right = True\n\tdraw_left = True\n\n\t# Find slopes of all lines\n\t# But only care about lines where abs(slope) > slope_threshold\n\tslope_threshold = 0.5\n\tslopes = []\n\tnew_lines = []\n\tfor line in lines:\n\t\tx1, y1, x2, y2 = line[0]  # line = [[x1, y1, x2, y2]]\n\n\t\t# Calculate slope\n\t\tif x2 - x1 == 0.:  # corner case, avoiding division by 0\n\t\t\tslope = 999.  # practically infinite slope\n\t\telse:\n\t\t\tslope = (y2 - y1) / (x2 - x1)\n\n\t\t# Filter lines based on slope\n\t\tif abs(slope) > slope_threshold:\n\t\t\tslopes.append(slope)\n\t\t\tnew_lines.append(line)\n\n\tlines = new_lines\n\n\t# Split lines into right_lines and left_lines, representing the right and left lane lines\n\t# Right/left lane lines must have positive/negative slope, and be on the right/left half of the image\n\tright_lines = []\n\tleft_lines = []\n\tfor i, line in enumerate(lines):\n\t\tx1, y1, x2, y2 = line[0]\n\t\timg_x_center = img.shape[1] / 2  # x coordinate of center of image\n\t\tif slopes[i] > 0 and x1 > img_x_center and x2 > img_x_center:\n\t\t\tright_lines.append(line)\n\t\telif slopes[i] < 0 and x1 < img_x_center and x2 < img_x_center:\n\t\t\tleft_lines.append(line)\n\n\t# Run linear regression to find best fit line for right and left lane lines\n\t# Right lane lines\n\tright_lines_x = []\n\tright_lines_y = []\n\n\tfor line in right_lines:\n\t\tx1, y1, x2, y2 = line[0]\n\n\t\tright_lines_x.append(x1)\n\t\tright_lines_x.append(x2)\n\n\t\tright_lines_y.append(y1)\n\t\tright_lines_y.append(y2)\n\n\tif len(right_lines_x) > 0:\n\t\tright_m, right_b = np.polyfit(right_lines_x, right_lines_y, 1)  # y = m*x + b\n\telse:\n\t\tright_m, right_b = 1, 1\n\t\tdraw_right = False\n\n\t# Left lane lines\n\tleft_lines_x = []\n\tleft_lines_y = []\n\n\tfor line in left_lines:\n\t\tx1, y1, x2, y2 = line[0]\n\n\t\tleft_lines_x.append(x1)\n\t\tleft_lines_x.append(x2)\n\n\t\tleft_lines_y.append(y1)\n\t\tleft_lines_y.append(y2)\n\n\tif len(left_lines_x) > 0:\n\t\tleft_m, left_b = np.polyfit(left_lines_x, left_lines_y, 1)  # y = m*x + b\n\telse:\n\t\tleft_m, left_b = 1, 1\n\t\tdraw_left = False\n\n\t# Find 2 end points for right and left lines, used for drawing the line\n\t# y = m*x + b --> x = (y - b)/m\n\ty1 = img.shape[0]\n\ty2 = img.shape[0] * (1 - trap_height)\n\n\tright_x1 = (y1 - right_b) / right_m\n\tright_x2 = (y2 - right_b) / right_m\n\n\tleft_x1 = (y1 - left_b) / left_m\n\tleft_x2 = (y2 - left_b) / left_m\n\n\t# Convert calculated end points from float to int\n\ty1 = int(y1)\n\ty2 = int(y2)\n\tright_x1 = int(right_x1)\n\tright_x2 = int(right_x2)\n\tleft_x1 = int(left_x1)\n\tleft_x2 = int(left_x2)\n  \n\t# Draw the right and left lines on image\n\t# if draw_right:\n\t# \tcv2.line(img, (right_x1, y1), (right_x2, y2), color, thickness)\n\t# if draw_left:\n\t# \tcv2.line(img, (left_x1, y1), (left_x2, y2), color, thickness)\n\t\n\tline_right = (right_x1, y1, right_x2, y2)\n\tline_left = (left_x1, y1, left_x2, y2)\n\treturn [line_right, line_left]", "fn_id": 2, "class_fn": false, "repo": "showkeyjar/TruckCamper", "file": "sim/python/lane_lines.py", "last_update_at": "2018-01-02T14:19:35+00:00", "question_id": "1361759f484b66b307f8c5a3d31a2b5a9c67f540_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def draw_lines(img, lines, color=[255, 0, 0], thickness=10):\n    \"\"\"\n\tNOTE: this is the function you might want to use as a starting point once you want to\n\taverage/extrapolate the line segments you detect to map out the full\n\textent of the lane (going from the result shown in raw-lines-example.mp4\n\tto that shown in P1_example.mp4).\n\n\tThink about things like separating line segments by their\n\tslope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n\tline vs. the right line.  Then, you can average the position of each of\n\tthe lines and extrapolate to the top and bottom of the lane.\n\n\tThis function draws `lines` with `color` and `thickness`.\n\tLines are drawn on the image inplace (mutates the image).\n\tIf you want to make the lines semi-transparent, think about combining\n\tthis function with the weighted_img() function below\n\t\"\"\"\n    if lines is None:\n        return\n    if len(lines) == 0:\n        return\n    draw_right = True\n    draw_left = True\n    slope_threshold = 0.5\n    slopes = []\n    new_lines = []\n    for line in lines:\n        x1, y1, x2, y2 = line[0]\n        if x2 - x1 == 0.0:\n            slope = 999.0\n        else:\n            slope = (y2 - y1) / (x2 - x1)\n        if abs(slope) > slope_threshold:\n            slopes.append(slope)\n            new_lines.append(line)\n    lines = new_lines\n    right_lines = []\n    left_lines = []\n    for i, line in enumerate(lines):\n        x1, y1, x2, y2 = line[0]\n        img_x_center = img.shape[1] / 2\n        if slopes[i] > 0 and x1 > img_x_center and (x2 > img_x_center):\n            right_lines.append(line)\n        elif slopes[i] < 0 and x1 < img_x_center and (x2 < img_x_center):\n            left_lines.append(line)\n    right_lines_x = []\n    right_lines_y = []\n    for line in right_lines:\n        x1, y1, x2, y2 = line[0]\n        right_lines_x.append(x1)\n        right_lines_x.append(x2)\n        right_lines_y.append(y1)\n        right_lines_y.append(y2)\n    if len(right_lines_x) > 0:\n        right_m, right_b = np.polyfit(right_lines_x, right_lines_y, 1)\n    else:\n        right_m, right_b = (1, 1)\n        draw_right = False\n    left_lines_x = []\n    left_lines_y = []\n    for line in left_lines:\n        x1, y1, x2, y2 = line[0]\n        left_lines_x.append(x1)\n        left_lines_x.append(x2)\n        left_lines_y.append(y1)\n        left_lines_y.append(y2)\n    if len(left_lines_x) > 0:\n        left_m, left_b = np.polyfit(left_lines_x, left_lines_y, 1)\n    else:\n        left_m, left_b = (1, 1)\n        draw_left = False\n    y1 = img.shape[0]\n    y2 = img.shape[0] * (1 - trap_height)\n    right_x1 = (y1 - right_b) / right_m\n    right_x2 = (y2 - right_b) / right_m\n    left_x1 = (y1 - left_b) / left_m\n    left_x2 = (y2 - left_b) / left_m\n    y1 = int(y1)\n    y2 = int(y2)\n    right_x1 = int(right_x1)\n    right_x2 = int(right_x2)\n    left_x1 = int(left_x1)\n    left_x2 = int(left_x2)\n    line_right = (right_x1, y1, right_x2, y2)\n    line_left = (left_x1, y1, left_x2, y2)\n"]]}
{"hexsha": "333798cbe019c32d34e40d9f47e4ae6232ce343c", "ext": "py", "lang": "Python", "content": "def test_response_set_content_type_set():\n    resp = falcon.Response()\n    resp._set_media_type(MEDIA_TEXT)\n    assert resp._headers['content-type'] == MEDIA_TEXT", "fn_id": 0, "class_fn": false, "repo": "astonm/falcon", "file": "tests/test_response.py", "last_update_at": "2018-10-07T21:06:10+00:00", "question_id": "333798cbe019c32d34e40d9f47e4ae6232ce343c_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_response_set_content_type_set():\n    resp = falcon.Response()\n    resp._set_media_type(MEDIA_TEXT)\n"]]}
{"hexsha": "48001d96d99461626ef538dafa8e93a96f02c5b0", "ext": "py", "lang": "Python", "content": "def bindListByTitle(column, dataList):\n    d1, d2 = {}, {}\n    for j in range(len(dataList)):\n        i = 0\n        for x in dataList[j]:\n            d1[column[i]], d2[j] = x, d1\n            i += 1\n    return d2", "fn_id": 1, "class_fn": false, "repo": "shayanadc/Convertor.csv", "file": "jsonConvertor/readCSV.py", "last_update_at": "2018-05-30T15:58:23+00:00", "question_id": "48001d96d99461626ef538dafa8e93a96f02c5b0_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def bindListByTitle(column, dataList):\n    d1, d2 = ({}, {})\n    for j in range(len(dataList)):\n        i = 0\n        for x in dataList[j]:\n            d1[column[i]], d2[j] = (x, d1)\n            i += 1\n"]]}
{"hexsha": "792a06433102075502db4b1733b021f572e9080b", "ext": "py", "lang": "Python", "content": "def main():\n    N = 100000\n\n    xy = rand(N, 2)\n\n    r = xy[:,0] ** 2 + xy[:,1]**2\n\n    n = sum(r < 1)\n\n    pi_est = 4 * n / float(N)\n\n    print(pi_est)", "fn_id": 0, "class_fn": false, "repo": "nonator/cp2018", "file": "00/src/pi_num.py", "last_update_at": "2018-06-06T19:38:55+00:00", "question_id": "792a06433102075502db4b1733b021f572e9080b_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main():\n    N = 100000\n    xy = rand(N, 2)\n    r = xy[:, 0] ** 2 + xy[:, 1] ** 2\n    n = sum(r < 1)\n    pi_est = 4 * n / float(N)\n"]]}
{"hexsha": "9b4ff6733b5a77f3fd810e8d919f031c83cbf26b", "ext": "py", "lang": "Python", "content": "def Fun_locateCorr(scoreMap, band):\n    assert len(scoreMap.shape) == 3\n    M_s = np.amax(scoreMap, axis = 2)\n    M_s = np.repeat(M_s[:, :, np.newaxis], band, axis=2) ##? Normalization?\n    maxIdxMap = np.argmax(scoreMap, axis = 2)\n    return M_s, maxIdxMap", "fn_id": 3, "class_fn": false, "repo": "cianhwang/nn-stitching", "file": "offline/patch_match.py", "last_update_at": "2018-08-05T03:54:59+00:00", "question_id": "9b4ff6733b5a77f3fd810e8d919f031c83cbf26b_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def Fun_locateCorr(scoreMap, band):\n    assert len(scoreMap.shape) == 3\n    M_s = np.amax(scoreMap, axis=2)\n    M_s = np.repeat(M_s[:, :, np.newaxis], band, axis=2)\n    maxIdxMap = np.argmax(scoreMap, axis=2)\n"]]}
{"hexsha": "cc20b8d10ba8793748ad472f2f4a3167d7f1623e", "ext": "py", "lang": "Python", "content": "def class_view_decorator(function_decorator):\n\t\"\"\"Convert a function based decorator into a class based decorator usable\n\ton class based Views.\n\tCan't subclass the `View` as it breaks inheritance (super in particular),\n\tso we monkey-patch instead.\n\t\"\"\"\n\n\tdef simple_decorator(view):\n\t\tview.dispatch = method_decorator(function_decorator)(view.dispatch)\n\t\treturn view\n\n\treturn simple_decorator", "fn_id": 0, "class_fn": false, "repo": "xuhuiliang-maybe/ace_office", "file": "modules/share_module/permissionMixin.py", "last_update_at": "2018-11-27T08:08:07+00:00", "question_id": "cc20b8d10ba8793748ad472f2f4a3167d7f1623e_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def class_view_decorator(function_decorator):\n    \"\"\"Convert a function based decorator into a class based decorator usable\n\ton class based Views.\n\tCan't subclass the `View` as it breaks inheritance (super in particular),\n\tso we monkey-patch instead.\n\t\"\"\"\n\n    def simple_decorator(view):\n        view.dispatch = method_decorator(function_decorator)(view.dispatch)\n        return view\n"]]}
{"hexsha": "5563fb5e00980509f3c5704f01d074062dd1d2c1", "ext": "py", "lang": "Python", "content": "@register.filter\ndef price(value, autoescape=None):\n\tvalue = int(value)\n\tif not value:\n\t\tg, s, c = 0, 0, 0\n\telse:\n\t\tg = divmod(value, 10000)[0]\n\t\ts = divmod(value, 100)[0] % 100\n\t\tc = value % 100\n\n\toutput = '<span class=\"price\">%s %s %s</span>' % (\n\t\tg and PRICE_TEMPLATE % {\"amt\": g, \"letter\": \"g\", \"alt\": \"Gold\"} or \"\",\n\t\ts and PRICE_TEMPLATE % {\"amt\": s, \"letter\": \"s\", \"alt\": \"Silver\"} or \"\",\n\t\tc and PRICE_TEMPLATE % {\"amt\": c, \"letter\": \"c\", \"alt\": \"Copper\"} or \"\",\n\t)\n\n\treturn safestring.mark_safe(output)", "fn_id": 4, "class_fn": false, "repo": "jleclanche/pywow", "file": "sigrie/sigrie/common/templatetags/extratags.py", "last_update_at": "2018-11-02T12:55:39+00:00", "question_id": "5563fb5e00980509f3c5704f01d074062dd1d2c1_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@register.filter\ndef price(value, autoescape=None):\n    value = int(value)\n    if not value:\n        g, s, c = (0, 0, 0)\n    else:\n        g = divmod(value, 10000)[0]\n        s = divmod(value, 100)[0] % 100\n        c = value % 100\n    output = '<span class=\"price\">%s %s %s</span>' % (g and PRICE_TEMPLATE % {'amt': g, 'letter': 'g', 'alt': 'Gold'} or '', s and PRICE_TEMPLATE % {'amt': s, 'letter': 's', 'alt': 'Silver'} or '', c and PRICE_TEMPLATE % {'amt': c, 'letter': 'c', 'alt': 'Copper'} or '')\n"]]}
{"hexsha": "1459454e2e53d67f8bf74512d0c34f48b41635d4", "ext": "py", "lang": "Python", "content": "@main.route(\"/search\")\ndef search():\n    text = request.args.get(\"text\", \"\", type=str)\n    if len(text) == 0 or len(text) > 128:\n        return redirect(url_for(\"main.index\"))\n\n    page = request.args.get(\"page\", 1, type=int)\n    pagination = Post.query.filter_by(disable=False).msearch(\n        text, fields=[\"html\", \"title\"]\n    ).order_by(\n        Post.timestamp.desc()\n    ).paginate(\n        page, current_app.config.get(\"FLASK_POST_PER_PAGE\", 20), error_out=False\n    )\n    posts = pagination.items\n    return render_template(\n        \"main/search.html\", posts=posts, pagination=pagination, text=text\n    )", "fn_id": 19, "class_fn": false, "repo": "Arianxx/LoniceraBlog", "file": "app/controller/main/view.py", "last_update_at": "2018-09-08T13:15:59+00:00", "question_id": "1459454e2e53d67f8bf74512d0c34f48b41635d4_19", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@main.route('/search')\ndef search():\n    text = request.args.get('text', '', type=str)\n    if len(text) == 0 or len(text) > 128:\n        return redirect(url_for('main.index'))\n    page = request.args.get('page', 1, type=int)\n    pagination = Post.query.filter_by(disable=False).msearch(text, fields=['html', 'title']).order_by(Post.timestamp.desc()).paginate(page, current_app.config.get('FLASK_POST_PER_PAGE', 20), error_out=False)\n    posts = pagination.items\n"]]}
{"hexsha": "b3f7c6bc7ff1be7d1d272943a1844cc2144a065d", "ext": "py", "lang": "Python", "content": "def check_directory(experiment_config, key):\n    '''Check whether a value in experiment_config is a valid directory'''\n    if not os.path.isdir(experiment_config[key]):\n        raise NotADirectoryError('%s is not a valid directory' % key)", "fn_id": 4, "class_fn": false, "repo": "narumiruna/nni", "file": "tools/nnicmd/launcher_utils.py", "last_update_at": "2018-09-12T06:32:56+00:00", "question_id": "b3f7c6bc7ff1be7d1d272943a1844cc2144a065d_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def check_directory(experiment_config, key):\n    \"\"\"Check whether a value in experiment_config is a valid directory\"\"\"\n    if not os.path.isdir(experiment_config[key]):\n"]]}
{"hexsha": "87534233570507f0d3c843ae7a174085e6179708", "ext": "py", "lang": "Python", "content": "def build_k_indices(y, k_fold, seed):\n    \"\"\"build k indices for k-fold.\"\"\"\n    num_row = len(y)\n    interval = int(num_row / k_fold)\n    np.random.seed(seed)\n    indices = np.random.permutation(num_row)\n    k_indices = [indices[k * interval: (k + 1) * interval]\n                 for k in range(k_fold)]\n    return np.array(k_indices)", "fn_id": 0, "class_fn": false, "repo": "dufourc1/ML_CS433_project2", "file": "src/cross_validation.py", "last_update_at": "2018-12-12T15:49:07+00:00", "question_id": "87534233570507f0d3c843ae7a174085e6179708_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def build_k_indices(y, k_fold, seed):\n    \"\"\"build k indices for k-fold.\"\"\"\n    num_row = len(y)\n    interval = int(num_row / k_fold)\n    np.random.seed(seed)\n    indices = np.random.permutation(num_row)\n    k_indices = [indices[k * interval:(k + 1) * interval] for k in range(k_fold)]\n"]]}
{"hexsha": "345953517a76826ec606ef9b1ea1d2e49f55af66", "ext": "py", "lang": "Python", "content": "def run(base_url='http://kolibridemo.learningequality.org', learners=3):\n    rate = 10\n    admin = AdminUser(base_url=base_url)\n    KolibriUserBehavior.KOLIBRI_USERS = admin.get_users()\n    resources = admin.get_resources()\n    exercise = [] if not resources['exercise'] else resources['exercise']\n    html5 = [] if not resources['html5'] else resources['html5']\n    KolibriUserBehavior.KOLIBRI_RESOURCES = {'video': [], 'html5': html5, 'document': [], 'exercise': exercise}\n    launch(WebsiteUser, base_url, learners, rate, run_time=30)", "fn_id": 0, "class_fn": false, "repo": "learningequality/velox", "file": "scenarios/opening_exercises_bundles_performance.py", "last_update_at": "2018-09-20T16:54:06+00:00", "question_id": "345953517a76826ec606ef9b1ea1d2e49f55af66_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def run(base_url='http://kolibridemo.learningequality.org', learners=3):\n    rate = 10\n    admin = AdminUser(base_url=base_url)\n    KolibriUserBehavior.KOLIBRI_USERS = admin.get_users()\n    resources = admin.get_resources()\n    exercise = [] if not resources['exercise'] else resources['exercise']\n    html5 = [] if not resources['html5'] else resources['html5']\n    KolibriUserBehavior.KOLIBRI_RESOURCES = {'video': [], 'html5': html5, 'document': [], 'exercise': exercise}\n"]]}
{"hexsha": "da955bc72241f3381c36db88f3d20e6ae419e9bc", "ext": "py", "lang": "Python", "content": "def main():\n    import random\n    secretNumber = random.randint(1, 20)\n    print('I am thinking of a number between 1 and 20.')\n\n    # Ask the player to guess 6 times.\n    for guessesTaken in range(1, 7):\n        print('Take a guess.')\n        guess = int(input())\n\n        if guess < secretNumber:\n            print('Your guess is too low.')\n        elif guess > secretNumber:\n            print('Your guess is too high.')\n        else:\n            break  # This condition is the correct guess!\n\n    if guess == secretNumber:\n        print('Good job! You guessed my number in ' + str(guessesTaken) + ' guesses!')\n    else:\n        print('Nope. The number I was thinking of was ' + str(secretNumber))", "fn_id": 0, "class_fn": false, "repo": "JoseALermaIII/python-tutorials", "file": "pythontutorials/books/AutomateTheBoringStuff/Ch03/P11_guessTheNumber.py", "last_update_at": "2018-10-12T20:15:47+00:00", "question_id": "da955bc72241f3381c36db88f3d20e6ae419e9bc_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main():\n    import random\n    secretNumber = random.randint(1, 20)\n    print('I am thinking of a number between 1 and 20.')\n    for guessesTaken in range(1, 7):\n        print('Take a guess.')\n        guess = int(input())\n        if guess < secretNumber:\n            print('Your guess is too low.')\n        elif guess > secretNumber:\n            print('Your guess is too high.')\n        else:\n            break\n    if guess == secretNumber:\n        print('Good job! You guessed my number in ' + str(guessesTaken) + ' guesses!')\n    else:\n"]]}
{"hexsha": "d0a342dd9bc21f5a13452e59322a4a47220800d5", "ext": "py", "lang": "Python", "content": "def get_simulated_distribution(n, k, sampler_name, num_trials):\n    if sampler_name == 'right':\n        Sampler = PacketSampler\n    elif sampler_name == 'wrong':\n        Sampler = PacketSamplerWrong\n    else:\n        raise ValueError('Unrecognized sampler name.')\n    \n    packet_counter = {p: 0 for p in range(n)}\n    for trial_ind in range(num_trials):\n        subset = get_packet_subset(n, Sampler(k))\n        for p in subset:\n            packet_counter[p] += 1\n    \n    return packet_counter", "fn_id": 1, "class_fn": false, "repo": "frrad/eopi", "file": "five/thirteen.py", "last_update_at": "2018-07-09T01:35:24+00:00", "question_id": "d0a342dd9bc21f5a13452e59322a4a47220800d5_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_simulated_distribution(n, k, sampler_name, num_trials):\n    if sampler_name == 'right':\n        Sampler = PacketSampler\n    elif sampler_name == 'wrong':\n        Sampler = PacketSamplerWrong\n    else:\n        raise ValueError('Unrecognized sampler name.')\n    packet_counter = {p: 0 for p in range(n)}\n    for trial_ind in range(num_trials):\n        subset = get_packet_subset(n, Sampler(k))\n        for p in subset:\n            packet_counter[p] += 1\n"]]}
{"hexsha": "fa77dd08a8bc2cf62a61f8d1b262aa436172e746", "ext": "py", "lang": "Python", "content": "def get_cell_ngrams(\n    mention: Union[Candidate, Mention, TemporarySpanMention],\n    attrib: str = \"words\",\n    n_min: int = 1,\n    n_max: int = 1,\n    lower: bool = True,\n) -> Iterator[str]:\n    \"\"\"Get the ngrams that are in the Cell of the given mention, not including itself.\n\n    Note that if a candidate is passed in, all of its Mentions will be searched.\n\n    :param mention: The Mention whose Cell is being searched\n    :param attrib: The token attribute type (e.g. words, lemmas, poses)\n    :param n_min: The minimum n of the ngrams that should be returned\n    :param n_max: The maximum n of the ngrams that should be returned\n    :param lower: If True, all ngrams will be returned in lower case\n    :rtype: a *generator* of ngrams\n    \"\"\"\n    spans = _to_spans(mention)\n    for span in spans:\n        for ngram in get_sentence_ngrams(\n            span, attrib=attrib, n_min=n_min, n_max=n_max, lower=lower\n        ):\n            yield ngram\n        if span.sentence.is_tabular():\n            for ngram in chain.from_iterable(\n                [\n                    tokens_to_ngrams(\n                        getattr(sentence, attrib), n_min=n_min, n_max=n_max, lower=lower\n                    )\n                    for sentence in _get_table_cells(span.sentence.table)[\n                        span.sentence.cell\n                    ]\n                    if sentence != span.sentence\n                ]\n            ):\n                yield ngram", "fn_id": 11, "class_fn": false, "repo": "kaikun213/fonduer", "file": "src/fonduer/utils/data_model_utils/tabular.py", "last_update_at": "2018-11-02T06:02:13+00:00", "question_id": "fa77dd08a8bc2cf62a61f8d1b262aa436172e746_11", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_cell_ngrams(mention: Union[Candidate, Mention, TemporarySpanMention], attrib: str='words', n_min: int=1, n_max: int=1, lower: bool=True) -> Iterator[str]:\n    \"\"\"Get the ngrams that are in the Cell of the given mention, not including itself.\n\n    Note that if a candidate is passed in, all of its Mentions will be searched.\n\n    :param mention: The Mention whose Cell is being searched\n    :param attrib: The token attribute type (e.g. words, lemmas, poses)\n    :param n_min: The minimum n of the ngrams that should be returned\n    :param n_max: The maximum n of the ngrams that should be returned\n    :param lower: If True, all ngrams will be returned in lower case\n    :rtype: a *generator* of ngrams\n    \"\"\"\n    spans = _to_spans(mention)\n    for span in spans:\n        for ngram in get_sentence_ngrams(span, attrib=attrib, n_min=n_min, n_max=n_max, lower=lower):\n            yield ngram\n        if span.sentence.is_tabular():\n            for ngram in chain.from_iterable([tokens_to_ngrams(getattr(sentence, attrib), n_min=n_min, n_max=n_max, lower=lower) for sentence in _get_table_cells(span.sentence.table)[span.sentence.cell] if sentence != span.sentence]):\n"]]}
{"hexsha": "fe113738d2252bc64fa7ad75fcb06d08e471e6cc", "ext": "py", "lang": "Python", "content": "def get_between_to_end_of_str(text, from_letter):\n\tif text is None:\n\t\treturn ''\n\n\tparts = []\n\tstart_saving = False\n\tfor s in text:\n\t\t# if you don't have a string then save it \n\t\tif start_saving and not is_alpha(s) and s !='_' :\n\t\t\treturn ''.join(parts)\n\t\t# add the letters\n\t\tif s == from_letter:\n\t\t\tstart_saving = True\n\t\telif start_saving:\n\t\t\tparts.append(s) \n\treturn ''.join (parts)", "fn_id": 4, "class_fn": false, "repo": "narratorai/py-queryparser", "file": "queryParser.py", "last_update_at": "2018-12-03T21:44:44+00:00", "question_id": "fe113738d2252bc64fa7ad75fcb06d08e471e6cc_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_between_to_end_of_str(text, from_letter):\n    if text is None:\n        return ''\n    parts = []\n    start_saving = False\n    for s in text:\n        if start_saving and (not is_alpha(s)) and (s != '_'):\n            return ''.join(parts)\n        if s == from_letter:\n            start_saving = True\n        elif start_saving:\n            parts.append(s)\n"]]}
{"hexsha": "6fea3de05c7bf763b51e5261c176aa7945155989", "ext": "py", "lang": "Python", "content": "def N(m, L):\n    if (m, L) in cache.keys():\n        return cache[(m, L)]\n    else:\n        cache[(m, L)] = _N(m, L)\n        return cache[(m, L)]", "fn_id": 0, "class_fn": false, "repo": "jaimeliew1/Project_Euler_Solutions", "file": "Python/115.py", "last_update_at": "2018-04-16T21:01:50+00:00", "question_id": "6fea3de05c7bf763b51e5261c176aa7945155989_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def N(m, L):\n    if (m, L) in cache.keys():\n        return cache[m, L]\n    else:\n        cache[m, L] = _N(m, L)\n"]]}
{"hexsha": "d1267f95c8d6024b1d0fdf76614c62ea7746645c", "ext": "py", "lang": "Python", "content": "def test_linearizer_performs_topological_ordering(valid_graph, linearizer):\n    ordering = linearizer.linearize(valid_graph)\n    assert set(ordering) == set(valid_graph)\n    for index, item in enumerate(ordering):\n        assert valid_graph[item].parents <= set(ordering[:index])", "fn_id": 0, "class_fn": false, "repo": "thoughteer/edera", "file": "tests/unit/linearizers/test_linearizers.py", "last_update_at": "2018-12-21T20:32:10+00:00", "question_id": "d1267f95c8d6024b1d0fdf76614c62ea7746645c_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_linearizer_performs_topological_ordering(valid_graph, linearizer):\n    ordering = linearizer.linearize(valid_graph)\n    assert set(ordering) == set(valid_graph)\n    for index, item in enumerate(ordering):\n"]]}
{"hexsha": "123ebd763cbf4c742c2363c86f93d8dac352b66d", "ext": "py", "lang": "Python", "content": "def get_digikey_parts_set(path):\n    \"\"\"\n    Reads in the digikey part dictionary and yeilds each part.\n    \"\"\"\n    all_parts = set()\n    with open(path, \"r\") as csvinput:\n        reader = csv.reader(csvinput)\n        for line in reader:\n            (part, url) = line\n            all_parts.add(part)\n    return all_parts", "fn_id": 0, "class_fn": false, "repo": "leewaymay/839_fonduer", "file": "tutorials/hardware/max_storage_temp_tutorial.py", "last_update_at": "2018-05-31T02:44:00+00:00", "question_id": "123ebd763cbf4c742c2363c86f93d8dac352b66d_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_digikey_parts_set(path):\n    \"\"\"\n    Reads in the digikey part dictionary and yeilds each part.\n    \"\"\"\n    all_parts = set()\n    with open(path, 'r') as csvinput:\n        reader = csv.reader(csvinput)\n        for line in reader:\n            part, url = line\n            all_parts.add(part)\n"]]}
{"hexsha": "d3d69168a927610239335d1b46a4e0afe4b0e6b0", "ext": "py", "lang": "Python", "content": "def test_where():\n    ray_df = create_test_dataframe()\n\n    with pytest.raises(NotImplementedError):\n        ray_df.where(None)", "fn_id": 189, "class_fn": false, "repo": "cathywu/ray", "file": "python/ray/dataframe/test/test_dataframe.py", "last_update_at": "2018-01-19T02:42:28+00:00", "question_id": "d3d69168a927610239335d1b46a4e0afe4b0e6b0_189", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_where():\n    ray_df = create_test_dataframe()\n    with pytest.raises(NotImplementedError):\n"]]}
{"hexsha": "6636c2db5d917dd3290a01326f8c2e81f247677a", "ext": "py", "lang": "Python", "content": "@then('they are able to see the Status for each collection exercise')\ndef survey_ce_state_is_scheduled(context):\n    ce_state = collection_exercise.get_table_row_by_period(context.period)['state']\n    assert collection_exercise.is_scheduled(ce_state), ce_state", "fn_id": 4, "class_fn": false, "repo": "ONSdigital/ras-integration-tests", "file": "acceptance_tests/features/steps/view_collection_exercise_scheduled_state.py", "last_update_at": "2018-01-29T13:12:12+00:00", "question_id": "6636c2db5d917dd3290a01326f8c2e81f247677a_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@then('they are able to see the Status for each collection exercise')\ndef survey_ce_state_is_scheduled(context):\n    ce_state = collection_exercise.get_table_row_by_period(context.period)['state']\n"]]}
{"hexsha": "9305b9d74d47329bbb26439c66ef4462dc6354f2", "ext": "py", "lang": "Python", "content": "def create_ecdsap256_key_pair():\n    \"\"\"\n    Create a new ECDSAP256 key pair.\n\n    :returns: a tuple of the public and private keys\n    \"\"\"\n    pub  = ECDSAP256PublicKey()\n    priv = ECDSAP256PrivateKey()\n    rc = _lib.xtt_crypto_create_ecdsap256_key_pair(pub.native, priv.native)\n    if rc == RC.SUCCESS:\n        return (pub, priv)\n    else:\n        raise error_from_code(rc)", "fn_id": 0, "class_fn": false, "repo": "xaptum/xtt-python", "file": "xtt/crypto/ecdsap256.py", "last_update_at": "2018-11-13T17:14:32+00:00", "question_id": "9305b9d74d47329bbb26439c66ef4462dc6354f2_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def create_ecdsap256_key_pair():\n    \"\"\"\n    Create a new ECDSAP256 key pair.\n\n    :returns: a tuple of the public and private keys\n    \"\"\"\n    pub = ECDSAP256PublicKey()\n    priv = ECDSAP256PrivateKey()\n    rc = _lib.xtt_crypto_create_ecdsap256_key_pair(pub.native, priv.native)\n    if rc == RC.SUCCESS:\n        return (pub, priv)\n    else:\n"]]}
{"hexsha": "cb740bae988930c3351e3b9a0d512bf202ad6dcc", "ext": "py", "lang": "Python", "content": "def outlier_rejection(X, y):\n    model = IsolationForest(max_samples=100,\n                            contamination=0.4,\n                            random_state=rng)\n    model.fit(X)\n    y_pred = model.predict(X)\n    return X[y_pred == 1], y[y_pred == 1]", "fn_id": 1, "class_fn": false, "repo": "seabay/UnbalancedDataset", "file": "examples/plot_outlier_rejections.py", "last_update_at": "2018-07-11T06:47:11+00:00", "question_id": "cb740bae988930c3351e3b9a0d512bf202ad6dcc_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def outlier_rejection(X, y):\n    model = IsolationForest(max_samples=100, contamination=0.4, random_state=rng)\n    model.fit(X)\n    y_pred = model.predict(X)\n"]]}
{"hexsha": "742ad604de0f6aef053e6c6a60279b2f11fb6047", "ext": "py", "lang": "Python", "content": "@baker.command\ndef show_npz_info(*npz_file):\n    import numpy as np\n\n    for fname in npz_file:\n        print('filename', fname)\n        x, y, qid, docno = core.io.load_npz(fname)\n        if docno is not None:\n            print('x', x.shape, 'y', y.shape, 'qid', qid.shape, 'docno', docno.shape)\n        else:\n            print('x', x.shape, 'y', y.shape, 'qid', qid.shape, 'docno', None)\n\n        print('labels:', {int(k): v for k, v in zip(*map(list, np.unique(y, return_counts=True)))})\n\n        unique_qid = np.unique(qid)\n        print('qid (unique):', unique_qid.size)\n        print(unique_qid)\n        print()", "fn_id": 3, "class_fn": false, "repo": "JerryMXB/LTR_Cascade", "file": "python/tools.py", "last_update_at": "2018-05-17T03:13:50+00:00", "question_id": "742ad604de0f6aef053e6c6a60279b2f11fb6047_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@baker.command\ndef show_npz_info(*npz_file):\n    import numpy as np\n    for fname in npz_file:\n        print('filename', fname)\n        x, y, qid, docno = core.io.load_npz(fname)\n        if docno is not None:\n            print('x', x.shape, 'y', y.shape, 'qid', qid.shape, 'docno', docno.shape)\n        else:\n            print('x', x.shape, 'y', y.shape, 'qid', qid.shape, 'docno', None)\n        print('labels:', {int(k): v for k, v in zip(*map(list, np.unique(y, return_counts=True)))})\n        unique_qid = np.unique(qid)\n        print('qid (unique):', unique_qid.size)\n        print(unique_qid)\n"]]}
{"hexsha": "ac5adc216e25d4e12328bbe4b1ed47787893ea3f", "ext": "py", "lang": "Python", "content": "def parameters_for_script(script_name, config):\n    \"\"\"Return a list consisting of :py:class:`cea.config.Parameter` objects for each parameter of a script\"\"\"\n    import cea.scripts\n    parameters = [p for _, p in config.matching_parameters(cea.scripts.by_name(script_name).parameters)]\n    return parameters", "fn_id": 11, "class_fn": false, "repo": "architecture-building-systems/cea-dashboard", "file": "cea_dashboard/tools/routes.py", "last_update_at": "2018-10-03T10:20:23+00:00", "question_id": "ac5adc216e25d4e12328bbe4b1ed47787893ea3f_11", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def parameters_for_script(script_name, config):\n    \"\"\"Return a list consisting of :py:class:`cea.config.Parameter` objects for each parameter of a script\"\"\"\n    import cea.scripts\n    parameters = [p for _, p in config.matching_parameters(cea.scripts.by_name(script_name).parameters)]\n"]]}
{"hexsha": "a4559ffde5465496c709e5729d790051fb880309", "ext": "py", "lang": "Python", "content": "def test_modules_test_no_name_no_prompts(self):\n    \"\"\"Test the check_inputs() function - raise UserWarning prompts are deactivated and module name is not provided.\"\"\"\n    cwd = os.getcwd()\n    os.chdir(self.nfcore_modules)\n    meta_builder = nf_core.modules.ModulesTest(None, True, \"\")\n    with pytest.raises(UserWarning) as excinfo:\n        meta_builder._check_inputs()\n    os.chdir(cwd)\n    assert \"Tool name not provided and prompts deactivated.\" in str(excinfo.value)", "fn_id": 1, "class_fn": false, "repo": "jfy133/nf-core-tools", "file": "tests/modules/module_test.py", "last_update_at": "2018-02-13T16:05:01+00:00", "question_id": "a4559ffde5465496c709e5729d790051fb880309_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_modules_test_no_name_no_prompts(self):\n    \"\"\"Test the check_inputs() function - raise UserWarning prompts are deactivated and module name is not provided.\"\"\"\n    cwd = os.getcwd()\n    os.chdir(self.nfcore_modules)\n    meta_builder = nf_core.modules.ModulesTest(None, True, '')\n    with pytest.raises(UserWarning) as excinfo:\n        meta_builder._check_inputs()\n    os.chdir(cwd)\n"]]}
{"hexsha": "8cd8527dcae517b1a1bb913ab6531b6e6cece151", "ext": "py", "lang": "Python", "content": "def selectCenters(image, centers, size):\n    size = int(size)\n    padded = pad(image, size, 'constant')\n    return array([padded[center[0]:center[0]+2*size+1,center[1]:center[1]+2*size+1] for center in centers])", "fn_id": 0, "class_fn": false, "repo": "sofroniewn/Mesoscope", "file": "mesoscope/CC.py", "last_update_at": "2018-12-21T16:32:21+00:00", "question_id": "8cd8527dcae517b1a1bb913ab6531b6e6cece151_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def selectCenters(image, centers, size):\n    size = int(size)\n    padded = pad(image, size, 'constant')\n"]]}
{"hexsha": "d17203bc58489c2d4bf54d79f6379d4ff366e7c1", "ext": "py", "lang": "Python", "content": "def add_K_Relations(searchExe, varRels):\n    relations = searchExe.relations\n    tasks = collections.defaultdict(set)\n    for (acro, ks) in varRels.items():\n        j = searchExe.relationFromName[acro]\n        ji = searchExe.converse[j]\n        if ji < j:\n            (j, ji) = (ji, j)\n        acro = relations[j][\"acro\"]\n        acroi = relations[ji][\"acro\"]\n        tasks[(j, acro, ji, acroi)] |= ks\n\n    for ((j, acro, ji, acroi), ks) in tasks.items():\n        for k in ks:\n            newAcro = acro.replace(\"k\", str(k))\n            newAcroi = acroi.replace(\"k\", str(k))\n            r = relations[j]\n            ri = relations[ji]\n            lr = len(relations)\n            relations.extend(\n                [\n                    dict(\n                        name=acro,\n                        acro=newAcro,\n                        spin=r[\"spin\"],\n                        func=r[\"func\"](k),\n                        desc=r[\"desc\"],\n                    ),\n                    dict(\n                        name=acroi,\n                        acro=newAcroi,\n                        spin=ri[\"spin\"],\n                        func=ri[\"func\"](k),\n                        desc=ri[\"desc\"],\n                    ),\n                ]\n            )\n            searchExe.relationFromName[newAcro] = lr\n            searchExe.relationFromName[newAcroi] = lr + 1\n            searchExe.converse[lr] = lr + 1\n            searchExe.converse[lr + 1] = lr", "fn_id": 3, "class_fn": false, "repo": "ancient-data/text-fabric", "file": "tf/search/relations.py", "last_update_at": "2018-12-12T06:10:10+00:00", "question_id": "d17203bc58489c2d4bf54d79f6379d4ff366e7c1_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def add_K_Relations(searchExe, varRels):\n    relations = searchExe.relations\n    tasks = collections.defaultdict(set)\n    for acro, ks in varRels.items():\n        j = searchExe.relationFromName[acro]\n        ji = searchExe.converse[j]\n        if ji < j:\n            j, ji = (ji, j)\n        acro = relations[j]['acro']\n        acroi = relations[ji]['acro']\n        tasks[j, acro, ji, acroi] |= ks\n    for (j, acro, ji, acroi), ks in tasks.items():\n        for k in ks:\n            newAcro = acro.replace('k', str(k))\n            newAcroi = acroi.replace('k', str(k))\n            r = relations[j]\n            ri = relations[ji]\n            lr = len(relations)\n            relations.extend([dict(name=acro, acro=newAcro, spin=r['spin'], func=r['func'](k), desc=r['desc']), dict(name=acroi, acro=newAcroi, spin=ri['spin'], func=ri['func'](k), desc=ri['desc'])])\n            searchExe.relationFromName[newAcro] = lr\n            searchExe.relationFromName[newAcroi] = lr + 1\n            searchExe.converse[lr] = lr + 1\n"]]}
{"hexsha": "d6bde785ae4a603ccea1d9f9eddf6af4a21ebf1f", "ext": "py", "lang": "Python", "content": "def get_token():\n    request = requests.get('http://randomword.setgetgo.com/get.php')\n    word = request.text\n    print(\"\")\n    print('\\x1b[0m' + \"Hashing the word \"  + '\\033[93m' + word + '\\x1b[0m' + \". Please wait...\" + '\\033[92m')\n    print('\\033[92m')\n    password = word.encode(encoding='UTF-8',errors='strict')\n    hashed = bcrypt.hashpw(password, bcrypt.gensalt(14))\n    return hashed", "fn_id": 0, "class_fn": false, "repo": "Santiago-vdk/jabbs", "file": "jobs/models.py", "last_update_at": "2018-05-02T11:06:52+00:00", "question_id": "d6bde785ae4a603ccea1d9f9eddf6af4a21ebf1f_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_token():\n    request = requests.get('http://randomword.setgetgo.com/get.php')\n    word = request.text\n    print('')\n    print('\\x1b[0m' + 'Hashing the word ' + '\\x1b[93m' + word + '\\x1b[0m' + '. Please wait...' + '\\x1b[92m')\n    print('\\x1b[92m')\n    password = word.encode(encoding='UTF-8', errors='strict')\n    hashed = bcrypt.hashpw(password, bcrypt.gensalt(14))\n"]]}
{"hexsha": "52ca976eac44d9114107c1b51283d302e02a92d0", "ext": "py", "lang": "Python", "content": "def create_indexed_signal(timestamps, signal): # both assumed to be time frames\n    signal['timestamps'] = timestamps\n    signal_indexed = signal.set_index(['timestamps'])\n    return signal_indexed", "fn_id": 2, "class_fn": false, "repo": "alexDeCastroAtGit/belkin_challenge", "file": "data/data_processing.py", "last_update_at": "2018-05-02T00:48:39+00:00", "question_id": "52ca976eac44d9114107c1b51283d302e02a92d0_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def create_indexed_signal(timestamps, signal):\n    signal['timestamps'] = timestamps\n    signal_indexed = signal.set_index(['timestamps'])\n"]]}
{"hexsha": "6a660cf0a5e11b4dcec0f57e569a500951cfaa24", "ext": "py", "lang": "Python", "content": "@rule\nasync def setup_isort(isort: Isort) -> IsortSetup:\n  config_path: Optional[List[str]] = isort.options.config\n  config_snapshot = await Get[Snapshot](PathGlobs(include=config_path or ()))\n  requirements_pex = await Get[Pex](\n    CreatePex(\n      output_filename=\"isort.pex\",\n      requirements=PexRequirements(requirements=tuple(isort.get_requirement_specs())),\n      interpreter_constraints=PexInterpreterConstraints(\n        constraint_set=tuple(isort.default_interpreter_constraints)\n      ),\n      entry_point=isort.get_entry_point(),\n    )\n  )\n  return IsortSetup(\n    requirements_pex=requirements_pex,\n    config_snapshot=config_snapshot,\n    passthrough_args=tuple(isort.options.args),\n    skip=isort.options.skip,\n  )", "fn_id": 0, "class_fn": false, "repo": "mpopenko-exos/pants", "file": "src/python/pants/backend/python/lint/isort/rules.py", "last_update_at": "2018-09-04T19:42:58+00:00", "question_id": "6a660cf0a5e11b4dcec0f57e569a500951cfaa24_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@rule\nasync def setup_isort(isort: Isort) -> IsortSetup:\n    config_path: Optional[List[str]] = isort.options.config\n    config_snapshot = await Get[Snapshot](PathGlobs(include=config_path or ()))\n    requirements_pex = await Get[Pex](CreatePex(output_filename='isort.pex', requirements=PexRequirements(requirements=tuple(isort.get_requirement_specs())), interpreter_constraints=PexInterpreterConstraints(constraint_set=tuple(isort.default_interpreter_constraints)), entry_point=isort.get_entry_point()))\n"]]}
{"hexsha": "0ee24f0ede5963637b0001c5322ef2a31c5be87f", "ext": "py", "lang": "Python", "content": "def get_init_bg(data):\n    #Compute the log background frequency of all words\n    sums = np.sum(data, axis=0)+1\n    print(\"Computing background frequencies\")\n    print(\"Min/max word counts in training data: %d %d\" % (int(np.min(sums)), int(np.max(sums))))\n    bg = np.array(np.log(sums) - np.log(float(np.sum(sums))), dtype=np.float32)\n    return bg", "fn_id": 6, "class_fn": false, "repo": "rococode/scholar", "file": "run_scholar.py", "last_update_at": "2018-12-08T02:18:20+00:00", "question_id": "0ee24f0ede5963637b0001c5322ef2a31c5be87f_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_init_bg(data):\n    sums = np.sum(data, axis=0) + 1\n    print('Computing background frequencies')\n    print('Min/max word counts in training data: %d %d' % (int(np.min(sums)), int(np.max(sums))))\n    bg = np.array(np.log(sums) - np.log(float(np.sum(sums))), dtype=np.float32)\n"]]}
{"hexsha": "40793c0dd18dff62c006cfb6fc284053076cde42", "ext": "py", "lang": "Python", "content": "@pytest.fixture()\ndef dummy_featuretiles():\n    yaml = \"\"\"\nname: vp1\n    \"\"\"\n    vp = FeaturetilesWidget('widget1', 'widget1', yaml)\n    yield vp", "fn_id": 0, "class_fn": false, "repo": "pauleveritt/kaybee", "file": "tests/unit/plugins/articles/test_featuretiles.py", "last_update_at": "2018-12-21T12:41:41+00:00", "question_id": "40793c0dd18dff62c006cfb6fc284053076cde42_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.fixture()\ndef dummy_featuretiles():\n    yaml = '\\nname: vp1\\n    '\n    vp = FeaturetilesWidget('widget1', 'widget1', yaml)\n"]]}
{"hexsha": "2ac3a7f55130bc75a7cd25c38393cea4a8cafd3f", "ext": "py", "lang": "Python", "content": "def test_generate_date_series_end_date_none(start_date, interval, granularity):\n    (interval_param, interval, interval_str) = interval\n    (start_date_param, start_date, start_date_str) = start_date\n    (granularity_param, granularity, granularity_str) = granularity\n    if start_date_param and interval_param:\n        end_date_str = start_date.strftime('%Y-%m-%d %H:%M:%S.%f')\n    else:\n        end_date_str = UTCNOW.strftime('%Y-%m-%d %H:%M:%S.%f')\n\n    if not start_date_param:\n        expected = 'generate_series(DATE {} - INTERVAL {}, {}, {})'.format(\n            end_date_str, interval_str, end_date_str, granularity_str)\n    elif not interval_param:\n        expected = 'generate_series({}, {}, {})'.format(start_date_str, end_date_str, granularity_str)\n    else:\n        expected = 'generate_series({}, DATE {} + INTERVAL {}, {})'.format(\n            start_date_str, end_date_str, interval_str, granularity_str)\n\n    query = generate_date_series(start_date_param, None, interval_param, granularity_param)\n    expression = query.compile(dialect=postgresql.dialect())\n    actual = str(expression) % expression.params\n    assert expected == actual", "fn_id": 6, "class_fn": false, "repo": "magfest/residue", "file": "tests/test_query.py", "last_update_at": "2018-02-26T19:03:19+00:00", "question_id": "2ac3a7f55130bc75a7cd25c38393cea4a8cafd3f_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_generate_date_series_end_date_none(start_date, interval, granularity):\n    interval_param, interval, interval_str = interval\n    start_date_param, start_date, start_date_str = start_date\n    granularity_param, granularity, granularity_str = granularity\n    if start_date_param and interval_param:\n        end_date_str = start_date.strftime('%Y-%m-%d %H:%M:%S.%f')\n    else:\n        end_date_str = UTCNOW.strftime('%Y-%m-%d %H:%M:%S.%f')\n    if not start_date_param:\n        expected = 'generate_series(DATE {} - INTERVAL {}, {}, {})'.format(end_date_str, interval_str, end_date_str, granularity_str)\n    elif not interval_param:\n        expected = 'generate_series({}, {}, {})'.format(start_date_str, end_date_str, granularity_str)\n    else:\n        expected = 'generate_series({}, DATE {} + INTERVAL {}, {})'.format(start_date_str, end_date_str, interval_str, granularity_str)\n    query = generate_date_series(start_date_param, None, interval_param, granularity_param)\n    expression = query.compile(dialect=postgresql.dialect())\n    actual = str(expression) % expression.params\n"]]}
{"hexsha": "4d7cc775f00b1b11a0c08dffa7ffc626adaef5d6", "ext": "py", "lang": "Python", "content": "def strip_leader(s, prefix):\n    \"\"\"Remove given prefix from underscored name.\"\"\"\n    leader = prefix + \"_\"\n    if s.startswith(leader):\n        return s[len(leader) :]\n    else:\n        return s", "fn_id": 5, "class_fn": false, "repo": "italocoin-project/Huva", "file": "src/device_trezor/trezor/tools/pb2cpp.py", "last_update_at": "2018-12-01T17:54:57+00:00", "question_id": "4d7cc775f00b1b11a0c08dffa7ffc626adaef5d6_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def strip_leader(s, prefix):\n    \"\"\"Remove given prefix from underscored name.\"\"\"\n    leader = prefix + '_'\n    if s.startswith(leader):\n        return s[len(leader):]\n    else:\n"]]}
{"hexsha": "39f09795a7cfe287cf26316abfab0ef79424135a", "ext": "py", "lang": "Python", "content": "def check_password(password):\n    if re.match(r'[a-zA-Z_]+[A-Za-z0-9@#!$%^&+=]{8,}', str(password)):\n        return False\n    response = {'message': 'Password should contain at least eight ' +\n                           'characters with at least one digit, one ' +\n                           'uppercase letter and one lowercase letter'}\n    return jsonify(response), 400", "fn_id": 4, "class_fn": false, "repo": "muthash/Weconnect-api", "file": "app/utils.py", "last_update_at": "2018-03-15T17:08:11+00:00", "question_id": "39f09795a7cfe287cf26316abfab0ef79424135a_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def check_password(password):\n    if re.match('[a-zA-Z_]+[A-Za-z0-9@#!$%^&+=]{8,}', str(password)):\n        return False\n    response = {'message': 'Password should contain at least eight ' + 'characters with at least one digit, one ' + 'uppercase letter and one lowercase letter'}\n"]]}
{"hexsha": "f5a4db3668dc937e3959615b4d2fcbb357d2769c", "ext": "py", "lang": "Python", "content": "@common.arg(\n    'node',\n    metavar='<node_uuid>',\n    help='Create a port based on a given ironic node uuid.')\n@common.arg(\n    '-m', '--mac',\n    help='MAC Address of the HPE OneView Server Hardware.')\ndef do_port_create(args):\n    \"\"\"Create port based on a Ironic Node.\n\n    If not specified, it retrieves the mac address of the first '-a' available\n    port at the Server Hardware to which the Ironic Node is related to. It\n    also gathers the local link connection if the Ironic Node is enabled to\n    use the OneView ml2 driver.\n    \"\"\"\n    facade_obj = facade.Facade(args)\n    port_creator = PortCreator(facade_obj)\n\n    ironic_node = facade_obj.get_ironic_node(args.node)\n    port = port_creator.create_port(args, ironic_node)\n\n    if port:\n        print(\"Created port %s\" % port.uuid)\n", "fn_id": 0, "class_fn": false, "repo": "HewlettPackard/ironic-oneview-cli", "file": "ironic_oneview_cli/create_port_shell/commands.py", "last_update_at": "2018-03-19T03:44:28+00:00", "question_id": "f5a4db3668dc937e3959615b4d2fcbb357d2769c_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@common.arg('node', metavar='<node_uuid>', help='Create a port based on a given ironic node uuid.')\n@common.arg('-m', '--mac', help='MAC Address of the HPE OneView Server Hardware.')\ndef do_port_create(args):\n    \"\"\"Create port based on a Ironic Node.\n\n    If not specified, it retrieves the mac address of the first '-a' available\n    port at the Server Hardware to which the Ironic Node is related to. It\n    also gathers the local link connection if the Ironic Node is enabled to\n    use the OneView ml2 driver.\n    \"\"\"\n    facade_obj = facade.Facade(args)\n    port_creator = PortCreator(facade_obj)\n    ironic_node = facade_obj.get_ironic_node(args.node)\n    port = port_creator.create_port(args, ironic_node)\n    if port:\n"]]}
{"hexsha": "fc376780cca12cf7d8b363ab2ea7991d81344231", "ext": "py", "lang": "Python", "content": "def VSFcalc(u,v,lat,lon, nd):\n    \"\"\"\n    : VSFcalc:\n      Calculate Vortex-surface fields applying\n      solution of geodesic using Vincenty formula\n    \"\"\"\n\n    # vectorize the computation:\n    # Slice the arrays for differencing\n    du_j = u[1:nd,:] - u[0:nd-1,:]\n    dv_j = v[1:nd,:] - v[0:nd-1,:]\n\n    arr1 = np.array((lat[0:nd-1,:]))\n    arr2 = np.array((lon[0:nd-1,:]))\n    arr3 = np.array((lat[1:nd,:]))\n    arr4 = np.array((lon[1:nd,:]))\n\n    # Warning: geopy.distance.vincenty is depracated!\n    #          Try geopy.distance.geodesic for more accurate numbers\n    print('')\n    print(' Begin \"vincenty\" calculations... ')\n    # This part consumes more resources and can be parallelized\n    # if you intend to manipulate a 3D array or larger 2D arrays\n    # It takes about 30seconds for the current array dims nd, nt\n    dx_j = [ vincenty((kj,lj),(mj,nj)).km if np.isfinite(oj) else np.nan \n             for kj,lj,mj,nj,oj in np.nditer([arr1,arr2,arr1,arr4,du_j]) ] \n    dy_j = [ vincenty((kj,lj),(mj,nj)).km if np.isfinite(oj) else np.nan \n             for kj,lj,mj,nj,oj in np.nditer([arr1,arr2,arr3,arr2,du_j]) ] \n    dr_j = [ vincenty((kj,lj),(mj,nj)).km if np.isfinite(oj) else np.nan \n             for kj,lj,mj,nj,oj in np.nditer([arr1,arr2,arr3,arr4,du_j]) ] \n    # \"dr_j2\" would be necessary if an iterator is returned by the function\n    #dr_j2 = [ (yield vincenty((kj,lj),(mj,nj)).km) if np.isfinite(oj) else (yield np.nan) \n    #         for kj,lj,mj,nj,oj in np.nditer([arr1,arr2,arr3,arr4,du_j]) ] \n\n    dx_s = [ np.sign(kj-lj) if np.isfinite(oj) else np.nan \n             for kj,lj,oj in np.nditer([arr4,arr2,du_j]) ] \n    dy_s = [ np.sign(kj-lj) if np.isfinite(oj) else np.nan \n             for kj,lj,oj in np.nditer([arr3,arr1,du_j]) ] \n    print(' \"vincenty\" calculations Finished')\n\n    # Mask the variables to avoid 'NaNs'\n    dx_j = np.ma.masked_where(np.isfinite(dx_j), dx_j)\n    dy_j = np.ma.masked_where(np.isfinite(dy_j), dy_j)\n    dx_s = np.ma.masked_where(np.isfinite(dx_s), dx_s)\n    dy_s = np.ma.masked_where(np.isfinite(dy_s), dy_s)\n\n    print(' Begin functions mapping... ')\n    # - \"dx=dx_j.data*dx_s.data\" and dy=dy_j.data*dy_s.data\"\n    #   would also work but could result to\n    #   erroneous numbers. It is not clear how Numpy handles 'NaN'\n    # - Using the conditions a below will only give correct results\n    #   if both boolean values of the ordered pair are similar\n    #   otherwise the truth table of the if condition will not\n    #   result to the expected results\n    # - The map function generates an iterator which is more efficient\n    dx   = map( lambda x: x[0]*x[1] if np.any([x[0], x[1]], axis=0)   \n                else np.nan, list(zip(dx_j.data,dx_s.data))) \n    dy   = map( lambda y: y[0]*y[1] if np.any([y[0], y[1]], axis=0)  \n                else np.nan, list(zip(dy_j.data,dy_s.data)))  \n\n    # It is necessary to copy your generators here for multiple usage\n    dx, dxObj = itertools.tee(dx)\n    dy, dyObj = itertools.tee(dy)\n   \n    # - \"dl=(du_j*dx + dv_j*dy)/dr_j\" and \"dt=(-du_j*dy + dv_j*dx)/dr_j\" \n    #   would also work but could result to\n    #   erroneous numbers. It is not clear how Numpy handles 'NaN'\n    # - Using the conditions a below will only give correct results\n    #   if both boolean values of the ordered tuple are similar\n    #   otherwise the truth table of the if condition will not\n    #   result to the expected results\n    # - The map function generates an iterator which is more efficient\n    dl   = map( lambda dj: (dj[0]*dj[2] + dj[1]*dj[3])/dj[4] if np.any([dj[0], dj[4]], axis=0)     \n                else np.nan, list(zip(*du_j,*dv_j,list(dx),list(dy),dr_j)))    \n    dt   = map( lambda dj: (-dj[0]*dj[3] + dj[1]*dj[2])/dj[4] if np.any([dj[0], dj[4]], axis=0)     \n                else np.nan, list(zip(*du_j,*dv_j,list(dxObj),list(dyObj),dr_j)))      \n    print(' Functions mapping Finished ')\n\n    print('... returning a list of output')\n    # returning list consumes a lot of memory\n    # and slows down the I/O. This can be avoided\n    # by returning an iterator which can be \n    # used to write data to an appendable text file\n    return list(dl), list(dt), dr_j", "fn_id": 0, "class_fn": false, "repo": "JackOgaja/geo-dynamics", "file": "VSF_simple.py", "last_update_at": "2018-08-12T21:57:09+00:00", "question_id": "fc376780cca12cf7d8b363ab2ea7991d81344231_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def VSFcalc(u, v, lat, lon, nd):\n    \"\"\"\n    : VSFcalc:\n      Calculate Vortex-surface fields applying\n      solution of geodesic using Vincenty formula\n    \"\"\"\n    du_j = u[1:nd, :] - u[0:nd - 1, :]\n    dv_j = v[1:nd, :] - v[0:nd - 1, :]\n    arr1 = np.array(lat[0:nd - 1, :])\n    arr2 = np.array(lon[0:nd - 1, :])\n    arr3 = np.array(lat[1:nd, :])\n    arr4 = np.array(lon[1:nd, :])\n    print('')\n    print(' Begin \"vincenty\" calculations... ')\n    dx_j = [vincenty((kj, lj), (mj, nj)).km if np.isfinite(oj) else np.nan for kj, lj, mj, nj, oj in np.nditer([arr1, arr2, arr1, arr4, du_j])]\n    dy_j = [vincenty((kj, lj), (mj, nj)).km if np.isfinite(oj) else np.nan for kj, lj, mj, nj, oj in np.nditer([arr1, arr2, arr3, arr2, du_j])]\n    dr_j = [vincenty((kj, lj), (mj, nj)).km if np.isfinite(oj) else np.nan for kj, lj, mj, nj, oj in np.nditer([arr1, arr2, arr3, arr4, du_j])]\n    dx_s = [np.sign(kj - lj) if np.isfinite(oj) else np.nan for kj, lj, oj in np.nditer([arr4, arr2, du_j])]\n    dy_s = [np.sign(kj - lj) if np.isfinite(oj) else np.nan for kj, lj, oj in np.nditer([arr3, arr1, du_j])]\n    print(' \"vincenty\" calculations Finished')\n    dx_j = np.ma.masked_where(np.isfinite(dx_j), dx_j)\n    dy_j = np.ma.masked_where(np.isfinite(dy_j), dy_j)\n    dx_s = np.ma.masked_where(np.isfinite(dx_s), dx_s)\n    dy_s = np.ma.masked_where(np.isfinite(dy_s), dy_s)\n    print(' Begin functions mapping... ')\n    dx = map(lambda x: x[0] * x[1] if np.any([x[0], x[1]], axis=0) else np.nan, list(zip(dx_j.data, dx_s.data)))\n    dy = map(lambda y: y[0] * y[1] if np.any([y[0], y[1]], axis=0) else np.nan, list(zip(dy_j.data, dy_s.data)))\n    dx, dxObj = itertools.tee(dx)\n    dy, dyObj = itertools.tee(dy)\n    dl = map(lambda dj: (dj[0] * dj[2] + dj[1] * dj[3]) / dj[4] if np.any([dj[0], dj[4]], axis=0) else np.nan, list(zip(*du_j, *dv_j, list(dx), list(dy), dr_j)))\n    dt = map(lambda dj: (-dj[0] * dj[3] + dj[1] * dj[2]) / dj[4] if np.any([dj[0], dj[4]], axis=0) else np.nan, list(zip(*du_j, *dv_j, list(dxObj), list(dyObj), dr_j)))\n    print(' Functions mapping Finished ')\n    print('... returning a list of output')\n"]]}
{"hexsha": "30f90defea366450f18f134a6c378f7ef8fb6a36", "ext": "py", "lang": "Python", "content": "def update_indices(years=None):\n    '''\n    Update all geophysical indices (e.g., KP, DST, AE).\n\n    update_indices(years=None)\n\n    :param years: (optional) a list of years to download.\n            If this input is not provided, default\n            values will be used.\n    '''\n\n    update_kpap(years=years)\n    update_dst(years=years)\n    update_ae(years=years)\n\n    return", "fn_id": 6, "class_fn": false, "repo": "JinYunfei/pyglow", "file": "src/pyglow/pyglow.py", "last_update_at": "2018-12-23T15:41:07+00:00", "question_id": "30f90defea366450f18f134a6c378f7ef8fb6a36_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def update_indices(years=None):\n    \"\"\"\n    Update all geophysical indices (e.g., KP, DST, AE).\n\n    update_indices(years=None)\n\n    :param years: (optional) a list of years to download.\n            If this input is not provided, default\n            values will be used.\n    \"\"\"\n    update_kpap(years=years)\n    update_dst(years=years)\n    update_ae(years=years)\n"]]}
{"hexsha": "651f9d71ce14d4ef7bc0720374e523952f4d1d9c", "ext": "py", "lang": "Python", "content": "def get_server_id_by_partial_name(body_response_server_list, partial_server_name):\n    \"\"\"\n    Looks for server Id in the server list by server name\n    :param body_response_server_list: Parsed response (python dic). List of deployed instances\n    :param partial_name: The name of the server to find (or a substring)\n    :return: Server ID\n    \"\"\"\n    server_id = None\n    for server in body_response_server_list['servers']:\n        if partial_server_name in server['name']:\n            server_id = server['id']\n            break\n\n    return server_id", "fn_id": 2, "class_fn": false, "repo": "FIWARE/cloud.PaaS", "file": "test/acceptance/tools/nova_request.py", "last_update_at": "2018-03-05T23:28:55+00:00", "question_id": "651f9d71ce14d4ef7bc0720374e523952f4d1d9c_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_server_id_by_partial_name(body_response_server_list, partial_server_name):\n    \"\"\"\n    Looks for server Id in the server list by server name\n    :param body_response_server_list: Parsed response (python dic). List of deployed instances\n    :param partial_name: The name of the server to find (or a substring)\n    :return: Server ID\n    \"\"\"\n    server_id = None\n    for server in body_response_server_list['servers']:\n        if partial_server_name in server['name']:\n            server_id = server['id']\n            break\n"]]}
{"hexsha": "5fdbf1bd97929e0ec5856ba7e3de146a99e45281", "ext": "py", "lang": "Python", "content": "@pytest.mark.parametrize(\"method\", methods)\n@pytest.mark.moco\ndef test_create_motion_correction_workflow(method):\n    moco_wf = create_motion_correction_workflow(method=method)\n    moco_wf.base_dir = '/tmp/spynoza/workingdir'\n    moco_wf.inputs.inputspec.in_files = [op.join(test_data_path, 'func', 'sub-0020_task-harriri_bold_cut.nii.gz'),\n                                         op.join(test_data_path, 'func', 'sub-0020_task-wm_bold_cut.nii.gz')]\n    moco_wf.inputs.inputspec.output_directory = '/tmp/spynoza'\n    moco_wf.inputs.inputspec.sub_id = 'sub-0020'\n    moco_wf.inputs.inputspec.tr = 2.0\n    moco_wf.inputs.inputspec.which_file_is_EPI_space = 'first'\n    moco_wf.run()\n\n    datasink = op.join(moco_wf.inputs.inputspec.output_directory,\n                       moco_wf.inputs.inputspec.sub_id, 'mcf')\n    for f in moco_wf.inputs.inputspec.in_files:\n\n        assert(op.isfile(op.join(datasink, op.basename(f).replace('.nii.gz', '_mcf.nii.gz'))))\n        assert(op.isfile(op.join(datasink, 'motion_pars',\n                                 op.basename(f).replace('.nii.gz', '_mcf.par'))))\n        assert (op.isfile(op.join(datasink, 'motion_plots',\n                                  op.basename(f).replace('.nii.gz', '_mcf_rot.png'))))\n        assert (op.isfile(op.join(datasink, 'motion_plots',\n                                  op.basename(f).replace('.nii.gz', '_mcf_rot.png'))))", "fn_id": 1, "class_fn": false, "repo": "spinoza-centre/spynoza", "file": "spynoza/motion_correction/tests/test_motion_correction_workflow.py", "last_update_at": "2018-08-10T15:41:37+00:00", "question_id": "5fdbf1bd97929e0ec5856ba7e3de146a99e45281_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.mark.parametrize('method', methods)\n@pytest.mark.moco\ndef test_create_motion_correction_workflow(method):\n    moco_wf = create_motion_correction_workflow(method=method)\n    moco_wf.base_dir = '/tmp/spynoza/workingdir'\n    moco_wf.inputs.inputspec.in_files = [op.join(test_data_path, 'func', 'sub-0020_task-harriri_bold_cut.nii.gz'), op.join(test_data_path, 'func', 'sub-0020_task-wm_bold_cut.nii.gz')]\n    moco_wf.inputs.inputspec.output_directory = '/tmp/spynoza'\n    moco_wf.inputs.inputspec.sub_id = 'sub-0020'\n    moco_wf.inputs.inputspec.tr = 2.0\n    moco_wf.inputs.inputspec.which_file_is_EPI_space = 'first'\n    moco_wf.run()\n    datasink = op.join(moco_wf.inputs.inputspec.output_directory, moco_wf.inputs.inputspec.sub_id, 'mcf')\n    for f in moco_wf.inputs.inputspec.in_files:\n        assert op.isfile(op.join(datasink, op.basename(f).replace('.nii.gz', '_mcf.nii.gz')))\n        assert op.isfile(op.join(datasink, 'motion_pars', op.basename(f).replace('.nii.gz', '_mcf.par')))\n        assert op.isfile(op.join(datasink, 'motion_plots', op.basename(f).replace('.nii.gz', '_mcf_rot.png')))\n"]]}
{"hexsha": "8393024796feb1fac5d2a8be7ed14164b561a575", "ext": "py", "lang": "Python", "content": "def main(url):\n    response = requests.get(url)\n    if not response.status_code == 200:\n        print('\u041e\u0448\u0438\u0431\u043a\u0430 ({}) {}'.format(response.status_code, url))\n        sys.exit(1)\n    html = response.content\n    soup = BeautifulSoup(html,'html.parser')\n    print('{} (via tmfeed CLI)'.format(soup.html.head.title.text))\n    for link in soup.find_all('li', 'tm-post'):\n        post = link.find_all('div')\n        print(post[0].a.text, end=' ')\n        print(colored(post[0].span.text, 'cyan'))\n        print(colored(post[1].a.text), 'blue')\n        print(colored(post[1].a['href'] , 'green'), end=' ')\n        print(colored('{}'.format(post[3].find_all('div')[0].text), 'cyan'))\n    print('2006 \u2014 2018 \u00abTM\u00bb')", "fn_id": 0, "class_fn": false, "repo": "tvl/tmfeed", "file": "tmfeed.py", "last_update_at": "2018-03-06T12:36:24+00:00", "question_id": "8393024796feb1fac5d2a8be7ed14164b561a575_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main(url):\n    response = requests.get(url)\n    if not response.status_code == 200:\n        print('\u041e\u0448\u0438\u0431\u043a\u0430 ({}) {}'.format(response.status_code, url))\n        sys.exit(1)\n    html = response.content\n    soup = BeautifulSoup(html, 'html.parser')\n    print('{} (via tmfeed CLI)'.format(soup.html.head.title.text))\n    for link in soup.find_all('li', 'tm-post'):\n        post = link.find_all('div')\n        print(post[0].a.text, end=' ')\n        print(colored(post[0].span.text, 'cyan'))\n        print(colored(post[1].a.text), 'blue')\n        print(colored(post[1].a['href'], 'green'), end=' ')\n        print(colored('{}'.format(post[3].find_all('div')[0].text), 'cyan'))\n"]]}
{"hexsha": "0991fd41708c384f3d4879fbe359511b6dce95d7", "ext": "py", "lang": "Python", "content": "def resize_point(point, in_size, out_size):\n    \"\"\"Adapt point coordinates to the rescaled image space.\n\n    Args:\n        point (~numpy.ndarray): Points in the image.\n            The shape of this array is :math:`(P, 2)`. :math:`P` is the number\n            of points in the image.\n            The last dimension is composed of :math:`y` and :math:`x`\n            coordinates of the points.\n        in_size (tuple): A tuple of length 2. The height and the width\n            of the image before resized.\n        out_size (tuple): A tuple of length 2. The height and the width\n            of the image after resized.\n\n    Returns:\n        ~numpy.ndarray:\n        Points rescaled according to the given image shapes.\n\n    \"\"\"\n    point = point.copy()\n    y_scale = float(out_size[0]) / in_size[0]\n    x_scale = float(out_size[1]) / in_size[1]\n    point[:, 0] = y_scale * point[:, 0]\n    point[:, 1] = x_scale * point[:, 1]\n    return point", "fn_id": 0, "class_fn": false, "repo": "souravsingh/chainercv", "file": "chainercv/transforms/point/resize_point.py", "last_update_at": "2018-08-24T02:28:31+00:00", "question_id": "0991fd41708c384f3d4879fbe359511b6dce95d7_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def resize_point(point, in_size, out_size):\n    \"\"\"Adapt point coordinates to the rescaled image space.\n\n    Args:\n        point (~numpy.ndarray): Points in the image.\n            The shape of this array is :math:`(P, 2)`. :math:`P` is the number\n            of points in the image.\n            The last dimension is composed of :math:`y` and :math:`x`\n            coordinates of the points.\n        in_size (tuple): A tuple of length 2. The height and the width\n            of the image before resized.\n        out_size (tuple): A tuple of length 2. The height and the width\n            of the image after resized.\n\n    Returns:\n        ~numpy.ndarray:\n        Points rescaled according to the given image shapes.\n\n    \"\"\"\n    point = point.copy()\n    y_scale = float(out_size[0]) / in_size[0]\n    x_scale = float(out_size[1]) / in_size[1]\n    point[:, 0] = y_scale * point[:, 0]\n    point[:, 1] = x_scale * point[:, 1]\n"]]}
{"hexsha": "53a3685fd3dc15d196a75e19574000efd6e57805", "ext": "py", "lang": "Python", "content": "def _noise_model_program_header(noise_model):\n    \"\"\"\n    Generate the header for a pyquil Program that uses ``noise_model`` to overload noisy gates.\n    The program header consists of 3 sections:\n\n        - The ``DEFGATE`` statements that define the meaning of the newly introduced \"noisy\" gate\n          names.\n        - The ``PRAGMA ADD-KRAUS`` statements to overload these noisy gates on specific qubit\n          targets with their noisy implementation.\n        - THe ``PRAGMA READOUT-POVM`` statements that define the noisy readout per qubit.\n\n    :param NoiseModel noise_model: The assumed noise model.\n    :return: A quil Program with the noise pragmas.\n    :rtype: pyquil.quil.Program\n    \"\"\"\n    from pyquil.quil import Program\n    p = Program()\n    defgates = set()\n    for k in noise_model.gates:\n\n        # obtain ideal gate matrix and new, noisy name by looking it up in the NOISY_GATES dict\n        try:\n            ideal_gate, new_name = get_noisy_gate(k.gate, tuple(k.params))\n\n            # if ideal version of gate has not yet been DEFGATE'd, do this\n            if new_name not in defgates:\n                p.defgate(new_name, ideal_gate)\n                defgates.add(new_name)\n        except NoisyGateUndefined:\n            print(\"WARNING: Could not find ideal gate definition for gate {}\".format(k.gate),\n                  file=sys.stderr)\n            new_name = k.gate\n\n        # define noisy version of gate on specific targets\n        p.define_noisy_gate(new_name, k.targets, k.kraus_ops)\n\n    # define noisy readouts\n    for q, ap in noise_model.assignment_probs.items():\n        p.define_noisy_readout(q, p00=ap[0, 0], p11=ap[1, 1])\n    return p", "fn_id": 12, "class_fn": false, "repo": "bishoymoussa/pyquil", "file": "pyquil/noise.py", "last_update_at": "2018-09-01T17:56:58+00:00", "question_id": "53a3685fd3dc15d196a75e19574000efd6e57805_12", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _noise_model_program_header(noise_model):\n    \"\"\"\n    Generate the header for a pyquil Program that uses ``noise_model`` to overload noisy gates.\n    The program header consists of 3 sections:\n\n        - The ``DEFGATE`` statements that define the meaning of the newly introduced \"noisy\" gate\n          names.\n        - The ``PRAGMA ADD-KRAUS`` statements to overload these noisy gates on specific qubit\n          targets with their noisy implementation.\n        - THe ``PRAGMA READOUT-POVM`` statements that define the noisy readout per qubit.\n\n    :param NoiseModel noise_model: The assumed noise model.\n    :return: A quil Program with the noise pragmas.\n    :rtype: pyquil.quil.Program\n    \"\"\"\n    from pyquil.quil import Program\n    p = Program()\n    defgates = set()\n    for k in noise_model.gates:\n        try:\n            ideal_gate, new_name = get_noisy_gate(k.gate, tuple(k.params))\n            if new_name not in defgates:\n                p.defgate(new_name, ideal_gate)\n                defgates.add(new_name)\n        except NoisyGateUndefined:\n            print('WARNING: Could not find ideal gate definition for gate {}'.format(k.gate), file=sys.stderr)\n            new_name = k.gate\n        p.define_noisy_gate(new_name, k.targets, k.kraus_ops)\n    for q, ap in noise_model.assignment_probs.items():\n        p.define_noisy_readout(q, p00=ap[0, 0], p11=ap[1, 1])\n"]]}
{"hexsha": "42d9327787c0bc8a99aab5e63601a658e8f5825d", "ext": "py", "lang": "Python", "content": "def remove_node(network, node):\n    if node is None:\n        raise ValueError(\"Node must be specified when trying to remove it.\")\n    network.getNodes().remove(node)", "fn_id": 7, "class_fn": false, "repo": "morganics/BayesPy", "file": "bayespy/network.py", "last_update_at": "2018-11-24T12:54:42+00:00", "question_id": "42d9327787c0bc8a99aab5e63601a658e8f5825d_7", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def remove_node(network, node):\n    if node is None:\n        raise ValueError('Node must be specified when trying to remove it.')\n"]]}
{"hexsha": "29cbfb2c722f4efa5ded92398163040c8bf192d7", "ext": "py", "lang": "Python", "content": "def test_yelp():\n    location_input = \"times square\"\n    result = yelp(location_input)\n    result = result[\"id\"]\n    test_list = [\"U5hCNNyJmb7f3dmC1HTzSQ\", \"22nKUyCIbpnzR6R3_g1ptQ\", \"DoSU8IPq-Py_YV3kYmXPfQ\", \"al9HKZ3kCJipAJW4uxzj4A\", \"5TX0X8w5ssIACU_pnBEq6g\"]\n    assert result in test_list", "fn_id": 1, "class_fn": false, "repo": "jessicalee127/DineCision", "file": "test/test.py", "last_update_at": "2018-08-06T16:56:00+00:00", "question_id": "29cbfb2c722f4efa5ded92398163040c8bf192d7_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_yelp():\n    location_input = 'times square'\n    result = yelp(location_input)\n    result = result['id']\n    test_list = ['U5hCNNyJmb7f3dmC1HTzSQ', '22nKUyCIbpnzR6R3_g1ptQ', 'DoSU8IPq-Py_YV3kYmXPfQ', 'al9HKZ3kCJipAJW4uxzj4A', '5TX0X8w5ssIACU_pnBEq6g']\n"]]}
{"hexsha": "5d634ae89c89e67ba3cf126492fabe9b01acf62c", "ext": "py", "lang": "Python", "content": "def test_resolve__default(info):\n    with mock.patch.object(Child._meta.model._default_manager, 'get_queryset', return_value=[1, 2, 3]) as get_queryset:\n        assert [1, 2, 3] == Parent.children.resolver(None, info(field_name='children'))\n        get_queryset.assert_called_with()", "fn_id": 1, "class_fn": false, "repo": "karol-gruszczyk/sloth-gql", "file": "slothql/django/types/tests/resolution.py", "last_update_at": "2018-01-23T16:25:56+00:00", "question_id": "5d634ae89c89e67ba3cf126492fabe9b01acf62c_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_resolve__default(info):\n    with mock.patch.object(Child._meta.model._default_manager, 'get_queryset', return_value=[1, 2, 3]) as get_queryset:\n        assert [1, 2, 3] == Parent.children.resolver(None, info(field_name='children'))\n"]]}
{"hexsha": "f4d668ab8a23815224a9c6ddab557d9c4726aed8", "ext": "py", "lang": "Python", "content": "def verify_submodule_branch_structure(repo, branch_name, fetch=True,\n                                      remote='origin'):\n    \"\"\"\n    Throws an exception unless the commit at the tip of branch_name\n    in the supermodule points to the tip of branch_name in each of\n    the submodules\n    \"\"\"\n    remote_branch = '/'.join([remote, branch_name])\n\n    repo.git.reset('--hard', 'HEAD')\n    repo.git.checkout('-f', branch_name)\n    repo.git.reset('--hard', remote_branch)\n    if fetch:\n        repo.git.submodule('update', '--init')\n        repo.git.submodule('foreach', 'git fetch')\n    else:\n        repo.git.submodule('update', '--init', '--no-fetch')\n    try:\n        repo.git.submodule('foreach', \"git diff --quiet %s\" % remote_branch)\n    except GitCommandError:\n        raise InvalidSubmoduleBranch(branch_name)", "fn_id": 7, "class_fn": false, "repo": "amplify-education/release-path", "file": "release_path.py", "last_update_at": "2018-11-23T17:46:07+00:00", "question_id": "f4d668ab8a23815224a9c6ddab557d9c4726aed8_7", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def verify_submodule_branch_structure(repo, branch_name, fetch=True, remote='origin'):\n    \"\"\"\n    Throws an exception unless the commit at the tip of branch_name\n    in the supermodule points to the tip of branch_name in each of\n    the submodules\n    \"\"\"\n    remote_branch = '/'.join([remote, branch_name])\n    repo.git.reset('--hard', 'HEAD')\n    repo.git.checkout('-f', branch_name)\n    repo.git.reset('--hard', remote_branch)\n    if fetch:\n        repo.git.submodule('update', '--init')\n        repo.git.submodule('foreach', 'git fetch')\n    else:\n        repo.git.submodule('update', '--init', '--no-fetch')\n    try:\n        repo.git.submodule('foreach', 'git diff --quiet %s' % remote_branch)\n    except GitCommandError:\n"]]}
{"hexsha": "38692937cb4cdc55ef409bcac4ef0cf5e6ae0d61", "ext": "py", "lang": "Python", "content": "def test_terasort():\n\n    dataset = [gen_fragment() for _ in range(10)]\n    dds = DDS().load(dataset, -1).sort_by_key().collect()\n    prev = 0\n\n    for i, k in dds:\n        assert i > prev\n        prev = i", "fn_id": 2, "class_fn": false, "repo": "ramonamela/compss", "file": "tests/sources/python/2_dds/src/test_dds.py", "last_update_at": "2018-05-08T12:14:19+00:00", "question_id": "38692937cb4cdc55ef409bcac4ef0cf5e6ae0d61_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_terasort():\n    dataset = [gen_fragment() for _ in range(10)]\n    dds = DDS().load(dataset, -1).sort_by_key().collect()\n    prev = 0\n    for i, k in dds:\n        assert i > prev\n"]]}
{"hexsha": "2f859f8994e33ba15117d31607c058c7b04356ed", "ext": "py", "lang": "Python", "content": "def runSimulation():\n    global flightScore, otherPartStatus\n    # stuff = [[1, 1, 2, [1, 0]], [2, 1, 0, [1, 0]],  [2, 1, 1, [1, 0]] , [2, 1, 2, [1, 0]] , [2, 1, 3, [1, 0]], [2, 1, 4, [1, 0]], [3, 1, 2, [1, 0]], [4, 1, 2, [1, 0]]]\n    # stuff = [[-3, 0, -6, [35, 0]], [-3, 1, 2, [35, 0]], [-2, 1, 2, [35, 0]], [-2, 1, 3, [35, 0]], [-1, 1, -4, [35, 0]], [-1, 1, 2, [35, 0]], [-1, 1, 3, [35, 0]], [-1, 1, 4, [35, 0]], [0, 1, -4, [35, 0]], [0, 1, 2, [35, 0]], [0, 1, 3, [35, 0]], [0, 1, 4, [35, 0]], [1, 0, -3, [35, 15]], [1, 1, -4, [35, 0]], [1, 1, -3, [35, 0]], [1, 1, 2, [35, 0]], [1, 1, 3, [35, 0]], [1, 1, 4, [35, 0]], [2, 1, -4, [35, 0]], [2, 1, -3, [35, 0]], [2, 1, -2, [35, 0]], [2, 1, -1, [35, 0]], [2, 1, 0, [35, 0]], [2, 1, 1, [35, 0]], [2, 1, 2, [35, 0]], [2, 1, 3, [35, 0]], [2, 1, 4, [35, 0]], [2, 1, 5, [35, 0]], [2, 1, 6, [35, 0]], [2, 1, 7, [35, 0]], [2, 1, 8, [35, 0]], [2, 2, -4, [35, 0]], [2, 2, -3, [35, 0]], [2, 2, -2, [20, 0]], [2, 2, -1, [35, 0]], [2, 2, 0, [20, 0]], [2, 2, 1, [35, 0]], [2, 2, 2, [20, 0]], [2, 2, 3, [35, 0]], [2, 2, 4, [20, 0]], [2, 2, 5, [35, 0]], [2, 2, 6, [20, 0]], [2, 2, 7, [35, 0]], [2, 2, 8, [20, 0]], [3, 0, 8, [35, 15]], [3, 1, -4, [35, 0]], [3, 1, -3, [35, 0]], [3, 1, -2, [35, 0]], [3, 1, -1, [35, 0]], [3, 1, 0, [35, 0]], [3, 1, 1, [35, 0]], [3, 1, 2, [35, 0]], [3, 1, 3, [35, 0]], [3, 1, 4, [35, 0]], [3, 1, 5, [35, 0]], [3, 1, 6, [35, 0]], [3, 1, 7, [35, 0]], [3, 1, 8, [35, 0]], [3, 1, 9, [35, 0]], [3, 2, -4, [35, 0]], [3, 2, 9, [20, 0]], [3, 3, -4, [35, 0]], [3, 3, -3, [35, 0]], [3, 3, -2, [35, 0]], [3, 3, -1, [35, 0]], [3, 3, 0, [35, 0]], [3, 3, 1, [35, 0]], [3, 3, 2, [35, 0]], [3, 3, 3, [35, 0]], [3, 3, 4, [35, 0]], [3, 3, 5, [35, 0]], [3, 3, 6, [35, 0]], [3, 3, 7, [35, 0]], [3, 3, 8, [20, 0]], [3, 4, -4, [35, 0]], [4, 1, -4, [35, 0]], [4, 1, -3, [35, 0]], [4, 1, -2, [35, 0]], [4, 1, -1, [35, 0]], [4, 1, 0, [35, 0]], [4, 1, 1, [35, 0]], [4, 1, 2, [35, 0]], [4, 1, 3, [35, 0]], [4, 1, 4, [35, 0]], [4, 1, 5, [35, 0]], [4, 1, 6, [35, 0]], [4, 1, 7, [35, 0]], [4, 1, 8, [35, 0]], [4, 2, -4, [35, 0]], [4, 2, -3, [35, 0]], [4, 2, -2, [20, 0]], [4, 2, -1, [35, 0]], [4, 2, 0, [20, 0]], [4, 2, 1, [35, 0]], [4, 2, 2, [20, 0]], [4, 2, 3, [35, 0]], [4, 2, 4, [20, 0]], [4, 2, 5, [35, 0]], [4, 2, 6, [20, 0]], [4, 2, 7, [35, 0]], [4, 2, 8, [20, 0]], [5, 0, -3, [35, 15]], [5, 1, -4, [35, 0]], [5, 1, -3, [35, 0]], [5, 1, 2, [35, 0]], [5, 1, 3, [35, 0]], [5, 1, 4, [35, 0]], [6, 1, -4, [35, 0]], [6, 1, 2, [35, 0]], [6, 1, 3, [35, 0]], [6, 1, 4, [35, 0]], [7, 1, -4, [35, 0]], [7, 1, 2, [35, 0]], [7, 1, 3, [35, 0]], [7, 1, 4, [35, 0]], [8, 1, 2, [35, 0]], [8, 1, 3, [35, 0]], [9, 1, 2, [35, 0]], [11, 0, 10, [45, 0]], [11, 1, 10, [45, 0]], [11, 2, 10, [45, 0]], [11, 3, 10, [45, 0]], [11, 4, 10, [45, 0]], [11, 5, 10, [45, 0]]]\n    # stuff = [[-3, 1, 2, [35, 0]], [-2, 1, 2, [35, 0]], [-2, 1, 3, [35, 0]], [-1, 1, -4, [35, 0]], [-1, 1, 2, [35, 0]], [-1, 1, 3, [35, 0]], [-1, 1, 4, [35, 0]], [0, 1, -4, [35, 0]], [0, 1, 2, [35, 0]], [0, 1, 3, [35, 0]], [0, 1, 4, [35, 0]], [1, 0, -3, [35, 15]], [1, 1, -4, [35, 0]], [1, 1, -3, [35, 0]], [1, 1, 2, [35, 0]], [1, 1, 3, [35, 0]], [1, 1, 4, [35, 0]], [2, 1, -4, [35, 0]], [2, 1, -3, [35, 0]], [2, 1, -2, [35, 0]], [2, 1, -1, [35, 0]], [2, 1, 0, [35, 0]], [2, 1, 1, [35, 0]], [2, 1, 2, [35, 0]], [2, 1, 3, [35, 0]], [2, 1, 4, [35, 0]], [2, 1, 5, [35, 0]], [2, 1, 6, [35, 0]], [2, 1, 7, [35, 0]], [2, 1, 8, [35, 0]], [2, 2, -4, [35, 0]], [2, 2, -3, [35, 0]], [2, 2, -2, [20, 0]], [2, 2, -1, [35, 0]], [2, 2, 0, [20, 0]], [2, 2, 1, [35, 0]], [2, 2, 2, [20, 0]], [2, 2, 3, [35, 0]], [2, 2, 4, [20, 0]], [2, 2, 5, [35, 0]], [2, 2, 6, [20, 0]], [2, 2, 7, [35, 0]], [2, 2, 8, [20, 0]], [3, 0, 8, [35, 15]], [3, 1, -4, [35, 0]], [3, 1, -3, [35, 0]], [3, 1, -2, [35, 0]], [3, 1, -1, [35, 0]], [3, 1, 0, [35, 0]], [3, 1, 1, [35, 0]], [3, 1, 2, [35, 0]], [3, 1, 3, [35, 0]], [3, 1, 4, [35, 0]], [3, 1, 5, [35, 0]], [3, 1, 6, [35, 0]], [3, 1, 7, [35, 0]], [3, 1, 8, [35, 0]], [3, 1, 9, [35, 0]], [3, 2, -4, [35, 0]], [3, 2, 9, [20, 0]], [3, 3, -4, [35, 0]], [3, 3, -3, [35, 0]], [3, 3, -2, [35, 0]], [3, 3, -1, [35, 0]], [3, 3, 0, [35, 0]], [3, 3, 1, [35, 0]], [3, 3, 2, [35, 0]], [3, 3, 3, [35, 0]], [3, 3, 4, [35, 0]], [3, 3, 5, [35, 0]], [3, 3, 6, [35, 0]], [3, 3, 7, [35, 0]], [3, 3, 8, [20, 0]], [3, 4, -4, [35, 0]], [4, 1, -4, [35, 0]], [4, 1, -3, [35, 0]], [4, 1, -2, [35, 0]], [4, 1, -1, [35, 0]], [4, 1, 0, [35, 0]], [4, 1, 1, [35, 0]], [4, 1, 2, [35, 0]], [4, 1, 3, [35, 0]], [4, 1, 4, [35, 0]], [4, 1, 5, [35, 0]], [4, 1, 6, [35, 0]], [4, 1, 7, [35, 0]], [4, 1, 8, [35, 0]], [4, 2, -4, [35, 0]], [4, 2, -3, [35, 0]], [4, 2, -2, [20, 0]], [4, 2, -1, [35, 0]], [4, 2, 0, [20, 0]], [4, 2, 1, [35, 0]], [4, 2, 2, [20, 0]], [4, 2, 3, [35, 0]], [4, 2, 4, [20, 0]], [4, 2, 5, [35, 0]], [4, 2, 6, [20, 0]], [4, 2, 7, [35, 0]], [4, 2, 8, [20, 0]], [5, 0, -3, [35, 15]], [5, 1, -4, [35, 0]], [5, 1, -3, [35, 0]], [5, 1, 2, [35, 0]], [5, 1, 3, [35, 0]], [5, 1, 4, [35, 0]], [6, 1, -4, [35, 0]], [6, 1, 2, [35, 0]], [6, 1, 3, [35, 0]], [6, 1, 4, [35, 0]], [7, 1, -4, [35, 0]], [7, 1, 2, [35, 0]], [7, 1, 3, [35, 0]], [7, 1, 4, [35, 0]], [8, 1, 2, [35, 0]], [8, 1, 3, [35, 0]], [9, 1, 2, [35, 0]]]\n\n    # North facing plane\n    # stuff = [[-22, 0, -2, [35, 15]], [-22, 0, 2, [35, 15]], [-22, 1, -2, [1, 0]], [-22, 1, -1, [1, 0]], [-22, 1, 0, [1, 0]], [-22, 1, 1, [1, 0]], [-22, 1, 2, [1, 0]], [-22, 2, -1, [1, 0]], [-22, 2, 1, [1, 0]], [-22, 3, 0, [1, 0]], [-21, 1, -1, [1, 0]], [-21, 1, 0, [1, 0]], [-21, 1, 1, [1, 0]], [-21, 2, -1, [20, 0]], [-21, 2, 1, [20, 0]], [-21, 3, 0, [1, 0]], [-20, 1, -1, [1, 0]], [-20, 1, 0, [1, 0]], [-20, 1, 1, [1, 0]], [-20, 2, -1, [1, 0]], [-20, 2, 1, [1, 0]], [-20, 3, 0, [1, 0]], [-19, 1, -1, [1, 0]], [-19, 1, 0, [1, 0]], [-19, 1, 1, [1, 0]], [-19, 2, -1, [20, 0]], [-19, 2, 1, [20, 0]], [-19, 3, 0, [1, 0]], [-18, 1, -1, [1, 0]], [-18, 1, 0, [1, 0]], [-18, 1, 1, [1, 0]], [-18, 2, -1, [1, 0]], [-18, 2, 1, [1, 0]], [-18, 3, 0, [1, 0]], [-17, 1, -6, [1, 0]], [-17, 1, -5, [1, 0]], [-17, 1, -4, [1, 0]], [-17, 1, -3, [1, 0]], [-17, 1, -2, [1, 0]], [-17, 1, -1, [1, 0]], [-17, 1, 0, [1, 0]], [-17, 1, 1, [1, 0]], [-17, 1, 2, [1, 0]], [-17, 1, 3, [1, 0]], [-17, 1, 4, [1, 0]], [-17, 1, 5, [1, 0]], [-17, 1, 6, [1, 0]], [-17, 2, -1, [20, 0]], [-17, 2, 1, [20, 0]], [-17, 3, 0, [1, 0]], [-16, 1, -5, [1, 0]], [-16, 1, -4, [1, 0]], [-16, 1, -3, [1, 0]], [-16, 1, -2, [1, 0]], [-16, 1, -1, [1, 0]], [-16, 1, 0, [1, 0]], [-16, 1, 1, [1, 0]], [-16, 1, 2, [1, 0]], [-16, 1, 3, [1, 0]], [-16, 1, 4, [1, 0]], [-16, 1, 5, [1, 0]], [-16, 2, -1, [1, 0]], [-16, 2, 1, [1, 0]], [-16, 3, 0, [1, 0]], [-15, 1, -4, [1, 0]], [-15, 1, -3, [1, 0]], [-15, 1, -2, [1, 0]], [-15, 1, -1, [1, 0]], [-15, 1, 0, [1, 0]], [-15, 1, 1, [1, 0]], [-15, 1, 2, [1, 0]], [-15, 1, 3, [1, 0]], [-15, 1, 4, [1, 0]], [-15, 2, -1, [20, 0]], [-15, 2, 1, [20, 0]], [-15, 3, 0, [1, 0]], [-14, 1, -1, [1, 0]], [-14, 1, 0, [1, 0]], [-14, 1, 1, [1, 0]], [-14, 2, -1, [1, 0]], [-14, 2, 1, [1, 0]], [-14, 3, 0, [1, 0]], [-13, 1, -1, [1, 0]], [-13, 1, 0, [1, 0]], [-13, 1, 1, [1, 0]], [-13, 2, -1, [20, 0]], [-13, 2, 1, [20, 0]], [-13, 3, 0, [1, 0]], [-12, 1, -1, [1, 0]], [-12, 1, 0, [1, 0]], [-12, 1, 1, [1, 0]], [-12, 2, -1, [1, 0]], [-12, 2, 1, [1, 0]], [-12, 3, 0, [1, 0]], [-11, 0, 0, [35, 15]], [-11, 1, -1, [1, 0]], [-11, 1, 0, [1, 0]], [-11, 1, 1, [1, 0]], [-11, 2, -1, [20, 0]], [-11, 2, 1, [20, 0]], [-11, 3, 0, [20, 0]], [-10, 1, 0, [1, 0]], [-10, 2, 0, [20, 0]]]\n\n    # West facing plane\n    # stuff = [[-3, 1, 2, [1, 0]], [-2, 1, 2, [1, 0]], [-2, 1, 3, [1, 0]], [-1, 1, -4, [1, 0]], [-1, 1, 2, [1, 0]], [-1, 1, 3, [1, 0]], [-1, 1, 4, [1, 0]], [0, 1, -4, [1, 0]], [0, 1, 2, [1, 0]], [0, 1, 3, [1, 0]], [0, 1, 4, [1, 0]], [1, 0, -3, [1, 15]], [1, 1, -4, [1, 0]], [1, 1, -3, [1, 0]], [1, 1, 2, [1, 0]], [1, 1, 3, [1, 0]], [1, 1, 4, [1, 0]], [2, 1, -4, [1, 0]], [2, 1, -3, [1, 0]], [2, 1, -2, [1, 0]], [2, 1, -1, [1, 0]], [2, 1, 0, [1, 0]], [2, 1, 1, [1, 0]], [2, 1, 2, [1, 0]], [2, 1, 3, [1, 0]], [2, 1, 4, [1, 0]], [2, 1, 5, [1, 0]], [2, 1, 6, [1, 0]], [2, 1, 7, [1, 0]], [2, 1, 8, [1, 0]], [2, 2, -4, [1, 0]], [2, 2, -3, [1, 0]], [2, 2, -2, [20, 0]], [2, 2, -1, [1, 0]], [2, 2, 0, [20, 0]], [2, 2, 1, [1, 0]], [2, 2, 2, [20, 0]], [2, 2, 3, [1, 0]], [2, 2, 4, [20, 0]], [2, 2, 5, [1, 0]], [2, 2, 6, [20, 0]], [2, 2, 7, [1, 0]], [2, 2, 8, [20, 0]], [3, 0, 8, [1, 15]], [3, 1, -4, [1, 0]], [3, 1, -3, [1, 0]], [3, 1, -2, [1, 0]], [3, 1, -1, [1, 0]], [3, 1, 0, [1, 0]], [3, 1, 1, [1, 0]], [3, 1, 2, [1, 0]], [3, 1, 3, [1, 0]], [3, 1, 4, [1, 0]], [3, 1, 5, [1, 0]], [3, 1, 6, [1, 0]], [3, 1, 7, [1, 0]], [3, 1, 8, [1, 0]], [3, 1, 9, [1, 0]], [3, 2, -4, [1, 0]], [3, 2, 9, [20, 0]], [3, 3, -4, [1, 0]], [3, 3, -3, [1, 0]], [3, 3, -2, [1, 0]], [3, 3, -1, [1, 0]], [3, 3, 0, [1, 0]], [3, 3, 1, [1, 0]], [3, 3, 2, [1, 0]], [3, 3, 3, [1, 0]], [3, 3, 4, [1, 0]], [3, 3, 5, [1, 0]], [3, 3, 6, [1, 0]], [3, 3, 7, [1, 0]], [3, 3, 8, [20, 0]], [3, 4, -4, [1, 0]], [4, 1, -4, [1, 0]], [4, 1, -3, [1, 0]], [4, 1, -2, [1, 0]], [4, 1, -1, [1, 0]], [4, 1, 0, [1, 0]], [4, 1, 1, [1, 0]], [4, 1, 2, [1, 0]], [4, 1, 3, [1, 0]], [4, 1, 4, [1, 0]], [4, 1, 5, [1, 0]], [4, 1, 6, [1, 0]], [4, 1, 7, [1, 0]], [4, 1, 8, [1, 0]], [4, 2, -4, [1, 0]], [4, 2, -3, [1, 0]], [4, 2, -2, [20, 0]], [4, 2, -1, [1, 0]], [4, 2, 0, [20, 0]], [4, 2, 1, [1, 0]], [4, 2, 2, [20, 0]], [4, 2, 3, [1, 0]], [4, 2, 4, [20, 0]], [4, 2, 5, [1, 0]], [4, 2, 6, [20, 0]], [4, 2, 7, [1, 0]], [4, 2, 8, [20, 0]], [5, 0, -3, [1, 15]], [5, 1, -4, [1, 0]], [5, 1, -3, [1, 0]], [5, 1, 2, [1, 0]], [5, 1, 3, [1, 0]], [5, 1, 4, [1, 0]], [6, 1, -4, [1, 0]], [6, 1, 2, [1, 0]], [6, 1, 3, [1, 0]], [6, 1, 4, [1, 0]], [7, 1, -4, [1, 0]], [7, 1, 2, [1, 0]], [7, 1, 3, [1, 0]], [7, 1, 4, [1, 0]], [8, 1, 2, [1, 0]], [8, 1, 3, [1, 0]], [9, 1, 2, [1, 0]]]\n\n    # West experiment\n    # stuff = [[-3, 1, 2, [35, 0]], [-2, 1, 2, [35, 0]], [-2, 1, 3, [35, 0]], [-1, 1, -4, [35, 0]], [-1, 1, 2, [35, 0]], [-1, 1, 3, [35, 0]], [-1, 1, 4, [35, 0]], [0, 1, -4, [35, 0]], [0, 1, 2, [35, 0]], [0, 1, 3, [35, 0]], [0, 1, 4, [35, 0]], [1, 0, -3, [35, 15]], [1, 1, -4, [35, 0]], [1, 1, -3, [35, 0]], [1, 1, 2, [35, 0]], [1, 1, 3, [35, 0]], [1, 1, 4, [35, 0]], [2, 1, -4, [35, 0]], [2, 1, -3, [35, 0]], [2, 1, -2, [35, 0]], [2, 1, -1, [35, 0]], [2, 1, 0, [35, 0]], [2, 1, 1, [35, 0]], [2, 1, 2, [35, 0]], [2, 1, 3, [35, 0]], [2, 1, 4, [35, 0]], [2, 1, 5, [35, 0]], [2, 1, 6, [35, 0]], [2, 1, 7, [35, 0]], [2, 1, 8, [35, 0]], [2, 2, -4, [35, 0]], [2, 2, -3, [35, 0]], [2, 2, -2, [20, 0]], [2, 2, -1, [35, 0]], [2, 2, 0, [20, 0]], [2, 2, 1, [35, 0]], [2, 2, 2, [20, 0]], [2, 2, 3, [35, 0]], [2, 2, 4, [20, 0]], [2, 2, 5, [35, 0]], [2, 2, 6, [20, 0]], [2, 2, 7, [35, 0]], [2, 2, 8, [20, 0]], [3, 0, 8, [35, 15]], [3, 1, -4, [35, 0]], [3, 1, -3, [35, 0]], [3, 1, -2, [35, 0]], [3, 1, -1, [35, 0]], [3, 1, 0, [35, 0]], [3, 1, 1, [35, 0]], [3, 1, 2, [35, 0]], [3, 1, 3, [35, 0]], [3, 1, 4, [35, 0]], [3, 1, 5, [35, 0]], [3, 1, 6, [35, 0]], [3, 1, 7, [35, 0]], [3, 1, 8, [35, 0]], [3, 1, 9, [35, 0]], [3, 2, -4, [35, 0]], [3, 2, 9, [20, 0]], [3, 3, -4, [35, 0]], [3, 3, -3, [35, 0]], [3, 3, -2, [35, 0]], [3, 3, -1, [35, 0]], [3, 3, 0, [35, 0]], [3, 3, 1, [35, 0]], [3, 3, 2, [35, 0]], [3, 3, 3, [35, 0]], [3, 3, 4, [35, 0]], [3, 3, 5, [35, 0]], [3, 3, 6, [35, 0]], [3, 3, 7, [35, 0]], [3, 3, 8, [20, 0]], [3, 4, -4, [35, 0]], [4, 1, -4, [35, 0]], [4, 1, -3, [35, 0]], [4, 1, -2, [35, 0]], [4, 1, -1, [35, 0]], [4, 1, 0, [35, 0]], [4, 1, 1, [35, 0]], [4, 1, 2, [35, 0]], [4, 1, 3, [35, 0]], [4, 1, 4, [35, 0]], [4, 1, 5, [35, 0]], [4, 1, 6, [35, 0]], [4, 1, 7, [35, 0]], [4, 1, 8, [35, 0]], [4, 2, -4, [35, 0]], [4, 2, -3, [35, 0]], [4, 2, -2, [20, 0]], [4, 2, -1, [35, 0]], [4, 2, 0, [20, 0]], [4, 2, 1, [35, 0]], [4, 2, 2, [20, 0]], [4, 2, 3, [35, 0]], [4, 2, 4, [20, 0]], [4, 2, 5, [35, 0]], [4, 2, 6, [20, 0]], [4, 2, 7, [35, 0]], [4, 2, 8, [20, 0]], [5, 0, -3, [35, 15]], [5, 1, -4, [35, 0]], [5, 1, -3, [35, 0]], [5, 1, 2, [35, 0]], [5, 1, 3, [35, 0]], [5, 1, 4, [35, 0]], [6, 1, -4, [35, 0]], [6, 1, 2, [35, 0]], [6, 1, 3, [35, 0]], [6, 1, 4, [35, 0]], [7, 1, -4, [35, 0]], [7, 1, 2, [35, 0]], [7, 1, 3, [35, 0]], [7, 1, 4, [35, 0]], [8, 1, 2, [35, 0]], [8, 1, 3, [35, 0]], [9, 1, 2, [35, 0]]]\n\n    # West wool\n    WoolStuff = [[13, 1, 2, [35, 14]], [14, 1, 2, [35, 14]], [14, 1, 3, [35, 14]], [15, 1, -4, [35, 13]],\n                 [15, 1, 2, [35, 14]], [15, 1, 3, [35, 14]], [15, 1, 4, [35, 14]], [16, 1, -4, [35, 13]],\n                 [16, 1, 2, [35, 14]], [16, 1, 3, [35, 14]], [16, 1, 4, [35, 14]], [17, 0, -3, [35, 13]],\n                 [17, 1, -4, [35, 13]], [17, 1, -3, [35, 13]], [17, 1, 2, [35, 14]], [17, 1, 3, [35, 14]],\n                 [17, 1, 4, [35, 14]], [18, 1, -4, [35, 12]], [18, 1, -3, [35, 5]], [18, 1, -2, [35, 5]],\n                 [18, 1, -1, [35, 3]], [18, 1, 0, [35, 3]], [18, 1, 1, [35, 3]], [18, 1, 2, [35, 15]],\n                 [18, 1, 3, [35, 15]], [18, 1, 4, [35, 15]], [18, 1, 5, [35, 1]], [18, 1, 6, [35, 1]],\n                 [18, 1, 7, [35, 1]], [18, 1, 8, [35, 2]], [18, 2, -4, [35, 12]], [18, 2, -3, [35, 5]],\n                 [18, 2, -2, [35, 5]], [18, 2, -1, [35, 3]], [18, 2, 0, [35, 3]], [18, 2, 1, [35, 3]],\n                 [18, 2, 2, [35, 15]], [18, 2, 3, [35, 15]], [18, 2, 4, [35, 15]], [18, 2, 5, [35, 1]],\n                 [18, 2, 6, [35, 1]], [18, 2, 7, [35, 1]], [18, 2, 8, [35, 2]], [19, 0, 8, [35, 2]],\n                 [19, 1, -4, [35, 12]], [19, 1, -3, [35, 5]], [19, 1, -2, [35, 5]], [19, 1, -1, [35, 3]],\n                 [19, 1, 0, [35, 3]], [19, 1, 1, [35, 3]], [19, 1, 2, [35, 15]], [19, 1, 3, [35, 15]],\n                 [19, 1, 4, [35, 15]], [19, 1, 5, [35, 1]], [19, 1, 6, [35, 1]], [19, 1, 7, [35, 1]],\n                 [19, 1, 8, [35, 2]], [19, 1, 9, [35, 2]], [19, 2, -4, [35, 12]], [19, 2, 9, [35, 2]],\n                 [19, 3, -4, [35, 12]], [19, 3, -3, [35, 5]], [19, 3, -2, [35, 5]], [19, 3, -1, [35, 3]],\n                 [19, 3, 0, [35, 3]], [19, 3, 1, [35, 3]], [19, 3, 2, [35, 15]], [19, 3, 3, [35, 15]],\n                 [19, 3, 4, [35, 15]], [19, 3, 5, [35, 1]], [19, 3, 6, [35, 1]], [19, 3, 7, [35, 1]],\n                 [19, 3, 8, [35, 2]], [19, 4, -4, [35, 12]], [20, 1, -4, [35, 12]], [20, 1, -3, [35, 5]],\n                 [20, 1, -2, [35, 5]], [20, 1, -1, [35, 3]], [20, 1, 0, [35, 3]], [20, 1, 1, [35, 3]],\n                 [20, 1, 2, [35, 15]], [20, 1, 3, [35, 15]], [20, 1, 4, [35, 15]], [20, 1, 5, [35, 1]],\n                 [20, 1, 6, [35, 1]], [20, 1, 7, [35, 1]], [20, 1, 8, [35, 2]], [20, 2, -4, [35, 12]],\n                 [20, 2, -3, [35, 5]], [20, 2, -2, [35, 5]], [20, 2, -1, [35, 3]], [20, 2, 0, [35, 3]],\n                 [20, 2, 1, [35, 3]], [20, 2, 2, [35, 15]], [20, 2, 3, [35, 15]], [20, 2, 4, [35, 15]],\n                 [20, 2, 5, [35, 1]], [20, 2, 6, [35, 1]], [20, 2, 7, [35, 1]], [20, 2, 8, [35, 2]],\n                 [21, 0, -3, [35, 6]], [21, 1, -4, [35, 6]], [21, 1, -3, [35, 6]], [21, 1, 2, [35, 4]],\n                 [21, 1, 3, [35, 4]], [21, 1, 4, [35, 4]], [22, 1, -4, [35, 6]], [22, 1, 2, [35, 4]],\n                 [22, 1, 3, [35, 4]], [22, 1, 4, [35, 4]], [23, 1, -4, [35, 6]], [23, 1, 2, [35, 4]],\n                 [23, 1, 3, [35, 4]], [23, 1, 4, [35, 4]], [24, 1, 2, [35, 4]], [24, 1, 3, [35, 4]],\n                 [25, 1, 2, [35, 4]]]\n\n    # West withwool\n    # stuff = [[-3, 1, 2, [35, 0], 'Right Wing'], [-2, 1, 2, [35, 0], 'Right Wing'], [-2, 1, 3, [35, 0], 'Right Wing'], [-1, 1, -4, [35, 0], 'Right Tailplane'], [-1, 1, 2, [35, 0], 'Right Wing'], [-1, 1, 3, [35, 0], 'Right Wing'], [-1, 1, 4, [35, 0], 'Right Wing'], [0, 1, -4, [35, 0], 'Right Tailplane'], [0, 1, 2, [35, 0], 'Right Wing'], [0, 1, 3, [35, 0], 'Right Wing'], [0, 1, 4, [35, 0], 'Right Wing'], [1, 0, -3, [35, 15], 'Right Tailplane'], [1, 1, -4, [35, 0], 'Right Tailplane'], [1, 1, -3, [35, 0], 'Right Tailplane'], [1, 1, 2, [35, 0], 'Right Wing'], [1, 1, 3, [35, 0], 'Right Wing'], [1, 1, 4, [35, 0], 'Right Wing'], [2, 1, -4, [35, 0], 'Tail'], [2, 1, -3, [35, 0], 'Rear Cabin'], [2, 1, -2, [35, 0], 'Rear Cabin'], [2, 1, -1, [35, 0], 'Mid Cabin'], [2, 1, 0, [35, 0], 'Mid Cabin'], [2, 1, 1, [35, 0], 'Mid Cabin'], [2, 1, 2, [35, 0], 'Wing Cabin'], [2, 1, 3, [35, 0], 'Wing Cabin'], [2, 1, 4, [35, 0], 'Wing Cabin'], [2, 1, 5, [35, 0], 'Forward Cabin'], [2, 1, 6, [35, 0], 'Forward Cabin'], [2, 1, 7, [35, 0], 'Forward Cabin'], [2, 1, 8, [35, 0], 'Cockpit'], [2, 2, -4, [35, 0], 'Tail'], [2, 2, -3, [35, 0], 'Rear Cabin'], [2, 2, -2, [20, 0], 'Rear Cabin'], [2, 2, -1, [35, 0], 'Mid Cabin'], [2, 2, 0, [20, 0], 'Mid Cabin'], [2, 2, 1, [35, 0], 'Mid Cabin'], [2, 2, 2, [20, 0], 'Wing Cabin'], [2, 2, 3, [35, 0], 'Wing Cabin'], [2, 2, 4, [20, 0], 'Wing Cabin'], [2, 2, 5, [35, 0], 'Forward Cabin'], [2, 2, 6, [20, 0], 'Forward Cabin'], [2, 2, 7, [35, 0], 'Forward Cabin'], [2, 2, 8, [20, 0], 'Cockpit'], [3, 0, 8, [35, 15], 'Cockpit'], [3, 1, -4, [35, 0], 'Tail'], [3, 1, -3, [35, 0], 'Rear Cabin'], [3, 1, -2, [35, 0], 'Rear Cabin'], [3, 1, -1, [35, 0], 'Mid Cabin'], [3, 1, 0, [35, 0], 'Mid Cabin'], [3, 1, 1, [35, 0], 'Mid Cabin'], [3, 1, 2, [35, 0], 'Wing Cabin'], [3, 1, 3, [35, 0], 'Wing Cabin'], [3, 1, 4, [35, 0], 'Wing Cabin'], [3, 1, 5, [35, 0], 'Forward Cabin'], [3, 1, 6, [35, 0], 'Forward Cabin'], [3, 1, 7, [35, 0], 'Forward Cabin'], [3, 1, 8, [35, 0], 'Cockpit'], [3, 1, 9, [35, 0], 'Cockpit'], [3, 2, -4, [35, 0], 'Tail'], [3, 2, 9, [20, 0], 'Cockpit'], [3, 3, -4, [35, 0], 'Tail'], [3, 3, -3, [35, 0], 'Rear Cabin'], [3, 3, -2, [35, 0], 'Rear Cabin'], [3, 3, -1, [35, 0], 'Mid Cabin'], [3, 3, 0, [35, 0], 'Mid Cabin'], [3, 3, 1, [35, 0], 'Mid Cabin'], [3, 3, 2, [35, 0], 'Wing Cabin'], [3, 3, 3, [35, 0], 'Wing Cabin'], [3, 3, 4, [35, 0], 'Wing Cabin'], [3, 3, 5, [35, 0], 'Forward Cabin'], [3, 3, 6, [35, 0], 'Forward Cabin'], [3, 3, 7, [35, 0], 'Forward Cabin'], [3, 3, 8, [20, 0], 'Cockpit'], [3, 4, -4, [35, 0], 'Tail'], [4, 1, -4, [35, 0], 'Tail'], [4, 1, -3, [35, 0], 'Rear Cabin'], [4, 1, -2, [35, 0], 'Rear Cabin'], [4, 1, -1, [35, 0], 'Mid Cabin'], [4, 1, 0, [35, 0], 'Mid Cabin'], [4, 1, 1, [35, 0], 'Mid Cabin'], [4, 1, 2, [35, 0], 'Wing Cabin'], [4, 1, 3, [35, 0], 'Wing Cabin'], [4, 1, 4, [35, 0], 'Wing Cabin'], [4, 1, 5, [35, 0], 'Forward Cabin'], [4, 1, 6, [35, 0], 'Forward Cabin'], [4, 1, 7, [35, 0], 'Forward Cabin'], [4, 1, 8, [35, 0], 'Cockpit'], [4, 2, -4, [35, 0], 'Tail'], [4, 2, -3, [35, 0], 'Rear Cabin'], [4, 2, -2, [20, 0], 'Rear Cabin'], [4, 2, -1, [35, 0], 'Mid Cabin'], [4, 2, 0, [20, 0], 'Mid Cabin'], [4, 2, 1, [35, 0], 'Mid Cabin'], [4, 2, 2, [20, 0], 'Wing Cabin'], [4, 2, 3, [35, 0], 'Wing Cabin'], [4, 2, 4, [20, 0], 'Wing Cabin'], [4, 2, 5, [35, 0], 'Forward Cabin'], [4, 2, 6, [20, 0], 'Forward Cabin'], [4, 2, 7, [35, 0], 'Forward Cabin'], [4, 2, 8, [20, 0], 'Cockpit'], [5, 0, -3, [35, 15], 'Left Tailplane'], [5, 1, -4, [35, 0], 'Left Tailplane'], [5, 1, -3, [35, 0], 'Left Tailplane'], [5, 1, 2, [35, 0], 'Left Wing'], [5, 1, 3, [35, 0], 'Left Wing'], [5, 1, 4, [35, 0], 'Left Wing'], [6, 1, -4, [35, 0], 'Left Tailplane'], [6, 1, 2, [35, 0], 'Left Wing'], [6, 1, 3, [35, 0], 'Left Wing'], [6, 1, 4, [35, 0], 'Left Wing'], [7, 1, -4, [35, 0], 'Left Tailplane'], [7, 1, 2, [35, 0], 'Left Wing'], [7, 1, 3, [35, 0], 'Left Wing'], [7, 1, 4, [35, 0], 'Left Wing'], [8, 1, 2, [35, 0], 'Left Wing'], [8, 1, 3, [35, 0], 'Left Wing'], [9, 1, 2, [35, 0], 'Left Wing']]\n    stuff = [[-3, 1, 2, [1, 0], 'Right Wing'], [-2, 1, 2, [1, 0], 'Right Wing'], [-2, 1, 3, [1, 0], 'Right Wing'],\n             [-1, 1, -4, [1, 0], 'Right Tailplane'], [-1, 1, 2, [1, 0], 'Right Wing'], [-1, 1, 3, [1, 0], 'Right Wing'],\n             [-1, 1, 4, [1, 0], 'Right Wing'], [0, 1, -4, [1, 0], 'Right Tailplane'], [0, 1, 2, [1, 0], 'Right Wing'],\n             [0, 1, 3, [1, 0], 'Right Wing'], [0, 1, 4, [1, 0], 'Right Wing'], [1, 0, -3, [35, 15], 'Right Tailplane'],\n             [1, 1, -4, [1, 0], 'Right Tailplane'], [1, 1, -3, [1, 0], 'Right Tailplane'],\n             [1, 1, 2, [1, 0], 'Right Wing'], [1, 1, 3, [1, 0], 'Right Wing'], [1, 1, 4, [1, 0], 'Right Wing'],\n             [2, 1, -4, [1, 0], 'Tail'], [2, 1, -3, [1, 0], 'Rear Cabin'], [2, 1, -2, [1, 0], 'Rear Cabin'],\n             [2, 1, -1, [1, 0], 'Mid Cabin'], [2, 1, 0, [1, 0], 'Mid Cabin'], [2, 1, 1, [1, 0], 'Mid Cabin'],\n             [2, 1, 2, [1, 0], 'Wing Cabin'], [2, 1, 3, [1, 0], 'Wing Cabin'], [2, 1, 4, [1, 0], 'Wing Cabin'],\n             [2, 1, 5, [1, 0], 'Forward Cabin'], [2, 1, 6, [1, 0], 'Forward Cabin'], [2, 1, 7, [1, 0], 'Forward Cabin'],\n             [2, 1, 8, [1, 0], 'Cockpit'], [2, 2, -4, [1, 0], 'Tail'], [2, 2, -3, [1, 0], 'Rear Cabin'],\n             [2, 2, -2, [20, 0], 'Rear Cabin'], [2, 2, -1, [1, 0], 'Mid Cabin'], [2, 2, 0, [20, 0], 'Mid Cabin'],\n             [2, 2, 1, [1, 0], 'Mid Cabin'], [2, 2, 2, [20, 0], 'Wing Cabin'], [2, 2, 3, [1, 0], 'Wing Cabin'],\n             [2, 2, 4, [20, 0], 'Wing Cabin'], [2, 2, 5, [1, 0], 'Forward Cabin'], [2, 2, 6, [20, 0], 'Forward Cabin'],\n             [2, 2, 7, [1, 0], 'Forward Cabin'], [2, 2, 8, [20, 0], 'Cockpit'], [3, 0, 8, [35, 15], 'Cockpit'],\n             [3, 1, -4, [1, 0], 'Tail'], [3, 1, -3, [1, 0], 'Rear Cabin'], [3, 1, -2, [1, 0], 'Rear Cabin'],\n             [3, 1, -1, [1, 0], 'Mid Cabin'], [3, 1, 0, [1, 0], 'Mid Cabin'], [3, 1, 1, [1, 0], 'Mid Cabin'],\n             [3, 1, 2, [1, 0], 'Wing Cabin'], [3, 1, 3, [1, 0], 'Wing Cabin'], [3, 1, 4, [1, 0], 'Wing Cabin'],\n             [3, 1, 5, [1, 0], 'Forward Cabin'], [3, 1, 6, [1, 0], 'Forward Cabin'], [3, 1, 7, [1, 0], 'Forward Cabin'],\n             [3, 1, 8, [1, 0], 'Cockpit'], [3, 1, 9, [1, 0], 'Cockpit'], [3, 2, -4, [1, 0], 'Tail'],\n             [3, 2, 9, [20, 0], 'Cockpit'], [3, 3, -4, [1, 0], 'Tail'], [3, 3, -3, [1, 0], 'Rear Cabin'],\n             [3, 3, -2, [1, 0], 'Rear Cabin'], [3, 3, -1, [1, 0], 'Mid Cabin'], [3, 3, 0, [1, 0], 'Mid Cabin'],\n             [3, 3, 1, [1, 0], 'Mid Cabin'], [3, 3, 2, [1, 0], 'Wing Cabin'], [3, 3, 3, [1, 0], 'Wing Cabin'],\n             [3, 3, 4, [1, 0], 'Wing Cabin'], [3, 3, 5, [1, 0], 'Forward Cabin'], [3, 3, 6, [1, 0], 'Forward Cabin'],\n             [3, 3, 7, [1, 0], 'Forward Cabin'], [3, 3, 8, [20, 0], 'Cockpit'], [3, 4, -4, [1, 0], 'Tail'],\n             [4, 1, -4, [1, 0], 'Tail'], [4, 1, -3, [1, 0], 'Rear Cabin'], [4, 1, -2, [1, 0], 'Rear Cabin'],\n             [4, 1, -1, [1, 0], 'Mid Cabin'], [4, 1, 0, [1, 0], 'Mid Cabin'], [4, 1, 1, [1, 0], 'Mid Cabin'],\n             [4, 1, 2, [1, 0], 'Wing Cabin'], [4, 1, 3, [1, 0], 'Wing Cabin'], [4, 1, 4, [1, 0], 'Wing Cabin'],\n             [4, 1, 5, [1, 0], 'Forward Cabin'], [4, 1, 6, [1, 0], 'Forward Cabin'], [4, 1, 7, [1, 0], 'Forward Cabin'],\n             [4, 1, 8, [1, 0], 'Cockpit'], [4, 2, -4, [1, 0], 'Tail'], [4, 2, -3, [1, 0], 'Rear Cabin'],\n             [4, 2, -2, [20, 0], 'Rear Cabin'], [4, 2, -1, [1, 0], 'Mid Cabin'], [4, 2, 0, [20, 0], 'Mid Cabin'],\n             [4, 2, 1, [1, 0], 'Mid Cabin'], [4, 2, 2, [20, 0], 'Wing Cabin'], [4, 2, 3, [1, 0], 'Wing Cabin'],\n             [4, 2, 4, [20, 0], 'Wing Cabin'], [4, 2, 5, [1, 0], 'Forward Cabin'], [4, 2, 6, [20, 0], 'Forward Cabin'],\n             [4, 2, 7, [1, 0], 'Forward Cabin'], [4, 2, 8, [20, 0], 'Cockpit'], [5, 0, -3, [35, 15], 'Left Tailplane'],\n             [5, 1, -4, [1, 0], 'Left Tailplane'], [5, 1, -3, [1, 0], 'Left Tailplane'], [5, 1, 2, [1, 0], 'Left Wing'],\n             [5, 1, 3, [1, 0], 'Left Wing'], [5, 1, 4, [1, 0], 'Left Wing'], [6, 1, -4, [1, 0], 'Left Tailplane'],\n             [6, 1, 2, [1, 0], 'Left Wing'], [6, 1, 3, [1, 0], 'Left Wing'], [6, 1, 4, [1, 0], 'Left Wing'],\n             [7, 1, -4, [1, 0], 'Left Tailplane'], [7, 1, 2, [1, 0], 'Left Wing'], [7, 1, 3, [1, 0], 'Left Wing'],\n             [7, 1, 4, [1, 0], 'Left Wing'], [8, 1, 2, [1, 0], 'Left Wing'], [8, 1, 3, [1, 0], 'Left Wing'],\n             [9, 1, 2, [1, 0], 'Left Wing']]\n    resetWorld()\n    #while True:\n    #    mc.postToChat(\"Place your Dots Board on top of the Raspberry Pi and hit enter in the commandline (not Minecraft Pi).\")\n    #    mc.postToChat(\" \")\n    #    answer = readInput(\"\", None)\n    #    if answer is not None:\n    #        break\n\n    mc.setBlock(-27, 3, 2, 20)  #Create a glass platform for the player to stand on\n    mc.player.setPos(-27, 4, 2) #Teleport the player to that platform\n    waitBlock(\"Place your dots board on top of the Raspberry Pi and right click the gold block when you are ready.\")\n\n    updatedStuff = checkParts(AIRPLANE)\n    checkColours()\n    demoPlane = offset(updatedStuff, -20, 0, 0)\n    if (len(demoPlane) == 93) and (enableRocketEasterEgg == True):\n        mc.postToChat(\"Easter egg!\")\n\n        if OtherPartStatus[\"Cloud\"]:\n            addClouds(-10, 0, -10)\n            #l = Lightning(0, 0, 0, 0, 0)\n            #l.daemon = True\n            #l.start()\n        if OtherPartStatus[\"Bear\"]:\n            b = Babbage(babbage, 0, 0, -6, 0, 0)\n            b.daemon = True\n            b.start()\n\n        runRocket()\n        sys.exit(0)\n    #mc.setBlock(-27, 3, 2, 20)  #Create a glass platform for the player to stand on\n    #mc.player.setPos(-27, 4, 2) #Teleport the player to that platform\n    #waitBlock()\n    mc.camera.setNormal()\n    if demoPlane == []:\n        mc.postToChat(\"\")\n        mc.postToChat(\"Dots board not detected! Did you correctly attach it or forget to join the dots?\")\n        mc.postToChat(\" \")\n        runSimulation()\n    else:\n\n        placeBlocks(demoPlane)\n        mc.postToChat(\" \")\n        #mc.postToChat(\"When you are ready to test your plane, hit enter in commandline (not Minecraft\")\n        #input()\n        waitBlock(\"When you are ready to test your plane, right click the golden block again.\")\n\n        resetWorld()\n        mc.player.setPos(-20, 8, 17)\n        mc.setBlock(-20, 7, 17, 20)\n\n        if OtherPartStatus[\"Cloud\"]:\n            addClouds()\n            l = Lightning(0, 0, 0, 0, 0)\n            l.daemon = True\n            l.start()\n        if OtherPartStatus[\"Bear\"]:\n            b = Babbage(babbage, 0, 0, -6, 0, 0)\n            b.daemon = True\n            b.start()\n\n        if flightScore == 24:\n            movePlane(updatedStuff, 20, 0)\n        else:\n            movePlane(updatedStuff, 20, 10)\n        resetWorld()\n        mc.player.setPos(-20, 8, 17)\n        mc.setBlock(-20, 7, 17, 20)\n        createSign()\n        mc.player.setPos(-20, 8, 17)\n        mc.setBlock(-20, 7, 17, 20)", "fn_id": 6, "class_fn": false, "repo": "gbaman/dots-minecraft", "file": "rpi_dots_minecraft/dots_minecraft.py", "last_update_at": "2018-02-23T22:22:34+00:00", "question_id": "2f859f8994e33ba15117d31607c058c7b04356ed_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def runSimulation():\n    global flightScore, otherPartStatus\n    WoolStuff = [[13, 1, 2, [35, 14]], [14, 1, 2, [35, 14]], [14, 1, 3, [35, 14]], [15, 1, -4, [35, 13]], [15, 1, 2, [35, 14]], [15, 1, 3, [35, 14]], [15, 1, 4, [35, 14]], [16, 1, -4, [35, 13]], [16, 1, 2, [35, 14]], [16, 1, 3, [35, 14]], [16, 1, 4, [35, 14]], [17, 0, -3, [35, 13]], [17, 1, -4, [35, 13]], [17, 1, -3, [35, 13]], [17, 1, 2, [35, 14]], [17, 1, 3, [35, 14]], [17, 1, 4, [35, 14]], [18, 1, -4, [35, 12]], [18, 1, -3, [35, 5]], [18, 1, -2, [35, 5]], [18, 1, -1, [35, 3]], [18, 1, 0, [35, 3]], [18, 1, 1, [35, 3]], [18, 1, 2, [35, 15]], [18, 1, 3, [35, 15]], [18, 1, 4, [35, 15]], [18, 1, 5, [35, 1]], [18, 1, 6, [35, 1]], [18, 1, 7, [35, 1]], [18, 1, 8, [35, 2]], [18, 2, -4, [35, 12]], [18, 2, -3, [35, 5]], [18, 2, -2, [35, 5]], [18, 2, -1, [35, 3]], [18, 2, 0, [35, 3]], [18, 2, 1, [35, 3]], [18, 2, 2, [35, 15]], [18, 2, 3, [35, 15]], [18, 2, 4, [35, 15]], [18, 2, 5, [35, 1]], [18, 2, 6, [35, 1]], [18, 2, 7, [35, 1]], [18, 2, 8, [35, 2]], [19, 0, 8, [35, 2]], [19, 1, -4, [35, 12]], [19, 1, -3, [35, 5]], [19, 1, -2, [35, 5]], [19, 1, -1, [35, 3]], [19, 1, 0, [35, 3]], [19, 1, 1, [35, 3]], [19, 1, 2, [35, 15]], [19, 1, 3, [35, 15]], [19, 1, 4, [35, 15]], [19, 1, 5, [35, 1]], [19, 1, 6, [35, 1]], [19, 1, 7, [35, 1]], [19, 1, 8, [35, 2]], [19, 1, 9, [35, 2]], [19, 2, -4, [35, 12]], [19, 2, 9, [35, 2]], [19, 3, -4, [35, 12]], [19, 3, -3, [35, 5]], [19, 3, -2, [35, 5]], [19, 3, -1, [35, 3]], [19, 3, 0, [35, 3]], [19, 3, 1, [35, 3]], [19, 3, 2, [35, 15]], [19, 3, 3, [35, 15]], [19, 3, 4, [35, 15]], [19, 3, 5, [35, 1]], [19, 3, 6, [35, 1]], [19, 3, 7, [35, 1]], [19, 3, 8, [35, 2]], [19, 4, -4, [35, 12]], [20, 1, -4, [35, 12]], [20, 1, -3, [35, 5]], [20, 1, -2, [35, 5]], [20, 1, -1, [35, 3]], [20, 1, 0, [35, 3]], [20, 1, 1, [35, 3]], [20, 1, 2, [35, 15]], [20, 1, 3, [35, 15]], [20, 1, 4, [35, 15]], [20, 1, 5, [35, 1]], [20, 1, 6, [35, 1]], [20, 1, 7, [35, 1]], [20, 1, 8, [35, 2]], [20, 2, -4, [35, 12]], [20, 2, -3, [35, 5]], [20, 2, -2, [35, 5]], [20, 2, -1, [35, 3]], [20, 2, 0, [35, 3]], [20, 2, 1, [35, 3]], [20, 2, 2, [35, 15]], [20, 2, 3, [35, 15]], [20, 2, 4, [35, 15]], [20, 2, 5, [35, 1]], [20, 2, 6, [35, 1]], [20, 2, 7, [35, 1]], [20, 2, 8, [35, 2]], [21, 0, -3, [35, 6]], [21, 1, -4, [35, 6]], [21, 1, -3, [35, 6]], [21, 1, 2, [35, 4]], [21, 1, 3, [35, 4]], [21, 1, 4, [35, 4]], [22, 1, -4, [35, 6]], [22, 1, 2, [35, 4]], [22, 1, 3, [35, 4]], [22, 1, 4, [35, 4]], [23, 1, -4, [35, 6]], [23, 1, 2, [35, 4]], [23, 1, 3, [35, 4]], [23, 1, 4, [35, 4]], [24, 1, 2, [35, 4]], [24, 1, 3, [35, 4]], [25, 1, 2, [35, 4]]]\n    stuff = [[-3, 1, 2, [1, 0], 'Right Wing'], [-2, 1, 2, [1, 0], 'Right Wing'], [-2, 1, 3, [1, 0], 'Right Wing'], [-1, 1, -4, [1, 0], 'Right Tailplane'], [-1, 1, 2, [1, 0], 'Right Wing'], [-1, 1, 3, [1, 0], 'Right Wing'], [-1, 1, 4, [1, 0], 'Right Wing'], [0, 1, -4, [1, 0], 'Right Tailplane'], [0, 1, 2, [1, 0], 'Right Wing'], [0, 1, 3, [1, 0], 'Right Wing'], [0, 1, 4, [1, 0], 'Right Wing'], [1, 0, -3, [35, 15], 'Right Tailplane'], [1, 1, -4, [1, 0], 'Right Tailplane'], [1, 1, -3, [1, 0], 'Right Tailplane'], [1, 1, 2, [1, 0], 'Right Wing'], [1, 1, 3, [1, 0], 'Right Wing'], [1, 1, 4, [1, 0], 'Right Wing'], [2, 1, -4, [1, 0], 'Tail'], [2, 1, -3, [1, 0], 'Rear Cabin'], [2, 1, -2, [1, 0], 'Rear Cabin'], [2, 1, -1, [1, 0], 'Mid Cabin'], [2, 1, 0, [1, 0], 'Mid Cabin'], [2, 1, 1, [1, 0], 'Mid Cabin'], [2, 1, 2, [1, 0], 'Wing Cabin'], [2, 1, 3, [1, 0], 'Wing Cabin'], [2, 1, 4, [1, 0], 'Wing Cabin'], [2, 1, 5, [1, 0], 'Forward Cabin'], [2, 1, 6, [1, 0], 'Forward Cabin'], [2, 1, 7, [1, 0], 'Forward Cabin'], [2, 1, 8, [1, 0], 'Cockpit'], [2, 2, -4, [1, 0], 'Tail'], [2, 2, -3, [1, 0], 'Rear Cabin'], [2, 2, -2, [20, 0], 'Rear Cabin'], [2, 2, -1, [1, 0], 'Mid Cabin'], [2, 2, 0, [20, 0], 'Mid Cabin'], [2, 2, 1, [1, 0], 'Mid Cabin'], [2, 2, 2, [20, 0], 'Wing Cabin'], [2, 2, 3, [1, 0], 'Wing Cabin'], [2, 2, 4, [20, 0], 'Wing Cabin'], [2, 2, 5, [1, 0], 'Forward Cabin'], [2, 2, 6, [20, 0], 'Forward Cabin'], [2, 2, 7, [1, 0], 'Forward Cabin'], [2, 2, 8, [20, 0], 'Cockpit'], [3, 0, 8, [35, 15], 'Cockpit'], [3, 1, -4, [1, 0], 'Tail'], [3, 1, -3, [1, 0], 'Rear Cabin'], [3, 1, -2, [1, 0], 'Rear Cabin'], [3, 1, -1, [1, 0], 'Mid Cabin'], [3, 1, 0, [1, 0], 'Mid Cabin'], [3, 1, 1, [1, 0], 'Mid Cabin'], [3, 1, 2, [1, 0], 'Wing Cabin'], [3, 1, 3, [1, 0], 'Wing Cabin'], [3, 1, 4, [1, 0], 'Wing Cabin'], [3, 1, 5, [1, 0], 'Forward Cabin'], [3, 1, 6, [1, 0], 'Forward Cabin'], [3, 1, 7, [1, 0], 'Forward Cabin'], [3, 1, 8, [1, 0], 'Cockpit'], [3, 1, 9, [1, 0], 'Cockpit'], [3, 2, -4, [1, 0], 'Tail'], [3, 2, 9, [20, 0], 'Cockpit'], [3, 3, -4, [1, 0], 'Tail'], [3, 3, -3, [1, 0], 'Rear Cabin'], [3, 3, -2, [1, 0], 'Rear Cabin'], [3, 3, -1, [1, 0], 'Mid Cabin'], [3, 3, 0, [1, 0], 'Mid Cabin'], [3, 3, 1, [1, 0], 'Mid Cabin'], [3, 3, 2, [1, 0], 'Wing Cabin'], [3, 3, 3, [1, 0], 'Wing Cabin'], [3, 3, 4, [1, 0], 'Wing Cabin'], [3, 3, 5, [1, 0], 'Forward Cabin'], [3, 3, 6, [1, 0], 'Forward Cabin'], [3, 3, 7, [1, 0], 'Forward Cabin'], [3, 3, 8, [20, 0], 'Cockpit'], [3, 4, -4, [1, 0], 'Tail'], [4, 1, -4, [1, 0], 'Tail'], [4, 1, -3, [1, 0], 'Rear Cabin'], [4, 1, -2, [1, 0], 'Rear Cabin'], [4, 1, -1, [1, 0], 'Mid Cabin'], [4, 1, 0, [1, 0], 'Mid Cabin'], [4, 1, 1, [1, 0], 'Mid Cabin'], [4, 1, 2, [1, 0], 'Wing Cabin'], [4, 1, 3, [1, 0], 'Wing Cabin'], [4, 1, 4, [1, 0], 'Wing Cabin'], [4, 1, 5, [1, 0], 'Forward Cabin'], [4, 1, 6, [1, 0], 'Forward Cabin'], [4, 1, 7, [1, 0], 'Forward Cabin'], [4, 1, 8, [1, 0], 'Cockpit'], [4, 2, -4, [1, 0], 'Tail'], [4, 2, -3, [1, 0], 'Rear Cabin'], [4, 2, -2, [20, 0], 'Rear Cabin'], [4, 2, -1, [1, 0], 'Mid Cabin'], [4, 2, 0, [20, 0], 'Mid Cabin'], [4, 2, 1, [1, 0], 'Mid Cabin'], [4, 2, 2, [20, 0], 'Wing Cabin'], [4, 2, 3, [1, 0], 'Wing Cabin'], [4, 2, 4, [20, 0], 'Wing Cabin'], [4, 2, 5, [1, 0], 'Forward Cabin'], [4, 2, 6, [20, 0], 'Forward Cabin'], [4, 2, 7, [1, 0], 'Forward Cabin'], [4, 2, 8, [20, 0], 'Cockpit'], [5, 0, -3, [35, 15], 'Left Tailplane'], [5, 1, -4, [1, 0], 'Left Tailplane'], [5, 1, -3, [1, 0], 'Left Tailplane'], [5, 1, 2, [1, 0], 'Left Wing'], [5, 1, 3, [1, 0], 'Left Wing'], [5, 1, 4, [1, 0], 'Left Wing'], [6, 1, -4, [1, 0], 'Left Tailplane'], [6, 1, 2, [1, 0], 'Left Wing'], [6, 1, 3, [1, 0], 'Left Wing'], [6, 1, 4, [1, 0], 'Left Wing'], [7, 1, -4, [1, 0], 'Left Tailplane'], [7, 1, 2, [1, 0], 'Left Wing'], [7, 1, 3, [1, 0], 'Left Wing'], [7, 1, 4, [1, 0], 'Left Wing'], [8, 1, 2, [1, 0], 'Left Wing'], [8, 1, 3, [1, 0], 'Left Wing'], [9, 1, 2, [1, 0], 'Left Wing']]\n    resetWorld()\n    mc.setBlock(-27, 3, 2, 20)\n    mc.player.setPos(-27, 4, 2)\n    waitBlock('Place your dots board on top of the Raspberry Pi and right click the gold block when you are ready.')\n    updatedStuff = checkParts(AIRPLANE)\n    checkColours()\n    demoPlane = offset(updatedStuff, -20, 0, 0)\n    if len(demoPlane) == 93 and enableRocketEasterEgg == True:\n        mc.postToChat('Easter egg!')\n        if OtherPartStatus['Cloud']:\n            addClouds(-10, 0, -10)\n        if OtherPartStatus['Bear']:\n            b = Babbage(babbage, 0, 0, -6, 0, 0)\n            b.daemon = True\n            b.start()\n        runRocket()\n        sys.exit(0)\n    mc.camera.setNormal()\n    if demoPlane == []:\n        mc.postToChat('')\n        mc.postToChat('Dots board not detected! Did you correctly attach it or forget to join the dots?')\n        mc.postToChat(' ')\n        runSimulation()\n    else:\n        placeBlocks(demoPlane)\n        mc.postToChat(' ')\n        waitBlock('When you are ready to test your plane, right click the golden block again.')\n        resetWorld()\n        mc.player.setPos(-20, 8, 17)\n        mc.setBlock(-20, 7, 17, 20)\n        if OtherPartStatus['Cloud']:\n            addClouds()\n            l = Lightning(0, 0, 0, 0, 0)\n            l.daemon = True\n            l.start()\n        if OtherPartStatus['Bear']:\n            b = Babbage(babbage, 0, 0, -6, 0, 0)\n            b.daemon = True\n            b.start()\n        if flightScore == 24:\n            movePlane(updatedStuff, 20, 0)\n        else:\n            movePlane(updatedStuff, 20, 10)\n        resetWorld()\n        mc.player.setPos(-20, 8, 17)\n        mc.setBlock(-20, 7, 17, 20)\n        createSign()\n        mc.player.setPos(-20, 8, 17)\n"]]}
{"hexsha": "3d017c8f3862f87dea3cbb27cc41173158a94874", "ext": "py", "lang": "Python", "content": "def PositionalEncoding(indices, n_symbols, output_dim, max_len=500, cycle_scale=10000, random_state=None,\n                       init=\"embedding_normal\", scale=1., strict=None, name=None):\n    pos_name = name + \"_pos_cyclic\"\n    emb_name = name + \"_embedding\"\n\n    def sincos(x, i):\n        if i % 2 == 0:\n            return np.sin(x)\n        return np.cos(x)\n\n    pe = tf.convert_to_tensor([sincos(pos / (cycle_scale ** (2 * i / float(output_dim))), i)\n                               for pos in range(1, max_len + 1)\n                               for i in range(1, output_dim + 1)])\n    pe = tf.reshape(pe, [-1, max_len, output_dim])\n    pe = tf.transpose(pe, [1, 0, 2])\n\n    e_inds, emb = Embedding(indices, n_symbols, output_dim, random_state=random_state,\n                            init=init, scale=scale, strict=strict, name=emb_name)\n\n    # hardcode 3d assumption for now\n    shp = _shape(indices)\n    if len(shp) == 3:\n        faker = tf.ones_like(indices)[:, 0, 0]\n    else:\n        raise ValueError(\"Currently unsupported input shape {} to PositionalEncoding\".format(shp))\n    cl = tf.cast(tf.reduce_sum(faker), tf.int32)\n    return tf.add(e_inds, pe[:cl]), emb", "fn_id": 13, "class_fn": false, "repo": "kastnerkyle/harmonic_recomposition_workshop", "file": "code/lib/nodes/nodes.py", "last_update_at": "2018-07-18T11:44:23+00:00", "question_id": "3d017c8f3862f87dea3cbb27cc41173158a94874_13", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def PositionalEncoding(indices, n_symbols, output_dim, max_len=500, cycle_scale=10000, random_state=None, init='embedding_normal', scale=1.0, strict=None, name=None):\n    pos_name = name + '_pos_cyclic'\n    emb_name = name + '_embedding'\n\n    def sincos(x, i):\n        if i % 2 == 0:\n            return np.sin(x)\n        return np.cos(x)\n    pe = tf.convert_to_tensor([sincos(pos / cycle_scale ** (2 * i / float(output_dim)), i) for pos in range(1, max_len + 1) for i in range(1, output_dim + 1)])\n    pe = tf.reshape(pe, [-1, max_len, output_dim])\n    pe = tf.transpose(pe, [1, 0, 2])\n    e_inds, emb = Embedding(indices, n_symbols, output_dim, random_state=random_state, init=init, scale=scale, strict=strict, name=emb_name)\n    shp = _shape(indices)\n    if len(shp) == 3:\n        faker = tf.ones_like(indices)[:, 0, 0]\n    else:\n        raise ValueError('Currently unsupported input shape {} to PositionalEncoding'.format(shp))\n    cl = tf.cast(tf.reduce_sum(faker), tf.int32)\n"]]}
{"hexsha": "64e670dd99f55537c86b06007c5a54c613560b4f", "ext": "py", "lang": "Python", "content": "def to_safe_annotation_key(key):\n    \"\"\"Xray doesn't like keys that have punctuations\n    and likes to silently drop things.\"\"\"\n    safe_key = key.translate(str.maketrans(\"\", \"\", string.punctuation))\n    return safe_key", "fn_id": 12, "class_fn": false, "repo": "szilveszter/fleece", "file": "fleece/xray.py", "last_update_at": "2018-11-16T03:49:46+00:00", "question_id": "64e670dd99f55537c86b06007c5a54c613560b4f_12", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def to_safe_annotation_key(key):\n    \"\"\"Xray doesn't like keys that have punctuations\n    and likes to silently drop things.\"\"\"\n    safe_key = key.translate(str.maketrans('', '', string.punctuation))\n"]]}
{"hexsha": "ad98b1576f343fcacd3cbee72169b039a416cdf4", "ext": "py", "lang": "Python", "content": "def test_that_viewspec_prints_help_format(capsys):\n\n    rc = perform_viewspec([\"help-format\"])\n    sys_out_lines, sys_err_lines = capsys.readouterr()\n\n    assert 1 == rc\n\n    # print \">>>\" + \"\n\".join(sys_out_lines) + \"<<<<\"\n\n    expected =       \"\"\"Viewspec File Format\n====================\n\nThe viewspec file format used by this tool is a collection of headers\n(using the typical one-per-line name:value syntax), followed by an\nempty line, followed by a set of one-per-line rules.\n\nThe headers must contain at least the following:\n\n    Format   - version of the viewspec format used throughout the file\n    Url      - base URL applied to all rules; tree checkout location\n\nThe following headers are optional:\n\n    Revision - version of the tree items to checkout\n\nFollowing the headers and blank line separator are the path rules.\nThe rules are list of URLs -- relative to the base URL stated in the\nheaders -- with optional annotations to specify the desired working\ncopy depth of each item:\n\n    PATH/**  - checkout PATH and all its children to infinite depth\n    PATH/*   - checkout PATH and its immediate children\n    PATH/~   - checkout PATH and its file children\n    PATH     - checkout PATH non-recursively\n\nBy default, the top-level directory (associated with the base URL) is\nchecked out with empty depth.  You can override this using the special\nrules '**', '*', and '~' as appropriate.\n\nIt is not necessary to explicitly list the parent directories of each\npath associated with a rule.  If the parent directory of a given path\nis not \"covered\" by a previous rule, it will be checked out with empty\ndepth.\n\nExamples\n========\n\nHere's a sample viewspec file:\n\n    Format: 1\n    Url: http://svn.apache.org/repos/asf/subversion\n    Revision: 36366\n\n    trunk/**\n    branches/1.5.x/**\n    branches/1.6.x/**\n    README\n    branches/1.4.x/STATUS\n    branches/1.4.x/subversion/tests/cmdline/~\n\nYou may wish to version your viewspec files.  If so, you can use this\nscript in conjunction with 'svn cat' to fetch, parse, and act on a\nversioned viewspec file:\n\n    $ svn cat http://svn.example.com/specs/dev-spec.txt |\n         __SCRIPTNAME__ checkout - /path/to/target/directory\n         \"\"\".replace(\"__SCRIPTNAME__\", __SCRIPTNAME__)\n\n    all_the_lines_should_be_the_same(expected, sys_out_lines)\n\n    all_the_lines_should_be_the_same([], sys_err_lines)\n", "fn_id": 8, "class_fn": false, "repo": "timgates42/subversion", "file": "tools/client-side/svnviewspec_test.py", "last_update_at": "2018-12-24T22:05:09+00:00", "question_id": "ad98b1576f343fcacd3cbee72169b039a416cdf4_8", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_that_viewspec_prints_help_format(capsys):\n    rc = perform_viewspec(['help-format'])\n    sys_out_lines, sys_err_lines = capsys.readouterr()\n    assert 1 == rc\n    expected = 'Viewspec File Format\\n====================\\n\\nThe viewspec file format used by this tool is a collection of headers\\n(using the typical one-per-line name:value syntax), followed by an\\nempty line, followed by a set of one-per-line rules.\\n\\nThe headers must contain at least the following:\\n\\n    Format   - version of the viewspec format used throughout the file\\n    Url      - base URL applied to all rules; tree checkout location\\n\\nThe following headers are optional:\\n\\n    Revision - version of the tree items to checkout\\n\\nFollowing the headers and blank line separator are the path rules.\\nThe rules are list of URLs -- relative to the base URL stated in the\\nheaders -- with optional annotations to specify the desired working\\ncopy depth of each item:\\n\\n    PATH/**  - checkout PATH and all its children to infinite depth\\n    PATH/*   - checkout PATH and its immediate children\\n    PATH/~   - checkout PATH and its file children\\n    PATH     - checkout PATH non-recursively\\n\\nBy default, the top-level directory (associated with the base URL) is\\nchecked out with empty depth.  You can override this using the special\\nrules \\'**\\', \\'*\\', and \\'~\\' as appropriate.\\n\\nIt is not necessary to explicitly list the parent directories of each\\npath associated with a rule.  If the parent directory of a given path\\nis not \"covered\" by a previous rule, it will be checked out with empty\\ndepth.\\n\\nExamples\\n========\\n\\nHere\\'s a sample viewspec file:\\n\\n    Format: 1\\n    Url: http://svn.apache.org/repos/asf/subversion\\n    Revision: 36366\\n\\n    trunk/**\\n    branches/1.5.x/**\\n    branches/1.6.x/**\\n    README\\n    branches/1.4.x/STATUS\\n    branches/1.4.x/subversion/tests/cmdline/~\\n\\nYou may wish to version your viewspec files.  If so, you can use this\\nscript in conjunction with \\'svn cat\\' to fetch, parse, and act on a\\nversioned viewspec file:\\n\\n    $ svn cat http://svn.example.com/specs/dev-spec.txt |\\n         __SCRIPTNAME__ checkout - /path/to/target/directory\\n         '.replace('__SCRIPTNAME__', __SCRIPTNAME__)\n    all_the_lines_should_be_the_same(expected, sys_out_lines)\n"]]}
{"hexsha": "38bf50b1c1ad069611c020e0df44711105596d91", "ext": "py", "lang": "Python", "content": "def check_comment_spacing(self, lines):\n    comment_line = self.current_line_num\n    prev_line = comment_line - 1\n\n    if self.current_line_num == 0 or (lines[comment_line] != '/**/' and not re.search(r'^\\s*//', lines[comment_line])):\n        return\n\n    # Check that there is a blank link above a comment.\n    if (lines[prev_line] != '/**/' and not re.search(r'^\\s*//', lines[prev_line]) and \\\n        not re.search(r'[\\}\\{\\:]\\s*$', lines[prev_line]) and \\\n        (not lines[prev_line].isspace() and lines[prev_line])):\n            # Add 1 to line number because indexes start with 0\n            self.add_error(\"MISSING_COMMENT_SEPERATION\", line = comment_line + 1)\n\n    # Check if there is a blank line below a comment.\n    next_line = comment_line + 1\n    if (len(lines) < next_line and (lines[next_line].isspace() or not lines[next_line])):\n        # Make sure this is not the top comment\n        while prev_line > 0 and (lines[prev_line] == '/**/' or re.search(r'^\\s*//', lines[prev_line])):\n            prev_line = prev_line - 1\n            #print(prev_line, \": \", lines[prev_line])\n\n        if prev_line > 0:\n            self.add_error(\"EXTRA_COMMENT_SEPERATION\", line = comment_line + 1)", "fn_id": 3, "class_fn": false, "repo": "DoctorHayes/235CppStyle", "file": "comment_checks.py", "last_update_at": "2018-11-10T16:39:17+00:00", "question_id": "38bf50b1c1ad069611c020e0df44711105596d91_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def check_comment_spacing(self, lines):\n    comment_line = self.current_line_num\n    prev_line = comment_line - 1\n    if self.current_line_num == 0 or (lines[comment_line] != '/**/' and (not re.search('^\\\\s*//', lines[comment_line]))):\n        return\n    if lines[prev_line] != '/**/' and (not re.search('^\\\\s*//', lines[prev_line])) and (not re.search('[\\\\}\\\\{\\\\:]\\\\s*$', lines[prev_line])) and (not lines[prev_line].isspace() and lines[prev_line]):\n        self.add_error('MISSING_COMMENT_SEPERATION', line=comment_line + 1)\n    next_line = comment_line + 1\n    if len(lines) < next_line and (lines[next_line].isspace() or not lines[next_line]):\n        while prev_line > 0 and (lines[prev_line] == '/**/' or re.search('^\\\\s*//', lines[prev_line])):\n            prev_line = prev_line - 1\n        if prev_line > 0:\n"]]}
{"hexsha": "db8109bed31a6a519d2db98e9bae372e324191b8", "ext": "py", "lang": "Python", "content": "def main(args=None):\n    if args is None:\n        args = sys.argv[1:]\n    ParserShell().main(args)", "fn_id": 0, "class_fn": false, "repo": "RIFTIO/tosca-parser", "file": "toscaparser/shell.py", "last_update_at": "2018-12-06T23:11:11+00:00", "question_id": "db8109bed31a6a519d2db98e9bae372e324191b8_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main(args=None):\n    if args is None:\n        args = sys.argv[1:]\n"]]}
{"hexsha": "f020e797c30e724301607bec0a8b0a39f790127d", "ext": "py", "lang": "Python", "content": "def imread(path, grayscale = False):\n  if (grayscale):\n    return scipy.misc.imread(path, flatten = True).astype(np.float)\n  else:\n    return scipy.misc.imread(path).astype(np.float)", "fn_id": 0, "class_fn": false, "repo": "vritxii/machine_learning_labs", "file": "dcgan.py", "last_update_at": "2018-11-08T15:36:10+00:00", "question_id": "f020e797c30e724301607bec0a8b0a39f790127d_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def imread(path, grayscale=False):\n    if grayscale:\n        return scipy.misc.imread(path, flatten=True).astype(np.float)\n    else:\n"]]}
{"hexsha": "3db2c6e6cf4d2fec1d014dae352f88a3c154522f", "ext": "py", "lang": "Python", "content": "def priors(name, vary):\n    \"\"\"Return covariance matrix with prior knowledge about parameters\"\"\"\n    \n    mock = pickle.load(open('../data/mock_{}.params'.format(name), 'rb'))\n    \n    cprog = mock['prog_prior']\n    cbary = np.array([0.1*x.value for x in pparams_fid[:5]])**-2\n    chalo = np.zeros(4)\n    cdipole = np.zeros(3)\n    cquad = np.zeros(5)\n    coctu = np.zeros(7)\n    \n    priors = {'progenitor': cprog, 'bary': cbary, 'halo': chalo, 'dipole': cdipole, 'quad': cquad, 'octu': coctu}\n    cprior = np.empty(0)\n    for v in vary:\n        cprior = np.concatenate([cprior, priors[v]])\n    \n    pxi = np.diag(cprior)\n    \n    return pxi", "fn_id": 35, "class_fn": false, "repo": "abonaca/stream_information", "file": "scripts/stream_info/stream_info.py", "last_update_at": "2018-06-02T09:53:19+00:00", "question_id": "3db2c6e6cf4d2fec1d014dae352f88a3c154522f_35", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def priors(name, vary):\n    \"\"\"Return covariance matrix with prior knowledge about parameters\"\"\"\n    mock = pickle.load(open('../data/mock_{}.params'.format(name), 'rb'))\n    cprog = mock['prog_prior']\n    cbary = np.array([0.1 * x.value for x in pparams_fid[:5]]) ** (-2)\n    chalo = np.zeros(4)\n    cdipole = np.zeros(3)\n    cquad = np.zeros(5)\n    coctu = np.zeros(7)\n    priors = {'progenitor': cprog, 'bary': cbary, 'halo': chalo, 'dipole': cdipole, 'quad': cquad, 'octu': coctu}\n    cprior = np.empty(0)\n    for v in vary:\n        cprior = np.concatenate([cprior, priors[v]])\n    pxi = np.diag(cprior)\n"]]}
{"hexsha": "a76539d63c30a989cb7da6378964de67e875ec90", "ext": "py", "lang": "Python", "content": "def get_credentials(rcfile='~/.virlrc'):\n    \"\"\"\n    Used to get the VIRL credentials\n\n    * The login credentials are taken in the following order\n\n    * Check for .virlrc in current directory\n\n    * Check environment variables\n\n    * Check ~/.virlrc\n\n    * Prompt user\n\n    \"\"\"\n    # initialize vars\n    host = None\n    username = None\n    password = None\n    config = dict()\n\n    host = get_prop('VIRL_HOST')\n    username = get_prop('VIRL_USERNAME')\n    password = get_prop('VIRL_PASSWORD')\n\n    # some additional configuration that can be set / overriden\n    configurable_props = ['VIRL_TELNET_COMMAND', 'VIRL_CONSOLE_COMMAND',\n                          'VIRL_SSH_COMMAND', 'VIRL_SSH_USERNAME']\n\n    for p in configurable_props:\n        if get_prop(p):\n            config[p] = get_prop(p)\n\n    if not host:  # pragma: no cover\n        prompt = 'Please enter the IP / hostname of your virl server: '\n        host = _get_from_user(prompt)\n\n    if not username:\n        username = _get_from_user(\"Please enter your VIRL username: \")\n\n    if not password:\n        password = _get_password(\"Please enter your password: \")\n\n    if not all([host, username, password]):  # pragma: no cover\n        prompt = \"Unable to determine VIRL credentials, please see docs\"\n        sys.exit(prompt)\n    else:\n        return (host, username, password, config)", "fn_id": 4, "class_fn": false, "repo": "gve-vse-tim/virlutils", "file": "virl/api/credentials.py", "last_update_at": "2018-06-07T16:19:38+00:00", "question_id": "a76539d63c30a989cb7da6378964de67e875ec90_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_credentials(rcfile='~/.virlrc'):\n    \"\"\"\n    Used to get the VIRL credentials\n\n    * The login credentials are taken in the following order\n\n    * Check for .virlrc in current directory\n\n    * Check environment variables\n\n    * Check ~/.virlrc\n\n    * Prompt user\n\n    \"\"\"\n    host = None\n    username = None\n    password = None\n    config = dict()\n    host = get_prop('VIRL_HOST')\n    username = get_prop('VIRL_USERNAME')\n    password = get_prop('VIRL_PASSWORD')\n    configurable_props = ['VIRL_TELNET_COMMAND', 'VIRL_CONSOLE_COMMAND', 'VIRL_SSH_COMMAND', 'VIRL_SSH_USERNAME']\n    for p in configurable_props:\n        if get_prop(p):\n            config[p] = get_prop(p)\n    if not host:\n        prompt = 'Please enter the IP / hostname of your virl server: '\n        host = _get_from_user(prompt)\n    if not username:\n        username = _get_from_user('Please enter your VIRL username: ')\n    if not password:\n        password = _get_password('Please enter your password: ')\n    if not all([host, username, password]):\n        prompt = 'Unable to determine VIRL credentials, please see docs'\n        sys.exit(prompt)\n    else:\n"]]}
{"hexsha": "d9e1bbfe4521aff871c953fa4504d8d0371e2889", "ext": "py", "lang": "Python", "content": "def get_filtered_path(path_to_image, filename_key, storage):\n    \"\"\"\n    Return the 'filtered path'\n    \"\"\"\n    containing_folder, filename = os.path.split(path_to_image)\n\n    filtered_filename = get_filtered_filename(filename, filename_key)\n    path_to_return = os.path.join(*[\n        containing_folder,\n        VERSATILEIMAGEFIELD_FILTERED_DIRNAME,\n        filtered_filename\n    ])\n    # Removing spaces so this path is memcached key friendly\n    path_to_return = path_to_return.replace(' ', '')\n    return path_to_return", "fn_id": 4, "class_fn": false, "repo": "nrullo/django-versatileimagefield", "file": "versatileimagefield/utils.py", "last_update_at": "2018-05-31T20:16:35+00:00", "question_id": "d9e1bbfe4521aff871c953fa4504d8d0371e2889_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_filtered_path(path_to_image, filename_key, storage):\n    \"\"\"\n    Return the 'filtered path'\n    \"\"\"\n    containing_folder, filename = os.path.split(path_to_image)\n    filtered_filename = get_filtered_filename(filename, filename_key)\n    path_to_return = os.path.join(*[containing_folder, VERSATILEIMAGEFIELD_FILTERED_DIRNAME, filtered_filename])\n    path_to_return = path_to_return.replace(' ', '')\n"]]}
{"hexsha": "5642bea2a4d006a16cb5dc638961e8224156c351", "ext": "py", "lang": "Python", "content": "@CELERY.task\ndef add_task(name):\n    \"\"\"Run the slow task as a subprocess and send results to the web site.\"\"\"\n    args = './slow_task.sh', str(name)\n    with Popen(args, stdout=PIPE, universal_newlines=True) as proc:\n        for line in proc.stdout:\n            SOCKETIO.emit('log', {'data': line.rstrip()})", "fn_id": 1, "class_fn": false, "repo": "cemsbr/flask-cpu-tasks", "file": "src/worker/worker.py", "last_update_at": "2018-02-04T18:19:07+00:00", "question_id": "5642bea2a4d006a16cb5dc638961e8224156c351_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@CELERY.task\ndef add_task(name):\n    \"\"\"Run the slow task as a subprocess and send results to the web site.\"\"\"\n    args = ('./slow_task.sh', str(name))\n    with Popen(args, stdout=PIPE, universal_newlines=True) as proc:\n        for line in proc.stdout:\n"]]}
{"hexsha": "f9fb953da7000c2d128f3ddaf6797febacc8609b", "ext": "py", "lang": "Python", "content": "def get_log_volume_map(root_log_dir, dockerrun_dict):\n    \"\"\"\n    Return host log path to container log path mapping if Logging is provided\n    in the dockerrun, and otherwise return empty dict.\n    :param root_log_dir: str: the root local logs directory\n    :param dockerrun_dict: dict: Dockerrun.aws.json as dict\n    :return: dict\n    \"\"\"\n\n    if not dockerrun_dict:\n        return {}\n    host_log = get_host_log_path(root_log_dir)\n    container_log = dockerrun.get_logdir(dockerrun_dict)\n    return {host_log: container_log} if container_log else {}", "fn_id": 0, "class_fn": false, "repo": "ianblenke/awsebcli", "file": "ebcli/docker/log.py", "last_update_at": "2018-12-19T14:06:22+00:00", "question_id": "f9fb953da7000c2d128f3ddaf6797febacc8609b_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_log_volume_map(root_log_dir, dockerrun_dict):\n    \"\"\"\n    Return host log path to container log path mapping if Logging is provided\n    in the dockerrun, and otherwise return empty dict.\n    :param root_log_dir: str: the root local logs directory\n    :param dockerrun_dict: dict: Dockerrun.aws.json as dict\n    :return: dict\n    \"\"\"\n    if not dockerrun_dict:\n        return {}\n    host_log = get_host_log_path(root_log_dir)\n    container_log = dockerrun.get_logdir(dockerrun_dict)\n"]]}
{"hexsha": "491cd31433245be5f70acf3ca25e1b46c94ffcc3", "ext": "py", "lang": "Python", "content": "def make_window(length):\n  # Based on https://github.com/WebKit/webkit/blob/89c28d471fae35f1788a0f857067896a10af8974/Source/WebCore/Modules/webaudio/RealtimeAnalyser.cpp\n  alpha = 0.16\n  a0 = 0.5 * (1.0 - alpha)\n  a1 = 0.5\n  a2 = 0.5 * alpha\n  ts = np.arange(0, length, 1.0).astype(np.float32) / length\n  return a0 - a1 * np.cos(2 * np.pi * ts) + a2 * np.cos(4 * np.pi * ts)", "fn_id": 0, "class_fn": false, "repo": "caisq/tfjs-dump", "file": "speech-command/spectrogram.py", "last_update_at": "2018-11-26T07:58:37+00:00", "question_id": "491cd31433245be5f70acf3ca25e1b46c94ffcc3_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def make_window(length):\n    alpha = 0.16\n    a0 = 0.5 * (1.0 - alpha)\n    a1 = 0.5\n    a2 = 0.5 * alpha\n    ts = np.arange(0, length, 1.0).astype(np.float32) / length\n"]]}
{"hexsha": "7d817f751ddab505219f00053d70e33baf50f601", "ext": "py", "lang": "Python", "content": "def test_error_raises_invalid_type(auth_client):\n    \"\"\"Test that an error is raised with inproper input type.\"\"\"\n    with pytest.raises(ValueError):\n        auth_client.create_transaction(model='invalid_transaction')", "fn_id": 0, "class_fn": false, "repo": "RJB888/Python_Final", "file": "tests/test_create_trans.py", "last_update_at": "2018-01-10T21:50:10+00:00", "question_id": "7d817f751ddab505219f00053d70e33baf50f601_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_error_raises_invalid_type(auth_client):\n    \"\"\"Test that an error is raised with inproper input type.\"\"\"\n    with pytest.raises(ValueError):\n"]]}
