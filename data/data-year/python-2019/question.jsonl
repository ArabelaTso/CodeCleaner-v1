{"hexsha": "b07a8734a34e89e577bd162d0ecf9d465ec717c3", "ext": "py", "lang": "Python", "content": "def load_model(model, filename, device):\n    try:\n        state = torch.load(filename, map_location=device)\n        model.load_state_dict(state['model'], strict=True)\n        print(f'Loaded model {filename}.')\n    except FileNotFoundError:\n        raise Exception(f'The model file {filename} was not found!')", "fn_id": 1, "class_fn": false, "repo": "expz/mt-fast-training", "file": "src/model.py", "last_update_at": "2019-07-03T00:28:40+00:00", "question_id": "b07a8734a34e89e577bd162d0ecf9d465ec717c3_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def load_model(model, filename, device):\n    try:\n        state = torch.load(filename, map_location=device)\n        model.load_state_dict(state['model'], strict=True)\n        print(f'Loaded model {filename}.')\n    except FileNotFoundError:\n"]]}
{"hexsha": "c7c6415b744176918ca31da98e09adaf690729fa", "ext": "py", "lang": "Python", "content": "@cli.command()\n@pass_ctx\ndef create(ctx):\n    \"\"\"Create a new CloudFormation stack.\"\"\"\n    validate_and_upload(ctx.region, ctx.config)\n    ctx.stack.create()", "fn_id": 3, "class_fn": false, "repo": "flou/brume", "file": "brume/cli.py", "last_update_at": "2019-04-17T12:59:32+00:00", "question_id": "c7c6415b744176918ca31da98e09adaf690729fa_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@cli.command()\n@pass_ctx\ndef create(ctx):\n    \"\"\"Create a new CloudFormation stack.\"\"\"\n    validate_and_upload(ctx.region, ctx.config)\n"]]}
{"hexsha": "fcac755a616fb4075c3ad8a8f9bde5fcebff6cb7", "ext": "py", "lang": "Python", "content": "def create(large_person_group_id, name=None, user_data=None):\n    \"\"\"Create a new large person group with specified `large_person_group_id`,\n    `name` and user-provided `user_data`.\n\n    Args:\n        large_person_group_id: User-provided `large_person_group_id` as a\n            string. The valid characters include numbers, English letters in\n            lower case, '-' and '_'.  The maximum length is 64.\n        name: Name of the created large person group, maximum length is 128.\n        user_data: Optional user defined data for the large person group.\n            Length should not exceed 16KB.\n\n    Returns:\n        An empty response body.\n    \"\"\"\n    name = name or large_person_group_id\n    url = 'largepersongroups/{}'.format(large_person_group_id)\n    json = {\n        'name': name,\n        'userData': user_data,\n    }\n\n    return util.request('PUT', url, json=json)", "fn_id": 0, "class_fn": false, "repo": "PacktPublishing/Smarter-Web-Apps-with-Azure-ML-and-Cognitive-Services", "file": "Cognitive-Code/Cognitive-Face-Python/cognitive_face/large_person_group.py", "last_update_at": "2019-10-30T13:31:12+00:00", "question_id": "fcac755a616fb4075c3ad8a8f9bde5fcebff6cb7_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def create(large_person_group_id, name=None, user_data=None):\n    \"\"\"Create a new large person group with specified `large_person_group_id`,\n    `name` and user-provided `user_data`.\n\n    Args:\n        large_person_group_id: User-provided `large_person_group_id` as a\n            string. The valid characters include numbers, English letters in\n            lower case, '-' and '_'.  The maximum length is 64.\n        name: Name of the created large person group, maximum length is 128.\n        user_data: Optional user defined data for the large person group.\n            Length should not exceed 16KB.\n\n    Returns:\n        An empty response body.\n    \"\"\"\n    name = name or large_person_group_id\n    url = 'largepersongroups/{}'.format(large_person_group_id)\n    json = {'name': name, 'userData': user_data}\n"]]}
{"hexsha": "0d3fbd1633338c602c4cddbabb702cde97e629d9", "ext": "py", "lang": "Python", "content": "def main(argv):\n    # dataset load\n    data, MAX_LENGTH, MAX_ARGS, VOCAB_SIZE, vocab = load_all_datasets()\n\n    # parameter setup\n    MAX_LENGTH += 2\n    BATCH_SIZE = 50\n    VALUE_SIZE = 150\n    MIN_RETURN_WIDTH = VALUE_SIZE\n    STACK_SIZE = 5\n\n    d4_params = d4InitParams(stack_size=STACK_SIZE,\n                             value_size=VALUE_SIZE,\n                             batch_size=BATCH_SIZE,\n                             min_return_width=MIN_RETURN_WIDTH)\n\n    data_params = DataParams(vocab_size=VOCAB_SIZE,\n                             max_length=MAX_LENGTH,\n                             max_args=MAX_ARGS)\n\n    train_params = TrainParams(train=True,\n                               learning_rate=0.02,\n                               num_steps_train=7,\n                               num_steps_test=7)\n\n    def load_sketch_from_file(filename):\n        with open(filename, \"r\") as f:\n            scaffold = f.read()\n        return scaffold\n\n    # building batcher\n    batcher_train = ArithmeticDatasetBatcher(data.train, BATCH_SIZE)\n\n    # build the model\n    sketch = load_sketch_from_file(\"./experiments/wap/sketch_wap.d4\")\n    # print(sketch)\n    model = AlgebraD4Model(sketch, d4_params, data_params, train_params)\n    model.build_graph()\n\n    directory_save = \"./tmp/wap/checkpoints/\"\n    import os\n    if not os.path.exists(directory_save):\n        os.makedirs(directory_save)\n\n    epoch_count = tf.Variable(0, name=\"epoch\", trainable=False)\n    max_accuracy = float('-inf')\n\n    with tf.Session() as sess:\n\n        # if True:\n        #     model.load_model(sess, directory_save)\n        #     print('loaded model')\n        #     accuracy = model.run_eval_step(sess, data.dev, debug=False)\n        #     print(accuracy)\n        #     # accuracy, partial_accuracy = model.run_eval_step(sess, dataset_dev)\n        #     exit(0)\n\n        summary_writer = tf.train.SummaryWriter(\"./tmp/summaries/wap\", tf.get_default_graph())\n        sess.run(tf.initialize_all_variables())\n\n        for epoch in range(50):\n            epoch_count.assign_add(1)\n            print('epoch', epoch)\n\n            # TRAIN\n            total_loss = 0.0\n            for batch_no in range(batcher_train.batch_number):\n                batch = batcher_train.next_batch()\n                _, summaries, loss, global_step = model.run_train_step(sess, batch)\n                # print('    Loss per batch: ', loss / BATCH_SIZE)\n                total_loss += loss\n                summary_writer.add_summary(summaries, global_step)\n\n            total_loss /= (batcher_train.batch_number * BATCH_SIZE)\n            print('  loss per epoch: ', total_loss)\n\n            # logging summaries\n            summary_loss = tf.Summary(\n                value=[tf.Summary.Value(tag=\"loss_per_epoch\", simple_value=total_loss)]\n            )\n            summary_writer.add_summary(summary_loss, epoch)\n            summary_writer.flush()\n\n            # if epoch % 10 == 0:\n            #     model.run_test_step(sess, batch)\n\n            print(\"  train set eval...\")\n            if epoch % 1 == 0:\n                model.run_eval_step(sess, data.train, debug=False)\n\n            print(\"  dev set eval...\")\n            if epoch % 1 == 0:\n                accuracy = model.run_eval_step(sess, data.dev)\n                if accuracy > max_accuracy and accuracy > 0.94:\n                    max_accuracy = accuracy\n                    print('Saving model...')\n\n                    model.save_model(sess, directory_save + \"model.checkpoint\",\n                                     global_step=global_step)\n                    print('Model saved...')", "fn_id": 0, "class_fn": false, "repo": "namin/d4", "file": "experiments/wap/trainer.py", "last_update_at": "2019-08-14T14:08:44+00:00", "question_id": "0d3fbd1633338c602c4cddbabb702cde97e629d9_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main(argv):\n    data, MAX_LENGTH, MAX_ARGS, VOCAB_SIZE, vocab = load_all_datasets()\n    MAX_LENGTH += 2\n    BATCH_SIZE = 50\n    VALUE_SIZE = 150\n    MIN_RETURN_WIDTH = VALUE_SIZE\n    STACK_SIZE = 5\n    d4_params = d4InitParams(stack_size=STACK_SIZE, value_size=VALUE_SIZE, batch_size=BATCH_SIZE, min_return_width=MIN_RETURN_WIDTH)\n    data_params = DataParams(vocab_size=VOCAB_SIZE, max_length=MAX_LENGTH, max_args=MAX_ARGS)\n    train_params = TrainParams(train=True, learning_rate=0.02, num_steps_train=7, num_steps_test=7)\n\n    def load_sketch_from_file(filename):\n        with open(filename, 'r') as f:\n            scaffold = f.read()\n        return scaffold\n    batcher_train = ArithmeticDatasetBatcher(data.train, BATCH_SIZE)\n    sketch = load_sketch_from_file('./experiments/wap/sketch_wap.d4')\n    model = AlgebraD4Model(sketch, d4_params, data_params, train_params)\n    model.build_graph()\n    directory_save = './tmp/wap/checkpoints/'\n    import os\n    if not os.path.exists(directory_save):\n        os.makedirs(directory_save)\n    epoch_count = tf.Variable(0, name='epoch', trainable=False)\n    max_accuracy = float('-inf')\n    with tf.Session() as sess:\n        summary_writer = tf.train.SummaryWriter('./tmp/summaries/wap', tf.get_default_graph())\n        sess.run(tf.initialize_all_variables())\n        for epoch in range(50):\n            epoch_count.assign_add(1)\n            print('epoch', epoch)\n            total_loss = 0.0\n            for batch_no in range(batcher_train.batch_number):\n                batch = batcher_train.next_batch()\n                _, summaries, loss, global_step = model.run_train_step(sess, batch)\n                total_loss += loss\n                summary_writer.add_summary(summaries, global_step)\n            total_loss /= batcher_train.batch_number * BATCH_SIZE\n            print('  loss per epoch: ', total_loss)\n            summary_loss = tf.Summary(value=[tf.Summary.Value(tag='loss_per_epoch', simple_value=total_loss)])\n            summary_writer.add_summary(summary_loss, epoch)\n            summary_writer.flush()\n            print('  train set eval...')\n            if epoch % 1 == 0:\n                model.run_eval_step(sess, data.train, debug=False)\n            print('  dev set eval...')\n            if epoch % 1 == 0:\n                accuracy = model.run_eval_step(sess, data.dev)\n                if accuracy > max_accuracy and accuracy > 0.94:\n                    max_accuracy = accuracy\n                    print('Saving model...')\n                    model.save_model(sess, directory_save + 'model.checkpoint', global_step=global_step)\n"]]}
{"hexsha": "bb965a997cb0f8f4f1428568aaef9bf6f7320e63", "ext": "py", "lang": "Python", "content": "def train(args, trainer, task, epoch_itr):\n    \"\"\"Train the model for one epoch.\"\"\"\n\n    # Initialize data iterator\n    itr = epoch_itr.next_epoch_itr()\n    progress = progress_bar.build_progress_bar(args, itr, epoch_itr.epoch, no_progress_bar='simple')\n\n    # update parameters every N batches\n    if epoch_itr.epoch <= len(args.update_freq):\n        update_freq = args.update_freq[epoch_itr.epoch - 1]\n    else:\n        update_freq = args.update_freq[-1]\n\n    if args.enable_parallel_backward_allred_opt and update_freq > 1:\n        raise RuntimeError('--enable-parallel-backward-allred-opt is incompatible with --update-freq > 1')\n\n    extra_meters = collections.defaultdict(lambda: AverageMeter())\n    first_valid = args.valid_subset.split(',')[0]\n    max_update = args.max_update or math.inf\n    num_batches = len(epoch_itr)\n    #begin = time.time()\n    #inside = 0\n    for i, sample in enumerate(progress, start=epoch_itr.iterations_in_epoch):\n        #newbegin = time.time()\n        #print(\"iter time\", newbegin - begin, inside, (newbegin - begin - inside)*1000)\n        #begin = newbegin\n        if i < num_batches - 1 and (i + 1) % update_freq > 0:\n            # buffer updates according to --update-freq\n            trainer.train_step(sample, update_params=False, last_step=(i == len(itr)-1))\n            continue\n        else:\n            log_output = trainer.train_step(sample, update_params=True, last_step=(i == len(itr)-1))\n\n        # log mid-epoch stats\n        stats = get_training_stats(trainer)\n        for k, v in log_output.items():\n            if k in ['loss', 'nll_loss', 'sample_size']:\n                continue  # these are already logged above\n            if 'loss' in k:\n                extra_meters[k].update(v, log_output['sample_size'])\n            else:\n                extra_meters[k].update(v)\n            stats[k] = extra_meters[k].avg\n        progress.log(stats)\n\n        # ignore the first mini-batch in words-per-second calculation\n        if i == 0:\n            trainer.get_meter('wps').reset()\n\n        if args.profile is not None and i == args.profile:\n            import sys\n            sys.exit()\n\n        num_updates = trainer.get_num_updates()\n        if args.save_interval_updates > 0 and num_updates % args.save_interval_updates == 0:\n            valid_losses = validate(args, trainer, task, epoch_itr, [first_valid])\n            save_checkpoint(args, trainer, epoch_itr, valid_losses[0])\n\n        if num_updates >= max_update:\n            break\n        #end = time.time()\n        #inside = end - begin\n\n    # log end-of-epoch stats\n    stats = get_training_stats(trainer)\n    for k, meter in extra_meters.items():\n        stats[k] = meter.avg\n    progress.print(stats)\n\n    # reset training meters\n    for k in ['train_loss', 'train_nll_loss', 'wps', 'ups', 'wpb', 'bsz', 'clip']:\n        meter = trainer.get_meter(k)\n        if meter is not None:\n            meter.reset()", "fn_id": 1, "class_fn": false, "repo": "myelintek/results", "file": "v0.5.0/nvidia/submission/code/translation/pytorch/train.py", "last_update_at": "2019-07-06T12:48:18+00:00", "question_id": "bb965a997cb0f8f4f1428568aaef9bf6f7320e63_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def train(args, trainer, task, epoch_itr):\n    \"\"\"Train the model for one epoch.\"\"\"\n    itr = epoch_itr.next_epoch_itr()\n    progress = progress_bar.build_progress_bar(args, itr, epoch_itr.epoch, no_progress_bar='simple')\n    if epoch_itr.epoch <= len(args.update_freq):\n        update_freq = args.update_freq[epoch_itr.epoch - 1]\n    else:\n        update_freq = args.update_freq[-1]\n    if args.enable_parallel_backward_allred_opt and update_freq > 1:\n        raise RuntimeError('--enable-parallel-backward-allred-opt is incompatible with --update-freq > 1')\n    extra_meters = collections.defaultdict(lambda: AverageMeter())\n    first_valid = args.valid_subset.split(',')[0]\n    max_update = args.max_update or math.inf\n    num_batches = len(epoch_itr)\n    for i, sample in enumerate(progress, start=epoch_itr.iterations_in_epoch):\n        if i < num_batches - 1 and (i + 1) % update_freq > 0:\n            trainer.train_step(sample, update_params=False, last_step=i == len(itr) - 1)\n            continue\n        else:\n            log_output = trainer.train_step(sample, update_params=True, last_step=i == len(itr) - 1)\n        stats = get_training_stats(trainer)\n        for k, v in log_output.items():\n            if k in ['loss', 'nll_loss', 'sample_size']:\n                continue\n            if 'loss' in k:\n                extra_meters[k].update(v, log_output['sample_size'])\n            else:\n                extra_meters[k].update(v)\n            stats[k] = extra_meters[k].avg\n        progress.log(stats)\n        if i == 0:\n            trainer.get_meter('wps').reset()\n        if args.profile is not None and i == args.profile:\n            import sys\n            sys.exit()\n        num_updates = trainer.get_num_updates()\n        if args.save_interval_updates > 0 and num_updates % args.save_interval_updates == 0:\n            valid_losses = validate(args, trainer, task, epoch_itr, [first_valid])\n            save_checkpoint(args, trainer, epoch_itr, valid_losses[0])\n        if num_updates >= max_update:\n            break\n    stats = get_training_stats(trainer)\n    for k, meter in extra_meters.items():\n        stats[k] = meter.avg\n    progress.print(stats)\n    for k in ['train_loss', 'train_nll_loss', 'wps', 'ups', 'wpb', 'bsz', 'clip']:\n        meter = trainer.get_meter(k)\n        if meter is not None:\n"]]}
{"hexsha": "4e7a6e833f6d3fd7a0daae31da01afe7204c5fbd", "ext": "py", "lang": "Python", "content": "def read_seqs(infile, filter_list=None):\n    \"\"\"\n    Reads up sequences from a path to a fasta file\n    :param infile: path to fasta file\n    :param filter_list: Strings that should be in the description of the sequences\n    :return: a list of strings\n    \"\"\"\n    r = []\n    f = open_possible_gzip(infile)\n    for seq in SeqIO.parse(f, \"fasta\"):\n        if filter_list is not None:\n            assert isinstance(filter_list, list)\n            if any([x in seq.description for x in filter_list]):\n                r.append(seq)\n        else:\n            r.append(seq)\n    f.close()\n    return r", "fn_id": 0, "class_fn": false, "repo": "bfssi-forest-dussault/centreseq", "file": "centreseq/bin/core/pick_best_nucleotide.py", "last_update_at": "2019-07-20T02:00:33+00:00", "question_id": "4e7a6e833f6d3fd7a0daae31da01afe7204c5fbd_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def read_seqs(infile, filter_list=None):\n    \"\"\"\n    Reads up sequences from a path to a fasta file\n    :param infile: path to fasta file\n    :param filter_list: Strings that should be in the description of the sequences\n    :return: a list of strings\n    \"\"\"\n    r = []\n    f = open_possible_gzip(infile)\n    for seq in SeqIO.parse(f, 'fasta'):\n        if filter_list is not None:\n            assert isinstance(filter_list, list)\n            if any([x in seq.description for x in filter_list]):\n                r.append(seq)\n        else:\n            r.append(seq)\n    f.close()\n"]]}
{"hexsha": "21b63c6f23f455912da461c7bb010989f8ececaa", "ext": "py", "lang": "Python", "content": "def _pack_kvec(L, n):\n    \"\"\"\n    Utility function to find \n      k:= 2 pi / L * (u, v, w)\n    for the sequence of u,v,w \n       (0,0,0), (1,0,0), (1,1,0), (1,1,1), (2,0,0), (2,1,0), (2,1,1),... (M-1,M-1,M-1)\n    where M := 1 + n//2\n\n    i.e. u >= v >= w >= 0 and the last index is rolling fastest.\n\n    L - size of the box\n    n - Size for (n,n,n) grid this is equivalent to (i.e. your fft-size)\n\n    retiurns 2d array of (M(M+1)(M+2)/6, 3) k-vectors\n    \"\"\"\n    mid = 1+n//2 # indices [0,1,..., m-1]\n    \n    vals = empty(((mid*(mid+1)*(mid+2))//6, 3), dtype=int32)\n    idx = 0\n    kw = arange(mid)\n    for i in range(mid):\n        ni = ((i+1)*(i+2))//2\n        vals[idx:idx+ni,0] = i\n        for j in range(i+1):\n            nk = j+1\n            vals[idx:idx+nk,1] = j\n            vals[idx:idx+nk,2] = kw[:nk]\n            idx += nk\n\n    assert(idx==len(vals))\n    return (2*pi/L) * vals", "fn_id": 4, "class_fn": false, "repo": "pec27/lizard", "file": "lizard/grid.py", "last_update_at": "2019-07-09T13:21:47+00:00", "question_id": "21b63c6f23f455912da461c7bb010989f8ececaa_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _pack_kvec(L, n):\n    \"\"\"\n    Utility function to find \n      k:= 2 pi / L * (u, v, w)\n    for the sequence of u,v,w \n       (0,0,0), (1,0,0), (1,1,0), (1,1,1), (2,0,0), (2,1,0), (2,1,1),... (M-1,M-1,M-1)\n    where M := 1 + n//2\n\n    i.e. u >= v >= w >= 0 and the last index is rolling fastest.\n\n    L - size of the box\n    n - Size for (n,n,n) grid this is equivalent to (i.e. your fft-size)\n\n    retiurns 2d array of (M(M+1)(M+2)/6, 3) k-vectors\n    \"\"\"\n    mid = 1 + n // 2\n    vals = empty((mid * (mid + 1) * (mid + 2) // 6, 3), dtype=int32)\n    idx = 0\n    kw = arange(mid)\n    for i in range(mid):\n        ni = (i + 1) * (i + 2) // 2\n        vals[idx:idx + ni, 0] = i\n        for j in range(i + 1):\n            nk = j + 1\n            vals[idx:idx + nk, 1] = j\n            vals[idx:idx + nk, 2] = kw[:nk]\n            idx += nk\n    assert idx == len(vals)\n"]]}
{"hexsha": "90f9c7caff3318b20c39749b582ca7eda1c342d1", "ext": "py", "lang": "Python", "content": "def filter_tx_log10(file, library):\n\tread = pd.read_csv(file,index_col=\"Barcode\")\n\ttx_log10 = read[read.columns[-1]]\n\tfilter_key = tx_log10.loc[library.index] #filtering library barcodes\t\n\treturn filter_key", "fn_id": 1, "class_fn": false, "repo": "ssyim/TXTL_ReadAnalysis", "file": "code/03_DRAFTS_compute_tx.py", "last_update_at": "2019-09-18T13:28:29+00:00", "question_id": "90f9c7caff3318b20c39749b582ca7eda1c342d1_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def filter_tx_log10(file, library):\n    read = pd.read_csv(file, index_col='Barcode')\n    tx_log10 = read[read.columns[-1]]\n    filter_key = tx_log10.loc[library.index]\n"]]}
{"hexsha": "b3cb7e3ca4f5f8d769af64c0d9923591f0049ff5", "ext": "py", "lang": "Python", "content": "@_register(\"bool\")\ndef string_boolean(value):\n    \"\"\"Determines the boolean value for a specified string\"\"\"\n    if value.lower() in (\"false\", \"f\", \"0\", \"\"):\n        return False\n    else:\n        return True", "fn_id": 1, "class_fn": false, "repo": "jcrowgey/koalified_python", "file": "koalified/types.py", "last_update_at": "2019-02-12T01:33:26+00:00", "question_id": "b3cb7e3ca4f5f8d769af64c0d9923591f0049ff5_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@_register('bool')\ndef string_boolean(value):\n    \"\"\"Determines the boolean value for a specified string\"\"\"\n    if value.lower() in ('false', 'f', '0', ''):\n        return False\n    else:\n"]]}
{"hexsha": "53e74672e205e38a5a0582d1841b67f14497dd48", "ext": "py", "lang": "Python", "content": "def should_validate_while_training(iteration, val_every, val_after, resume, start_iteration):\n    if val_every is None:\n        return False\n    return (iteration % val_every == 0 and iteration >= val_after) or (resume and iteration == start_iteration)", "fn_id": 4, "class_fn": false, "repo": "stanford-oval/decaNLP", "file": "genienlp/train.py", "last_update_at": "2019-11-30T04:16:47+00:00", "question_id": "53e74672e205e38a5a0582d1841b67f14497dd48_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def should_validate_while_training(iteration, val_every, val_after, resume, start_iteration):\n    if val_every is None:\n        return False\n"]]}
{"hexsha": "ec5796792eda1d6437f4f053abebce1203f89657", "ext": "py", "lang": "Python", "content": "def test_ct():\n    N_TURBINES = 4\n\n    turbine_data = SampleInputs().turbine\n    turbine = Turbine.from_dict(turbine_data)\n    turbine_type_map = np.array(N_TURBINES * [turbine.turbine_type])\n    turbine_type_map = turbine_type_map[None, None, :]\n\n    # Single turbine\n    # yaw angle / fCt are (n wind direction, n wind speed, n turbine)\n    wind_speed = 10.0\n    thrust = Ct(\n        velocities=wind_speed * np.ones((1, 1, 1, 3, 3)),\n        yaw_angle=np.zeros((1, 1, 1)),\n        fCt=np.array([(turbine.turbine_type, turbine.fCt_interp)]),\n        turbine_type_map=turbine_type_map[:,:,0]\n    )\n\n    truth_index = turbine_data[\"power_thrust_table\"][\"wind_speed\"].index(wind_speed)\n    np.testing.assert_allclose(thrust, turbine_data[\"power_thrust_table\"][\"thrust\"][truth_index])\n\n    # Multiple turbines with index filter\n    # 4 turbines with 3 x 3 grid arrays\n    thrusts = Ct(\n        velocities=np.ones((N_TURBINES, 3, 3)) * WIND_CONDITION_BROADCAST,  # 3 x 4 x 4 x 3 x 3\n        yaw_angle=np.zeros((1, 1, N_TURBINES)),\n        fCt=np.array([(turbine.turbine_type, turbine.fCt_interp)]),\n        turbine_type_map=turbine_type_map,\n        ix_filter=INDEX_FILTER,\n    )\n    assert len(thrusts[0, 0]) == len(INDEX_FILTER)\n\n    for i in range(len(INDEX_FILTER)):\n        truth_index = turbine_data[\"power_thrust_table\"][\"wind_speed\"].index(WIND_SPEEDS[0])\n        np.testing.assert_allclose(thrusts[0, 0, i], turbine_data[\"power_thrust_table\"][\"thrust\"][truth_index])", "fn_id": 6, "class_fn": false, "repo": "ElieKadoche/floris", "file": "tests/turbine_unit_test.py", "last_update_at": "2019-03-02T04:59:54+00:00", "question_id": "ec5796792eda1d6437f4f053abebce1203f89657_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_ct():\n    N_TURBINES = 4\n    turbine_data = SampleInputs().turbine\n    turbine = Turbine.from_dict(turbine_data)\n    turbine_type_map = np.array(N_TURBINES * [turbine.turbine_type])\n    turbine_type_map = turbine_type_map[None, None, :]\n    wind_speed = 10.0\n    thrust = Ct(velocities=wind_speed * np.ones((1, 1, 1, 3, 3)), yaw_angle=np.zeros((1, 1, 1)), fCt=np.array([(turbine.turbine_type, turbine.fCt_interp)]), turbine_type_map=turbine_type_map[:, :, 0])\n    truth_index = turbine_data['power_thrust_table']['wind_speed'].index(wind_speed)\n    np.testing.assert_allclose(thrust, turbine_data['power_thrust_table']['thrust'][truth_index])\n    thrusts = Ct(velocities=np.ones((N_TURBINES, 3, 3)) * WIND_CONDITION_BROADCAST, yaw_angle=np.zeros((1, 1, N_TURBINES)), fCt=np.array([(turbine.turbine_type, turbine.fCt_interp)]), turbine_type_map=turbine_type_map, ix_filter=INDEX_FILTER)\n    assert len(thrusts[0, 0]) == len(INDEX_FILTER)\n    for i in range(len(INDEX_FILTER)):\n        truth_index = turbine_data['power_thrust_table']['wind_speed'].index(WIND_SPEEDS[0])\n"]]}
{"hexsha": "f6894fc552c5927f9a2d0715eec985f4c410a9fc", "ext": "py", "lang": "Python", "content": "def test_getgenre_stations_cache_disabled(\n    config, get_genre_stations_return_value_mock\n):\n    with mock.patch.object(\n        APIClient,\n        \"get_genre_stations\",\n        return_value=get_genre_stations_return_value_mock,\n    ):\n        cache_config = config\n        cache_config[\"pandora\"][\"cache_time_to_live\"] = 0\n        backend = conftest.get_backend(cache_config)\n\n        assert backend.api.genre_stations_cache.currsize == 0\n\n        assert len(backend.api.get_genre_stations()) == 1\n        assert backend.api.genre_stations_cache.currsize == 0", "fn_id": 4, "class_fn": false, "repo": "ron4mac/mopidy-pandora", "file": "tests/test_client.py", "last_update_at": "2019-07-15T21:46:33+00:00", "question_id": "f6894fc552c5927f9a2d0715eec985f4c410a9fc_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_getgenre_stations_cache_disabled(config, get_genre_stations_return_value_mock):\n    with mock.patch.object(APIClient, 'get_genre_stations', return_value=get_genre_stations_return_value_mock):\n        cache_config = config\n        cache_config['pandora']['cache_time_to_live'] = 0\n        backend = conftest.get_backend(cache_config)\n        assert backend.api.genre_stations_cache.currsize == 0\n        assert len(backend.api.get_genre_stations()) == 1\n"]]}
{"hexsha": "fb4dcbf1b279172ef53eeea7e1fb7934f906f01a", "ext": "py", "lang": "Python", "content": "def upgrade():\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.create_table('publisher',\n    sa.Column('created_at', sa.DateTime(), nullable=False),\n    sa.Column('modified_at', sa.DateTime(), nullable=False),\n    sa.Column('id', sa.String(length=255), nullable=False),\n    sa.Column('name', sa.Text(), nullable=False),\n    sa.Column('total_datasets', sa.Integer(), nullable=False),\n    sa.Column('first_published_on', sa.Date(), nullable=True),\n    sa.Column('last_checked_at', sa.DateTime(), nullable=True),\n    sa.Column('queued_at', sa.DateTime(), nullable=True),\n    sa.PrimaryKeyConstraint('id')\n    )\n    op.create_table('contact',\n    sa.Column('created_at', sa.DateTime(), nullable=False),\n    sa.Column('modified_at', sa.DateTime(), nullable=False),\n    sa.Column('id', sa.Integer(), nullable=False),\n    sa.Column('name', sa.Text(), nullable=False),\n    sa.Column('email', sa.Text(), nullable=False),\n    sa.Column('publisher_id', sa.String(length=255), nullable=False),\n    sa.Column('active', sa.Boolean(), nullable=False),\n    sa.Column('confirmed_at', sa.DateTime(), nullable=True),\n    sa.Column('last_messaged_at', sa.DateTime(), nullable=True),\n    sa.ForeignKeyConstraint(['publisher_id'], ['publisher.id'], ondelete='CASCADE'),\n    sa.PrimaryKeyConstraint('id'),\n    sa.UniqueConstraint('email', 'publisher_id')\n    )\n    op.create_table('dataseterror',\n    sa.Column('created_at', sa.DateTime(), nullable=False),\n    sa.Column('modified_at', sa.DateTime(), nullable=False),\n    sa.Column('id', sa.Integer(), nullable=False),\n    sa.Column('dataset_id', sa.String(length=255), nullable=False),\n    sa.Column('dataset_name', sa.Text(), nullable=False),\n    sa.Column('dataset_url', sa.String(length=255), nullable=False),\n    sa.Column('publisher_id', sa.String(length=255), nullable=False),\n    sa.Column('error_type', sa.String(length=20), nullable=True),\n    sa.Column('last_status', sa.String(length=20), nullable=False),\n    sa.Column('error_count', sa.Integer(), nullable=False),\n    sa.Column('check_count', sa.Integer(), nullable=False),\n    sa.Column('last_errored_at', sa.DateTime(), nullable=False),\n    sa.ForeignKeyConstraint(['publisher_id'], ['publisher.id'], ondelete='CASCADE'),\n    sa.PrimaryKeyConstraint('id'),\n    sa.UniqueConstraint('dataset_id')\n    )", "fn_id": 0, "class_fn": false, "repo": "andylolz/iati-canary", "file": "migrations/versions/3efb48a5ca66_.py", "last_update_at": "2019-08-29T13:15:17+00:00", "question_id": "fb4dcbf1b279172ef53eeea7e1fb7934f906f01a_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def upgrade():\n    op.create_table('publisher', sa.Column('created_at', sa.DateTime(), nullable=False), sa.Column('modified_at', sa.DateTime(), nullable=False), sa.Column('id', sa.String(length=255), nullable=False), sa.Column('name', sa.Text(), nullable=False), sa.Column('total_datasets', sa.Integer(), nullable=False), sa.Column('first_published_on', sa.Date(), nullable=True), sa.Column('last_checked_at', sa.DateTime(), nullable=True), sa.Column('queued_at', sa.DateTime(), nullable=True), sa.PrimaryKeyConstraint('id'))\n    op.create_table('contact', sa.Column('created_at', sa.DateTime(), nullable=False), sa.Column('modified_at', sa.DateTime(), nullable=False), sa.Column('id', sa.Integer(), nullable=False), sa.Column('name', sa.Text(), nullable=False), sa.Column('email', sa.Text(), nullable=False), sa.Column('publisher_id', sa.String(length=255), nullable=False), sa.Column('active', sa.Boolean(), nullable=False), sa.Column('confirmed_at', sa.DateTime(), nullable=True), sa.Column('last_messaged_at', sa.DateTime(), nullable=True), sa.ForeignKeyConstraint(['publisher_id'], ['publisher.id'], ondelete='CASCADE'), sa.PrimaryKeyConstraint('id'), sa.UniqueConstraint('email', 'publisher_id'))\n"]]}
{"hexsha": "bd3afe39a69fd4c12579800c0a62417708b1e78e", "ext": "py", "lang": "Python", "content": "def learn_embeddings(walks):\n    '''\n    Learn embeddings by optimizing the Skipgram objective using SGD.\n    '''\n    walks = [list(map(str, walk)) for walk in walks]\n    model = Word2Vec(walks, size=args.dimensions, window=args.window_size, min_count=0, sg=1, workers=args.workers,\n                     iter=args.iter)\n    model.wv.save_word2vec_format(args.output)\n\n    return", "fn_id": 2, "class_fn": false, "repo": "godkillok/node2vec", "file": "src/main.py", "last_update_at": "2019-12-09T09:14:11+00:00", "question_id": "bd3afe39a69fd4c12579800c0a62417708b1e78e_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def learn_embeddings(walks):\n    \"\"\"\n    Learn embeddings by optimizing the Skipgram objective using SGD.\n    \"\"\"\n    walks = [list(map(str, walk)) for walk in walks]\n    model = Word2Vec(walks, size=args.dimensions, window=args.window_size, min_count=0, sg=1, workers=args.workers, iter=args.iter)\n    model.wv.save_word2vec_format(args.output)\n"]]}
{"hexsha": "539d4089c3e564ccea592e9dbf344f4b3f55b04e", "ext": "py", "lang": "Python", "content": "def test_runner(region, q, key_name, extra_args):\n    global success\n    global failure\n    global results_lock\n\n    while True:\n        item = q.get()\n\n        retval = 1\n        # just in case we miss an exception in run_test, don't abort everything...\n        try:\n            if not prochelp.termination_caught():\n                run_test(\n                    region=region,\n                    distro=item[\"distro\"],\n                    scheduler=item[\"scheduler\"],\n                    instance_type=item[\"instance_type\"],\n                    key_name=key_name,\n                    expected_asg_capacity=item[\"expected_asg_capacity\"],\n                    expected_compute_nodes=item[\"expected_compute_nodes\"],\n                    extra_args=extra_args,\n                )\n                retval = 0\n        except (ReleaseCheckException, prochelp.ProcessHelperError, sub.CalledProcessError):\n            pass\n        except Exception as exc:\n            print(\"[test_runner] Unexpected exception %s: %s\\n\" % (str(type(exc)), str(exc)))\n\n        results_lock.acquire(True)\n        if retval == 0:\n            success += 1\n        else:\n            failure += 1\n        results_lock.release()\n        q.task_done()", "fn_id": 10, "class_fn": false, "repo": "DalavanCloud/aws-parallelcluster", "file": "tests/parallelcluster-release-check.py", "last_update_at": "2019-02-25T22:37:07+00:00", "question_id": "539d4089c3e564ccea592e9dbf344f4b3f55b04e_10", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_runner(region, q, key_name, extra_args):\n    global success\n    global failure\n    global results_lock\n    while True:\n        item = q.get()\n        retval = 1\n        try:\n            if not prochelp.termination_caught():\n                run_test(region=region, distro=item['distro'], scheduler=item['scheduler'], instance_type=item['instance_type'], key_name=key_name, expected_asg_capacity=item['expected_asg_capacity'], expected_compute_nodes=item['expected_compute_nodes'], extra_args=extra_args)\n                retval = 0\n        except (ReleaseCheckException, prochelp.ProcessHelperError, sub.CalledProcessError):\n            pass\n        except Exception as exc:\n            print('[test_runner] Unexpected exception %s: %s\\n' % (str(type(exc)), str(exc)))\n        results_lock.acquire(True)\n        if retval == 0:\n            success += 1\n        else:\n            failure += 1\n        results_lock.release()\n"]]}
{"hexsha": "709597dd0405ea27b693a5c8be92d4a3cb761c36", "ext": "py", "lang": "Python", "content": "def test_adder_gain_bias():\n    unit_step = basic_signals.UnitStep()\n    upsampled_unit_step = building_blocks.SplitSignal(4, unit_step)\n    source1 = building_blocks.Adder(upsampled_unit_step, upsampled_unit_step)\n    source2 = building_blocks.Gain(2., upsampled_unit_step)\n    source3 = building_blocks.Bias(1., upsampled_unit_step)\n\n    for _ in range(test_basic_signals.MAX_TEARDOWNS):\n        for _ in range(test_basic_signals.MAX_STEPS):\n            assert all_equal(\n                source1.next_value(),\n                source2.next_value(),\n                source3.next_value())\n        source1.rewind()\n        source2.rewind()\n        source3.rewind()", "fn_id": 2, "class_fn": false, "repo": "jamlamberti/dsp-tools", "file": "tests/core_tests/test_building_blocks.py", "last_update_at": "2019-10-30T00:27:45+00:00", "question_id": "709597dd0405ea27b693a5c8be92d4a3cb761c36_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_adder_gain_bias():\n    unit_step = basic_signals.UnitStep()\n    upsampled_unit_step = building_blocks.SplitSignal(4, unit_step)\n    source1 = building_blocks.Adder(upsampled_unit_step, upsampled_unit_step)\n    source2 = building_blocks.Gain(2.0, upsampled_unit_step)\n    source3 = building_blocks.Bias(1.0, upsampled_unit_step)\n    for _ in range(test_basic_signals.MAX_TEARDOWNS):\n        for _ in range(test_basic_signals.MAX_STEPS):\n            assert all_equal(source1.next_value(), source2.next_value(), source3.next_value())\n        source1.rewind()\n        source2.rewind()\n"]]}
{"hexsha": "1d89b6df211725a48f7b96e7298f589dcff16ee0", "ext": "py", "lang": "Python", "content": "def test_hyperparameters():\n    hp = hp_module.HyperParameters()\n    assert hp.values == {}\n    assert hp.space == []\n    hp.Choice('choice', [1, 2, 3], default=2)\n    assert hp.values == {'choice': 2}\n    assert len(hp.space) == 1\n    assert hp.space[0].name == 'choice'\n    hp.values['choice'] = 3\n    assert hp.get('choice') == 3\n    hp = hp.copy()\n    assert hp.values == {'choice': 3}\n    assert len(hp.space) == 1\n    assert hp.space[0].name == 'choice'\n    with pytest.raises(ValueError, match='Unknown parameter'):\n        hp.get('wrong')", "fn_id": 1, "class_fn": false, "repo": "krantirk/keras-tuner", "file": "tests/kerastuner/engine/hyperparameters_test.py", "last_update_at": "2019-07-12T17:17:06+00:00", "question_id": "1d89b6df211725a48f7b96e7298f589dcff16ee0_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_hyperparameters():\n    hp = hp_module.HyperParameters()\n    assert hp.values == {}\n    assert hp.space == []\n    hp.Choice('choice', [1, 2, 3], default=2)\n    assert hp.values == {'choice': 2}\n    assert len(hp.space) == 1\n    assert hp.space[0].name == 'choice'\n    hp.values['choice'] = 3\n    assert hp.get('choice') == 3\n    hp = hp.copy()\n    assert hp.values == {'choice': 3}\n    assert len(hp.space) == 1\n    assert hp.space[0].name == 'choice'\n    with pytest.raises(ValueError, match='Unknown parameter'):\n"]]}
{"hexsha": "fa13b418dadba5b166b403a1291e9a20622ff124", "ext": "py", "lang": "Python", "content": "def delete_id(impact_id, flash_msg=True):\n\timpact = Impact.query.filter_by(id=impact_id).limit(1).first()\n\n\tif impact:\n\t\tdbo.session.delete(impact)\n\t\tdbo.session.commit()\n\n\t\tif flash_msg:\n\t\t\tflash(\"Deleted Impact {}\".format(impact.name), category='success')", "fn_id": 0, "class_fn": false, "repo": "mrcrilly/vs-vlan-db", "file": "vsvlandb/impacts.py", "last_update_at": "2019-11-24T13:02:05+00:00", "question_id": "fa13b418dadba5b166b403a1291e9a20622ff124_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def delete_id(impact_id, flash_msg=True):\n    impact = Impact.query.filter_by(id=impact_id).limit(1).first()\n    if impact:\n        dbo.session.delete(impact)\n        dbo.session.commit()\n        if flash_msg:\n"]]}
{"hexsha": "79f30e89a28b9ecbbafd616848542eeb26655202", "ext": "py", "lang": "Python", "content": "def solution():\n    n = 4\n    edges = [[0,1,1],[0,2,5],[1,2,1],[2,3,1]]\n    src = 0\n    dst = 3\n    k = 1\n    problem = Problem()\n    return problem.find_cheapest_price(n, edges, src, dst, k)", "fn_id": 0, "class_fn": false, "repo": "yskang/AlgorithmPracticeWithPython", "file": "leetCode/cheapest_flights_within_k_stops.py", "last_update_at": "2019-11-04T06:46:55+00:00", "question_id": "79f30e89a28b9ecbbafd616848542eeb26655202_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def solution():\n    n = 4\n    edges = [[0, 1, 1], [0, 2, 5], [1, 2, 1], [2, 3, 1]]\n    src = 0\n    dst = 3\n    k = 1\n    problem = Problem()\n"]]}
{"hexsha": "a00eac733256a3b6d482971b346cd59ff9fce3d7", "ext": "py", "lang": "Python", "content": "def join_multiline_pairs(text, pair=\"()\"):\n    \"\"\"\n    Finds and removes newlines in multiline matching pairs of characters in\n    'text'.  For example, \"(.*\\n.*), {.*\\n.*}, or [.*\\n.*]\".\n\n    By default it joins parens () but it will join any two characters given via\n    the 'pair' variable.\n\n    **Note:** Doesnt remove extraneous whitespace that ends up between the pair.\n    Use reduce_operators() for that.\n\n    Example:\n\n    .. code-block:: python\n\n        test = (\n            \"This is inside a multi-line pair of parentheses\"\n        )\n\n    Will become:\n\n    .. code-block:: python\n\n        test = (         \"This is inside a multi-line pair of parentheses\"     )\n    \"\"\"\n    # Readability variables\n    opener = pair[0]\n    closer = pair[1]\n\n    # Tracking variables\n    inside_pair = False\n    inside_quotes = False\n    inside_double_quotes = False\n    inside_single_quotes = False\n    quoted_string = False\n    openers = 0\n    closers = 0\n    linecount = 0  # lint:ok\n\n    # Regular expressions\n    opener_regex = re.compile('\\%s' % opener)\n    closer_regex = re.compile('\\%s' % closer)\n\n    output = \"\"\n\n    for line in text.split('\\n'):\n        escaped = False\n        # First we rule out multi-line strings\n        multline_match = multiline_quoted_string.search(line)\n        not_quoted_string_match = not_quoted_string.search(line)\n        if multline_match and not not_quoted_string_match and not quoted_string:\n            if len(line.split('\"\"\"')) > 1 or len(line.split(\"'''\")):\n                # This is a single line that uses the triple quotes twice\n                # Treat it as if it were just a regular line:\n                output += line + '\\n'\n                quoted_string = False\n            else:\n                output += line + '\\n'\n                quoted_string = True\n        elif quoted_string and multiline_quoted_string.search(line):\n            output += line + '\\n'\n            quoted_string = False\n        # Now let's focus on the lines containing our opener and/or closer:\n        elif not quoted_string:\n            if opener_regex.search(line) \\\n               or closer_regex.search(line) or inside_pair:\n                for character in line:\n                    if character == opener:\n                        if not escaped and not inside_quotes:\n                            openers += 1\n                            inside_pair = True\n                            output += character\n                        else:\n                            escaped = False\n                            output += character\n                    elif character == closer:\n                        if not escaped and not inside_quotes:\n                            if openers and openers == (closers + 1):\n                                closers = 0\n                                openers = 0\n                                inside_pair = False\n                                output += character\n                            else:\n                                closers += 1\n                                output += character\n                        else:\n                            escaped = False\n                            output += character\n                    elif character == '\\\\':\n                        if escaped:\n                            escaped = False\n                            output += character\n                        else:\n                            escaped = True\n                            output += character\n                    elif character == '\"' and escaped:\n                        output += character\n                        escaped = False\n                    elif character == \"'\" and escaped:\n                        output += character\n                        escaped = False\n                    elif character == '\"' and inside_quotes:\n                        if inside_single_quotes:\n                            output += character\n                        else:\n                            inside_quotes = False\n                            inside_double_quotes = False\n                            output += character\n                    elif character == \"'\" and inside_quotes:\n                        if inside_double_quotes:\n                            output += character\n                        else:\n                            inside_quotes = False\n                            inside_single_quotes = False\n                            output += character\n                    elif character == '\"' and not inside_quotes:\n                        inside_quotes = True\n                        inside_double_quotes = True\n                        output += character\n                    elif character == \"'\" and not inside_quotes:\n                        inside_quotes = True\n                        inside_single_quotes = True\n                        output += character\n                    elif character == ' ' and inside_pair and not inside_quotes:\n                        if not output[-1] in [' ', opener]:\n                            output += ' '\n                    else:\n                        if escaped:\n                            escaped = False\n                        output += character\n                if inside_pair is False:\n                    output += '\\n'\n            else:\n                output += line + '\\n'\n        else:\n            output += line + '\\n'\n\n    # Clean up\n    output = trailing_newlines.sub('\\n', output)\n\n    return output", "fn_id": 3, "class_fn": false, "repo": "JamesHutchison/brython", "file": "scripts/pyminifier.py", "last_update_at": "2019-12-18T04:58:34+00:00", "question_id": "a00eac733256a3b6d482971b346cd59ff9fce3d7_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def join_multiline_pairs(text, pair='()'):\n    \"\"\"\n    Finds and removes newlines in multiline matching pairs of characters in\n    'text'.  For example, \"(.*\n.*), {.*\n.*}, or [.*\n.*]\".\n\n    By default it joins parens () but it will join any two characters given via\n    the 'pair' variable.\n\n    **Note:** Doesnt remove extraneous whitespace that ends up between the pair.\n    Use reduce_operators() for that.\n\n    Example:\n\n    .. code-block:: python\n\n        test = (\n            \"This is inside a multi-line pair of parentheses\"\n        )\n\n    Will become:\n\n    .. code-block:: python\n\n        test = (         \"This is inside a multi-line pair of parentheses\"     )\n    \"\"\"\n    opener = pair[0]\n    closer = pair[1]\n    inside_pair = False\n    inside_quotes = False\n    inside_double_quotes = False\n    inside_single_quotes = False\n    quoted_string = False\n    openers = 0\n    closers = 0\n    linecount = 0\n    opener_regex = re.compile('\\\\%s' % opener)\n    closer_regex = re.compile('\\\\%s' % closer)\n    output = ''\n    for line in text.split('\\n'):\n        escaped = False\n        multline_match = multiline_quoted_string.search(line)\n        not_quoted_string_match = not_quoted_string.search(line)\n        if multline_match and (not not_quoted_string_match) and (not quoted_string):\n            if len(line.split('\"\"\"')) > 1 or len(line.split(\"'''\")):\n                output += line + '\\n'\n                quoted_string = False\n            else:\n                output += line + '\\n'\n                quoted_string = True\n        elif quoted_string and multiline_quoted_string.search(line):\n            output += line + '\\n'\n            quoted_string = False\n        elif not quoted_string:\n            if opener_regex.search(line) or closer_regex.search(line) or inside_pair:\n                for character in line:\n                    if character == opener:\n                        if not escaped and (not inside_quotes):\n                            openers += 1\n                            inside_pair = True\n                            output += character\n                        else:\n                            escaped = False\n                            output += character\n                    elif character == closer:\n                        if not escaped and (not inside_quotes):\n                            if openers and openers == closers + 1:\n                                closers = 0\n                                openers = 0\n                                inside_pair = False\n                                output += character\n                            else:\n                                closers += 1\n                                output += character\n                        else:\n                            escaped = False\n                            output += character\n                    elif character == '\\\\':\n                        if escaped:\n                            escaped = False\n                            output += character\n                        else:\n                            escaped = True\n                            output += character\n                    elif character == '\"' and escaped:\n                        output += character\n                        escaped = False\n                    elif character == \"'\" and escaped:\n                        output += character\n                        escaped = False\n                    elif character == '\"' and inside_quotes:\n                        if inside_single_quotes:\n                            output += character\n                        else:\n                            inside_quotes = False\n                            inside_double_quotes = False\n                            output += character\n                    elif character == \"'\" and inside_quotes:\n                        if inside_double_quotes:\n                            output += character\n                        else:\n                            inside_quotes = False\n                            inside_single_quotes = False\n                            output += character\n                    elif character == '\"' and (not inside_quotes):\n                        inside_quotes = True\n                        inside_double_quotes = True\n                        output += character\n                    elif character == \"'\" and (not inside_quotes):\n                        inside_quotes = True\n                        inside_single_quotes = True\n                        output += character\n                    elif character == ' ' and inside_pair and (not inside_quotes):\n                        if not output[-1] in [' ', opener]:\n                            output += ' '\n                    else:\n                        if escaped:\n                            escaped = False\n                        output += character\n                if inside_pair is False:\n                    output += '\\n'\n            else:\n                output += line + '\\n'\n        else:\n            output += line + '\\n'\n    output = trailing_newlines.sub('\\n', output)\n"]]}
{"hexsha": "bcf257a1f3e9e47e79f5adccc4cb7718c993bdb6", "ext": "py", "lang": "Python", "content": "def _insert_widget_or_layout(layout: QLayout, item: WidgetOrLayout, *args, **kwargs):\n    if isinstance(item, QWidget):\n        layout.addWidget(item, *args, **kwargs)\n    elif isinstance(item, QLayout):\n        # QLayout and some subclasses (like QFormLayout) omit this method,\n        # and will crash at runtime.\n        layout.addLayout(item, *args, **kwargs)\n    else:\n        raise TypeError(item)", "fn_id": 3, "class_fn": false, "repo": "N-SPC700/corrscope", "file": "corrscope/gui/view_stack.py", "last_update_at": "2019-10-10T12:08:58+00:00", "question_id": "bcf257a1f3e9e47e79f5adccc4cb7718c993bdb6_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _insert_widget_or_layout(layout: QLayout, item: WidgetOrLayout, *args, **kwargs):\n    if isinstance(item, QWidget):\n        layout.addWidget(item, *args, **kwargs)\n    elif isinstance(item, QLayout):\n        layout.addLayout(item, *args, **kwargs)\n    else:\n"]]}
{"hexsha": "cca0ae0b0e53349589c0da2ebf78e2b30c8c3489", "ext": "py", "lang": "Python", "content": "def calculate_all_sentiment_features(entry):\n    post_title_sentiment = calculate_sentiment_features([entry[\"postText\"][0]])\n    article_title_sentiment = calculate_sentiment_features([entry[\"targetTitle\"]])\n    article_desc_sentiment = calculate_sentiment_features([entry[\"targetDescription\"]])\n    article_keywords_sentiment = calculate_sentiment_features([entry[\"targetKeywords\"]])\n    article_paragraphs_sentiment = calculate_sentiment_features(entry[\"targetParagraphs\"])\n    lst = [post_title_sentiment, article_title_sentiment, article_desc_sentiment, article_keywords_sentiment,\n            article_paragraphs_sentiment]\n    return list(sum(lst, ()))", "fn_id": 3, "class_fn": false, "repo": "rpytel1/clickbait-challenge", "file": "feature_extraction/services/sentiment_analysis_service.py", "last_update_at": "2019-10-29T05:01:11+00:00", "question_id": "cca0ae0b0e53349589c0da2ebf78e2b30c8c3489_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def calculate_all_sentiment_features(entry):\n    post_title_sentiment = calculate_sentiment_features([entry['postText'][0]])\n    article_title_sentiment = calculate_sentiment_features([entry['targetTitle']])\n    article_desc_sentiment = calculate_sentiment_features([entry['targetDescription']])\n    article_keywords_sentiment = calculate_sentiment_features([entry['targetKeywords']])\n    article_paragraphs_sentiment = calculate_sentiment_features(entry['targetParagraphs'])\n    lst = [post_title_sentiment, article_title_sentiment, article_desc_sentiment, article_keywords_sentiment, article_paragraphs_sentiment]\n"]]}
{"hexsha": "13e0ccfeb2e3e97056a8e67acb62fb222daefc23", "ext": "py", "lang": "Python", "content": "@pytest.mark.vcr()\ndef test_agentgroups_delete_agent_from_group_scanner_id_typeerror(api):\n    with pytest.raises(TypeError):\n        api.agent_groups.delete_agent(1, 1, scanner_id='nope')", "fn_id": 21, "class_fn": false, "repo": "widnyana/pyTenable", "file": "tests/io/test_agent_groups.py", "last_update_at": "2019-01-25T11:36:07+00:00", "question_id": "13e0ccfeb2e3e97056a8e67acb62fb222daefc23_21", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.mark.vcr()\ndef test_agentgroups_delete_agent_from_group_scanner_id_typeerror(api):\n    with pytest.raises(TypeError):\n"]]}
{"hexsha": "73d42cd85530f7cdacfa7fe123df893bce39d102", "ext": "py", "lang": "Python", "content": "def add_user(data, username):\n        if usr_already_exists(data) == True:\n                return \"User already exists\"\n        try:\n                connect = connect_to_sql()\n                cursor = connect.cursor()\n                cursor.execute(\"INSERT INTO user (user_id, username) VALUES ('%s', '%s')\"\n                % (data, username))\n                connect.commit()\n\n                cursor.close()\n                connect.close()\n                return \"User created\"\n        except:\n              pass", "fn_id": 5, "class_fn": false, "repo": "PoCInnovation/Domotics", "file": "API/api.py", "last_update_at": "2019-10-10T16:44:03+00:00", "question_id": "73d42cd85530f7cdacfa7fe123df893bce39d102_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def add_user(data, username):\n    if usr_already_exists(data) == True:\n        return 'User already exists'\n    try:\n        connect = connect_to_sql()\n        cursor = connect.cursor()\n        cursor.execute(\"INSERT INTO user (user_id, username) VALUES ('%s', '%s')\" % (data, username))\n        connect.commit()\n        cursor.close()\n        connect.close()\n        return 'User created'\n    except:\n"]]}
{"hexsha": "7c1fca17abea1cb3d462e00f82098fc5716ad3a4", "ext": "py", "lang": "Python", "content": "def control(**kwargs):\n    if kwargs['payload'] in Encoders().shellcode:\n        data = open(kwargs['files'][0], \"r\").read().strip()\n\n        if kwargs['payload'] == \"encoders/shellcode/intel/x86/xor86.py\":\n            from .xor import prestart\n        elif kwargs['payload'] == \"encoders/shellcode/intel/x86/xor_b3m.py\":\n            from .xor_b3m import prestart\n\n        with open(kwargs['files'][0], \"w\") as encoded:\n            encoded.write(prestart((data.replace(\"\\\\x\", \"\")), kwargs['iteration']))", "fn_id": 0, "class_fn": false, "repo": "dromero1452/shellsploit-framework", "file": "shell/encoders/shellcode/starter.py", "last_update_at": "2019-12-23T15:50:03+00:00", "question_id": "7c1fca17abea1cb3d462e00f82098fc5716ad3a4_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def control(**kwargs):\n    if kwargs['payload'] in Encoders().shellcode:\n        data = open(kwargs['files'][0], 'r').read().strip()\n        if kwargs['payload'] == 'encoders/shellcode/intel/x86/xor86.py':\n            from .xor import prestart\n        elif kwargs['payload'] == 'encoders/shellcode/intel/x86/xor_b3m.py':\n            from .xor_b3m import prestart\n        with open(kwargs['files'][0], 'w') as encoded:\n"]]}
{"hexsha": "5994f22d2cb4c39e1e53070447029e3a3dbc5a7d", "ext": "py", "lang": "Python", "content": "def headerfix(header):\n    ## this code fix the header problem of fits out from CASA 5.4+ which leads to a streched solar image\n    import copy\n    hdr = copy.copy(header)\n    for hd in header:\n        if hd.upper().startswith('PC'):\n            if not hd.upper().startswith('PC0'):\n                hd_ = 'PC0' + hd.upper().replace('PC', '')\n                hdr.pop(hd)\n                hdr[hd_] = header[hd]\n    return hdr", "fn_id": 32, "class_fn": false, "repo": "wyq24/suncasa", "file": "suncasa/utils/DButil.py", "last_update_at": "2019-07-16T18:25:12+00:00", "question_id": "5994f22d2cb4c39e1e53070447029e3a3dbc5a7d_32", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def headerfix(header):\n    import copy\n    hdr = copy.copy(header)\n    for hd in header:\n        if hd.upper().startswith('PC'):\n            if not hd.upper().startswith('PC0'):\n                hd_ = 'PC0' + hd.upper().replace('PC', '')\n                hdr.pop(hd)\n                hdr[hd_] = header[hd]\n"]]}
{"hexsha": "c1e959297079c8b361ed050bf40e71e5c0711833", "ext": "py", "lang": "Python", "content": "def test_stack_enque():\n  test_stack.push(1)\n  assert not test_stack.is_empty()\n  assert test_stack.peek() == 1\n  test_stack.push(2)\n  test_stack.push(3)\n  test_stack.push(4)\n  assert test_stack.peek() == 4", "fn_id": 1, "class_fn": false, "repo": "Stanels42/python-data-structures-and-algorithms", "file": "data_structures/stack-and-queue/test_stack.py", "last_update_at": "2019-12-05T05:00:30+00:00", "question_id": "c1e959297079c8b361ed050bf40e71e5c0711833_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_stack_enque():\n    test_stack.push(1)\n    assert not test_stack.is_empty()\n    assert test_stack.peek() == 1\n    test_stack.push(2)\n    test_stack.push(3)\n    test_stack.push(4)\n"]]}
{"hexsha": "b16cc1646ad4dbe41303de150cd50b7d001e0910", "ext": "py", "lang": "Python", "content": "@bp.route('/month/<month>', methods=['GET'])\ndef get_events_by_month(month):\n    events = Date.query.filter((Date.events != None) | (Date.events != 0)).filter(Date.day.month == int(month))\n    return event_schema.jsonify(events)", "fn_id": 3, "class_fn": false, "repo": "Info-ag/labplaner", "file": "app/blueprints/api/v1/event.py", "last_update_at": "2019-01-06T17:39:59+00:00", "question_id": "b16cc1646ad4dbe41303de150cd50b7d001e0910_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@bp.route('/month/<month>', methods=['GET'])\ndef get_events_by_month(month):\n    events = Date.query.filter((Date.events != None) | (Date.events != 0)).filter(Date.day.month == int(month))\n"]]}
{"hexsha": "37249a4b4f2e000a76c6fe26af8aab48e98cee37", "ext": "py", "lang": "Python", "content": "def plot_rain_case_poster(cases_r, save=SAVE_DEFAULT):\n    c = copy.deepcopy(cases_r.loc['140812T02'].case)\n    c.data = c.data.loc[:,:, '2014-08-12 03:40':].copy()\n    fig_kws = dict(fig_w_factor=0.6)\n    fig, axarr = c.plot(params=['kdp', 'zh', 'zdr'],\n                        n_extra_ax=0, plot_extras=['cl'],\n                        t_contour_ax_ind='all',\n                        t_levels=[-40, -20, -10, -8, -3],\n                        fig_scale_factor=0.85, fig_kws=fig_kws)\n    formatter = plotting.concise_formatter()\n    axarr[-1].xaxis.set_major_formatter(formatter)\n    if save:\n        fig.savefig(path.join(conf.POSTER_FIG_DIR, 'case_rain.png'), **SAVE_KWS)\n    return fig, axarr", "fn_id": 1, "class_fn": false, "repo": "juhi24/radcomp", "file": "scripts/vertical/plot_wrappers.py", "last_update_at": "2019-06-18T01:54:00+00:00", "question_id": "37249a4b4f2e000a76c6fe26af8aab48e98cee37_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def plot_rain_case_poster(cases_r, save=SAVE_DEFAULT):\n    c = copy.deepcopy(cases_r.loc['140812T02'].case)\n    c.data = c.data.loc[:, :, '2014-08-12 03:40':].copy()\n    fig_kws = dict(fig_w_factor=0.6)\n    fig, axarr = c.plot(params=['kdp', 'zh', 'zdr'], n_extra_ax=0, plot_extras=['cl'], t_contour_ax_ind='all', t_levels=[-40, -20, -10, -8, -3], fig_scale_factor=0.85, fig_kws=fig_kws)\n    formatter = plotting.concise_formatter()\n    axarr[-1].xaxis.set_major_formatter(formatter)\n    if save:\n        fig.savefig(path.join(conf.POSTER_FIG_DIR, 'case_rain.png'), **SAVE_KWS)\n"]]}
{"hexsha": "db78dfb1c03c1fde2ef325ec3db4849b32bc70b7", "ext": "py", "lang": "Python", "content": "def get_deployment_history_services(deployment):\n    template_name = 'deployments/_cell_services.html'\n    services = {}\n    for service in deployment.description['services']:\n        service_type = service['?']['type']\n        if service_type.find('/') != -1:\n            service_type = service_type[:service_type.find('/')]\n        services[service.get('name', service['?']['name'])] = service_type\n    context = {\n        \"services\": services,\n    }\n    return template.loader.render_to_string(template_name, context)", "fn_id": 4, "class_fn": false, "repo": "starlingx-staging/stx-murano-dashboard", "file": "muranodashboard/environments/tables.py", "last_update_at": "2019-01-11T16:04:33+00:00", "question_id": "db78dfb1c03c1fde2ef325ec3db4849b32bc70b7_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_deployment_history_services(deployment):\n    template_name = 'deployments/_cell_services.html'\n    services = {}\n    for service in deployment.description['services']:\n        service_type = service['?']['type']\n        if service_type.find('/') != -1:\n            service_type = service_type[:service_type.find('/')]\n        services[service.get('name', service['?']['name'])] = service_type\n    context = {'services': services}\n"]]}
{"hexsha": "63d9db81366c5aaa02808ea12f9ec81eade531b2", "ext": "py", "lang": "Python", "content": "def to_midnight(dt: datetime):\n    '''\n    Round the provided datetime object to the last day\n    Usage:\n        >>> to_midnight(datetime.strptime('14 Aug 1993 10:21', '%d %b %Y %H:%M')).strftime('%d %b %Y %H:%M')\n        \"14 Aug 1993 00:00\"\n    '''\n    return dt.replace(hour=0, minute=0, second=0, microsecond=0)", "fn_id": 2, "class_fn": false, "repo": "bamaxw/ion", "file": "ion/time/interval.py", "last_update_at": "2019-04-29T15:13:33+00:00", "question_id": "63d9db81366c5aaa02808ea12f9ec81eade531b2_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def to_midnight(dt: datetime):\n    \"\"\"\n    Round the provided datetime object to the last day\n    Usage:\n        >>> to_midnight(datetime.strptime('14 Aug 1993 10:21', '%d %b %Y %H:%M')).strftime('%d %b %Y %H:%M')\n        \"14 Aug 1993 00:00\"\n    \"\"\"\n"]]}
{"hexsha": "31894a67647dbf5378e4d20ebf5140b8b69d6d6d", "ext": "py", "lang": "Python", "content": "@executer\ndef delete_groups_dec():\n    base_url, headers = get_api_info()\n    group_url = \"{}/groups\".format(base_url)\n    group_response = requests.get(\"{}?limits={}\".format(group_url, 200), headers=headers)\n    group_details = json.loads(group_response.text)\n    groups_id_list = [item['id'] for item in group_details]\n\n    successfully_deleted_groups = []\n    failed_groups = []\n\n    for group_id in tqdm(groups_id_list):\n        group_response = requests.delete(\"{}/{}\".format(group_url, group_id), headers=headers)\n        if group_response:\n            successfully_deleted_groups.append(group_id)\n        else:\n            failed_groups.append(group_id)\n    \n    if successfully_deleted_groups:\n        click.secho(\"\\nList of groups deleted successfully: {}\".format(\n            successfully_deleted_groups), fg='green')\n    if failed_groups:\n        click.secho(\"\\nFailed to delete these groups: {}.\\n\".format(failed_groups), fg='red')", "fn_id": 5, "class_fn": false, "repo": "atul3015kr/oktactl", "file": "oktactl/okta.py", "last_update_at": "2019-09-09T13:14:46+00:00", "question_id": "31894a67647dbf5378e4d20ebf5140b8b69d6d6d_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@executer\ndef delete_groups_dec():\n    base_url, headers = get_api_info()\n    group_url = '{}/groups'.format(base_url)\n    group_response = requests.get('{}?limits={}'.format(group_url, 200), headers=headers)\n    group_details = json.loads(group_response.text)\n    groups_id_list = [item['id'] for item in group_details]\n    successfully_deleted_groups = []\n    failed_groups = []\n    for group_id in tqdm(groups_id_list):\n        group_response = requests.delete('{}/{}'.format(group_url, group_id), headers=headers)\n        if group_response:\n            successfully_deleted_groups.append(group_id)\n        else:\n            failed_groups.append(group_id)\n    if successfully_deleted_groups:\n        click.secho('\\nList of groups deleted successfully: {}'.format(successfully_deleted_groups), fg='green')\n    if failed_groups:\n"]]}
{"hexsha": "49b103e10d93f562b298b9c36f1574e96fa2f031", "ext": "py", "lang": "Python", "content": "def msg_list(pkg, search_path, ext):\n    dir_list = search_path[pkg]\n    files = []\n    for d in dir_list:\n        files.extend([f for f in os.listdir(d) if f.endswith(ext)])\n    return [f[:-len(ext)] for f in files]", "fn_id": 37, "class_fn": false, "repo": "slicht-uri/Sandshark-Beta-Lab-", "file": "vehicle/adapt-sysroot/ros_install_isolated/lib/python2.7/dist-packages/genlisp/generate.py", "last_update_at": "2019-10-18T06:25:14+00:00", "question_id": "49b103e10d93f562b298b9c36f1574e96fa2f031_37", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def msg_list(pkg, search_path, ext):\n    dir_list = search_path[pkg]\n    files = []\n    for d in dir_list:\n        files.extend([f for f in os.listdir(d) if f.endswith(ext)])\n"]]}
{"hexsha": "13c1c0b85cfc57cbefee6425cbf5890b144bd8df", "ext": "py", "lang": "Python", "content": "def remove_blank(x):\n\t\"\"\"creating a function to remove the empty words\"\"\"\n\tif(x != \"\"):\n\t\treturn(x)", "fn_id": 0, "class_fn": false, "repo": "dsp-uga/Sushanth-Kathirvelu-p0", "file": "p0_sp_d.py", "last_update_at": "2019-05-02T04:48:10+00:00", "question_id": "13c1c0b85cfc57cbefee6425cbf5890b144bd8df_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def remove_blank(x):\n    \"\"\"creating a function to remove the empty words\"\"\"\n    if x != '':\n"]]}
{"hexsha": "d9bef0062335735f85138ca286bea734ef9177cd", "ext": "py", "lang": "Python", "content": "def derivative(requestContext, seriesList):\n  \"\"\"\n  This is the opposite of the integral function.  This is useful for taking a\n  running total metric and calculating the delta between subsequent data points.\n\n  This function does not normalize for periods of time, as a true derivative would.\n  Instead see the perSecond() function to calculate a rate of change over time.\n\n  Example:\n\n  .. code-block:: none\n\n    &target=derivative(company.server.application01.ifconfig.TXPackets)\n\n  Each time you run ifconfig, the RX and TXPackets are higher (assuming there\n  is network traffic.) By applying the derivative function, you can get an\n  idea of the packets per minute sent or received, even though you're only\n  recording the total.\n  \"\"\"\n  results = []\n  for series in seriesList:\n    newValues = []\n    prev = None\n    for val in series:\n      if None in (prev,val):\n        newValues.append(None)\n        prev = val\n        continue\n      newValues.append(val - prev)\n      prev = val\n    newName = \"derivative(%s)\" % series.name\n    newSeries = TimeSeries(newName, series.start, series.end, series.step, newValues)\n    newSeries.pathExpression = newName\n    results.append(newSeries)\n  return results", "fn_id": 45, "class_fn": false, "repo": "jssjr/graphite-web", "file": "webapp/graphite/render/functions.py", "last_update_at": "2019-06-17T18:55:55+00:00", "question_id": "d9bef0062335735f85138ca286bea734ef9177cd_45", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def derivative(requestContext, seriesList):\n    \"\"\"\n  This is the opposite of the integral function.  This is useful for taking a\n  running total metric and calculating the delta between subsequent data points.\n\n  This function does not normalize for periods of time, as a true derivative would.\n  Instead see the perSecond() function to calculate a rate of change over time.\n\n  Example:\n\n  .. code-block:: none\n\n    &target=derivative(company.server.application01.ifconfig.TXPackets)\n\n  Each time you run ifconfig, the RX and TXPackets are higher (assuming there\n  is network traffic.) By applying the derivative function, you can get an\n  idea of the packets per minute sent or received, even though you're only\n  recording the total.\n  \"\"\"\n    results = []\n    for series in seriesList:\n        newValues = []\n        prev = None\n        for val in series:\n            if None in (prev, val):\n                newValues.append(None)\n                prev = val\n                continue\n            newValues.append(val - prev)\n            prev = val\n        newName = 'derivative(%s)' % series.name\n        newSeries = TimeSeries(newName, series.start, series.end, series.step, newValues)\n        newSeries.pathExpression = newName\n        results.append(newSeries)\n"]]}
{"hexsha": "be19f4904518e5c80c7c9ea979874478eee09450", "ext": "py", "lang": "Python", "content": "@contextmanager\ndef tag(name):\n    print('<%s>' % name)\n    yield\n    print('<%s>' % name)", "fn_id": 1, "class_fn": false, "repo": "Realize0917/career", "file": "python/20190128/Code/c2.py", "last_update_at": "2019-03-15T10:10:07+00:00", "question_id": "be19f4904518e5c80c7c9ea979874478eee09450_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@contextmanager\ndef tag(name):\n    print('<%s>' % name)\n    yield\n"]]}
{"hexsha": "41236aba427df80cf7a2b637e35861491c8b0e0c", "ext": "py", "lang": "Python", "content": "def shn_pr_rheader(jr, tabs=[]):\n\n    \"\"\" Person Registry page headers \"\"\"\n\n    if jr.representation == \"html\":\n\n        rheader_tabs = shn_rheader_tabs(jr, tabs)\n\n        if jr.name == \"person\":\n\n            _next = jr.here()\n            _same = jr.same()\n\n            person = jr.record\n\n            if person:\n                rheader = DIV(TABLE(\n\n                    TR(TH(T(\"Name: \")),\n                       vita.fullname(person),\n                       TH(T(\"ID Label: \")),\n                       \"%(pe_label)s\" % person),\n\n                    TR(TH(T(\"Date of Birth: \")),\n                       \"%s\" % (person.date_of_birth or T(\"unknown\")),\n                       TH(T(\"Gender: \")),\n                       \"%s\" % pr_gender_opts.get(person.gender, T(\"unknown\"))),\n\n                    TR(TH(T(\"Nationality: \")),\n                       \"%s\" % pr_nations.get(person.nationality, T(\"unknown\")),\n                       TH(T(\"Age Group: \")),\n                       \"%s\" % pr_age_group_opts.get(person.age_group, T(\"unknown\"))),\n\n                    #))\n                    ), rheader_tabs)\n\n                return rheader\n\n        elif jr.name == \"group\":\n\n            _next = jr.here()\n            _same = jr.same()\n\n            group = jr.record\n\n            if group:\n                rheader = DIV(TABLE(\n\n                    TR(TH(T(\"Name: \")),\n                       group.name,\n                       TH(\"\"),\n                       \"\"),\n                    TR(TH(T(\"Description: \")),\n                       group.description,\n                       TH(\"\"),\n                       \"\")\n\n                    ), rheader_tabs)\n\n                return rheader\n\n    return None", "fn_id": 5, "class_fn": false, "repo": "dineshkummarc/SahanaEden", "file": "models/02_pr.py", "last_update_at": "2019-04-22T16:43:05+00:00", "question_id": "41236aba427df80cf7a2b637e35861491c8b0e0c_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def shn_pr_rheader(jr, tabs=[]):\n    \"\"\" Person Registry page headers \"\"\"\n    if jr.representation == 'html':\n        rheader_tabs = shn_rheader_tabs(jr, tabs)\n        if jr.name == 'person':\n            _next = jr.here()\n            _same = jr.same()\n            person = jr.record\n            if person:\n                rheader = DIV(TABLE(TR(TH(T('Name: ')), vita.fullname(person), TH(T('ID Label: ')), '%(pe_label)s' % person), TR(TH(T('Date of Birth: ')), '%s' % (person.date_of_birth or T('unknown')), TH(T('Gender: ')), '%s' % pr_gender_opts.get(person.gender, T('unknown'))), TR(TH(T('Nationality: ')), '%s' % pr_nations.get(person.nationality, T('unknown')), TH(T('Age Group: ')), '%s' % pr_age_group_opts.get(person.age_group, T('unknown')))), rheader_tabs)\n                return rheader\n        elif jr.name == 'group':\n            _next = jr.here()\n            _same = jr.same()\n            group = jr.record\n            if group:\n                rheader = DIV(TABLE(TR(TH(T('Name: ')), group.name, TH(''), ''), TR(TH(T('Description: ')), group.description, TH(''), '')), rheader_tabs)\n                return rheader\n"]]}
{"hexsha": "979feb4188fe880ad26146c97ee90a0b3537c071", "ext": "py", "lang": "Python", "content": "def param_values():\n    \n    x = [0] * C.NUM\n\n    ## CYCE SYNTHESISx[C.DEGRADATION AND P27 BINDING/DISSOCIATION:\n    x[C.kscyce]=0.003\n    x[C.kdcyce]=0.001\n    x[C.kdcycee]=0.0001\n    x[C.kdcycea]=0.03\n    x[C.kasse]=1\n    x[C.kdise]=0.02\n    ## CYCA SYNTHESISx[C.DEGRADATION AND P27 BINDING/DISSOCIATION:\n    x[C.kscyca]=0.0025\n    x[C.kdcyca]=0.002\n    x[C.kdcycac1]=0.4\n    x[C.kassa]=1\n    x[C.kdisa]=0.02\n    ## P27 SYNTHESIS AND DEGRADATION:\n    x[C.ks27]=0.008\n    x[C.kd27]=0.004\n    x[C.kd27e]=2\n    x[C.kd27a]=2\n    ## EMI1 SYNTHESIS AND DEGRADATION:\n    x[C.ksemi1]=0.003\n    x[C.kdemi1]=0.001\n    ## CDH1 REGULATION:\n    x[C.Cdh1T]=1\n    x[C.kacdh1]=0.02\n    x[C.kicdh1e]=0.07\n    x[C.kicdh1a]=0.2\n    x[C.kasec]=2\n    x[C.kdiec]=0.02\n    ## SKP2 SYNTHESIS AND DEGRADATION:\n    x[C.ksskp2]=0.004\n    x[C.kdskp2]=0.002\n    x[C.kdskp2c1]=0.2\n    ## CDK INHIBITOR\n    x[C.Inhibitor]=0\n\n    return x", "fn_id": 1, "class_fn": false, "repo": "okadalabipr/cancer_signaling", "file": "Barr2016/model/set_model.py", "last_update_at": "2019-08-18T10:26:04+00:00", "question_id": "979feb4188fe880ad26146c97ee90a0b3537c071_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def param_values():\n    x = [0] * C.NUM\n    x[C.kscyce] = 0.003\n    x[C.kdcyce] = 0.001\n    x[C.kdcycee] = 0.0001\n    x[C.kdcycea] = 0.03\n    x[C.kasse] = 1\n    x[C.kdise] = 0.02\n    x[C.kscyca] = 0.0025\n    x[C.kdcyca] = 0.002\n    x[C.kdcycac1] = 0.4\n    x[C.kassa] = 1\n    x[C.kdisa] = 0.02\n    x[C.ks27] = 0.008\n    x[C.kd27] = 0.004\n    x[C.kd27e] = 2\n    x[C.kd27a] = 2\n    x[C.ksemi1] = 0.003\n    x[C.kdemi1] = 0.001\n    x[C.Cdh1T] = 1\n    x[C.kacdh1] = 0.02\n    x[C.kicdh1e] = 0.07\n    x[C.kicdh1a] = 0.2\n    x[C.kasec] = 2\n    x[C.kdiec] = 0.02\n    x[C.ksskp2] = 0.004\n    x[C.kdskp2] = 0.002\n    x[C.kdskp2c1] = 0.2\n    x[C.Inhibitor] = 0\n"]]}
{"hexsha": "9df86b84b9037fca72144612aafd758c97264d6c", "ext": "py", "lang": "Python", "content": "def main():\n    filename = 'data/steam_resetera_2017_goty.txt'\n\n    data = load_input(filename)\n\n    observations = parse_data(data)\n\n    verbose = False\n    prior = choose_prior(observations, verbose)\n\n    ranking = compute_ranking(observations, prior)\n\n    print_ranking(ranking, observations, prior)\n\n    return True", "fn_id": 4, "class_fn": false, "repo": "woctezuma/steam-era-goty", "file": "bayesian_goty.py", "last_update_at": "2019-03-11T12:35:36+00:00", "question_id": "9df86b84b9037fca72144612aafd758c97264d6c_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main():\n    filename = 'data/steam_resetera_2017_goty.txt'\n    data = load_input(filename)\n    observations = parse_data(data)\n    verbose = False\n    prior = choose_prior(observations, verbose)\n    ranking = compute_ranking(observations, prior)\n    print_ranking(ranking, observations, prior)\n"]]}
{"hexsha": "77508dd2aeb0c35af663e0129bb4b22cb9713ce8", "ext": "py", "lang": "Python", "content": "@C.funcs\ndef theme_infographic() -> Bar:\n    c = (\n        Bar(init_opts=opts.InitOpts(theme=ThemeType.INFOGRAPHIC))\n        .add_xaxis(Faker.choose())\n        .add_yaxis(\"\u5546\u5bb6A\", Faker.values())\n        .add_yaxis(\"\u5546\u5bb6B\", Faker.values())\n        .add_yaxis(\"\u5546\u5bb6C\", Faker.values())\n        .add_yaxis(\"\u5546\u5bb6D\", Faker.values())\n        .set_global_opts(title_opts=opts.TitleOpts(\"Theme-infographic\"))\n    )\n    return c", "fn_id": 5, "class_fn": false, "repo": "lakdred/pyecharts", "file": "example/theme_example.py", "last_update_at": "2019-06-29T09:37:45+00:00", "question_id": "77508dd2aeb0c35af663e0129bb4b22cb9713ce8_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@C.funcs\ndef theme_infographic() -> Bar:\n    c = Bar(init_opts=opts.InitOpts(theme=ThemeType.INFOGRAPHIC)).add_xaxis(Faker.choose()).add_yaxis('\u5546\u5bb6A', Faker.values()).add_yaxis('\u5546\u5bb6B', Faker.values()).add_yaxis('\u5546\u5bb6C', Faker.values()).add_yaxis('\u5546\u5bb6D', Faker.values()).set_global_opts(title_opts=opts.TitleOpts('Theme-infographic'))\n"]]}
{"hexsha": "1f2aea5e6b4fe2f969e1898654f9b9ef365dffe5", "ext": "py", "lang": "Python", "content": "def complain(what: str, iwant_object) -> dict:\n    print(f'INFO: More than 1 {what} was found.')\n    if what == 'behest':\n        listing = f\"`{'`, `'.join(iwant_object.possible_behests)}`\"\n    elif what == 'activity':\n        listing = f\"`{'`, `'.join(iwant_object.possible_activities)}`\"\n    else:\n        print(f'WARNING: Someone complain to \"{what}\", but unknown meaning.')\n        return {'text': 'You cannot want this.'}\n\n    return {'text': f'You can use only one {what} from {listing} at the same time.'}", "fn_id": 5, "class_fn": false, "repo": "kiwicom/iwant-bot", "file": "src/iwant_bot/start.py", "last_update_at": "2019-02-19T14:53:40+00:00", "question_id": "1f2aea5e6b4fe2f969e1898654f9b9ef365dffe5_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def complain(what: str, iwant_object) -> dict:\n    print(f'INFO: More than 1 {what} was found.')\n    if what == 'behest':\n        listing = f\"`{'`, `'.join(iwant_object.possible_behests)}`\"\n    elif what == 'activity':\n        listing = f\"`{'`, `'.join(iwant_object.possible_activities)}`\"\n    else:\n        print(f'WARNING: Someone complain to \"{what}\", but unknown meaning.')\n        return {'text': 'You cannot want this.'}\n"]]}
{"hexsha": "ffb730bdd67eaf23b5b0bbb1c04b7882c8c15722", "ext": "py", "lang": "Python", "content": "@pytest.mark.parametrize(\n    \"vstr,major,minor,pyenv\",\n    [\n        (\"3.0\", 3, 0, \"py30\"),\n        (\"3.6\", 3, 6, \"py36\"),\n        (\"3.10\", 3, 10, \"py310\"),\n    ],\n)\ndef test_pyversion(vstr: str, major: int, minor: int, pyenv: str) -> None:\n    v = PyVersion.parse(vstr)\n    assert v == vstr\n    assert str(v) == vstr\n    assert repr(v) == f\"PyVersion({vstr!r})\"\n    assert v.major == major\n    assert v.minor == minor\n    assert v.pyenv == pyenv\n    assert PyVersion.construct(major, minor) == v\n    assert json.dumps(v) == f'\"{vstr}\"'", "fn_id": 0, "class_fn": false, "repo": "jwodder/pyrepo", "file": "test/test_util.py", "last_update_at": "2019-05-04T01:23:51+00:00", "question_id": "ffb730bdd67eaf23b5b0bbb1c04b7882c8c15722_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.mark.parametrize('vstr,major,minor,pyenv', [('3.0', 3, 0, 'py30'), ('3.6', 3, 6, 'py36'), ('3.10', 3, 10, 'py310')])\ndef test_pyversion(vstr: str, major: int, minor: int, pyenv: str) -> None:\n    v = PyVersion.parse(vstr)\n    assert v == vstr\n    assert str(v) == vstr\n    assert repr(v) == f'PyVersion({vstr!r})'\n    assert v.major == major\n    assert v.minor == minor\n    assert v.pyenv == pyenv\n    assert PyVersion.construct(major, minor) == v\n"]]}
{"hexsha": "2c947d5b6e054f7b898a48da0fd8ed4cbc29c190", "ext": "py", "lang": "Python", "content": "def get_sequence_length(fasta_file_path: Path) -> int:\n    if fasta_file_path.suffix == \".gz\":\n        with gzip.open(fasta_file_path, \"rt\") as fhandle:\n            record = next(SeqIO.parse(fhandle, \"fasta\"))\n    else:\n        record = next(SeqIO.parse(fasta_file_path, \"fasta\"))\n    return len(record.seq)", "fn_id": 0, "class_fn": false, "repo": "iqbal-lab-org/py-cortex-api", "file": "cortex/utils.py", "last_update_at": "2019-04-19T05:44:43+00:00", "question_id": "2c947d5b6e054f7b898a48da0fd8ed4cbc29c190_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_sequence_length(fasta_file_path: Path) -> int:\n    if fasta_file_path.suffix == '.gz':\n        with gzip.open(fasta_file_path, 'rt') as fhandle:\n            record = next(SeqIO.parse(fhandle, 'fasta'))\n    else:\n        record = next(SeqIO.parse(fasta_file_path, 'fasta'))\n"]]}
{"hexsha": "c7794e99fc646416806c03a485b55a23b082ff62", "ext": "py", "lang": "Python", "content": "def export_papers_table(filename, rows):\n    results = []\n    for row in rows:\n        numpt = row['NumLANLIsolatesQCPassed']\n        if not numpt:\n            continue\n        results.append({\n            'PubMedID': row['PubMedID'],\n            'PubYear': row['PubYear'],\n            'NumPatients': numpt,\n            'RxStatus': row['RxStatus'],\n            'Title': row['Title'],\n            'Subtypes': row['Subtypes'],\n            'Authors': row['Authors'],\n        })\n    csv_writer(filename, results, CLEAN_TABLE_HEADERS)", "fn_id": 10, "class_fn": false, "repo": "hivdb/gag-gp41", "file": "scripts/analyze-naive-studies.py", "last_update_at": "2019-02-21T05:02:20+00:00", "question_id": "c7794e99fc646416806c03a485b55a23b082ff62_10", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def export_papers_table(filename, rows):\n    results = []\n    for row in rows:\n        numpt = row['NumLANLIsolatesQCPassed']\n        if not numpt:\n            continue\n        results.append({'PubMedID': row['PubMedID'], 'PubYear': row['PubYear'], 'NumPatients': numpt, 'RxStatus': row['RxStatus'], 'Title': row['Title'], 'Subtypes': row['Subtypes'], 'Authors': row['Authors']})\n"]]}
{"hexsha": "435d6317d476f9dd97265f66987c6a2d71512eb8", "ext": "py", "lang": "Python", "content": "def applyNonMaximaSuppression(nmsThreshold, labels, scores, coords, ignore_background=False):\n    # generate input for nms\n    allIndices = []\n    nmsRects = [[[]] for _ in range(max(labels) + 1)]\n    coordsWithScores = np.hstack((coords, np.array([scores]).T))\n    for i in range(max(labels) + 1):\n        indices = np.where(np.array(labels) == i)[0]\n        nmsRects[i][0] = coordsWithScores[indices,:]\n        allIndices.append(indices)\n\n    # call nms\n    _, nmsKeepIndicesList = apply_nms(nmsRects, nmsThreshold, ignore_background=ignore_background)\n\n    # map back to original roi indices\n    nmsKeepIndices = []\n    for i in range(max(labels) + 1):\n        for keepIndex in nmsKeepIndicesList[i][0]:\n            nmsKeepIndices.append(allIndices[i][keepIndex]) # for keepIndex in nmsKeepIndicesList[i][0]]\n    assert (len(nmsKeepIndices) == len(set(nmsKeepIndices)))  # check if no roi indices was added >1 times\n    return nmsKeepIndices", "fn_id": 22, "class_fn": false, "repo": "shyamalschandra/CNTK", "file": "Examples/Image/Detection/FastRCNN/BrainScript/cntk_helpers.py", "last_update_at": "2019-05-06T09:23:41+00:00", "question_id": "435d6317d476f9dd97265f66987c6a2d71512eb8_22", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def applyNonMaximaSuppression(nmsThreshold, labels, scores, coords, ignore_background=False):\n    allIndices = []\n    nmsRects = [[[]] for _ in range(max(labels) + 1)]\n    coordsWithScores = np.hstack((coords, np.array([scores]).T))\n    for i in range(max(labels) + 1):\n        indices = np.where(np.array(labels) == i)[0]\n        nmsRects[i][0] = coordsWithScores[indices, :]\n        allIndices.append(indices)\n    _, nmsKeepIndicesList = apply_nms(nmsRects, nmsThreshold, ignore_background=ignore_background)\n    nmsKeepIndices = []\n    for i in range(max(labels) + 1):\n        for keepIndex in nmsKeepIndicesList[i][0]:\n            nmsKeepIndices.append(allIndices[i][keepIndex])\n    assert len(nmsKeepIndices) == len(set(nmsKeepIndices))\n"]]}
{"hexsha": "f69263d3923b67987b690c6d3a20e27e2a4ab1f8", "ext": "py", "lang": "Python", "content": "def print_corpus_hard_core_stats(name, corpus):\n    if corpus:\n        print(name + \" corpus stats:\")\n        print(\"\\t#documents: {}\".format(len(corpus)))\n        print(\"\\t#relations total: {}\".format(sum(1 for r in corpus.relations())))\n        print(\"\\t#relations prot<-->loc: {}\".format(sum(1 for r in corpus.relations() if r.class_id == REL_PRO_LOC_ID)))\n        entity_counter = Counter()\n        for e in corpus.entities():\n            entity_counter.update([e.class_id])\n        print(\"\\t#entities: {}\".format(entity_counter))\n\n        print_corpus_pipeline_dependent_stats(corpus)\n        print()", "fn_id": 10, "class_fn": false, "repo": "Rostlab/LocText", "file": "loctext/learning/train.py", "last_update_at": "2019-02-19T02:54:32+00:00", "question_id": "f69263d3923b67987b690c6d3a20e27e2a4ab1f8_10", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def print_corpus_hard_core_stats(name, corpus):\n    if corpus:\n        print(name + ' corpus stats:')\n        print('\\t#documents: {}'.format(len(corpus)))\n        print('\\t#relations total: {}'.format(sum((1 for r in corpus.relations()))))\n        print('\\t#relations prot<-->loc: {}'.format(sum((1 for r in corpus.relations() if r.class_id == REL_PRO_LOC_ID))))\n        entity_counter = Counter()\n        for e in corpus.entities():\n            entity_counter.update([e.class_id])\n        print('\\t#entities: {}'.format(entity_counter))\n        print_corpus_pipeline_dependent_stats(corpus)\n"]]}
{"hexsha": "f114f80f70c62e5d9633744cc3ff9756e5ebf407", "ext": "py", "lang": "Python", "content": "def test_modern_signin(user_signin, user_signup, user_create, user_model):\n\n    user = user_create(attributes={'email': 'user@host.com'})\n    user.delete()\n\n    # login with wrong credentials\n    response = user_signin(user, {'username': 'nobody'})\n    assert response.status_code == 200\n    assert b'Please enter a correct username and password' in response.content\n\n    # create deactivated test user\n    response = user_signup(user)\n    assert response['location'].endswith(reverse('ok'))\n\n    # inactive user login\n    response = user_signin(user)\n    assert (\n            b'This account is inactive.' in response.content or\n            b'Please enter a correct username and password' in response.content)\n\n    # activate user and try to login again\n    assert user_model.objects.count() == 1\n    user_model.objects.all().update(is_active=True)\n    response = user_signin(user)\n    assert response['location'].endswith(reverse('ok'))\n\n    # how about to login when user is already signed in?\n    response = user_signin(user, client=response.client)\n    assert response['location'].endswith(reverse('fail'))\n\n    response.client.logout()\n\n    # more than one user with this e-mail\n    user_create(attributes={'email': user.email})\n    # user_model.objects.create(username='dummy', )\n    response = user_signin(user)\n\n    assert b'There is more than one user with this e-mail.' in response.content", "fn_id": 2, "class_fn": false, "repo": "idlesign/django-sitegate", "file": "sitegate/tests/test_flow_modern.py", "last_update_at": "2019-12-26T03:56:42+00:00", "question_id": "f114f80f70c62e5d9633744cc3ff9756e5ebf407_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_modern_signin(user_signin, user_signup, user_create, user_model):\n    user = user_create(attributes={'email': 'user@host.com'})\n    user.delete()\n    response = user_signin(user, {'username': 'nobody'})\n    assert response.status_code == 200\n    assert b'Please enter a correct username and password' in response.content\n    response = user_signup(user)\n    assert response['location'].endswith(reverse('ok'))\n    response = user_signin(user)\n    assert b'This account is inactive.' in response.content or b'Please enter a correct username and password' in response.content\n    assert user_model.objects.count() == 1\n    user_model.objects.all().update(is_active=True)\n    response = user_signin(user)\n    assert response['location'].endswith(reverse('ok'))\n    response = user_signin(user, client=response.client)\n    assert response['location'].endswith(reverse('fail'))\n    response.client.logout()\n    user_create(attributes={'email': user.email})\n    response = user_signin(user)\n"]]}
{"hexsha": "811e07607ad3d7d12ad096319861ae130782bc4f", "ext": "py", "lang": "Python", "content": "def dy(f, x, pcov, jac=None, n_samples=1e6, seed=42):\n    \"\"\"\n    Data una variabile aleatoria x, calcola matrice di covarianza della\n    variabile aleatoria y=f(x). Nota che la matrice di covarianza corrisponde\n    all'errore al quadrato, di conseguenza in caso di funzione da R^n->R\n    si deve fare la radice per ottenere l'errore\n\n    Il calcolo di default \u00e8 fatto probabilisticamente, ovvero non si propaga\n    l'errore usando la derivata ma si fa un sampling dalla distribuzione della x,\n    poi successivamente si ricostruisce la matrice di convarianza della y.\n    Questo metodo \u00e8 esatto e funziona anche se la funzione f \u00e8 in presenza di\n    un massimo o un minimo, tuttavia in questi casi la distribuzione della y\n    non \u00e8 pi\u00f9 gaussiana e vanno trattati con cura, la funzione notifica questo\n    con un warning.\n    L'unico problema di questo metodo \u00e8 che potrebbe essere lento, sopratutto\n    nel caso di funzioni f molto complicate e/o con output in alta dimensione,\n    se la funzione risulta lenta si pu\u00f2 abbassare il parametro n_samples, \n    tenendo conto del fatto che l'errore relativo su ciascun elemento della\n    matrice di covarianza va come 1/sqrt(n_samples), di default n_samples=1e6 \n    cosi' l'errore \u00e8 sulla terza cifra.\n\n    Se si vuole propagare gli errori col metodo \"classico\" si pu\u00f2 passare\n    come argomento in jac una funzione che calcola la jacobiana nel punto x,\n    un buon pacchetto per calcolare la jacobiana senza smattare \u00e8 jax,\n    sviluppato da google: https://github.com/google/jax\n\n    Args:\n        f(x, y, ...): funzione R^n->R^m che restituisce y=f(x)\n        x (tupla, array o numpy array): indica il punto in cui calcolare\n            la matrice di covarianza\n        pcov (2d array): Matrice di covarianza della variabile aleatoria x\n        jac (Callable, optional): Funzione che restituisce la matrice jacobiana\n            della funzione f in un punto x. Defaults to None\n        n_samples ([int, float], optional): Samples to draw from f. Defaults to 1e6.\n        seed (int, optional): seed of the random number generator. Defaults to 42.\n\n\n    Returns:\n        [float, 2d array]: Matrice di covarianza di y=f(x)\n\n    Es: Calcolo dell'errore su y=f(x)=x/(1+x**2) in x=2 +- 0.1\n    In questo caso la matrice di covarianza (cov) \u00e8 uno scalare tale che cov==dx**2\n    dove == indica una definizione e dx indica l'errore sulla x, quindi:\n    >>> import menzalib as mz\n    >>> def f(x):\n            return x/(1+x**2)\n    >>> mz.dy(f, 2, 0.1**2)\n   \t0.012000000000000004\n    \"\"\"\n\n    x, pcov = jnp.array(x, ndmin=1, dtype=jnp.float64), jnp.array(pcov, ndmin=2, dtype=jnp.float64)\n\n    # Vedo quanti argomenti ha f e li immetto come vettore x\n\n    \n    if x.ndim!=0 and len(signature(f).parameters) == len(x): \n        g = lambda x: f(*x)\n    else:\n        g = f\n\n    # Calcolo l'errore standard\n    if jac is not None:\n        J=jac(x)\n        return J@pcov@J.T\n\n    # Altrimenti calcolo quello statistico\n    key = random.PRNGKey(seed)\n    samples = random.multivariate_normal(key, mean=x, cov=pcov, shape=(int(n_samples),))\n    y = g(samples.T)\n\n    # Test per vedere se la distribuzione della y \u00e8 gaussiana\n    true_mean = g(x)\n    try:\n        sample_mean = jnp.mean(y, axis=1)\n        std = jnp.std(y, axis=1, ddof=1)/jnp.sqrt(n_samples)\n    except IndexError:\n        sample_mean = jnp.mean(y)\n        std = jnp.std(y, ddof=1)/jnp.sqrt(n_samples)\n    \n    if (normal_test(true_mean, sample_mean, std) < 1e-5).any():\n        message = f\"\\nThe output distribution of input x: {x} isn't normally distributed anymore\\n\"\n        message += f\"A possible cause is that the function f is very close to a maximum/minimum\"\n        warn(message, RuntimeWarning)\n\n    return np.asarray(jnp.cov(y, ddof=1))", "fn_id": 6, "class_fn": false, "repo": "LetteraUnica/menzalib", "file": "build/lib/menzalib/analisi_errori.py", "last_update_at": "2019-02-21T20:04:16+00:00", "question_id": "811e07607ad3d7d12ad096319861ae130782bc4f_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def dy(f, x, pcov, jac=None, n_samples=1000000.0, seed=42):\n    \"\"\"\n    Data una variabile aleatoria x, calcola matrice di covarianza della\n    variabile aleatoria y=f(x). Nota che la matrice di covarianza corrisponde\n    all'errore al quadrato, di conseguenza in caso di funzione da R^n->R\n    si deve fare la radice per ottenere l'errore\n\n    Il calcolo di default \u00e8 fatto probabilisticamente, ovvero non si propaga\n    l'errore usando la derivata ma si fa un sampling dalla distribuzione della x,\n    poi successivamente si ricostruisce la matrice di convarianza della y.\n    Questo metodo \u00e8 esatto e funziona anche se la funzione f \u00e8 in presenza di\n    un massimo o un minimo, tuttavia in questi casi la distribuzione della y\n    non \u00e8 pi\u00f9 gaussiana e vanno trattati con cura, la funzione notifica questo\n    con un warning.\n    L'unico problema di questo metodo \u00e8 che potrebbe essere lento, sopratutto\n    nel caso di funzioni f molto complicate e/o con output in alta dimensione,\n    se la funzione risulta lenta si pu\u00f2 abbassare il parametro n_samples, \n    tenendo conto del fatto che l'errore relativo su ciascun elemento della\n    matrice di covarianza va come 1/sqrt(n_samples), di default n_samples=1e6 \n    cosi' l'errore \u00e8 sulla terza cifra.\n\n    Se si vuole propagare gli errori col metodo \"classico\" si pu\u00f2 passare\n    come argomento in jac una funzione che calcola la jacobiana nel punto x,\n    un buon pacchetto per calcolare la jacobiana senza smattare \u00e8 jax,\n    sviluppato da google: https://github.com/google/jax\n\n    Args:\n        f(x, y, ...): funzione R^n->R^m che restituisce y=f(x)\n        x (tupla, array o numpy array): indica il punto in cui calcolare\n            la matrice di covarianza\n        pcov (2d array): Matrice di covarianza della variabile aleatoria x\n        jac (Callable, optional): Funzione che restituisce la matrice jacobiana\n            della funzione f in un punto x. Defaults to None\n        n_samples ([int, float], optional): Samples to draw from f. Defaults to 1e6.\n        seed (int, optional): seed of the random number generator. Defaults to 42.\n\n\n    Returns:\n        [float, 2d array]: Matrice di covarianza di y=f(x)\n\n    Es: Calcolo dell'errore su y=f(x)=x/(1+x**2) in x=2 +- 0.1\n    In questo caso la matrice di covarianza (cov) \u00e8 uno scalare tale che cov==dx**2\n    dove == indica una definizione e dx indica l'errore sulla x, quindi:\n    >>> import menzalib as mz\n    >>> def f(x):\n            return x/(1+x**2)\n    >>> mz.dy(f, 2, 0.1**2)\n   \t0.012000000000000004\n    \"\"\"\n    x, pcov = (jnp.array(x, ndmin=1, dtype=jnp.float64), jnp.array(pcov, ndmin=2, dtype=jnp.float64))\n    if x.ndim != 0 and len(signature(f).parameters) == len(x):\n        g = lambda x: f(*x)\n    else:\n        g = f\n    if jac is not None:\n        J = jac(x)\n        return J @ pcov @ J.T\n    key = random.PRNGKey(seed)\n    samples = random.multivariate_normal(key, mean=x, cov=pcov, shape=(int(n_samples),))\n    y = g(samples.T)\n    true_mean = g(x)\n    try:\n        sample_mean = jnp.mean(y, axis=1)\n        std = jnp.std(y, axis=1, ddof=1) / jnp.sqrt(n_samples)\n    except IndexError:\n        sample_mean = jnp.mean(y)\n        std = jnp.std(y, ddof=1) / jnp.sqrt(n_samples)\n    if (normal_test(true_mean, sample_mean, std) < 1e-05).any():\n        message = f\"\\nThe output distribution of input x: {x} isn't normally distributed anymore\\n\"\n        message += f'A possible cause is that the function f is very close to a maximum/minimum'\n        warn(message, RuntimeWarning)\n"]]}
{"hexsha": "d0fc5b2a0582cf1093b38de0c2b95db3cbd5563a", "ext": "py", "lang": "Python", "content": "def run(args):\n    if args.layout:\n        import json\n        args.attributes = True\n        # Open the document, read the JSON\n        layout = args.layout\n        if not ':' in layout:\n            layout = 'file:' + layout\n        timelineDoc = urllib.request.urlopen(layout)\n        timelineData = json.load(timelineDoc)\n        # Get all componentIds mentioned in the constraints\n        layoutComponentIds = list(map((lambda constraint: constraint['constraintId']), timelineData['constraints']))\n        # Store a set of these into the ref-checker class\n        RefDelegate2Immerse.constraintIds = set(layoutComponentIds)\n    if not args.realtime:\n        clock = clocks.CallbackPausableClock(clocks.FastClock())\n    else:\n        clock = clocks.CallbackPausableClock(clocks.SystemClock())\n    \n    d = Document(clock, idAttribute=NS_XML(\"id\"))\n    if args.tracefile:\n        d.setTracefile(args.tracefile)\n    if args.attributes:\n        d.setDelegateFactory(RefDelegate2Immerse)\n    d.setDelegateFactory(UpdateDelegate2Immerse, tag=NS_2IMMERSE(\"update\"))\n    try:\n        url = args.document\n        if not ':' in url:\n            # Shortcut to allow specifying local files\n            url = 'file:' + url\n        d.loadDocument(url)\n        d.prepareDocument()\n        d.runDocument()\n        assert d.isDocumentDone()\n    finally:\n        if args.dump:\n            print('--------------------')\n            print(d.dumps())\n        if args.dumpfile:\n            fp = open(args.dumpfile, 'w')\n            fp.write(d.dumps())\n            fp.close()\n        d.setTracefile(None)", "fn_id": 1, "class_fn": false, "repo": "josvos/timeline-service", "file": "timelineService/document.py", "last_update_at": "2019-08-02T11:37:25+00:00", "question_id": "d0fc5b2a0582cf1093b38de0c2b95db3cbd5563a_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def run(args):\n    if args.layout:\n        import json\n        args.attributes = True\n        layout = args.layout\n        if not ':' in layout:\n            layout = 'file:' + layout\n        timelineDoc = urllib.request.urlopen(layout)\n        timelineData = json.load(timelineDoc)\n        layoutComponentIds = list(map(lambda constraint: constraint['constraintId'], timelineData['constraints']))\n        RefDelegate2Immerse.constraintIds = set(layoutComponentIds)\n    if not args.realtime:\n        clock = clocks.CallbackPausableClock(clocks.FastClock())\n    else:\n        clock = clocks.CallbackPausableClock(clocks.SystemClock())\n    d = Document(clock, idAttribute=NS_XML('id'))\n    if args.tracefile:\n        d.setTracefile(args.tracefile)\n    if args.attributes:\n        d.setDelegateFactory(RefDelegate2Immerse)\n    d.setDelegateFactory(UpdateDelegate2Immerse, tag=NS_2IMMERSE('update'))\n    try:\n        url = args.document\n        if not ':' in url:\n            url = 'file:' + url\n        d.loadDocument(url)\n        d.prepareDocument()\n        d.runDocument()\n        assert d.isDocumentDone()\n    finally:\n        if args.dump:\n            print('--------------------')\n            print(d.dumps())\n        if args.dumpfile:\n            fp = open(args.dumpfile, 'w')\n            fp.write(d.dumps())\n            fp.close()\n"]]}
{"hexsha": "291f843a1d44829c3b2e71f3b304e4751fc07586", "ext": "py", "lang": "Python", "content": "def parse_theory(lines, **debuginfo):\n    lines = remove_comments_and_add_padding(lines)\n    rules = parse_lines_to_rules(lines, **debuginfo)\n    lines = erase_rules_from_lines(rules, lines, **debuginfo)\n    facts = parse_lines_to_facts(lines, **debuginfo)\n    return {'facts': facts, 'rules': rules}", "fn_id": 8, "class_fn": false, "repo": "fritzo/pomagma", "file": "src/compiler/parser.py", "last_update_at": "2019-06-11T16:07:31+00:00", "question_id": "291f843a1d44829c3b2e71f3b304e4751fc07586_8", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def parse_theory(lines, **debuginfo):\n    lines = remove_comments_and_add_padding(lines)\n    rules = parse_lines_to_rules(lines, **debuginfo)\n    lines = erase_rules_from_lines(rules, lines, **debuginfo)\n    facts = parse_lines_to_facts(lines, **debuginfo)\n"]]}
{"hexsha": "7cb73d7b4164b49ffab48fc8e065291b135db1c5", "ext": "py", "lang": "Python", "content": "@transactional\ndef _confirm_payment(payment_record):\n    secure_user_id = get_system_account_user_id(SECURE_USER_NAME)\n    # \u786e\u8ba4\u91d1\u989d\u4e3a\u8ba2\u5355\u91d1\u989d - \u5df2\u9000\u6b3e\u91d1\u989d\n    amount = payment_record.amount - payment_record.refunded_amount\n    event_id1 = zyt_bookkeeping(EventType.TRANSFER_OUT_FROZEN, payment_record.sn, secure_user_id, amount)\n    event_id2 = zyt_bookkeeping(EventType.TRANSFER_IN, payment_record.sn, payment_record.payee_id, amount)\n\n    transit_transaction_state(payment_record.tx_id, PaymentTxState.SECURED, PaymentTxState.SUCCESS,\n                              [event_id1, event_id2])", "fn_id": 11, "class_fn": false, "repo": "webee/pay", "file": "api_site/src/api_x/zyt/biz/pay/__init__.py", "last_update_at": "2019-10-14T11:51:49+00:00", "question_id": "7cb73d7b4164b49ffab48fc8e065291b135db1c5_11", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@transactional\ndef _confirm_payment(payment_record):\n    secure_user_id = get_system_account_user_id(SECURE_USER_NAME)\n    amount = payment_record.amount - payment_record.refunded_amount\n    event_id1 = zyt_bookkeeping(EventType.TRANSFER_OUT_FROZEN, payment_record.sn, secure_user_id, amount)\n    event_id2 = zyt_bookkeeping(EventType.TRANSFER_IN, payment_record.sn, payment_record.payee_id, amount)\n"]]}
{"hexsha": "eae5fb61c5fd7fee54c4fdfbe746e2eb690eafd3", "ext": "py", "lang": "Python", "content": "def main():\n    # start = (90, 100)\n    # goal = (100, 114)\n    # Spawn\n    start = (29, 65)\n    goal = (154, 114)\n    # Ramp\n    # start = (32, 51)\n    # goal = (150, 129)\n    # map_grid = np.loadtxt(\"AutomatonLE.txt\", delimiter=\"\").astype(int)\n    grid = []\n    with open(\"../AutomatonLE.txt\") as f:\n        for line in f.readlines():\n            values = [int(i) for i in list(line.strip())]\n            grid.append(values)\n    # print(grid)\n    map_grid = np.asarray(grid)\n    # print(map_grid)\n\n    path = []\n    with open(\"../path.txt\") as f:\n        for line in f.readlines():\n            x, y = line.split(\",\")\n            path.append((int(x.strip()), int(y.strip())))\n    print()\n    # print(map_grid.shape)\n    plot(map_grid, route=path, start=start, goal=goal)", "fn_id": 1, "class_fn": false, "repo": "BurnySc2/rust-python-pyo3-test", "file": "src/plot_automaton.py", "last_update_at": "2019-12-08T14:33:50+00:00", "question_id": "eae5fb61c5fd7fee54c4fdfbe746e2eb690eafd3_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main():\n    start = (29, 65)\n    goal = (154, 114)\n    grid = []\n    with open('../AutomatonLE.txt') as f:\n        for line in f.readlines():\n            values = [int(i) for i in list(line.strip())]\n            grid.append(values)\n    map_grid = np.asarray(grid)\n    path = []\n    with open('../path.txt') as f:\n        for line in f.readlines():\n            x, y = line.split(',')\n            path.append((int(x.strip()), int(y.strip())))\n    print()\n"]]}
{"hexsha": "821ecd85ba25c5ff3a4ed642fbe2f4c4e182a428", "ext": "py", "lang": "Python", "content": "def produce_feed(sermons, links, connection):\n    from feedgen.feed import FeedGenerator\n    from datetime import datetime\n    import pytz #lib to make datetime objects timezone aware.\n    print(\"========== PRODUCING FEED! ===========\")\n    org_name = cf.read_config('MAIN', 'org_name')\n    org_email = cf.read_config('MAIN', 'org_email')\n    org_link = cf.read_config('MAIN', 'org_link')\n    org_logo_link = \"https://s3-ap-southeast-2.amazonaws.com/sermon-skeleton/index.png\"\n    # org_logo_link = fl.url_for('static', filename='img/ico.ico')\n\n    fg = FeedGenerator()\n    fg.load_extension('podcast')\n\n    fg.title(org_name+\" Podcast\")\n    fg.author({'name': org_name, 'email': org_email})\n    fg.link(href=org_link)\n    fg.logo(org_logo_link)\n    fg.description(org_name+\" sermons. Available for all.\")\n    fg.language('en')\n\n    fg.podcast.itunes_category('Religion & Spirituality', 'Christianity')\n    fg.podcast.itunes_explicit(\"clean\")\n\n    for sermon in sermons:\n        fe = fg.add_entry()\n        fe.id(links[sermon.id][0])\n        fe.title(sermon.title)\n        if sermon.description == '':\n            fe.description(\"No description for this sermon.\")\n        else:\n            fe.description(description=sermon.description, isSummary=True)\n            print(sermon.description)\n        fe.enclosure(links[sermon.id][0], str(sermon.length), 'audio/mpeg')\n        \n        # published takes in a datetime object, but we record date (time is\n        # irrelevant...) so we need to instantiate a time to supply Feedgen\n        date = datetime.combine(sermon.date_given, datetime.min.time())\n        timezone = pytz.timezone(\"Australia/Sydney\")\n        date_tz = timezone.localize(date)\n        fe.published(date_tz)\n\n    fg.rss_file('podcast.xml')\n    uploaded = connection.upload_resource('podcast.xml', 'xml', 'podcast.xml')\n    if not uploaded:\n        print(\"false for upload\")\n        old_podcast = connection.get_obj('podcast.xml')\n        print(\"current object: \"+ str(old_podcast))\n        print(\"will we delete? \"+ str(connection.rm_objs([old_podcast]) ))\n        print(\"Trying again... \"+ str(connection.upload_resource('podcast.xml', 'xml', 'podcast.xml')))\n\n    else:\n        # initial run case\n        pass", "fn_id": 1, "class_fn": false, "repo": "bcartwri96/sermon-skeleton", "file": "src/controllers/helper.py", "last_update_at": "2019-01-21T03:11:14+00:00", "question_id": "821ecd85ba25c5ff3a4ed642fbe2f4c4e182a428_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def produce_feed(sermons, links, connection):\n    from feedgen.feed import FeedGenerator\n    from datetime import datetime\n    import pytz\n    print('========== PRODUCING FEED! ===========')\n    org_name = cf.read_config('MAIN', 'org_name')\n    org_email = cf.read_config('MAIN', 'org_email')\n    org_link = cf.read_config('MAIN', 'org_link')\n    org_logo_link = 'https://s3-ap-southeast-2.amazonaws.com/sermon-skeleton/index.png'\n    fg = FeedGenerator()\n    fg.load_extension('podcast')\n    fg.title(org_name + ' Podcast')\n    fg.author({'name': org_name, 'email': org_email})\n    fg.link(href=org_link)\n    fg.logo(org_logo_link)\n    fg.description(org_name + ' sermons. Available for all.')\n    fg.language('en')\n    fg.podcast.itunes_category('Religion & Spirituality', 'Christianity')\n    fg.podcast.itunes_explicit('clean')\n    for sermon in sermons:\n        fe = fg.add_entry()\n        fe.id(links[sermon.id][0])\n        fe.title(sermon.title)\n        if sermon.description == '':\n            fe.description('No description for this sermon.')\n        else:\n            fe.description(description=sermon.description, isSummary=True)\n            print(sermon.description)\n        fe.enclosure(links[sermon.id][0], str(sermon.length), 'audio/mpeg')\n        date = datetime.combine(sermon.date_given, datetime.min.time())\n        timezone = pytz.timezone('Australia/Sydney')\n        date_tz = timezone.localize(date)\n        fe.published(date_tz)\n    fg.rss_file('podcast.xml')\n    uploaded = connection.upload_resource('podcast.xml', 'xml', 'podcast.xml')\n    if not uploaded:\n        print('false for upload')\n        old_podcast = connection.get_obj('podcast.xml')\n        print('current object: ' + str(old_podcast))\n        print('will we delete? ' + str(connection.rm_objs([old_podcast])))\n        print('Trying again... ' + str(connection.upload_resource('podcast.xml', 'xml', 'podcast.xml')))\n    else:\n"]]}
{"hexsha": "e92e3c9656813cdfb0f28d57fec510c2fd4e1cf2", "ext": "py", "lang": "Python", "content": "def test_replace_in_file_regex(tmp_path):\n    original = \" * @see https://unite.org/en/developer-reference#version\"\n    expected_result = \" * @see https://docs.unit-e.io/reference/p2p/version.html\"\n\n    file_name = tmp_path / \"test\"\n    with file_name.open(\"w\") as file:\n        file.write(original)\n\n    Processor(ForkConfig()).replace_in_file_regex(file_name,\n            r\"https://unite.org/en/developer-reference#(\\w+)\",\n            r\"https://docs.unit-e.io/reference/p2p/\\1.html\")\n\n    with file_name.open() as result_file:\n        result = result_file.read()\n\n    assert result == expected_result", "fn_id": 3, "class_fn": false, "repo": "cornelius/unit-e-clonemachine", "file": "test_processor.py", "last_update_at": "2019-05-03T15:15:18+00:00", "question_id": "e92e3c9656813cdfb0f28d57fec510c2fd4e1cf2_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_replace_in_file_regex(tmp_path):\n    original = ' * @see https://unite.org/en/developer-reference#version'\n    expected_result = ' * @see https://docs.unit-e.io/reference/p2p/version.html'\n    file_name = tmp_path / 'test'\n    with file_name.open('w') as file:\n        file.write(original)\n    Processor(ForkConfig()).replace_in_file_regex(file_name, 'https://unite.org/en/developer-reference#(\\\\w+)', 'https://docs.unit-e.io/reference/p2p/\\\\1.html')\n    with file_name.open() as result_file:\n        result = result_file.read()\n"]]}
{"hexsha": "79d852c09bad4e71f2e3342e4ab8b2c72f245488", "ext": "py", "lang": "Python", "content": "def join_bbox(bbox1, bbox2):\n\tx1_t, y1_t, x2_t, y2_t = bbox1[0], bbox1[1], bbox1[2]+bbox1[0], bbox1[3]+bbox1[1]\n\tx1_p, y1_p, x2_p, y2_p = bbox2[0], bbox2[1], bbox2[2]+bbox2[0], bbox2[3]+bbox2[1]\n\t\n\t# x1_n = max(x1_t, x1_p)\n\t# y1_n = max(y1_t, y1_p)\n\t# x2_n = min(x2_t, x2_p)\n\t# y2_n = min(y2_t, y2_p)\n\n\tx1_n = min(x1_t, x1_p)\n\ty1_n = min(y1_t, y1_p)\n\tx2_n = max(x2_t, x2_p)\n\ty2_n = max(y2_t, y2_p)\n\n\t# x1_n = (x1_t + x1_p)//2\n\t# y1_n = (y1_t + y1_p)//2\n\t# x2_n = (x2_t + x2_p)//2\n\t# y2_n = (y2_t + y2_p)//2\t\n\n\treturn x1_n, y1_n, x2_n - x1_n, y2_n - y1_n", "fn_id": 0, "class_fn": false, "repo": "prakharg24/object_detection", "file": "scripts/join_bbox.py", "last_update_at": "2019-04-02T14:23:20+00:00", "question_id": "79d852c09bad4e71f2e3342e4ab8b2c72f245488_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def join_bbox(bbox1, bbox2):\n    x1_t, y1_t, x2_t, y2_t = (bbox1[0], bbox1[1], bbox1[2] + bbox1[0], bbox1[3] + bbox1[1])\n    x1_p, y1_p, x2_p, y2_p = (bbox2[0], bbox2[1], bbox2[2] + bbox2[0], bbox2[3] + bbox2[1])\n    x1_n = min(x1_t, x1_p)\n    y1_n = min(y1_t, y1_p)\n    x2_n = max(x2_t, x2_p)\n    y2_n = max(y2_t, y2_p)\n"]]}
{"hexsha": "a4afb473731ae1947c4e12f7622e1506d4b79c12", "ext": "py", "lang": "Python", "content": "@route('/stop', method='POST')\ndef stop():\n    #global stop_variable\n    #stop_variable = request.forms.get('submit')\n    #stop_variable = True\n    #print(stop_variable)\n    button_pressed.put(1)\n    print(button_pressed)\n    return \"stopped\"", "fn_id": 1, "class_fn": false, "repo": "prashant0079/Facial-Recognition", "file": "main.py", "last_update_at": "2019-06-11T12:23:46+00:00", "question_id": "a4afb473731ae1947c4e12f7622e1506d4b79c12_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@route('/stop', method='POST')\ndef stop():\n    button_pressed.put(1)\n    print(button_pressed)\n"]]}
{"hexsha": "8aac7ad2641c37bd8f65034205a1512380e6f979", "ext": "py", "lang": "Python", "content": "@pytest.mark.parametrize('env_vars, expected', [\n    (dict(), None),\n    (dict(CI='true'), None),\n    (dict(GCLOUD_PROJECT='example'), 'It is GCP but deal is enabled'),\n    (dict(LAMBDA_TASK_ROOT='/home/'), 'It is AWS but deal is enabled'),\n])\ndef test_enable__warnings(restore_state, env_vars, set_env_vars, expected):\n    os.environ.clear()\n    set_env_vars(env_vars)\n    ewarn = RuntimeWarning if expected else None\n    with pytest.warns(ewarn) as warns:\n        deal.enable()\n    if expected:\n        assert len(warns) == 1\n        assert str(warns[0].message) == f'{expected}. Is it intentional?'\n    else:\n        assert len(warns) == 0\n\n    with pytest.warns(None) as warns:\n        deal.enable(warn=False)\n    assert len(warns) == 0", "fn_id": 11, "class_fn": false, "repo": "orsinium/condition", "file": "tests/test_state.py", "last_update_at": "2019-05-07T08:02:20+00:00", "question_id": "8aac7ad2641c37bd8f65034205a1512380e6f979_11", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.mark.parametrize('env_vars, expected', [(dict(), None), (dict(CI='true'), None), (dict(GCLOUD_PROJECT='example'), 'It is GCP but deal is enabled'), (dict(LAMBDA_TASK_ROOT='/home/'), 'It is AWS but deal is enabled')])\ndef test_enable__warnings(restore_state, env_vars, set_env_vars, expected):\n    os.environ.clear()\n    set_env_vars(env_vars)\n    ewarn = RuntimeWarning if expected else None\n    with pytest.warns(ewarn) as warns:\n        deal.enable()\n    if expected:\n        assert len(warns) == 1\n        assert str(warns[0].message) == f'{expected}. Is it intentional?'\n    else:\n        assert len(warns) == 0\n    with pytest.warns(None) as warns:\n        deal.enable(warn=False)\n"]]}
{"hexsha": "0250c17ee0f5b6ecbb27511538c3b3e5ff4e7c73", "ext": "py", "lang": "Python", "content": "def read_forcefield_template(template_filename):\n    \"\"\"Read-in the forcefield template. The template is constructed from a functional forcefield file by replacing all optimizable numerical values with variable names enclosed within dual angled brackets << and >>.\n\n    :param template_filename: Name of the forcefield template file to be read-in\n    :type template_filename: str\n    \"\"\"\n    while True: # Force-read the template forcefield. This will loop until something is read-in. This is required if multiple ranks read the same file at the same time\n        time.sleep(np.random.rand())\n        with open(template_filename) as forcefield_template_file:\n            template_string = forcefield_template_file.read()\n        if len(template_string) > 0:\n            break\n\n    return template_string", "fn_id": 1, "class_fn": false, "repo": "sctiwari/EZFF_ASE", "file": "ezff/ffio.py", "last_update_at": "2019-04-02T22:50:40+00:00", "question_id": "0250c17ee0f5b6ecbb27511538c3b3e5ff4e7c73_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def read_forcefield_template(template_filename):\n    \"\"\"Read-in the forcefield template. The template is constructed from a functional forcefield file by replacing all optimizable numerical values with variable names enclosed within dual angled brackets << and >>.\n\n    :param template_filename: Name of the forcefield template file to be read-in\n    :type template_filename: str\n    \"\"\"\n    while True:\n        time.sleep(np.random.rand())\n        with open(template_filename) as forcefield_template_file:\n            template_string = forcefield_template_file.read()\n        if len(template_string) > 0:\n            break\n"]]}
{"hexsha": "48057c1f8910600a4abc42782b3354be12d45d0d", "ext": "py", "lang": "Python", "content": "def fetch_environment_json(args, text):\n    # Load or extract environment.json\n    if args.env_json_path:\n        with open(args.env_json_path) as f:\n            env = json.load(f)\n    else:\n        env = None\n        start = 0\n        while True:\n            start = text.find(\"\\n+ cat /\", start)\n            if start == -1: break\n            start = text.find(\"/environment.json\\n\", start)\n            if start == -1: break\n            start = text.find(\"{\", start)\n            end = text.find(\"\\n}\", start)\n            j = text[start:end+2]\n            start = end\n            env = json.loads(j)\n\n    if not env:\n        log.error(\"environment.json has not been created yet or the build failed earlier\")\n        sys.exit(1)\n\n    return env", "fn_id": 2, "class_fn": false, "repo": "dirkmueller/socok8s", "file": "files/misc-tools/parallelssh/tool.py", "last_update_at": "2019-08-08T09:43:41+00:00", "question_id": "48057c1f8910600a4abc42782b3354be12d45d0d_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def fetch_environment_json(args, text):\n    if args.env_json_path:\n        with open(args.env_json_path) as f:\n            env = json.load(f)\n    else:\n        env = None\n        start = 0\n        while True:\n            start = text.find('\\n+ cat /', start)\n            if start == -1:\n                break\n            start = text.find('/environment.json\\n', start)\n            if start == -1:\n                break\n            start = text.find('{', start)\n            end = text.find('\\n}', start)\n            j = text[start:end + 2]\n            start = end\n            env = json.loads(j)\n    if not env:\n        log.error('environment.json has not been created yet or the build failed earlier')\n        sys.exit(1)\n"]]}
{"hexsha": "2d7deba4f204f032e24a74feb1a47e420a420faf", "ext": "py", "lang": "Python", "content": "def obj(beta, lambd = .1, x=X_train, y=y_train, h = .5):\n    \"\"\"\n    Function for calculating the objective function for the huberized hinge loss.\n    \n    Inputs:\n        beta: numpy vector\n            a vector of length d corresponding to the beta vector\n        lambd: int\n            lambda, the penalization constant. Default = .1\n        x: numpy matrix\n            a matrix of size nxd\n        y: numpy matrix\n            a matrix of size nx1\n        h: float\n            huberized hinge loss parameter. Default = .5\n    \n    Returns:\n        objective value: float, the objective value.\n    \"\"\"\n    n, d = x.shape\n    o = np.zeros(n)\n    o[y*x.dot(beta) < 1 - h] = (1 - y*x.dot(beta))[y*x.dot(beta) < 1 - h]\n    o[abs(1 - y*x.dot(beta)) <= h] = ((1 + h - y*(x.dot(beta)))**2 / (4 * h))[abs(1 - y*x.dot(beta)) <= h]\n    return  (1.0/n) * np.sum(o) + lambd * np.sum(beta**2)", "fn_id": 0, "class_fn": false, "repo": "pcwright1/my_linear_svm", "file": "code/svm.py", "last_update_at": "2019-04-23T13:48:17+00:00", "question_id": "2d7deba4f204f032e24a74feb1a47e420a420faf_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def obj(beta, lambd=0.1, x=X_train, y=y_train, h=0.5):\n    \"\"\"\n    Function for calculating the objective function for the huberized hinge loss.\n    \n    Inputs:\n        beta: numpy vector\n            a vector of length d corresponding to the beta vector\n        lambd: int\n            lambda, the penalization constant. Default = .1\n        x: numpy matrix\n            a matrix of size nxd\n        y: numpy matrix\n            a matrix of size nx1\n        h: float\n            huberized hinge loss parameter. Default = .5\n    \n    Returns:\n        objective value: float, the objective value.\n    \"\"\"\n    n, d = x.shape\n    o = np.zeros(n)\n    o[y * x.dot(beta) < 1 - h] = (1 - y * x.dot(beta))[y * x.dot(beta) < 1 - h]\n    o[abs(1 - y * x.dot(beta)) <= h] = ((1 + h - y * x.dot(beta)) ** 2 / (4 * h))[abs(1 - y * x.dot(beta)) <= h]\n"]]}
{"hexsha": "5ff29770c9534576e0f205848798ac3b81eb79a0", "ext": "py", "lang": "Python", "content": "def general_stats(x, rel_threshold_outliers=2.5):\n    r\"\"\"Computes some general statistical properties of a set of values\n    :math:`\\mathbf{X}=\\{x_j\\}_{j=1}^n`\n\n    * quartiles :math:`Q_1(\\mathbf{X}),\\,Q_2(\\mathbf{X}),\\,Q_3(\\mathbf{X})`\n    * inter-quartile range\n        :math:`IQR(\\mathbf{X}) = Q_3(\\mathbf{X}) - Q_1(\\mathbf{X})`\n    * outlier threshold :math:`\\theta = \\beta \\cdot IQR(\\mathbf{X})`\n    * mean: :math:`\\mu_\\mathbf{x'} = ave(\\mathbf{X'})`\n    * standard deviation. :math:`\\sigma_\\mathbf{x'} = std(\\mathbf{X'})`\n    * mean/IQR: :math:`\\mu_\\mathbf{x'}/IQR(\\mathbf{X})`\n\n    where :math:`\\mathbf{X}'=\\{x \\in \\mathbf{X} \\,:\\,\\, |x-m_x| < \\theta\\}`\n    is the set of points without its outliers.\n\n    :param x: vector of values\n    :param rel_threshold_outliers: outlier threshold :math:`\\beta` relative to\n        the inter-quartile range.\n    :return: dictionary with general statistics\n    \"\"\"\n    quartiles = np.nanquantile(x, (0.25, 0.5, 0.75))\n    iqr = quartiles[2] - quartiles[0]\n    threshold = rel_threshold_outliers*iqr\n    is_ok = np.abs(x - quartiles[1]) < threshold\n    mean = x[is_ok].mean()\n    gen_stats = {'quartiles': quartiles,\n                 'threshold': threshold,\n                 'mean': mean,\n                 'std': x[is_ok].std(),\n                 'mean/iqr': mean/iqr}\n    return gen_stats", "fn_id": 5, "class_fn": false, "repo": "whigg/gnss_timeseries", "file": "gnss_timeseries/stats.py", "last_update_at": "2019-09-27T01:40:26+00:00", "question_id": "5ff29770c9534576e0f205848798ac3b81eb79a0_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def general_stats(x, rel_threshold_outliers=2.5):\n    \"\"\"Computes some general statistical properties of a set of values\n    :math:`\\\\mathbf{X}=\\\\{x_j\\\\}_{j=1}^n`\n\n    * quartiles :math:`Q_1(\\\\mathbf{X}),\\\\,Q_2(\\\\mathbf{X}),\\\\,Q_3(\\\\mathbf{X})`\n    * inter-quartile range\n        :math:`IQR(\\\\mathbf{X}) = Q_3(\\\\mathbf{X}) - Q_1(\\\\mathbf{X})`\n    * outlier threshold :math:`\\\\theta = \\\\beta \\\\cdot IQR(\\\\mathbf{X})`\n    * mean: :math:`\\\\mu_\\\\mathbf{x'} = ave(\\\\mathbf{X'})`\n    * standard deviation. :math:`\\\\sigma_\\\\mathbf{x'} = std(\\\\mathbf{X'})`\n    * mean/IQR: :math:`\\\\mu_\\\\mathbf{x'}/IQR(\\\\mathbf{X})`\n\n    where :math:`\\\\mathbf{X}'=\\\\{x \\\\in \\\\mathbf{X} \\\\,:\\\\,\\\\, |x-m_x| < \\\\theta\\\\}`\n    is the set of points without its outliers.\n\n    :param x: vector of values\n    :param rel_threshold_outliers: outlier threshold :math:`\\\\beta` relative to\n        the inter-quartile range.\n    :return: dictionary with general statistics\n    \"\"\"\n    quartiles = np.nanquantile(x, (0.25, 0.5, 0.75))\n    iqr = quartiles[2] - quartiles[0]\n    threshold = rel_threshold_outliers * iqr\n    is_ok = np.abs(x - quartiles[1]) < threshold\n    mean = x[is_ok].mean()\n    gen_stats = {'quartiles': quartiles, 'threshold': threshold, 'mean': mean, 'std': x[is_ok].std(), 'mean/iqr': mean / iqr}\n"]]}
{"hexsha": "85fbe81154e86cc8fbe011d9ee9e5188b8d4fcea", "ext": "py", "lang": "Python", "content": "def test_shortest_path():\n    test_node1 = Node(node_id=1, adjacency_dict={2: {'weight': 10, 'status': True}})\n    test_node2 = Node(node_id=2, adjacency_dict={3: {'weight': 5, 'status': True}})\n    test_node3 = Node(node_id=3, adjacency_dict={4: {'weight': 3, 'status': True}})\n    test_node4 = Node(node_id=4, adjacency_dict={1: {'weight': 6, 'status': True}})\n    test_node5 = Node(node_id=5, adjacency_dict={1: {'weight': 1, 'status': True},\n                                                 3: {'weight': 2, 'status': True}})\n    test_net = Network({test_node1.node_id: test_node1,\n                        test_node2.node_id: test_node2,\n                        test_node3.node_id: test_node3,\n                        test_node4.node_id: test_node4,\n                        test_node5.node_id: test_node5})\n\n    dijkstra = Dijkstra(graph=test_net, source=test_node1.node_id)\n    path, weight = dijkstra.shortest_path(destination=test_node3.node_id)\n    assert path == [1, 5, 3]\n    assert weight is 3\n\n    test_net.remove_node(test_node5.node_id)\n    dijkstra = Dijkstra(graph=test_net, source=test_node1.node_id)\n    path, weight = dijkstra.shortest_path(destination=test_node3.node_id)\n    assert path == [1, 4, 3]\n    assert weight is 9\n\n    test_net.remove_node(test_node4.node_id)\n    dijkstra = Dijkstra(graph=test_net, source=test_node1.node_id)\n    path, weight = dijkstra.shortest_path(destination=test_node3.node_id)\n    assert path == [1, 2, 3]\n    assert weight is 15\n\n    test_net.remove_node(test_node2.node_id)\n    dijkstra = Dijkstra(graph=test_net, source=test_node1.node_id)\n    path, weight = dijkstra.shortest_path(destination=test_node3.node_id)\n    assert path is None\n    assert weight == float('inf')", "fn_id": 2, "class_fn": false, "repo": "zspatter/network-simulation", "file": "tests/test_dijkstra.py", "last_update_at": "2019-02-11T19:42:28+00:00", "question_id": "85fbe81154e86cc8fbe011d9ee9e5188b8d4fcea_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_shortest_path():\n    test_node1 = Node(node_id=1, adjacency_dict={2: {'weight': 10, 'status': True}})\n    test_node2 = Node(node_id=2, adjacency_dict={3: {'weight': 5, 'status': True}})\n    test_node3 = Node(node_id=3, adjacency_dict={4: {'weight': 3, 'status': True}})\n    test_node4 = Node(node_id=4, adjacency_dict={1: {'weight': 6, 'status': True}})\n    test_node5 = Node(node_id=5, adjacency_dict={1: {'weight': 1, 'status': True}, 3: {'weight': 2, 'status': True}})\n    test_net = Network({test_node1.node_id: test_node1, test_node2.node_id: test_node2, test_node3.node_id: test_node3, test_node4.node_id: test_node4, test_node5.node_id: test_node5})\n    dijkstra = Dijkstra(graph=test_net, source=test_node1.node_id)\n    path, weight = dijkstra.shortest_path(destination=test_node3.node_id)\n    assert path == [1, 5, 3]\n    assert weight is 3\n    test_net.remove_node(test_node5.node_id)\n    dijkstra = Dijkstra(graph=test_net, source=test_node1.node_id)\n    path, weight = dijkstra.shortest_path(destination=test_node3.node_id)\n    assert path == [1, 4, 3]\n    assert weight is 9\n    test_net.remove_node(test_node4.node_id)\n    dijkstra = Dijkstra(graph=test_net, source=test_node1.node_id)\n    path, weight = dijkstra.shortest_path(destination=test_node3.node_id)\n    assert path == [1, 2, 3]\n    assert weight is 15\n    test_net.remove_node(test_node2.node_id)\n    dijkstra = Dijkstra(graph=test_net, source=test_node1.node_id)\n    path, weight = dijkstra.shortest_path(destination=test_node3.node_id)\n    assert path is None\n"]]}
{"hexsha": "d20aa03a15a837c91185bec2a28b723f48ec4b9e", "ext": "py", "lang": "Python", "content": "@app.route(\"/upload\", methods=[\"POST\"], cors=True)\n@app.pass_event\ndef upload_job_spec(event: Dict, body: str) -> Tuple[str, str, str]:\n    \"\"\"Send Job definition to process.\"\"\"\n    if event.get(\"isBase64Encoded\"):\n        body = base64.b64decode(body).decode()\n\n    jobid = get_hash(body=body, version=app_version)\n    body = json.loads(body)\n\n    # Check if we are not overwriding a mosaic\n    mosaicid = body.get(\"mosaicid\", jobid)\n\n    # TODO\n    # Validate schema\n    key = f\"jobs/{jobid}.json\"\n    bucket = os.environ[\"MOSAIC_BUCKET\"]\n    _aws_put_data(key, bucket, json.dumps(body).encode(\"utf-8\"))\n    return (\"OK\", \"text/plain\", mosaicid)", "fn_id": 0, "class_fn": false, "repo": "developmentseed/cogeo-watchbot", "file": "app/handler.py", "last_update_at": "2019-11-06T16:52:50+00:00", "question_id": "d20aa03a15a837c91185bec2a28b723f48ec4b9e_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@app.route('/upload', methods=['POST'], cors=True)\n@app.pass_event\ndef upload_job_spec(event: Dict, body: str) -> Tuple[str, str, str]:\n    \"\"\"Send Job definition to process.\"\"\"\n    if event.get('isBase64Encoded'):\n        body = base64.b64decode(body).decode()\n    jobid = get_hash(body=body, version=app_version)\n    body = json.loads(body)\n    mosaicid = body.get('mosaicid', jobid)\n    key = f'jobs/{jobid}.json'\n    bucket = os.environ['MOSAIC_BUCKET']\n    _aws_put_data(key, bucket, json.dumps(body).encode('utf-8'))\n"]]}
{"hexsha": "df89b374617f742546d6eb7e0fd0ae663bedfddc", "ext": "py", "lang": "Python", "content": "def load_data(dataset_name, directory_name):\n    \"\"\"\n    Load data in JSON format into memory\n    :param dataset_name: input dataset name\n    :param directory_name: input directory name\n    :return:\n    \"\"\"\n    filepath = os.path.join(directory_name, 'reviews_%s_5.json' % dataset_name)\n    if not os.path.exists(filepath):\n        download_data(dataset_name, directory_name)\n    data = []\n    with open(filepath, 'r') as f:\n        for line in f:                            # read file line by line\n            item_hash = hash(line)                # we will use this later for partitioning our data\n            item = json.loads(line)               # convert JSON string to Python dict\n            item['hash'] = item_hash              # add hash for identification purposes\n            data.append(item)\n    print(\"Loaded %d data for dataset %s\" % (len(data), dataset_name))\n    return data", "fn_id": 1, "class_fn": false, "repo": "SolangeUG/nltk-book", "file": "06-learning-to-classify-text/util/data_util.py", "last_update_at": "2019-01-24T05:52:02+00:00", "question_id": "df89b374617f742546d6eb7e0fd0ae663bedfddc_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def load_data(dataset_name, directory_name):\n    \"\"\"\n    Load data in JSON format into memory\n    :param dataset_name: input dataset name\n    :param directory_name: input directory name\n    :return:\n    \"\"\"\n    filepath = os.path.join(directory_name, 'reviews_%s_5.json' % dataset_name)\n    if not os.path.exists(filepath):\n        download_data(dataset_name, directory_name)\n    data = []\n    with open(filepath, 'r') as f:\n        for line in f:\n            item_hash = hash(line)\n            item = json.loads(line)\n            item['hash'] = item_hash\n            data.append(item)\n    print('Loaded %d data for dataset %s' % (len(data), dataset_name))\n"]]}
{"hexsha": "c9c10e0aa5b560f3cce9a55087728b0f5cccdc71", "ext": "py", "lang": "Python", "content": "def get_file_pairs_from_composition_wikitext(wikitext):\n    \"\"\"\n    CPDL Wikitext has lines like this:\n    *{{PostedDate|2014-11-24}} {{CPDLno|33477}} [[Media:Torrejon-A_este_sol_peregrino.pdf|{{pdf}}]] [[Media:Torrejon-A_este_sol_peregrino.mid|{{mid}}]] [[Media:Torrejon-A_este_sol_peregrino.mxl|{{XML}}]] [[Media:Torrejon-A_este_sol_peregrino.musx|{{F14}}]] (Finale 2014)\n    Look for these, and return ones that include an {{XML}} link. If there is also a PDF, return that too\n    \"\"\"\n    parsed = mwph.parse(wikitext['content'])\n\n    # Look for nodes which are {{CPDLno}} templates\n    cpdl_nodes = [template for template in parsed.filter_templates() if template.name == 'CPDLno']\n    cpdl_nodes.append(parsed.nodes[-1])\n\n    ret = []\n\n    # For each of these nodes, from the node to the next, see if there is\n    # a wikilink with {{XML}}. If so, return both the pdf in this range if it exists\n    # and the xml file\n    # e.g. nodes 3, 12, 15. We append the last node so that we can group them\n    # into 3-12, 12-15, 15-end\n    parsed_nodes = parsed.nodes\n    for i in range(len(cpdl_nodes)-1):\n        start = cpdl_nodes[i]\n        end = cpdl_nodes[i+1]\n        try:\n            start_i = parsed_nodes.index(start)\n            end_i = parsed_nodes.index(end)\n        except ValueError:\n            continue\n        relevant_nodes = parsed_nodes[start_i:end_i]\n        wikilinks = [n for n in relevant_nodes if isinstance(n, mwph.nodes.Wikilink)]\n        xml_templates = [str(n.title) for n in wikilinks if n.text == \"{{XML}}\"]\n        pdf_templates = [str(n.title) for n in wikilinks if n.text == \"{{pdf}}\"]\n\n        if len(xml_templates) == 1 and len(pdf_templates) in [0, 1]:\n            xml = xml_templates[0]\n            pdf = pdf_templates[0] if len(pdf_templates) else None\n            data = {\"xml\": xml.replace(\"Media:\", \"File:\")}\n            if pdf:\n                data[\"pdf\"] = pdf.replace(\"Media:\", \"File:\")\n\n            ret.append(data)\n\n    return ret", "fn_id": 4, "class_fn": false, "repo": "trompamusic/ce-data-import", "file": "ceimport/sites/cpdl.py", "last_update_at": "2019-10-02T19:06:08+00:00", "question_id": "c9c10e0aa5b560f3cce9a55087728b0f5cccdc71_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_file_pairs_from_composition_wikitext(wikitext):\n    \"\"\"\n    CPDL Wikitext has lines like this:\n    *{{PostedDate|2014-11-24}} {{CPDLno|33477}} [[Media:Torrejon-A_este_sol_peregrino.pdf|{{pdf}}]] [[Media:Torrejon-A_este_sol_peregrino.mid|{{mid}}]] [[Media:Torrejon-A_este_sol_peregrino.mxl|{{XML}}]] [[Media:Torrejon-A_este_sol_peregrino.musx|{{F14}}]] (Finale 2014)\n    Look for these, and return ones that include an {{XML}} link. If there is also a PDF, return that too\n    \"\"\"\n    parsed = mwph.parse(wikitext['content'])\n    cpdl_nodes = [template for template in parsed.filter_templates() if template.name == 'CPDLno']\n    cpdl_nodes.append(parsed.nodes[-1])\n    ret = []\n    parsed_nodes = parsed.nodes\n    for i in range(len(cpdl_nodes) - 1):\n        start = cpdl_nodes[i]\n        end = cpdl_nodes[i + 1]\n        try:\n            start_i = parsed_nodes.index(start)\n            end_i = parsed_nodes.index(end)\n        except ValueError:\n            continue\n        relevant_nodes = parsed_nodes[start_i:end_i]\n        wikilinks = [n for n in relevant_nodes if isinstance(n, mwph.nodes.Wikilink)]\n        xml_templates = [str(n.title) for n in wikilinks if n.text == '{{XML}}']\n        pdf_templates = [str(n.title) for n in wikilinks if n.text == '{{pdf}}']\n        if len(xml_templates) == 1 and len(pdf_templates) in [0, 1]:\n            xml = xml_templates[0]\n            pdf = pdf_templates[0] if len(pdf_templates) else None\n            data = {'xml': xml.replace('Media:', 'File:')}\n            if pdf:\n                data['pdf'] = pdf.replace('Media:', 'File:')\n            ret.append(data)\n"]]}
{"hexsha": "7ccc725acf9b7e6719083bd5d3c9a3289225526d", "ext": "py", "lang": "Python", "content": "def run(parsed_args):\n    sonos = common.get_sonos(parsed_args)\n    sonos.next()\n    change_track_common.send_notification(sonos)", "fn_id": 0, "class_fn": false, "repo": "RobinDeBaets/SonosScripts", "file": "sonosscripts/next.py", "last_update_at": "2019-11-21T20:22:01+00:00", "question_id": "7ccc725acf9b7e6719083bd5d3c9a3289225526d_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def run(parsed_args):\n    sonos = common.get_sonos(parsed_args)\n    sonos.next()\n"]]}
{"hexsha": "e1e4aadfcabe73126029872821aa334d109a995f", "ext": "py", "lang": "Python", "content": "def subplot(times, data, yname=\"\", title=\"\", **kwargs):\n  plt.figure(title)\n\n  if len(data.shape) <= 1:\n    simpleplot(times, data, yname, title, **kwargs)\n\n  else:\n    n_dims = data.shape[1]\n    for i in range(n_dims):\n      plt.subplot(n_dims * 100 + 11 + i)\n      if not i: plt.title(title)\n      plt.plot(times, data[:, i], **kwargs)\n      ax_id = 'XYZ'[i] if i < 3 else str(i)\n      plt.ylabel(\"%s %s\" % (ax_id, yname))\n\n    plt.xlabel(\"Time (s)\")\n\n    if 'label' in kwargs:\n      plt.legend()", "fn_id": 5, "class_fn": false, "repo": "pumaking/python_utils", "file": "plotu.py", "last_update_at": "2019-02-25T01:30:19+00:00", "question_id": "e1e4aadfcabe73126029872821aa334d109a995f_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def subplot(times, data, yname='', title='', **kwargs):\n    plt.figure(title)\n    if len(data.shape) <= 1:\n        simpleplot(times, data, yname, title, **kwargs)\n    else:\n        n_dims = data.shape[1]\n        for i in range(n_dims):\n            plt.subplot(n_dims * 100 + 11 + i)\n            if not i:\n                plt.title(title)\n            plt.plot(times, data[:, i], **kwargs)\n            ax_id = 'XYZ'[i] if i < 3 else str(i)\n            plt.ylabel('%s %s' % (ax_id, yname))\n        plt.xlabel('Time (s)')\n        if 'label' in kwargs:\n"]]}
{"hexsha": "5e3ad83c20d80570bad4f49c935e0ac2dcf12632", "ext": "pyw", "lang": "Python", "content": "def ToggleFullscreen():\n\tglobal_status[\"settings\"][\"display\"][\"fullscreen\"] = not global_status[\"settings\"][\"display\"][\"fullscreen\"]\n\tif global_status[\"settings\"][\"display\"][\"fullscreen\"]:\n\t\tglobal_status[\"player\"][\"pos\"][1] += GetSystemMetrics(1)-global_status[\"settings\"][\"display\"][\"size\"][1]\n\t\twindow = pygame.display.set_mode((GetSystemMetrics(0), GetSystemMetrics(1)), pygame.FULLSCREEN)\n\t\tglobal_status[\"settings\"][\"display\"][\"size\"] = [GetSystemMetrics(0), GetSystemMetrics(1)]\n\telse:\n\t\tglobal_status[\"player\"][\"pos\"][1] += 640-global_status[\"settings\"][\"display\"][\"size\"][1]\n\t\tglobal_status[\"settings\"][\"display\"][\"size\"] = [1024, 640]\n\t\twindow = pygame.display.set_mode((global_status[\"settings\"][\"display\"][\"size\"][0], global_status[\"settings\"][\"display\"][\"size\"][1]), pygame.RESIZABLE)\n\tif \"back\" in global_status[\"assets\"]: global_status[\"assets\"][\"back\"] = pygame.transform.scale(global_status[\"assets\"][\"back\"], global_status['settings']['display']['size']).convert()\n\tglobal_status[\"assets\"][\"mmback\"] = pygame.transform.scale(global_status[\"assets\"][\"mmback\"], global_status['settings']['display']['size']).convert()\n\tglobal_status['assets']['opacity'] = global_status['assets']['opacity'] = pygame.transform.scale(pygame.image.load('assets/ui/opacity.png'), global_status[\"settings\"][\"display\"][\"size\"])", "fn_id": 2, "class_fn": false, "repo": "jaobernardi/Quack", "file": "QuackRevisited.pyw", "last_update_at": "2019-06-08T17:30:21+00:00", "question_id": "5e3ad83c20d80570bad4f49c935e0ac2dcf12632_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def ToggleFullscreen():\n    global_status['settings']['display']['fullscreen'] = not global_status['settings']['display']['fullscreen']\n    if global_status['settings']['display']['fullscreen']:\n        global_status['player']['pos'][1] += GetSystemMetrics(1) - global_status['settings']['display']['size'][1]\n        window = pygame.display.set_mode((GetSystemMetrics(0), GetSystemMetrics(1)), pygame.FULLSCREEN)\n        global_status['settings']['display']['size'] = [GetSystemMetrics(0), GetSystemMetrics(1)]\n    else:\n        global_status['player']['pos'][1] += 640 - global_status['settings']['display']['size'][1]\n        global_status['settings']['display']['size'] = [1024, 640]\n        window = pygame.display.set_mode((global_status['settings']['display']['size'][0], global_status['settings']['display']['size'][1]), pygame.RESIZABLE)\n    if 'back' in global_status['assets']:\n        global_status['assets']['back'] = pygame.transform.scale(global_status['assets']['back'], global_status['settings']['display']['size']).convert()\n    global_status['assets']['mmback'] = pygame.transform.scale(global_status['assets']['mmback'], global_status['settings']['display']['size']).convert()\n"]]}
{"hexsha": "280f872f49d0aaa77bb8772fcb26ba2d7e6df157", "ext": "py", "lang": "Python", "content": "def send_message(msg_type, data):\n    panel_config = load_config()\n    ws = WebSocket()\n    ws.connect(\"ws://\" + panel_config['uri'][0] + \"/core\")\n    message = '{\"type\": \"' + msg_type + '\", \"data\":' + data + '}'\n    ws.send(message)\n    ws.recv()\n    ws.close()", "fn_id": 1, "class_fn": false, "repo": "unwisegeek/mycroft-panel", "file": "mycroft-panel.py", "last_update_at": "2019-06-26T12:37:49+00:00", "question_id": "280f872f49d0aaa77bb8772fcb26ba2d7e6df157_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def send_message(msg_type, data):\n    panel_config = load_config()\n    ws = WebSocket()\n    ws.connect('ws://' + panel_config['uri'][0] + '/core')\n    message = '{\"type\": \"' + msg_type + '\", \"data\":' + data + '}'\n    ws.send(message)\n    ws.recv()\n"]]}
{"hexsha": "3ccf6fc84327865b8aa888d62745e83f24193085", "ext": "py", "lang": "Python", "content": "def write_example_config(example_file_path: str):\n    \"\"\"\n    Writes an example config file using the config values declared so far\n\n    :param example_file_path: path to write to\n    \"\"\"\n    document = tomlkit.document()\n    for header_line in _get_header():\n        document.add(tomlkit.comment(header_line))\n    config_keys = _aggregate_config_values(ConfigValue.config_values)\n    _add_config_values_to_toml_object(document, config_keys)\n    _doc_as_str = document.as_string().replace(f'\"{_NOT_SET}\"', '')\n    with open(example_file_path, 'w') as stream:\n        stream.write(_doc_as_str)", "fn_id": 3, "class_fn": false, "repo": "etcher-be/elib_config", "file": "elib_config/_file/_config_example.py", "last_update_at": "2019-11-12T12:17:06+00:00", "question_id": "3ccf6fc84327865b8aa888d62745e83f24193085_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def write_example_config(example_file_path: str):\n    \"\"\"\n    Writes an example config file using the config values declared so far\n\n    :param example_file_path: path to write to\n    \"\"\"\n    document = tomlkit.document()\n    for header_line in _get_header():\n        document.add(tomlkit.comment(header_line))\n    config_keys = _aggregate_config_values(ConfigValue.config_values)\n    _add_config_values_to_toml_object(document, config_keys)\n    _doc_as_str = document.as_string().replace(f'\"{_NOT_SET}\"', '')\n    with open(example_file_path, 'w') as stream:\n"]]}
{"hexsha": "c472825b5f6c0668eb3307f778eca0bcc6c0718c", "ext": "py", "lang": "Python", "content": "def chunk(s):\n    w = u''\n    t0 = 0\n    for c in s:\n        if c.isdigit():\n            t1 = 1\n        elif c.isalpha():\n            if ord(c) < 256:\n                t1 = 2\n            else:\n                t1 = 3\n        else:\n            t1 = 0\n        if t0 != t1 and w:\n            yield w\n            w = u''\n        t0 = t1\n        w += c\n    if w:\n        yield w\n    return", "fn_id": 1, "class_fn": false, "repo": "euske/osmtools", "file": "addr/reg.py", "last_update_at": "2019-12-23T14:34:54+00:00", "question_id": "c472825b5f6c0668eb3307f778eca0bcc6c0718c_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def chunk(s):\n    w = u''\n    t0 = 0\n    for c in s:\n        if c.isdigit():\n            t1 = 1\n        elif c.isalpha():\n            if ord(c) < 256:\n                t1 = 2\n            else:\n                t1 = 3\n        else:\n            t1 = 0\n        if t0 != t1 and w:\n            yield w\n            w = u''\n        t0 = t1\n        w += c\n    if w:\n        yield w\n"]]}
{"hexsha": "711402f2be79eb5c292967d95f900d9626dcdb91", "ext": "py", "lang": "Python", "content": "def jsonToMySQL(host, user, passwd, db_name, table_name):\n    json_url = 'https://api.hearthstonejson.com/v1/latest/zhCN/cards.json'\n    json_response = requests.get(json_url)\n    #print (response.text)\n    json_data = json_response.json()\n\n    #link db\n    db = MySQLdb.connect(host, user, passwd, db_name, use_unicode=True, charset=\"utf8\")\n    cursor = db.cursor()\n\n    #delete already exist table\n    cursor.execute(\"DROP TABLE IF EXISTS \" + table_name)\n\n    #create table\n    sql_create_table = '''CREATE TABLE ''' + table_name + ''' (\n             hs_jsonId INT,\n             hs_dbfId INT,\n             hs_id VARCHAR(225),\n             hs_name VARCHAR(225),\n             hs_cost INT,\n             hs_rarity VARCHAR(225)) DEFAULT CHARSET=utf8'''\n\n    header_tag_list = ('dbfId','id','name','cost','rarity')\n    char_type_tags = ('id', 'name', 'rarity')\n\n    cursor.execute(sql_create_table)\n\n    #with open(json_file, 'r', encoding='UTF-8') as f:\n    #    json_data = json.load(f)\n\n    print (len(json_data))\n\n    for i in range(0, len(json_data), 1):\n    #for i in range(0, 10, 1):\n        '''\n        if 'dbfId' not in json_data[i] or 'name' not in json_data[i] or 'id' not in json_data[i]:\n            print(\"data missing: jsonId=\"+str(i))\n            continue\n        '''\n        data = {'id': i}\n        for header_tag in header_tag_list:\n            if header_tag in json_data[i]:\n                data[header_tag] = str(json_data[i][header_tag])\n\n        sql_pre_key = '(hs_jsonId'\n        sql_pre_value = '(' + str(i)\n        for key, value in data.items():\n            sql_pre_key = sql_pre_key + ', hs_' + key\n            if key in char_type_tags:\n                sql_pre_value = sql_pre_value + ', \"' + value + '\"'\n            else:\n                sql_pre_value = sql_pre_value + ', ' + value\n        sql_pre_key = sql_pre_key + ')'\n        sql_pre_value = sql_pre_value + ')'\n\n        '''\n        data_jsonId = str(i)\n        data_dbfId = str(json_data[i]['dbfId']) # 2539\n        data_id = json_data[i]['id']            # AT_001\n        data_name = json_data[i]['name']        # \u708e\u67aa\u672f\n        '''\n        sql_insert = '''INSERT INTO ''' + table_name + sql_pre_key + ''' VALUES ''' + sql_pre_value\n        print (sql_insert)\n\n        try:\n           # \u6267\u884csql\u8bed\u53e5\n           cursor.execute(sql_insert)\n           # \u63d0\u4ea4\u5230\u6570\u636e\u5e93\u6267\u884c\n           db.commit()\n           print('ok')\n        except:\n           # Rollback in case there is any error\n           db.rollback()\n           print('err: jsonId=' + str(i))\n           print (sql_insert)\n\n    #disconnect db\n    db.close()\n\n    print('Done.')", "fn_id": 0, "class_fn": false, "repo": "mashirozx/hearthstone-deck-embed", "file": "db_initial/json_to_mysql.py", "last_update_at": "2019-05-26T20:46:11+00:00", "question_id": "711402f2be79eb5c292967d95f900d9626dcdb91_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def jsonToMySQL(host, user, passwd, db_name, table_name):\n    json_url = 'https://api.hearthstonejson.com/v1/latest/zhCN/cards.json'\n    json_response = requests.get(json_url)\n    json_data = json_response.json()\n    db = MySQLdb.connect(host, user, passwd, db_name, use_unicode=True, charset='utf8')\n    cursor = db.cursor()\n    cursor.execute('DROP TABLE IF EXISTS ' + table_name)\n    sql_create_table = 'CREATE TABLE ' + table_name + ' (\\n             hs_jsonId INT,\\n             hs_dbfId INT,\\n             hs_id VARCHAR(225),\\n             hs_name VARCHAR(225),\\n             hs_cost INT,\\n             hs_rarity VARCHAR(225)) DEFAULT CHARSET=utf8'\n    header_tag_list = ('dbfId', 'id', 'name', 'cost', 'rarity')\n    char_type_tags = ('id', 'name', 'rarity')\n    cursor.execute(sql_create_table)\n    print(len(json_data))\n    for i in range(0, len(json_data), 1):\n        '\\n        if \\'dbfId\\' not in json_data[i] or \\'name\\' not in json_data[i] or \\'id\\' not in json_data[i]:\\n            print(\"data missing: jsonId=\"+str(i))\\n            continue\\n        '\n        data = {'id': i}\n        for header_tag in header_tag_list:\n            if header_tag in json_data[i]:\n                data[header_tag] = str(json_data[i][header_tag])\n        sql_pre_key = '(hs_jsonId'\n        sql_pre_value = '(' + str(i)\n        for key, value in data.items():\n            sql_pre_key = sql_pre_key + ', hs_' + key\n            if key in char_type_tags:\n                sql_pre_value = sql_pre_value + ', \"' + value + '\"'\n            else:\n                sql_pre_value = sql_pre_value + ', ' + value\n        sql_pre_key = sql_pre_key + ')'\n        sql_pre_value = sql_pre_value + ')'\n        \"\\n        data_jsonId = str(i)\\n        data_dbfId = str(json_data[i]['dbfId']) # 2539\\n        data_id = json_data[i]['id']            # AT_001\\n        data_name = json_data[i]['name']        # \u708e\u67aa\u672f\\n        \"\n        sql_insert = 'INSERT INTO ' + table_name + sql_pre_key + ' VALUES ' + sql_pre_value\n        print(sql_insert)\n        try:\n            cursor.execute(sql_insert)\n            db.commit()\n            print('ok')\n        except:\n            db.rollback()\n            print('err: jsonId=' + str(i))\n            print(sql_insert)\n    db.close()\n"]]}
{"hexsha": "646025c823822ad2539e6196ea53af5a519e26bf", "ext": "py", "lang": "Python", "content": "def printList3(movie_list):\n    for each_item in movie_list:\n        if isinstance(each_item, list):\n            for nested_item in each_item:\n                if isinstance(nested_item, list):\n                    for deeper_item in nested_item:\n                        print(deeper_item)\n                else:\n                    print(nested_item)\n        else:\n            print(each_item)", "fn_id": 1, "class_fn": false, "repo": "kadenkykim/Python-Tutorial", "file": "HeadFirst/Ed_1/Chap01_Meet_Python/Movies.py", "last_update_at": "2019-10-25T02:27:48+00:00", "question_id": "646025c823822ad2539e6196ea53af5a519e26bf_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def printList3(movie_list):\n    for each_item in movie_list:\n        if isinstance(each_item, list):\n            for nested_item in each_item:\n                if isinstance(nested_item, list):\n                    for deeper_item in nested_item:\n                        print(deeper_item)\n                else:\n                    print(nested_item)\n        else:\n"]]}
{"hexsha": "721fdfeb6f8ae6f20c3b89353ed74fcc6649c7f5", "ext": "py", "lang": "Python", "content": "@pytest.mark.parametrize(\n    'added_exchanges',\n    [(Location.BINANCE, Location.POLONIEX, Location.BITTREX, Location.BITMEX, Location.KRAKEN)],\n)\n@pytest.mark.parametrize('ethereum_accounts', [[ETH_ADDRESS1, ETH_ADDRESS2, ETH_ADDRESS3]])\n@pytest.mark.parametrize('mocked_price_queries', [prices])\n@pytest.mark.parametrize(\n    'start_ts,end_ts',\n    [(0, 1601040361), (1539713237, 1539713238)],\n)\ndef test_query_history(rotkehlchen_api_server_with_exchanges, start_ts, end_ts):\n    \"\"\"Test that the history processing REST API endpoint works. Similar to test_history.py\n\n    Both a test for full and limited time range.\n    \"\"\"\n    report_id, report_result, events_result = query_api_create_and_get_report(\n        server=rotkehlchen_api_server_with_exchanges,\n        start_ts=start_ts,\n        end_ts=end_ts,\n        prepare_mocks=True,\n    )\n\n    # Simply check that the results got returned here. The actual correctness of\n    # accounting results is checked in other tests such as test_simple_accounting\n    assert report_result['entries_found'] == 1\n    assert report_result['entries_limit'] == FREE_REPORTS_LOOKUP_LIMIT\n    report = report_result['entries'][0]\n    assert len(report) == 11  # 11 entries in the report api endpoint\n    assert report['first_processed_timestamp'] == 1428994442\n    assert report['last_processed_timestamp'] == end_ts if end_ts == 1539713238 else 1566572401\n    assert report['identifier'] == report_id\n    assert report['size_on_disk'] > 0\n\n    overview = report['overview']\n    if start_ts == 0:\n        assert len(overview) == 6\n        assert overview[str(AccountingEventType.ASSET_MOVEMENT)] is not None\n        assert overview[str(AccountingEventType.LOAN)] is not None\n        assert overview[str(AccountingEventType.MARGIN_POSITION)] is not None\n        assert overview[str(AccountingEventType.TRANSACTION_EVENT)] is not None\n    else:\n        assert len(overview) == 2\n    assert overview[str(AccountingEventType.TRADE)] is not None\n    assert overview[str(AccountingEventType.FEE)] is not None\n\n    settings = report['settings']\n    assert len(settings) == 6\n    assert settings['profit_currency'] == 'EUR'\n    assert settings['account_for_assets_movements'] is True\n    assert settings['calculate_past_cost_basis'] is True\n    assert settings['include_crypto2crypto'] is True\n    assert settings['include_gas_costs'] is True\n    assert settings['taxfree_after_period'] == 31536000\n\n    assert events_result['entries_limit'] == FREE_PNL_EVENTS_LIMIT\n    entries_length = 47 if start_ts == 0 else 44\n    assert events_result['entries_found'] == entries_length\n    assert isinstance(events_result['entries'], list)\n    # TODO: These events are not actually checked anywhere for correctness\n    #       A test should probably be made for their correctness, even though\n    #       they are assumed correct if the overview is correct\n    assert len(events_result['entries']) == entries_length\n\n    # And now make sure that warnings have also been generated for the query of\n    # the unsupported/unknown assets\n    rotki = rotkehlchen_api_server_with_exchanges.rest_api.rotkehlchen\n    warnings = rotki.msg_aggregator.consume_warnings()\n    assert len(warnings) == 10\n    assert 'poloniex trade with unknown asset NOEXISTINGASSET' in warnings[0]\n    assert 'poloniex trade with unsupported asset BALLS' in warnings[1]\n    assert 'withdrawal of unknown poloniex asset IDONTEXIST' in warnings[2]\n    assert 'withdrawal of unsupported poloniex asset DIS' in warnings[3]\n    assert 'deposit of unknown poloniex asset IDONTEXIST' in warnings[4]\n    assert 'deposit of unsupported poloniex asset EBT' in warnings[5]\n    assert 'poloniex loan with unsupported asset BDC' in warnings[6]\n    assert 'poloniex loan with unknown asset NOTEXISTINGASSET' in warnings[7]\n    assert 'bittrex trade with unsupported asset PTON' in warnings[8]\n    assert 'bittrex trade with unknown asset IDONTEXIST' in warnings[9]\n\n    errors = rotki.msg_aggregator.consume_errors()\n    assert len(errors) == 3\n    assert 'bittrex trade with unprocessable pair %$#%$#%#$%' in errors[0]\n    assert 'Failed to read ledger event from kraken' in errors[1]\n    assert 'Failed to read ledger event from kraken ' in errors[2]\n\n    response = requests.get(\n        api_url_for(\n            rotkehlchen_api_server_with_exchanges,\n            'historyactionableitemsresource',\n        ),\n    )\n    assert_proper_response_with_result(response=response, status_code=HTTPStatus.OK)\n    assert len(response.json()['result']['missing_acquisitions']) == 10\n    assert len(response.json()['result']['missing_prices']) == 0\n", "fn_id": 0, "class_fn": false, "repo": "rotkehlchenio/rotkehlchen", "file": "rotkehlchen/tests/api/test_history.py", "last_update_at": "2019-11-03T16:38:42+00:00", "question_id": "721fdfeb6f8ae6f20c3b89353ed74fcc6649c7f5_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.mark.parametrize('added_exchanges', [(Location.BINANCE, Location.POLONIEX, Location.BITTREX, Location.BITMEX, Location.KRAKEN)])\n@pytest.mark.parametrize('ethereum_accounts', [[ETH_ADDRESS1, ETH_ADDRESS2, ETH_ADDRESS3]])\n@pytest.mark.parametrize('mocked_price_queries', [prices])\n@pytest.mark.parametrize('start_ts,end_ts', [(0, 1601040361), (1539713237, 1539713238)])\ndef test_query_history(rotkehlchen_api_server_with_exchanges, start_ts, end_ts):\n    \"\"\"Test that the history processing REST API endpoint works. Similar to test_history.py\n\n    Both a test for full and limited time range.\n    \"\"\"\n    report_id, report_result, events_result = query_api_create_and_get_report(server=rotkehlchen_api_server_with_exchanges, start_ts=start_ts, end_ts=end_ts, prepare_mocks=True)\n    assert report_result['entries_found'] == 1\n    assert report_result['entries_limit'] == FREE_REPORTS_LOOKUP_LIMIT\n    report = report_result['entries'][0]\n    assert len(report) == 11\n    assert report['first_processed_timestamp'] == 1428994442\n    assert report['last_processed_timestamp'] == end_ts if end_ts == 1539713238 else 1566572401\n    assert report['identifier'] == report_id\n    assert report['size_on_disk'] > 0\n    overview = report['overview']\n    if start_ts == 0:\n        assert len(overview) == 6\n        assert overview[str(AccountingEventType.ASSET_MOVEMENT)] is not None\n        assert overview[str(AccountingEventType.LOAN)] is not None\n        assert overview[str(AccountingEventType.MARGIN_POSITION)] is not None\n        assert overview[str(AccountingEventType.TRANSACTION_EVENT)] is not None\n    else:\n        assert len(overview) == 2\n    assert overview[str(AccountingEventType.TRADE)] is not None\n    assert overview[str(AccountingEventType.FEE)] is not None\n    settings = report['settings']\n    assert len(settings) == 6\n    assert settings['profit_currency'] == 'EUR'\n    assert settings['account_for_assets_movements'] is True\n    assert settings['calculate_past_cost_basis'] is True\n    assert settings['include_crypto2crypto'] is True\n    assert settings['include_gas_costs'] is True\n    assert settings['taxfree_after_period'] == 31536000\n    assert events_result['entries_limit'] == FREE_PNL_EVENTS_LIMIT\n    entries_length = 47 if start_ts == 0 else 44\n    assert events_result['entries_found'] == entries_length\n    assert isinstance(events_result['entries'], list)\n    assert len(events_result['entries']) == entries_length\n    rotki = rotkehlchen_api_server_with_exchanges.rest_api.rotkehlchen\n    warnings = rotki.msg_aggregator.consume_warnings()\n    assert len(warnings) == 10\n    assert 'poloniex trade with unknown asset NOEXISTINGASSET' in warnings[0]\n    assert 'poloniex trade with unsupported asset BALLS' in warnings[1]\n    assert 'withdrawal of unknown poloniex asset IDONTEXIST' in warnings[2]\n    assert 'withdrawal of unsupported poloniex asset DIS' in warnings[3]\n    assert 'deposit of unknown poloniex asset IDONTEXIST' in warnings[4]\n    assert 'deposit of unsupported poloniex asset EBT' in warnings[5]\n    assert 'poloniex loan with unsupported asset BDC' in warnings[6]\n    assert 'poloniex loan with unknown asset NOTEXISTINGASSET' in warnings[7]\n    assert 'bittrex trade with unsupported asset PTON' in warnings[8]\n    assert 'bittrex trade with unknown asset IDONTEXIST' in warnings[9]\n    errors = rotki.msg_aggregator.consume_errors()\n    assert len(errors) == 3\n    assert 'bittrex trade with unprocessable pair %$#%$#%#$%' in errors[0]\n    assert 'Failed to read ledger event from kraken' in errors[1]\n    assert 'Failed to read ledger event from kraken ' in errors[2]\n    response = requests.get(api_url_for(rotkehlchen_api_server_with_exchanges, 'historyactionableitemsresource'))\n    assert_proper_response_with_result(response=response, status_code=HTTPStatus.OK)\n    assert len(response.json()['result']['missing_acquisitions']) == 10\n"]]}
{"hexsha": "81a5899b0055966583cbf93f22c2fbaf3992b2f1", "ext": "py", "lang": "Python", "content": "def check_np_array(item, field_name, ndim, parent_class, channel_num=None):\n    \"\"\"\n    Check a numpy array's shape and dtype against required\n    specifications.\n\n    Parameters\n    ----------\n    item : numpy array\n        The numpy array to check\n    field_name : str\n        The name of the field to check\n    ndim : int\n        The required number of dimensions\n    parent_class : type\n        The parent class of the dtype. ie. np.integer, np.floating.\n    channel_num : int, optional\n        If not None, indicates that the item passed in is a subelement\n        of a list. Indicate this in the error message if triggered.\n\n    \"\"\"\n    # Check shape\n    if item.ndim != ndim:\n        error_msg = 'Field `%s` must have ndim == %d' % (field_name, ndim)\n        if channel_num is not None:\n            error_msg = ('Channel %d of f' % channel_num) + error_msg[1:]\n        raise TypeError(error_msg)\n\n    # Check dtype\n    if not np.issubdtype(item.dtype, parent_class):\n        error_msg = 'Field `%s` must have a dtype that subclasses %s' % (field_name, parent_class)\n        if channel_num is not None:\n            error_msg = ('Channel %d of f' % channel_num) + error_msg[1:]\n        raise TypeError(error_msg)", "fn_id": 1, "class_fn": false, "repo": "vishwas1234567/wfdb-python", "file": "wfdb/io/record.py", "last_update_at": "2019-07-06T05:57:49+00:00", "question_id": "81a5899b0055966583cbf93f22c2fbaf3992b2f1_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def check_np_array(item, field_name, ndim, parent_class, channel_num=None):\n    \"\"\"\n    Check a numpy array's shape and dtype against required\n    specifications.\n\n    Parameters\n    ----------\n    item : numpy array\n        The numpy array to check\n    field_name : str\n        The name of the field to check\n    ndim : int\n        The required number of dimensions\n    parent_class : type\n        The parent class of the dtype. ie. np.integer, np.floating.\n    channel_num : int, optional\n        If not None, indicates that the item passed in is a subelement\n        of a list. Indicate this in the error message if triggered.\n\n    \"\"\"\n    if item.ndim != ndim:\n        error_msg = 'Field `%s` must have ndim == %d' % (field_name, ndim)\n        if channel_num is not None:\n            error_msg = 'Channel %d of f' % channel_num + error_msg[1:]\n        raise TypeError(error_msg)\n    if not np.issubdtype(item.dtype, parent_class):\n        error_msg = 'Field `%s` must have a dtype that subclasses %s' % (field_name, parent_class)\n        if channel_num is not None:\n            error_msg = 'Channel %d of f' % channel_num + error_msg[1:]\n"]]}
{"hexsha": "f016eccb2a8fef9f83541909a8e0e2cb9b757e9b", "ext": "py", "lang": "Python", "content": "def unpickle(file):\n    \n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo,encoding='iso-8859-1')\n    return dict", "fn_id": 0, "class_fn": false, "repo": "saurabhcommand/Hello-world", "file": "Python/AlexNet.py", "last_update_at": "2019-03-31T18:38:36+00:00", "question_id": "f016eccb2a8fef9f83541909a8e0e2cb9b757e9b_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def unpickle(file):\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='iso-8859-1')\n"]]}
{"hexsha": "2c0bb179f7647e891760dbede059edfc220539dd", "ext": "py", "lang": "Python", "content": "@app.route(\"/api/group/<group>\", methods=[\"GET\"])\n@api\n@auth\ndef get_group_keys_view(group):\n    name = \"funnel:\" + group + \":keys\"\n    key_members = r.smembers(name)\n    funnel_list = []\n    for key in key_members:\n        funnel = r.hgetall(key)\n        funnel = {key: float(value) for key, value in funnel.iteritems()}\n        funnel[\"name\"] = key\n        funnel_list.append(funnel)\n    funnel_list.sort(key=lambda x: x[\"name\"])\n    data = {\n        \"funnel_list\": funnel_list,\n        \"total_items\": len(funnel_list),\n    }\n    return data", "fn_id": 5, "class_fn": false, "repo": "PurpleSun/redis_funnel", "file": "redis_funnel/mgmt/app.py", "last_update_at": "2019-03-29T03:16:04+00:00", "question_id": "2c0bb179f7647e891760dbede059edfc220539dd_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@app.route('/api/group/<group>', methods=['GET'])\n@api\n@auth\ndef get_group_keys_view(group):\n    name = 'funnel:' + group + ':keys'\n    key_members = r.smembers(name)\n    funnel_list = []\n    for key in key_members:\n        funnel = r.hgetall(key)\n        funnel = {key: float(value) for key, value in funnel.iteritems()}\n        funnel['name'] = key\n        funnel_list.append(funnel)\n    funnel_list.sort(key=lambda x: x['name'])\n    data = {'funnel_list': funnel_list, 'total_items': len(funnel_list)}\n"]]}
{"hexsha": "46a766a86230f7ed856136d090c8c0408f00fa5e", "ext": "py", "lang": "Python", "content": "@manager.route('/<job_id>/<role>/<party_id>/cancel', methods=['POST'])\ndef cancel_job(job_id, role, party_id):\n    res = JobController.cancel_job(job_id=job_id, role=role, party_id=int(party_id),\n                                   job_initiator=request.json.get('job_initiator', {}))\n    if res:\n        return get_json_result(retcode=0, retmsg='cancel job success')\n    return get_json_result(retcode=101, retmsg='cancel job failed')", "fn_id": 5, "class_fn": false, "repo": "caolin12/FATE", "file": "fate_flow/apps/schedule_app.py", "last_update_at": "2019-12-11T06:27:09+00:00", "question_id": "46a766a86230f7ed856136d090c8c0408f00fa5e_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@manager.route('/<job_id>/<role>/<party_id>/cancel', methods=['POST'])\ndef cancel_job(job_id, role, party_id):\n    res = JobController.cancel_job(job_id=job_id, role=role, party_id=int(party_id), job_initiator=request.json.get('job_initiator', {}))\n    if res:\n        return get_json_result(retcode=0, retmsg='cancel job success')\n"]]}
{"hexsha": "3bad42d8a50abd9b7592a29fe46bc7ff0b7fd6fa", "ext": "py", "lang": "Python", "content": "def ordinary_least_squares(y, x=[], fe=[], data=None, **kwargs):\n    # base poisson distribution\n    link = links['identity']\n    loss0 = losses['least_squares']\n    extra = ['lsigma']\n\n    # zero inflation\n    def loss(par, yh, y):\n        lsigma = par[0]\n        sigma2 = np.exp(2*lsigma)\n        like = -lsigma + 0.5*loss0(yh, y)/sigma2\n        return like\n\n    return glm(y, x=x, fe=fe, data=data, extra=extra, link=link, loss=loss, **kwargs)", "fn_id": 6, "class_fn": false, "repo": "paulgp/fastreg", "file": "fastreg/general.py", "last_update_at": "2019-12-18T01:59:59+00:00", "question_id": "3bad42d8a50abd9b7592a29fe46bc7ff0b7fd6fa_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def ordinary_least_squares(y, x=[], fe=[], data=None, **kwargs):\n    link = links['identity']\n    loss0 = losses['least_squares']\n    extra = ['lsigma']\n\n    def loss(par, yh, y):\n        lsigma = par[0]\n        sigma2 = np.exp(2 * lsigma)\n        like = -lsigma + 0.5 * loss0(yh, y) / sigma2\n        return like\n"]]}
{"hexsha": "bc86398eecf3833614c097df7bf622fb746c9a2a", "ext": "py", "lang": "Python", "content": "@pytest.mark.parametrize(\n    (\"fragment\", \"canonical_name\", \"expected\"),\n    [\n        # Trivial.\n        (\"pip-18.0\", \"pip\", \"18.0\"),\n        (\"zope-interface-4.5.0\", \"zope-interface\", \"4.5.0\"),\n\n        # Canonicalized name match non-canonicalized egg info. (pypa/pip#5870)\n        (\"Jinja2-2.10\", \"jinja2\", \"2.10\"),\n        (\"zope.interface-4.5.0\", \"zope-interface\", \"4.5.0\"),\n        (\"zope_interface-4.5.0\", \"zope-interface\", \"4.5.0\"),\n\n        # Should be smart enough to parse ambiguous names from the provided\n        # package name.\n        (\"foo-2-2\", \"foo\", \"2-2\"),\n        (\"foo-2-2\", \"foo-2\", \"2\"),\n        (\"zope.interface--4.5.0\", \"zope-interface\", \"-4.5.0\"),\n        (\"zope.interface--\", \"zope-interface\", \"-\"),\n\n        # Should be able to detect collapsed characters in the egg info.\n        (\"foo--bar-1.0\", \"foo-bar\", \"1.0\"),\n        (\"foo-_bar-1.0\", \"foo-bar\", \"1.0\"),\n\n        # Invalid.\n        (\"the-package-name-8.19\", \"does-not-match\", None),\n        (\"zope.interface.-4.5.0\", \"zope.interface\", None),\n        (\"zope.interface-\", \"zope-interface\", None),\n        (\"zope.interface4.5.0\", \"zope-interface\", None),\n        (\"zope.interface.4.5.0\", \"zope-interface\", None),\n        (\"zope.interface.-4.5.0\", \"zope-interface\", None),\n        (\"zope.interface\", \"zope-interface\", None),\n    ],\n)\ndef test_extract_version_from_fragment(fragment, canonical_name, expected):\n    version = _extract_version_from_fragment(fragment, canonical_name)\n    assert version == expected", "fn_id": 11, "class_fn": false, "repo": "j420247/pip", "file": "tests/unit/test_index.py", "last_update_at": "2019-12-20T05:27:25+00:00", "question_id": "bc86398eecf3833614c097df7bf622fb746c9a2a_11", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.mark.parametrize(('fragment', 'canonical_name', 'expected'), [('pip-18.0', 'pip', '18.0'), ('zope-interface-4.5.0', 'zope-interface', '4.5.0'), ('Jinja2-2.10', 'jinja2', '2.10'), ('zope.interface-4.5.0', 'zope-interface', '4.5.0'), ('zope_interface-4.5.0', 'zope-interface', '4.5.0'), ('foo-2-2', 'foo', '2-2'), ('foo-2-2', 'foo-2', '2'), ('zope.interface--4.5.0', 'zope-interface', '-4.5.0'), ('zope.interface--', 'zope-interface', '-'), ('foo--bar-1.0', 'foo-bar', '1.0'), ('foo-_bar-1.0', 'foo-bar', '1.0'), ('the-package-name-8.19', 'does-not-match', None), ('zope.interface.-4.5.0', 'zope.interface', None), ('zope.interface-', 'zope-interface', None), ('zope.interface4.5.0', 'zope-interface', None), ('zope.interface.4.5.0', 'zope-interface', None), ('zope.interface.-4.5.0', 'zope-interface', None), ('zope.interface', 'zope-interface', None)])\ndef test_extract_version_from_fragment(fragment, canonical_name, expected):\n    version = _extract_version_from_fragment(fragment, canonical_name)\n"]]}
{"hexsha": "3c5029f17ae60f20b37d5457d5f9a7cc3f079b7e", "ext": "py", "lang": "Python", "content": "def debug(bp):\n    #bp = [0xea0,0xd31,0xc52]\n    #bp = [0x00000dfb,0x00000b7c,0x00000d10]\n    script = \"\"\n    PIE = get_PIE(sh)\n    PAPA = PIE\n    print(hex(PIE))\n    for x in bp:\n        script += \"b *0x%x\\n\"%(PIE+x)\n    gdb.attach(sh,gdbscript=script) ", "fn_id": 0, "class_fn": false, "repo": "kamithanthanh/hacmao.github.io", "file": "ctf/2020/hacktm/twisty/solve.py", "last_update_at": "2019-09-27T13:23:00+00:00", "question_id": "3c5029f17ae60f20b37d5457d5f9a7cc3f079b7e_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def debug(bp):\n    script = ''\n    PIE = get_PIE(sh)\n    PAPA = PIE\n    print(hex(PIE))\n    for x in bp:\n        script += 'b *0x%x\\n' % (PIE + x)\n"]]}
{"hexsha": "160a24baa158808f31426c2f2a50e9da3e700399", "ext": "py", "lang": "Python", "content": "def test_meta_present():\n    reg = get_builtin_sites()\n\n    greenwich = reg['greenwich']\n    assert greenwich.info.meta['source'] == ('Ordnance Survey via '\n           'http://gpsinformation.net/main/greenwich.htm and UNESCO')", "fn_id": 8, "class_fn": false, "repo": "zabop/astropy", "file": "astropy/coordinates/tests/test_sites.py", "last_update_at": "2019-03-11T12:26:49+00:00", "question_id": "160a24baa158808f31426c2f2a50e9da3e700399_8", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_meta_present():\n    reg = get_builtin_sites()\n    greenwich = reg['greenwich']\n"]]}
{"hexsha": "2bad962a0dc8bb788093ce90927202a39b225396", "ext": "py", "lang": "Python", "content": "def _validate_registers(registers: t.Sequence[Register]) -> None:\n    # Check that no registers overlap\n    register_intervals = IntervalTree.from_tuples(\n        [(register.byte_range[0], register.byte_range[1], register) for register in registers]\n    )\n    overlaps = find_overlapping_intervals(register_intervals)\n    if overlaps:\n        description = \"\\n\".join(f\"- {overlap.data.name}\" for overlap in overlaps)\n        raise ValueError(f\"Overlapping registers:\\n{description}\")", "fn_id": 6, "class_fn": false, "repo": "sifive/scribble-testsocket-sifive", "file": "docs/scribble/document/util/register_map/converter.py", "last_update_at": "2019-12-12T21:11:52+00:00", "question_id": "2bad962a0dc8bb788093ce90927202a39b225396_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _validate_registers(registers: t.Sequence[Register]) -> None:\n    register_intervals = IntervalTree.from_tuples([(register.byte_range[0], register.byte_range[1], register) for register in registers])\n    overlaps = find_overlapping_intervals(register_intervals)\n    if overlaps:\n        description = '\\n'.join((f'- {overlap.data.name}' for overlap in overlaps))\n"]]}
{"hexsha": "38aa0f11b040c6e2b0f15e6b26ecdcb95217d8c4", "ext": "py", "lang": "Python", "content": "def bootstrap(config):\n\t#\n\t# BACnet \u30c7\u30fc\u30e2\u30f3\u306e\u7ba1\u7406\u7528\u5909\u6570\n\t#\n\tconfig.registry.bacnetd = None\n\n\t#\n\t# Scan controller\n\t#\n\tconfig.add_route('api::bacnetd:status', '/status')\n\tconfig.add_route('api::bacnetd:start', '/start')\n\tconfig.scan('.controller')", "fn_id": 0, "class_fn": false, "repo": "ThousandMileEye/Eye", "file": "eyed/old/api/bacnetd/__init__.py", "last_update_at": "2019-01-20T02:49:41+00:00", "question_id": "38aa0f11b040c6e2b0f15e6b26ecdcb95217d8c4_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def bootstrap(config):\n    config.registry.bacnetd = None\n    config.add_route('api::bacnetd:status', '/status')\n    config.add_route('api::bacnetd:start', '/start')\n"]]}
{"hexsha": "00e7bf1ae8d8c8a3db1e716f8b5d3881f7ff39c3", "ext": "py", "lang": "Python", "content": "def _validate_file_has_start_and_end_lines(user_input, path, identifier):\n    try:\n        update_file_chunk_content(path=path, code=[], identifier=identifier, check_only=True)\n    except ValueError as e:\n        print(e)\n        return False\n    else:\n        return True", "fn_id": 16, "class_fn": false, "repo": "wearefair/modelmapper", "file": "modelmapper/misc.py", "last_update_at": "2019-03-15T18:28:07+00:00", "question_id": "00e7bf1ae8d8c8a3db1e716f8b5d3881f7ff39c3_16", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _validate_file_has_start_and_end_lines(user_input, path, identifier):\n    try:\n        update_file_chunk_content(path=path, code=[], identifier=identifier, check_only=True)\n    except ValueError as e:\n        print(e)\n        return False\n    else:\n"]]}
{"hexsha": "1d10744a8ebf8809ee640fe7b28884cb8c71d4ba", "ext": "py", "lang": "Python", "content": "def flag_update_status(f, s, stat):\n    f.update_status.setdefault(stat, []).append(s)\n    if s is not None:\n        s.update_status.setdefault(stat, []).append(f)", "fn_id": 2, "class_fn": false, "repo": "mtholder/taxalotl", "file": "taxalotl/cmds/analyze_update.py", "last_update_at": "2019-09-14T13:30:39+00:00", "question_id": "1d10744a8ebf8809ee640fe7b28884cb8c71d4ba_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def flag_update_status(f, s, stat):\n    f.update_status.setdefault(stat, []).append(s)\n    if s is not None:\n"]]}
{"hexsha": "b16cc1646ad4dbe41303de150cd50b7d001e0910", "ext": "py", "lang": "Python", "content": "@bp.route('/name/<name>', methods=['GET'])\ndef get_event_by_name(name):\n    event = Event.query.filter_by(name=name).scalar()\n    return event_schema.jsonify(event)", "fn_id": 2, "class_fn": false, "repo": "Info-ag/labplaner", "file": "app/blueprints/api/v1/event.py", "last_update_at": "2019-01-06T17:39:59+00:00", "question_id": "b16cc1646ad4dbe41303de150cd50b7d001e0910_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@bp.route('/name/<name>', methods=['GET'])\ndef get_event_by_name(name):\n    event = Event.query.filter_by(name=name).scalar()\n"]]}
{"hexsha": "5d2683984e28f77df8e777a9bf40f8bbd269ddd6", "ext": "py", "lang": "Python", "content": "@main.before_request\ndef before_request():\n    if 'cart' not in session:\n        session['cart'] = Cart().to_dict()", "fn_id": 0, "class_fn": false, "repo": "Guillerbr/python-pagseguro", "file": "examples/flask/flask_seguro/controllers/main/__init__.py", "last_update_at": "2019-07-24T17:31:30+00:00", "question_id": "5d2683984e28f77df8e777a9bf40f8bbd269ddd6_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@main.before_request\ndef before_request():\n    if 'cart' not in session:\n"]]}
{"hexsha": "be36b25e573e9d6482f6a39dad790637e8e31240", "ext": "py", "lang": "Python", "content": "def remove_license_file(license_file):\n    if not click.confirm(f\"Remove {green(str(license_file.absolute()))}?\"):\n        click.echo(\"Not removing license.\")\n        sys.exit(0)\n\n    try:\n        license_file.unlink()\n        click.echo(f\"Removed {green(str(license_file.absolute()))}.\")\n    except Exception:\n        click.echo(f\"Could not remove {green(str(license_file.absolute()))}.\", err=True)", "fn_id": 5, "class_fn": false, "repo": "sxn/notary", "file": "notary/cli.py", "last_update_at": "2019-04-17T19:37:08+00:00", "question_id": "be36b25e573e9d6482f6a39dad790637e8e31240_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def remove_license_file(license_file):\n    if not click.confirm(f'Remove {green(str(license_file.absolute()))}?'):\n        click.echo('Not removing license.')\n        sys.exit(0)\n    try:\n        license_file.unlink()\n        click.echo(f'Removed {green(str(license_file.absolute()))}.')\n    except Exception:\n"]]}
{"hexsha": "c0173e2df03e13aa3f3df73dd0a1d470656714ca", "ext": "py", "lang": "Python", "content": "def main():\n    n, m = read_list_int()\n    islands = []\n    for _ in range(n):\n        row = list(sys.stdin.readline().strip())\n        islands.append(row)\n    print(solution(n, m, islands))", "fn_id": 1, "class_fn": false, "repo": "yskang/AlgorithmPractice", "file": "baekjoon/python/why_the_rabbit_landing_on_information_islands_17130.py", "last_update_at": "2019-11-04T06:46:55+00:00", "question_id": "c0173e2df03e13aa3f3df73dd0a1d470656714ca_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main():\n    n, m = read_list_int()\n    islands = []\n    for _ in range(n):\n        row = list(sys.stdin.readline().strip())\n        islands.append(row)\n"]]}
{"hexsha": "fc728cedccf53c3365f38a9ea23a88c0ce989db3", "ext": "py", "lang": "Python", "content": "def emit(level, message, exc_info=None, **extras):\n  \"\"\"Log in JSON.\"\"\"\n  logger = get_logger()\n  if not logger:\n    return\n\n  # Include extras passed as an argument and default extras.\n  all_extras = _default_extras.copy()\n  all_extras.update(extras)\n\n  path_name, line_number, method_name = get_source_location()\n\n  if (level >= logging.ERROR and _is_running_on_app_engine()):\n    # App Engine only reports errors if there is an exception stacktrace, so we\n    # generate one. We don't create an exception here and then format it, as\n    # that will not include frames below this emit() call. We do [:-2] on\n    # the stacktrace to exclude emit() and the logging function below it (e.g.\n    # log_error).\n    message = (\n        message + '\\n' + 'Traceback (most recent call last):\\n' + ''.join(\n            traceback.format_stack()[:-2]) + 'LogError: ' + message)\n\n  # We need to make a dict out of it because member of the dict becomes the\n  # first class attributes of LogEntry. It is very tricky to identify the extra\n  # attributes. Therefore, we wrap extra fields under the attribute 'extras'.\n  logger.log(\n      level,\n      truncate(message, LOCAL_LOG_MESSAGE_LIMIT),\n      exc_info=exc_info,\n      extra={\n          'extras': all_extras,\n          'location': {\n              'path': path_name,\n              'line': line_number,\n              'method': method_name\n          }\n      })", "fn_id": 13, "class_fn": false, "repo": "swazer/clusterfuzz", "file": "src/python/metrics/logs.py", "last_update_at": "2019-04-09T06:40:55+00:00", "question_id": "fc728cedccf53c3365f38a9ea23a88c0ce989db3_13", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def emit(level, message, exc_info=None, **extras):\n    \"\"\"Log in JSON.\"\"\"\n    logger = get_logger()\n    if not logger:\n        return\n    all_extras = _default_extras.copy()\n    all_extras.update(extras)\n    path_name, line_number, method_name = get_source_location()\n    if level >= logging.ERROR and _is_running_on_app_engine():\n        message = message + '\\n' + 'Traceback (most recent call last):\\n' + ''.join(traceback.format_stack()[:-2]) + 'LogError: ' + message\n"]]}
{"hexsha": "aa875c2026f5a8927de62ff56dd5fbb29ebe876b", "ext": "py", "lang": "Python", "content": "def moveFilesToFolder(lst, destFolderPath):\n    for f in lst:\n        base = basename(f)\n        dest = os.path.join(destFolderPath, base)\n        print(\"Moving: \", f, \"      To: \", dest)\n        shutil.move(f, dest)", "fn_id": 9, "class_fn": false, "repo": "adwuard/OP1_File_Organizer", "file": "file_util.py", "last_update_at": "2019-08-22T04:51:13+00:00", "question_id": "aa875c2026f5a8927de62ff56dd5fbb29ebe876b_9", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def moveFilesToFolder(lst, destFolderPath):\n    for f in lst:\n        base = basename(f)\n        dest = os.path.join(destFolderPath, base)\n        print('Moving: ', f, '      To: ', dest)\n"]]}
{"hexsha": "e3573fed0b03b0133d480240a87c50a8883c61ce", "ext": "py", "lang": "Python", "content": "def load_models():\n    parent_dir = os.path.dirname(os.path.realpath(__file__))\n    data_models_yml = Path(parent_dir) / \"data_models.yml\"\n    with open(data_models_yml) as f:\n        data_models = yaml.safe_load(f)\n    model_list = []\n    for data_model in data_models:\n        module = importlib.import_module(data_model[\"parent_module\"])\n        model_list.append(getattr(module, data_model[\"model_class\"]))\n    return model_list", "fn_id": 0, "class_fn": false, "repo": "autognc/jigsaw", "file": "jigsaw/data_interface.py", "last_update_at": "2019-03-27T22:07:41+00:00", "question_id": "e3573fed0b03b0133d480240a87c50a8883c61ce_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def load_models():\n    parent_dir = os.path.dirname(os.path.realpath(__file__))\n    data_models_yml = Path(parent_dir) / 'data_models.yml'\n    with open(data_models_yml) as f:\n        data_models = yaml.safe_load(f)\n    model_list = []\n    for data_model in data_models:\n        module = importlib.import_module(data_model['parent_module'])\n        model_list.append(getattr(module, data_model['model_class']))\n"]]}
{"hexsha": "559d1153e6387191e5d6f5c6e18e97a9e57296db", "ext": "py", "lang": "Python", "content": "def test_fees_update_on_verifier_remove(erc20_relay):\n    ERC20Relay = erc20_relay.ERC20Relay\n    owner = ERC20Relay.owner\n\n    ERC20Relay.functions.addVerifier(int_to_address(1)).transact({'from': owner})\n    ERC20Relay.functions.addVerifier(int_to_address(2)).transact({'from': owner})\n    amount = ERC20Relay.functions.fees().call()\n    assert amount == calculate_fees(5)\n\n    ERC20Relay.functions.removeVerifier(int_to_address(2)).transact({'from': owner})\n    amount = ERC20Relay.functions.fees().call()\n\n    assert amount == calculate_fees(4)", "fn_id": 33, "class_fn": false, "repo": "polyswarm/contractor", "file": "tests/test_ERC20Relay.py", "last_update_at": "2019-12-04T03:30:45+00:00", "question_id": "559d1153e6387191e5d6f5c6e18e97a9e57296db_33", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_fees_update_on_verifier_remove(erc20_relay):\n    ERC20Relay = erc20_relay.ERC20Relay\n    owner = ERC20Relay.owner\n    ERC20Relay.functions.addVerifier(int_to_address(1)).transact({'from': owner})\n    ERC20Relay.functions.addVerifier(int_to_address(2)).transact({'from': owner})\n    amount = ERC20Relay.functions.fees().call()\n    assert amount == calculate_fees(5)\n    ERC20Relay.functions.removeVerifier(int_to_address(2)).transact({'from': owner})\n    amount = ERC20Relay.functions.fees().call()\n"]]}
{"hexsha": "c9ccfa6cc05bdb10070b423d52ff71781850cfa4", "ext": "py", "lang": "Python", "content": "def _get_cdl_info(cdlpoint, vals, names, colors):\n\n    tval = ee.Number(cdlpoint.get('CDL'))\n    valindx = vals.indexOf(tval)\n\n    return cdlpoint.set('CDL_NAME', ee.String(names.get(valindx)),\n                        'CDL_COLOR', ee.String(colors.get(valindx)))", "fn_id": 2, "class_fn": false, "repo": "AnthonyPerez/gee_tools", "file": "gee_tools/cdltools.py", "last_update_at": "2019-03-11T12:57:46+00:00", "question_id": "c9ccfa6cc05bdb10070b423d52ff71781850cfa4_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _get_cdl_info(cdlpoint, vals, names, colors):\n    tval = ee.Number(cdlpoint.get('CDL'))\n    valindx = vals.indexOf(tval)\n"]]}
{"hexsha": "cce51bea0a99f09e95c89c72fa2f703a2e0a2965", "ext": "py", "lang": "Python", "content": "def lis_size_dp(\n        node: Optional[TabulatedNode] = None,\n        parent_selected: Optional[bool] = None\n) -> int:\n    \"\"\"\n    We add extra params to node for tabulation\n    \"\"\"\n    if node is None:\n        return 0\n\n    if node.left is None and node.right is None:\n        if node.max_inc is None:\n            node.max_inc = 1\n            node.max_exc = 0\n\n        return node.max_exc if parent_selected else node.max_inc\n\n    if not parent_selected:\n        if node.max_inc is None:\n            node.max_inc = 1 + lis_size_dp(node.left, True) + lis_size_dp(node.right, True)\n\n    if node.max_exc is None:\n        node.max_exc = lis_size_dp(node.left, False) + lis_size_dp(node.right, False)\n\n    return max(node.max_inc or 0, node.max_exc or 0)", "fn_id": 1, "class_fn": false, "repo": "rrwt/daily-coding-challenge", "file": "gfg/dp/largest_independent_set_tree.py", "last_update_at": "2019-04-18T03:29:02+00:00", "question_id": "cce51bea0a99f09e95c89c72fa2f703a2e0a2965_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def lis_size_dp(node: Optional[TabulatedNode]=None, parent_selected: Optional[bool]=None) -> int:\n    \"\"\"\n    We add extra params to node for tabulation\n    \"\"\"\n    if node is None:\n        return 0\n    if node.left is None and node.right is None:\n        if node.max_inc is None:\n            node.max_inc = 1\n            node.max_exc = 0\n        return node.max_exc if parent_selected else node.max_inc\n    if not parent_selected:\n        if node.max_inc is None:\n            node.max_inc = 1 + lis_size_dp(node.left, True) + lis_size_dp(node.right, True)\n    if node.max_exc is None:\n        node.max_exc = lis_size_dp(node.left, False) + lis_size_dp(node.right, False)\n"]]}
{"hexsha": "37ecb653e7dc18e4874f32e50d6088abb2d7098f", "ext": "py", "lang": "Python", "content": "def read_gff(\n        file: str,\n        as_dict: bool = False) \\\n        -> Union[List[GffFeature], Dict[str, GffFeature]]:\n    \"\"\"\n    Args:\n        file: path-like\n            The input GFF file\n\n        as_dict:\n            If True, returns a dictionary\n\n    Returns: list of GffFeature objects, or dict\n\n        [GffFeature_1, GffFeature_2, ...]\n\n        or\n\n        {\n            seqid_1: [GffFeature_1, ...],\n            seqid_2: [GffFeature_2, ...], ...\n        }\n    \"\"\"\n    with GffParser(file) as parser:\n        features = [feature for feature in parser]\n    if as_dict:\n        D = {}\n        for f in features:\n            D.setdefault(f.seqid, [])\n            D[f.seqid].append(f)\n        return D\n    return features", "fn_id": 0, "class_fn": false, "repo": "nebiolabs/ngslite", "file": "ngslite/gff.py", "last_update_at": "2019-08-15T03:20:03+00:00", "question_id": "37ecb653e7dc18e4874f32e50d6088abb2d7098f_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def read_gff(file: str, as_dict: bool=False) -> Union[List[GffFeature], Dict[str, GffFeature]]:\n    \"\"\"\n    Args:\n        file: path-like\n            The input GFF file\n\n        as_dict:\n            If True, returns a dictionary\n\n    Returns: list of GffFeature objects, or dict\n\n        [GffFeature_1, GffFeature_2, ...]\n\n        or\n\n        {\n            seqid_1: [GffFeature_1, ...],\n            seqid_2: [GffFeature_2, ...], ...\n        }\n    \"\"\"\n    with GffParser(file) as parser:\n        features = [feature for feature in parser]\n    if as_dict:\n        D = {}\n        for f in features:\n            D.setdefault(f.seqid, [])\n            D[f.seqid].append(f)\n        return D\n"]]}
{"hexsha": "a3fe4ca6378c81dc6c16f114a862eea6f04204b0", "ext": "py", "lang": "Python", "content": "def dict_patch(path, value):\n    \"\"\"Return dictionary patch.\n\n    Used for merging.\n    \"\"\"\n    if not path:\n        return value\n\n    if isinstance(path, str):\n        path = path.split(\".\")\n\n    curr = result = {}\n    for k in path[:-1]:\n        curr[k] = {}\n        curr = curr[k]\n\n    curr[path[-1]] = value\n    return result", "fn_id": 11, "class_fn": false, "repo": "jkr78/PyEnvVirtualEnv", "file": "PyenvEnv.py", "last_update_at": "2019-02-14T04:48:25+00:00", "question_id": "a3fe4ca6378c81dc6c16f114a862eea6f04204b0_11", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def dict_patch(path, value):\n    \"\"\"Return dictionary patch.\n\n    Used for merging.\n    \"\"\"\n    if not path:\n        return value\n    if isinstance(path, str):\n        path = path.split('.')\n    curr = result = {}\n    for k in path[:-1]:\n        curr[k] = {}\n        curr = curr[k]\n    curr[path[-1]] = value\n"]]}
{"hexsha": "bbe4897ba0221b59de6a01b5a4d7a01e83b0015f", "ext": "py", "lang": "Python", "content": "def get_schema(cursor):\n    \"\"\"Get the sqlite schema for all the tables\"\"\"\n    tables = query_sqlite(cursor, \"name\", \"sqlite_master\", \"type='table'\")\n    schema_dict = {}\n    for table in tables:\n        # print(row[0])\n        # print(table[0])\n        cursor.execute(\"PRAGMA table_info('%s')\" % table[0])\n        schema_list = cursor.fetchall()\n        schema = {}\n        for row in schema_list:\n            schema[row[1]] = row[0]\n            # print(row)\n        schema_dict[table[0]] = schema\n    return schema_dict", "fn_id": 2, "class_fn": false, "repo": "mkschleg/zotero_manager", "file": "zotero_pdf_manager.py", "last_update_at": "2019-03-05T11:06:08+00:00", "question_id": "bbe4897ba0221b59de6a01b5a4d7a01e83b0015f_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_schema(cursor):\n    \"\"\"Get the sqlite schema for all the tables\"\"\"\n    tables = query_sqlite(cursor, 'name', 'sqlite_master', \"type='table'\")\n    schema_dict = {}\n    for table in tables:\n        cursor.execute(\"PRAGMA table_info('%s')\" % table[0])\n        schema_list = cursor.fetchall()\n        schema = {}\n        for row in schema_list:\n            schema[row[1]] = row[0]\n        schema_dict[table[0]] = schema\n"]]}
{"hexsha": "987e5461de1316dcbe99ae34707833866b4ceec8", "ext": "py", "lang": "Python", "content": "def evil_player(lines, columns, white_positions, black_positions):\n    move = []\n    board = [lines, columns, white_positions, black_positions]\n    current_score = evaluation(*board)\n    possible_moves = {}\n\n    #print(current_score)\n\n    for move in get_possible_moves(*board):\n        if move[1][0] == lines:\n            return move\n        wp, bp = simulate_move(move, white_positions, black_positions)\n        score = evaluation(lines, columns, wp, bp)\n        possible_moves[move] = (score - current_score)\n        \n    if possible_moves:\n        max_value = max(possible_moves.values())\n        best_moves = list(filter(lambda key: possible_moves[key] == max_value, possible_moves.keys()))\n        index = random.randint(0, abs(len(best_moves) - 1))\n        move = best_moves[index]\n\n    return move", "fn_id": 5, "class_fn": false, "repo": "sr-henry/py_breakthrough", "file": "strategies.py", "last_update_at": "2019-08-25T16:04:04+00:00", "question_id": "987e5461de1316dcbe99ae34707833866b4ceec8_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def evil_player(lines, columns, white_positions, black_positions):\n    move = []\n    board = [lines, columns, white_positions, black_positions]\n    current_score = evaluation(*board)\n    possible_moves = {}\n    for move in get_possible_moves(*board):\n        if move[1][0] == lines:\n            return move\n        wp, bp = simulate_move(move, white_positions, black_positions)\n        score = evaluation(lines, columns, wp, bp)\n        possible_moves[move] = score - current_score\n    if possible_moves:\n        max_value = max(possible_moves.values())\n        best_moves = list(filter(lambda key: possible_moves[key] == max_value, possible_moves.keys()))\n        index = random.randint(0, abs(len(best_moves) - 1))\n        move = best_moves[index]\n"]]}
{"hexsha": "a7e3852cc2ba11d5ab68c9aeaa32949fb2d31c3a", "ext": "py", "lang": "Python", "content": "def test_web_authorize(client_with_auth):\n    env = client_with_auth.config.env\n\n    global KEY_PAIR\n    KEY_PAIR[env] = utility.create_key_pair()\n\n    res = client_with_auth.dapp.web_authorize(APP_ADDRESS[env])\n    assert res.status_code == 200\n    data = res.json()\n    global CODE\n    CODE[env] = data['code']\n    assert CODE[env]", "fn_id": 8, "class_fn": false, "repo": "Press-One/prs-lib-py", "file": "tests/test_dapp.py", "last_update_at": "2019-07-27T06:41:18+00:00", "question_id": "a7e3852cc2ba11d5ab68c9aeaa32949fb2d31c3a_8", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_web_authorize(client_with_auth):\n    env = client_with_auth.config.env\n    global KEY_PAIR\n    KEY_PAIR[env] = utility.create_key_pair()\n    res = client_with_auth.dapp.web_authorize(APP_ADDRESS[env])\n    assert res.status_code == 200\n    data = res.json()\n    global CODE\n    CODE[env] = data['code']\n"]]}
{"hexsha": "249cd3e855842f095ddeb112f4f22c4de4942320", "ext": "py", "lang": "Python", "content": "def test_add_delete_prefix():\n    ipam.add_prefix('to_be_removed','10.0.0.0/16')\n    ipam.delete_prefix('10.0.0.0/16')\n    with db() as conn:\n        sql = \"SELECT * FROM netrino_prefix WHERE a4=? \" \\\n              \"AND prefix_len=? ORDER BY prefix_len\"\n        rows = conn.execute(sql, (167772160,16)).fetchall()\n    assert len(rows) == 0", "fn_id": 17, "class_fn": false, "repo": "HieronymusCrouse/netrino", "file": "tests/test_ipam.py", "last_update_at": "2019-05-16T16:57:30+00:00", "question_id": "249cd3e855842f095ddeb112f4f22c4de4942320_17", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_add_delete_prefix():\n    ipam.add_prefix('to_be_removed', '10.0.0.0/16')\n    ipam.delete_prefix('10.0.0.0/16')\n    with db() as conn:\n        sql = 'SELECT * FROM netrino_prefix WHERE a4=? AND prefix_len=? ORDER BY prefix_len'\n        rows = conn.execute(sql, (167772160, 16)).fetchall()\n"]]}
{"hexsha": "5a6f639acb1b161fc4c758cee5e0d6b1c99b56d6", "ext": "py", "lang": "Python", "content": "def make_index(host, port, bucket):\n\n    s3 = boto3.client('s3')\n    response = s3.list_objects_v2(Bucket=bucket, Prefix='{host}:{port}/'.format(host=host, port=port), Delimiter='/')\n\n    print(response)\n\n    prefixes = [p['Prefix'] for p in response.get('CommonPrefixes', [])]\n\n    with tempfile.NamedTemporaryFile() as tmp:\n\n        tmp.write('''\n<html><head><title>Reports for {host}:{port}</title></head>\n<h1>Reports for {host}:{port}</h1>\n<ul>\n        '''.format(**locals()).encode('utf-8'))\n\n        for prefix in sorted(prefixes):\n            print(prefix)\n            dirname = prefix.split('/')[1]\n            tmp.write('''\n<li>\n  <a href=\"/{prefix}report.html\">\n    {dirname}\n  </a>\n</li>\n'''.format(**locals()).encode('utf-8'))\n\n        tmp.write(b'''\n</ul>\n''')\n\n        tmp.flush()\n        tmp.seek(0)\n\n        key = '{host}:{port}/index.html'.format(**locals())\n        s3.put_object(Bucket=bucket, Key=key, Body=tmp, ContentType='text/html; charset=utf-8')\n\n        print('create index:', key)", "fn_id": 6, "class_fn": false, "repo": "voyagegroup/hakaru201911-team-b", "file": "kakeru/multinode.py", "last_update_at": "2019-11-04T00:17:55+00:00", "question_id": "5a6f639acb1b161fc4c758cee5e0d6b1c99b56d6_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def make_index(host, port, bucket):\n    s3 = boto3.client('s3')\n    response = s3.list_objects_v2(Bucket=bucket, Prefix='{host}:{port}/'.format(host=host, port=port), Delimiter='/')\n    print(response)\n    prefixes = [p['Prefix'] for p in response.get('CommonPrefixes', [])]\n    with tempfile.NamedTemporaryFile() as tmp:\n        tmp.write('\\n<html><head><title>Reports for {host}:{port}</title></head>\\n<h1>Reports for {host}:{port}</h1>\\n<ul>\\n        '.format(**locals()).encode('utf-8'))\n        for prefix in sorted(prefixes):\n            print(prefix)\n            dirname = prefix.split('/')[1]\n            tmp.write('\\n<li>\\n  <a href=\"/{prefix}report.html\">\\n    {dirname}\\n  </a>\\n</li>\\n'.format(**locals()).encode('utf-8'))\n        tmp.write(b'\\n</ul>\\n')\n        tmp.flush()\n        tmp.seek(0)\n        key = '{host}:{port}/index.html'.format(**locals())\n        s3.put_object(Bucket=bucket, Key=key, Body=tmp, ContentType='text/html; charset=utf-8')\n"]]}
{"hexsha": "7c80933d5b2e98d963d6420181a06d08257f1993", "ext": "py", "lang": "Python", "content": "def test_create_dir_isfile(tmpdir):\n    entry = {'assembly_accession': 'FAKE0.1'}\n    output = tmpdir.mkdir('output')\n    output.join('refseq', 'bacteria', 'FAKE0.1').write('foo', ensure=True)\n    with pytest.raises(OSError):\n        core.create_dir(entry, 'refseq', 'bacteria', str(output), flat_output=False)", "fn_id": 31, "class_fn": false, "repo": "luizirber/ncbi-genome-download", "file": "tests/test_core.py", "last_update_at": "2019-11-25T03:46:32+00:00", "question_id": "7c80933d5b2e98d963d6420181a06d08257f1993_31", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_create_dir_isfile(tmpdir):\n    entry = {'assembly_accession': 'FAKE0.1'}\n    output = tmpdir.mkdir('output')\n    output.join('refseq', 'bacteria', 'FAKE0.1').write('foo', ensure=True)\n    with pytest.raises(OSError):\n"]]}
{"hexsha": "1840e87be59bd6818b0b1170d5b7b76a9db29ded", "ext": "py", "lang": "Python", "content": "def main():\n    glutInit(sys.argv)                              # tells the python we are going to be displaying GLUT style graphics\n    glutInitDisplayMode(GLUT_SINGLE | GLUT_RGB)\n    glutCreateWindow(\"Plot Points\")\n    glutInitWindowSize(400,400)\n    glutInitWindowPosition(50,50)\n    glutDisplayFunc(plotfunc)\n    init()\n    glutMainLoop()", "fn_id": 1, "class_fn": false, "repo": "SayanGhoshBDA/code-backup", "file": "python/pyopenGL/ogl1/ogl_8_multiple_plots.py", "last_update_at": "2019-05-08T10:09:52+00:00", "question_id": "1840e87be59bd6818b0b1170d5b7b76a9db29ded_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main():\n    glutInit(sys.argv)\n    glutInitDisplayMode(GLUT_SINGLE | GLUT_RGB)\n    glutCreateWindow('Plot Points')\n    glutInitWindowSize(400, 400)\n    glutInitWindowPosition(50, 50)\n    glutDisplayFunc(plotfunc)\n    init()\n"]]}
{"hexsha": "c382277e65ca74c7ee0c5c3853bca8cac8886eba", "ext": "py", "lang": "Python", "content": "@then('the text is substituted as expected')\ndef step_impl(context):\n    assert context.saved_text, 'context.saved_text is %r!!' % (context.saved_text, )\n    expected = TEXT.replace('ipsum', context.active_outline['ipsum'])\n    context.saved_text.assert_equals(expected)", "fn_id": 6, "class_fn": false, "repo": "wombat70/behave", "file": "tools/test-features/steps/steps.py", "last_update_at": "2019-10-16T02:01:57+00:00", "question_id": "c382277e65ca74c7ee0c5c3853bca8cac8886eba_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@then('the text is substituted as expected')\ndef step_impl(context):\n    assert context.saved_text, 'context.saved_text is %r!!' % (context.saved_text,)\n    expected = TEXT.replace('ipsum', context.active_outline['ipsum'])\n"]]}
{"hexsha": "95025b8ecc0433bcac856af7d80552724c5265d7", "ext": "py", "lang": "Python", "content": "def listPersons(date, computer_id=None, shift_id=None):\n  global _PERSONS, _PERSONS_PER_PID\n\n  if not _PERSONS:\n    listShifts()\n    listComputers()\n    where = [('start_date', '<=', date), 'and', ('end_date', '>=', date)]\n    _PERSONS = database.select('persons', where=where, order='name')\n    _PERSONS_PER_PID.update({ p['pid']: p for p in _PERSONS })\n    for p in _PERSONS: _updatePerson(p, date)\n\n  pl = _PERSONS\n\n  if computer_id is not None:\n    pl = [p for p in pl if p['computer_id'] == computer_id]\n  if shift_id is not None:\n    pl = [p for p in pl if p['shift_id'] == shift_id]\n\n  return pl", "fn_id": 18, "class_fn": false, "repo": "tpseitz/sykeit", "file": "bin/objects.py", "last_update_at": "2019-06-06T08:23:21+00:00", "question_id": "95025b8ecc0433bcac856af7d80552724c5265d7_18", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def listPersons(date, computer_id=None, shift_id=None):\n    global _PERSONS, _PERSONS_PER_PID\n    if not _PERSONS:\n        listShifts()\n        listComputers()\n        where = [('start_date', '<=', date), 'and', ('end_date', '>=', date)]\n        _PERSONS = database.select('persons', where=where, order='name')\n        _PERSONS_PER_PID.update({p['pid']: p for p in _PERSONS})\n        for p in _PERSONS:\n            _updatePerson(p, date)\n    pl = _PERSONS\n    if computer_id is not None:\n        pl = [p for p in pl if p['computer_id'] == computer_id]\n    if shift_id is not None:\n        pl = [p for p in pl if p['shift_id'] == shift_id]\n"]]}
{"hexsha": "2466ab033bb80ae175af1d8873a42351c8e440a8", "ext": "py", "lang": "Python", "content": "@mock.patch('spreadsplug.hidtrigger.hidapi.enumerate')\n@mock.patch('spreadsplug.hidtrigger.hidapi.Device')\ndef test_trigger_loop(devicecls, hid_enumerate, plugin):\n    mock_dev = mock.Mock()\n    mock_dev.read.side_effect = chain(\n        list(chain(repeat(None, 10), ('foo',), repeat(None, 10), ('bar',)))*6,\n        repeat(None))\n    hid_enumerate.return_value = [mock.Mock(), mock.Mock()]\n    devicecls.return_value = mock_dev\n    mock_cb = mock.Mock()\n    plugin.start_trigger_loop(mock_cb)\n    time.sleep(1.3)\n    plugin.stop_trigger_loop()\n    assert not plugin._loop_thread.is_alive()\n    assert mock_cb.call_count == 6", "fn_id": 0, "class_fn": false, "repo": "atomotic/spreads", "file": "tests/hidtrigger_test.py", "last_update_at": "2019-05-03T11:58:10+00:00", "question_id": "2466ab033bb80ae175af1d8873a42351c8e440a8_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@mock.patch('spreadsplug.hidtrigger.hidapi.enumerate')\n@mock.patch('spreadsplug.hidtrigger.hidapi.Device')\ndef test_trigger_loop(devicecls, hid_enumerate, plugin):\n    mock_dev = mock.Mock()\n    mock_dev.read.side_effect = chain(list(chain(repeat(None, 10), ('foo',), repeat(None, 10), ('bar',))) * 6, repeat(None))\n    hid_enumerate.return_value = [mock.Mock(), mock.Mock()]\n    devicecls.return_value = mock_dev\n    mock_cb = mock.Mock()\n    plugin.start_trigger_loop(mock_cb)\n    time.sleep(1.3)\n    plugin.stop_trigger_loop()\n    assert not plugin._loop_thread.is_alive()\n"]]}
{"hexsha": "0c588378bd5401215cabdd21bf0ac6979ca81716", "ext": "py", "lang": "Python", "content": "def user_music_dir():\n    r\"\"\"Return full path to the user's music directory.\n\n    Typical user desktop directories are:\n        Mac OS X:   ~/Music\n        Unix:       ~/Music  # or under $XDG_MUSIC_DIR if defined\n        Windows:    C:\\Users\\<username>\\Music\n\n    Returns\n    -------\n    path : str\n        Returns a full path to the directory.\n    \"\"\"\n    if system == \"darwin\":\n        path = os.path.expanduser('~/Music')\n    elif system == \"win32\":\n        path = _get_win_folder_from_knownid('{4BD8D571-6D19-48D3-BE97-422220080E43}')\n    else:\n        path = os.getenv('XDG_MUSIC_DIR', xdg_user_dirs['XDG_MUSIC_DIR'])\n    return path", "fn_id": 10, "class_fn": false, "repo": "Doik/micropsi2", "file": "appdirs.py", "last_update_at": "2019-01-07T21:33:18+00:00", "question_id": "0c588378bd5401215cabdd21bf0ac6979ca81716_10", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def user_music_dir():\n    \"\"\"Return full path to the user's music directory.\n\n    Typical user desktop directories are:\n        Mac OS X:   ~/Music\n        Unix:       ~/Music  # or under $XDG_MUSIC_DIR if defined\n        Windows:    C:\\\\Users\\\\<username>\\\\Music\n\n    Returns\n    -------\n    path : str\n        Returns a full path to the directory.\n    \"\"\"\n    if system == 'darwin':\n        path = os.path.expanduser('~/Music')\n    elif system == 'win32':\n        path = _get_win_folder_from_knownid('{4BD8D571-6D19-48D3-BE97-422220080E43}')\n    else:\n        path = os.getenv('XDG_MUSIC_DIR', xdg_user_dirs['XDG_MUSIC_DIR'])\n"]]}
{"hexsha": "566e2f5954672b5e51587b206d9832cf0f5600de", "ext": "py", "lang": "Python", "content": "def check_bq_table(table):\n    \"\"\" Check connection string to BigQuery \"\"\"\n    bq_client = None\n    try:\n        bq_client = bigquery.Client.from_service_account_json(settings.BQ_SETTING_FILE)\n    except Exception as ex:\n        print(\"Authentication with BigQuery failed. (check settings.BQ_SETTING_FILE)\")\n        return False\n\n    tables = []\n    try:\n        bq_dataset = bq_client.dataset(settings.DATASET_NAME)\n        tables = list(bq_client.list_tables(bq_dataset))\n    except Exception as ex:\n        print(\"Dataset '{}' not found in BigQuery. Command failed.\".format(settings.DATASET_NAME))\n        return False\n\n    exist = table in [t.table_id for t in tables]\n    if not exist:\n        print(\"Table '{}' not found in BigQuery. Command failed.\".format(table))\n    return exist", "fn_id": 10, "class_fn": false, "repo": "rjuppa/soc_marketing", "file": "twapi.py", "last_update_at": "2019-11-18T08:20:32+00:00", "question_id": "566e2f5954672b5e51587b206d9832cf0f5600de_10", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def check_bq_table(table):\n    \"\"\" Check connection string to BigQuery \"\"\"\n    bq_client = None\n    try:\n        bq_client = bigquery.Client.from_service_account_json(settings.BQ_SETTING_FILE)\n    except Exception as ex:\n        print('Authentication with BigQuery failed. (check settings.BQ_SETTING_FILE)')\n        return False\n    tables = []\n    try:\n        bq_dataset = bq_client.dataset(settings.DATASET_NAME)\n        tables = list(bq_client.list_tables(bq_dataset))\n    except Exception as ex:\n        print(\"Dataset '{}' not found in BigQuery. Command failed.\".format(settings.DATASET_NAME))\n        return False\n    exist = table in [t.table_id for t in tables]\n    if not exist:\n        print(\"Table '{}' not found in BigQuery. Command failed.\".format(table))\n"]]}
{"hexsha": "878a1f84d31b1cecec2f70bd27005a1a3bb9ce40", "ext": "py", "lang": "Python", "content": "def generate_and_save_lmplot(df, outf):\n    \"\"\"Generate a limplot and save it out.\"\"\"\n    sns_fig = sns.lmplot(data=df, x='sqft_living', y='price', hue='waterfront')\n    sns_fig.savefig(outf, dpi=600)", "fn_id": 3, "class_fn": false, "repo": "BenjaminSchwessinger/ABC_python", "file": "Housing_sales_analysis.py", "last_update_at": "2019-02-06T22:38:47+00:00", "question_id": "878a1f84d31b1cecec2f70bd27005a1a3bb9ce40_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def generate_and_save_lmplot(df, outf):\n    \"\"\"Generate a limplot and save it out.\"\"\"\n    sns_fig = sns.lmplot(data=df, x='sqft_living', y='price', hue='waterfront')\n"]]}
{"hexsha": "7f29bffc7ead33753995a53e50a51fd006db7d57", "ext": "py", "lang": "Python", "content": "def solve():\n    part_one = True\n    for n in numbers:\n        for b in boards:\n            if b.active and b.mark(n) and b.check_win():\n                if part_one:\n                    print(f\"The following board won:{b}\")\n                    print(f\"The last drawn number was {n}\")\n                    print(f\"Sum of unmarked numbers on board: {(sum := b.sum())}\")\n                    print(f\"The answer to part one: {sum}\")\n                    part_one = False\n                if active_boards() > 1:\n                    b.active = False\n                    print(\n                        f\"A board was eliminated. Remaining boards: {active_boards()}\"\n                    )\n                else:\n                    print(f\"The following was the last board:{b}\")\n                    print(f\"The last drawn number was {n}\")\n                    print(f\"Sum of unmarked numbers on board: {(sum := b.sum())}\")\n                    print(f\"The answer to part two: {n*sum}\")\n                    return", "fn_id": 0, "class_fn": false, "repo": "bucsi/aoc", "file": "2021/4/solution.py", "last_update_at": "2019-12-04T12:01:29+00:00", "question_id": "7f29bffc7ead33753995a53e50a51fd006db7d57_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def solve():\n    part_one = True\n    for n in numbers:\n        for b in boards:\n            if b.active and b.mark(n) and b.check_win():\n                if part_one:\n                    print(f'The following board won:{b}')\n                    print(f'The last drawn number was {n}')\n                    print(f'Sum of unmarked numbers on board: {(sum := b.sum())}')\n                    print(f'The answer to part one: {sum}')\n                    part_one = False\n                if active_boards() > 1:\n                    b.active = False\n                    print(f'A board was eliminated. Remaining boards: {active_boards()}')\n                else:\n                    print(f'The following was the last board:{b}')\n                    print(f'The last drawn number was {n}')\n                    print(f'Sum of unmarked numbers on board: {(sum := b.sum())}')\n                    print(f'The answer to part two: {n * sum}')\n"]]}
{"hexsha": "92ff2720f68619c5fab208029a1b917012cc5338", "ext": "py", "lang": "Python", "content": "def is_func_default(node):\n    \"\"\"return true if the given Name node is used in function default argument's\n    value\n    \"\"\"\n    parent = node.scope()\n    if isinstance(parent, astng.Function):\n        for default_node in parent.args.defaults:\n            for default_name_node in default_node.nodes_of_class(astng.Name):\n                if default_name_node is node:\n                    return True\n    return False", "fn_id": 6, "class_fn": false, "repo": "jgmize/kitsune", "file": "vendor/packages/pylint/checkers/utils.py", "last_update_at": "2019-10-05T11:37:02+00:00", "question_id": "92ff2720f68619c5fab208029a1b917012cc5338_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def is_func_default(node):\n    \"\"\"return true if the given Name node is used in function default argument's\n    value\n    \"\"\"\n    parent = node.scope()\n    if isinstance(parent, astng.Function):\n        for default_node in parent.args.defaults:\n            for default_name_node in default_node.nodes_of_class(astng.Name):\n                if default_name_node is node:\n                    return True\n"]]}
{"hexsha": "16d5224e9fa82f81b7db23062bd2bd0f7a445c86", "ext": "py", "lang": "Python", "content": "@hookimpl(trylast=True)\ndef pytest_runtest_setup(item: Item) -> None:\n    if not isinstance(item, Function):\n        return\n    # Don't do nose style setup/teardown on direct unittest style classes.\n    if isinstance(item, TestCaseFunction):\n        return\n\n    # Capture the narrowed type of item for the teardown closure,\n    # see https://github.com/python/mypy/issues/2608\n    func = item\n\n    if not call_optional(func.obj, \"setup\"):\n        # Call module level setup if there is no object level one.\n        assert func.parent is not None\n        call_optional(func.parent.obj, \"setup\")  # type: ignore[attr-defined]\n\n    def teardown_nose() -> None:\n        if not call_optional(func.obj, \"teardown\"):\n            assert func.parent is not None\n            call_optional(func.parent.obj, \"teardown\")  # type: ignore[attr-defined]\n\n    # XXX This implies we only call teardown when setup worked.\n    func.addfinalizer(teardown_nose)", "fn_id": 0, "class_fn": false, "repo": "christian-steinmeyer/pytest", "file": "src/_pytest/nose.py", "last_update_at": "2019-12-17T09:16:09+00:00", "question_id": "16d5224e9fa82f81b7db23062bd2bd0f7a445c86_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@hookimpl(trylast=True)\ndef pytest_runtest_setup(item: Item) -> None:\n    if not isinstance(item, Function):\n        return\n    if isinstance(item, TestCaseFunction):\n        return\n    func = item\n    if not call_optional(func.obj, 'setup'):\n        assert func.parent is not None\n        call_optional(func.parent.obj, 'setup')\n\n    def teardown_nose() -> None:\n        if not call_optional(func.obj, 'teardown'):\n            assert func.parent is not None\n            call_optional(func.parent.obj, 'teardown')\n"]]}
{"hexsha": "73ddfa2398fea7404aa54690d3a3b3f61838dee1", "ext": "py", "lang": "Python", "content": "def process_expertise_change(inputs):\n    sent = []\n    for i in inputs:\n        sent.append(Expertise.query.filter_by(course_prefix=i.split('-')[0],\n                                              course_level=i.split('-')[1]).first())\n\n    user = User.query.get(current_user.id)\n    current = user.fields.all()\n\n    # checks the sent fields against current fields\n    # looks for expertise that exist in sent but not in current fields\n    # adds the new fields\n    for s in sent:\n        if s not in current:\n            user.fields.append(s)\n\n    # looks for expertise that exist in current but not in sent\n    # removes them from current\n    for c in current:\n        if c not in sent:\n            user.fields.remove(c)\n\n    db.session.commit()", "fn_id": 1, "class_fn": false, "repo": "tclerico/SAAC", "file": "app/services.py", "last_update_at": "2019-01-24T15:09:17+00:00", "question_id": "73ddfa2398fea7404aa54690d3a3b3f61838dee1_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def process_expertise_change(inputs):\n    sent = []\n    for i in inputs:\n        sent.append(Expertise.query.filter_by(course_prefix=i.split('-')[0], course_level=i.split('-')[1]).first())\n    user = User.query.get(current_user.id)\n    current = user.fields.all()\n    for s in sent:\n        if s not in current:\n            user.fields.append(s)\n    for c in current:\n        if c not in sent:\n            user.fields.remove(c)\n"]]}
{"hexsha": "c54a9788e7a189d623e8f3728d46069cef94a2a0", "ext": "py", "lang": "Python", "content": "def load_tree_object(filename):\n    \"\"\"\n    Load scikit-learn decision tree ensemble object from file.\n    \n    Parameters\n    ----------\n    filename : str\n        Name of the pickle file containing the tree object.\n    \n    Returns\n    -------\n    tree ensemble object\n    \"\"\"\n    with open(filename) as file_obj:\n        tree_ensemble_obj = pickle.load(file_obj)\n    return tree_ensemble_obj", "fn_id": 1, "class_fn": false, "repo": "alburke/hagelslag", "file": "hagelslag/util/output_tree_ensembles.py", "last_update_at": "2019-04-09T11:57:08+00:00", "question_id": "c54a9788e7a189d623e8f3728d46069cef94a2a0_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def load_tree_object(filename):\n    \"\"\"\n    Load scikit-learn decision tree ensemble object from file.\n    \n    Parameters\n    ----------\n    filename : str\n        Name of the pickle file containing the tree object.\n    \n    Returns\n    -------\n    tree ensemble object\n    \"\"\"\n    with open(filename) as file_obj:\n        tree_ensemble_obj = pickle.load(file_obj)\n"]]}
{"hexsha": "542190e3b5ee0862eefa27377bd21469fe4daedc", "ext": "py", "lang": "Python", "content": "def main(argv = None):\n\tif argv is None:\n\t\targv = sys.argv[1:] # pragma: no cover\n\n\tsumode = 'not'\n\tif '--sumode-pre' in argv:\n\t\targv.remove('--sumode-pre')\n\t\tsumode = 'pre'\n\telif '--sumode-post' in argv:\n\t\targv.remove('--sumode-post')\n\t\tsumode = 'post'\n\n\t_parser = flags.new('sadm', desc = 'deploy sadm env')\n\targs = _getArgs(_parser, argv)\n\tlog.debug(\"deploy %s/%s sumode=%s\" % (args.profile, args.env, sumode))\n\n\tif sumode == 'not' and sh.getuid() == 0:\n\t\tlog.error('do not run as root')\n\t\treturn 9\n\n\ttry:\n\t\tcmd = args.command\n\texcept AttributeError: # pragma: no cover\n\t\tlog.error('invalid usage')\n\t\t_parser.print_usage()\n\t\treturn 1\n\tlog.debug(\"dispatch command %s\" % cmd)\n\n\tif args.command == 'import':\n\t\treturn loader.main(args)\n\n\treturn deploy.main(args, sumode)", "fn_id": 1, "class_fn": false, "repo": "jrmsdev/pysadm", "file": "_sadm/cmd/deploy/__init__.py", "last_update_at": "2019-10-15T08:37:56+00:00", "question_id": "542190e3b5ee0862eefa27377bd21469fe4daedc_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main(argv=None):\n    if argv is None:\n        argv = sys.argv[1:]\n    sumode = 'not'\n    if '--sumode-pre' in argv:\n        argv.remove('--sumode-pre')\n        sumode = 'pre'\n    elif '--sumode-post' in argv:\n        argv.remove('--sumode-post')\n        sumode = 'post'\n    _parser = flags.new('sadm', desc='deploy sadm env')\n    args = _getArgs(_parser, argv)\n    log.debug('deploy %s/%s sumode=%s' % (args.profile, args.env, sumode))\n    if sumode == 'not' and sh.getuid() == 0:\n        log.error('do not run as root')\n        return 9\n    try:\n        cmd = args.command\n    except AttributeError:\n        log.error('invalid usage')\n        _parser.print_usage()\n        return 1\n    log.debug('dispatch command %s' % cmd)\n    if args.command == 'import':\n        return loader.main(args)\n"]]}
{"hexsha": "30ba5390ae67857af456ae2787d75573c28e66b3", "ext": "py", "lang": "Python", "content": "def send_mail(mail_name,mail_host,mail_user,mail_pass,mail_postfix,to_list,subject,content): \n    me=mail_name+\"<\"+mail_user+\"@\"+mail_postfix+\">\"\n    msg = MIMEText(content,_subtype='html',_charset='utf-8')\n    msg['Subject'] = subject\n    msg['From'] = me  \n    msg['To'] = \";\".join(to_list)  \n    try:  \n        s = smtplib.SMTP()  \n        s.connect(mail_host) \n        s.login(mail_user,mail_pass) \n        s.sendmail(me, to_list, msg.as_string()) \n        s.close()  \n        return True  \n    except Exception as e:  \n        print(str(e)  )\n        return False  ", "fn_id": 35, "class_fn": false, "repo": "einsxiao/evawiz", "file": "scripts/evawiz_basic.py", "last_update_at": "2019-06-07T03:44:39+00:00", "question_id": "30ba5390ae67857af456ae2787d75573c28e66b3_35", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def send_mail(mail_name, mail_host, mail_user, mail_pass, mail_postfix, to_list, subject, content):\n    me = mail_name + '<' + mail_user + '@' + mail_postfix + '>'\n    msg = MIMEText(content, _subtype='html', _charset='utf-8')\n    msg['Subject'] = subject\n    msg['From'] = me\n    msg['To'] = ';'.join(to_list)\n    try:\n        s = smtplib.SMTP()\n        s.connect(mail_host)\n        s.login(mail_user, mail_pass)\n        s.sendmail(me, to_list, msg.as_string())\n        s.close()\n        return True\n    except Exception as e:\n        print(str(e))\n"]]}
{"hexsha": "3f9ec282ed4547f2862e2f1365aea29123eb3226", "ext": "py", "lang": "Python", "content": "def test_snips_component_mqtt_connection_with_tls_and_authentication(fs, mocker):\n    \"\"\"Test whether a `MQTTSnipsComponent` object with TLS and MQTT\n    authentication connects to the MQTT broker correctly.\n    \"\"\"\n\n    config_file = '/etc/snips.toml'\n    fs.create_file(config_file,\n                   contents='[snips-common]\\n'\n                            'mqtt = \"mqtt.example.com:4883\"\\n'\n                            'mqtt_username = \"foobar\"\\n'\n                            'mqtt_password = \"secretpassword\"\\n'\n                            'mqtt_tls_hostname=\"mqtt.example.com\"\\n'\n                            'mqtt_tls_cafile=\"/etc/ssl/certs/ca-certificates.crt\"\\n')\n\n    mocker.patch('paho.mqtt.client.Client.connect')\n    mocker.patch('paho.mqtt.client.Client.loop_forever')\n    mocker.patch('paho.mqtt.client.Client.tls_set')\n    mocker.patch('paho.mqtt.client.Client.username_pw_set')\n    mocker.patch.object(SimpleMQTTComponent, 'initialize')\n\n    component = SimpleMQTTComponent()\n\n    # Check configuration\n    assert component.snips.mqtt.broker_address == 'mqtt.example.com:4883'\n    assert component.snips.mqtt.auth.username == 'foobar'\n    assert component.snips.mqtt.auth.password == 'secretpassword'\n    assert component.snips.mqtt.tls.hostname == 'mqtt.example.com'\n    assert component.snips.mqtt.tls.ca_file == '/etc/ssl/certs/ca-certificates.crt'\n\n    # Check MQTT connection\n    component.mqtt.username_pw_set.assert_called_once_with('foobar',\n                                                           'secretpassword')\n    component.mqtt.tls_set.assert_called_once_with(ca_certs='/etc/ssl/certs/ca-certificates.crt',\n                                                   certfile=None,\n                                                   keyfile=None)\n    assert component.mqtt.loop_forever.call_count == 1\n    component.mqtt.connect.assert_called_once_with('mqtt.example.com', 4883,\n                                                   60, '')\n\n    # Check whether `initialize()` method is called.\n    assert component.initialize.call_count == 1", "fn_id": 3, "class_fn": false, "repo": "fossabot/snipskit", "file": "tests/mqtt/test_components_mqtt_connection.py", "last_update_at": "2019-08-14T03:13:32+00:00", "question_id": "3f9ec282ed4547f2862e2f1365aea29123eb3226_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_snips_component_mqtt_connection_with_tls_and_authentication(fs, mocker):\n    \"\"\"Test whether a `MQTTSnipsComponent` object with TLS and MQTT\n    authentication connects to the MQTT broker correctly.\n    \"\"\"\n    config_file = '/etc/snips.toml'\n    fs.create_file(config_file, contents='[snips-common]\\nmqtt = \"mqtt.example.com:4883\"\\nmqtt_username = \"foobar\"\\nmqtt_password = \"secretpassword\"\\nmqtt_tls_hostname=\"mqtt.example.com\"\\nmqtt_tls_cafile=\"/etc/ssl/certs/ca-certificates.crt\"\\n')\n    mocker.patch('paho.mqtt.client.Client.connect')\n    mocker.patch('paho.mqtt.client.Client.loop_forever')\n    mocker.patch('paho.mqtt.client.Client.tls_set')\n    mocker.patch('paho.mqtt.client.Client.username_pw_set')\n    mocker.patch.object(SimpleMQTTComponent, 'initialize')\n    component = SimpleMQTTComponent()\n    assert component.snips.mqtt.broker_address == 'mqtt.example.com:4883'\n    assert component.snips.mqtt.auth.username == 'foobar'\n    assert component.snips.mqtt.auth.password == 'secretpassword'\n    assert component.snips.mqtt.tls.hostname == 'mqtt.example.com'\n    assert component.snips.mqtt.tls.ca_file == '/etc/ssl/certs/ca-certificates.crt'\n    component.mqtt.username_pw_set.assert_called_once_with('foobar', 'secretpassword')\n    component.mqtt.tls_set.assert_called_once_with(ca_certs='/etc/ssl/certs/ca-certificates.crt', certfile=None, keyfile=None)\n    assert component.mqtt.loop_forever.call_count == 1\n    component.mqtt.connect.assert_called_once_with('mqtt.example.com', 4883, 60, '')\n"]]}
{"hexsha": "5ce0d38f64d98f27c8796affbb3105766dfea656", "ext": "py", "lang": "Python", "content": "@given(\n    data_stack_depth=data_stack_depths(with_room_for_values=2),\n    tos=unsigned_numbers,\n    nos=unsigned_numbers,\n)\ndef test_unsigned_greaterthan(emulator, data_stack, data_stack_depth, tos, nos):\n    # Arrange\n    data_stack.set_depth_in_bytes(data_stack_depth)\n    data_stack.push_word(nos)\n    data_stack.push_word(tos)\n    # Act\n    _do_test_thread(emulator, \"forth.core.ext.U>\")\n    # Assert\n    assert (nos > tos) == data_stack.pop_flag()\n    assert data_stack_depth == len(data_stack)", "fn_id": 13, "class_fn": false, "repo": "psr/gigatron-rom", "file": "Contrib/psr/Forth/tests/test_core.py", "last_update_at": "2019-12-19T10:29:08+00:00", "question_id": "5ce0d38f64d98f27c8796affbb3105766dfea656_13", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@given(data_stack_depth=data_stack_depths(with_room_for_values=2), tos=unsigned_numbers, nos=unsigned_numbers)\ndef test_unsigned_greaterthan(emulator, data_stack, data_stack_depth, tos, nos):\n    data_stack.set_depth_in_bytes(data_stack_depth)\n    data_stack.push_word(nos)\n    data_stack.push_word(tos)\n    _do_test_thread(emulator, 'forth.core.ext.U>')\n    assert (nos > tos) == data_stack.pop_flag()\n"]]}
{"hexsha": "3578a862e1eb29b52b91db967dcaf7d3884d9245", "ext": "py", "lang": "Python", "content": "def test_get_non_existent_value(tracked_db):\n    with pytest.raises(KeyError):\n        tracked_db.get(b'does-not-exist')\n    assert b'does-not-exist' not in tracked_db.access_logs.reads", "fn_id": 2, "class_fn": false, "repo": "jestersimpps/py-evm", "file": "tests/database/test_tracked_db.py", "last_update_at": "2019-02-22T15:25:01+00:00", "question_id": "3578a862e1eb29b52b91db967dcaf7d3884d9245_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_get_non_existent_value(tracked_db):\n    with pytest.raises(KeyError):\n        tracked_db.get(b'does-not-exist')\n"]]}
{"hexsha": "5a213431867a3dd8f2c35ba55578f95b1f4daf8b", "ext": "py", "lang": "Python", "content": "def main():\n    parser = argparse.ArgumentParser(prog=os.path.basename(sys.argv[0]),description=\"Lumi DB schema operations.\")\n    # add the arguments\n    parser.add_argument('-c',dest='connect',action='store',required=True,help='connect string to lumiDB')\n    parser.add_argument('-P',dest='authpath',action='store',help='path to authentication file')\n    parser.add_argument('action',choices=['create','drop','describe','addindex','dropindex'],help='action on the schema')\n    parser.add_argument('--validationTab',dest='validationTab',action='store_true',help='validation table only')\n    parser.add_argument('--verbose',dest='verbose',action='store_true',help='verbose')\n    parser.add_argument('--debug',dest='debug',action='store_true',help='debug mode')\n    # parse arguments\n    args=parser.parse_args()\n    connectstring=args.connect\n    if args.debug:\n        msg=coral.MessageStream('')\n        msg.setMsgVerbosity(coral.message_Level_Debug)\n    svc = coral.ConnectionService()\n    if args.authpath and len(args.authpath)!=0:\n        os.environ['CORAL_AUTH_PATH']=args.authpath\n    session=svc.connect(connectstring,accessMode=coral.access_Update)\n    if args.action == 'create':\n       if args.validationTab:\n           createValidation(session)\n       else:\n           createLumi(session)\n    if args.action == 'drop':\n       dropLumi(session)\n    if args.action == 'describe':\n       describeLumi(session)\n    if args.action == 'addindex':\n       createIndex(session)\n    if args.action == 'dropindex':\n       dropIndex(session)\n    if args.verbose :\n        print('verbose mode')", "fn_id": 6, "class_fn": false, "repo": "bisnupriyasahu/cmssw", "file": "RecoLuminosity/LumiDB/scripts/lumiSchema.py", "last_update_at": "2019-02-19T11:45:32+00:00", "question_id": "5a213431867a3dd8f2c35ba55578f95b1f4daf8b_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main():\n    parser = argparse.ArgumentParser(prog=os.path.basename(sys.argv[0]), description='Lumi DB schema operations.')\n    parser.add_argument('-c', dest='connect', action='store', required=True, help='connect string to lumiDB')\n    parser.add_argument('-P', dest='authpath', action='store', help='path to authentication file')\n    parser.add_argument('action', choices=['create', 'drop', 'describe', 'addindex', 'dropindex'], help='action on the schema')\n    parser.add_argument('--validationTab', dest='validationTab', action='store_true', help='validation table only')\n    parser.add_argument('--verbose', dest='verbose', action='store_true', help='verbose')\n    parser.add_argument('--debug', dest='debug', action='store_true', help='debug mode')\n    args = parser.parse_args()\n    connectstring = args.connect\n    if args.debug:\n        msg = coral.MessageStream('')\n        msg.setMsgVerbosity(coral.message_Level_Debug)\n    svc = coral.ConnectionService()\n    if args.authpath and len(args.authpath) != 0:\n        os.environ['CORAL_AUTH_PATH'] = args.authpath\n    session = svc.connect(connectstring, accessMode=coral.access_Update)\n    if args.action == 'create':\n        if args.validationTab:\n            createValidation(session)\n        else:\n            createLumi(session)\n    if args.action == 'drop':\n        dropLumi(session)\n    if args.action == 'describe':\n        describeLumi(session)\n    if args.action == 'addindex':\n        createIndex(session)\n    if args.action == 'dropindex':\n        dropIndex(session)\n    if args.verbose:\n"]]}
{"hexsha": "36ae8ad2dc716541867233bc66cd1b2c94d0b099", "ext": "py", "lang": "Python", "content": "def __return_converted_value(value, std_conv_str, conv_coeffs_list, \\\n                             std_from_unit, std_to_unit, use_gnu=False, print_result=False, debug=False):\n\n    value_converted = 1.0\n    if not use_gnu:\n        value_converted = value * conv_coeffs_list[std_conv_str]\n    else:\n        out_gnu_units = sp.check_output(['units','%s %s' % (value, std_from_unit), '%s' % std_to_unit])\n        if debug:\n            print(out_gnu_units.split())\n            print(flag_from_to_units, std_conv_str, std_from_unit, std_to_unit)\n        value_converted = float(out_gnu_units.split()[1])\n\n    if print_result:\n        print(\" %s %s = %e %s\" % \\\n              (value, std_from_unit, value_converted, std_to_unit) )\n    \n    return value_converted", "fn_id": 4, "class_fn": false, "repo": "minyez/mykit", "file": "tools/pc_unitconv.py", "last_update_at": "2019-12-26T07:15:59+00:00", "question_id": "36ae8ad2dc716541867233bc66cd1b2c94d0b099_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def __return_converted_value(value, std_conv_str, conv_coeffs_list, std_from_unit, std_to_unit, use_gnu=False, print_result=False, debug=False):\n    value_converted = 1.0\n    if not use_gnu:\n        value_converted = value * conv_coeffs_list[std_conv_str]\n    else:\n        out_gnu_units = sp.check_output(['units', '%s %s' % (value, std_from_unit), '%s' % std_to_unit])\n        if debug:\n            print(out_gnu_units.split())\n            print(flag_from_to_units, std_conv_str, std_from_unit, std_to_unit)\n        value_converted = float(out_gnu_units.split()[1])\n    if print_result:\n        print(' %s %s = %e %s' % (value, std_from_unit, value_converted, std_to_unit))\n"]]}
{"hexsha": "283865c160ca3ad33e48b27b7d1a9bd2f8f0584b", "ext": "py", "lang": "Python", "content": "def vectorize_count(corpus: List[List[str]], labels: List[str] = None):\n    \"\"\" Met un corpus sous une forme vectoris\u00e9e. \"\"\"\n    corpus = map(lambda d: \" \".join(d), corpus)\n    vectorizer = CountVectorizer()\n    if labels == []:\n        return vectorizer.transform(corpus)\n    else:\n        return vectorizer.fit_transform(corpus, labels)", "fn_id": 0, "class_fn": false, "repo": "NicolasBizzozzero/Competitive-Programming", "file": "Contests/2018-03-16 - TAL 2017-2018/vectorization.py", "last_update_at": "2019-04-23T12:07:38+00:00", "question_id": "283865c160ca3ad33e48b27b7d1a9bd2f8f0584b_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def vectorize_count(corpus: List[List[str]], labels: List[str]=None):\n    \"\"\" Met un corpus sous une forme vectoris\u00e9e. \"\"\"\n    corpus = map(lambda d: ' '.join(d), corpus)\n    vectorizer = CountVectorizer()\n    if labels == []:\n        return vectorizer.transform(corpus)\n    else:\n"]]}
{"hexsha": "d4ba167c2657e860124f60def9f58fcdbba7c0df", "ext": "py", "lang": "Python", "content": "@fixture\n@using(api=api)\ndef form_view(api: Api):\n    @api.route(\"/form\")\n    class Form:\n        async def on_post(self, req, resp):\n            given_form = dict(**(await req.media()))\n            assert form_data == given_form\n\n    return Form", "fn_id": 14, "class_fn": false, "repo": "tkamenoko/spangle", "file": "tests/models/test_request.py", "last_update_at": "2019-12-01T15:32:03+00:00", "question_id": "d4ba167c2657e860124f60def9f58fcdbba7c0df_14", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@fixture\n@using(api=api)\ndef form_view(api: Api):\n\n    @api.route('/form')\n    class Form:\n\n        async def on_post(self, req, resp):\n            given_form = dict(**await req.media())\n            assert form_data == given_form\n"]]}
{"hexsha": "1bf8f41c1e9b7cf2e6801da679657578b5d57c76", "ext": "py", "lang": "Python", "content": "def sample_id_to_stft_frame_id(sample, window_length, shift, fading=True):\n    \"\"\"\n    Calculates the best frame index for a given sample index\n    :param sample: Sample index in time domain.\n    :param size: FFT size.\n    :param shift: Hop in samples.\n    :return: Best STFT frame index.\n\n\n    ## ## ## ##\n       ## ## ## ##\n          ## ## ## ##\n             ## ## ## ##\n    00 00 01 12 23 34 45\n\n\n    ## ## ## ##\n     # ## ## ## #\n       ## ## ## ##\n        # ## ## ## #\n    00 00 01 23 5 ...\n          12 34 6 ...\n\n    ## ## ## #\n       ## ## ## #\n          ## ## ## #\n             ## ## ## #\n    ## ## ## #\n    00 00 01 12 23 34 45\n\n    >>> [sample_id_to_stft_frame_id(i, 8, 1, fading=False) for i in range(12)]\n    [0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8]\n    >>> [sample_id_to_stft_frame_id(i, 8, 2, fading=False) for i in range(10)]\n    [0, 0, 0, 0, 1, 1, 2, 2, 3, 3]\n    >>> [sample_id_to_stft_frame_id(i, 7, 2, fading=False) for i in range(10)]\n    [0, 0, 0, 0, 1, 1, 2, 2, 3, 3]\n    >>> [sample_id_to_stft_frame_id(i, 7, 1, fading=False) for i in range(10)]\n    [0, 0, 0, 0, 1, 2, 3, 4, 5, 6]\n\n    >>> [sample_id_to_stft_frame_id(i, 8, 1, fading=True) for i in range(12)]\n    [7, 7, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n    >>> [sample_id_to_stft_frame_id(i, 8, 2, fading=True) for i in range(10)]\n    [3, 3, 3, 3, 4, 4, 5, 5, 6, 6]\n    >>> [sample_id_to_stft_frame_id(i, 7, 2, fading=True) for i in range(10)]\n    [3, 3, 3, 3, 4, 4, 5, 5, 6, 6]\n    >>> [sample_id_to_stft_frame_id(i, 7, 1, fading=True) for i in range(10)]\n    [6, 6, 6, 6, 7, 8, 9, 10, 11, 12]\n\n    >>> stft(np.zeros([8]), size=8, shift=2).shape\n    (7, 5)\n    >>> stft(np.zeros([8]), size=8, shift=1).shape\n    (15, 5)\n    >>> stft(np.zeros([8]), size=8, shift=4).shape\n    (3, 5)\n    \"\"\"\n\n    if (window_length + 1) // 2 > sample:\n        frame = 0\n    else:\n        frame = (sample - (window_length + 1) // 2) // shift + 1\n\n    if fading:\n        frame = frame + ceil((window_length - shift) / shift)\n\n    return frame", "fn_id": 4, "class_fn": false, "repo": "byfaith/pb_chime5", "file": "toolbox/nt/transform/module_stft.py", "last_update_at": "2019-04-04T01:46:46+00:00", "question_id": "1bf8f41c1e9b7cf2e6801da679657578b5d57c76_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def sample_id_to_stft_frame_id(sample, window_length, shift, fading=True):\n    \"\"\"\n    Calculates the best frame index for a given sample index\n    :param sample: Sample index in time domain.\n    :param size: FFT size.\n    :param shift: Hop in samples.\n    :return: Best STFT frame index.\n\n\n    ## ## ## ##\n       ## ## ## ##\n          ## ## ## ##\n             ## ## ## ##\n    00 00 01 12 23 34 45\n\n\n    ## ## ## ##\n     # ## ## ## #\n       ## ## ## ##\n        # ## ## ## #\n    00 00 01 23 5 ...\n          12 34 6 ...\n\n    ## ## ## #\n       ## ## ## #\n          ## ## ## #\n             ## ## ## #\n    ## ## ## #\n    00 00 01 12 23 34 45\n\n    >>> [sample_id_to_stft_frame_id(i, 8, 1, fading=False) for i in range(12)]\n    [0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8]\n    >>> [sample_id_to_stft_frame_id(i, 8, 2, fading=False) for i in range(10)]\n    [0, 0, 0, 0, 1, 1, 2, 2, 3, 3]\n    >>> [sample_id_to_stft_frame_id(i, 7, 2, fading=False) for i in range(10)]\n    [0, 0, 0, 0, 1, 1, 2, 2, 3, 3]\n    >>> [sample_id_to_stft_frame_id(i, 7, 1, fading=False) for i in range(10)]\n    [0, 0, 0, 0, 1, 2, 3, 4, 5, 6]\n\n    >>> [sample_id_to_stft_frame_id(i, 8, 1, fading=True) for i in range(12)]\n    [7, 7, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n    >>> [sample_id_to_stft_frame_id(i, 8, 2, fading=True) for i in range(10)]\n    [3, 3, 3, 3, 4, 4, 5, 5, 6, 6]\n    >>> [sample_id_to_stft_frame_id(i, 7, 2, fading=True) for i in range(10)]\n    [3, 3, 3, 3, 4, 4, 5, 5, 6, 6]\n    >>> [sample_id_to_stft_frame_id(i, 7, 1, fading=True) for i in range(10)]\n    [6, 6, 6, 6, 7, 8, 9, 10, 11, 12]\n\n    >>> stft(np.zeros([8]), size=8, shift=2).shape\n    (7, 5)\n    >>> stft(np.zeros([8]), size=8, shift=1).shape\n    (15, 5)\n    >>> stft(np.zeros([8]), size=8, shift=4).shape\n    (3, 5)\n    \"\"\"\n    if (window_length + 1) // 2 > sample:\n        frame = 0\n    else:\n        frame = (sample - (window_length + 1) // 2) // shift + 1\n    if fading:\n        frame = frame + ceil((window_length - shift) / shift)\n"]]}
{"hexsha": "642c188d74b4a92bf70d867e87ae07bd7728aac5", "ext": "py", "lang": "Python", "content": "def main(env=_environment):\n    args = parse_arguments()\n    if args.verbose:\n        logging.getLogger().setLevel(logging.INFO)\n    logging.info(\"arguments read: %s\", args)\n\n    assert \"method\" in args\n    assert \"resource_type\" not in args or args.resource_type in [\n        \"jobs\",\n        \"jobs.reports\",\n        \"reportTypes\",\n    ]\n    if args.method == \"fetch\":\n        r = api.fetch_report(env, job_id=args.jobId, report_id=args.reportId)\n    elif args.resource_type == \"jobs\":\n        assert args.method in [\"create\", \"delete\", \"get\", \"list\"]\n        if args.method == \"create\":\n            r = api.jobs_create(env, report_type_id=args.reportType, job_name=args.name)\n        elif args.method == \"delete\":\n            r = api.jobs_delete(env, job_id=args.jobId)\n        elif args.method == \"get\":\n            r = api.jobs_get(env, job_id=args.jobId)\n        else:  # args.method == \"list\":\n            r = api.jobs_list(env)\n    elif args.resource_type == \"jobs.reports\":\n        assert args.method in [\"get\", \"list\"]\n        if args.method == \"get\":\n            r = api.reports_get(env, job_id=args.jobId, report_id=args.reportId)\n        else:  # args.method == \"list\":\n            r = api.reports_list(\n                env,\n                job_id=args.jobId,\n                created_after=args.created_after,\n                start_time_at_or_after=args.start_time_at_or_after,\n                start_time_before=args.start_time_before,\n            )\n    else:  # args.resource_type == \"reportTypes\":\n        assert args.method in [\"list\"]\n        r = api.reporttypes_list(env)\n\n    if isinstance(r, str):\n        print(r, end=\"\")\n    elif isinstance(r, dict):\n        print(json.dumps(r, indent=2, sort_keys=True))\n    else:\n        print(r)\n\n    return ExitStatus.SUCCESS", "fn_id": 1, "class_fn": false, "repo": "understood/ytreporty", "file": "ytreporty/cli.py", "last_update_at": "2019-07-12T20:17:29+00:00", "question_id": "642c188d74b4a92bf70d867e87ae07bd7728aac5_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main(env=_environment):\n    args = parse_arguments()\n    if args.verbose:\n        logging.getLogger().setLevel(logging.INFO)\n    logging.info('arguments read: %s', args)\n    assert 'method' in args\n    assert 'resource_type' not in args or args.resource_type in ['jobs', 'jobs.reports', 'reportTypes']\n    if args.method == 'fetch':\n        r = api.fetch_report(env, job_id=args.jobId, report_id=args.reportId)\n    elif args.resource_type == 'jobs':\n        assert args.method in ['create', 'delete', 'get', 'list']\n        if args.method == 'create':\n            r = api.jobs_create(env, report_type_id=args.reportType, job_name=args.name)\n        elif args.method == 'delete':\n            r = api.jobs_delete(env, job_id=args.jobId)\n        elif args.method == 'get':\n            r = api.jobs_get(env, job_id=args.jobId)\n        else:\n            r = api.jobs_list(env)\n    elif args.resource_type == 'jobs.reports':\n        assert args.method in ['get', 'list']\n        if args.method == 'get':\n            r = api.reports_get(env, job_id=args.jobId, report_id=args.reportId)\n        else:\n            r = api.reports_list(env, job_id=args.jobId, created_after=args.created_after, start_time_at_or_after=args.start_time_at_or_after, start_time_before=args.start_time_before)\n    else:\n        assert args.method in ['list']\n        r = api.reporttypes_list(env)\n    if isinstance(r, str):\n        print(r, end='')\n    elif isinstance(r, dict):\n        print(json.dumps(r, indent=2, sort_keys=True))\n    else:\n        print(r)\n"]]}
{"hexsha": "76ba63c14a08313afcb2dc4e9820bf99718875b9", "ext": "py", "lang": "Python", "content": "def main():\n    \"\"\"Go Main Go\"\"\"\n    pgconn = get_dbconn('coop')\n    ccursor = pgconn.cursor()\n\n    fn = sys.argv[1]\n    station = sys.argv[2]\n    with ncopen(fn) as nc:\n        byear = nc.variables['byear'][:]\n        maxt = nc.variables['maxt'][:]\n        mint = nc.variables['mint'][:]\n        pcpn = nc.variables['pcpn'][:]\n        snow = nc.variables['snow'][:]\n        snwg = nc.variables['snwg'][:]\n\n    current = read_sql(\"\"\"\n        SELECT day, high, low, precip, snow, snowd from\n        alldata_ia WHERE station = %s ORDER by day ASC\n    \"\"\", pgconn, params=(station,), index_col='day')\n\n    added = 0\n    for yr in range(byear, 2016):\n        for mo in range(12):\n            for dy in range(31):\n                try:\n                    date = datetime.date(yr, mo + 1, dy + 1)\n                except ValueError:\n                    continue\n                high = maxt[yr-byear, mo, dy]\n                if (np.ma.is_masked(high) or np.isnan(high) or\n                        high < -100 or high > 150):\n                    high = None\n                else:\n                    high = int(high)\n\n                low = mint[yr-byear, mo, dy]\n                if (np.ma.is_masked(low) or np.isnan(low) or\n                        low < -100 or low > 150):\n                    low = None\n                else:\n                    low = int(low)\n\n                precip = convert(pcpn[yr-byear, mo, dy], 2)\n                snowfall = convert(snow[yr-byear, mo, dy], 1)\n                snowd = convert(snwg[yr-byear, mo, dy], 1)\n                if all([a is None\n                        for a in [high, low, precip, snowfall, snowd]]):\n                    continue\n                if date not in current.index.values:\n                    sday = \"%02i%02i\" % (date.month, date.day)\n                    added += 1\n                    ccursor.execute(\"\"\"\n                        INSERT into alldata_ia(station, day, high,\n                        low, precip, snow, sday, year, month, snowd) VALUES\n                        (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n                    \"\"\", (station, date, high, low, precip, snowfall,\n                          sday, int(date.year), int(date.month), snowd))\n\n    print(\"added %s\" % (added,))\n    ccursor.close()\n    pgconn.commit()", "fn_id": 1, "class_fn": false, "repo": "jamayfieldjr/iem", "file": "scripts/coop/ingest_nws_netcdf.py", "last_update_at": "2019-10-07T17:01:24+00:00", "question_id": "76ba63c14a08313afcb2dc4e9820bf99718875b9_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main():\n    \"\"\"Go Main Go\"\"\"\n    pgconn = get_dbconn('coop')\n    ccursor = pgconn.cursor()\n    fn = sys.argv[1]\n    station = sys.argv[2]\n    with ncopen(fn) as nc:\n        byear = nc.variables['byear'][:]\n        maxt = nc.variables['maxt'][:]\n        mint = nc.variables['mint'][:]\n        pcpn = nc.variables['pcpn'][:]\n        snow = nc.variables['snow'][:]\n        snwg = nc.variables['snwg'][:]\n    current = read_sql('\\n        SELECT day, high, low, precip, snow, snowd from\\n        alldata_ia WHERE station = %s ORDER by day ASC\\n    ', pgconn, params=(station,), index_col='day')\n    added = 0\n    for yr in range(byear, 2016):\n        for mo in range(12):\n            for dy in range(31):\n                try:\n                    date = datetime.date(yr, mo + 1, dy + 1)\n                except ValueError:\n                    continue\n                high = maxt[yr - byear, mo, dy]\n                if np.ma.is_masked(high) or np.isnan(high) or high < -100 or (high > 150):\n                    high = None\n                else:\n                    high = int(high)\n                low = mint[yr - byear, mo, dy]\n                if np.ma.is_masked(low) or np.isnan(low) or low < -100 or (low > 150):\n                    low = None\n                else:\n                    low = int(low)\n                precip = convert(pcpn[yr - byear, mo, dy], 2)\n                snowfall = convert(snow[yr - byear, mo, dy], 1)\n                snowd = convert(snwg[yr - byear, mo, dy], 1)\n                if all([a is None for a in [high, low, precip, snowfall, snowd]]):\n                    continue\n                if date not in current.index.values:\n                    sday = '%02i%02i' % (date.month, date.day)\n                    added += 1\n                    ccursor.execute('\\n                        INSERT into alldata_ia(station, day, high,\\n                        low, precip, snow, sday, year, month, snowd) VALUES\\n                        (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\\n                    ', (station, date, high, low, precip, snowfall, sday, int(date.year), int(date.month), snowd))\n    print('added %s' % (added,))\n    ccursor.close()\n"]]}
{"hexsha": "3ca67e9442436a3a4c05f92ccc99c1b4150df427", "ext": "py", "lang": "Python", "content": "def plot_and_get_real_data(row: int) -> (np.ndarray, np.ndarray):\n    data = load_data()\n    plot_real_data(data, row, row+1)\n    return get_x_y(data, row)", "fn_id": 9, "class_fn": false, "repo": "akerestely/nonlinearBestFit", "file": "tools.py", "last_update_at": "2019-10-09T07:39:55+00:00", "question_id": "3ca67e9442436a3a4c05f92ccc99c1b4150df427_9", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def plot_and_get_real_data(row: int) -> (np.ndarray, np.ndarray):\n    data = load_data()\n    plot_real_data(data, row, row + 1)\n"]]}
{"hexsha": "71cf6c963cea2a625de05fc4fdf2a497bd64100f", "ext": "py", "lang": "Python", "content": "@pytest.fixture\ndef prep_org_w_identifier():\n    o = Organization(name='test org')\n    i = Identifier(system=US_NPI, value='123-45')\n    o.identifiers.append(i)\n    with SessionScope(db):\n        db.session.add(o)\n        db.session.commit()\n    o = db.session.merge(o)\n    OrgTree().invalidate_cache()\n    yield o\n\n    OrgTree().invalidate_cache()", "fn_id": 2, "class_fn": false, "repo": "uwcirg/truenth-portal", "file": "tests/conftest.py", "last_update_at": "2019-03-11T12:25:18+00:00", "question_id": "71cf6c963cea2a625de05fc4fdf2a497bd64100f_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.fixture\ndef prep_org_w_identifier():\n    o = Organization(name='test org')\n    i = Identifier(system=US_NPI, value='123-45')\n    o.identifiers.append(i)\n    with SessionScope(db):\n        db.session.add(o)\n        db.session.commit()\n    o = db.session.merge(o)\n    OrgTree().invalidate_cache()\n    yield o\n"]]}
{"hexsha": "34889ac9488b56eb626d3c7f88669e596c3bd0cd", "ext": "py", "lang": "Python", "content": "def test_load_file():\n    response_dict = {}\n    test_folder = path.abspath(path.join(__file__, \"..\"))\n    setting_file = \"settings.yml\"\n    settings = test_folder + \"/\" + setting_file\n    client = EtcdTool(host=\"127.0.0.1\")\n    client.load(settings)\n\n    response = client.read(\"/\", recursive=True)\n\n    for result in response.children:\n        response_dict[result.key] = result.value\n\n    assert response_dict[\"/key_1\"] == \"1000\"\n    assert response_dict[\"/key_2\"] == \"1000\"\n    assert response_dict[\"/key_3\"] == \"1000.0\"\n    assert response_dict[\"/key_4\"] == \"1000.0\"\n    assert response_dict[\"/key_5\"] == \"1000\"\n    assert response_dict[\"/key_6\"] == \"Yes\"\n    assert response_dict[\"/key_7\"] == \"True\"\n\n    assert response_dict[\"/one_level/key_1\"] == \"1000\"\n    assert response_dict[\"/one_level/key_2\"] == \"1000\"\n    assert response_dict[\"/one_level/key_3\"] == \"1000.0\"\n    assert response_dict[\"/one_level/key_4\"] == \"1000.0\"\n    assert response_dict[\"/one_level/key_5\"] == \"1000\"\n    assert response_dict[\"/one_level/key_6\"] == \"Yes\"\n    assert response_dict[\"/one_level/key_7\"] == \"True\"\n\n    assert response_dict[\"/two_levels/intermediate_level/key_1\"] == \"1000\"\n    assert response_dict[\"/two_levels/intermediate_level/key_2\"] == \"1000\"\n    assert response_dict[\"/two_levels/intermediate_level/key_3\"] == \"1000.0\"\n    assert response_dict[\"/two_levels/intermediate_level/key_4\"] == \"1000.0\"\n    assert response_dict[\"/two_levels/intermediate_level/key_5\"] == \"1000\"\n    assert response_dict[\"/two_levels/intermediate_level/key_6\"] == \"Yes\"\n    assert response_dict[\"/two_levels/intermediate_level/key_7\"] == \"True\"", "fn_id": 2, "class_fn": false, "repo": "System73/tamarco", "file": "tests/functional/core/settings/utils/test_etcd_tool.py", "last_update_at": "2019-10-14T07:24:02+00:00", "question_id": "34889ac9488b56eb626d3c7f88669e596c3bd0cd_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_load_file():\n    response_dict = {}\n    test_folder = path.abspath(path.join(__file__, '..'))\n    setting_file = 'settings.yml'\n    settings = test_folder + '/' + setting_file\n    client = EtcdTool(host='127.0.0.1')\n    client.load(settings)\n    response = client.read('/', recursive=True)\n    for result in response.children:\n        response_dict[result.key] = result.value\n    assert response_dict['/key_1'] == '1000'\n    assert response_dict['/key_2'] == '1000'\n    assert response_dict['/key_3'] == '1000.0'\n    assert response_dict['/key_4'] == '1000.0'\n    assert response_dict['/key_5'] == '1000'\n    assert response_dict['/key_6'] == 'Yes'\n    assert response_dict['/key_7'] == 'True'\n    assert response_dict['/one_level/key_1'] == '1000'\n    assert response_dict['/one_level/key_2'] == '1000'\n    assert response_dict['/one_level/key_3'] == '1000.0'\n    assert response_dict['/one_level/key_4'] == '1000.0'\n    assert response_dict['/one_level/key_5'] == '1000'\n    assert response_dict['/one_level/key_6'] == 'Yes'\n    assert response_dict['/one_level/key_7'] == 'True'\n    assert response_dict['/two_levels/intermediate_level/key_1'] == '1000'\n    assert response_dict['/two_levels/intermediate_level/key_2'] == '1000'\n    assert response_dict['/two_levels/intermediate_level/key_3'] == '1000.0'\n    assert response_dict['/two_levels/intermediate_level/key_4'] == '1000.0'\n    assert response_dict['/two_levels/intermediate_level/key_5'] == '1000'\n    assert response_dict['/two_levels/intermediate_level/key_6'] == 'Yes'\n"]]}
{"hexsha": "fff96ec350f97de4db3150975c7d7f55f2b80f58", "ext": "py", "lang": "Python", "content": "def find_project_files(window, folders=None, hash_files=True):\n    \"\"\"\n    Given a list of folder entries and a potential project path, return a list\n    of all files that exist at that particular path.\n    \"\"\"\n    path = None\n    if folders is None:\n        data = window.project_data()\n        folders = data.get(\"folders\", None) if data else None\n        path = window.project_file_name()\n        if path:\n            path = os.path.split(path)[0]\n\n    files = {}\n    if not folders:\n        view = window.active_view()\n        if view and view.file_name() is not None:\n            base_folder, filename = os.path.split(view.file_name())\n            files[base_folder] = _get_file_details(base_folder, filename, hash_files)\n\n        return files\n\n    for folder in folders:\n        base_folder, folder_files = _files_for_folder(window, folder, path, hash_files)\n        files[base_folder] = folder_files\n\n    return _coalesce_folders(files)", "fn_id": 5, "class_fn": false, "repo": "OdatNurd/devember-2018", "file": "file_gather.py", "last_update_at": "2019-01-14T07:12:19+00:00", "question_id": "fff96ec350f97de4db3150975c7d7f55f2b80f58_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def find_project_files(window, folders=None, hash_files=True):\n    \"\"\"\n    Given a list of folder entries and a potential project path, return a list\n    of all files that exist at that particular path.\n    \"\"\"\n    path = None\n    if folders is None:\n        data = window.project_data()\n        folders = data.get('folders', None) if data else None\n        path = window.project_file_name()\n        if path:\n            path = os.path.split(path)[0]\n    files = {}\n    if not folders:\n        view = window.active_view()\n        if view and view.file_name() is not None:\n            base_folder, filename = os.path.split(view.file_name())\n            files[base_folder] = _get_file_details(base_folder, filename, hash_files)\n        return files\n    for folder in folders:\n        base_folder, folder_files = _files_for_folder(window, folder, path, hash_files)\n        files[base_folder] = folder_files\n"]]}
{"hexsha": "d44e1dfa133bbb79f09ce7d952a2b5ba90ccb66a", "ext": "py", "lang": "Python", "content": "def test_commmit_requires_project_id(test_db):\n    commit_id = get_dummy_hash()\n\n    try:\n        commit = Commit(id=commit_id, filename='model.onnx')\n        test_db.session.add(commit)\n        test_db.session.commit()\n    except exc.IntegrityError:\n        pass  # This exception should be thrown", "fn_id": 2, "class_fn": false, "repo": "lamby-ml/lamby-web", "file": "lamby/tests/models/test_commit.py", "last_update_at": "2019-04-25T21:32:38+00:00", "question_id": "d44e1dfa133bbb79f09ce7d952a2b5ba90ccb66a_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_commmit_requires_project_id(test_db):\n    commit_id = get_dummy_hash()\n    try:\n        commit = Commit(id=commit_id, filename='model.onnx')\n        test_db.session.add(commit)\n        test_db.session.commit()\n    except exc.IntegrityError:\n"]]}
{"hexsha": "a1f71f2efd8453668fe2ab6ac11b7f221a77698c", "ext": "py", "lang": "Python", "content": "def compute_tasks(tasks: Iterable[Any], client: Client,\n                  max_in_flight: int = 3) -> Iterable[Any]:\n    \"\"\" Parallel compute stream with back pressure.\n\n        Equivalent to:\n\n        (client.compute(task).result()\n          for task in tasks)\n\n        but with up to `max_in_flight` tasks being processed at the same time.\n        Input/Output order is preserved, so there is a possibility of head of\n        line blocking.\n\n        NOTE: lower limit is 3 concurrent tasks to simplify implementation,\n              there is no point calling this function if you want one active\n              task and supporting exactly 2 active tasks is not worth the complexity,\n              for now. We might special-case `2` at some point.\n\n    \"\"\"\n    # New thread:\n    #    1. Take dask task from iterator\n    #    2. Submit to client for processing\n    #    3. Send it of to wrk_q\n    #\n    # Calling thread:\n    #    1. Pull scheduled future from wrk_q\n    #    2. Wait for result of the future\n    #    3. yield result to calling code\n    from .generic import it2q, qmap\n\n    # (max_in_flight - 2) -- one on each side of queue\n    wrk_q = queue.Queue(maxsize=max(1, max_in_flight - 2))  # type: queue.Queue\n\n    # fifo_timeout='0ms' ensures that priority of later tasks is lower\n    futures = (client.compute(task, fifo_timeout='0ms') for task in tasks)\n\n    in_thread = threading.Thread(target=it2q, args=(futures, wrk_q))\n    in_thread.start()\n\n    yield from qmap(lambda f: f.result(), wrk_q)\n\n    in_thread.join()", "fn_id": 2, "class_fn": false, "repo": "PhilipeRLeal/datacube-core", "file": "datacube/utils/dask.py", "last_update_at": "2019-10-24T15:29:58+00:00", "question_id": "a1f71f2efd8453668fe2ab6ac11b7f221a77698c_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def compute_tasks(tasks: Iterable[Any], client: Client, max_in_flight: int=3) -> Iterable[Any]:\n    \"\"\" Parallel compute stream with back pressure.\n\n        Equivalent to:\n\n        (client.compute(task).result()\n          for task in tasks)\n\n        but with up to `max_in_flight` tasks being processed at the same time.\n        Input/Output order is preserved, so there is a possibility of head of\n        line blocking.\n\n        NOTE: lower limit is 3 concurrent tasks to simplify implementation,\n              there is no point calling this function if you want one active\n              task and supporting exactly 2 active tasks is not worth the complexity,\n              for now. We might special-case `2` at some point.\n\n    \"\"\"\n    from .generic import it2q, qmap\n    wrk_q = queue.Queue(maxsize=max(1, max_in_flight - 2))\n    futures = (client.compute(task, fifo_timeout='0ms') for task in tasks)\n    in_thread = threading.Thread(target=it2q, args=(futures, wrk_q))\n    in_thread.start()\n    yield from qmap(lambda f: f.result(), wrk_q)\n"]]}
{"hexsha": "6449df6c32e60e7984c5e8dea2c96d853c68056e", "ext": "py", "lang": "Python", "content": "@pytest.mark.parametrize(\"port\", [PORT_DEFAULT])\ndef test_slider(port):\n    nexSerial = PySerialNex(port)\n    nexSerial.init()\n\n    nexPage = NexPage(nexSerial, \"pg_slider\", pid=11)\n\n    nexSlider = NexSlider(nexSerial, \"h0\", cid=4)\n\n    nexPage.show()\n\n    time.sleep(0.1)\n\n    nexSlider.value = 43691  # 0-65535\n\n    time.sleep(1)\n\n    # nexSlider.cursor.color = NamedColor.GRAY\n    nexSlider.forecolor = NamedColor.GRAY\n\n    time.sleep(1)\n\n    w = 10\n    nexSlider.cursor.width = w\n    assert nexSlider.cursor.width == w\n\n    time.sleep(1)\n\n    h = 13\n    nexSlider.cursor.height = h\n    assert nexSlider.cursor.height == h\n\n    time.sleep(1)\n\n    nexSerial.close()", "fn_id": 0, "class_fn": false, "repo": "cowo78/pynextion", "file": "examples/slider.py", "last_update_at": "2019-02-24T14:40:42+00:00", "question_id": "6449df6c32e60e7984c5e8dea2c96d853c68056e_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.mark.parametrize('port', [PORT_DEFAULT])\ndef test_slider(port):\n    nexSerial = PySerialNex(port)\n    nexSerial.init()\n    nexPage = NexPage(nexSerial, 'pg_slider', pid=11)\n    nexSlider = NexSlider(nexSerial, 'h0', cid=4)\n    nexPage.show()\n    time.sleep(0.1)\n    nexSlider.value = 43691\n    time.sleep(1)\n    nexSlider.forecolor = NamedColor.GRAY\n    time.sleep(1)\n    w = 10\n    nexSlider.cursor.width = w\n    assert nexSlider.cursor.width == w\n    time.sleep(1)\n    h = 13\n    nexSlider.cursor.height = h\n    assert nexSlider.cursor.height == h\n    time.sleep(1)\n"]]}
{"hexsha": "44fd57093cd4ae65f6ed17ef9aa879c90208cf5e", "ext": "py", "lang": "Python", "content": "def toFollower(term):\n    global currentTerm, state, timer, votedFor\n    state = FOLLOWER\n    currentTerm = term\n    votedFor = -1\n    timer = time()", "fn_id": 5, "class_fn": false, "repo": "yutao-li/RAFT-implementation", "file": "server.py", "last_update_at": "2019-12-09T00:02:18+00:00", "question_id": "44fd57093cd4ae65f6ed17ef9aa879c90208cf5e_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def toFollower(term):\n    global currentTerm, state, timer, votedFor\n    state = FOLLOWER\n    currentTerm = term\n    votedFor = -1\n"]]}
{"hexsha": "0aa8a507d6e7432199c19d487284ee7d3c686f01", "ext": "py", "lang": "Python", "content": "def ensure_file_exists(filename, context=None):\n    real_filename = filename\n    if context:\n        real_filename = realpath_with_context(filename, context)\n    if not os.path.exists(real_filename):\n        create_textfile_with_contents(real_filename, \"\")\n    assert os.path.exists(real_filename), \"ENSURE file exists: %s\" % filename", "fn_id": 5, "class_fn": false, "repo": "wombat70/behave", "file": "behave4cmd0/pathutil.py", "last_update_at": "2019-10-16T02:01:57+00:00", "question_id": "0aa8a507d6e7432199c19d487284ee7d3c686f01_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def ensure_file_exists(filename, context=None):\n    real_filename = filename\n    if context:\n        real_filename = realpath_with_context(filename, context)\n    if not os.path.exists(real_filename):\n        create_textfile_with_contents(real_filename, '')\n"]]}
{"hexsha": "df21750d2032e4a1fe0859fbab7247878e3650dc", "ext": "py", "lang": "Python", "content": "def test_env(monkeypatch):\n    monkeypatch.setenv('CLEANROOM_ENV_VAR', '42')\n\n    proxy = factory.create_instance(DummyClass)\n    assert proxy.env() == '42'", "fn_id": 7, "class_fn": false, "repo": "huntzhan/cleanroom", "file": "tests/test_factory.py", "last_update_at": "2019-10-04T13:01:36+00:00", "question_id": "df21750d2032e4a1fe0859fbab7247878e3650dc_7", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_env(monkeypatch):\n    monkeypatch.setenv('CLEANROOM_ENV_VAR', '42')\n    proxy = factory.create_instance(DummyClass)\n"]]}
{"hexsha": "a04d8575f20c529b36ee6618718d2c0cf7dea892", "ext": "py", "lang": "Python", "content": "def upload_file(api_client, id, file_path):\n    api = rest.DataApi(api_client)\n    upload_info = object_storage.upload_file(api_client, file_path, 'Data')\n    model = rest.ComponentsAddFileInputModel(file_name=upload_info.file_name, stored_path=upload_info.stored_path)\n    result = api.add_data_file(id, model=model)\n    return result", "fn_id": 4, "class_fn": false, "repo": "sinpcw/kamonohashi", "file": "sdk/kamonohashi/op/data.py", "last_update_at": "2019-08-02T01:51:04+00:00", "question_id": "a04d8575f20c529b36ee6618718d2c0cf7dea892_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def upload_file(api_client, id, file_path):\n    api = rest.DataApi(api_client)\n    upload_info = object_storage.upload_file(api_client, file_path, 'Data')\n    model = rest.ComponentsAddFileInputModel(file_name=upload_info.file_name, stored_path=upload_info.stored_path)\n    result = api.add_data_file(id, model=model)\n"]]}
{"hexsha": "5314e2610299d51feaf0fb680356a310055b3292", "ext": "py", "lang": "Python", "content": "def find_program_win(name, program_to_find='SOFTWARE\\\\7-Zip'):\n    log = Log(name=name)\n    try:\n        h_key = winreg.CreateKey(winreg.HKEY_LOCAL_MACHINE, program_to_find)\n        try:\n            prog_path = (winreg.QueryValueEx(h_key, 'Path'))[0]\n            return prog_path + '7z'\n        except OSError:\n            log(\"7-Zip isn't correctly installed!! \")\n            return None\n    except PermissionError:\n        log(\"7-Zip not found!! \")\n        answer = query_yes_no(\"Do you wish to install 7zip? \", default='yes')\n        if answer:\n\n            url = \"https://www.7-zip.org/a/7z1900-x64.msi\"\n            log(\"Attempting to download {}\".format(url))\n            local_filename = url.split('/')[-1]\n\n            with requests.get(url, stream=True) as r:\n                r.raise_for_status()\n                homepath = os.environ.get('HOMEPATH', \".\")\n                parentpath = \"C:\" + homepath + \"\\\\Downloads\\\\\"\n                filepath = parentpath + local_filename\n                with open(filepath, 'wb') as f:\n                    for chunk in r.iter_content(chunk_size=8192):\n                        if chunk:  # filter out keep-alive new chunks\n                            f.write(chunk)\n\n            log(\"Attempting to install {}\".format(local_filename))\n            print(\"Please check for a Windows Installer icon on the Task Bar and follow the prompts.\")\n            subprocess.call('msiexec /i \"{fp}\" /passive /norestart /l*v {pp}7zip_install.log'.format(fp=filepath,\n                                                                                                     pp=parentpath))\n            return find_program_win()\n        else:\n            return None", "fn_id": 0, "class_fn": false, "repo": "clrogers2/stackexchangeparser", "file": "separser/utils/utils.py", "last_update_at": "2019-08-25T17:03:51+00:00", "question_id": "5314e2610299d51feaf0fb680356a310055b3292_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def find_program_win(name, program_to_find='SOFTWARE\\\\7-Zip'):\n    log = Log(name=name)\n    try:\n        h_key = winreg.CreateKey(winreg.HKEY_LOCAL_MACHINE, program_to_find)\n        try:\n            prog_path = winreg.QueryValueEx(h_key, 'Path')[0]\n            return prog_path + '7z'\n        except OSError:\n            log(\"7-Zip isn't correctly installed!! \")\n            return None\n    except PermissionError:\n        log('7-Zip not found!! ')\n        answer = query_yes_no('Do you wish to install 7zip? ', default='yes')\n        if answer:\n            url = 'https://www.7-zip.org/a/7z1900-x64.msi'\n            log('Attempting to download {}'.format(url))\n            local_filename = url.split('/')[-1]\n            with requests.get(url, stream=True) as r:\n                r.raise_for_status()\n                homepath = os.environ.get('HOMEPATH', '.')\n                parentpath = 'C:' + homepath + '\\\\Downloads\\\\'\n                filepath = parentpath + local_filename\n                with open(filepath, 'wb') as f:\n                    for chunk in r.iter_content(chunk_size=8192):\n                        if chunk:\n                            f.write(chunk)\n            log('Attempting to install {}'.format(local_filename))\n            print('Please check for a Windows Installer icon on the Task Bar and follow the prompts.')\n            subprocess.call('msiexec /i \"{fp}\" /passive /norestart /l*v {pp}7zip_install.log'.format(fp=filepath, pp=parentpath))\n            return find_program_win()\n        else:\n"]]}
{"hexsha": "224e19be46ddf50db6ace667fb06ae8d5525adaa", "ext": "py", "lang": "Python", "content": "def confint(seq):\n    \"\"\"\n    Computes 95% confidence intervals.\n    :param seq: list or a numpy array with sample measurements\n    \"\"\"\n    return np.mean(seq) - (1.96 * np.std(seq)), np.mean(seq) + (1.96 * np.std(seq))", "fn_id": 4, "class_fn": false, "repo": "clips/seg-cnn", "file": "src/stats_util.py", "last_update_at": "2019-02-04T15:42:14+00:00", "question_id": "224e19be46ddf50db6ace667fb06ae8d5525adaa_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def confint(seq):\n    \"\"\"\n    Computes 95% confidence intervals.\n    :param seq: list or a numpy array with sample measurements\n    \"\"\"\n"]]}
{"hexsha": "28cf06ec1082d143c6f1b0c746ae4649398a80ae", "ext": "py", "lang": "Python", "content": "def _fileserver_mesh_import(url, filename):\n    \"\"\"Internal function that adds primitive support for DAE files\n    to the _mesh_import function of compas.robots.\"\"\"\n    file_extension = _get_file_format(url)\n\n    if file_extension == 'dae':\n        # Magic!\n        return _dae_mesh_importer(filename)\n    else:\n        return _mesh_import(url, filename)", "fn_id": 3, "class_fn": false, "repo": "Kathrin3010/compas_fab", "file": "src/compas_fab/backends/ros/fileserver_loader.py", "last_update_at": "2019-08-15T17:34:43+00:00", "question_id": "28cf06ec1082d143c6f1b0c746ae4649398a80ae_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _fileserver_mesh_import(url, filename):\n    \"\"\"Internal function that adds primitive support for DAE files\n    to the _mesh_import function of compas.robots.\"\"\"\n    file_extension = _get_file_format(url)\n    if file_extension == 'dae':\n        return _dae_mesh_importer(filename)\n    else:\n"]]}
{"hexsha": "61673a3563c904c8f16b45554119722ec7269453", "ext": "py", "lang": "Python", "content": "def rule2struct(rule):\n    \"\"\"\n    Returns the structure of a rule used to partition a knowledge base\n    :param rule: a rule\n    :return: a tuple representing the structure of the rule\n    \"\"\"\n    predicates = {}\n    constants = {}\n    variables = {}\n    struct = []\n    for predicate, args in rule:\n        atom_struct = []\n        if predicate not in predicates:\n            predicates[predicate] = \"p\" + str(len(predicates))\n        atom_struct.append(predicates[predicate])\n        for arg in args:\n            if is_variable(arg):\n                if arg not in variables:\n                    variables[arg] = \"X\" + str(len(variables))\n                atom_struct.append(variables[arg])\n            else:\n                if arg not in constants:\n                    constants[arg] = \"c\" # + str(len(constants))\n                atom_struct.append(constants[arg])\n        struct.append(tuple(atom_struct))\n    return tuple(struct)", "fn_id": 0, "class_fn": false, "repo": "uclmr/ntp", "file": "ntp/nkb.py", "last_update_at": "2019-09-23T20:54:37+00:00", "question_id": "61673a3563c904c8f16b45554119722ec7269453_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def rule2struct(rule):\n    \"\"\"\n    Returns the structure of a rule used to partition a knowledge base\n    :param rule: a rule\n    :return: a tuple representing the structure of the rule\n    \"\"\"\n    predicates = {}\n    constants = {}\n    variables = {}\n    struct = []\n    for predicate, args in rule:\n        atom_struct = []\n        if predicate not in predicates:\n            predicates[predicate] = 'p' + str(len(predicates))\n        atom_struct.append(predicates[predicate])\n        for arg in args:\n            if is_variable(arg):\n                if arg not in variables:\n                    variables[arg] = 'X' + str(len(variables))\n                atom_struct.append(variables[arg])\n            else:\n                if arg not in constants:\n                    constants[arg] = 'c'\n                atom_struct.append(constants[arg])\n        struct.append(tuple(atom_struct))\n"]]}
{"hexsha": "8fe41949e056d46badadc0165fafcde1384f74d2", "ext": "py", "lang": "Python", "content": "def print_bytes(seq):\n    out = []\n    for i in seq:\n        out.append(\"{:02X}\".format(i))\n    return out", "fn_id": 2, "class_fn": false, "repo": "alantelles/galaxydb", "file": "galaxydb/statics.py", "last_update_at": "2019-03-15T20:47:14+00:00", "question_id": "8fe41949e056d46badadc0165fafcde1384f74d2_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def print_bytes(seq):\n    out = []\n    for i in seq:\n        out.append('{:02X}'.format(i))\n"]]}
{"hexsha": "6f04f44a681cacfdcd3106446d2eb254f7035e11", "ext": "py", "lang": "Python", "content": "def getDevice(token,serverip,devid):\n\n  authheader = {'Authorization': token}\n\n  url = 'http://'+serverip+'/things/'+devid\n\n  try:\n     response = requests.get(url, headers=authheader )\n  except ConnectionError as ce:\n     return None\n\n  if response.status_code != 200:\n     return None\n  else:\n     data = response.json()\n     return data", "fn_id": 3, "class_fn": false, "repo": "juanmagal/iot-slice-orchestrator", "file": "iotorch/utils/serverutils.py", "last_update_at": "2019-12-24T16:57:29+00:00", "question_id": "6f04f44a681cacfdcd3106446d2eb254f7035e11_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def getDevice(token, serverip, devid):\n    authheader = {'Authorization': token}\n    url = 'http://' + serverip + '/things/' + devid\n    try:\n        response = requests.get(url, headers=authheader)\n    except ConnectionError as ce:\n        return None\n    if response.status_code != 200:\n        return None\n    else:\n        data = response.json()\n"]]}
{"hexsha": "581dc1b573fdb022e2a285aaa5826218f438ca2f", "ext": "py", "lang": "Python", "content": "def create_babel_i18n(_app):\n    \"\"\" i18n configuration\n    :param _app: Flask app\n    :return: Babel configuration\n    \"\"\"\n    return Babel(_app)", "fn_id": 3, "class_fn": false, "repo": "eubr-bigsea/stand", "file": "stand/factory.py", "last_update_at": "2019-07-12T15:14:26+00:00", "question_id": "581dc1b573fdb022e2a285aaa5826218f438ca2f_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def create_babel_i18n(_app):\n    \"\"\" i18n configuration\n    :param _app: Flask app\n    :return: Babel configuration\n    \"\"\"\n"]]}
{"hexsha": "79881a9843be0db7191e35e2fc0199373f3983d0", "ext": "py", "lang": "Python", "content": "def loop_through_books(book_orderedpages_dict, collection_sourcepath, collection_outputpath, books_needing_converting):\n    for book_name, ordered_pages_pointers in sorted(book_orderedpages_dict.items()):\n        if book_name not in books_needing_converting:\n            continue\n        convert_a_book(\n            book_name,\n            ordered_pages_pointers,\n            collection_sourcepath,\n            collection_outputpath\n        )", "fn_id": 5, "class_fn": false, "repo": "lsulibraries/convert_to_islandorabooknews", "file": "Book_Newspaper_Batch/convert_jp2cpd_to_book_with_derivs.py", "last_update_at": "2019-10-23T18:57:37+00:00", "question_id": "79881a9843be0db7191e35e2fc0199373f3983d0_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def loop_through_books(book_orderedpages_dict, collection_sourcepath, collection_outputpath, books_needing_converting):\n    for book_name, ordered_pages_pointers in sorted(book_orderedpages_dict.items()):\n        if book_name not in books_needing_converting:\n            continue\n"]]}
{"hexsha": "3135c1e1a3915c263f59be5108d17d06e3a4d782", "ext": "py", "lang": "Python", "content": "def main():\n    from pprint import pformat\n    from textwrap import indent\n    for name in globals():\n        if name.startswith('somefunc_'):\n            print(\"\\n{}():\".format(name))\n            print(indent(pformat(globals()[name]()), ' '*4))", "fn_id": 15, "class_fn": false, "repo": "fabianoengler/dictvars", "file": "docs/more_examples.py", "last_update_at": "2019-11-21T11:52:15+00:00", "question_id": "3135c1e1a3915c263f59be5108d17d06e3a4d782_15", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main():\n    from pprint import pformat\n    from textwrap import indent\n    for name in globals():\n        if name.startswith('somefunc_'):\n            print('\\n{}():'.format(name))\n"]]}
{"hexsha": "123219954cd02311e9672fcd03228d2819d24348", "ext": "py", "lang": "Python", "content": "def process_doc_file(code_file, add_new_line=True):\n    \"\"\"\n    Process given file.\n\n    Args:\n        code_file (`str` or `os.PathLike`): The file in which we want to style the docstring.\n    \"\"\"\n    with open(code_file, \"r\", encoding=\"utf-8\", newline=\"\\n\") as f:\n        code = f.read()\n\n    # fmt: off\n    splits = code.split(\"```\")\n    splits = [s if i % 2 == 0 else process_code_block(s, add_new_line=add_new_line) for i, s in enumerate(splits)]\n    clean_code = \"```\".join(splits)\n    # fmt: on\n\n    diff = clean_code != code\n    if diff:\n        print(f\"Overwriting content of {code_file}.\")\n        with open(code_file, \"w\", encoding=\"utf-8\", newline=\"\\n\") as f:\n            f.write(clean_code)", "fn_id": 3, "class_fn": false, "repo": "dctelus/transformers", "file": "utils/prepare_for_doc_test.py", "last_update_at": "2019-07-16T09:14:59+00:00", "question_id": "123219954cd02311e9672fcd03228d2819d24348_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def process_doc_file(code_file, add_new_line=True):\n    \"\"\"\n    Process given file.\n\n    Args:\n        code_file (`str` or `os.PathLike`): The file in which we want to style the docstring.\n    \"\"\"\n    with open(code_file, 'r', encoding='utf-8', newline='\\n') as f:\n        code = f.read()\n    splits = code.split('```')\n    splits = [s if i % 2 == 0 else process_code_block(s, add_new_line=add_new_line) for i, s in enumerate(splits)]\n    clean_code = '```'.join(splits)\n    diff = clean_code != code\n    if diff:\n        print(f'Overwriting content of {code_file}.')\n        with open(code_file, 'w', encoding='utf-8', newline='\\n') as f:\n"]]}
{"hexsha": "82fab4db8212cd5e2b9dea5cb431264ab8ebba9e", "ext": "py", "lang": "Python", "content": "def test_mnist():\n    import tensorflow as tf\n    import tensorflow.examples.tutorials.mnist.input_data as input_data\n    import matplotlib.pyplot as plt\n\n    # %%\n    # load MNIST as before\n    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n    mean_img = np.mean(mnist.train.images, axis=0)\n    ae = autoencoder(dimensions=[784, 256, 64])\n\n    # %%\n    learning_rate = 0.001\n    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(ae['cost'])\n\n    # %%\n    # We create a session to use the graph\n    sess = tf.Session()\n    sess.run(tf.initialize_all_variables())\n\n    # %%\n    # Fit all training data\n    batch_size = 50\n    n_epochs = 10\n    for epoch_i in range(n_epochs):\n        for batch_i in range(mnist.train.num_examples // batch_size):\n            batch_xs, _ = mnist.train.next_batch(batch_size)\n            train = np.array([img - mean_img for img in batch_xs])\n            sess.run(optimizer, feed_dict={\n                ae['x']: train, ae['corrupt_prob']: [1.0]})\n        print(epoch_i, sess.run(ae['cost'], feed_dict={\n            ae['x']: train, ae['corrupt_prob']: [1.0]}))\n\n    # %%\n    # Plot example reconstructions\n    n_examples = 15\n    test_xs, _ = mnist.test.next_batch(n_examples)\n    test_xs_norm = np.array([img - mean_img for img in test_xs])\n    recon = sess.run(ae['y'], feed_dict={\n        ae['x']: test_xs_norm, ae['corrupt_prob']: [0.0]})\n    fig, axs = plt.subplots(2, n_examples, figsize=(10, 2))\n    for example_i in range(n_examples):\n        axs[0][example_i].imshow(\n            np.reshape(test_xs[example_i, :], (28, 28)))\n        axs[1][example_i].imshow(\n            np.reshape([recon[example_i, :] + mean_img], (28, 28)))\n    fig.show()\n    plt.draw()\n    plt.waitforbuttonpress()", "fn_id": 1, "class_fn": false, "repo": "nraythz/Mini-tutorial-TensorFlow", "file": "Denoising_autoencoder.py", "last_update_at": "2019-02-28T12:54:14+00:00", "question_id": "82fab4db8212cd5e2b9dea5cb431264ab8ebba9e_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_mnist():\n    import tensorflow as tf\n    import tensorflow.examples.tutorials.mnist.input_data as input_data\n    import matplotlib.pyplot as plt\n    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n    mean_img = np.mean(mnist.train.images, axis=0)\n    ae = autoencoder(dimensions=[784, 256, 64])\n    learning_rate = 0.001\n    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(ae['cost'])\n    sess = tf.Session()\n    sess.run(tf.initialize_all_variables())\n    batch_size = 50\n    n_epochs = 10\n    for epoch_i in range(n_epochs):\n        for batch_i in range(mnist.train.num_examples // batch_size):\n            batch_xs, _ = mnist.train.next_batch(batch_size)\n            train = np.array([img - mean_img for img in batch_xs])\n            sess.run(optimizer, feed_dict={ae['x']: train, ae['corrupt_prob']: [1.0]})\n        print(epoch_i, sess.run(ae['cost'], feed_dict={ae['x']: train, ae['corrupt_prob']: [1.0]}))\n    n_examples = 15\n    test_xs, _ = mnist.test.next_batch(n_examples)\n    test_xs_norm = np.array([img - mean_img for img in test_xs])\n    recon = sess.run(ae['y'], feed_dict={ae['x']: test_xs_norm, ae['corrupt_prob']: [0.0]})\n    fig, axs = plt.subplots(2, n_examples, figsize=(10, 2))\n    for example_i in range(n_examples):\n        axs[0][example_i].imshow(np.reshape(test_xs[example_i, :], (28, 28)))\n        axs[1][example_i].imshow(np.reshape([recon[example_i, :] + mean_img], (28, 28)))\n    fig.show()\n    plt.draw()\n"]]}
{"hexsha": "af1a2e6b9b1bf3aca976508a10b163371a64c6aa", "ext": "py", "lang": "Python", "content": "def residential(params):\n\n\tprint(params)\n\n\t# geo_name,geo_id,pop,adult_obesity,income_below_poverty,high_school_graduation,unemployment,violent_crime,age,median_property_value,owner_occupied_housing_units,population_living_in_a_rural_area,grads_total\n\n\tdata_cols = [\"geo_name\",\"geo_id\",\"pop\",\"obesity\",\"poverty\",\n\t\"high_school_graduation\",\"unemployment\",\"violent_crime\",\n\t\"age\",\"median_property_value\",\n\t\"own_housing_percentage\",\n\t\"rural\",\"grads_total\"]\n\n\tpath = str(os.path.dirname(os.path.realpath(__file__)))\n\n\tdata = pd.read_csv(path+\"/../data/data1.csv\", sep=\",\", names=data_cols, encoding=\"latin-1\")\n\n\t# weight data and return\n\n\timp = 1\n\t# weighter. this decreases importance by .1 for each param\n\tfor i in params.order():\n\n\t\t# make sure best option is highest\n\n\t\tif params[i] == \"education\":\n\n\t\t\tnormalise(data, \"grads_total\", \"grads_total\", 1)\n\t\t\tnormalise(data, \"high_school_graduation\", \"high_school_graduation\", 1)\n\t\t\t\n\t\t\tdata[\"education\"] = data[\"high_school_graduation\"] + data[\"grads_total\"]\n\t\t\t\n\t\t\tnormalise(data, \"education\", \"education\", 1)\n\n\t\t\torder = data[[\"education\"]]\n\t\t\to_scaled = min_max_scaler.fit_transform(order)\n\t\t\torder = pd.DataFrame(o_scaled)\n\t\t\tdata[[\"education\"]] = order*imp\n \n\t\telif params[i] == \"jobs\":\n\n\t\t\t# as we want lowest unemployment\n\t\t\tnormalise(data, \"employment\", \"unemployment\", -1)\n\n\t\t\torder = data[[\"employment\"]]\n\t\t\to_scaled = min_max_scaler.fit_transform(order)\n\t\t\torder = pd.DataFrame(o_scaled)\n\t\t\tdata[[\"employment\"]] = order*imp\n\n\t\telif params[i] == \"health\":\n\n\t\t\t# as violent crimes is per 100,000\n\t\t\tdata[\"health\"] = data[\"obesity\"] + (data[\"violent_crime\"] / 100000)\n\n\t\t\tnormalise(data, \"health\", \"health\", -1)\n\n\t\t\torder = data[[\"health\"]]\n\t\t\to_scaled = min_max_scaler.fit_transform(order)\n\t\t\torder = pd.DataFrame(o_scaled)\n\t\t\tdata[[\"health\"]] = order*imp\n\n\t\telif params[i] == \"home\":\n\n\t\t\tnormalise(data, \"home\", \"own_housing_percentage\", 1)\n\n\t\t\torder = data[[\"home\"]]\n\t\t\to_scaled = min_max_scaler.fit_transform(order)\n\t\t\torder = pd.DataFrame(o_scaled)\n\t\t\tdata[[\"home\"]] = order*imp\n\n\t\telif params[i] == \"wealth\":\n\n\t\t\tnormalise(data, \"wealth\", \"median_property_value\", 1)\n\n\t\t\torder = data[[\"wealth\"]]\n\t\t\to_scaled = min_max_scaler.fit_transform(order)\n\t\t\torder = pd.DataFrame(o_scaled)\n\t\t\tdata[[\"wealth\"]] = order*imp\n\n\n\t\timp -= .2\n\n\tdata[\"population\"] = data[\"pop\"]\n\n\tfor k in params.prefs.keys():\n\n\t\t# the best is closest to 0 for these\n\n\t\tif k == \"pop\":\n\n\t\t\tdata[\"pop\"] = abs(params.prefs[k] - data[\"pop\"])\n\t\t\t\n\t\telif k == \"price\":\n\n\t\t\tdata[\"price\"] = abs(params.prefs[k] - data[\"median_property_value\"])\n\n\t\telif k == \"urban\":\n\n\t\t\t# urban should be a percentage\n\n\t\t\tdata[\"urban\"] = abs(params.prefs[k] - (1 - data[\"rural\"]))\n\n\n\t# now normalise the data once again using sklearn\n\n\n\tprefs = data[[\"pop\", \"price\", \"urban\"]]\n\tp_scaled = min_max_scaler.fit_transform(prefs)\n\tprefs = pd.DataFrame(p_scaled)\n\tdata[[\"pop\", \"price\", \"urban\"]] = prefs\n\n\n\treturn {\n\t\t\"order\": data[[\"geo_name\", \"geo_id\", \"education\", \"employment\", \"health\", \"home\", \"wealth\"]],\n\t\t\"prefs\": data[[\"geo_name\", \"geo_id\", \"pop\", \"price\", \"urban\",    \"population\", \"median_property_value\"]]\n\t}", "fn_id": 0, "class_fn": false, "repo": "py-the-way/py-the-way", "file": "src/recommender/weighter.py", "last_update_at": "2019-01-12T20:46:36+00:00", "question_id": "af1a2e6b9b1bf3aca976508a10b163371a64c6aa_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def residential(params):\n    print(params)\n    data_cols = ['geo_name', 'geo_id', 'pop', 'obesity', 'poverty', 'high_school_graduation', 'unemployment', 'violent_crime', 'age', 'median_property_value', 'own_housing_percentage', 'rural', 'grads_total']\n    path = str(os.path.dirname(os.path.realpath(__file__)))\n    data = pd.read_csv(path + '/../data/data1.csv', sep=',', names=data_cols, encoding='latin-1')\n    imp = 1\n    for i in params.order():\n        if params[i] == 'education':\n            normalise(data, 'grads_total', 'grads_total', 1)\n            normalise(data, 'high_school_graduation', 'high_school_graduation', 1)\n            data['education'] = data['high_school_graduation'] + data['grads_total']\n            normalise(data, 'education', 'education', 1)\n            order = data[['education']]\n            o_scaled = min_max_scaler.fit_transform(order)\n            order = pd.DataFrame(o_scaled)\n            data[['education']] = order * imp\n        elif params[i] == 'jobs':\n            normalise(data, 'employment', 'unemployment', -1)\n            order = data[['employment']]\n            o_scaled = min_max_scaler.fit_transform(order)\n            order = pd.DataFrame(o_scaled)\n            data[['employment']] = order * imp\n        elif params[i] == 'health':\n            data['health'] = data['obesity'] + data['violent_crime'] / 100000\n            normalise(data, 'health', 'health', -1)\n            order = data[['health']]\n            o_scaled = min_max_scaler.fit_transform(order)\n            order = pd.DataFrame(o_scaled)\n            data[['health']] = order * imp\n        elif params[i] == 'home':\n            normalise(data, 'home', 'own_housing_percentage', 1)\n            order = data[['home']]\n            o_scaled = min_max_scaler.fit_transform(order)\n            order = pd.DataFrame(o_scaled)\n            data[['home']] = order * imp\n        elif params[i] == 'wealth':\n            normalise(data, 'wealth', 'median_property_value', 1)\n            order = data[['wealth']]\n            o_scaled = min_max_scaler.fit_transform(order)\n            order = pd.DataFrame(o_scaled)\n            data[['wealth']] = order * imp\n        imp -= 0.2\n    data['population'] = data['pop']\n    for k in params.prefs.keys():\n        if k == 'pop':\n            data['pop'] = abs(params.prefs[k] - data['pop'])\n        elif k == 'price':\n            data['price'] = abs(params.prefs[k] - data['median_property_value'])\n        elif k == 'urban':\n            data['urban'] = abs(params.prefs[k] - (1 - data['rural']))\n    prefs = data[['pop', 'price', 'urban']]\n    p_scaled = min_max_scaler.fit_transform(prefs)\n    prefs = pd.DataFrame(p_scaled)\n    data[['pop', 'price', 'urban']] = prefs\n"]]}
{"hexsha": "62f9e4f70aaca02aa6392b481ad4bc121505d4b9", "ext": "py", "lang": "Python", "content": "@patch('helga_poems.util.get_api')\ndef test_tweet_handles_unicode(api):\n    settings.TWITTER_CONSUMER_KEY = 'foo'\n    settings.TWITTER_CONSUMER_SECRET = 'foo'\n    settings.TWITTER_OAUTH_TOKEN = 'foo'\n    settings.TWITTER_OAUTH_TOKEN_SECRET = 'foo'\n    settings.TWITTER_USERNAME = 'helgabot'\n\n    api.return_value = api\n    api.update_status.return_value = Mock(id=123456789)\n\n    assert twitter.tweet(u'\u2603') == 'http://twitter.com/helgabot/status/123456789'", "fn_id": 4, "class_fn": false, "repo": "shaunduncan/helga-poems", "file": "helga_poems/tests/test_util.py", "last_update_at": "2019-04-21T17:24:13+00:00", "question_id": "62f9e4f70aaca02aa6392b481ad4bc121505d4b9_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@patch('helga_poems.util.get_api')\ndef test_tweet_handles_unicode(api):\n    settings.TWITTER_CONSUMER_KEY = 'foo'\n    settings.TWITTER_CONSUMER_SECRET = 'foo'\n    settings.TWITTER_OAUTH_TOKEN = 'foo'\n    settings.TWITTER_OAUTH_TOKEN_SECRET = 'foo'\n    settings.TWITTER_USERNAME = 'helgabot'\n    api.return_value = api\n    api.update_status.return_value = Mock(id=123456789)\n"]]}
{"hexsha": "5b20f43d1e8858c0cecff4f03261d9d1d9c3d1bf", "ext": "py", "lang": "Python", "content": "def concat_dicts(d1, d2):\n    d = d1.copy()\n    d.update(d2)\n    return d", "fn_id": 14, "class_fn": false, "repo": "lhillber/qops", "file": "matrix.py", "last_update_at": "2019-10-06T14:44:47+00:00", "question_id": "5b20f43d1e8858c0cecff4f03261d9d1d9c3d1bf_14", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def concat_dicts(d1, d2):\n    d = d1.copy()\n    d.update(d2)\n"]]}
{"hexsha": "b3eda0810900ed468f05f7bf351efa2c5217f283", "ext": "py", "lang": "Python", "content": "def binary_error(preds, train_data):\n    labels = train_data.get_label()\n    e=np.mean(np.square(np.log10(preds+1)-np.log10(labels+1)))\n    return 'myloss',e,False", "fn_id": 12, "class_fn": false, "repo": "zangzelin/Text-Information-Classification-Model-for-Medical-Big-Data-Processing", "file": "putonghuiguijiazi.py", "last_update_at": "2019-05-29T14:03:03+00:00", "question_id": "b3eda0810900ed468f05f7bf351efa2c5217f283_12", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def binary_error(preds, train_data):\n    labels = train_data.get_label()\n    e = np.mean(np.square(np.log10(preds + 1) - np.log10(labels + 1)))\n"]]}
{"hexsha": "8a092e39c20dbb0581f46701185c3e55faf9e460", "ext": "py", "lang": "Python", "content": "@wvtest\ndef booga2():\n    # ensure tests run in the order they were declared\n    global last\n    WVPASSEQ(last, 'test1')\n    last='booga2'", "fn_id": 1, "class_fn": false, "repo": "wlach/libroutez", "file": "wvtest/python/t/twvtest.py", "last_update_at": "2019-06-23T14:20:39+00:00", "question_id": "8a092e39c20dbb0581f46701185c3e55faf9e460_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@wvtest\ndef booga2():\n    global last\n    WVPASSEQ(last, 'test1')\n"]]}
{"hexsha": "dabd40c6bbf7161f44be3e67813ac8040a7cc8bd", "ext": "py", "lang": "Python", "content": "def test_content_type():\n    r = Response()\n    # default ctype and charset\n    eq_(r.content_type, 'text/html')\n    eq_(r.charset, 'UTF-8')\n    # setting to none, removes the header\n    r.content_type = None\n    eq_(r.content_type, None)\n    eq_(r.charset, None)\n    # can set missing ctype\n    r.content_type = None\n    eq_(r.content_type, None)", "fn_id": 6, "class_fn": false, "repo": "AniX/webapp-improved", "file": "lib/WebOb-1.2.2/tests/test_response.py", "last_update_at": "2019-04-15T13:50:16+00:00", "question_id": "dabd40c6bbf7161f44be3e67813ac8040a7cc8bd_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_content_type():\n    r = Response()\n    eq_(r.content_type, 'text/html')\n    eq_(r.charset, 'UTF-8')\n    r.content_type = None\n    eq_(r.content_type, None)\n    eq_(r.charset, None)\n    r.content_type = None\n"]]}
{"hexsha": "8815d4975da480fc89fc030b18d7376c5bed88c1", "ext": "py", "lang": "Python", "content": "def _next_and_end(cls: \"StateMirror\") -> \"StateMirror\":\n    \"\"\"Add \"Next\" and \"End\" parameters to the class.\n    Also adds the \"then()\" and \"end()\" helper methods.\n    \"\"\"\n\n    def _validate_next(instance, attribute: attr.Attribute, value: Any):\n        if value is not None and instance.End is not None:\n            raise ValueError(\"Only one of 'Next' and 'End' is allowed\")\n\n    cls.Next = RHODES_ATTRIB(validator=(optional(instance_of(str)), _validate_next))\n    cls.__doc__ = docstring_with_param(cls, \"Next\", description=\"The state that will follow this state\")\n\n    def _validate_end(instance, attribute: attr.Attribute, value: Any):\n        if value is not None and instance.Next is not None:\n            raise ValueError(\"Only one of 'Next' and 'End' is allowed\")\n\n        if value is not None and value is not True:\n            raise ValueError(\"If 'End' is set, value must be True\")\n\n    cls.End = RHODES_ATTRIB(validator=(optional(instance_of(bool)), _validate_end))\n    cls.__doc__ = docstring_with_param(cls, \"End\", bool, description=\"This state is a terminal state\")\n\n    def _then(instance, next_state):\n        \"\"\"Set the next state in this state machine.\"\"\"\n\n        if instance.End is not None:\n            raise InvalidDefinitionError(\n                f\"Cannot set state transition. State {instance.title!r} already has an end condition.\"\n            )\n\n        if instance.Next is not None:\n            raise InvalidDefinitionError(\n                f\"Cannot set state transition. State {instance.title!r} already has a state transition.\"\n            )\n\n        instance.member_of.add_state(next_state)\n        # TODO: set reference rather than extracting name\n        instance.Next = next_state.title\n        return next_state\n\n    cls.then = _then\n\n    def _end(instance):\n        \"\"\"Make this state a terminal state.\"\"\"\n\n        if instance.Next is not None:\n            raise InvalidDefinitionError(\n                \"Cannot set end condition.\" f\"State {instance.title!r} already has a state transition.\"\n            )\n\n        instance.End = True\n\n        return instance\n\n    cls.end = _end\n\n    return cls", "fn_id": 0, "class_fn": false, "repo": "mattsb42/rhodes", "file": "src/rhodes/states/_parameters.py", "last_update_at": "2019-11-18T07:34:36+00:00", "question_id": "8815d4975da480fc89fc030b18d7376c5bed88c1_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _next_and_end(cls: 'StateMirror') -> 'StateMirror':\n    \"\"\"Add \"Next\" and \"End\" parameters to the class.\n    Also adds the \"then()\" and \"end()\" helper methods.\n    \"\"\"\n\n    def _validate_next(instance, attribute: attr.Attribute, value: Any):\n        if value is not None and instance.End is not None:\n            raise ValueError(\"Only one of 'Next' and 'End' is allowed\")\n    cls.Next = RHODES_ATTRIB(validator=(optional(instance_of(str)), _validate_next))\n    cls.__doc__ = docstring_with_param(cls, 'Next', description='The state that will follow this state')\n\n    def _validate_end(instance, attribute: attr.Attribute, value: Any):\n        if value is not None and instance.Next is not None:\n            raise ValueError(\"Only one of 'Next' and 'End' is allowed\")\n        if value is not None and value is not True:\n            raise ValueError(\"If 'End' is set, value must be True\")\n    cls.End = RHODES_ATTRIB(validator=(optional(instance_of(bool)), _validate_end))\n    cls.__doc__ = docstring_with_param(cls, 'End', bool, description='This state is a terminal state')\n\n    def _then(instance, next_state):\n        \"\"\"Set the next state in this state machine.\"\"\"\n        if instance.End is not None:\n            raise InvalidDefinitionError(f'Cannot set state transition. State {instance.title!r} already has an end condition.')\n        if instance.Next is not None:\n            raise InvalidDefinitionError(f'Cannot set state transition. State {instance.title!r} already has a state transition.')\n        instance.member_of.add_state(next_state)\n        instance.Next = next_state.title\n        return next_state\n    cls.then = _then\n\n    def _end(instance):\n        \"\"\"Make this state a terminal state.\"\"\"\n        if instance.Next is not None:\n            raise InvalidDefinitionError(f'Cannot set end condition.State {instance.title!r} already has a state transition.')\n        instance.End = True\n        return instance\n    cls.end = _end\n"]]}
{"hexsha": "29fa653158c379c607c80942cfb1360111d01bae", "ext": "py", "lang": "Python", "content": "def inject_config(binder):\n    config_manager = SwitchBotHubConfigManager(os.path.dirname(os.path.abspath(__file__)))\n    binder.bind(AbstractConfigurationManager, config_manager)\n    binder.bind(AbstractMqttClient, CloudIoTCoreClient(config_manager))\n    binder.bind(AbstractBotController, MockBotController(config_manager))", "fn_id": 0, "class_fn": false, "repo": "masato-ka/switchbot-hub", "file": "switchbot_hub/main.py", "last_update_at": "2019-10-10T16:26:17+00:00", "question_id": "29fa653158c379c607c80942cfb1360111d01bae_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def inject_config(binder):\n    config_manager = SwitchBotHubConfigManager(os.path.dirname(os.path.abspath(__file__)))\n    binder.bind(AbstractConfigurationManager, config_manager)\n    binder.bind(AbstractMqttClient, CloudIoTCoreClient(config_manager))\n"]]}
{"hexsha": "4a4c360b0c3fea943bf380ae8e14b9e0fc574a7b", "ext": "py", "lang": "Python", "content": "@pytest.mark.usefixtures(\"job_constants\")\ndef test_check_generation_prereqs_ef_has_errors(database):\n    \"\"\" Tests a set of conditions that has an error in cross-file, fail the generation check for E/F files. \"\"\"\n    sess = database.session\n\n    sub = SubmissionFactory(submission_id=1, d2_submission=False)\n    cross_val = JobFactory(submission_id=sub.submission_id, job_type_id=JOB_TYPE_DICT['validation'], file_type_id=None,\n                           job_status_id=JOB_STATUS_DICT['finished'], number_of_errors=1, number_of_warnings=0,\n                           error_message=None)\n    sess.add_all([sub, cross_val])\n    sess.commit()\n\n    can_generate = check_generation_prereqs(sub.submission_id, 'E')\n    assert can_generate is False", "fn_id": 16, "class_fn": false, "repo": "dael-victoria-reyes/data-act-broker-backend", "file": "tests/unit/dataactbroker/test_generation_helper.py", "last_update_at": "2019-06-22T21:53:16+00:00", "question_id": "4a4c360b0c3fea943bf380ae8e14b9e0fc574a7b_16", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.mark.usefixtures('job_constants')\ndef test_check_generation_prereqs_ef_has_errors(database):\n    \"\"\" Tests a set of conditions that has an error in cross-file, fail the generation check for E/F files. \"\"\"\n    sess = database.session\n    sub = SubmissionFactory(submission_id=1, d2_submission=False)\n    cross_val = JobFactory(submission_id=sub.submission_id, job_type_id=JOB_TYPE_DICT['validation'], file_type_id=None, job_status_id=JOB_STATUS_DICT['finished'], number_of_errors=1, number_of_warnings=0, error_message=None)\n    sess.add_all([sub, cross_val])\n    sess.commit()\n    can_generate = check_generation_prereqs(sub.submission_id, 'E')\n"]]}
{"hexsha": "1163848a901f0841c800345b1f75dc8b119d3611", "ext": "py", "lang": "Python", "content": "def part_1(puzzle):\n    answer = -1\n    pattern = re.compile(\"^0{5}\")\n    while True:\n        answer += 1\n        hasher = md5()\n        attempt = puzzle + str(answer)\n        hasher.update(attempt.encode(\"utf-8\"))\n        digest = hasher.hexdigest()\n        if re.search(pattern, digest):\n            return answer", "fn_id": 1, "class_fn": false, "repo": "BrendanLeber/adventofcode", "file": "2015/day-04.py", "last_update_at": "2019-03-21T16:21:03+00:00", "question_id": "1163848a901f0841c800345b1f75dc8b119d3611_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def part_1(puzzle):\n    answer = -1\n    pattern = re.compile('^0{5}')\n    while True:\n        answer += 1\n        hasher = md5()\n        attempt = puzzle + str(answer)\n        hasher.update(attempt.encode('utf-8'))\n        digest = hasher.hexdigest()\n        if re.search(pattern, digest):\n"]]}
{"hexsha": "08671982ae844a113a420a3cf7e1c4041265c5cd", "ext": "py", "lang": "Python", "content": "def nonzero_groups(a, minlen=1, include_any=None):\n    '''Return groups of indexes where elements are non-zero. This function\nis similar to numpy's `nonzero()`, but instead of returning a single array of\nindexes, a tuple of consecutive groups of indexes is returned. Unlike\n`nonzero()` only 1d arrays are supported.\n\nParameters\n----------\n\na : array\nThe input array to search. The `dtype` must be boolean or coerceable to\nboolean.\n\nminlen : int\nThe minimum length of a run in order to be included in the output.\nRuns with fewer than `minlen` elements are excluded.\n\ninclude_any : scalar or array_like, optional\nOne or more indexes that the output runs must include. Any runs that\ncontain at least one of the indexes provided by `include_any` are\nin the output. Runs that do not contain at least one of the indexes\nare excluded. This parameter does not guarantee that all\n\nReturns\n-------\n\nruns : tuple of arrays\nTuple of arrays in which the contents of each array are the indexes\ninto `a` that represent a run of consecutive `True` values.\n\n'''\n    # Coerce to array of (0, 1) values.\n    a = np.asanyarray(a).astype(bool).astype(int)\n\n    # By taking the diff of `a` we detect transitions between True\n    # and False values. A value of `1` marks a transition from False\n    # to True, `-1` marks a transition from True to False, and `0`\n    # indicates a steady state from the previous True or False value.\n    # `0` is padded to the edges of `a` so that we can detect\n    # transitions to/from True values at the beginning and end.\n    try:\n        states = np.diff(a, prepend=0, append=0)\n    except TypeError:  # For older numpy\n        states = np.diff(np.hstack([0, a, 0]))\n\n    # Indexes of transitions to true and false.\n    true_starts = (states == 1).nonzero()[0]\n    false_starts = (states == -1).nonzero()[0]\n    try:\n        assert(np.all(true_starts < false_starts))\n    except:\n        raise RuntimeError('Unexpected state in nonzero_groups().')\n    if include_any is not None:\n        runs = tuple((\n            np.arange(tidx, fidx) \\\n                for tidx, fidx in zip(true_starts, false_starts) \\\n                    if (fidx - tidx) >= minlen \\\n                        and np.any(np.isin(np.arange(tidx, fidx), include_any)) \n        ))\n    else:\n        runs = tuple((\n            np.arange(tidx, fidx) \\\n                for tidx, fidx in zip(true_starts, false_starts) \\\n                    if (fidx - tidx) >= minlen\n        ))\n    return runs", "fn_id": 0, "class_fn": false, "repo": "rsprouse/phonlab", "file": "phonlab/array.py", "last_update_at": "2019-04-14T15:50:30+00:00", "question_id": "08671982ae844a113a420a3cf7e1c4041265c5cd_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def nonzero_groups(a, minlen=1, include_any=None):\n    \"\"\"Return groups of indexes where elements are non-zero. This function\nis similar to numpy's `nonzero()`, but instead of returning a single array of\nindexes, a tuple of consecutive groups of indexes is returned. Unlike\n`nonzero()` only 1d arrays are supported.\n\nParameters\n----------\n\na : array\nThe input array to search. The `dtype` must be boolean or coerceable to\nboolean.\n\nminlen : int\nThe minimum length of a run in order to be included in the output.\nRuns with fewer than `minlen` elements are excluded.\n\ninclude_any : scalar or array_like, optional\nOne or more indexes that the output runs must include. Any runs that\ncontain at least one of the indexes provided by `include_any` are\nin the output. Runs that do not contain at least one of the indexes\nare excluded. This parameter does not guarantee that all\n\nReturns\n-------\n\nruns : tuple of arrays\nTuple of arrays in which the contents of each array are the indexes\ninto `a` that represent a run of consecutive `True` values.\n\n\"\"\"\n    a = np.asanyarray(a).astype(bool).astype(int)\n    try:\n        states = np.diff(a, prepend=0, append=0)\n    except TypeError:\n        states = np.diff(np.hstack([0, a, 0]))\n    true_starts = (states == 1).nonzero()[0]\n    false_starts = (states == -1).nonzero()[0]\n    try:\n        assert np.all(true_starts < false_starts)\n    except:\n        raise RuntimeError('Unexpected state in nonzero_groups().')\n    if include_any is not None:\n        runs = tuple((np.arange(tidx, fidx) for tidx, fidx in zip(true_starts, false_starts) if fidx - tidx >= minlen and np.any(np.isin(np.arange(tidx, fidx), include_any))))\n    else:\n        runs = tuple((np.arange(tidx, fidx) for tidx, fidx in zip(true_starts, false_starts) if fidx - tidx >= minlen))\n"]]}
{"hexsha": "27545099dfad8f6242352652570f4c64b04e62cd", "ext": "py", "lang": "Python", "content": "def arr_to_cla(arr_intensity, str_output_type='full', int_dp=0):\n    \"\"\"\n    Takes flux intensity in the xrsb band and returns the classification.\n    Note, intensities below 10.0**-8.0 get an empty sting.\n\n    Parameters\n    ----------\n    arr_intensity : arr\n        The float or array of intensity values to find the classification of.\n\n    str_output_type : `str`\n        A string to decide the output necessary.\n        'full' = the character and number\n        'number' = just the number\n        'character' = just the character\n\n    int_dp : `int`\n        The dataset to look for maxima in.\n\n    Returns\n    -------\n    result : array\n        The list of indices for local maxima.\n    \"\"\"\n    lis_results = []\n\n    for i in range(0,len(arr_intensity)):\n        lis_results.append(flo_to_cla(arr_intensity[i], str_output_type='full', int_dp=int_dp))\n\n    return np.array(lis_results)", "fn_id": 2, "class_fn": false, "repo": "Alex-Ian-Hamilton/flarepy", "file": "flarepy/utils/flare_utils.py", "last_update_at": "2019-08-30T06:47:21+00:00", "question_id": "27545099dfad8f6242352652570f4c64b04e62cd_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def arr_to_cla(arr_intensity, str_output_type='full', int_dp=0):\n    \"\"\"\n    Takes flux intensity in the xrsb band and returns the classification.\n    Note, intensities below 10.0**-8.0 get an empty sting.\n\n    Parameters\n    ----------\n    arr_intensity : arr\n        The float or array of intensity values to find the classification of.\n\n    str_output_type : `str`\n        A string to decide the output necessary.\n        'full' = the character and number\n        'number' = just the number\n        'character' = just the character\n\n    int_dp : `int`\n        The dataset to look for maxima in.\n\n    Returns\n    -------\n    result : array\n        The list of indices for local maxima.\n    \"\"\"\n    lis_results = []\n    for i in range(0, len(arr_intensity)):\n        lis_results.append(flo_to_cla(arr_intensity[i], str_output_type='full', int_dp=int_dp))\n"]]}
{"hexsha": "e67257aa98a4bba4ba858bd41a94c1f1d29ccfa2", "ext": "py", "lang": "Python", "content": "def _serialize_allocations_for_resource_provider(allocations,\n                                                 resource_provider):\n    \"\"\"Turn a list of allocations into a dict by consumer id.\n\n    {'resource_provider_generation': GENERATION,\n     'allocations':\n       CONSUMER_ID_1: {\n           'resources': {\n              'DISK_GB': 4,\n              'VCPU': 2\n           }\n       },\n       CONSUMER_ID_2: {\n           'resources': {\n              'DISK_GB': 6,\n              'VCPU': 3\n           }\n       }\n    }\n    \"\"\"\n    return _allocations_dict(allocations, lambda x: x.consumer_id,\n                             resource_provider=resource_provider)", "fn_id": 3, "class_fn": false, "repo": "gotostack/nova", "file": "nova/api/openstack/placement/handlers/allocation.py", "last_update_at": "2019-07-29T10:30:24+00:00", "question_id": "e67257aa98a4bba4ba858bd41a94c1f1d29ccfa2_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _serialize_allocations_for_resource_provider(allocations, resource_provider):\n    \"\"\"Turn a list of allocations into a dict by consumer id.\n\n    {'resource_provider_generation': GENERATION,\n     'allocations':\n       CONSUMER_ID_1: {\n           'resources': {\n              'DISK_GB': 4,\n              'VCPU': 2\n           }\n       },\n       CONSUMER_ID_2: {\n           'resources': {\n              'DISK_GB': 6,\n              'VCPU': 3\n           }\n       }\n    }\n    \"\"\"\n"]]}
{"hexsha": "82fc8a6d44773a0bb7cf9d500ff474d661a9467d", "ext": "py", "lang": "Python", "content": "def get_metrics(run_id):\n    with open_connection() as conn:\n        with conn.cursor() as cursor:\n            cursor.execute(\n                f\"SELECT win_rate, win_rate_random, win_rate_expert_policy, average_reward FROM \\\n                cards.metrics \\\n                WHERE run_id = '{run_id}' \\\n                ORDER BY id ASC ;\"\n            )\n            result = cursor.fetchall()\n\n    df = pd.DataFrame(result, columns=['win_rate', 'win_rate_random', 'win_rate_expert_policy', 'average_reward'])\n    return df", "fn_id": 7, "class_fn": false, "repo": "Atrus619/DeckOfCards", "file": "util/db.py", "last_update_at": "2019-06-27T12:14:38+00:00", "question_id": "82fc8a6d44773a0bb7cf9d500ff474d661a9467d_7", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_metrics(run_id):\n    with open_connection() as conn:\n        with conn.cursor() as cursor:\n            cursor.execute(f\"SELECT win_rate, win_rate_random, win_rate_expert_policy, average_reward FROM                 cards.metrics                 WHERE run_id = '{run_id}'                 ORDER BY id ASC ;\")\n            result = cursor.fetchall()\n    df = pd.DataFrame(result, columns=['win_rate', 'win_rate_random', 'win_rate_expert_policy', 'average_reward'])\n"]]}
{"hexsha": "57f38f69d31e27bf6baf07a4993e242ed3f28f7a", "ext": "py", "lang": "Python", "content": "def get_summary_path(folder, fname, kind = 'train'):\n    import os\n    from time import gmtime, strftime\n    \n    o_fold = os.path.join(folder, kind)\n    time_str = strftime(\"%d_%b_%Y_%H_%M\", gmtime())\n    summ_path = os.path.join(o_fold,'{}_{}'.format(fname, time_str))\n    if not os.path.exists(summ_path):\n        os.makedirs(summ_path)\n    return summ_path", "fn_id": 4, "class_fn": false, "repo": "Maayan-Moshe/image_denoising_and_completion", "file": "utils/utils.py", "last_update_at": "2019-07-17T13:04:27+00:00", "question_id": "57f38f69d31e27bf6baf07a4993e242ed3f28f7a_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_summary_path(folder, fname, kind='train'):\n    import os\n    from time import gmtime, strftime\n    o_fold = os.path.join(folder, kind)\n    time_str = strftime('%d_%b_%Y_%H_%M', gmtime())\n    summ_path = os.path.join(o_fold, '{}_{}'.format(fname, time_str))\n    if not os.path.exists(summ_path):\n        os.makedirs(summ_path)\n"]]}
{"hexsha": "a3da0f36dc0edcaead0767f88813529235989b4a", "ext": "py", "lang": "Python", "content": "def create_readme(template_path, project_dir, project_name):\n    \"\"\"Check if a readme exists, and if not create one.\"\"\"\n    file_path = os.path.join(project_dir, 'README.md')\n    if not os.path.isfile(file_path):\n        if template_path:\n            # Makes a copy of the template file\n            shutil.copyfile(template_path, file_path)\n            click.echo('Created a README file based on the provided template')\n        else:\n            # No template file was provided, use the standard\n            with open(file_path, 'w') as f:\n                f.write(f'# {project_name}\\n\\n## TODO\\n\\n## Hylla\\nThis file was generated by [Hylla](https://github.com/adelhult/hylla). If you wish to use a template of your own. Specifiy the environmental varible HYLLA_README_TEMPLATE.')\n            click.echo('Created a standard README file')\n    else:\n        click.echo('A README does already exist in the folder')", "fn_id": 8, "class_fn": false, "repo": "adelhult/hylla", "file": "hylla.py", "last_update_at": "2019-09-17T11:17:45+00:00", "question_id": "a3da0f36dc0edcaead0767f88813529235989b4a_8", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def create_readme(template_path, project_dir, project_name):\n    \"\"\"Check if a readme exists, and if not create one.\"\"\"\n    file_path = os.path.join(project_dir, 'README.md')\n    if not os.path.isfile(file_path):\n        if template_path:\n            shutil.copyfile(template_path, file_path)\n            click.echo('Created a README file based on the provided template')\n        else:\n            with open(file_path, 'w') as f:\n                f.write(f'# {project_name}\\n\\n## TODO\\n\\n## Hylla\\nThis file was generated by [Hylla](https://github.com/adelhult/hylla). If you wish to use a template of your own. Specifiy the environmental varible HYLLA_README_TEMPLATE.')\n            click.echo('Created a standard README file')\n    else:\n"]]}
{"hexsha": "190bbde7328f320d582d24941b053de43c0edeb0", "ext": "py", "lang": "Python", "content": "@app.route('/plot/ph')\ndef plot_ph():\n\ttimes, temps, hums = getHistData(numSamples)\n\tys = hums\n\tfig = Figure()\n\taxis = fig.add_subplot(1, 1, 1)\n\taxis.set_title(\"Humidity Sensor\")\n\taxis.set_xlabel(\"Samples\")\n\taxis.set_ylabel(\"Percentage Humidity\")\n\taxis.grid(True)\n\txs = range(numSamples)\n\taxis.plot(xs, ys)\n\tcanvas = FigureCanvas(fig)\n\toutput = io.BytesIO()\n\tcanvas.print_png(output)\n\tresponse = make_response(output.getvalue())\n\tresponse.mimetype = 'image/png'\n\treturn response", "fn_id": 16, "class_fn": false, "repo": "eYSIP-2018/Flying-Sensor-Node", "file": "Drone-Server/app.py", "last_update_at": "2019-03-23T14:46:29+00:00", "question_id": "190bbde7328f320d582d24941b053de43c0edeb0_16", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@app.route('/plot/ph')\ndef plot_ph():\n    times, temps, hums = getHistData(numSamples)\n    ys = hums\n    fig = Figure()\n    axis = fig.add_subplot(1, 1, 1)\n    axis.set_title('Humidity Sensor')\n    axis.set_xlabel('Samples')\n    axis.set_ylabel('Percentage Humidity')\n    axis.grid(True)\n    xs = range(numSamples)\n    axis.plot(xs, ys)\n    canvas = FigureCanvas(fig)\n    output = io.BytesIO()\n    canvas.print_png(output)\n    response = make_response(output.getvalue())\n    response.mimetype = 'image/png'\n"]]}
{"hexsha": "ef3baf31c452befa79cb785eae94479a8ef80ff8", "ext": "py", "lang": "Python", "content": "def json_date_handler(object):\n    if isinstance(object, (datetime.datetime, datetime.date)):\n        return object.isoformat()\n\n    return None", "fn_id": 2, "class_fn": false, "repo": "openstack/stackviz", "file": "stackviz/export.py", "last_update_at": "2019-08-17T05:13:20+00:00", "question_id": "ef3baf31c452befa79cb785eae94479a8ef80ff8_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def json_date_handler(object):\n    if isinstance(object, (datetime.datetime, datetime.date)):\n        return object.isoformat()\n"]]}
{"hexsha": "85641744f156aac3d10e36e2fade7a219b65e031", "ext": "py", "lang": "Python", "content": "def find_modules():\n  \"\"\"Finds all the modules in the core package imported.\"\"\"\n\n  tf_modules = []\n  for _, name, _ in pkgutil.walk_packages(\n      core.__path__, prefix=core.__name__ + '.'):\n    try:\n      tf_modules.append(__import__(name, fromlist=['']))\n    except (ImportError, AttributeError):\n      pass\n\n  return tf_modules", "fn_id": 0, "class_fn": false, "repo": "maciekcc/tensorflow", "file": "tensorflow/tools/docs/tf_doctest.py", "last_update_at": "2019-09-04T09:58:58+00:00", "question_id": "85641744f156aac3d10e36e2fade7a219b65e031_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def find_modules():\n    \"\"\"Finds all the modules in the core package imported.\"\"\"\n    tf_modules = []\n    for _, name, _ in pkgutil.walk_packages(core.__path__, prefix=core.__name__ + '.'):\n        try:\n            tf_modules.append(__import__(name, fromlist=['']))\n        except (ImportError, AttributeError):\n            pass\n"]]}
{"hexsha": "a285eb59aed6f5a7dbd1db185352613e6ab47729", "ext": "py", "lang": "Python", "content": "def duck_duck_goose(lista_nombres,num_elegido):\n    while num_elegido > len(lista_nombres):\n        num_elegido = num_elegido - 4\n    jugador_elegido = lista_nombres[num_elegido - 1]\n    return jugador_elegido", "fn_id": 0, "class_fn": false, "repo": "pedromulas/Ejercicios_feb", "file": "duck_duck_goose.py", "last_update_at": "2019-02-15T16:03:38+00:00", "question_id": "a285eb59aed6f5a7dbd1db185352613e6ab47729_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def duck_duck_goose(lista_nombres, num_elegido):\n    while num_elegido > len(lista_nombres):\n        num_elegido = num_elegido - 4\n    jugador_elegido = lista_nombres[num_elegido - 1]\n"]]}
{"hexsha": "ab02dd1295db335ed735a7be6be97ea7212268eb", "ext": "py", "lang": "Python", "content": "def test_parser_service_arguments():\n    result = parse('my_service command key:\"value\"\\n')\n    args = result.block.service_block.service.service_fragment.arguments\n    assert args.child(0) == Token('NAME', 'key')\n    entity = get_entity(arith_exp(Tree('an_exp', [args.expression])))\n    assert entity.values.string.child(0) == Token('DOUBLE_QUOTED', '\"value\"')", "fn_id": 11, "class_fn": false, "repo": "omkar-dsd/storyscript", "file": "tests/integration/parser/Parser.py", "last_update_at": "2019-05-06T14:04:40+00:00", "question_id": "ab02dd1295db335ed735a7be6be97ea7212268eb_11", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_parser_service_arguments():\n    result = parse('my_service command key:\"value\"\\n')\n    args = result.block.service_block.service.service_fragment.arguments\n    assert args.child(0) == Token('NAME', 'key')\n    entity = get_entity(arith_exp(Tree('an_exp', [args.expression])))\n"]]}
{"hexsha": "b993ad5a3a0e8bd45bf6b21962c310b57375d83a", "ext": "py", "lang": "Python", "content": "def solve(masses: List[int]) -> Tuple[int, int]:\n    one: int = 0\n    for mass in masses:\n        fuel = mass // 3 - 2\n        one += fuel\n        if VERBOSE:\n            print(f\"{mass} {fuel} {one}\")\n\n    two: int = 0\n    for mass in masses:\n        module_fuel = mass // 3 - 2\n        fuel = 0\n        while module_fuel > 0:\n            fuel += module_fuel\n            module_fuel = module_fuel // 3 - 2\n        two += fuel\n        if VERBOSE:\n            print(f\"{mass} {fuel} {two}\")\n\n    return (one, two)", "fn_id": 0, "class_fn": false, "repo": "BrendanLeber/adventofcode", "file": "2019/01-tyranny_rocket/solve.py", "last_update_at": "2019-03-21T16:21:03+00:00", "question_id": "b993ad5a3a0e8bd45bf6b21962c310b57375d83a_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def solve(masses: List[int]) -> Tuple[int, int]:\n    one: int = 0\n    for mass in masses:\n        fuel = mass // 3 - 2\n        one += fuel\n        if VERBOSE:\n            print(f'{mass} {fuel} {one}')\n    two: int = 0\n    for mass in masses:\n        module_fuel = mass // 3 - 2\n        fuel = 0\n        while module_fuel > 0:\n            fuel += module_fuel\n            module_fuel = module_fuel // 3 - 2\n        two += fuel\n        if VERBOSE:\n            print(f'{mass} {fuel} {two}')\n"]]}
{"hexsha": "e626735d3c9fbbadf839f399c8163bb28aa204dc", "ext": "py", "lang": "Python", "content": "@mark.gate\n@mark.platform_incompatible(['ostl'])\ndef test_ecmp_dstip_enable(netop_login, topology, step, sanity_check):\n\n    # enable ecmp dest ip\n\n    ECMP_PATCH[0][\"value\"][\"hash_dstip_enabled\"] = (\n        ECMP_PATCH[0][\"value\"].pop(list(ECMP_PATCH[0][\"value\"])[0])\n    )\n    ECMP_PATCH[0][\"value\"][\"hash_dstip_enabled\"] = TRUE\n\n    status_code, response_data = execute_request(\n        PATH, \"PATCH\", json.dumps(ECMP_PATCH), SWITCH_IP,\n        False, xtra_header=cookie_header\n    )\n\n    assert status_code == http.client.NO_CONTENT, \\\n        \"Error patching ecmp dest ip enable Status code: \" \\\n        \"%s Response data: %s \" % (status_code, response_data)\n    step(\"### Enable Dest IP ECMP Patched. \"\n         \"Status code is 204 NO CONTENT  ###\\n\")\n\n    # Verify data\n    status_code, response_data = execute_request(\n        PATH, \"GET\", None, SWITCH_IP, False,\n        xtra_header=cookie_header\n    )\n\n    assert status_code == http.client.OK, \"Failed to query ecmp config\"\n    json_data = get_json(response_data)\n    assert json_data[\"configuration\"][\"ecmp_config\"][\"hash_dstip_enabled\"] \\\n        == TRUE, \"ECMP dest IP enable failed\"\n    step(\"### ECMP dest IP enable validated ###\\n\")", "fn_id": 5, "class_fn": false, "repo": "johcheun/ops-webui", "file": "ops-tests/feature/test_webui_ft_ecmp_config.py", "last_update_at": "2019-07-19T03:15:35+00:00", "question_id": "e626735d3c9fbbadf839f399c8163bb28aa204dc_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@mark.gate\n@mark.platform_incompatible(['ostl'])\ndef test_ecmp_dstip_enable(netop_login, topology, step, sanity_check):\n    ECMP_PATCH[0]['value']['hash_dstip_enabled'] = ECMP_PATCH[0]['value'].pop(list(ECMP_PATCH[0]['value'])[0])\n    ECMP_PATCH[0]['value']['hash_dstip_enabled'] = TRUE\n    status_code, response_data = execute_request(PATH, 'PATCH', json.dumps(ECMP_PATCH), SWITCH_IP, False, xtra_header=cookie_header)\n    assert status_code == http.client.NO_CONTENT, 'Error patching ecmp dest ip enable Status code: %s Response data: %s ' % (status_code, response_data)\n    step('### Enable Dest IP ECMP Patched. Status code is 204 NO CONTENT  ###\\n')\n    status_code, response_data = execute_request(PATH, 'GET', None, SWITCH_IP, False, xtra_header=cookie_header)\n    assert status_code == http.client.OK, 'Failed to query ecmp config'\n    json_data = get_json(response_data)\n    assert json_data['configuration']['ecmp_config']['hash_dstip_enabled'] == TRUE, 'ECMP dest IP enable failed'\n"]]}
{"hexsha": "d8fff4907cd423ef5771529f6e5c4e334f4a0123", "ext": "py", "lang": "Python", "content": "def createPlotFile(startNonce, nonces):\n    cmdLine = [ plotterPathName, \"-k\", str(key), \"-d\", tmpDirName, \"-t\", str(threads), \"-x\", plotCore,\n                \"-s\", str(startNonce), \"-n\", str(nonces) ]\n    print(BRIGHTGREEN + f\"Compute {nonces} missing nonces through running:\")\n    print(\"  \" + \" \".join(cmdLine))\n    if bDryRun :\n        return None\n    prc = subprocess.run(cmdLine, stdout = subprocess.PIPE, stderr = subprocess.PIPE)\n    print(BRIGHTGREEN + prc.stdout.decode(\"utf-8\"))\n    print(BRIGHTRED + prc.stderr.decode(\"utf-8\") + RESET_ALL)\n    if prc.returncode :\n        print(BRIGHTRED + f\"Error: Plotter returned with error code {prc.returncode}!\" + RESET_ALL)\n        sys.exit(1)\n    return os.path.join(tmpDirName, f\"{key}_{startNonce}_{nonces}_{nonces}\")", "fn_id": 1, "class_fn": false, "repo": "brmmm3/plotTools", "file": "plotMerger.py", "last_update_at": "2019-09-20T02:31:01+00:00", "question_id": "d8fff4907cd423ef5771529f6e5c4e334f4a0123_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def createPlotFile(startNonce, nonces):\n    cmdLine = [plotterPathName, '-k', str(key), '-d', tmpDirName, '-t', str(threads), '-x', plotCore, '-s', str(startNonce), '-n', str(nonces)]\n    print(BRIGHTGREEN + f'Compute {nonces} missing nonces through running:')\n    print('  ' + ' '.join(cmdLine))\n    if bDryRun:\n        return None\n    prc = subprocess.run(cmdLine, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    print(BRIGHTGREEN + prc.stdout.decode('utf-8'))\n    print(BRIGHTRED + prc.stderr.decode('utf-8') + RESET_ALL)\n    if prc.returncode:\n        print(BRIGHTRED + f'Error: Plotter returned with error code {prc.returncode}!' + RESET_ALL)\n        sys.exit(1)\n"]]}
{"hexsha": "a07802b34f124785381c058781894542f06e4f8a", "ext": "py", "lang": "Python", "content": "def var_of_means(n):\n    \"\"\"Construct a random matrix A with values drawn from the standard normal\n    distribution. Calculate the mean value of each row, then calculate the\n    variance of these means. Return the variance.\n\n    Inputs:\n        n (int): The number of rows and columns in the matrix A.\n\n    Returns:\n        (float) The variance of the means of each row.\n    \"\"\"\n    A = np.random.randn(n,n)\n    return A.mean(axis=1).var()", "fn_id": 0, "class_fn": false, "repo": "joshualy/numerical_computing", "file": "Introduction/PlottingIntro/solutions.py", "last_update_at": "2019-11-05T14:45:03+00:00", "question_id": "a07802b34f124785381c058781894542f06e4f8a_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def var_of_means(n):\n    \"\"\"Construct a random matrix A with values drawn from the standard normal\n    distribution. Calculate the mean value of each row, then calculate the\n    variance of these means. Return the variance.\n\n    Inputs:\n        n (int): The number of rows and columns in the matrix A.\n\n    Returns:\n        (float) The variance of the means of each row.\n    \"\"\"\n    A = np.random.randn(n, n)\n"]]}
{"hexsha": "97ff55103330230c0917ec1e7fcd7025f28507be", "ext": "py", "lang": "Python", "content": "def get_header_row():\n    header = ['Country', 'Person', 'Scorer']\n    for question in TCB_QUESTIONS:\n        header.append(f'{question}_relevancy')\n        header.append(f'{question}_priority')\n        header.append(f'{question}_score')\n        header.append(f'{question}_notes')\n    return header", "fn_id": 3, "class_fn": false, "repo": "PMA-2020/tcb", "file": "tcb/combine.py", "last_update_at": "2019-07-10T23:34:50+00:00", "question_id": "97ff55103330230c0917ec1e7fcd7025f28507be_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_header_row():\n    header = ['Country', 'Person', 'Scorer']\n    for question in TCB_QUESTIONS:\n        header.append(f'{question}_relevancy')\n        header.append(f'{question}_priority')\n        header.append(f'{question}_score')\n        header.append(f'{question}_notes')\n"]]}
{"hexsha": "7ca1eae2e575cb3df492f94b04f0fb4f95a03c9b", "ext": "py", "lang": "Python", "content": "def test_direct_dependencies(mock_packages):\n    out = dependencies('mpileaks')\n    actual = set(re.split(r'\\s+', out.strip()))\n    expected = set(['callpath'] + mpis)\n    assert expected == actual", "fn_id": 0, "class_fn": false, "repo": "mtmiller/spack", "file": "lib/spack/spack/test/cmd/dependencies.py", "last_update_at": "2019-06-06T19:18:50+00:00", "question_id": "7ca1eae2e575cb3df492f94b04f0fb4f95a03c9b_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_direct_dependencies(mock_packages):\n    out = dependencies('mpileaks')\n    actual = set(re.split('\\\\s+', out.strip()))\n    expected = set(['callpath'] + mpis)\n"]]}
{"hexsha": "f72482536502a08c92fdd47d1959c93914af950f", "ext": "py", "lang": "Python", "content": "def FindWhat(f,value,weight,i,j,item,num):\n    if i>=0:\n        if f[i][j]==f[i-1][j]:\n            item[i]=0\n            FindWhat(f,value,weight,i-1,j,item,num)\n        elif j-weight[i]>=0:\n            for k in range(num[i]+1):\n                if f[i][j]==f[i-1][j-k*weight[i]]+k*value[i]:\n                    item[i]=k\n                    break\n            FindWhat(f,value,weight,i-1,j-item[i]*weight[i],item,num)", "fn_id": 1, "class_fn": false, "repo": "Harrdy2018/2018-Huawei-Code-Craft", "file": "Competition Codes/packageFunction.py", "last_update_at": "2019-04-08T04:15:51+00:00", "question_id": "f72482536502a08c92fdd47d1959c93914af950f_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def FindWhat(f, value, weight, i, j, item, num):\n    if i >= 0:\n        if f[i][j] == f[i - 1][j]:\n            item[i] = 0\n            FindWhat(f, value, weight, i - 1, j, item, num)\n        elif j - weight[i] >= 0:\n            for k in range(num[i] + 1):\n                if f[i][j] == f[i - 1][j - k * weight[i]] + k * value[i]:\n                    item[i] = k\n                    break\n"]]}
{"hexsha": "5c7f7d1cad4c4947e6ca038c4d1651b3134a707f", "ext": "py", "lang": "Python", "content": "def test_midcurve_vol():\n    replace = Replacer()\n    mock_usd = Currency('MA890', 'USD')\n    xrefs = replace('gs_quant.timeseries.measures.GsAssetApi.get_asset_xrefs', Mock())\n    xrefs.return_value = [GsTemporalXRef(dt.date(2019, 1, 1), dt.date(2952, 12, 31), XRef(bbid='USD', ))]\n    identifiers = replace('gs_quant.timeseries.measures.GsAssetApi.map_identifiers', Mock())\n    identifiers.return_value = {'USD-LIBOR-BBA': 'MA123'}\n    replace('gs_quant.timeseries.measures.GsDataApi.get_market_data', mock_curr)\n    actual = tm.midcurve_vol(mock_usd, '3m', '1y', '1y', 50)\n    assert_series_equal(pd.Series([1, 2, 3], index=_index * 3, name='midcurveVol'), actual)\n    with pytest.raises(NotImplementedError):\n        tm.midcurve_vol(..., '3m', '1y', '1y', 50, real_time=True)\n    replace.restore()", "fn_id": 17, "class_fn": false, "repo": "robertoronderosjr/gs-quant-1", "file": "gs_quant/test/timeseries/test_measures.py", "last_update_at": "2019-09-07T19:54:35+00:00", "question_id": "5c7f7d1cad4c4947e6ca038c4d1651b3134a707f_17", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_midcurve_vol():\n    replace = Replacer()\n    mock_usd = Currency('MA890', 'USD')\n    xrefs = replace('gs_quant.timeseries.measures.GsAssetApi.get_asset_xrefs', Mock())\n    xrefs.return_value = [GsTemporalXRef(dt.date(2019, 1, 1), dt.date(2952, 12, 31), XRef(bbid='USD'))]\n    identifiers = replace('gs_quant.timeseries.measures.GsAssetApi.map_identifiers', Mock())\n    identifiers.return_value = {'USD-LIBOR-BBA': 'MA123'}\n    replace('gs_quant.timeseries.measures.GsDataApi.get_market_data', mock_curr)\n    actual = tm.midcurve_vol(mock_usd, '3m', '1y', '1y', 50)\n    assert_series_equal(pd.Series([1, 2, 3], index=_index * 3, name='midcurveVol'), actual)\n    with pytest.raises(NotImplementedError):\n        tm.midcurve_vol(..., '3m', '1y', '1y', 50, real_time=True)\n"]]}
{"hexsha": "a2046a045297bcf697640e8b3d61277c84c39f8c", "ext": "py", "lang": "Python", "content": "@pytest.fixture\ndef exp_dispatcher(mocker, networked_nodes_base):   # noqa: F811\n    api = mocker.Mock()\n    api.get_nodes = mocker.Mock(\n        return_value={'items': networked_nodes_base}\n    )\n    yield descs_runner.ExperimentDispatcher(\"test.yaml\", api=api)", "fn_id": 0, "class_fn": false, "repo": "miri64/iotlab_controller", "file": "iotlab_controller/tests/experiment/descs/test_runner.py", "last_update_at": "2019-05-28T11:41:38+00:00", "question_id": "a2046a045297bcf697640e8b3d61277c84c39f8c_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.fixture\ndef exp_dispatcher(mocker, networked_nodes_base):\n    api = mocker.Mock()\n    api.get_nodes = mocker.Mock(return_value={'items': networked_nodes_base})\n"]]}
{"hexsha": "d5fecf49f1bddaeee44aebd23a276dc45480c7f5", "ext": "py", "lang": "Python", "content": "def main(args):\n    model = load_config(args.model)\n    dataset = load_config(args.dataset)\n\n    cuda = model[\"common\"][\"cuda\"]\n\n    if cuda and not torch.cuda.is_available():\n        sys.exit(\"Error: CUDA requested but not available\")\n\n    global size\n    size = args.tile_size\n\n    global token\n    token = os.getenv(\"MAPBOX_ACCESS_TOKEN\")\n\n    if not token:\n        sys.exit(\"Error: map token needed visualizing results; export MAPBOX_ACCESS_TOKEN\")\n\n    global session\n    session = requests.Session()\n\n    global tiles\n    tiles = args.url\n\n    global predictor\n    predictor = Predictor(args.checkpoint, model, dataset)\n\n    app.run(host=args.host, port=args.port, threaded=False)", "fn_id": 3, "class_fn": false, "repo": "jjmata/robosat", "file": "robosat/tools/serve.py", "last_update_at": "2019-01-15T02:41:37+00:00", "question_id": "d5fecf49f1bddaeee44aebd23a276dc45480c7f5_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main(args):\n    model = load_config(args.model)\n    dataset = load_config(args.dataset)\n    cuda = model['common']['cuda']\n    if cuda and (not torch.cuda.is_available()):\n        sys.exit('Error: CUDA requested but not available')\n    global size\n    size = args.tile_size\n    global token\n    token = os.getenv('MAPBOX_ACCESS_TOKEN')\n    if not token:\n        sys.exit('Error: map token needed visualizing results; export MAPBOX_ACCESS_TOKEN')\n    global session\n    session = requests.Session()\n    global tiles\n    tiles = args.url\n    global predictor\n    predictor = Predictor(args.checkpoint, model, dataset)\n"]]}
{"hexsha": "809f2ff93387e4dae6dfe998053f859ab29d43cf", "ext": "py", "lang": "Python", "content": "@app.route('/transaction/<string:transaction_id>', methods=['GET'])\n@cors()\n@jsonify_exceptions\ndef transaction_get(transaction_id=None):\n    transaction = app.ledger.get_transaction(transaction_id)\n\n    if transaction is None:\n        abort(404)\n\n    return jsonify(transaction=transaction)", "fn_id": 4, "class_fn": false, "repo": "conservancy/accounting-api", "file": "accounting/web.py", "last_update_at": "2019-03-26T08:37:51+00:00", "question_id": "809f2ff93387e4dae6dfe998053f859ab29d43cf_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@app.route('/transaction/<string:transaction_id>', methods=['GET'])\n@cors()\n@jsonify_exceptions\ndef transaction_get(transaction_id=None):\n    transaction = app.ledger.get_transaction(transaction_id)\n    if transaction is None:\n        abort(404)\n"]]}
{"hexsha": "b7e35ffc217f29c99d34b0a4ed5c2765668d4900", "ext": "py", "lang": "Python", "content": "def generateBoundedProxMatrix(agentOpinions, epsilon, proximityLimit):\n    \n    confidenceMatrix = []\n    \n    for i in range (len(agentOpinions)):\n        \n        boundedAgents = np.zeros(len(agentOpinions))\n        validAgents = 0\n        \n        if (i + proximityLimit + 1 >= len(agentOpinions)):\n            startIndex = len(agentOpinions) - i - proximityLimit - 1\n            endIndex = startIndex + (proximityLimit * 2) + 1\n\n            \n        else:\n            startIndex = i - proximityLimit\n            endIndex = i + proximityLimit + 1\n        \n        for x in range (startIndex, endIndex):\n            if (np.abs(agentOpinions[x] - agentOpinions[i]) <= epsilon):\n                boundedAgents[x] = 1\n                validAgents += 1\n                \n        distribution = (np.random.dirichlet(np.ones(validAgents), 1))[0]\n        iterator = 0\n        \n        for n in range (len(boundedAgents)):\n            \n            if (iterator == validAgents):\n                break\n            \n            elif (boundedAgents[n] == 1):\n                boundedAgents[n] = distribution[iterator]\n                iterator += 1\n    \n        confidenceMatrix.append(boundedAgents)\n    \n    return confidenceMatrix", "fn_id": 3, "class_fn": false, "repo": "AlessandroHardjono/PolarizationModel", "file": "frag_model.py", "last_update_at": "2019-01-29T02:53:08+00:00", "question_id": "b7e35ffc217f29c99d34b0a4ed5c2765668d4900_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def generateBoundedProxMatrix(agentOpinions, epsilon, proximityLimit):\n    confidenceMatrix = []\n    for i in range(len(agentOpinions)):\n        boundedAgents = np.zeros(len(agentOpinions))\n        validAgents = 0\n        if i + proximityLimit + 1 >= len(agentOpinions):\n            startIndex = len(agentOpinions) - i - proximityLimit - 1\n            endIndex = startIndex + proximityLimit * 2 + 1\n        else:\n            startIndex = i - proximityLimit\n            endIndex = i + proximityLimit + 1\n        for x in range(startIndex, endIndex):\n            if np.abs(agentOpinions[x] - agentOpinions[i]) <= epsilon:\n                boundedAgents[x] = 1\n                validAgents += 1\n        distribution = np.random.dirichlet(np.ones(validAgents), 1)[0]\n        iterator = 0\n        for n in range(len(boundedAgents)):\n            if iterator == validAgents:\n                break\n            elif boundedAgents[n] == 1:\n                boundedAgents[n] = distribution[iterator]\n                iterator += 1\n        confidenceMatrix.append(boundedAgents)\n"]]}
{"hexsha": "60857cf700bb64c9c1be37fa96c09b36a657003c", "ext": "py", "lang": "Python", "content": "def setup():\n    pygame.init()\n    viewport = (1024,768)\n    pygame.display.set_mode(viewport, OPENGL | DOUBLEBUF)\n    glLightfv(GL_LIGHT0, GL_POSITION,   (viewport[0]/2, 0, viewport[1]/2, 0.0))\n    glLightfv(GL_LIGHT0, GL_AMBIENT,    (0.2, 0.2, 0.2, 1.0))\n    glLightfv(GL_LIGHT0, GL_DIFFUSE,    (0.5, 0.5, 0.5, 1.0))\n    glEnable(GL_LIGHT0)\n    glEnable(GL_LIGHTING)\n    glEnable(GL_COLOR_MATERIAL)\n    glEnable(GL_DEPTH_TEST)\n    glShadeModel(GL_SMOOTH)\n    glEnable(GL_BLEND)\n    glBlendFunc(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA)\n\n    global clock\n    clock   = pygame.time.Clock()\n    \n    global player\n    player  = Player(0., 0.)\n    \n    global enemy\n    enemy = Player(200., 0.)\n\n    global trailMatrix\n    trailMatrix\t= {}\n    \n    global floor\n    floor   = Floor(size=20, tileSize=10)\n    \n    global camera\n    camera  = Camera(viewport, (floor.size*floor.tileSize, floor.size*floor.tileSize))\n    camera.bindToPlayer(player)\n    \n    global playerEnabled\n    playerEnabled = True", "fn_id": 0, "class_fn": false, "repo": "rgoliveira/PyTRON", "file": "src/pytron.py", "last_update_at": "2019-08-06T22:59:40+00:00", "question_id": "60857cf700bb64c9c1be37fa96c09b36a657003c_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def setup():\n    pygame.init()\n    viewport = (1024, 768)\n    pygame.display.set_mode(viewport, OPENGL | DOUBLEBUF)\n    glLightfv(GL_LIGHT0, GL_POSITION, (viewport[0] / 2, 0, viewport[1] / 2, 0.0))\n    glLightfv(GL_LIGHT0, GL_AMBIENT, (0.2, 0.2, 0.2, 1.0))\n    glLightfv(GL_LIGHT0, GL_DIFFUSE, (0.5, 0.5, 0.5, 1.0))\n    glEnable(GL_LIGHT0)\n    glEnable(GL_LIGHTING)\n    glEnable(GL_COLOR_MATERIAL)\n    glEnable(GL_DEPTH_TEST)\n    glShadeModel(GL_SMOOTH)\n    glEnable(GL_BLEND)\n    glBlendFunc(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA)\n    global clock\n    clock = pygame.time.Clock()\n    global player\n    player = Player(0.0, 0.0)\n    global enemy\n    enemy = Player(200.0, 0.0)\n    global trailMatrix\n    trailMatrix = {}\n    global floor\n    floor = Floor(size=20, tileSize=10)\n    global camera\n    camera = Camera(viewport, (floor.size * floor.tileSize, floor.size * floor.tileSize))\n    camera.bindToPlayer(player)\n    global playerEnabled\n"]]}
{"hexsha": "3a2d856395d3eb7764d567716d1f16e603f91e66", "ext": "py", "lang": "Python", "content": "def antijoin(\n    left: Union[pd.DataFrame, gs.DataFile],\n    right: Union[pd.DataFrame, gs.DataFile],\n    on: list = None,\n    left_on: list = None,\n    right_on: list = None) -> pd.DataFrame:\n    \"\"\"Filtering join: extract rows in 'left' with no match in 'right'.\n\n    The `left` frame is filtered by the `right` frame.\n\n    Parameters\n    ----------\n    left : Data to be filtered.\n    right : Data to do the filtering.\n    on : List of columns common to `left` and `right` to be used for filtering.\n        If this is anything but `None` the parameters `left_on` and `right_on`\n        will be ignored.\n    left_on : List of columns from `left` to match on. Must be for the same\n        column types and in sequence specified with `right_on`.\n    right_on : List of columns from `right` to match on. Must be for the same\n        column types and in sequence specified with `left_on`.\n\n    Return\n    ------\n    The data `left` is returned minus rows that have no match in `right` for\n    the given list of columns (`on` or `left_on` + `right_on`).\n\n    Example\n    -------\n\n    import pandas.util.testing as tm\n\n    # Set default rows and columns for Pandas testing utilities.\n    tm.N, tm.K = 5, 3\n\n    # Make dummy DataFrames\n    right = tm.makeDataFrame()\\\n        .set_index(tm.makeCategoricalIndex(k=5, name=\"bhid\"))\\\n        .reset_index()\n\n    # Convert the `bhid` column to numeric.\n    dtfl, dhdict = alpha2numeric(df)\n\n    print(\"Original DataFrame:\\n\", df, \"\\n\")\n    print(\"Updated DataFrame:\\n\", dtfl, \"\\n\")\n    print(\"Hole id dictionary:\\n\", dhdict)\n\n    \"\"\"\n\n    # Handle gs.DataFile.\n    if isinstance(left, gs.DataFile):\n        left = left.data\n    if isinstance(right, gs.DataFile):\n        right = right.data\n\n    # Handle the `on` parameters.\n    if on is not None:\n        left_on = on\n        right_on = on\n    elif left_on is not None:\n        if right_on is None:\n            raise Exception(\"If specifying `left_on` or `right_on` both must be supplied\")\n        if len(right_on) != len(left_on):\n            raise Eception(\"The `left_on` and `right_on` list must have the same number of items\")\n\n    filt = left[~left[left_on].apply(tuple, 1).isin(right[right_on].apply(tuple, 1))]\n\n    return filt", "fn_id": 0, "class_fn": false, "repo": "truemoid/myutils", "file": "myutils/antijoin.py", "last_update_at": "2019-09-14T15:43:59+00:00", "question_id": "3a2d856395d3eb7764d567716d1f16e603f91e66_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def antijoin(left: Union[pd.DataFrame, gs.DataFile], right: Union[pd.DataFrame, gs.DataFile], on: list=None, left_on: list=None, right_on: list=None) -> pd.DataFrame:\n    \"\"\"Filtering join: extract rows in 'left' with no match in 'right'.\n\n    The `left` frame is filtered by the `right` frame.\n\n    Parameters\n    ----------\n    left : Data to be filtered.\n    right : Data to do the filtering.\n    on : List of columns common to `left` and `right` to be used for filtering.\n        If this is anything but `None` the parameters `left_on` and `right_on`\n        will be ignored.\n    left_on : List of columns from `left` to match on. Must be for the same\n        column types and in sequence specified with `right_on`.\n    right_on : List of columns from `right` to match on. Must be for the same\n        column types and in sequence specified with `left_on`.\n\n    Return\n    ------\n    The data `left` is returned minus rows that have no match in `right` for\n    the given list of columns (`on` or `left_on` + `right_on`).\n\n    Example\n    -------\n\n    import pandas.util.testing as tm\n\n    # Set default rows and columns for Pandas testing utilities.\n    tm.N, tm.K = 5, 3\n\n    # Make dummy DataFrames\n    right = tm.makeDataFrame()        .set_index(tm.makeCategoricalIndex(k=5, name=\"bhid\"))        .reset_index()\n\n    # Convert the `bhid` column to numeric.\n    dtfl, dhdict = alpha2numeric(df)\n\n    print(\"Original DataFrame:\n\", df, \"\n\")\n    print(\"Updated DataFrame:\n\", dtfl, \"\n\")\n    print(\"Hole id dictionary:\n\", dhdict)\n\n    \"\"\"\n    if isinstance(left, gs.DataFile):\n        left = left.data\n    if isinstance(right, gs.DataFile):\n        right = right.data\n    if on is not None:\n        left_on = on\n        right_on = on\n    elif left_on is not None:\n        if right_on is None:\n            raise Exception('If specifying `left_on` or `right_on` both must be supplied')\n        if len(right_on) != len(left_on):\n            raise Eception('The `left_on` and `right_on` list must have the same number of items')\n    filt = left[~left[left_on].apply(tuple, 1).isin(right[right_on].apply(tuple, 1))]\n"]]}
{"hexsha": "ea21300009d923f7eaca8d5a9a2f0367da37b10a", "ext": "py", "lang": "Python", "content": "def main():\n\n    args = ARG_LIST.parse_args(sys.argv[1:])\n    logging.basicConfig(level=LEVELS[args.log_level])\n\n    run_dmdismod(\n        file=args.file,\n        dm_commands=args.dm_commands\n    )", "fn_id": 1, "class_fn": false, "repo": "ihmeuw/cascade-at", "file": "src/cascade_at/executor/run_dmdismod.py", "last_update_at": "2019-10-14T23:18:04+00:00", "question_id": "ea21300009d923f7eaca8d5a9a2f0367da37b10a_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main():\n    args = ARG_LIST.parse_args(sys.argv[1:])\n    logging.basicConfig(level=LEVELS[args.log_level])\n"]]}
{"hexsha": "aec5f2829dffd715cb37bd89dfdef58bbc4baa7c", "ext": "py", "lang": "Python", "content": "def soft_jaccard_binary_loss(output, label, weight=1):\n    \"\"\"\n        Original:\n        class LossBinary:\n        Loss defined as BCE - log(soft_jaccard)\n        Vladimir Iglovikov, Sergey Mushinskiy, Vladimir Osin,\n        Satellite Imagery Feature Detection using Deep Convolutional Neural Network: A Kaggle Competition\n        arXiv:1706.06169\n\n        def __init__(self, jaccard_weight=0):\n            self.nll_loss = nn.BCEWithLogitsLoss()\n            self.jaccard_weight = jaccard_weight\n\n        def __call__(self, outputs, targets):\n            loss = self.nll_loss(outputs, targets)\n\n            if self.jaccard_weight:\n                eps = 1e-15\n                jaccard_target = (targets == 1).float()\n                jaccard_output = F.sigmoid(outputs)\n\n                intersection = (jaccard_output * jaccard_target).sum()\n                union = jaccard_output.sum() + jaccard_target.sum()\n\n                loss -= self.jaccard_weight * torch.log((intersection + eps) / (union - intersection + eps))\n            return loss\n        or,\n        class Loss:\n            def __init__(self, dice_weight=1):\n                self.nll_loss = nn.BCELoss()\n                self.dice_weight = dice_weight\n\n            def __call__(self, outputs, targets):\n                loss = self.nll_loss(outputs, targets)\n                if self.dice_weight:\n                    eps = 1e-15\n                    dice_target = (targets == 1).float()\n                    dice_output = outputs\n                    intersection = (dice_output * dice_target).sum()\n                    union = dice_output.sum() + dice_target.sum() + eps\n\n                    loss -= torch.log(2 * intersection / union)\n\n                return loss\n    \"\"\"\n    label = tf.cast(tf.greater(label, 0), tf.float32)\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=label))\n\n    if weight > 0:\n        output = tf.nn.sigmoid(output)\n        smooth = 1e-15\n        intersection = tf.reduce_sum(output * label)\n        union = tf.reduce_sum(output) + tf.reduce_sum(label)\n        loss -= weight *  tf.log((intersection + smooth) / (union - intersection + smooth))\n\n    return loss", "fn_id": 2, "class_fn": false, "repo": "philferriere/tf-dsb-18", "file": "losses.py", "last_update_at": "2019-08-05T08:06:41+00:00", "question_id": "aec5f2829dffd715cb37bd89dfdef58bbc4baa7c_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def soft_jaccard_binary_loss(output, label, weight=1):\n    \"\"\"\n        Original:\n        class LossBinary:\n        Loss defined as BCE - log(soft_jaccard)\n        Vladimir Iglovikov, Sergey Mushinskiy, Vladimir Osin,\n        Satellite Imagery Feature Detection using Deep Convolutional Neural Network: A Kaggle Competition\n        arXiv:1706.06169\n\n        def __init__(self, jaccard_weight=0):\n            self.nll_loss = nn.BCEWithLogitsLoss()\n            self.jaccard_weight = jaccard_weight\n\n        def __call__(self, outputs, targets):\n            loss = self.nll_loss(outputs, targets)\n\n            if self.jaccard_weight:\n                eps = 1e-15\n                jaccard_target = (targets == 1).float()\n                jaccard_output = F.sigmoid(outputs)\n\n                intersection = (jaccard_output * jaccard_target).sum()\n                union = jaccard_output.sum() + jaccard_target.sum()\n\n                loss -= self.jaccard_weight * torch.log((intersection + eps) / (union - intersection + eps))\n            return loss\n        or,\n        class Loss:\n            def __init__(self, dice_weight=1):\n                self.nll_loss = nn.BCELoss()\n                self.dice_weight = dice_weight\n\n            def __call__(self, outputs, targets):\n                loss = self.nll_loss(outputs, targets)\n                if self.dice_weight:\n                    eps = 1e-15\n                    dice_target = (targets == 1).float()\n                    dice_output = outputs\n                    intersection = (dice_output * dice_target).sum()\n                    union = dice_output.sum() + dice_target.sum() + eps\n\n                    loss -= torch.log(2 * intersection / union)\n\n                return loss\n    \"\"\"\n    label = tf.cast(tf.greater(label, 0), tf.float32)\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=label))\n    if weight > 0:\n        output = tf.nn.sigmoid(output)\n        smooth = 1e-15\n        intersection = tf.reduce_sum(output * label)\n        union = tf.reduce_sum(output) + tf.reduce_sum(label)\n        loss -= weight * tf.log((intersection + smooth) / (union - intersection + smooth))\n"]]}
{"hexsha": "73595d0356a1da6efdacc82d9051b1ca7e85e85b", "ext": "py", "lang": "Python", "content": "def main(prog_name=os.path.basename(sys.argv[0]), args=None):\n    if args is None:\n        args = sys.argv[1:]\n    parser = create_parser(prog_name)\n    args = parser.parse_args(args)\n\n    if args.verbose is None:\n        verbose_level = 0\n    else:\n        verbose_level = args.verbose\n\n    setup_loggers(verbose_level=verbose_level)\n\n    config = load_config()\n\n    if args.command == \"create\":\n        do_create_artifact(args, config) \n    elif args.command == \"list-artifact\":\n        do_list_artifact(args, config)\n    elif args.command == \"retrieve\":\n        do_retrieve_artifact(args, config)\n    elif args.command == \"amend\":\n        do_amend_artifact(args, config)    \n    elif args.command == \"AddArtifact\":\n        do_add_sub_artifact(args, config)  \n    elif args.command == \"AddURI\":\n        do_add_uri_to_artifact(args,config)\n    else:    \n        raise ArtifactException(\"invalid command {}\".format(args.command))", "fn_id": 19, "class_fn": false, "repo": "pkthein/sparts_all_fam", "file": "proto/tp_artifact_1.0/sawtooth_artifact/artifact_cli.py", "last_update_at": "2019-04-03T18:31:36+00:00", "question_id": "73595d0356a1da6efdacc82d9051b1ca7e85e85b_19", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main(prog_name=os.path.basename(sys.argv[0]), args=None):\n    if args is None:\n        args = sys.argv[1:]\n    parser = create_parser(prog_name)\n    args = parser.parse_args(args)\n    if args.verbose is None:\n        verbose_level = 0\n    else:\n        verbose_level = args.verbose\n    setup_loggers(verbose_level=verbose_level)\n    config = load_config()\n    if args.command == 'create':\n        do_create_artifact(args, config)\n    elif args.command == 'list-artifact':\n        do_list_artifact(args, config)\n    elif args.command == 'retrieve':\n        do_retrieve_artifact(args, config)\n    elif args.command == 'amend':\n        do_amend_artifact(args, config)\n    elif args.command == 'AddArtifact':\n        do_add_sub_artifact(args, config)\n    elif args.command == 'AddURI':\n        do_add_uri_to_artifact(args, config)\n    else:\n"]]}
{"hexsha": "ed2c780bbbff996e3c06eeeb0b34fa0e9db60490", "ext": "py", "lang": "Python", "content": "def patch_node(node, docpath, docname=None):\n    '''\n    Recursively patches links in nodes.\n    '''\n    node_name = node.localName\n\n    # if node is <img>\n    if node_name == \"img\":\n        src = node.getAttributeNode(\"src\")\n        # if this is relative path (internal link)\n        if src.value.startswith(\"..\"):\n            src.value = docpath + src.value\n        src.value = collapse_path(src.value)\n    # if node is hyperlink\n    elif node_name == \"a\":\n        ref = node.getAttributeNode(\"href\")\n        # skip anchor links <a name=\"anchor1\"></a>, <a name=\"more\"/>\n        if ref != None:\n            # patch links only - either starting with \"../\" or having\n            # \"internal\" class\n            is_relative = ref.value.startswith(\"../\")\n            if is_relative or \"internal\" in node.getAttribute(\"class\"):\n                ref.value = docpath + ref.value\n\n            # html anchor with missing post.html\n            # e.g. href=\"2012/08/23/#the-cross-compiler\"\n            # now href=\"2012/08/23/a_post.html#the-cross-compiler\"\n            ref.value = ref.value.replace(\"/#\", \"/%s.html#\" % docname)\n\n            # normalize urls so \"2012/08/23/../../../_static/\" becomes\n            # \"_static/\" - we can use normpath for this, just make sure\n            # to revert change on protocol prefix as normpath deduplicates\n            # // (http:// becomes http:/)\n            ref.value = collapse_path(ref.value)\n\n    # recurse\n    for node in node.childNodes:\n        patch_node(node, docpath, docname)", "fn_id": 7, "class_fn": false, "repo": "sgillies/tinkerer", "file": "tinkerer/ext/patch.py", "last_update_at": "2019-02-16T15:11:44+00:00", "question_id": "ed2c780bbbff996e3c06eeeb0b34fa0e9db60490_7", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def patch_node(node, docpath, docname=None):\n    \"\"\"\n    Recursively patches links in nodes.\n    \"\"\"\n    node_name = node.localName\n    if node_name == 'img':\n        src = node.getAttributeNode('src')\n        if src.value.startswith('..'):\n            src.value = docpath + src.value\n        src.value = collapse_path(src.value)\n    elif node_name == 'a':\n        ref = node.getAttributeNode('href')\n        if ref != None:\n            is_relative = ref.value.startswith('../')\n            if is_relative or 'internal' in node.getAttribute('class'):\n                ref.value = docpath + ref.value\n            ref.value = ref.value.replace('/#', '/%s.html#' % docname)\n            ref.value = collapse_path(ref.value)\n    for node in node.childNodes:\n"]]}
{"hexsha": "4e3d9574adf2dc9d717e461ff90951fa77ac1631", "ext": "py", "lang": "Python", "content": "def ko_model(model, field_names=None, data=None):\n    \"\"\"\n    Given a model, returns the Knockout Model and the Knockout ViewModel.\n    Takes optional field names and data.\n    \"\"\"\n\n    try:\n        if isinstance(model, str):\n            modelName = model\n        else:\n            modelName = model.__class__.__name__\n\n        if field_names:\n            fields = field_names\n        else:\n            fields = get_fields(model)\n\n        if hasattr(model, \"comparator\"):\n            comparator = str(model.comparator())\n        else:\n            comparator = 'id'\n\n        modelViewString = render_to_string(\n            \"knockout_modeler/model.js\",\n            {'modelName': modelName, 'fields': fields, 'data': data, 'comparator': comparator}\n        )\n\n        return modelViewString\n    except Exception as e:\n        logger.exception(e)\n        return ''", "fn_id": 2, "class_fn": false, "repo": "Miserlou/django-knockout-modeler", "file": "knockout_modeler/ko.py", "last_update_at": "2019-12-17T04:19:41+00:00", "question_id": "4e3d9574adf2dc9d717e461ff90951fa77ac1631_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def ko_model(model, field_names=None, data=None):\n    \"\"\"\n    Given a model, returns the Knockout Model and the Knockout ViewModel.\n    Takes optional field names and data.\n    \"\"\"\n    try:\n        if isinstance(model, str):\n            modelName = model\n        else:\n            modelName = model.__class__.__name__\n        if field_names:\n            fields = field_names\n        else:\n            fields = get_fields(model)\n        if hasattr(model, 'comparator'):\n            comparator = str(model.comparator())\n        else:\n            comparator = 'id'\n        modelViewString = render_to_string('knockout_modeler/model.js', {'modelName': modelName, 'fields': fields, 'data': data, 'comparator': comparator})\n        return modelViewString\n    except Exception as e:\n        logger.exception(e)\n"]]}
{"hexsha": "be6f24091f09bd7beb62aa38489c89ecf8b03c6e", "ext": "py", "lang": "Python", "content": "def merge_counts(counts, output, attrs, reduce=False):\n    handles = {}\n    for sample, path in counts.items():\n        handles[sample] = open(path, 'rt')\n    with open(output, 'w') as fh:\n        samples = list(counts.keys())\n        headers = attrs + '\\t' + '\\t'.join(samples) + '\\n'\n        fh.write(headers)\n        for lines in zip_longest(*[handles[sample] for sample in samples]):\n            if lines[0].startswith('__'):\n                continue\n            values = [line.rstrip().split('\\t')[-1] for line in lines]\n            gene_annos = '\\t'.join(lines[0].rstrip().split('\\t')[:-1])\n            if reduce:\n                if len([v for v in values if int(v) > 0]) < 1:\n                    continue\n            line = gene_annos + '\\t' + '\\t'.join(values) + '\\n'\n            fh.write(line)\n    for h in handles.values():\n        h.close()", "fn_id": 0, "class_fn": false, "repo": "zhuchcn/exceRNAseq", "file": "exceRNApipeline/tasks/task_summarize_counts.py", "last_update_at": "2019-11-26T02:41:11+00:00", "question_id": "be6f24091f09bd7beb62aa38489c89ecf8b03c6e_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def merge_counts(counts, output, attrs, reduce=False):\n    handles = {}\n    for sample, path in counts.items():\n        handles[sample] = open(path, 'rt')\n    with open(output, 'w') as fh:\n        samples = list(counts.keys())\n        headers = attrs + '\\t' + '\\t'.join(samples) + '\\n'\n        fh.write(headers)\n        for lines in zip_longest(*[handles[sample] for sample in samples]):\n            if lines[0].startswith('__'):\n                continue\n            values = [line.rstrip().split('\\t')[-1] for line in lines]\n            gene_annos = '\\t'.join(lines[0].rstrip().split('\\t')[:-1])\n            if reduce:\n                if len([v for v in values if int(v) > 0]) < 1:\n                    continue\n            line = gene_annos + '\\t' + '\\t'.join(values) + '\\n'\n            fh.write(line)\n    for h in handles.values():\n"]]}
{"hexsha": "daf6d637fc70dfc88256c42fe847cb88fc9cbc0e", "ext": "py", "lang": "Python", "content": "def get_facebook_text(uri, api):\n    \"\"\"\n    take in a facebook id and pattern facebook API instance\n    return a string of profile blurb + recent posts\n    if nothing interesting is returned, return empty string\n        - returns: string\n    \"\"\"\n    if isinstance(uri, str): \n        uri = unicode(uri)\n        \n    if isinstance(uri, unicode):\n        if not all([c.isdigit() for c in uri]):\n            fid = requests.get(url='http://graph.facebook.com/' + uri).json().get('id')  # get the Facebook id from graph\n        else:\n            fid = uri  # numeric id\n    elif isinstance(uri, int):\n        fid = uri\n\n    fetched = False\n\n    while not fetched:\n        user_text = []\n        try:\n            for post in api.search(fid, type=NEWS, count=100):\n                post_text = []\n                if not any([x in post.text for x in settings.useless_keywords]):  # i.e. `if the post isn't \"Charlie Hack likes a photo\":`\n                    post_text.append(unicode(remove_nonascii(post.text)))\n                if post.comments > 0:\n                    post_text.extend([unicode(remove_nonascii(r.text)) for r in api.search(post.id, type=COMMENTS)])\n                user_text.append(' '.join(post_text))\n\n            user_text  = unicode(' '.join(user_text))\n            fetched    = True\n\n        except URLTimeout as e:\n            print('URLTimeout:', e)\n            time.sleep(settings.sleep_time)\n        except URLError as e:\n            print('URLError:', e)\n            break\n\n    if isinstance(user_text, list):\n        if len(user_text) >= 1:\n            user_text = unicode(' '.join(user_text))  # sometimes these get popped off before the join\n        else:\n            user_text = u''  # return empty string\n\n    assert isinstance(user_text, unicode), \"facebook {user_text} isn't unicode, it's {type}.\".format(user_text=user_text, type=type(user_text))\n    return remove_nonascii(user_text)", "fn_id": 1, "class_fn": false, "repo": "hack-c/profilegrab", "file": "profilegrab/scrapers.py", "last_update_at": "2019-12-30T02:13:43+00:00", "question_id": "daf6d637fc70dfc88256c42fe847cb88fc9cbc0e_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_facebook_text(uri, api):\n    \"\"\"\n    take in a facebook id and pattern facebook API instance\n    return a string of profile blurb + recent posts\n    if nothing interesting is returned, return empty string\n        - returns: string\n    \"\"\"\n    if isinstance(uri, str):\n        uri = unicode(uri)\n    if isinstance(uri, unicode):\n        if not all([c.isdigit() for c in uri]):\n            fid = requests.get(url='http://graph.facebook.com/' + uri).json().get('id')\n        else:\n            fid = uri\n    elif isinstance(uri, int):\n        fid = uri\n    fetched = False\n    while not fetched:\n        user_text = []\n        try:\n            for post in api.search(fid, type=NEWS, count=100):\n                post_text = []\n                if not any([x in post.text for x in settings.useless_keywords]):\n                    post_text.append(unicode(remove_nonascii(post.text)))\n                if post.comments > 0:\n                    post_text.extend([unicode(remove_nonascii(r.text)) for r in api.search(post.id, type=COMMENTS)])\n                user_text.append(' '.join(post_text))\n            user_text = unicode(' '.join(user_text))\n            fetched = True\n        except URLTimeout as e:\n            print('URLTimeout:', e)\n            time.sleep(settings.sleep_time)\n        except URLError as e:\n            print('URLError:', e)\n            break\n    if isinstance(user_text, list):\n        if len(user_text) >= 1:\n            user_text = unicode(' '.join(user_text))\n        else:\n            user_text = u''\n    assert isinstance(user_text, unicode), \"facebook {user_text} isn't unicode, it's {type}.\".format(user_text=user_text, type=type(user_text))\n"]]}
{"hexsha": "8abca9050609c9b11dbe6046932271d762d68c70", "ext": "py", "lang": "Python", "content": "def login(username, password):\n    session = requests.session()\n    mobileAgent = 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Droid Build/FRG22D) AppleWebKit/533.1 (KHTML, like Gecko) \\\n                   Version/4.0 Mobile Safari/533.1'\n    session.headers.update({'User-Agent': mobileAgent})\n    anonResponse = session.get('https://www.linkedin.com/')\n    try:\n        loginCSRF = re.findall(r'name=\"loginCsrfParam\".*?value=\"(.*?)\"', anonResponse.text)[0]\n    except:\n        print('Having trouble with loading the page... try the command again.')\n        exit()\n\n    authPayload = {\n        'session_key': username,\n        'session_password': password,\n        'loginCsrfParam': loginCSRF\n        }\n\n    response = session.post('https://www.linkedin.com/uas/login-submit', data=authPayload)\n\n    if bool(re.search('<title>*?LinkedIn*?</title>', response.text)): # users get slightly different responses here\n        print('[+] Successfully logged in.\\n')\n        return session\n    elif '<title>Sign-In Verification</title>' in response.text:\n        print('[!] LinkedIn doesn\\'t like something about this login. Maybe you\\'re being sneaky on a VPN or')\n        print('    something. You may get an email with a verification token. You can ignore that.')\n        print('    Try logging in with the same account in your browser first, then try this tool again.\\n')\n        exit()\n    elif '<title>Sign In</title>' in response.text:\n        print('[!] You\\'ve been returned to the login page. Check your password and try again.\\n')\n        exit()\n    elif '<title>Security Verification' in response.text:\n        print('[!] You\\'ve triggered the security verification. Please verify your login details and try again.\\n')\n        exit()\n    else:\n        print('[!] Some unknown error logging in. If this persists, please open an issue on github.\\n')\n        exit()", "fn_id": 0, "class_fn": false, "repo": "techrec13/linkedin2username", "file": "linkedin2username.py", "last_update_at": "2019-10-19T23:15:32+00:00", "question_id": "8abca9050609c9b11dbe6046932271d762d68c70_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def login(username, password):\n    session = requests.session()\n    mobileAgent = 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Droid Build/FRG22D) AppleWebKit/533.1 (KHTML, like Gecko)                    Version/4.0 Mobile Safari/533.1'\n    session.headers.update({'User-Agent': mobileAgent})\n    anonResponse = session.get('https://www.linkedin.com/')\n    try:\n        loginCSRF = re.findall('name=\"loginCsrfParam\".*?value=\"(.*?)\"', anonResponse.text)[0]\n    except:\n        print('Having trouble with loading the page... try the command again.')\n        exit()\n    authPayload = {'session_key': username, 'session_password': password, 'loginCsrfParam': loginCSRF}\n    response = session.post('https://www.linkedin.com/uas/login-submit', data=authPayload)\n    if bool(re.search('<title>*?LinkedIn*?</title>', response.text)):\n        print('[+] Successfully logged in.\\n')\n        return session\n    elif '<title>Sign-In Verification</title>' in response.text:\n        print(\"[!] LinkedIn doesn't like something about this login. Maybe you're being sneaky on a VPN or\")\n        print('    something. You may get an email with a verification token. You can ignore that.')\n        print('    Try logging in with the same account in your browser first, then try this tool again.\\n')\n        exit()\n    elif '<title>Sign In</title>' in response.text:\n        print(\"[!] You've been returned to the login page. Check your password and try again.\\n\")\n        exit()\n    elif '<title>Security Verification' in response.text:\n        print(\"[!] You've triggered the security verification. Please verify your login details and try again.\\n\")\n        exit()\n    else:\n        print('[!] Some unknown error logging in. If this persists, please open an issue on github.\\n')\n"]]}
{"hexsha": "f3de7c7c082891154829a5c40c57d69c82b9fdee", "ext": "py", "lang": "Python", "content": "@click.command(\n    epilog=\"See 'slcli dedicatedhost create-options' for valid options.\")\n@click.option('--hostnames', '-H',\n              help=\"Host portion of the FQDN\",\n              required=True,\n              prompt=True)\n@click.option('--router', '-r',\n              help=\"Router hostname ex. fcr02a.dal13\",\n              show_default=True)\n@click.option('--domain', '-D',\n              help=\"Domain portion of the FQDN\",\n              required=True,\n              prompt=True)\n@click.option('--datacenter', '-d', help=\"Datacenter shortname\",\n              required=True,\n              prompt=True)\n@click.option('--flavor', '-f', help=\"Dedicated Virtual Host flavor\",\n              required=True,\n              prompt=True)\n@click.option('--billing',\n              type=click.Choice(['hourly', 'monthly']),\n              default='hourly',\n              show_default=True,\n              help=\"Billing rate\")\n@click.option('--verify',\n              is_flag=True,\n              help=\"Verify dedicatedhost without creating it.\")\n@click.option('--template', '-t',\n              is_eager=True,\n              callback=template.TemplateCallback(list_args=['key']),\n              help=\"A template file that defaults the command-line options\",\n              type=click.Path(exists=True, readable=True, resolve_path=True))\n@click.option('--export',\n              type=click.Path(writable=True, resolve_path=True),\n              help=\"Exports options to a template file\")\n@environment.pass_env\ndef cli(env, **kwargs):\n    \"\"\"Order/create a dedicated host.\"\"\"\n    mgr = SoftLayer.DedicatedHostManager(env.client)\n\n    order = {\n        'hostnames': kwargs['hostnames'].split(','),\n        'domain': kwargs['domain'],\n        'flavor': kwargs['flavor'],\n        'location': kwargs['datacenter'],\n        'hourly': kwargs.get('billing') == 'hourly',\n    }\n\n    if kwargs['router']:\n        order['router'] = kwargs['router']\n\n    do_create = not (kwargs['export'] or kwargs['verify'])\n\n    output = None\n\n    result = mgr.verify_order(**order)\n    table = formatting.Table(['Item', 'cost'])\n    table.align['Item'] = 'r'\n    table.align['cost'] = 'r'\n    if len(result['prices']) != 1:\n        raise exceptions.ArgumentError(\"More than 1 price was found or no \"\n                                       \"prices found\")\n    price = result['prices']\n    if order['hourly']:\n        total = float(price[0].get('hourlyRecurringFee', 0.0))\n    else:\n        total = float(price[0].get('recurringFee', 0.0))\n\n    if order['hourly']:\n        table.add_row(['Total hourly cost', \"%.2f\" % total])\n    else:\n        table.add_row(['Total monthly cost', \"%.2f\" % total])\n\n    output = []\n\n    if kwargs['export']:\n        export_file = kwargs.pop('export')\n        template.export_to_template(export_file, kwargs,\n                                    exclude=['wait', 'verify'])\n        env.fout('Successfully exported options to a template file.')\n\n    if do_create:\n        if not env.skip_confirmations and not formatting.confirm(\n                \"This action will incur charges on your account. \"\n                \"Continue?\"):\n            raise exceptions.CLIAbort('Aborting dedicated host order.')\n\n        result = mgr.place_order(**order)\n\n        hosts = _wait_for_host_ids(result['orderId'], mgr)\n\n        table = formatting.KeyValueTable(['name', 'value'])\n        table.align['name'] = 'r'\n        table.align['value'] = 'l'\n        table.add_row(['id', result['orderId']])\n        table.add_row(['created', result['orderDate']])\n        table.add_row(['hosts', hosts])\n        output.append(table)\n\n    env.fout(output)", "fn_id": 0, "class_fn": false, "repo": "rescale/softlayer-python", "file": "SoftLayer/CLI/dedicatedhost/create.py", "last_update_at": "2019-07-25T04:31:38+00:00", "question_id": "f3de7c7c082891154829a5c40c57d69c82b9fdee_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@click.command(epilog=\"See 'slcli dedicatedhost create-options' for valid options.\")\n@click.option('--hostnames', '-H', help='Host portion of the FQDN', required=True, prompt=True)\n@click.option('--router', '-r', help='Router hostname ex. fcr02a.dal13', show_default=True)\n@click.option('--domain', '-D', help='Domain portion of the FQDN', required=True, prompt=True)\n@click.option('--datacenter', '-d', help='Datacenter shortname', required=True, prompt=True)\n@click.option('--flavor', '-f', help='Dedicated Virtual Host flavor', required=True, prompt=True)\n@click.option('--billing', type=click.Choice(['hourly', 'monthly']), default='hourly', show_default=True, help='Billing rate')\n@click.option('--verify', is_flag=True, help='Verify dedicatedhost without creating it.')\n@click.option('--template', '-t', is_eager=True, callback=template.TemplateCallback(list_args=['key']), help='A template file that defaults the command-line options', type=click.Path(exists=True, readable=True, resolve_path=True))\n@click.option('--export', type=click.Path(writable=True, resolve_path=True), help='Exports options to a template file')\n@environment.pass_env\ndef cli(env, **kwargs):\n    \"\"\"Order/create a dedicated host.\"\"\"\n    mgr = SoftLayer.DedicatedHostManager(env.client)\n    order = {'hostnames': kwargs['hostnames'].split(','), 'domain': kwargs['domain'], 'flavor': kwargs['flavor'], 'location': kwargs['datacenter'], 'hourly': kwargs.get('billing') == 'hourly'}\n    if kwargs['router']:\n        order['router'] = kwargs['router']\n    do_create = not (kwargs['export'] or kwargs['verify'])\n    output = None\n    result = mgr.verify_order(**order)\n    table = formatting.Table(['Item', 'cost'])\n    table.align['Item'] = 'r'\n    table.align['cost'] = 'r'\n    if len(result['prices']) != 1:\n        raise exceptions.ArgumentError('More than 1 price was found or no prices found')\n    price = result['prices']\n    if order['hourly']:\n        total = float(price[0].get('hourlyRecurringFee', 0.0))\n    else:\n        total = float(price[0].get('recurringFee', 0.0))\n    if order['hourly']:\n        table.add_row(['Total hourly cost', '%.2f' % total])\n    else:\n        table.add_row(['Total monthly cost', '%.2f' % total])\n    output = []\n    if kwargs['export']:\n        export_file = kwargs.pop('export')\n        template.export_to_template(export_file, kwargs, exclude=['wait', 'verify'])\n        env.fout('Successfully exported options to a template file.')\n    if do_create:\n        if not env.skip_confirmations and (not formatting.confirm('This action will incur charges on your account. Continue?')):\n            raise exceptions.CLIAbort('Aborting dedicated host order.')\n        result = mgr.place_order(**order)\n        hosts = _wait_for_host_ids(result['orderId'], mgr)\n        table = formatting.KeyValueTable(['name', 'value'])\n        table.align['name'] = 'r'\n        table.align['value'] = 'l'\n        table.add_row(['id', result['orderId']])\n        table.add_row(['created', result['orderDate']])\n        table.add_row(['hosts', hosts])\n        output.append(table)\n"]]}
{"hexsha": "682faf08aee493a8daa4bb569a9cfe1509ad93dc", "ext": "py", "lang": "Python", "content": "@app.route('/', methods=['GET', 'POST'])\ndef index():\n    form = MDForm()\n    if form.validate_on_submit():\n        # \u4f20\u8fdb\u6765\u7684\u6570\u636e\u521d\u59cb\u72b6\u6001\u4e3a\u5b57\u7b26\u4e32\n        inputs = form.packets.data\n        if not inputs:\n            flash('\u4f60\u8fd8\u6ca1\u6709\u8f93\u5165\u6570\u636e')\n            return render_template('index.html', form=form)\n        # feed in string\n        convertor = MDConvertor(inputs.strip())\n        des = form.des.data\n        args = form.args.data\n        ultra = form.ultra.data\n        # ''.split(',') -> ['']\n        bonus_values = args.split(\",\")  # \u5b9e\u9645\u7c7b\u578b\n        title = ultra.split(\",\")  # \u7c7b\u578b\u57df\n        bonus_values = list(filter(None, bonus_values))\n        title = list(filter(None, title))  # \u53bb\u9664\u7a7a\u767d\u5b57\u7b26\n        markdown = convertor.gimmeThat(des, bonus_values, title)\n        return render_template(\"index.html\", form=form, markdown=markdown, set_tab=1)\n\n    return render_template(\"index.html\", form=form)", "fn_id": 0, "class_fn": false, "repo": "YihuiLu/json2markdown", "file": "toMD/views.py", "last_update_at": "2019-08-16T02:18:45+00:00", "question_id": "682faf08aee493a8daa4bb569a9cfe1509ad93dc_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@app.route('/', methods=['GET', 'POST'])\ndef index():\n    form = MDForm()\n    if form.validate_on_submit():\n        inputs = form.packets.data\n        if not inputs:\n            flash('\u4f60\u8fd8\u6ca1\u6709\u8f93\u5165\u6570\u636e')\n            return render_template('index.html', form=form)\n        convertor = MDConvertor(inputs.strip())\n        des = form.des.data\n        args = form.args.data\n        ultra = form.ultra.data\n        bonus_values = args.split(',')\n        title = ultra.split(',')\n        bonus_values = list(filter(None, bonus_values))\n        title = list(filter(None, title))\n        markdown = convertor.gimmeThat(des, bonus_values, title)\n        return render_template('index.html', form=form, markdown=markdown, set_tab=1)\n"]]}
{"hexsha": "e1ccabb5cf6098b3a2a0c1620ba64369ee04087b", "ext": "py", "lang": "Python", "content": "def filelist(path):\n    r = []\n    n = os.listdir(path)\n    for f in n:\n        if not os.path.isdir(f):\n            r.append(f)\n    return r", "fn_id": 1, "class_fn": false, "repo": "phlk/Netch", "file": "scripts/GENERATE.py", "last_update_at": "2019-07-01T14:29:06+00:00", "question_id": "e1ccabb5cf6098b3a2a0c1620ba64369ee04087b_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def filelist(path):\n    r = []\n    n = os.listdir(path)\n    for f in n:\n        if not os.path.isdir(f):\n            r.append(f)\n"]]}
{"hexsha": "ac78bf62ab378563a0db408197919b7b483bf4fb", "ext": "py", "lang": "Python", "content": "def repeated(n, f, x):\n    if n == 0:\n        return x\n    else:\n        return App(f, repeated(n-1, f, x))", "fn_id": 4, "class_fn": false, "repo": "triffon/lcpt-2017-18", "file": "nbe.py", "last_update_at": "2019-06-15T15:38:15+00:00", "question_id": "ac78bf62ab378563a0db408197919b7b483bf4fb_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def repeated(n, f, x):\n    if n == 0:\n        return x\n    else:\n"]]}
{"hexsha": "132e8b8b3fa5163f9210a6d1adca8aa2555545a6", "ext": "py", "lang": "Python", "content": "def test_bind2():\n    s = tir.Schedule(element_wise_compute_at_split, debug_mask=\"all\")\n    _, j0 = s.get_loops(s.get_block(\"B\"))\n    _, j1o, _ = s.get_loops(s.get_block(\"C\"))\n    s.bind(j0, \"threadIdx.x\")\n    s.bind(j1o, \"threadIdx.x\")\n    tvm.ir.assert_structural_equal(s.mod[\"main\"], element_wise_compute_at_split_j0_j1o_bound)\n    verify_trace_roundtrip(s, mod=element_wise_compute_at_split)", "fn_id": 38, "class_fn": false, "repo": "shengxinhu/tvm", "file": "tests/python/unittest/test_tir_schedule_for_kind.py", "last_update_at": "2019-11-04T15:29:46+00:00", "question_id": "132e8b8b3fa5163f9210a6d1adca8aa2555545a6_38", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_bind2():\n    s = tir.Schedule(element_wise_compute_at_split, debug_mask='all')\n    _, j0 = s.get_loops(s.get_block('B'))\n    _, j1o, _ = s.get_loops(s.get_block('C'))\n    s.bind(j0, 'threadIdx.x')\n    s.bind(j1o, 'threadIdx.x')\n    tvm.ir.assert_structural_equal(s.mod['main'], element_wise_compute_at_split_j0_j1o_bound)\n"]]}
{"hexsha": "babffeae0626d2dcf86f8338a29d4af7614544b4", "ext": "py", "lang": "Python", "content": "def get_file_content(filename):\n    assert os.path.exists(filename), filename+' not exists'\n    _, extension = os.path.splitext(filename)\n    if extension == '':\n        with open(filename) as fd:\n            output = fd.read()\n        return output\n    else:\n        linux_darwin_config_table = {\n            '.Z': {\n                'command': 'uncompress',\n                'args': ['-c',],\n            },\n            '.xz': {\n                'command': 'xz',\n                'args': ['-c', '-d'],\n            },\n            '.gz': {\n                'command': 'gzip',\n                'args': ['-c', '-d'],\n            },\n        }\n        buff = StringIO()\n        if platform.system() in ['Darwin', 'Linux']:\n            config_table = linux_darwin_config_table\n            assert extension in config_table, extension+' has not config'\n            config_table = config_table[extension]\n            command = config_table['command']\n            args    = config_table['args']\n            args.append(filename)\n            args = tuple(args)\n            sh.Command(command).__call__(*args, _out=buff)\n        elif platform.system() in ['Windows']:\n            raise NotImplementedError('.Z not support windows for now')\n        else:\n            raise NotImplementedError('Unknown system')\n        return buff.getvalue()", "fn_id": 0, "class_fn": false, "repo": "changsuc/vasptools", "file": "vasptools/utils.py", "last_update_at": "2019-03-28T07:38:56+00:00", "question_id": "babffeae0626d2dcf86f8338a29d4af7614544b4_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_file_content(filename):\n    assert os.path.exists(filename), filename + ' not exists'\n    _, extension = os.path.splitext(filename)\n    if extension == '':\n        with open(filename) as fd:\n            output = fd.read()\n        return output\n    else:\n        linux_darwin_config_table = {'.Z': {'command': 'uncompress', 'args': ['-c']}, '.xz': {'command': 'xz', 'args': ['-c', '-d']}, '.gz': {'command': 'gzip', 'args': ['-c', '-d']}}\n        buff = StringIO()\n        if platform.system() in ['Darwin', 'Linux']:\n            config_table = linux_darwin_config_table\n            assert extension in config_table, extension + ' has not config'\n            config_table = config_table[extension]\n            command = config_table['command']\n            args = config_table['args']\n            args.append(filename)\n            args = tuple(args)\n            sh.Command(command).__call__(*args, _out=buff)\n        elif platform.system() in ['Windows']:\n            raise NotImplementedError('.Z not support windows for now')\n        else:\n            raise NotImplementedError('Unknown system')\n"]]}
{"hexsha": "4c564e7cef6fda6a38a7d4069341781afb25f3ca", "ext": "py", "lang": "Python", "content": "def json2paramater(x, is_rand, random_state, oldy=None, Rand=False, name=NodeType.Root.value):\n    '''\n    Json to pramaters.\n    '''\n    if isinstance(x, dict):\n        if NodeType.Type.value in x.keys():\n            _type = x[NodeType.Type.value]\n            _value = x[NodeType.Value.value]\n            name = name + '-' + _type\n            Rand |= is_rand[name]\n            if Rand is True:\n                if _type == 'choice':\n                    _index = random_state.randint(len(_value))\n                    y = {\n                        NodeType.Index.value: _index,\n                        NodeType.Value.value: json2paramater(x[NodeType.Value.value][_index],\n                                                             is_rand,\n                                                             random_state,\n                                                             None,\n                                                             Rand,\n                                                             name=name+\"[%d]\" % _index)\n                    }\n                else:\n                    y = eval('parameter_expressions.' +\n                             _type)(*(_value + [random_state]))\n            else:\n                y = copy.deepcopy(oldy)\n        else:\n            y = dict()\n            for key in x.keys():\n                y[key] = json2paramater(x[key], is_rand, random_state, oldy[key]\n                                        if oldy != None else None, Rand, name + \"[%s]\" % str(key))\n    elif isinstance(x, list):\n        y = list()\n        for i, x_i in enumerate(x):\n            y.append(json2paramater(x_i, is_rand, random_state, oldy[i]\n                                    if oldy != None else None, Rand, name + \"[%d]\" % i))\n    else:\n        y = copy.deepcopy(x)\n    return y", "fn_id": 1, "class_fn": false, "repo": "kant/nni", "file": "src/sdk/pynni/nni/evolution_tuner/evolution_tuner.py", "last_update_at": "2019-06-27T16:31:20+00:00", "question_id": "4c564e7cef6fda6a38a7d4069341781afb25f3ca_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def json2paramater(x, is_rand, random_state, oldy=None, Rand=False, name=NodeType.Root.value):\n    \"\"\"\n    Json to pramaters.\n    \"\"\"\n    if isinstance(x, dict):\n        if NodeType.Type.value in x.keys():\n            _type = x[NodeType.Type.value]\n            _value = x[NodeType.Value.value]\n            name = name + '-' + _type\n            Rand |= is_rand[name]\n            if Rand is True:\n                if _type == 'choice':\n                    _index = random_state.randint(len(_value))\n                    y = {NodeType.Index.value: _index, NodeType.Value.value: json2paramater(x[NodeType.Value.value][_index], is_rand, random_state, None, Rand, name=name + '[%d]' % _index)}\n                else:\n                    y = eval('parameter_expressions.' + _type)(*_value + [random_state])\n            else:\n                y = copy.deepcopy(oldy)\n        else:\n            y = dict()\n            for key in x.keys():\n                y[key] = json2paramater(x[key], is_rand, random_state, oldy[key] if oldy != None else None, Rand, name + '[%s]' % str(key))\n    elif isinstance(x, list):\n        y = list()\n        for i, x_i in enumerate(x):\n            y.append(json2paramater(x_i, is_rand, random_state, oldy[i] if oldy != None else None, Rand, name + '[%d]' % i))\n    else:\n        y = copy.deepcopy(x)\n"]]}
{"hexsha": "ceb56a689e01c2806f579c136ab625f8a9b2546a", "ext": "py", "lang": "Python", "content": "def execute_callback(name, *args):\n    \"\"\" Execute provided callback \"\"\"\n\n    callbacks = settings.IPAYMU_CALLBACKS\n    callback_string = callbacks.get(name)\n\n    if callback_string and isinstance(callback_string, basestring):\n        # Fail silently when callback error\n        # Just notify via log console.\n\n        # Split callback namespace to module and its function\n        ns = callback_string.split('.')\n        callback_func = ns[-1]\n        callback_module_str = '.'.join(ns[:-1])\n\n        try:\n            callback_module = import_module(callback_module_str)\n            getattr(callback_module, callback_func)(*args)\n        except ImportError as e:\n            raise IpaymuCallbackError('Could not import Ipaymu callback module \\'%s\\'' % (callback_module_str))\n        except AttributeError as e:\n            raise IpaymuCallbackError('\\'%s\\' has no attribute \\'%s\\'' % (callback_module_str, callback_func))\n    return", "fn_id": 0, "class_fn": false, "repo": "ekaputra07/django-ipaymu", "file": "ipaymu/utils.py", "last_update_at": "2019-03-22T08:18:43+00:00", "question_id": "ceb56a689e01c2806f579c136ab625f8a9b2546a_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def execute_callback(name, *args):\n    \"\"\" Execute provided callback \"\"\"\n    callbacks = settings.IPAYMU_CALLBACKS\n    callback_string = callbacks.get(name)\n    if callback_string and isinstance(callback_string, basestring):\n        ns = callback_string.split('.')\n        callback_func = ns[-1]\n        callback_module_str = '.'.join(ns[:-1])\n        try:\n            callback_module = import_module(callback_module_str)\n            getattr(callback_module, callback_func)(*args)\n        except ImportError as e:\n            raise IpaymuCallbackError(\"Could not import Ipaymu callback module '%s'\" % callback_module_str)\n        except AttributeError as e:\n            raise IpaymuCallbackError(\"'%s' has no attribute '%s'\" % (callback_module_str, callback_func))\n"]]}
{"hexsha": "bf82db3de227ccc8eb0094315264afca9dd76fca", "ext": "py", "lang": "Python", "content": "def login():\n    # Load a previous session if one exists, otherwise make a new session\n    try:\n        with open(session_cache_path, 'rb') as f:\n            s = pickle.load(f)\n    except (IOError, EOFError):\n        s = requests.Session()\n        s.mount('https://', TLSAdapter())\n\n    # Make a simple request to see if a login is required\n    r = s.get(BASE_URL)\n\n    if \"auth_redirect\" in r.url:\n        # SSO redirection - login\n        parsed_url = urlparse(r.url)\n        params = parse_qs(parsed_url.query)\n        sysparm_url = params['sysparm_url'][0]\n\n        r = s.get(sysparm_url)\n        print(\"Navigated to \" + r.url)\n        if r.url == \"https://iam.auckland.ac.nz/profile/SAML2/Redirect/SSO?execution=e1s1\":\n            r = s.post(r.url, { \"j_username\": config.username, \"j_password\": config.password, \"submitted\": 0, \"_eventId_proceed\": \"\" })\n            print(\"Entered username and password\")\n            if INCORRECT_CREDENTIAL_STRING in r.text:\n                print(INCORRECT_CREDENTIAL_STRING + \". Check config.py\")\n                exit(1)\n            while \"j_token\" in r.text:\n                two_factor = input(\"Please enter your 2FA token: \")\n                r = s.post(r.url, { \"submitted\": \"\", \"j_token\": two_factor, \"rememberMe\": \"on\", \"_eventId_proceed\": \"\" })\n                if INCORRECT_2FA_STRING in r.text:\n                    print(\"Incorrect 2FA token, try again: \")\n            soup = BeautifulSoup(r.content, 'html.parser')\n            # login success, submit form\n            form = {}\n            form_inputs = soup.find_all(\"input\", attrs = {'name' : True})\n            for input_elem in form_inputs:\n                form[input_elem['name']] = input_elem['value']\n            r = s.post(form['RelayState'], form)\n            print(\"Navigated to \" + r.url)\n            csrf_token = re.search(r\"var g_ck = '(\\w+)';\", r.text).group(1)\n            s.headers['X-UserToken'] = csrf_token\n            with open(session_cache_path, 'wb') as f:\n                pickle.dump(s, f)\n\n    return s", "fn_id": 0, "class_fn": false, "repo": "UoA-eResearch/snow", "file": "util/login.py", "last_update_at": "2019-11-20T18:55:31+00:00", "question_id": "bf82db3de227ccc8eb0094315264afca9dd76fca_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def login():\n    try:\n        with open(session_cache_path, 'rb') as f:\n            s = pickle.load(f)\n    except (IOError, EOFError):\n        s = requests.Session()\n        s.mount('https://', TLSAdapter())\n    r = s.get(BASE_URL)\n    if 'auth_redirect' in r.url:\n        parsed_url = urlparse(r.url)\n        params = parse_qs(parsed_url.query)\n        sysparm_url = params['sysparm_url'][0]\n        r = s.get(sysparm_url)\n        print('Navigated to ' + r.url)\n        if r.url == 'https://iam.auckland.ac.nz/profile/SAML2/Redirect/SSO?execution=e1s1':\n            r = s.post(r.url, {'j_username': config.username, 'j_password': config.password, 'submitted': 0, '_eventId_proceed': ''})\n            print('Entered username and password')\n            if INCORRECT_CREDENTIAL_STRING in r.text:\n                print(INCORRECT_CREDENTIAL_STRING + '. Check config.py')\n                exit(1)\n            while 'j_token' in r.text:\n                two_factor = input('Please enter your 2FA token: ')\n                r = s.post(r.url, {'submitted': '', 'j_token': two_factor, 'rememberMe': 'on', '_eventId_proceed': ''})\n                if INCORRECT_2FA_STRING in r.text:\n                    print('Incorrect 2FA token, try again: ')\n            soup = BeautifulSoup(r.content, 'html.parser')\n            form = {}\n            form_inputs = soup.find_all('input', attrs={'name': True})\n            for input_elem in form_inputs:\n                form[input_elem['name']] = input_elem['value']\n            r = s.post(form['RelayState'], form)\n            print('Navigated to ' + r.url)\n            csrf_token = re.search(\"var g_ck = '(\\\\w+)';\", r.text).group(1)\n            s.headers['X-UserToken'] = csrf_token\n            with open(session_cache_path, 'wb') as f:\n                pickle.dump(s, f)\n"]]}
{"hexsha": "5d8822c368be141023cdb99c2879432fb6294ab1", "ext": "py", "lang": "Python", "content": "def convnet(repr_dim, inputs, num_layers, conv_width=3, activation=tf.nn.relu, **kwargs):\n    # dim reduction\n    output = inputs\n    for i in range(num_layers):\n        output = _convolutional_block(output, repr_dim, conv_width=conv_width, name=\"conv_%d\" % i)\n    return output", "fn_id": 3, "class_fn": false, "repo": "takuma-ynd/jack", "file": "jack/util/tf/sequence_encoder.py", "last_update_at": "2019-12-02T02:23:17+00:00", "question_id": "5d8822c368be141023cdb99c2879432fb6294ab1_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def convnet(repr_dim, inputs, num_layers, conv_width=3, activation=tf.nn.relu, **kwargs):\n    output = inputs\n    for i in range(num_layers):\n        output = _convolutional_block(output, repr_dim, conv_width=conv_width, name='conv_%d' % i)\n"]]}
{"hexsha": "f2a92934d973e2f01682833efb1f2012845ab910", "ext": "py", "lang": "Python", "content": "def test_place_properties():\n    amount = 5\n    for value in {4, 5, 6, 8, 9, 10}:\n        bet = CBPlace(value, amount)\n        assert bet.value == value\n        assert bet.is_working\n        assert bet.amount == amount\n        if bet.value in {4, 10}:\n            assert bet.win_amount() == amount * 9 / 5\n        elif bet.value in {5, 9}:\n            assert bet.win_amount() == amount * 7 / 5\n        else:\n            assert bet.win_amount() == amount * 7 / 6\n        bet.set_working(False)\n        assert not bet.is_working", "fn_id": 24, "class_fn": false, "repo": "pastly/craps-dice-control", "file": "tests/unit/lib/test_strategy.py", "last_update_at": "2019-05-09T02:11:17+00:00", "question_id": "f2a92934d973e2f01682833efb1f2012845ab910_24", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_place_properties():\n    amount = 5\n    for value in {4, 5, 6, 8, 9, 10}:\n        bet = CBPlace(value, amount)\n        assert bet.value == value\n        assert bet.is_working\n        assert bet.amount == amount\n        if bet.value in {4, 10}:\n            assert bet.win_amount() == amount * 9 / 5\n        elif bet.value in {5, 9}:\n            assert bet.win_amount() == amount * 7 / 5\n        else:\n            assert bet.win_amount() == amount * 7 / 6\n        bet.set_working(False)\n"]]}
{"hexsha": "432a038a49fa76a638f2d1480ac7d18f1f3dd622", "ext": "py", "lang": "Python", "content": "def init_parameters(config):\n    version = int(config.version)\n    global feature_size, embedding_size, deep_layers, deep_layers_activation, batch_size\n    global learning_rate, optimizer_type, batch_norm_Flag, batch_norm_decay, verbose\n    global random_seed, l2_reg, epoch_number\n\n    # if version == 1:\n    #     batch_norm_Flag = False\n    # elif version == 2:\n    #     batch_norm_Flag = True\n\n    if str(config.mode) == \"test\":\n        batch_size = 200\n\n    printParameter()", "fn_id": 10, "class_fn": false, "repo": "songjun54cm/ExampleBank", "file": "tensorflow_example/DeepFM/src/Model5.py", "last_update_at": "2019-01-18T07:51:39+00:00", "question_id": "432a038a49fa76a638f2d1480ac7d18f1f3dd622_10", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def init_parameters(config):\n    version = int(config.version)\n    global feature_size, embedding_size, deep_layers, deep_layers_activation, batch_size\n    global learning_rate, optimizer_type, batch_norm_Flag, batch_norm_decay, verbose\n    global random_seed, l2_reg, epoch_number\n    if str(config.mode) == 'test':\n        batch_size = 200\n"]]}
{"hexsha": "b21e2a9cf0676b4d382d841a6736d7dc02963669", "ext": "py", "lang": "Python", "content": "@pytest.fixture\ndef w3(base_tester):\n    web3 = Web3(EthereumTesterProvider(base_tester))\n    web3.eth.setGasPriceStrategy(zero_gas_price_strategy)\n    return web3", "fn_id": 5, "class_fn": false, "repo": "djrtwo/casper", "file": "tests/conftest.py", "last_update_at": "2019-09-02T07:45:38+00:00", "question_id": "b21e2a9cf0676b4d382d841a6736d7dc02963669_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.fixture\ndef w3(base_tester):\n    web3 = Web3(EthereumTesterProvider(base_tester))\n    web3.eth.setGasPriceStrategy(zero_gas_price_strategy)\n"]]}
{"hexsha": "6c01ec447021c6f4e78ec4a05f0cef94c058a5fb", "ext": "py", "lang": "Python", "content": "async def link(task1, task2, propagate=False, logger=None):\n    \"\"\"\n    Create a unidirectional link between two tasks,\n    such that an exception raised in task2 \n    result in cancellation of task1.\n    \"\"\"\n    logger = logger or logging.getLogger(__name__)\n    try:\n        await task2\n    except:\n        logger.info(\"link triggered on task {} following exception from task {}\".format(task1, task2))\n        task1.cancel()\n        if propagate:\n            raise", "fn_id": 1, "class_fn": false, "repo": "DrPyser/concurrency-utils", "file": "concurrency/task_manager.py", "last_update_at": "2019-12-13T06:17:19+00:00", "question_id": "6c01ec447021c6f4e78ec4a05f0cef94c058a5fb_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["async def link(task1, task2, propagate=False, logger=None):\n    \"\"\"\n    Create a unidirectional link between two tasks,\n    such that an exception raised in task2 \n    result in cancellation of task1.\n    \"\"\"\n    logger = logger or logging.getLogger(__name__)\n    try:\n        await task2\n    except:\n        logger.info('link triggered on task {} following exception from task {}'.format(task1, task2))\n        task1.cancel()\n        if propagate:\n"]]}
{"hexsha": "6b1566af0a9718133065c11ba289daa58900898d", "ext": "py", "lang": "Python", "content": "def test_reg_user_cannot_get_another_org_id_quota(reg_user_headers):\n    \"\"\" regular users cannot see an organization's cve id quota they don't belong to \"\"\"\n    org = str(uuid.uuid4())\n    user = str(uuid.uuid4())\n    create_new_user_with_new_org_by_shortname(org, user)\n    res = requests.get(\n        f'{env.AWG_BASE_URL}{ORG_URL}/{org}/id_quota',\n        headers=reg_user_headers\n    )\n    assert res.status_code == 403\n    response_contains_json(res, 'error', 'NOT_SAME_ORG_OR_SECRETARIAT')", "fn_id": 21, "class_fn": false, "repo": "CVEProject/CVE-Services", "file": "test-http/src/test/org_user_tests/regular_users.py", "last_update_at": "2019-08-22T15:55:07+00:00", "question_id": "6b1566af0a9718133065c11ba289daa58900898d_21", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_reg_user_cannot_get_another_org_id_quota(reg_user_headers):\n    \"\"\" regular users cannot see an organization's cve id quota they don't belong to \"\"\"\n    org = str(uuid.uuid4())\n    user = str(uuid.uuid4())\n    create_new_user_with_new_org_by_shortname(org, user)\n    res = requests.get(f'{env.AWG_BASE_URL}{ORG_URL}/{org}/id_quota', headers=reg_user_headers)\n    assert res.status_code == 403\n"]]}
{"hexsha": "6229d1560e40771a89efe3b988f92cb260998cb2", "ext": "py", "lang": "Python", "content": "def get_template(template_name):\n    \"\"\" Function to get the psrfits template from the templates module dir\n\n       Parameter\n       ---------\n       template_name: str\n           The name of the built-in template.\n       Return\n       ------\n           Full path to the template file. If the request file does not exists,\n           it will return None. \n    \"\"\"\n    template_path = os.path.join(__module_dir__, template_name)\n    if os.path.exists(template_path):\n        return template_path\n    else:\n        return None", "fn_id": 0, "class_fn": false, "repo": "Christine8888/PulsarDataToolbox", "file": "pdat/templates/template.py", "last_update_at": "2019-02-07T20:05:15+00:00", "question_id": "6229d1560e40771a89efe3b988f92cb260998cb2_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_template(template_name):\n    \"\"\" Function to get the psrfits template from the templates module dir\n\n       Parameter\n       ---------\n       template_name: str\n           The name of the built-in template.\n       Return\n       ------\n           Full path to the template file. If the request file does not exists,\n           it will return None. \n    \"\"\"\n    template_path = os.path.join(__module_dir__, template_name)\n    if os.path.exists(template_path):\n        return template_path\n    else:\n"]]}
{"hexsha": "dcfdfb7190b8531c9a888be1c5fb2e556ea714f0", "ext": "py", "lang": "Python", "content": "def ip_CallBack(ip_entry,page):\n    global ip\n    ip = ip_entry.get()\n    page.withdraw()\n    myStr = \"\"\n    for x in range(len(directory_List)):\n        myStr = myStr + \"From: \" + directory_List[x][0] + \" To: \" + directory_List[x][1] + \"\\n\"\n        init_Client(x)\n        print(\"Done: \", myStr)\n\n    messagebox.showinfo(message=\"Sync Complete: \\n\" + myStr)", "fn_id": 16, "class_fn": false, "repo": "cenkerkaraors/CS447-Project", "file": "PeerGui/peerGui.py", "last_update_at": "2019-12-16T14:57:27+00:00", "question_id": "dcfdfb7190b8531c9a888be1c5fb2e556ea714f0_16", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def ip_CallBack(ip_entry, page):\n    global ip\n    ip = ip_entry.get()\n    page.withdraw()\n    myStr = ''\n    for x in range(len(directory_List)):\n        myStr = myStr + 'From: ' + directory_List[x][0] + ' To: ' + directory_List[x][1] + '\\n'\n        init_Client(x)\n        print('Done: ', myStr)\n"]]}
{"hexsha": "1ace6e50fe9a696ec49d4b81bdfd2e95eea3942f", "ext": "py", "lang": "Python", "content": "def spew(t):\n    \"\"\"Prints a string based on DEBUG_OUTPUT bool\n\n    Parameters\n    ----------\n    t : str\n        * string to debug print\n    \"\"\"\n    if DEBUG_OUTPUT:\n        print(\"DEBUG::{}\".format(t))", "fn_id": 8, "class_fn": false, "repo": "c1rdan/pytan", "file": "lib/pytan/utils.py", "last_update_at": "2019-01-29T21:22:06+00:00", "question_id": "1ace6e50fe9a696ec49d4b81bdfd2e95eea3942f_8", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def spew(t):\n    \"\"\"Prints a string based on DEBUG_OUTPUT bool\n\n    Parameters\n    ----------\n    t : str\n        * string to debug print\n    \"\"\"\n    if DEBUG_OUTPUT:\n"]]}
{"hexsha": "2754a06c0a41969a9c50cd0caa65f9b1ecfdfdb3", "ext": "py", "lang": "Python", "content": "def test_whitening_tensor_e2_m1():\n    rng = np.random.RandomState(12)\n\n    n_features = 300\n    n_components = 25\n    min_count = 3\n    alpha0 = 10.\n    n_samples = rng.randint(100, 150)\n    doc_word_mtx = rng.randint(0, 3, size=(n_samples, n_features)).astype('float')\n    doc_word_mtx = sp.csr_matrix(doc_word_mtx)\n\n    m1, _ = first_order_moments(doc_word_mtx, min_words=min_count)\n    e2, _ = cooccurrence_expectation(doc_word_mtx, min_words=min_count)\n\n    # create M2 directly\n    m2 = (alpha0 + 1.) * e2.toarray()\n    m2 -= (alpha0 * m1) * m1[:, np.newaxis]\n    m2_vals, m2_vecs = sp.linalg.eigsh(m2, k=n_components)\n    # create whitening matrix\n    W = whitening(m2_vals, m2_vecs)\n\n    # optimized method\n    wt_m1 = np.dot(W.T, m1)\n    u1_2_3 = whitening_tensor_e2_m1(wt_m1, alpha0)\n\n    # compute directly\n    u1_2_3_true = _compute_e2_m1_directly(doc_word_mtx, W, wt_m1)\n    assert_array_almost_equal(u1_2_3_true, u1_2_3)", "fn_id": 11, "class_fn": false, "repo": "chyikwei/tensorLDA", "file": "tensor_lda/tests/test_moments.py", "last_update_at": "2019-03-12T02:18:15+00:00", "question_id": "2754a06c0a41969a9c50cd0caa65f9b1ecfdfdb3_11", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_whitening_tensor_e2_m1():\n    rng = np.random.RandomState(12)\n    n_features = 300\n    n_components = 25\n    min_count = 3\n    alpha0 = 10.0\n    n_samples = rng.randint(100, 150)\n    doc_word_mtx = rng.randint(0, 3, size=(n_samples, n_features)).astype('float')\n    doc_word_mtx = sp.csr_matrix(doc_word_mtx)\n    m1, _ = first_order_moments(doc_word_mtx, min_words=min_count)\n    e2, _ = cooccurrence_expectation(doc_word_mtx, min_words=min_count)\n    m2 = (alpha0 + 1.0) * e2.toarray()\n    m2 -= alpha0 * m1 * m1[:, np.newaxis]\n    m2_vals, m2_vecs = sp.linalg.eigsh(m2, k=n_components)\n    W = whitening(m2_vals, m2_vecs)\n    wt_m1 = np.dot(W.T, m1)\n    u1_2_3 = whitening_tensor_e2_m1(wt_m1, alpha0)\n    u1_2_3_true = _compute_e2_m1_directly(doc_word_mtx, W, wt_m1)\n"]]}
{"hexsha": "bfe3a04e069c7f4d3004ff9df76068a84d732c36", "ext": "py", "lang": "Python", "content": "def update_localhost_alias(hostname):\n    def not_local(alias):\n        return alias.partition(\".\")[0] not in (\"localhost\", \"localhost4\", \"localhost6\", \"centralnode\")\n\n    localhost_ips = list(__get_ips_for('localhost'))\n    data = __list_aliases()\n    for ip, aliases in data.items():\n        if ip not in localhost_ips:\n            continue\n        map(data[ip].remove, filter(not_local, aliases))\n        if hostname not in data[ip]:\n            data[ip].append(hostname)\n\n    __write_aliases(data)", "fn_id": 4, "class_fn": false, "repo": "bootforce-dev/ram-framework", "file": "lib/ram/net/aliases.py", "last_update_at": "2019-03-01T10:19:34+00:00", "question_id": "bfe3a04e069c7f4d3004ff9df76068a84d732c36_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def update_localhost_alias(hostname):\n\n    def not_local(alias):\n        return alias.partition('.')[0] not in ('localhost', 'localhost4', 'localhost6', 'centralnode')\n    localhost_ips = list(__get_ips_for('localhost'))\n    data = __list_aliases()\n    for ip, aliases in data.items():\n        if ip not in localhost_ips:\n            continue\n        map(data[ip].remove, filter(not_local, aliases))\n        if hostname not in data[ip]:\n            data[ip].append(hostname)\n"]]}
{"hexsha": "8e532b5f7c6cadae6cb69d97a5ebd9605c1f72df", "ext": "py", "lang": "Python", "content": "def _setup(filename):\n    if not os.path.exists(filename):\n        msg = \"Unable to find {}. Exiting.\".format(filename)\n        raise NotFoundError(msg)\n\n    working_dirs = [config._get_lock_dir(), config._get_clone_dir()]\n    for working_dir in working_dirs:\n        if not os.path.exists(working_dir):\n            os.makedirs(working_dir)", "fn_id": 2, "class_fn": false, "repo": "philipsd6/gilt", "file": "gilt/shell.py", "last_update_at": "2019-12-18T13:28:58+00:00", "question_id": "8e532b5f7c6cadae6cb69d97a5ebd9605c1f72df_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _setup(filename):\n    if not os.path.exists(filename):\n        msg = 'Unable to find {}. Exiting.'.format(filename)\n        raise NotFoundError(msg)\n    working_dirs = [config._get_lock_dir(), config._get_clone_dir()]\n    for working_dir in working_dirs:\n        if not os.path.exists(working_dir):\n"]]}
{"hexsha": "0dc90991e67373ed00dca475d0349134442fb042", "ext": "py", "lang": "Python", "content": "def set_volume(level):\n\tcommand=command_base()\n\tcommand[3]=0x06\n\tcommand[6]=level\n\treturn command", "fn_id": 6, "class_fn": false, "repo": "omarbenhamid/fajrclock", "file": "src/yx5300.py", "last_update_at": "2019-10-23T15:49:24+00:00", "question_id": "0dc90991e67373ed00dca475d0349134442fb042_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def set_volume(level):\n    command = command_base()\n    command[3] = 6\n    command[6] = level\n"]]}
{"hexsha": "a2c535b27a5ceabf9aa8b2875dae0c423b1a2c13", "ext": "py", "lang": "Python", "content": "def deploy():\n    regex = re.compile('^\\w+$')\n    apps = sorted(file for file in os.listdir(apath(r=request)) if regex.match(file))\n    form = SQLFORM.factory(\n        Field('appcfg',default=GAE_APPCFG,label='Path to appcfg.py',\n              requires=EXISTS(error_message=T('file not found'))),\n        Field('google_application_id',requires=IS_ALPHANUMERIC()),\n        Field('applications','list:string',\n              requires=IS_IN_SET(apps,multiple=True),\n              label=T('web2py apps to deploy')),\n        Field('email',requires=IS_EMAIL(),label=T('GAE Email')),\n        Field('password','password',requires=IS_NOT_EMPTY(),label=T('GAE Password')))\n    cmd = output = errors= \"\"\n    if form.accepts(request,session):\n        try:\n            kill()\n        except:\n            pass\n        ignore_apps = [item for item in apps \\\n                           if not item in form.vars.applications]\n        regex = re.compile('\\(applications/\\(.*')\n        yaml = apath('../app.yaml', r=request)\n        if not os.path.exists(yaml):\n            example = apath('../app.example.yaml', r=request)\n            shutil.copyfile(example,yaml)\n        data = read_file(yaml)\n        data = re.sub('application:.*','application: %s' % form.vars.google_application_id,data)\n        data = regex.sub('(applications/(%s)/.*)|' % '|'.join(ignore_apps),data)\n        write_file(yaml, data)\n\n        path = request.env.applications_parent\n        cmd = '%s --email=%s --passin update %s' % \\\n            (form.vars.appcfg, form.vars.email, path)\n        p = cache.ram('gae_upload',\n                      lambda s=subprocess,c=cmd:s.Popen(c, shell=True,\n                                                        stdin=s.PIPE,\n                                                        stdout=s.PIPE,\n                                                        stderr=s.PIPE, close_fds=True),-1)\n        p.stdin.write(form.vars.password+'\\n')\n        fcntl.fcntl(p.stdout.fileno(), fcntl.F_SETFL, os.O_NONBLOCK)\n        fcntl.fcntl(p.stderr.fileno(), fcntl.F_SETFL, os.O_NONBLOCK)\n    return dict(form=form,command=cmd)", "fn_id": 1, "class_fn": false, "repo": "spiffytech/MobileBlur", "file": "applications/admin/controllers/gae.py", "last_update_at": "2019-05-16T17:25:57+00:00", "question_id": "a2c535b27a5ceabf9aa8b2875dae0c423b1a2c13_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def deploy():\n    regex = re.compile('^\\\\w+$')\n    apps = sorted((file for file in os.listdir(apath(r=request)) if regex.match(file)))\n    form = SQLFORM.factory(Field('appcfg', default=GAE_APPCFG, label='Path to appcfg.py', requires=EXISTS(error_message=T('file not found'))), Field('google_application_id', requires=IS_ALPHANUMERIC()), Field('applications', 'list:string', requires=IS_IN_SET(apps, multiple=True), label=T('web2py apps to deploy')), Field('email', requires=IS_EMAIL(), label=T('GAE Email')), Field('password', 'password', requires=IS_NOT_EMPTY(), label=T('GAE Password')))\n    cmd = output = errors = ''\n    if form.accepts(request, session):\n        try:\n            kill()\n        except:\n            pass\n        ignore_apps = [item for item in apps if not item in form.vars.applications]\n        regex = re.compile('\\\\(applications/\\\\(.*')\n        yaml = apath('../app.yaml', r=request)\n        if not os.path.exists(yaml):\n            example = apath('../app.example.yaml', r=request)\n            shutil.copyfile(example, yaml)\n        data = read_file(yaml)\n        data = re.sub('application:.*', 'application: %s' % form.vars.google_application_id, data)\n        data = regex.sub('(applications/(%s)/.*)|' % '|'.join(ignore_apps), data)\n        write_file(yaml, data)\n        path = request.env.applications_parent\n        cmd = '%s --email=%s --passin update %s' % (form.vars.appcfg, form.vars.email, path)\n        p = cache.ram('gae_upload', lambda s=subprocess, c=cmd: s.Popen(c, shell=True, stdin=s.PIPE, stdout=s.PIPE, stderr=s.PIPE, close_fds=True), -1)\n        p.stdin.write(form.vars.password + '\\n')\n        fcntl.fcntl(p.stdout.fileno(), fcntl.F_SETFL, os.O_NONBLOCK)\n        fcntl.fcntl(p.stderr.fileno(), fcntl.F_SETFL, os.O_NONBLOCK)\n"]]}
{"hexsha": "b939c92a48869b8074e19ed7baecfbab1de0f936", "ext": "py", "lang": "Python", "content": "def public_enc_rsa(public_key: str, data: str) -> str:\n    \"\"\"\n     RSA \uc554\ud638\ud654\n\n    :param public_key: CODEF \ud68c\uc6d0\uc5d0\uac8c \uc81c\uacf5\ub418\ub294 PublicKey\n    :param data: \uc554\ud638\ud654\ud560 \ub370\uc774\ud130\n    :return: RSA256 \uc554\ud638\ud654\ub41c \ub370\uc774\ud130\n    \"\"\"\n    key_der = base64.b64decode(public_key)\n    key_pub = RSA.import_key(key_der)\n    cipher = PKCS1.new(key_pub)\n    cipher_text = cipher.encrypt(data.encode())\n\n    encrypted_data = base64.b64encode(cipher_text).decode('utf-8')\n\n    return encrypted_data", "fn_id": 2, "class_fn": false, "repo": "fiveio/easy-codef-py", "file": "easycodef/helper.py", "last_update_at": "2019-09-17T00:47:08+00:00", "question_id": "b939c92a48869b8074e19ed7baecfbab1de0f936_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def public_enc_rsa(public_key: str, data: str) -> str:\n    \"\"\"\n     RSA \uc554\ud638\ud654\n\n    :param public_key: CODEF \ud68c\uc6d0\uc5d0\uac8c \uc81c\uacf5\ub418\ub294 PublicKey\n    :param data: \uc554\ud638\ud654\ud560 \ub370\uc774\ud130\n    :return: RSA256 \uc554\ud638\ud654\ub41c \ub370\uc774\ud130\n    \"\"\"\n    key_der = base64.b64decode(public_key)\n    key_pub = RSA.import_key(key_der)\n    cipher = PKCS1.new(key_pub)\n    cipher_text = cipher.encrypt(data.encode())\n    encrypted_data = base64.b64encode(cipher_text).decode('utf-8')\n"]]}
{"hexsha": "ce72f7d71f6ae021c620ab6d7510d352f841e52b", "ext": "py", "lang": "Python", "content": "def add_three_mirrors(context):\n    datadir_config = _write_datadir_config_for_three_mirrors()\n    mirror_config_output_file = \"/tmp/test_gpaddmirrors.config\"\n\n    cmd_str = 'gpaddmirrors -o %s -m %s' % (mirror_config_output_file, datadir_config)\n    Command('generate mirror_config file', cmd_str).run(validateAfter=True)\n\n    cmd = Command('gpaddmirrors ', 'gpaddmirrors -a -i %s ' % mirror_config_output_file)\n    cmd.run(validateAfter=True)", "fn_id": 5, "class_fn": false, "repo": "zhjc/gpdb", "file": "gpMgmt/test/behave/mgmt_utils/steps/addmirrors_mgmt_utils.py", "last_update_at": "2019-03-16T15:09:48+00:00", "question_id": "ce72f7d71f6ae021c620ab6d7510d352f841e52b_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def add_three_mirrors(context):\n    datadir_config = _write_datadir_config_for_three_mirrors()\n    mirror_config_output_file = '/tmp/test_gpaddmirrors.config'\n    cmd_str = 'gpaddmirrors -o %s -m %s' % (mirror_config_output_file, datadir_config)\n    Command('generate mirror_config file', cmd_str).run(validateAfter=True)\n    cmd = Command('gpaddmirrors ', 'gpaddmirrors -a -i %s ' % mirror_config_output_file)\n"]]}
{"hexsha": "13b1c0172247e26d32cab2292a3168121479e12b", "ext": "py", "lang": "Python", "content": "def _randrange_impl(context, builder, start, stop, step, state):\n    state_ptr = get_state_ptr(context, builder, state)\n    ty = stop.type\n    zero = ir.Constant(ty, 0)\n    one = ir.Constant(ty, 1)\n    nptr = cgutils.alloca_once(builder, ty, name=\"n\")\n    # n = stop - start\n    builder.store(builder.sub(stop, start), nptr)\n\n    with builder.if_then(builder.icmp_signed('<', step, zero)):\n        # n = (n + step + 1) // step\n        w = builder.add(builder.add(builder.load(nptr), step), one)\n        n = builder.sdiv(w, step)\n        builder.store(n, nptr)\n    with builder.if_then(builder.icmp_signed('>', step, one)):\n        # n = (n + step - 1) // step\n        w = builder.sub(builder.add(builder.load(nptr), step), one)\n        n = builder.sdiv(w, step)\n        builder.store(n, nptr)\n\n    n = builder.load(nptr)\n    with cgutils.if_unlikely(builder, builder.icmp_signed('<=', n, zero)):\n        # n <= 0\n        msg = \"empty range for randrange()\"\n        context.call_conv.return_user_exc(builder, ValueError, (msg,))\n\n    fnty = ir.FunctionType(ty, [ty, cgutils.true_bit.type])\n    fn = builder.function.module.get_or_insert_function(fnty, \"llvm.ctlz.%s\" % ty)\n    # Since the upper bound is exclusive, we need to subtract one before\n    # calculating the number of bits. This leads to a special case when\n    # n == 1; there's only one possible result, so we don't need bits from\n    # the PRNG. This case is handled separately towards the end of this\n    # function. CPython's implementation is simpler and just runs another\n    # iteration of the while loop when the resulting number is too large\n    # instead of subtracting one, to avoid needing to handle a special\n    # case. Thus, we only perform this subtraction for the NumPy case.\n    nm1 = builder.sub(n, one) if state == \"np\" else n\n    nbits = builder.trunc(builder.call(fn, [nm1, cgutils.true_bit]), int32_t)\n    nbits = builder.sub(ir.Constant(int32_t, ty.width), nbits)\n\n    rptr = cgutils.alloca_once(builder, ty, name=\"r\")\n\n    def get_num():\n        bbwhile = builder.append_basic_block(\"while\")\n        bbend = builder.append_basic_block(\"while.end\")\n        builder.branch(bbwhile)\n\n        builder.position_at_end(bbwhile)\n        r = get_next_int(context, builder, state_ptr, nbits, state == \"np\")\n        r = builder.trunc(r, ty)\n        too_large = builder.icmp_signed('>=', r, n)\n        builder.cbranch(too_large, bbwhile, bbend)\n\n        builder.position_at_end(bbend)\n        builder.store(r, rptr)\n\n    if state == \"np\":\n        # Handle n == 1 case, per previous comment.\n        with builder.if_else(builder.icmp_signed('==', n, one)) as (is_one, is_not_one):\n            with is_one:\n                builder.store(zero, rptr)\n            with is_not_one:\n                get_num()\n    else:\n        get_num()\n\n    return builder.add(start, builder.mul(builder.load(rptr), step))", "fn_id": 18, "class_fn": false, "repo": "mawanda-jun/numba", "file": "numba/targets/randomimpl.py", "last_update_at": "2019-12-04T07:13:18+00:00", "question_id": "13b1c0172247e26d32cab2292a3168121479e12b_18", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _randrange_impl(context, builder, start, stop, step, state):\n    state_ptr = get_state_ptr(context, builder, state)\n    ty = stop.type\n    zero = ir.Constant(ty, 0)\n    one = ir.Constant(ty, 1)\n    nptr = cgutils.alloca_once(builder, ty, name='n')\n    builder.store(builder.sub(stop, start), nptr)\n    with builder.if_then(builder.icmp_signed('<', step, zero)):\n        w = builder.add(builder.add(builder.load(nptr), step), one)\n        n = builder.sdiv(w, step)\n        builder.store(n, nptr)\n    with builder.if_then(builder.icmp_signed('>', step, one)):\n        w = builder.sub(builder.add(builder.load(nptr), step), one)\n        n = builder.sdiv(w, step)\n        builder.store(n, nptr)\n    n = builder.load(nptr)\n    with cgutils.if_unlikely(builder, builder.icmp_signed('<=', n, zero)):\n        msg = 'empty range for randrange()'\n        context.call_conv.return_user_exc(builder, ValueError, (msg,))\n    fnty = ir.FunctionType(ty, [ty, cgutils.true_bit.type])\n    fn = builder.function.module.get_or_insert_function(fnty, 'llvm.ctlz.%s' % ty)\n    nm1 = builder.sub(n, one) if state == 'np' else n\n    nbits = builder.trunc(builder.call(fn, [nm1, cgutils.true_bit]), int32_t)\n    nbits = builder.sub(ir.Constant(int32_t, ty.width), nbits)\n    rptr = cgutils.alloca_once(builder, ty, name='r')\n\n    def get_num():\n        bbwhile = builder.append_basic_block('while')\n        bbend = builder.append_basic_block('while.end')\n        builder.branch(bbwhile)\n        builder.position_at_end(bbwhile)\n        r = get_next_int(context, builder, state_ptr, nbits, state == 'np')\n        r = builder.trunc(r, ty)\n        too_large = builder.icmp_signed('>=', r, n)\n        builder.cbranch(too_large, bbwhile, bbend)\n        builder.position_at_end(bbend)\n        builder.store(r, rptr)\n    if state == 'np':\n        with builder.if_else(builder.icmp_signed('==', n, one)) as (is_one, is_not_one):\n            with is_one:\n                builder.store(zero, rptr)\n            with is_not_one:\n                get_num()\n    else:\n        get_num()\n"]]}
{"hexsha": "1100651f69c86cccb4a06a87f3e5a059cd119a6a", "ext": "py", "lang": "Python", "content": "def precision_recall(classifier):\n    refsets = collections.defaultdict(set)\n    testsets = collections.defaultdict(set)\n    print('pos precision:', classifier.metrics.precision(refsets['pos'], testsets['pos']))\n    print('pos recall:', classifier.metrics.recall(refsets['pos'], testsets['pos']))\n    print('neg precision:', classifier.metrics.precision(refsets['neg'], testsets['neg']))\n    print('neg recall:', classifier.metrics.recall(refsets['neg'], testsets['neg']))", "fn_id": 1, "class_fn": false, "repo": "radityagumay/BenchmarkSentimentAnalysis_2", "file": "com/radityalabs/Python/training/new_text_blob_train_1.py", "last_update_at": "2019-06-02T10:52:36+00:00", "question_id": "1100651f69c86cccb4a06a87f3e5a059cd119a6a_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def precision_recall(classifier):\n    refsets = collections.defaultdict(set)\n    testsets = collections.defaultdict(set)\n    print('pos precision:', classifier.metrics.precision(refsets['pos'], testsets['pos']))\n    print('pos recall:', classifier.metrics.recall(refsets['pos'], testsets['pos']))\n    print('neg precision:', classifier.metrics.precision(refsets['neg'], testsets['neg']))\n"]]}
{"hexsha": "5c79f4a7efe63998a601d6528e27c87f02edeb2b", "ext": "py", "lang": "Python", "content": "def add_noise (df, n_columns, ammount):\n    '''\n    Given a dataframe add noise to n_columns\n    '''\n    columns = list(df)\n    for column in np.random.choice(columns, n_columns):\n        \n        if df[column].dtype == 'object':\n            df[column] = categorical_noise(df[column], ammount)\n        elif df[column].dtype in ['int64', 'int32', 'float64', 'float32']:\n            df[column] = scalar_noise(df[column], ammount)\n    \n    return df", "fn_id": 4, "class_fn": false, "repo": "vb690/data_viz_python", "file": "toolbox/tools.py", "last_update_at": "2019-02-12T14:54:17+00:00", "question_id": "5c79f4a7efe63998a601d6528e27c87f02edeb2b_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def add_noise(df, n_columns, ammount):\n    \"\"\"\n    Given a dataframe add noise to n_columns\n    \"\"\"\n    columns = list(df)\n    for column in np.random.choice(columns, n_columns):\n        if df[column].dtype == 'object':\n            df[column] = categorical_noise(df[column], ammount)\n        elif df[column].dtype in ['int64', 'int32', 'float64', 'float32']:\n            df[column] = scalar_noise(df[column], ammount)\n"]]}
{"hexsha": "2c12bcc26b0502ec1ee956edcf1918d5fca9de40", "ext": "py", "lang": "Python", "content": "def test_substitution_layer_width():\n    masters, instances = load_to_ufos(glyphs_file_path(), include_instances=True)\n    assert masters[0][\"B\"].width == 500\n    assert masters[1][\"B\"].width == 600\n    assert masters[0][\"B.BRACKET.40\"].width == 510\n    assert masters[1][\"B.BRACKET.40\"].width == 610", "fn_id": 2, "class_fn": false, "repo": "nrsiward/glyphsLib", "file": "tests/specal_layer_width_test.py", "last_update_at": "2019-01-30T01:31:30+00:00", "question_id": "2c12bcc26b0502ec1ee956edcf1918d5fca9de40_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_substitution_layer_width():\n    masters, instances = load_to_ufos(glyphs_file_path(), include_instances=True)\n    assert masters[0]['B'].width == 500\n    assert masters[1]['B'].width == 600\n    assert masters[0]['B.BRACKET.40'].width == 510\n"]]}
{"hexsha": "d9bef0062335735f85138ca286bea734ef9177cd", "ext": "py", "lang": "Python", "content": "def safeMul(*factors):\n  if None in factors:\n    return None\n\n  factors = [float(x) for x in factors]\n  product = reduce(lambda x,y: x*y, factors)\n  return product", "fn_id": 4, "class_fn": false, "repo": "jssjr/graphite-web", "file": "webapp/graphite/render/functions.py", "last_update_at": "2019-06-17T18:55:55+00:00", "question_id": "d9bef0062335735f85138ca286bea734ef9177cd_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def safeMul(*factors):\n    if None in factors:\n        return None\n    factors = [float(x) for x in factors]\n    product = reduce(lambda x, y: x * y, factors)\n"]]}
{"hexsha": "49d039db53e401ea452ec1cdb12ff96ae55c9a0e", "ext": "py", "lang": "Python", "content": "@click.command()\n@click_region_option\n@click.argument(\"stack_name\", required=True)\ndef wait_for_complete(stack_name, region):\n    \"\"\"Wait for the stack status to be *_COMPLETE\n\n    Wait for the stack status to become complete (any status\n    ending in '_COMPLETE' is considered complete.\n    \"\"\"\n    # how long to wait before the next check for complete (seconds)\n    period = 60\n\n    try:\n        while True:\n            status = _get_stack_status(stack_name, region)\n            _highlight('{time}: {status}'.format(time=time.strftime('%H:%M:%S'), status=click.style(status, fg='yellow')))\n\n            complete = status.endswith('_COMPLETE')\n            if complete:\n                break;\n\n            time.sleep(period)\n    except ClientError as e:\n        # if waiting for delete to complete, then this is expected, but still should be reported specially just in case\n        _highlight('{code}: {msg}'.format(code=e.response['Error']['Code'], msg=e.response['Error']['Message']), fg='red')", "fn_id": 10, "class_fn": false, "repo": "rifflearning/riff-docker", "file": "bin/docker-swarm.py", "last_update_at": "2019-07-30T13:51:22+00:00", "question_id": "49d039db53e401ea452ec1cdb12ff96ae55c9a0e_10", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@click.command()\n@click_region_option\n@click.argument('stack_name', required=True)\ndef wait_for_complete(stack_name, region):\n    \"\"\"Wait for the stack status to be *_COMPLETE\n\n    Wait for the stack status to become complete (any status\n    ending in '_COMPLETE' is considered complete.\n    \"\"\"\n    period = 60\n    try:\n        while True:\n            status = _get_stack_status(stack_name, region)\n            _highlight('{time}: {status}'.format(time=time.strftime('%H:%M:%S'), status=click.style(status, fg='yellow')))\n            complete = status.endswith('_COMPLETE')\n            if complete:\n                break\n            time.sleep(period)\n    except ClientError as e:\n"]]}
{"hexsha": "559d52f3610fcb535e53d457b1766f696c43f428", "ext": "py", "lang": "Python", "content": "def rectangle(x, y, width, height):                             # rectangle(x, y, width, height) \ud568\uc218\n    \"Draw rectangle at (x, y) with given width and height.\"     # \uc774 \ud568\uc218\ub294 \uac8c\uc784\ud310\uc744 \ucd08\uae30\ud654\ud558\ub294 \ud568\uc218\uc774\ub2e4.\n    up()\n    goto(x, y)\n    down()\n    begin_fill()\n    for count in range(2):\n        forward(width)\n        left(90)\n        forward(height)\n        left(90)\n    end_fill()", "fn_id": 0, "class_fn": false, "repo": "19-1-skku-oss/2019-1-OSS-E3", "file": "freegames/Code Description/pong_d.py", "last_update_at": "2019-06-10T14:11:37+00:00", "question_id": "559d52f3610fcb535e53d457b1766f696c43f428_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def rectangle(x, y, width, height):\n    \"\"\"Draw rectangle at (x, y) with given width and height.\"\"\"\n    up()\n    goto(x, y)\n    down()\n    begin_fill()\n    for count in range(2):\n        forward(width)\n        left(90)\n        forward(height)\n        left(90)\n"]]}
{"hexsha": "d7cea5bb2dbd77cb6888b1f35dbd4048d8df8794", "ext": "py", "lang": "Python", "content": "@app.route('/red')\ndef on():\n    ser.write(b\"r\")\n    return redirect('/')", "fn_id": 2, "class_fn": false, "repo": "Lapikud/arduino_remote", "file": "Holger/ardu/web.py", "last_update_at": "2019-11-05T19:44:11+00:00", "question_id": "d7cea5bb2dbd77cb6888b1f35dbd4048d8df8794_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@app.route('/red')\ndef on():\n    ser.write(b'r')\n"]]}
{"hexsha": "ed382011a00d6f83cb0e0ac487b3306b31a6e19c", "ext": "py", "lang": "Python", "content": "def find_typerefs(node, fileName):\n    \"\"\" Find all references to the type named 'typename'\n    \"\"\"\n    #if node.kind == clang.cindex.CursorKind.is_declaration\n    #if node.kind.is_definition():\n    #if node.is_definition():\n        #ref_node = clang.cindex.Cursor_ref(node)\n        #ref_node = node\n    #if node.kind == clang.cindex.CursorKind.ANNOTATE_ATTR:\n    #    print(\"is_definition\", node.spelling, node.location.file, node.kind)\n    #if node.location.file and node.location.file.name == fileName:\n    #if node.spelling != \"\":\n    #    print(\"data\", node.spelling, node.location.file, node.location.line, node.location.column)\n    # Recurse for children of this node\n    #for c in node.get_children():\n    #    find_typerefs(c, fileName)\n    for c in node.get_children():\n        if c.location and c.location.file.name == fileName:\n            parse_node(c)", "fn_id": 2, "class_fn": false, "repo": "xuantao/xlua", "file": "tmp/tpy/main.py", "last_update_at": "2019-10-24T13:49:23+00:00", "question_id": "ed382011a00d6f83cb0e0ac487b3306b31a6e19c_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def find_typerefs(node, fileName):\n    \"\"\" Find all references to the type named 'typename'\n    \"\"\"\n    for c in node.get_children():\n        if c.location and c.location.file.name == fileName:\n"]]}
{"hexsha": "d3173e58d9c4fc4a3d60c9d3f2b08b6f207ad48b", "ext": "py", "lang": "Python", "content": "def downgrade():\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_index(op.f('ix_project_SNo'), table_name='project')\n    op.drop_table('project')\n    op.drop_index(op.f('ix_student_SNo'), table_name='student')\n    op.drop_index(op.f('ix_student_Avatar'), table_name='student')\n    op.drop_table('student')\n    op.drop_table('admin')", "fn_id": 1, "class_fn": false, "repo": "os-harry/T_Team", "file": "teamUpPy/migrations/versions/fe189172a1a6_.py", "last_update_at": "2019-12-19T12:33:27+00:00", "question_id": "d3173e58d9c4fc4a3d60c9d3f2b08b6f207ad48b_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def downgrade():\n    op.drop_index(op.f('ix_project_SNo'), table_name='project')\n    op.drop_table('project')\n    op.drop_index(op.f('ix_student_SNo'), table_name='student')\n    op.drop_index(op.f('ix_student_Avatar'), table_name='student')\n    op.drop_table('student')\n"]]}
{"hexsha": "51b536d9c1fbc9f9bf6246ab80344c713f280b7d", "ext": "py", "lang": "Python", "content": "def create_schema(name, **options):\n    \"\"\"\n    This function creates a schema and perform a syncdb on it.\n    As we call some syncdb and migrate management commands, we can't rely on\n    transaction support.\n    We are going to catch any exception (including SystemExit).\n    \"\"\"\n    try:\n        cursor = connection.cursor()\n        # We can't use params with system names\n        cursor.execute('CREATE SCHEMA \"%s\"' % escape_schema_name(name))\n        transaction.commit_unless_managed()\n    except BaseException:\n        transaction.rollback_unless_managed()\n        raise\n\n    try:\n        defaults = {\n            'verbosity': 0,\n            'traceback': None,\n            'noinput': True\n        }\n        defaults.update(options)\n\n        sync_options = options\n        # We never want migration to launch with syncdb call\n        sync_options['migrate'] = False\n\n        _, isolated_apps = get_apps()\n\n        _syncdb_apps(isolated_apps, schema=name, force_close=False, **sync_options)\n        _migrate_apps(get_migration_candidates(isolated_apps), schema=name, force_close=False, **options)\n        schema_store.reset_path()\n    except BaseException:\n        transaction.rollback_unless_managed()\n        drop_schema(name)\n        raise", "fn_id": 1, "class_fn": false, "repo": "olivier-m/django-appschema", "file": "appschema/models.py", "last_update_at": "2019-03-05T22:52:39+00:00", "question_id": "51b536d9c1fbc9f9bf6246ab80344c713f280b7d_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def create_schema(name, **options):\n    \"\"\"\n    This function creates a schema and perform a syncdb on it.\n    As we call some syncdb and migrate management commands, we can't rely on\n    transaction support.\n    We are going to catch any exception (including SystemExit).\n    \"\"\"\n    try:\n        cursor = connection.cursor()\n        cursor.execute('CREATE SCHEMA \"%s\"' % escape_schema_name(name))\n        transaction.commit_unless_managed()\n    except BaseException:\n        transaction.rollback_unless_managed()\n        raise\n    try:\n        defaults = {'verbosity': 0, 'traceback': None, 'noinput': True}\n        defaults.update(options)\n        sync_options = options\n        sync_options['migrate'] = False\n        _, isolated_apps = get_apps()\n        _syncdb_apps(isolated_apps, schema=name, force_close=False, **sync_options)\n        _migrate_apps(get_migration_candidates(isolated_apps), schema=name, force_close=False, **options)\n        schema_store.reset_path()\n    except BaseException:\n        transaction.rollback_unless_managed()\n        drop_schema(name)\n"]]}
{"hexsha": "9d4e96a7d1b12e5ef876547dd08f519dc7a09dfb", "ext": "py", "lang": "Python", "content": "@api_blu.route('/user/avatar', methods=['POST'])\n@login_required\ndef set_user_avatar():\n    \"\"\"\n    0. \u5224\u65ad\u7528\u6237\u662f\u5426\u767b\u5f55\n    1. \u83b7\u53d6\u5230\u4e0a\u4f20\u7684\u6587\u4ef6\n    2. \u518d\u5c06\u6587\u4ef6\u4e0a\u4f20\u5230\u4e03\u725b\u4e91\n    3. \u5c06\u5934\u50cf\u4fe1\u606f\u66f4\u65b0\u5230\u5f53\u524d\u7528\u6237\u7684\u6a21\u578b\u4e2d\n    4. \u8fd4\u56de\u4e0a\u4f20\u7684\u7ed3\u679c<avatar_url>\n    :return:\n    \"\"\"\n    # 0. \u5224\u65ad\u7528\u6237\u662f\u5426\u767b\u5f55\n    user_id = g.user_id\n    user = User.query.get(user_id)\n    if not user:\n        return jsonify(errno=RET.SESSIONERR, errmsg=\"\u7528\u6237\u672a\u767b\u5f55\")\n\n    # 1. \u83b7\u53d6\u5230\u4e0a\u4f20\u7684\u6587\u4ef6\n    avatar = request.files.get(\"avatar\")\n    if not avatar:\n        return jsonify(errno=RET.PARAMERR, errmsg=\"\u53c2\u6570\u4e0d\u8db3\")\n\n    # 2. \u518d\u5c06\u6587\u4ef6\u4e0a\u4f20\u5230\u4e03\u725b\u4e91\n    try:\n        avatar_image = storage_image(avatar.read())\n    except Exception as e:\n        current_app.logger.error(e)\n        return jsonify(errno=RET.THIRDERR, errmsg=\"\u7b2c\u4e09\u65b9\u7cfb\u7edf\u9519\u8bef\")\n    if not avatar_image:\n        return jsonify(errno=RET.NODATA, errmsg=\"\u65e0\u6570\u636e\")\n\n    # 3. \u5c06\u5934\u50cf\u4fe1\u606f\u66f4\u65b0\u5230\u5f53\u524d\u7528\u6237\u7684\u6a21\u578b\u4e2d\n    user.avatar_url = avatar_image\n    try:\n        db.session.commit()\n    except Exception as e:\n        current_app.logger.error(e)\n        db.session.rollback()\n        return jsonify(errno=RET.DBERR, errmsg=\"\u6570\u636e\u5e93\u63d0\u4ea4\u9519\u8bef\")\n\n    # 4. \u8fd4\u56de\u4e0a\u4f20\u7684\u7ed3\u679c<avatar_url>\n    avatar_url = constants.QINIU_DOMIN_PREFIX + avatar_image\n    data = {\n        \"avatar_url\": avatar_url\n    }\n    return jsonify(errno=RET.OK, errmsg=\"\u6210\u529f\", data=data)", "fn_id": 2, "class_fn": false, "repo": "sexlovelove/info", "file": "ihome/modules/api/profile.py", "last_update_at": "2019-03-17T06:37:59+00:00", "question_id": "9d4e96a7d1b12e5ef876547dd08f519dc7a09dfb_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@api_blu.route('/user/avatar', methods=['POST'])\n@login_required\ndef set_user_avatar():\n    \"\"\"\n    0. \u5224\u65ad\u7528\u6237\u662f\u5426\u767b\u5f55\n    1. \u83b7\u53d6\u5230\u4e0a\u4f20\u7684\u6587\u4ef6\n    2. \u518d\u5c06\u6587\u4ef6\u4e0a\u4f20\u5230\u4e03\u725b\u4e91\n    3. \u5c06\u5934\u50cf\u4fe1\u606f\u66f4\u65b0\u5230\u5f53\u524d\u7528\u6237\u7684\u6a21\u578b\u4e2d\n    4. \u8fd4\u56de\u4e0a\u4f20\u7684\u7ed3\u679c<avatar_url>\n    :return:\n    \"\"\"\n    user_id = g.user_id\n    user = User.query.get(user_id)\n    if not user:\n        return jsonify(errno=RET.SESSIONERR, errmsg='\u7528\u6237\u672a\u767b\u5f55')\n    avatar = request.files.get('avatar')\n    if not avatar:\n        return jsonify(errno=RET.PARAMERR, errmsg='\u53c2\u6570\u4e0d\u8db3')\n    try:\n        avatar_image = storage_image(avatar.read())\n    except Exception as e:\n        current_app.logger.error(e)\n        return jsonify(errno=RET.THIRDERR, errmsg='\u7b2c\u4e09\u65b9\u7cfb\u7edf\u9519\u8bef')\n    if not avatar_image:\n        return jsonify(errno=RET.NODATA, errmsg='\u65e0\u6570\u636e')\n    user.avatar_url = avatar_image\n    try:\n        db.session.commit()\n    except Exception as e:\n        current_app.logger.error(e)\n        db.session.rollback()\n        return jsonify(errno=RET.DBERR, errmsg='\u6570\u636e\u5e93\u63d0\u4ea4\u9519\u8bef')\n    avatar_url = constants.QINIU_DOMIN_PREFIX + avatar_image\n    data = {'avatar_url': avatar_url}\n"]]}
{"hexsha": "e448594db7c73eaa0f2a152566132ac1a2539549", "ext": "py", "lang": "Python", "content": "def intersect(x1, x2, x3, x4):\n    if x1 > x3:\n        x1, x2, x3, x4 = x3, x4, x1, x2\n    if x3 > x2:\n        return None, None\n    return x3, min(x2, x4)", "fn_id": 0, "class_fn": false, "repo": "c-yan/atcoder", "file": "arc/arc049/arc049b.py", "last_update_at": "2019-08-21T00:49:34+00:00", "question_id": "e448594db7c73eaa0f2a152566132ac1a2539549_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def intersect(x1, x2, x3, x4):\n    if x1 > x3:\n        x1, x2, x3, x4 = (x3, x4, x1, x2)\n    if x3 > x2:\n        return (None, None)\n"]]}
{"hexsha": "352ab043ccc828a575977f5e6c14834db88b7602", "ext": "py", "lang": "Python", "content": "def plot_1d_field(\n    coords,\n    values,\n    fig=None,\n    ax=None,\n    color=\"k\",\n    alpha=1.0,\n    lw=1.0,\n    ls=\"-\",\n    marker=None,\n    markersize=None,\n    minorticks_on=True,\n    x_lims=None,\n    y_lims=None,\n    log_x=False,\n    log_y=False,\n    extra_artists=None,\n    extra_patches=None,\n    xlabel=None,\n    ylabel=None,\n    label=None,\n    legend_loc=None,\n    legend_fontsize=None,\n    title=None,\n    zorder=2,\n    output_path=None,\n    render_now=True,\n    fig_kwargs={},\n):\n\n    if fig is None or ax is None:\n        fig, ax = create_2d_subplots(**fig_kwargs)\n    (lines,) = ax.plot(\n        coords,\n        values,\n        color=color,\n        alpha=alpha,\n        lw=lw,\n        ls=ls,\n        marker=marker,\n        markersize=markersize,\n        markeredgewidth=0,\n        label=label,\n        zorder=zorder,\n    )\n\n    if extra_artists is not None:\n        for artist in extra_artists:\n            ax.add_artist(artist)\n\n    if extra_patches is not None:\n        for patch in extra_patches:\n            ax.add_patch(patch)\n\n    if log_x:\n        ax.set_xscale(\"log\")\n    if log_y:\n        ax.set_yscale(\"log\")\n\n    set_2d_plot_extent(ax, x_lims, y_lims)\n    set_2d_axis_labels(ax, xlabel, ylabel)\n\n    if minorticks_on:\n        ax.minorticks_on()\n\n    if title is not None:\n        ax.set_title(title)\n\n    if legend_loc is not None:\n        ax.legend(loc=legend_loc, fontsize=legend_fontsize)\n\n    if render_now:\n        render(fig, output_path=output_path)\n\n    return fig, ax, lines", "fn_id": 16, "class_fn": false, "repo": "lars-frogner/bifrost-rust", "file": "backstaff/plotting.py", "last_update_at": "2019-10-24T07:24:05+00:00", "question_id": "352ab043ccc828a575977f5e6c14834db88b7602_16", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def plot_1d_field(coords, values, fig=None, ax=None, color='k', alpha=1.0, lw=1.0, ls='-', marker=None, markersize=None, minorticks_on=True, x_lims=None, y_lims=None, log_x=False, log_y=False, extra_artists=None, extra_patches=None, xlabel=None, ylabel=None, label=None, legend_loc=None, legend_fontsize=None, title=None, zorder=2, output_path=None, render_now=True, fig_kwargs={}):\n    if fig is None or ax is None:\n        fig, ax = create_2d_subplots(**fig_kwargs)\n    lines, = ax.plot(coords, values, color=color, alpha=alpha, lw=lw, ls=ls, marker=marker, markersize=markersize, markeredgewidth=0, label=label, zorder=zorder)\n    if extra_artists is not None:\n        for artist in extra_artists:\n            ax.add_artist(artist)\n    if extra_patches is not None:\n        for patch in extra_patches:\n            ax.add_patch(patch)\n    if log_x:\n        ax.set_xscale('log')\n    if log_y:\n        ax.set_yscale('log')\n    set_2d_plot_extent(ax, x_lims, y_lims)\n    set_2d_axis_labels(ax, xlabel, ylabel)\n    if minorticks_on:\n        ax.minorticks_on()\n    if title is not None:\n        ax.set_title(title)\n    if legend_loc is not None:\n        ax.legend(loc=legend_loc, fontsize=legend_fontsize)\n    if render_now:\n        render(fig, output_path=output_path)\n"]]}
{"hexsha": "0dbd18b25b829660d44fc32931458d4e9a388188", "ext": "py", "lang": "Python", "content": "def AddLoadBalancingScheme(parser,\n                           include_l7_ilb=False,\n                           include_gfe3=False,\n                           include_l7_rxlb=False,\n                           include_psc_google_apis=False,\n                           include_target_service_attachment=False):\n  \"\"\"Adds the load-balancing-scheme flag.\"\"\"\n  td_proxies = ('--target-http-proxy, --target-https-proxy, '\n                '--target-grpc-proxy, --target-tcp-proxy')\n  load_balancing_choices = {\n      'EXTERNAL':\n          'External load balancing or forwarding, used with one of '\n          '--target-http-proxy, --target-https-proxy, --target-tcp-proxy, '\n          '--target-ssl-proxy, --target-pool, --target-vpn-gateway, '\n          '--target-instance.',\n      'INTERNAL':\n          'Internal load balancing or forwarding, used with --backend-service.',\n      'INTERNAL_SELF_MANAGED':\n          \"\"\"Traffic Director load balancing or forwarding, used with\n          {0}.\"\"\".format(td_proxies)\n  }\n\n  if include_l7_ilb:\n    load_balancing_choices.update({\n        'INTERNAL_MANAGED': 'Internal HTTP(S) Load Balancing, used with '\n                            '--target-http-proxy, --target-https-proxy.'\n    })\n\n  if include_gfe3 or include_l7_rxlb:\n    load_balancing_choices.update({\n        'EXTERNAL_MANAGED':\n            'Envoy based External HTTP(S) Load Balancing, used with '\n            '--target-http-proxy, --target-https-proxy.'\n    })\n\n  # There isn't a default load-balancing-scheme for PSC forwarding rules.\n  # But the default is EXTERNAL for non-PSC forwarding rules.\n  include_psc = (include_psc_google_apis or include_target_service_attachment)\n  parser.add_argument(\n      '--load-balancing-scheme',\n      choices=load_balancing_choices,\n      type=lambda x: x.replace('-', '_').upper(),\n      default=None if include_psc else 'EXTERNAL',\n      help=\"This defines the forwarding rule's load balancing scheme. Note that it defaults to EXTERNAL and is not applicable for Private Service Connect forwarding rules.\"\n      if include_psc else\n      \"This defines the forwarding rule's load balancing scheme.\")", "fn_id": 7, "class_fn": false, "repo": "google-cloud-sdk-unofficial/google-cloud-sdk", "file": "lib/googlecloudsdk/command_lib/compute/forwarding_rules/flags.py", "last_update_at": "2019-12-18T13:44:08+00:00", "question_id": "0dbd18b25b829660d44fc32931458d4e9a388188_7", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def AddLoadBalancingScheme(parser, include_l7_ilb=False, include_gfe3=False, include_l7_rxlb=False, include_psc_google_apis=False, include_target_service_attachment=False):\n    \"\"\"Adds the load-balancing-scheme flag.\"\"\"\n    td_proxies = '--target-http-proxy, --target-https-proxy, --target-grpc-proxy, --target-tcp-proxy'\n    load_balancing_choices = {'EXTERNAL': 'External load balancing or forwarding, used with one of --target-http-proxy, --target-https-proxy, --target-tcp-proxy, --target-ssl-proxy, --target-pool, --target-vpn-gateway, --target-instance.', 'INTERNAL': 'Internal load balancing or forwarding, used with --backend-service.', 'INTERNAL_SELF_MANAGED': 'Traffic Director load balancing or forwarding, used with\\n          {0}.'.format(td_proxies)}\n    if include_l7_ilb:\n        load_balancing_choices.update({'INTERNAL_MANAGED': 'Internal HTTP(S) Load Balancing, used with --target-http-proxy, --target-https-proxy.'})\n    if include_gfe3 or include_l7_rxlb:\n        load_balancing_choices.update({'EXTERNAL_MANAGED': 'Envoy based External HTTP(S) Load Balancing, used with --target-http-proxy, --target-https-proxy.'})\n    include_psc = include_psc_google_apis or include_target_service_attachment\n"]]}
{"hexsha": "4812e9b0d21ad189393c62303d4d25cfa33481f2", "ext": "py", "lang": "Python", "content": "def file_ref(*args, **kwargs):\n    args = args[1:] if len(args) > 1 else []\n    file_ref_str = \"_\".join(\n        [f\"{date.today():%Y%m%d}\"]\n        + [str(vv) for vv in args]\n        + [str(vv) for vv in kwargs.values()]\n    )\n    return file_ref_str", "fn_id": 1, "class_fn": false, "repo": "nzta-captif/py-ramm", "file": "pyramm/cache.py", "last_update_at": "2019-12-05T20:29:51+00:00", "question_id": "4812e9b0d21ad189393c62303d4d25cfa33481f2_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def file_ref(*args, **kwargs):\n    args = args[1:] if len(args) > 1 else []\n    file_ref_str = '_'.join([f'{date.today():%Y%m%d}'] + [str(vv) for vv in args] + [str(vv) for vv in kwargs.values()])\n"]]}
{"hexsha": "0767a77da79f15e4d316cc051c157cd2837ede5d", "ext": "py", "lang": "Python", "content": "def openSocket(client, port):\n    hostServer = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    hostServer.bind((client, port))\n    hostServer.listen(0)\n    return hostServer", "fn_id": 0, "class_fn": false, "repo": "FlantasticDan/photoPi", "file": "captureServer.py", "last_update_at": "2019-02-08T22:29:12+00:00", "question_id": "0767a77da79f15e4d316cc051c157cd2837ede5d_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def openSocket(client, port):\n    hostServer = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    hostServer.bind((client, port))\n    hostServer.listen(0)\n"]]}
{"hexsha": "393f23c6e0e997ce7723da08a72f575d21cf7b6c", "ext": "py", "lang": "Python", "content": "@frappe.whitelist()\ndef fetch_total_basic_da_hra(parent):\n\ttotal_basic_da_hra = 0\n\tsalary_details = frappe.db.sql(\"\"\" select amount,salary_component from `tabSalary Detail` where parent=%s and \n\t\t\t\t\tparentfield='earnings' \"\"\", parent, as_dict=1)\n\tif len(salary_details)!=0:\n\t\tfor data in salary_details:\n\t\t\tamount = data['amount']\n\t\t\tsalary_component = data['salary_component']\n\t\t\tif salary_component == 'Basic':\n\t\t\t\ttotal_basic_da_hra = float(total_basic_da_hra) + float(amount)\n\t\t\tif salary_component == 'DA':\n\t\t\t\ttotal_basic_da_hra = float(total_basic_da_hra) + float(amount)\n\t\t\tif salary_component == 'House Rent Allowance':\n\t\t\t\ttotal_basic_da_hra = float(total_basic_da_hra) + float(amount)\n\t\t\tif salary_component == 'Conveyance':\n\t\t\t\ttotal_basic_da_hra = float(total_basic_da_hra) + float(amount)\n\t\t\tif salary_component == 'Special Allowance':\n\t\t\t\ttotal_basic_da_hra = float(total_basic_da_hra) + float(amount)\n\treturn total_basic_da_hra", "fn_id": 5, "class_fn": false, "repo": "umaepoch/ICP", "file": "icp/api.py", "last_update_at": "2019-07-01T06:26:13+00:00", "question_id": "393f23c6e0e997ce7723da08a72f575d21cf7b6c_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@frappe.whitelist()\ndef fetch_total_basic_da_hra(parent):\n    total_basic_da_hra = 0\n    salary_details = frappe.db.sql(\" select amount,salary_component from `tabSalary Detail` where parent=%s and \\n\\t\\t\\t\\t\\tparentfield='earnings' \", parent, as_dict=1)\n    if len(salary_details) != 0:\n        for data in salary_details:\n            amount = data['amount']\n            salary_component = data['salary_component']\n            if salary_component == 'Basic':\n                total_basic_da_hra = float(total_basic_da_hra) + float(amount)\n            if salary_component == 'DA':\n                total_basic_da_hra = float(total_basic_da_hra) + float(amount)\n            if salary_component == 'House Rent Allowance':\n                total_basic_da_hra = float(total_basic_da_hra) + float(amount)\n            if salary_component == 'Conveyance':\n                total_basic_da_hra = float(total_basic_da_hra) + float(amount)\n            if salary_component == 'Special Allowance':\n                total_basic_da_hra = float(total_basic_da_hra) + float(amount)\n"]]}
{"hexsha": "75e96f1beb2324c685a831777a0aa3d0918f1302", "ext": "py", "lang": "Python", "content": "def extract(\n    ho_start: \"YYYY-MM-dd\",  # noqa: F821\n    spark,\n    ho_win=7,\n    model_win=120,\n    samp_fraction=0.1,\n    sample_ids=[0],\n    check_min_users=50000,\n    source=\"hive\",\n    bigquery_parameters=None,\n) -> Tuple[pd.DataFrame, int]:\n    \"\"\"\n    check_min_users: minimum number of users that should be pulled\n    TODO: heuristic to get a high enough sample size\n    \"\"\"\n    dfs_all, _q = run_rec_freq_spk(\n        model_win=model_win,\n        ho_start=ho_start,\n        sample_ids=sample_ids,\n        spark=spark,\n        holdout=True,\n        ho_win=ho_win,\n        source=source,\n        bigquery_parameters=bigquery_parameters,\n    )\n    df = dfs_all.sample(fraction=samp_fraction)\n    user_col = \"n_custs\"\n    dfpr = (\n        reduce_rec_freq_spk(df, rfn_cols=[\"Recency\", \"Frequency\", \"N\"])\n        .toPandas()\n        # Rename to conform to api\n        .rename(columns=str.lower)\n        .rename(columns={\"n_users\": user_col})\n    )\n    n_users = dfpr[user_col].sum()\n    print(\"{:,.0f} users pulled\".format(n_users))\n    assert (\n        dfpr[user_col].sum() > check_min_users\n    ), \"Assuming we're training on at least {} clients\".format(check_min_users)\n\n    return dfpr, n_users", "fn_id": 0, "class_fn": false, "repo": "wcbeard/bgbb_airflow", "file": "bgbb_airflow/fit_airflow_job.py", "last_update_at": "2019-11-26T21:14:19+00:00", "question_id": "75e96f1beb2324c685a831777a0aa3d0918f1302_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def extract(ho_start: 'YYYY-MM-dd', spark, ho_win=7, model_win=120, samp_fraction=0.1, sample_ids=[0], check_min_users=50000, source='hive', bigquery_parameters=None) -> Tuple[pd.DataFrame, int]:\n    \"\"\"\n    check_min_users: minimum number of users that should be pulled\n    TODO: heuristic to get a high enough sample size\n    \"\"\"\n    dfs_all, _q = run_rec_freq_spk(model_win=model_win, ho_start=ho_start, sample_ids=sample_ids, spark=spark, holdout=True, ho_win=ho_win, source=source, bigquery_parameters=bigquery_parameters)\n    df = dfs_all.sample(fraction=samp_fraction)\n    user_col = 'n_custs'\n    dfpr = reduce_rec_freq_spk(df, rfn_cols=['Recency', 'Frequency', 'N']).toPandas().rename(columns=str.lower).rename(columns={'n_users': user_col})\n    n_users = dfpr[user_col].sum()\n    print('{:,.0f} users pulled'.format(n_users))\n    assert dfpr[user_col].sum() > check_min_users, \"Assuming we're training on at least {} clients\".format(check_min_users)\n"]]}
{"hexsha": "036a4a271cba9a7f33d36bfe2f346f0ff2ac4bd1", "ext": "py", "lang": "Python", "content": "def multi_search(search_str):\n    response = get_tmdb_data(\"search/multi?query=%s&\" % url_quote(search_str), 1)\n    if response and \"results\" in response:\n        return response[\"results\"]\n    else:\n        log(\"Error when searching for %s\" % search_str)\n        return \"\"", "fn_id": 29, "class_fn": false, "repo": "TheWardoctor/wardoctors-repo", "file": "script.extendedinfo/resources/lib/TheMovieDB.py", "last_update_at": "2019-03-05T09:38:10+00:00", "question_id": "036a4a271cba9a7f33d36bfe2f346f0ff2ac4bd1_29", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def multi_search(search_str):\n    response = get_tmdb_data('search/multi?query=%s&' % url_quote(search_str), 1)\n    if response and 'results' in response:\n        return response['results']\n    else:\n        log('Error when searching for %s' % search_str)\n"]]}
{"hexsha": "b62424aee5b812da6d5f8e0ddaf4c5c38bbe2584", "ext": "py", "lang": "Python", "content": "def api_repositories():\n    root = sorted(os.listdir(config['public-directory']))\n    output = []\n\n    for user in root:\n        target = os.path.join(config['public-directory'], user)\n\n        # ignore files (eg: .keep file)\n        if not os.path.isdir(target):\n            continue\n\n        official = (user in config['PUBLIC_OFFICIALS'])\n        output.append({'name': user, 'official': official})\n\n    return output", "fn_id": 33, "class_fn": false, "repo": "jdelrue/digital_me", "file": "packages/hub/blueprints/hub/routes.py", "last_update_at": "2019-02-01T15:50:20+00:00", "question_id": "b62424aee5b812da6d5f8e0ddaf4c5c38bbe2584_33", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def api_repositories():\n    root = sorted(os.listdir(config['public-directory']))\n    output = []\n    for user in root:\n        target = os.path.join(config['public-directory'], user)\n        if not os.path.isdir(target):\n            continue\n        official = user in config['PUBLIC_OFFICIALS']\n        output.append({'name': user, 'official': official})\n"]]}
{"hexsha": "9c567b2891941129bd56e6f4b018599badf7c2a5", "ext": "py", "lang": "Python", "content": "def test_nonsilent_region_cpu():\n    pipe = Pipeline(batch_size=batch_size, num_threads=4, device_id=None)\n    test_data_shape = [200]\n    def get_data():\n        out = [np.random.randint(0, 255, size = test_data_shape, dtype = np.uint8) for _ in range(batch_size)]\n        out[0][0] = 0\n        out[1][0] = 0\n        out[1][1] = 0\n        return out\n    data = fn.external_source(source = get_data)\n    processed, _ = fn.nonsilent_region(data)\n    pipe.set_outputs(processed)\n    pipe.build()\n    for _ in range(3):\n        pipe.run()", "fn_id": 8, "class_fn": false, "repo": "ConnectionMaster/DALI", "file": "dali/test/python/test_dali_cpu_only.py", "last_update_at": "2019-05-20T18:49:34+00:00", "question_id": "9c567b2891941129bd56e6f4b018599badf7c2a5_8", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_nonsilent_region_cpu():\n    pipe = Pipeline(batch_size=batch_size, num_threads=4, device_id=None)\n    test_data_shape = [200]\n\n    def get_data():\n        out = [np.random.randint(0, 255, size=test_data_shape, dtype=np.uint8) for _ in range(batch_size)]\n        out[0][0] = 0\n        out[1][0] = 0\n        out[1][1] = 0\n        return out\n    data = fn.external_source(source=get_data)\n    processed, _ = fn.nonsilent_region(data)\n    pipe.set_outputs(processed)\n    pipe.build()\n    for _ in range(3):\n"]]}
{"hexsha": "340a33e53b2d20aa5e7efa8a18e86223184f852e", "ext": "py", "lang": "Python", "content": "def _reverse(x, bits):\n    y = 0\n    for i in xrange(bits):\n        y = (y << 1) | (x & 1)\n        x >>= 1\n    return y", "fn_id": 4, "class_fn": false, "repo": "rh314/pure-py-fft", "file": "fft.py", "last_update_at": "2019-08-20T18:28:47+00:00", "question_id": "340a33e53b2d20aa5e7efa8a18e86223184f852e_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _reverse(x, bits):\n    y = 0\n    for i in xrange(bits):\n        y = y << 1 | x & 1\n        x >>= 1\n"]]}
{"hexsha": "53d78cd74610fa846a4493dddef24c85a7d7fd59", "ext": "py", "lang": "Python", "content": "def getSceneryUnitProductUpdate(projectName, sceneryCategory, sceneryName, sceneryVariant, sceneryStage):\n    string = prsOutputs.Util.infoNonExistsLabel\n    #\n    serverProductFile = scnUnitProductFile(\n        prsConfigure.Utility.DEF_value_root_server, projectName, sceneryCategory, sceneryName, sceneryVariant, sceneryStage\n    )[1]\n    #\n    if bscMethods.OsFile.isExist(serverProductFile):\n        data = bscMethods.OsFile.mtimeChnPrettify(serverProductFile)\n        if data:\n            string = data\n    return string", "fn_id": 37, "class_fn": false, "repo": "no7hings/Lynxi", "file": "workspace/module/python-2.7/LxCore/preset/prod/sceneryPr.py", "last_update_at": "2019-03-26T03:25:11+00:00", "question_id": "53d78cd74610fa846a4493dddef24c85a7d7fd59_37", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def getSceneryUnitProductUpdate(projectName, sceneryCategory, sceneryName, sceneryVariant, sceneryStage):\n    string = prsOutputs.Util.infoNonExistsLabel\n    serverProductFile = scnUnitProductFile(prsConfigure.Utility.DEF_value_root_server, projectName, sceneryCategory, sceneryName, sceneryVariant, sceneryStage)[1]\n    if bscMethods.OsFile.isExist(serverProductFile):\n        data = bscMethods.OsFile.mtimeChnPrettify(serverProductFile)\n        if data:\n            string = data\n"]]}
{"hexsha": "7eceddef13801c878c30f3c472cc75fd73ad78d6", "ext": "py", "lang": "Python", "content": "def readStrFromFile(filePath):\n\t\"\"\"\n\t\u4ece\u6587\u4ef6\u4e2d\u8bfb\u53d6\u5b57\u7b26\u4e32str\n\tparam filePath: \u6587\u4ef6\u8def\u5f84\n\treturn string : \u6587\u672c\u5b57\u7b26\u4e32\n\t\"\"\"\n\twith open(filePath, \"rb\") as f:\n\t\tstring = f.read()\n\treturn string", "fn_id": 1, "class_fn": false, "repo": "Gaoyongxian666/Python-common", "file": "fileUtils.py", "last_update_at": "2019-12-26T02:49:05+00:00", "question_id": "7eceddef13801c878c30f3c472cc75fd73ad78d6_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def readStrFromFile(filePath):\n    \"\"\"\n\t\u4ece\u6587\u4ef6\u4e2d\u8bfb\u53d6\u5b57\u7b26\u4e32str\n\tparam filePath: \u6587\u4ef6\u8def\u5f84\n\treturn string : \u6587\u672c\u5b57\u7b26\u4e32\n\t\"\"\"\n    with open(filePath, 'rb') as f:\n        string = f.read()\n"]]}
{"hexsha": "883fd770cf1b721f8587c98d92695243f28f299c", "ext": "py", "lang": "Python", "content": "def print_info(msg):\n    \"\"\" print an informational message\n        msg can contain newlines if needed.\n    \"\"\"\n    lines = msg.split(\"\\n\")\n    click.secho(\"INFO: \" + (\"\\n      \".join(lines)), fg='white')", "fn_id": 12, "class_fn": false, "repo": "mkasa/taw", "file": "taw/util.py", "last_update_at": "2019-11-21T10:30:16+00:00", "question_id": "883fd770cf1b721f8587c98d92695243f28f299c_12", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def print_info(msg):\n    \"\"\" print an informational message\n        msg can contain newlines if needed.\n    \"\"\"\n    lines = msg.split('\\n')\n"]]}
{"hexsha": "76059e04225efb2185b89c25bc99860d1bb2401d", "ext": "py", "lang": "Python", "content": "def validate_tenant(cmd, namespace):\n    \"\"\"\n    Make sure tenant is a GUID. If domain name is provided, resolve to GUID.\n    https://docs.microsoft.com/en-us/azure/active-directory/develop/v2-protocols-oidc#fetch-the-openid-connect-metadata-document\n    \"\"\"\n    if namespace.tenant is not None and not _is_guid(namespace.tenant):\n        import requests\n        active_directory_endpoint = cmd.cli_ctx.cloud.endpoints.active_directory\n        url = '{}/{}/.well-known/openid-configuration'.format(active_directory_endpoint, namespace.tenant)\n        metadata = requests.get(url, verify=not should_disable_connection_verify()).json()\n\n        # Example issuer: https://sts.windows.net/72f988bf-86f1-41af-91ab-2d7cd011db47/\n        tenant_id = metadata['issuer'].split(\"/\")[3]\n\n        logger.debug('Resolve tenant domain name %s to GUID %s', namespace.tenant, tenant_id)\n        namespace.tenant = tenant_id", "fn_id": 1, "class_fn": false, "repo": "psignoret/azure-cli", "file": "src/azure-cli/azure/cli/command_modules/profile/_validators.py", "last_update_at": "2019-12-12T19:55:26+00:00", "question_id": "76059e04225efb2185b89c25bc99860d1bb2401d_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def validate_tenant(cmd, namespace):\n    \"\"\"\n    Make sure tenant is a GUID. If domain name is provided, resolve to GUID.\n    https://docs.microsoft.com/en-us/azure/active-directory/develop/v2-protocols-oidc#fetch-the-openid-connect-metadata-document\n    \"\"\"\n    if namespace.tenant is not None and (not _is_guid(namespace.tenant)):\n        import requests\n        active_directory_endpoint = cmd.cli_ctx.cloud.endpoints.active_directory\n        url = '{}/{}/.well-known/openid-configuration'.format(active_directory_endpoint, namespace.tenant)\n        metadata = requests.get(url, verify=not should_disable_connection_verify()).json()\n        tenant_id = metadata['issuer'].split('/')[3]\n        logger.debug('Resolve tenant domain name %s to GUID %s', namespace.tenant, tenant_id)\n"]]}
{"hexsha": "16b9d1d37c54317b50dfdee5ab5fb6e1d4c2af90", "ext": "py", "lang": "Python", "content": "def test_numpyarray():\n    for dtype1 in (\"i1\", \"i2\", \"i4\", \"i8\", \"u1\", \"u2\", \"u4\", \"u8\", \"f4\", \"f8\", \"?\"):\n        for dtype2 in (\"i1\", \"i2\", \"i4\", \"i8\", \"u1\", \"u2\", \"u4\", \"u8\", \"f4\", \"f8\", \"?\"):\n            for dtype3 in (\n                \"i1\",\n                \"i2\",\n                \"i4\",\n                \"i8\",\n                \"u1\",\n                \"u2\",\n                \"u4\",\n                \"u8\",\n                \"f4\",\n                \"f8\",\n                \"?\",\n            ):\n                for dtype4 in (\n                    \"i1\",\n                    \"i2\",\n                    \"i4\",\n                    \"i8\",\n                    \"u1\",\n                    \"u2\",\n                    \"u4\",\n                    \"u8\",\n                    \"f4\",\n                    \"f8\",\n                    \"?\",\n                ):\n                    one = np.array([0, 1, 2], dtype=dtype1)\n                    two = np.array([3, 0], dtype=dtype2)\n                    three = np.array([], dtype=dtype3)\n                    four = np.array([4, 5, 0, 6, 7], dtype=dtype4)\n                    combined = np.concatenate([one, two, three, four])\n\n                    ak_combined = ak.layout.NumpyArray(one).mergemany(\n                        [\n                            ak.layout.NumpyArray(two),\n                            ak.layout.NumpyArray(three),\n                            ak.layout.NumpyArray(four),\n                        ]\n                    )\n\n                    assert ak.to_list(ak_combined) == combined.tolist()\n                    assert ak.to_numpy(ak_combined).dtype == combined.dtype\n\n                    ak_combined = ak.layout.NumpyArray(one).mergemany(\n                        [\n                            ak.layout.NumpyArray(two),\n                            ak.layout.EmptyArray(),\n                            ak.layout.NumpyArray(four),\n                        ]\n                    )\n\n                    assert ak.to_list(ak_combined) == combined.tolist()\n                    assert (\n                        ak.to_numpy(ak_combined).dtype\n                        == np.concatenate([one, two, four]).dtype\n                    )", "fn_id": 0, "class_fn": false, "repo": "douglasdavis/awkward-1.0", "file": "tests/test_0449-merge-many-arrays-in-one-pass.py", "last_update_at": "2019-09-27T05:32:07+00:00", "question_id": "16b9d1d37c54317b50dfdee5ab5fb6e1d4c2af90_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_numpyarray():\n    for dtype1 in ('i1', 'i2', 'i4', 'i8', 'u1', 'u2', 'u4', 'u8', 'f4', 'f8', '?'):\n        for dtype2 in ('i1', 'i2', 'i4', 'i8', 'u1', 'u2', 'u4', 'u8', 'f4', 'f8', '?'):\n            for dtype3 in ('i1', 'i2', 'i4', 'i8', 'u1', 'u2', 'u4', 'u8', 'f4', 'f8', '?'):\n                for dtype4 in ('i1', 'i2', 'i4', 'i8', 'u1', 'u2', 'u4', 'u8', 'f4', 'f8', '?'):\n                    one = np.array([0, 1, 2], dtype=dtype1)\n                    two = np.array([3, 0], dtype=dtype2)\n                    three = np.array([], dtype=dtype3)\n                    four = np.array([4, 5, 0, 6, 7], dtype=dtype4)\n                    combined = np.concatenate([one, two, three, four])\n                    ak_combined = ak.layout.NumpyArray(one).mergemany([ak.layout.NumpyArray(two), ak.layout.NumpyArray(three), ak.layout.NumpyArray(four)])\n                    assert ak.to_list(ak_combined) == combined.tolist()\n                    assert ak.to_numpy(ak_combined).dtype == combined.dtype\n                    ak_combined = ak.layout.NumpyArray(one).mergemany([ak.layout.NumpyArray(two), ak.layout.EmptyArray(), ak.layout.NumpyArray(four)])\n                    assert ak.to_list(ak_combined) == combined.tolist()\n"]]}
{"hexsha": "c30ac5ef1835e2b761745642f33943630393bf9d", "ext": "py", "lang": "Python", "content": "def config_tempest(**kwargs):\n    # convert a list of remove values to a dict\n    remove = parse_values_to_remove(kwargs.get('remove', []))\n    add = parse_values_to_append(kwargs.get('append', []))\n    set_logging(kwargs.get('debug', False), kwargs.get('verbose', False))\n\n    accounts_path = kwargs.get('test_accounts')\n    if kwargs.get('create_accounts_file') is not None:\n        accounts_path = kwargs.get('create_accounts_file')\n    conf = TempestConf(write_credentials=accounts_path is None)\n    set_options(conf, kwargs.get('deployer_input'),\n                kwargs.get('non_admin', False),\n                kwargs.get('image_path', C.DEFAULT_IMAGE),\n                kwargs.get('overrides', []),\n                accounts_path,\n                kwargs.get('cloud_creds'))\n\n    credentials = Credentials(conf, not kwargs.get('non_admin', False))\n    clients = ClientManager(conf, credentials)\n    services = Services(clients, conf, credentials)\n\n    if kwargs.get('create', False) and kwargs.get('test_accounts') is None:\n        users = Users(clients.projects, clients.roles, clients.users, conf)\n        users.create_tempest_users()\n\n    if services.is_service(**{\"type\": \"compute\"}):\n        flavors = Flavors(clients.flavors, kwargs.get('create', False), conf,\n                          kwargs.get('flavor_min_mem', C.DEFAULT_FLAVOR_RAM),\n                          kwargs.get('flavor_min_disk', C.DEFAULT_FLAVOR_DISK),\n                          no_rng=kwargs.get('no_rng', False))\n        flavors.create_tempest_flavors()\n\n    if services.is_service(**{\"type\": \"image\"}):\n        image = services.get_service('image')\n        image.set_image_preferences(kwargs.get('image_disk_format',\n                                               C.DEFAULT_IMAGE_FORMAT),\n                                    kwargs.get('non_admin', False),\n                                    no_rng=kwargs.get('no_rng', False),\n                                    convert=kwargs.get('convert_to_raw',\n                                                       False))\n        image.create_tempest_images(conf)\n\n    if services.is_service(**{\"type\": \"network\"}):\n        network = services.get_service(\"network\")\n        network.create_tempest_networks(conf, kwargs.get('network_id'))\n\n    services.post_configuration()\n    services.set_supported_api_versions()\n    services.set_service_extensions()\n\n    if accounts_path is not None and kwargs.get('test_accounts') is None:\n        LOG.info(\"Creating an accounts.yaml file in: %s\", accounts_path)\n        accounts.create_accounts_file(kwargs.get('create', False),\n                                      accounts_path,\n                                      conf)\n\n    # remove all unwanted values if were specified\n    if remove != {}:\n        LOG.info(\"Removing configuration: %s\", str(remove))\n        conf.remove_values(remove)\n    if add != {}:\n        LOG.info(\"Adding configuration: %s\", str(add))\n        conf.append_values(add)\n    out_path = kwargs.get('out', 'etc/tempest.conf')\n    conf.write(out_path)", "fn_id": 11, "class_fn": false, "repo": "openstack/python-tempestconf", "file": "config_tempest/main.py", "last_update_at": "2019-11-11T11:01:27+00:00", "question_id": "c30ac5ef1835e2b761745642f33943630393bf9d_11", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def config_tempest(**kwargs):\n    remove = parse_values_to_remove(kwargs.get('remove', []))\n    add = parse_values_to_append(kwargs.get('append', []))\n    set_logging(kwargs.get('debug', False), kwargs.get('verbose', False))\n    accounts_path = kwargs.get('test_accounts')\n    if kwargs.get('create_accounts_file') is not None:\n        accounts_path = kwargs.get('create_accounts_file')\n    conf = TempestConf(write_credentials=accounts_path is None)\n    set_options(conf, kwargs.get('deployer_input'), kwargs.get('non_admin', False), kwargs.get('image_path', C.DEFAULT_IMAGE), kwargs.get('overrides', []), accounts_path, kwargs.get('cloud_creds'))\n    credentials = Credentials(conf, not kwargs.get('non_admin', False))\n    clients = ClientManager(conf, credentials)\n    services = Services(clients, conf, credentials)\n    if kwargs.get('create', False) and kwargs.get('test_accounts') is None:\n        users = Users(clients.projects, clients.roles, clients.users, conf)\n        users.create_tempest_users()\n    if services.is_service(**{'type': 'compute'}):\n        flavors = Flavors(clients.flavors, kwargs.get('create', False), conf, kwargs.get('flavor_min_mem', C.DEFAULT_FLAVOR_RAM), kwargs.get('flavor_min_disk', C.DEFAULT_FLAVOR_DISK), no_rng=kwargs.get('no_rng', False))\n        flavors.create_tempest_flavors()\n    if services.is_service(**{'type': 'image'}):\n        image = services.get_service('image')\n        image.set_image_preferences(kwargs.get('image_disk_format', C.DEFAULT_IMAGE_FORMAT), kwargs.get('non_admin', False), no_rng=kwargs.get('no_rng', False), convert=kwargs.get('convert_to_raw', False))\n        image.create_tempest_images(conf)\n    if services.is_service(**{'type': 'network'}):\n        network = services.get_service('network')\n        network.create_tempest_networks(conf, kwargs.get('network_id'))\n    services.post_configuration()\n    services.set_supported_api_versions()\n    services.set_service_extensions()\n    if accounts_path is not None and kwargs.get('test_accounts') is None:\n        LOG.info('Creating an accounts.yaml file in: %s', accounts_path)\n        accounts.create_accounts_file(kwargs.get('create', False), accounts_path, conf)\n    if remove != {}:\n        LOG.info('Removing configuration: %s', str(remove))\n        conf.remove_values(remove)\n    if add != {}:\n        LOG.info('Adding configuration: %s', str(add))\n        conf.append_values(add)\n    out_path = kwargs.get('out', 'etc/tempest.conf')\n"]]}
{"hexsha": "72ede3f0b4df0445ed7632e462b1c022df0aaa15", "ext": "py", "lang": "Python", "content": "def cross_correlation_plot(ticker, emps, srange=(-180, 180), smoothing=0, plot=True, resolution=1):\n    \"\"\"\n    Calculates the cross correlation plot and optimal lags\n    :param ticker: Stock ticker pandas.Series\n    :param emps: LinkedIn employment pandas.Series\n    :param srange: Tuple of timeshifts defining min and max\n    :param smoothing: Span parameter for exponential weighted smoothing function\n    :param plot: Bool, if True plots the cross correlation and dataframe\n    :param resolution: Step in timeshift within range\n    :return: Cleaned dataframe, location of optimal lag, correlation at optimal lag, list of calculated correlations\n    \"\"\"\n    cors = []\n    for shift in range(srange[0], srange[1], resolution):\n        df, cor = correlation(ticker, emps, shift, smoothing)\n        if len(df) < 100:\n            cors.append(np.nan)  # Too few datapoints to correlate\n        else:\n            cors.append(cor)\n\n    if np.isnan(cors).all():\n        print(\"Can't calculate correlaction\")\n        return (None, None, None, None)\n\n    max_cor = np.nanmax(cors)\n    max_lag = range(srange[0], srange[1], resolution)[np.nanargmax(cors)]\n\n    print('Max correlation at t=' + str(max_lag))\n    print('Max correlation:' + str(max_cor))\n\n    df, cor = correlation(ticker, emps, max_lag, smoothing=smoothing)\n\n    if plot:\n        fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n        plt.title(ticker.name)\n        ax[0].plot(range(srange[0], srange[1], resolution), cors, marker='.', linestyle='None', alpha=0.5)\n        df.plot(ax=ax[1])\n        ax[0].set_xlabel('Time shift of series (Negative is LinkedIn employee count leading stock price)')\n        ax[0].set_ylabel('Series Cross Correlation')\n        ax[1].set_ylabel('Normalized price / employee count')\n\n    return df, max_lag, max_cor, cors", "fn_id": 1, "class_fn": false, "repo": "arms3/Jobs-Stock-Price_Prediction", "file": "cross_correlation.py", "last_update_at": "2019-01-20T23:15:57+00:00", "question_id": "72ede3f0b4df0445ed7632e462b1c022df0aaa15_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def cross_correlation_plot(ticker, emps, srange=(-180, 180), smoothing=0, plot=True, resolution=1):\n    \"\"\"\n    Calculates the cross correlation plot and optimal lags\n    :param ticker: Stock ticker pandas.Series\n    :param emps: LinkedIn employment pandas.Series\n    :param srange: Tuple of timeshifts defining min and max\n    :param smoothing: Span parameter for exponential weighted smoothing function\n    :param plot: Bool, if True plots the cross correlation and dataframe\n    :param resolution: Step in timeshift within range\n    :return: Cleaned dataframe, location of optimal lag, correlation at optimal lag, list of calculated correlations\n    \"\"\"\n    cors = []\n    for shift in range(srange[0], srange[1], resolution):\n        df, cor = correlation(ticker, emps, shift, smoothing)\n        if len(df) < 100:\n            cors.append(np.nan)\n        else:\n            cors.append(cor)\n    if np.isnan(cors).all():\n        print(\"Can't calculate correlaction\")\n        return (None, None, None, None)\n    max_cor = np.nanmax(cors)\n    max_lag = range(srange[0], srange[1], resolution)[np.nanargmax(cors)]\n    print('Max correlation at t=' + str(max_lag))\n    print('Max correlation:' + str(max_cor))\n    df, cor = correlation(ticker, emps, max_lag, smoothing=smoothing)\n    if plot:\n        fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n        plt.title(ticker.name)\n        ax[0].plot(range(srange[0], srange[1], resolution), cors, marker='.', linestyle='None', alpha=0.5)\n        df.plot(ax=ax[1])\n        ax[0].set_xlabel('Time shift of series (Negative is LinkedIn employee count leading stock price)')\n        ax[0].set_ylabel('Series Cross Correlation')\n        ax[1].set_ylabel('Normalized price / employee count')\n"]]}
{"hexsha": "19849eb0845aa6a14f76fdb2455c1645b497a337", "ext": "py", "lang": "Python", "content": "def analyze_swaps(data):\n    swaps = defaultdict(lambda: 0)\n    frequency = defaultdict(lambda: 0)\n    frequency_count = 0\n    for elem in data:\n        orig_labels = elem['groundtruth']\n        reco_labels = elem['recognized']\n        for i in xrange(len(orig_labels)):\n            frequency[orig_labels[i]] += 1\n            frequency_count += 1\n            if orig_labels[i] != reco_labels[i]:\n                swaps[(orig_labels[i], reco_labels[i])] += 1\n    print(\"Frequency:\")\n    frequency = sorted(frequency.items(), key=operator.itemgetter(1), reverse=True)\n    for (label,count) in frequency:\n        print(\"\\t{}: {:.3f}\".format(label, count / float(frequency_count)))\n\n    print(\"Swaps:\")\n    swaps = sorted(swaps.items(), key=operator.itemgetter(1), reverse=True)\n    for swap in swaps:\n        print(\"\\t{} -> {} : {}\".format(swap[0][0], swap[0][1], swap[1]))", "fn_id": 3, "class_fn": false, "repo": "mzapotoczny/dependency-parser", "file": "exp/dependency/analyze_data.py", "last_update_at": "2019-10-26T13:08:23+00:00", "question_id": "19849eb0845aa6a14f76fdb2455c1645b497a337_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def analyze_swaps(data):\n    swaps = defaultdict(lambda: 0)\n    frequency = defaultdict(lambda: 0)\n    frequency_count = 0\n    for elem in data:\n        orig_labels = elem['groundtruth']\n        reco_labels = elem['recognized']\n        for i in xrange(len(orig_labels)):\n            frequency[orig_labels[i]] += 1\n            frequency_count += 1\n            if orig_labels[i] != reco_labels[i]:\n                swaps[orig_labels[i], reco_labels[i]] += 1\n    print('Frequency:')\n    frequency = sorted(frequency.items(), key=operator.itemgetter(1), reverse=True)\n    for label, count in frequency:\n        print('\\t{}: {:.3f}'.format(label, count / float(frequency_count)))\n    print('Swaps:')\n    swaps = sorted(swaps.items(), key=operator.itemgetter(1), reverse=True)\n    for swap in swaps:\n"]]}
{"hexsha": "5865be0e0b12adc728219da9a099f1f6a15a73ce", "ext": "py", "lang": "Python", "content": "def print_test_accuracy(show_example_errors=False,\n                        show_confusion_matrix=False):\n\n    # For all the images in the test-set,\n    # calculate the predicted classes and whether they are correct.\n    correct, cls_pred = predict_cls_test()\n\n    # Classification accuracy and the number of correct classifications.\n    acc, num_correct = cls_accuracy(correct)\n    \n    # Number of images being classified.\n    num_images = len(correct)\n\n    # Print the accuracy.\n    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n    print(msg.format(acc, num_correct, num_images))\n\n    # Plot some examples of mis-classifications, if desired.\n    if show_example_errors:\n        print(\"Example errors:\")\n        plot_example_errors(cls_pred=cls_pred, correct=correct)\n\n    # Plot the confusion matrix, if desired.\n    if show_confusion_matrix:\n        print(\"Confusion Matrix:\")\n        plot_confusion_matrix(cls_pred=cls_pred)", "fn_id": 3, "class_fn": false, "repo": "PYPIT/spit", "file": "spit/test.py", "last_update_at": "2019-07-02T18:28:55+00:00", "question_id": "5865be0e0b12adc728219da9a099f1f6a15a73ce_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def print_test_accuracy(show_example_errors=False, show_confusion_matrix=False):\n    correct, cls_pred = predict_cls_test()\n    acc, num_correct = cls_accuracy(correct)\n    num_images = len(correct)\n    msg = 'Accuracy on Test-Set: {0:.1%} ({1} / {2})'\n    print(msg.format(acc, num_correct, num_images))\n    if show_example_errors:\n        print('Example errors:')\n        plot_example_errors(cls_pred=cls_pred, correct=correct)\n    if show_confusion_matrix:\n        print('Confusion Matrix:')\n"]]}
{"hexsha": "a27b763f8eed3d166bd5de2f343e2225f312b1cc", "ext": "py", "lang": "Python", "content": "def SetClient(ip, port):\n\taddress = (ip, port)\n\tsock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # sock = socket.socket()  \n\tsock.connect(address) \n\treturn sock", "fn_id": 5, "class_fn": false, "repo": "ChiFang/FaceAnalyzing", "file": "SocketFunc.py", "last_update_at": "2019-04-17T18:19:52+00:00", "question_id": "a27b763f8eed3d166bd5de2f343e2225f312b1cc_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def SetClient(ip, port):\n    address = (ip, port)\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    sock.connect(address)\n"]]}
{"hexsha": "26e8e774cd29bfc5a8f663013a9a38404d393b76", "ext": "py", "lang": "Python", "content": "def main():\n\targs = handleArgs()\n\timgs_folder = args['path']\n\n\tprint('Searching {0!s} for images'.format(imgs_folder))\n\n\t# calibration_images = '%s/left*.jpg' % (imgs_folder)\n\tcalibration_images = '{0!s}/shot_*.png'.format((imgs_folder))\n\timages = []\n\timages = glob.glob(calibration_images)\n\n\tprint('Number images found: {0:d}'.format(len(images)))\n\t# print(images)\n\n\tcal = CameraCalibration()\n\tcal.save_file = args['matrix']\n\tcal.marker_size = (args['target_size'][0], args['target_size'][1])\n\n\tprint('Marker size:', cal.marker_size)\n\n\tif args['target'] == 'chessboard':\n\t\tcal.marker_checkerboard = True\n\telse:\n\t\tcal.marker_checkerboard = False\n\tcal.calibrate(images)\n\n\tcal.printMat()\n\n\t# save data to file\n\tcal.save('calibration.npy')\n\n\t# -----------------------------------------------------------------\n\n\t# read back in\n\tcal.read('calibration.npy')\n\n\t# crop the image\n\t# x,y,w,h = roi\n\t# crop the distorted edges off\n\t# # dst = dst[y:y+h, x:x+w]\n\t# cv2.imwrite('calibresult.png',dst)\n\n\timage = cv2.imread(images[0], 0)\n\tdst = cal.undistort(image)\n\tcv2.imshow('calibrated image', dst)\n\t# cv2.imshow('original image', image)\n\tcv2.waitKey(0)\n\n\tcv2.destroyAllWindows()", "fn_id": 1, "class_fn": false, "repo": "MomsFriendlyRobotCompany/opencvutils", "file": "bin/camera_calibrate.py", "last_update_at": "2019-05-07T09:01:25+00:00", "question_id": "26e8e774cd29bfc5a8f663013a9a38404d393b76_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main():\n    args = handleArgs()\n    imgs_folder = args['path']\n    print('Searching {0!s} for images'.format(imgs_folder))\n    calibration_images = '{0!s}/shot_*.png'.format(imgs_folder)\n    images = []\n    images = glob.glob(calibration_images)\n    print('Number images found: {0:d}'.format(len(images)))\n    cal = CameraCalibration()\n    cal.save_file = args['matrix']\n    cal.marker_size = (args['target_size'][0], args['target_size'][1])\n    print('Marker size:', cal.marker_size)\n    if args['target'] == 'chessboard':\n        cal.marker_checkerboard = True\n    else:\n        cal.marker_checkerboard = False\n    cal.calibrate(images)\n    cal.printMat()\n    cal.save('calibration.npy')\n    cal.read('calibration.npy')\n    image = cv2.imread(images[0], 0)\n    dst = cal.undistort(image)\n    cv2.imshow('calibrated image', dst)\n    cv2.waitKey(0)\n"]]}
{"hexsha": "bcc4525616e57f69b4ac7a064584ea128fdfc351", "ext": "py", "lang": "Python", "content": "async def test_example():\n    conn = await aiomysql.connect(\n\n            host=os.environ.get('HOSTNAME'),\n            user=os.environ.get('USERNAME'),\n            port=int(os.environ.get('PORT')),\n            password=os.environ.get('PASSWORD'),\n            db=os.environ.get('DATABASE')\n    )\n\n    async with conn.cursor() as cur:\n        await cur.execute(\"SELECT * FROM guild_settings\")\n        print(cur.description)\n        r = await cur.fetchall()\n        print(r)\n    conn.close()\n    return r", "fn_id": 0, "class_fn": false, "repo": "RohanRadia/YukiBot", "file": "bot/testdb.py", "last_update_at": "2019-04-18T09:22:00+00:00", "question_id": "bcc4525616e57f69b4ac7a064584ea128fdfc351_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["async def test_example():\n    conn = await aiomysql.connect(host=os.environ.get('HOSTNAME'), user=os.environ.get('USERNAME'), port=int(os.environ.get('PORT')), password=os.environ.get('PASSWORD'), db=os.environ.get('DATABASE'))\n    async with conn.cursor() as cur:\n        await cur.execute('SELECT * FROM guild_settings')\n        print(cur.description)\n        r = await cur.fetchall()\n        print(r)\n    conn.close()\n"]]}
{"hexsha": "b4b43a8392d0261cde1a0313b6522209eb4356d3", "ext": "py", "lang": "Python", "content": "@main.command()\n@click.argument(\"issue_key\", type=str)\ndef rm(issue_key):\n    config = read_config()\n    conn = get_conn(config)\n    issue = get_issue_by_key(conn, issue_key)\n    issue.delete()", "fn_id": 9, "class_fn": false, "repo": "cfmeyers/kujira", "file": "kujira/cli.py", "last_update_at": "2019-07-12T14:13:51+00:00", "question_id": "b4b43a8392d0261cde1a0313b6522209eb4356d3_9", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@main.command()\n@click.argument('issue_key', type=str)\ndef rm(issue_key):\n    config = read_config()\n    conn = get_conn(config)\n    issue = get_issue_by_key(conn, issue_key)\n"]]}
{"hexsha": "f74eace79f4f8bf8c10bb8c07aba841d848d9d58", "ext": "py", "lang": "Python", "content": "@pytest.mark.skip(\"https://github.com/rotkehlchenio/rotkehlchen/issues/377\")\n@pytest.mark.parametrize('should_mock_price_queries', [False])\ndef test_price_queries(price_historian):\n    \"\"\"Test some cryptocompare price queries making sure our querying mechanism works\"\"\"\n    # TODO: Get rid of the cache here and then try again with the cache\n    # TODO2: Once historical price of DASH and other token stabilize perhaps also\n    #        include them in the tests\n    do_queries_for(A_BTC, A_EUR, price_historian)\n    do_queries_for(A_ETH, A_EUR, price_historian)", "fn_id": 2, "class_fn": false, "repo": "esaulkov/rotkehlchen", "file": "rotkehlchen/tests/test_price_history.py", "last_update_at": "2019-08-04T08:30:14+00:00", "question_id": "f74eace79f4f8bf8c10bb8c07aba841d848d9d58_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.mark.skip('https://github.com/rotkehlchenio/rotkehlchen/issues/377')\n@pytest.mark.parametrize('should_mock_price_queries', [False])\ndef test_price_queries(price_historian):\n    \"\"\"Test some cryptocompare price queries making sure our querying mechanism works\"\"\"\n    do_queries_for(A_BTC, A_EUR, price_historian)\n"]]}
{"hexsha": "725ebbbbdb4cbc3d0e76dbdbd9e1ae325f4efbb1", "ext": "py", "lang": "Python", "content": "def test_dtype_category():\n    \"\"\"Test that categorical variables of dtype category are supported.\"\"\"\n    # Setup\n    data = pd.DataFrame({'a': ['a', 'b', 'c']}, dtype='category')\n\n    # Run\n    ht = HyperTransformer()\n    ht.detect_initial_config(data)\n    ht.fit(data)\n    transformed = ht.transform(data)\n    reverse = ht.reverse_transform(transformed)\n\n    # Assert\n    pd.testing.assert_frame_equal(reverse, data)", "fn_id": 5, "class_fn": false, "repo": "HDI-Project/RDT", "file": "tests/integration/test_hyper_transformer.py", "last_update_at": "2019-02-19T08:48:53+00:00", "question_id": "725ebbbbdb4cbc3d0e76dbdbd9e1ae325f4efbb1_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_dtype_category():\n    \"\"\"Test that categorical variables of dtype category are supported.\"\"\"\n    data = pd.DataFrame({'a': ['a', 'b', 'c']}, dtype='category')\n    ht = HyperTransformer()\n    ht.detect_initial_config(data)\n    ht.fit(data)\n    transformed = ht.transform(data)\n    reverse = ht.reverse_transform(transformed)\n"]]}
{"hexsha": "ab0cd55646c58aabfd0f34b5dd50c3e2d5945efb", "ext": "py", "lang": "Python", "content": "def test_journeys_organisation_weekday(load_org):\n    date = datetime.date(2019, 4, 8)\n    result = _query_journeys(SERVICE, DIRECTION, date).all()\n\n    # Services associated with organisations still only run on specified days\n    assert not result", "fn_id": 14, "class_fn": false, "repo": "macph/nextbus", "file": "tests/test_timetable.py", "last_update_at": "2019-10-17T19:40:35+00:00", "question_id": "ab0cd55646c58aabfd0f34b5dd50c3e2d5945efb_14", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_journeys_organisation_weekday(load_org):\n    date = datetime.date(2019, 4, 8)\n    result = _query_journeys(SERVICE, DIRECTION, date).all()\n"]]}
{"hexsha": "8bade1deeb24afd4b054cc023315e1438a266c8b", "ext": "py", "lang": "Python", "content": "def get_args():\n    parser = argparse.ArgumentParser(description='Echo')\n    parser.add_argument('host', default=HOST, help='', nargs='?')\n    parser.add_argument('port', default=PORT,\n                        help='Port',\n                        nargs='?')\n\n    args = parser.parse_args()\n\n    return args", "fn_id": 1, "class_fn": false, "repo": "kandarpck/networksecurity2018", "file": "pytest/pytest_8ballserver.py", "last_update_at": "2019-06-13T15:24:41+00:00", "question_id": "8bade1deeb24afd4b054cc023315e1438a266c8b_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_args():\n    parser = argparse.ArgumentParser(description='Echo')\n    parser.add_argument('host', default=HOST, help='', nargs='?')\n    parser.add_argument('port', default=PORT, help='Port', nargs='?')\n    args = parser.parse_args()\n"]]}
{"hexsha": "ccdf401e1a4453f505cfc4bbb99545ffdce75458", "ext": "py", "lang": "Python", "content": "def filter_created_range(qs, _, value):\n    gte, lte = value.get(\"gte\"), value.get(\"lte\")\n    if gte:\n        qs = qs.filter(created__date__gte=gte)\n    if lte:\n        qs = qs.filter(created__date__lte=lte)\n    return qs", "fn_id": 2, "class_fn": false, "repo": "dnordio/saleor", "file": "saleor/graphql/order/filters.py", "last_update_at": "2019-05-02T17:24:05+00:00", "question_id": "ccdf401e1a4453f505cfc4bbb99545ffdce75458_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def filter_created_range(qs, _, value):\n    gte, lte = (value.get('gte'), value.get('lte'))\n    if gte:\n        qs = qs.filter(created__date__gte=gte)\n    if lte:\n        qs = qs.filter(created__date__lte=lte)\n"]]}
{"hexsha": "5272ecc406dad5983dea69832350714c88f9489d", "ext": "py", "lang": "Python", "content": "def send_data(ip, port, data):\n\ttry:\n\t\ts = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n\t\ts.connect((ip, port))\n\t\ts.send(data)\n\t\ts.close()\n\texcept socket.error:\n\t\traise Exception(\"[*] Error: No se pudo conectar al socket deseado\")", "fn_id": 0, "class_fn": false, "repo": "dario617/RSE-Puppy-bot", "file": "internalCheck/sender.py", "last_update_at": "2019-11-27T15:43:00+00:00", "question_id": "5272ecc406dad5983dea69832350714c88f9489d_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def send_data(ip, port, data):\n    try:\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.connect((ip, port))\n        s.send(data)\n        s.close()\n    except socket.error:\n"]]}
{"hexsha": "5e4b90fe411751f3e5ee9d027575bcbed4bd649d", "ext": "py", "lang": "Python", "content": "def es_cadena_valida(adn):\n    \"\"\"\n    (str)-> boolean\n\n    >>> es_cadena_valida(\"ACT\")\n    True\n    >>> es_cadena_valida(\"XYZ\")\n    False\n    >>> es_cadena_valida(\"TSG\")\n    False\n\n    Valida si una cadena es valida o no\n\n    :param adn: String La cadena ingresada a evaluar\n    :return: retorna Boolean TRUE si la cadena es valida o FLASE si es incorrecta\n    \"\"\"\n    for caracter in adn:\n        if not es_base(caracter):\n            return False\n    return True", "fn_id": 4, "class_fn": false, "repo": "pcaball71927/Proyecto2Programacion20191", "file": "adn.py", "last_update_at": "2019-04-02T04:09:36+00:00", "question_id": "5e4b90fe411751f3e5ee9d027575bcbed4bd649d_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def es_cadena_valida(adn):\n    \"\"\"\n    (str)-> boolean\n\n    >>> es_cadena_valida(\"ACT\")\n    True\n    >>> es_cadena_valida(\"XYZ\")\n    False\n    >>> es_cadena_valida(\"TSG\")\n    False\n\n    Valida si una cadena es valida o no\n\n    :param adn: String La cadena ingresada a evaluar\n    :return: retorna Boolean TRUE si la cadena es valida o FLASE si es incorrecta\n    \"\"\"\n    for caracter in adn:\n        if not es_base(caracter):\n            return False\n"]]}
{"hexsha": "6b9c14472495851ac67e4282969ef3aee4d1ddcb", "ext": "py", "lang": "Python", "content": "def chanceX(dice, x):\n    # first, set up base cases\n    # account for only one die passed\n    # also accounts for recursive base\n    if isinstance(dice, tuple):\n        dice = list(dice)\n    if not isinstance(dice, list):\n        dice = [dice]\n\n    # each die can be at the minimum 1, so the sum cannot be less than the number of dice\n    if x < len(dice):\n        return 0\n\n    # is it possible for the dice to sum up to x?\n    max = 0\n    for die in dice:\n        max += die\n    if max < x:\n        return 0\n\n    if len(dice) == 1:\n        if dice[0] < x:\n            return 0 # cannot roll x, as dice has no side for it\n        else:\n            return 1 / dice[0] # one side has x\n    \"\"\"\n    For multiple dice,\n    compute the chance recursively.\n    There may be a way to do this\n    iteratively, or with a basic formula,\n    but I'm not sure how I would do that.\n    I assume the chance corresponds to the surface area of a plane,\n    as when the rolls required are graphed in cartesian coordinates,\n    the points form a slanted plane.\n    \"\"\"\n    chance = 0\n    otherDice = dice.copy()\n    lockedIn = otherDice.pop() # removes last die\n\n    # vary the value of the die removed\n    for i in range(1, lockedIn + 1):\n        # compute the probability that the other dice can sum to the x after the locked in value is added\n        chanceOthers = chanceX(otherDice, x - i)\n        #print(\"The chance of rolling {} using {}, given {} is {}\".format(x, otherDice, i, chanceOthers / lockedIn))\n        chance += chanceOthers / lockedIn # || to chances together\n        # chance to roll (x -i) times the chance to roll with the other dice, times the chance to roll i with this die\n\n    return chance", "fn_id": 0, "class_fn": false, "repo": "Matt-Crow/SmallPythonPrograms", "file": "diceChance.py", "last_update_at": "2019-12-11T21:56:59+00:00", "question_id": "6b9c14472495851ac67e4282969ef3aee4d1ddcb_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def chanceX(dice, x):\n    if isinstance(dice, tuple):\n        dice = list(dice)\n    if not isinstance(dice, list):\n        dice = [dice]\n    if x < len(dice):\n        return 0\n    max = 0\n    for die in dice:\n        max += die\n    if max < x:\n        return 0\n    if len(dice) == 1:\n        if dice[0] < x:\n            return 0\n        else:\n            return 1 / dice[0]\n    \"\\n    For multiple dice,\\n    compute the chance recursively.\\n    There may be a way to do this\\n    iteratively, or with a basic formula,\\n    but I'm not sure how I would do that.\\n    I assume the chance corresponds to the surface area of a plane,\\n    as when the rolls required are graphed in cartesian coordinates,\\n    the points form a slanted plane.\\n    \"\n    chance = 0\n    otherDice = dice.copy()\n    lockedIn = otherDice.pop()\n    for i in range(1, lockedIn + 1):\n        chanceOthers = chanceX(otherDice, x - i)\n        chance += chanceOthers / lockedIn\n"]]}
{"hexsha": "2a9dc6426014f9522215548d1e14daf472274ee1", "ext": "py", "lang": "Python", "content": "def update_proteinsequenceannotation(nex_session, dbentity_id, taxonomy_id, contig_id, seq_version, genomerelease_id, file_header, seq):\n\n    print (\"Update protein:\", dbentity_id, taxonomy_id, contig_id, seq_version, genomerelease_id, file_header, seq)\n    \n    x = nex_session.query(Proteinsequenceannotation).filter_by(dbentity_id=dbentity_id, taxonomy_id=taxonomy_id, contig_id=contig_id).one_or_none()\n    if x is None:\n        print (\"No Proteinsequenceannotation row found for dbentity_id=\", dbentity_id, \", taxonomy_id=\", taxonomy_id, \", contig_id=\", contig_id)\n    x.seq_version = seq_version\n    x.genomerelease_id = genomerelease_id\n    x.file_header = file_header\n    x.residues = seq\n    nex_session.add(x)         ", "fn_id": 1, "class_fn": false, "repo": "dougli1sqrd/SGDBackend-Nex2", "file": "scripts/loading/sequence/updateExistingFeatures_R64-3.py", "last_update_at": "2019-11-06T17:48:13+00:00", "question_id": "2a9dc6426014f9522215548d1e14daf472274ee1_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def update_proteinsequenceannotation(nex_session, dbentity_id, taxonomy_id, contig_id, seq_version, genomerelease_id, file_header, seq):\n    print('Update protein:', dbentity_id, taxonomy_id, contig_id, seq_version, genomerelease_id, file_header, seq)\n    x = nex_session.query(Proteinsequenceannotation).filter_by(dbentity_id=dbentity_id, taxonomy_id=taxonomy_id, contig_id=contig_id).one_or_none()\n    if x is None:\n        print('No Proteinsequenceannotation row found for dbentity_id=', dbentity_id, ', taxonomy_id=', taxonomy_id, ', contig_id=', contig_id)\n    x.seq_version = seq_version\n    x.genomerelease_id = genomerelease_id\n    x.file_header = file_header\n    x.residues = seq\n"]]}
{"hexsha": "2792a0709a569714392afdcea2c2862d0bea2e03", "ext": "py", "lang": "Python", "content": "def install(externalsdir, installdir, builddir):\n  # installdir = \"/usr/local\"\n  pi = PackageInstall(os.path.join(externalsdir, \"Xdmf_13_02_2018.tgz\"), installdir, builddir)\n  os.environ[\"HDF5_ROOT\"] = \"/usr/local\"\n  #XDMF_WRAP_PYTHON\n  cmakeoptions=\"-DBUILD_SHARED_LIBS=1 -DXDMF_WRAP_PYTHON=1 -Wno-dev -DXDMF_BUILD_TESTING=1\"\n  pi.install_cmake(cmakeoptions=cmakeoptions)", "fn_id": 0, "class_fn": false, "repo": "beckerrh/simfemsrc", "file": "External/Xdmf_install.py", "last_update_at": "2019-01-31T10:59:11+00:00", "question_id": "2792a0709a569714392afdcea2c2862d0bea2e03_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def install(externalsdir, installdir, builddir):\n    pi = PackageInstall(os.path.join(externalsdir, 'Xdmf_13_02_2018.tgz'), installdir, builddir)\n    os.environ['HDF5_ROOT'] = '/usr/local'\n    cmakeoptions = '-DBUILD_SHARED_LIBS=1 -DXDMF_WRAP_PYTHON=1 -Wno-dev -DXDMF_BUILD_TESTING=1'\n"]]}
{"hexsha": "ffc2bf43fd107f0d6feb4cf24564e2deca3e57a5", "ext": "py", "lang": "Python", "content": "def youtube_command(message, handler, args):\n    try:\n        '''\n        voice = handler.client.join_voice_channel(message.author.voice_channel)\n        player = voice.create_ytdl_player('https://www.youtube.com/watch?v=d62TYemN6MQ')\n        player.start()\n        '''\n        return \":microphone: Lets Rock 'n Roll :notes:\"\n    except Exception as e:\n        template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n        message = template.format(type(e).__name__, e.args)\n        print(message)", "fn_id": 7, "class_fn": false, "repo": "Marantesss/discord-bot-ronaldino", "file": "src/commands.py", "last_update_at": "2019-03-25T13:53:16+00:00", "question_id": "ffc2bf43fd107f0d6feb4cf24564e2deca3e57a5_7", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def youtube_command(message, handler, args):\n    try:\n        \"\\n        voice = handler.client.join_voice_channel(message.author.voice_channel)\\n        player = voice.create_ytdl_player('https://www.youtube.com/watch?v=d62TYemN6MQ')\\n        player.start()\\n        \"\n        return \":microphone: Lets Rock 'n Roll :notes:\"\n    except Exception as e:\n        template = 'An exception of type {0} occurred. Arguments:\\n{1!r}'\n        message = template.format(type(e).__name__, e.args)\n"]]}
{"hexsha": "52b7a9b3d521ecd2170c2282c7b86cccfa2131c6", "ext": "py", "lang": "Python", "content": "def main():\n    grid = []\n    with open('input', 'r') as fp:\n        for line in fp.read().split('\\n'):\n            grid.append([strToInt(c) for c in line])\n    gridLen = len(grid)\n    frame = 0\n    \n    while frame < 100:\n        newGrid = [[0 for _ in range(gridLen)] for _ in range(gridLen)]\n        for x in range(gridLen):\n            for y in range(gridLen):\n                s = getArround(grid, x, y)\n                if (s == 2 or s == 3) and grid[x][y] == 1:\n                    newGrid[x][y] = 1\n                elif s == 3 and grid[x][y] == 0:\n                    newGrid[x][y] = 1\n                # enable this condition for part 2\n                # elif (x,y) in [(0,0), (0, gridLen-1), (gridLen-1, 0), (gridLen-1, gridLen-1)]:\n                #     newGrid[x][y] = 1\n                else:\n                    newGrid[x][y] = 0\n        grid = newGrid\n        frame += 1\n\n    total = 0\n    for line in grid:\n        total += sum(line)\n\n    print(total)", "fn_id": 2, "class_fn": false, "repo": "smolsbs/aoc", "file": "2015/day-18/day18.py", "last_update_at": "2019-12-02T20:20:41+00:00", "question_id": "52b7a9b3d521ecd2170c2282c7b86cccfa2131c6_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main():\n    grid = []\n    with open('input', 'r') as fp:\n        for line in fp.read().split('\\n'):\n            grid.append([strToInt(c) for c in line])\n    gridLen = len(grid)\n    frame = 0\n    while frame < 100:\n        newGrid = [[0 for _ in range(gridLen)] for _ in range(gridLen)]\n        for x in range(gridLen):\n            for y in range(gridLen):\n                s = getArround(grid, x, y)\n                if (s == 2 or s == 3) and grid[x][y] == 1:\n                    newGrid[x][y] = 1\n                elif s == 3 and grid[x][y] == 0:\n                    newGrid[x][y] = 1\n                else:\n                    newGrid[x][y] = 0\n        grid = newGrid\n        frame += 1\n    total = 0\n    for line in grid:\n        total += sum(line)\n"]]}
{"hexsha": "9fb6e7df49c4e149bd7c60ce791a91ccb54db62a", "ext": "py", "lang": "Python", "content": "def list_folders(vignore, path):\n    # get all folders\n    folders = [x for x in os.listdir(path) if os.path.isdir(join(path, x))]\n    # folders = list(filter(lambda x: False if vignore(join(path, x)) else True, folders))\n    folders = list(filter(lambda x: False if x == \"src\" or x[0] == \".\" else True, folders))\n    return folders", "fn_id": 1, "class_fn": false, "repo": "Tloru/PyBlog", "file": "app/routes.py", "last_update_at": "2019-05-16T03:39:41+00:00", "question_id": "9fb6e7df49c4e149bd7c60ce791a91ccb54db62a_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def list_folders(vignore, path):\n    folders = [x for x in os.listdir(path) if os.path.isdir(join(path, x))]\n    folders = list(filter(lambda x: False if x == 'src' or x[0] == '.' else True, folders))\n"]]}
{"hexsha": "86d955c0aa4609abdac84b46f4da17969c3a904d", "ext": "py", "lang": "Python", "content": "def smart_str(s, encoding='utf8'):\n    \"\"\" Convert unicode to str. If s is str, return itself.\n    >>> smart_str(u'')\n    ''\n    >>> smart_str(u'abc')\n    'abc'\n    >>> smart_str(u'\\u4f60\\u597d') ==  '\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd'\n    True\n    >>> smart_str('abc')\n    'abc'\n    >>> smart_str('\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd') == '\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd'\n    True\n    \"\"\"\n    if isinstance(s, str):\n        return s\n    return s.encode(encoding)", "fn_id": 1, "class_fn": false, "repo": "dimyme/OpenBazaar-Server", "file": "api/utils.py", "last_update_at": "2019-01-26T10:59:50+00:00", "question_id": "86d955c0aa4609abdac84b46f4da17969c3a904d_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def smart_str(s, encoding='utf8'):\n    \"\"\" Convert unicode to str. If s is str, return itself.\n    >>> smart_str(u'')\n    ''\n    >>> smart_str(u'abc')\n    'abc'\n    >>> smart_str(u'\u4f60\u597d') ==  '\u00e4\u00bd\\xa0\u00e5\u00a5\u00bd'\n    True\n    >>> smart_str('abc')\n    'abc'\n    >>> smart_str('\u00e4\u00bd\\xa0\u00e5\u00a5\u00bd') == '\u00e4\u00bd\\xa0\u00e5\u00a5\u00bd'\n    True\n    \"\"\"\n    if isinstance(s, str):\n        return s\n"]]}
{"hexsha": "181875788a6e9712e36f588155033bf53d309f5a", "ext": "py", "lang": "Python", "content": "@login_in\n# \u7ed9\u7535\u5f71\u8fdb\u884c\u8bc4\u8bba\ndef make_comment(request, movie_id):\n    user = User.objects.get(id=request.session.get(\"user_id\"))\n    movie = Movie.objects.get(id=movie_id)\n    comment = request.POST.get(\"comment\")\n    Comment.objects.create(user=user, movie=movie, content=comment)\n    return redirect(reverse(\"movie\", args=(movie_id,)))", "fn_id": 16, "class_fn": false, "repo": "a81940595/DNN", "file": "views.py", "last_update_at": "2019-06-20T06:55:40+00:00", "question_id": "181875788a6e9712e36f588155033bf53d309f5a_16", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@login_in\ndef make_comment(request, movie_id):\n    user = User.objects.get(id=request.session.get('user_id'))\n    movie = Movie.objects.get(id=movie_id)\n    comment = request.POST.get('comment')\n    Comment.objects.create(user=user, movie=movie, content=comment)\n"]]}
{"hexsha": "2a857724911d0a4211d79737e630d72d68a9fbd4", "ext": "py", "lang": "Python", "content": "def _handle_error(response):\n    if response.status_code == 429:\n        raise errors.RateLimitException(response)\n\n    body = None\n    try:\n        body = response.json()\n    except ValueError:\n        raise errors.PDFShiftException('Invalid response from the server.', 500)\n\n    if body.get('code') == 400:\n        if body.get('message', None):\n            raise errors.InvalidRequestException(body.get('error'))\n\n        raise errors.InvalidRequestException(body.get('errors'))\n\n    if str(body.get('code')) in errors.codes:\n        raise getattr(errors, errors.codes.get(str(body['code'])))()\n\n    raise errors.PDFShiftException('An unknown error occured.', 500)", "fn_id": 0, "class_fn": false, "repo": "pdfshift/pdfshift-python", "file": "pdfshift/__init__.py", "last_update_at": "2019-10-03T21:03:14+00:00", "question_id": "2a857724911d0a4211d79737e630d72d68a9fbd4_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _handle_error(response):\n    if response.status_code == 429:\n        raise errors.RateLimitException(response)\n    body = None\n    try:\n        body = response.json()\n    except ValueError:\n        raise errors.PDFShiftException('Invalid response from the server.', 500)\n    if body.get('code') == 400:\n        if body.get('message', None):\n            raise errors.InvalidRequestException(body.get('error'))\n        raise errors.InvalidRequestException(body.get('errors'))\n    if str(body.get('code')) in errors.codes:\n        raise getattr(errors, errors.codes.get(str(body['code'])))()\n"]]}
{"hexsha": "e00b74faa37845674d4a561d04e62314a13a9c89", "ext": "py", "lang": "Python", "content": "def ensure_string(obj):\n    \"\"\"Return String and if Unicode convert to string.\n\n    :param obj: ``str`` || ``unicode``\n    :return: ``str``\n    \"\"\"\n\n    if sys.version_info < (3, 2, 0) and isinstance(obj, unicode):\n        return str(obj.encode('utf8'))\n    else:\n        return obj", "fn_id": 1, "class_fn": false, "repo": "JCallicoat/rpc-maas", "file": "playbooks/library/_uri.py", "last_update_at": "2019-06-23T22:21:24+00:00", "question_id": "e00b74faa37845674d4a561d04e62314a13a9c89_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def ensure_string(obj):\n    \"\"\"Return String and if Unicode convert to string.\n\n    :param obj: ``str`` || ``unicode``\n    :return: ``str``\n    \"\"\"\n    if sys.version_info < (3, 2, 0) and isinstance(obj, unicode):\n        return str(obj.encode('utf8'))\n    else:\n"]]}
{"hexsha": "65ddaa4a5feda5c18aaf2891f826b0ac1eef08c4", "ext": "py", "lang": "Python", "content": "def exit_with_error(msg, code=1, exception=None):\n    if exception:\n        exc_type, exc_value, exc_traceback = sys.exc_info()\n        traceback.print_exception(exc_type, exc_value, exc_traceback,\n                                limit=2, file=sys.stdout)\n        print(\"Exception:\", exception)\n    print(msg)\n    sys.exit(code)", "fn_id": 0, "class_fn": false, "repo": "taylorreece/bubblecheck", "file": "bubblecheck-pdf/cli.py", "last_update_at": "2019-11-28T05:10:23+00:00", "question_id": "65ddaa4a5feda5c18aaf2891f826b0ac1eef08c4_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def exit_with_error(msg, code=1, exception=None):\n    if exception:\n        exc_type, exc_value, exc_traceback = sys.exc_info()\n        traceback.print_exception(exc_type, exc_value, exc_traceback, limit=2, file=sys.stdout)\n        print('Exception:', exception)\n    print(msg)\n"]]}
{"hexsha": "0fff128892f2692e647312f1466281599bd654fd", "ext": "py", "lang": "Python", "content": "def test_lookup_inside_custom_generator():\n    values = ['AA', 'BB', 'CC', 'DD', 'EE', 'FF', 'GG', 'HH', 'II', 'JJ']\n    mapping = {2 * x.upper(): 2 * x for x in 'abcdefghij'}\n\n    class QuuxGenerator(CustomGenerator):\n        aa = SelectOne(values)\n        bb = Lookup(aa, mapping)\n\n    g = QuuxGenerator()\n    items = list(g.generate(num=50, seed=12345))\n    assert all([x.aa == x.bb.upper() for x in items])", "fn_id": 13, "class_fn": false, "repo": "maxalbert/tohu", "file": "tests/v6/test_custom_generator.py", "last_update_at": "2019-03-07T19:58:45+00:00", "question_id": "0fff128892f2692e647312f1466281599bd654fd_13", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_lookup_inside_custom_generator():\n    values = ['AA', 'BB', 'CC', 'DD', 'EE', 'FF', 'GG', 'HH', 'II', 'JJ']\n    mapping = {2 * x.upper(): 2 * x for x in 'abcdefghij'}\n\n    class QuuxGenerator(CustomGenerator):\n        aa = SelectOne(values)\n        bb = Lookup(aa, mapping)\n    g = QuuxGenerator()\n    items = list(g.generate(num=50, seed=12345))\n"]]}
{"hexsha": "5b610df30a28e843f346f99db2221d8220bc29c8", "ext": "py", "lang": "Python", "content": "@when('I try to publish something that is not of type Py_ps_image_data_msg')\ndef step_impl(context):\n    bad_obj = \"not the right type of object!\"\n    context.exception = None\n\n    try:\n        publish(bad_obj)\n    except Exception as e:\n        context.exception = e", "fn_id": 1, "class_fn": false, "repo": "PolySync/core-python-api", "file": "ps_util/features/steps/ps_image_data_msg.py", "last_update_at": "2019-03-09T14:31:09+00:00", "question_id": "5b610df30a28e843f346f99db2221d8220bc29c8_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@when('I try to publish something that is not of type Py_ps_image_data_msg')\ndef step_impl(context):\n    bad_obj = 'not the right type of object!'\n    context.exception = None\n    try:\n        publish(bad_obj)\n    except Exception as e:\n"]]}
{"hexsha": "76f3b457fe3d25fbb8d49ce255ae30cc71794149", "ext": "py", "lang": "Python", "content": "def parse_namespace_and_name(monitoring_info_proto):\n  \"\"\"Returns the (namespace, name) tuple of the URN in the monitoring info.\"\"\"\n  # Remove the URN prefix which indicates that it is a user counter.\n  if is_user_monitoring_info(monitoring_info_proto):\n    labels = monitoring_info_proto.labels\n    return labels[NAMESPACE_LABEL], labels[NAME_LABEL]\n\n  # If it is not a user counter, just use the first part of the URN, i.e. 'beam'\n  split = monitoring_info_proto.urn.split(':', 1)\n  return split[0], split[1]", "fn_id": 11, "class_fn": false, "repo": "nirguna-brahman/beam", "file": "sdks/python/apache_beam/metrics/monitoring_infos.py", "last_update_at": "2019-07-11T10:14:15+00:00", "question_id": "76f3b457fe3d25fbb8d49ce255ae30cc71794149_11", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def parse_namespace_and_name(monitoring_info_proto):\n    \"\"\"Returns the (namespace, name) tuple of the URN in the monitoring info.\"\"\"\n    if is_user_monitoring_info(monitoring_info_proto):\n        labels = monitoring_info_proto.labels\n        return (labels[NAMESPACE_LABEL], labels[NAME_LABEL])\n    split = monitoring_info_proto.urn.split(':', 1)\n"]]}
{"hexsha": "a3d236377598bd489b860be65905b840d2921e33", "ext": "py", "lang": "Python", "content": "def segment_length2(seg):\n    '''Return the square of the length of a segment.\n\n    Returns: Square of Euclidian distance between centres of points in seg\n    '''\n    return point_dist2(seg[0], seg[1])", "fn_id": 16, "class_fn": false, "repo": "NeuroDataDesign/NeuroM", "file": "neurom/morphmath.py", "last_update_at": "2019-12-09T01:56:24+00:00", "question_id": "a3d236377598bd489b860be65905b840d2921e33_16", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def segment_length2(seg):\n    \"\"\"Return the square of the length of a segment.\n\n    Returns: Square of Euclidian distance between centres of points in seg\n    \"\"\"\n"]]}
{"hexsha": "ea4c7ee38e4a21fc55b49f9830f4daed3671176e", "ext": "py", "lang": "Python", "content": "@timer\ndef get_train_ds(batch_size=128,shuffle=True,distort=True,distort_fn=None):\n    train_ds = get_tf_dataset_in_batches('train', batch_size, shuffle,distort,distort_fn)\n    return train_ds", "fn_id": 15, "class_fn": false, "repo": "Aspire-Mayank/tf_utils", "file": "tf_utils/data.py", "last_update_at": "2019-11-01T19:06:26+00:00", "question_id": "ea4c7ee38e4a21fc55b49f9830f4daed3671176e_15", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@timer\ndef get_train_ds(batch_size=128, shuffle=True, distort=True, distort_fn=None):\n    train_ds = get_tf_dataset_in_batches('train', batch_size, shuffle, distort, distort_fn)\n"]]}
{"hexsha": "12161c783a7dc81226285827d8bf0ac22aacf252", "ext": "py", "lang": "Python", "content": "def use_rdkit2():\n    # substructure matching\n    m6 = Chem.MolFromSmiles('c1ccccc1O')\n    patt = Chem.MolFromSmarts('ccO')\n    print('Boolean if substructure matches --> ', m6.HasSubstructMatch(patt))\n    print('Atoms in structure which match --> ',m6.GetSubstructMatch(patt))\n    print('if multiple structures match--> ',m6.GetSubstructMatches(patt))\n    \n    # chemical transformations\n    # deleting a substructure\n    rm = AllChem.DeleteSubstructs(m6, patt)\n    print ('The removed atoms -->', Chem.MolToSmiles(rm))\n    Draw.MolToFile(rm,'/home/stokm006/thesis/images/molecule_rm.png')\n    # replacing a substructure\n    m7 = Chem.MolFromSmiles('CC(=O)N')\n    patt2 = Chem.MolFromSmarts('[$(NC(=O))]')\n    repl = Chem.MolFromSmiles('OC')\n    rms = AllChem.ReplaceSubstructs(m7,patt2,repl)\n    print('New SMILE -->', Chem.MolToSmiles(rms[0]))", "fn_id": 2, "class_fn": false, "repo": "iomega/special-substructure-search", "file": "Code/Utilities/SubstructureFind/rdkit_try_script.py", "last_update_at": "2019-09-05T18:31:51+00:00", "question_id": "12161c783a7dc81226285827d8bf0ac22aacf252_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def use_rdkit2():\n    m6 = Chem.MolFromSmiles('c1ccccc1O')\n    patt = Chem.MolFromSmarts('ccO')\n    print('Boolean if substructure matches --> ', m6.HasSubstructMatch(patt))\n    print('Atoms in structure which match --> ', m6.GetSubstructMatch(patt))\n    print('if multiple structures match--> ', m6.GetSubstructMatches(patt))\n    rm = AllChem.DeleteSubstructs(m6, patt)\n    print('The removed atoms -->', Chem.MolToSmiles(rm))\n    Draw.MolToFile(rm, '/home/stokm006/thesis/images/molecule_rm.png')\n    m7 = Chem.MolFromSmiles('CC(=O)N')\n    patt2 = Chem.MolFromSmarts('[$(NC(=O))]')\n    repl = Chem.MolFromSmiles('OC')\n    rms = AllChem.ReplaceSubstructs(m7, patt2, repl)\n"]]}
{"hexsha": "5914558481cf63eb4d1cee362a1a4378ed960409", "ext": "py", "lang": "Python", "content": "def init(config_file_path=None, **kwargs):\n    '''Init the storage client. Basically, we set the Redis client and connects it\n    to the instance/cluster\n    '''\n    global redis_connection\n    global hosts\n    # If config_file_path is None we will assume that we only have localhost\n    # as storage node\n    if config_file_path is None:\n        import StringIO as sio\n        config_file_handler = sio.StringIO('localhost\\n')\n    else:\n        config_file_handler = open(config_file_path)\n    # As accorded in the API standar, this file must contain all the hosts names\n    # with no port, one per line\n    hosts = [x.strip() for x in config_file_handler.readlines()]\n    config_file_handler.close()\n    # If we have more than one host then we will assume that our backend is a Redis\n    # cluster. If not, we will assume that we are dealing with a Redis standalone\n    # instance\n    if len(hosts) > 1:\n        # Given that cluster clients are capable to perform master\n        # slave hierarchy discovery, we will simply connect to the first\n        # node we got\n        redis_connection = \\\n        rediscluster.StrictRedisCluster(host=hosts[0], port=REDIS_PORT)\n    else:\n        # We are in standalone mode\n        redis_connection = \\\n        redis.StrictRedis(host=hosts[0], port=REDIS_PORT)\n    # StrictRedis is not capable to know if we had success when connecting by\n    # simply calling the constructor. We need to perform an actual query to\n    # the backend\n    # If we had no success this first line should crash\n    redis_connection.set('PYCOMPSS_TEST', 'OK')\n    assert redis_connection.get('PYCOMPSS_TEST') == 'OK'\n    redis_connection.delete('PYCOMPSS_TEST')", "fn_id": 0, "class_fn": false, "repo": "TANGO-Project/compss-tango", "file": "utils/storage/redisPSCO/python/storage/api.py", "last_update_at": "2019-02-08T09:58:24+00:00", "question_id": "5914558481cf63eb4d1cee362a1a4378ed960409_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def init(config_file_path=None, **kwargs):\n    \"\"\"Init the storage client. Basically, we set the Redis client and connects it\n    to the instance/cluster\n    \"\"\"\n    global redis_connection\n    global hosts\n    if config_file_path is None:\n        import StringIO as sio\n        config_file_handler = sio.StringIO('localhost\\n')\n    else:\n        config_file_handler = open(config_file_path)\n    hosts = [x.strip() for x in config_file_handler.readlines()]\n    config_file_handler.close()\n    if len(hosts) > 1:\n        redis_connection = rediscluster.StrictRedisCluster(host=hosts[0], port=REDIS_PORT)\n    else:\n        redis_connection = redis.StrictRedis(host=hosts[0], port=REDIS_PORT)\n    redis_connection.set('PYCOMPSS_TEST', 'OK')\n    assert redis_connection.get('PYCOMPSS_TEST') == 'OK'\n"]]}
{"hexsha": "f4e36dc11497b3f68670ada79948a547be9ca946", "ext": "py", "lang": "Python", "content": "@pytest.fixture\ndef dir_examples(request):\n    tests_dir = Path(request.fspath).parent\n    return tests_dir.parent / 'examples'", "fn_id": 0, "class_fn": false, "repo": "perrenyang/dac-man", "file": "tests/conftest.py", "last_update_at": "2019-10-02T18:06:48+00:00", "question_id": "f4e36dc11497b3f68670ada79948a547be9ca946_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.fixture\ndef dir_examples(request):\n    tests_dir = Path(request.fspath).parent\n"]]}
{"hexsha": "61f64fc16f91c22130b6ab3d7970d5bcc070f129", "ext": "py", "lang": "Python", "content": "def create_dataframe(url):\n    \"\"\" Creates data frame from url \"\"\"\n    data_frame = pd.read_csv(url)\n    return data_frame", "fn_id": 0, "class_fn": false, "repo": "UWSEDS/homework-4-documentation-and-style-czarakas", "file": "read_in_data.py", "last_update_at": "2019-11-15T00:47:17+00:00", "question_id": "61f64fc16f91c22130b6ab3d7970d5bcc070f129_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def create_dataframe(url):\n    \"\"\" Creates data frame from url \"\"\"\n    data_frame = pd.read_csv(url)\n"]]}
{"hexsha": "86642cf9af1550ffb25d6350e4add25e9661e3ee", "ext": "py", "lang": "Python", "content": "def _create_time_series(series):\n    x_series = []\n\n    fake_day = datetime.date(2010, 1, 1)\n    first_time = None\n\n    for x, point in enumerate(series[TIME_COL]):\n        # point is something like: 11:10:46.215\n        h, m, s = [int(n) for n in point[:-4].split(':')]\n        milli = int(point[-3:])\n        u = datetime.time(h, m, s, milli * 1000)\n\n        if not first_time:\n            first_time = datetime.datetime.combine(fake_day, u)\n\n        delta = (datetime.datetime.combine(fake_day, u) - first_time)\n        x_series.append(delta.total_seconds())\n\n    return x_series", "fn_id": 1, "class_fn": false, "repo": "TwoLaid/pcm-graph", "file": "pcm_graph.py", "last_update_at": "2019-02-08T01:20:32+00:00", "question_id": "86642cf9af1550ffb25d6350e4add25e9661e3ee_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _create_time_series(series):\n    x_series = []\n    fake_day = datetime.date(2010, 1, 1)\n    first_time = None\n    for x, point in enumerate(series[TIME_COL]):\n        h, m, s = [int(n) for n in point[:-4].split(':')]\n        milli = int(point[-3:])\n        u = datetime.time(h, m, s, milli * 1000)\n        if not first_time:\n            first_time = datetime.datetime.combine(fake_day, u)\n        delta = datetime.datetime.combine(fake_day, u) - first_time\n        x_series.append(delta.total_seconds())\n"]]}
{"hexsha": "988a2a8401c431017a8556ffb7e5c066809f7e37", "ext": "py", "lang": "Python", "content": "@blueprint.route('/<int:poll_id>')\n@for_auth\ndef get_one(poll_id: int):\n    logger.info('Poll. Get info %s', poll_id)\n    obj = db.session.query(Poll).get_or_404(poll_id)  # type: Poll\n    validators.namespace_access(obj.namespace_code)\n    return jsonify(dict(results=obj.marshall()))", "fn_id": 1, "class_fn": false, "repo": "octomen/thupoll", "file": "thupoll/blueprints/polls.py", "last_update_at": "2019-04-15T01:43:09+00:00", "question_id": "988a2a8401c431017a8556ffb7e5c066809f7e37_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@blueprint.route('/<int:poll_id>')\n@for_auth\ndef get_one(poll_id: int):\n    logger.info('Poll. Get info %s', poll_id)\n    obj = db.session.query(Poll).get_or_404(poll_id)\n    validators.namespace_access(obj.namespace_code)\n"]]}
{"hexsha": "5f58f94187f53dbc0249e07f7f5bb6124b773112", "ext": "py", "lang": "Python", "content": "def site_analytics(request):\n    '''Add settings relating to site analytics to the context.\n    Currently consists of:\n\n    * GOOGLE_ANALYTICS_ENABLED\n    * GOOGLE_SITE_VERIFICATION\n\n    '''\n    keys = [\n        'GOOGLE_ANALYTICS_ENABLED',\n        'GOOGLE_SITE_VERIFICATION',\n    ]\n    return dict((k, getattr(settings, k, '')) for k in keys)", "fn_id": 2, "class_fn": false, "repo": "emory-libraries/OpenEmory", "file": "openemory/context_processors.py", "last_update_at": "2019-10-17T19:01:55+00:00", "question_id": "5f58f94187f53dbc0249e07f7f5bb6124b773112_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def site_analytics(request):\n    \"\"\"Add settings relating to site analytics to the context.\n    Currently consists of:\n\n    * GOOGLE_ANALYTICS_ENABLED\n    * GOOGLE_SITE_VERIFICATION\n\n    \"\"\"\n    keys = ['GOOGLE_ANALYTICS_ENABLED', 'GOOGLE_SITE_VERIFICATION']\n"]]}
{"hexsha": "329555674d8a6531145cd02a07fa0ffd300ca2e5", "ext": "py", "lang": "Python", "content": "def getfileby_func(dirPath,func=lambda r,f:True):\n    '''\n    func is a function that defined by you to filter the file\n    you wanted to operate\n    the function func has two parameter,the directory path of the file\n    and the filename\n    '''\n    file_all = []\n    gene = os.walk(dirPath)\n    for dirpath,dirnames,filenames in gene:\n        for file in filenames:\n            if func(dirpath,file):\n                file_all.append(os.path.join(dirpath, file))\n    return file_all", "fn_id": 1, "class_fn": false, "repo": "Rabbytr/python_toolkit", "file": "pykit/pathop.py", "last_update_at": "2019-07-18T06:04:38+00:00", "question_id": "329555674d8a6531145cd02a07fa0ffd300ca2e5_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def getfileby_func(dirPath, func=lambda r, f: True):\n    \"\"\"\n    func is a function that defined by you to filter the file\n    you wanted to operate\n    the function func has two parameter,the directory path of the file\n    and the filename\n    \"\"\"\n    file_all = []\n    gene = os.walk(dirPath)\n    for dirpath, dirnames, filenames in gene:\n        for file in filenames:\n            if func(dirpath, file):\n                file_all.append(os.path.join(dirpath, file))\n"]]}
{"hexsha": "3c820e9c53d427ea0cd4f8ddd361fd3b7d37f04b", "ext": "py", "lang": "Python", "content": "@pytest.yield_fixture\ndef rmock():\n    with requests_mock.mock() as rmock:\n        real_register_uri = rmock.register_uri\n\n        def register_uri_with_complete_qs(*args, **kwargs):\n            if 'complete_qs' not in kwargs:\n                kwargs['complete_qs'] = True\n\n            return real_register_uri(*args, **kwargs)\n\n        rmock.register_uri = register_uri_with_complete_qs\n\n        yield rmock", "fn_id": 1, "class_fn": false, "repo": "jonodrew/digitalmarketplace-scripts", "file": "tests/conftest.py", "last_update_at": "2019-01-10T12:43:24+00:00", "question_id": "3c820e9c53d427ea0cd4f8ddd361fd3b7d37f04b_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.yield_fixture\ndef rmock():\n    with requests_mock.mock() as rmock:\n        real_register_uri = rmock.register_uri\n\n        def register_uri_with_complete_qs(*args, **kwargs):\n            if 'complete_qs' not in kwargs:\n                kwargs['complete_qs'] = True\n            return real_register_uri(*args, **kwargs)\n        rmock.register_uri = register_uri_with_complete_qs\n"]]}
{"hexsha": "8150fd51bf255683c6fea7c93468cc064a221ee1", "ext": "py", "lang": "Python", "content": "def execute_query_find(query):\n    \"\"\"Search document in mycoll collection using a query.\n\n    Returns a list of documents.\n    \"\"\"\n    documents = []\n    for document in list(pymodm.connection._get_db().mycoll.find(query)):\n        documents.append(document)\n    return documents", "fn_id": 0, "class_fn": false, "repo": "cle-b/tt_demo", "file": "tt_demo/mycollection/controllers.py", "last_update_at": "2019-02-19T21:09:12+00:00", "question_id": "8150fd51bf255683c6fea7c93468cc064a221ee1_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def execute_query_find(query):\n    \"\"\"Search document in mycoll collection using a query.\n\n    Returns a list of documents.\n    \"\"\"\n    documents = []\n    for document in list(pymodm.connection._get_db().mycoll.find(query)):\n        documents.append(document)\n"]]}
{"hexsha": "67be26eb7d827e8abc0ef2092c83f55b63992c5f", "ext": "py", "lang": "Python", "content": "@login_required\ndef ordersection(request):\n    if request.POST['section-order']:\n        order_array = request.POST['section-order']\n        order_array = order_array.split(',')\n\n        i = 1\n        for section_id in order_array:\n            section = get_object_or_404(Section, pk=section_id)\n            section.order = i\n            section.save()\n            i += 1", "fn_id": 26, "class_fn": false, "repo": "kasimbozdag/swe_574", "file": "ocial/ocial_project/topics/views.py", "last_update_at": "2019-09-29T12:54:58+00:00", "question_id": "67be26eb7d827e8abc0ef2092c83f55b63992c5f_26", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@login_required\ndef ordersection(request):\n    if request.POST['section-order']:\n        order_array = request.POST['section-order']\n        order_array = order_array.split(',')\n        i = 1\n        for section_id in order_array:\n            section = get_object_or_404(Section, pk=section_id)\n            section.order = i\n            section.save()\n"]]}
{"hexsha": "245fded2214972a135a908e8b9a8522e0733038d", "ext": "py", "lang": "Python", "content": "def parse_modifiers(modifiers, args):\n    unrecognized = []\n    recognized = {}\n    for arg in (args or []):\n        try:\n            key, value = arg.split('=', 1)\n            if key in modifiers:\n                modifiers[key](recognized, key, value)\n            else:\n                unrecognized.append(arg)\n        except:\n            unrecognized.append(arg)\n    return recognized, unrecognized", "fn_id": 2, "class_fn": false, "repo": "Stratoscale/cliff-adaptive-table", "file": "cliff_adaptive_table/modifier.py", "last_update_at": "2019-07-01T13:05:29+00:00", "question_id": "245fded2214972a135a908e8b9a8522e0733038d_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def parse_modifiers(modifiers, args):\n    unrecognized = []\n    recognized = {}\n    for arg in args or []:\n        try:\n            key, value = arg.split('=', 1)\n            if key in modifiers:\n                modifiers[key](recognized, key, value)\n            else:\n                unrecognized.append(arg)\n        except:\n            unrecognized.append(arg)\n"]]}
{"hexsha": "89fb95166632cbcb60d2dc648add95de85a6ad64", "ext": "py", "lang": "Python", "content": "def pytest_addoption(parser):\n    parser.addoption(\n        \"--no-conv-assertions\", action=\"store_true\", default=1,\n        help='''\n        Disable assertiong on Convolution class.\n        ''')\n\n    parser.addoption(\n        \"--test-level\", action=\"store\", type=int, default=2,\n        help='''\n        0= test Tensile.Convolution class;\n        1= 0 plus generate YAML;\n        2= 1 plus run tensile client and compare generated contraction vs CPU;\n        3= 2 plus run tensile_client with convolution-vs-contraction (only forward conv tests which define Spatial will PASS )\n        '''\n        )\n    parser.addoption(\n        \"--problem-level\", action=\"store\", type=int, default=2,\n        help='''\n        How many exact configurations to generate for contraction testing for non-src solutions (typically asm).\n        1= single problem\n        2= tens of problems\n        3= hundreds of problems\n        '''\n        )", "fn_id": 6, "class_fn": false, "repo": "amcamd/Tensile", "file": "Tensile/Tests/extended/convolution_config/conftest.py", "last_update_at": "2019-11-18T06:49:20+00:00", "question_id": "89fb95166632cbcb60d2dc648add95de85a6ad64_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def pytest_addoption(parser):\n    parser.addoption('--no-conv-assertions', action='store_true', default=1, help='\\n        Disable assertiong on Convolution class.\\n        ')\n    parser.addoption('--test-level', action='store', type=int, default=2, help='\\n        0= test Tensile.Convolution class;\\n        1= 0 plus generate YAML;\\n        2= 1 plus run tensile client and compare generated contraction vs CPU;\\n        3= 2 plus run tensile_client with convolution-vs-contraction (only forward conv tests which define Spatial will PASS )\\n        ')\n"]]}
{"hexsha": "933bf7c5c64dd27fc2b55de940ce11ee6953ecdb", "ext": "py", "lang": "Python", "content": "def all_paths():\n  \"\"\"Return all paths which are checked in to git.\"\"\"\n  repo_root = os.path.abspath(os.path.join(INFRABOTS_DIR, os.pardir, os.pardir))\n  output = subprocess.check_output(['git', 'ls-files'], cwd=repo_root).rstrip()\n  return output.splitlines()", "fn_id": 0, "class_fn": false, "repo": "kizerkizer/skia", "file": "infra/bots/gen_compile_isolate.py", "last_update_at": "2019-09-06T20:04:22+00:00", "question_id": "933bf7c5c64dd27fc2b55de940ce11ee6953ecdb_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def all_paths():\n    \"\"\"Return all paths which are checked in to git.\"\"\"\n    repo_root = os.path.abspath(os.path.join(INFRABOTS_DIR, os.pardir, os.pardir))\n    output = subprocess.check_output(['git', 'ls-files'], cwd=repo_root).rstrip()\n"]]}
{"hexsha": "87c08181005716ca929b1a5364f26feaec9fff85", "ext": "py", "lang": "Python", "content": "def eval_fn(goldstd_positive_domains, searchresult, \n            ignore_search_keyerror=False):\n    \"\"\"\n    Evaluate the false negative rate for different score cutoffs\n    and print table to stdout.\n    \n    Parameters:\n       goldstd_positive_domains - \n                       list of identifiers that the query\n                       should match i.e. the 'gold standard' list of \n                       hits.\n       searchresult -  list of (score, domainid), sorted by ascending score\n        ignore_search_keyerror - If True, ignore key errors in search result.\n                      Usually this should not happen, but when using external\n                      results i.e. those not from same database (ASTRAL subset)\n                      used here, it can. Eg. using TableauSearch webserver\n                      results which have older SCOP as database,\n                      so there are  SCOP sids in our database that are\n                      not in the serach results at all. Then this option\n                      just ignores them rather than raising exception KeyError.\n\n    Return value:\n       None - table written to stdout.\n       \n    \"\"\"\n        \n    sys.stdout.write('score  fp_count     tpr     fpr\\n')\n    sys.stdout.write('#------------------------------\\n')\n\n    fprlist = []\n    tprlist = []\n\n    resultlist = searchresult\n\n    # remove gold standard SCOP domains that are not in the search\n    # result, which can happen from using external results, also\n    # happens for some domains where for some reason the Bio.SCOP\n    # isDomainInId(95) does not contain some domains that actually\n    # are in the downlaoded ASTRAL SCOP 95% set (e.g. d2aeph1)\n    # This can also happen when the search got an error for a domain\n    # so it is not in the search results.\n    # Use the -x option (ignore_search_keyerror) to handle these cases\n    # (not always on by default since these things \"shouldn't\" happen).\n    if ignore_search_keyerror:\n        search_dict = dict([(pdbid, (score, rank)) for (rank, (score, pdbid))\n                            in enumerate(searchresult)])\n        our_goldstd_positive_domains = [scopdom for scopdom in goldstd_positive_domains if search_dict.has_key(scopdom) ]\n    else:\n        our_goldstd_positive_domains = goldstd_positive_domains\n\n#    sys.stderr.write('original len, reduced len ' +str(len(goldstd_positive_domains)) +  ' , ' + str(len(our_goldstd_positive_domains)) + '\\n')\n\n    \n    # convert goldstd list of domainids to dictionary\n    # keyed by domainid for fast lookup as we iterate through search results.\n    # The dictionary is { domainid : True } (we don't have a value,\n    # just need to quickly test for presendce of domainid in gold stad\n    # postive list0\n\n    goldstd_pos_dict = dict([(scopdom, True) for\n                             scopdom in our_goldstd_positive_domains])\n    \n    # start at classifying all as true (TPR=FPR=1)\n    tp_count = len(our_goldstd_positive_domains)\n    fp_count = len(resultlist) - len(our_goldstd_positive_domains)\n    for cutoff_rank in xrange(len(resultlist)):\n        cutoff_score = resultlist[cutoff_rank][0]\n        if cutoff_rank > 0:\n            # we are now classifying the previous one and all below as negative\n            prev_scopsid =  resultlist[cutoff_rank - 1][1]\n            if goldstd_pos_dict.has_key(prev_scopsid):\n                tp_count -= 1\n            else:\n                fp_count -= 1\n\n        tpr = float(tp_count) / float(len(our_goldstd_positive_domains)) #sensitivity = true pos rate\n        fpr = float(fp_count) / float(len(resultlist) - len(our_goldstd_positive_domains)) #FP rate\n        specificity = 1.0 - fpr\n\n        fprlist.append(fpr)\n        tprlist.append(tpr)\n            \n        sys.stdout.write('%5.1f %8d    %5.3f   %5.3f\\n' %\n                         (cutoff_score, fp_count, tpr, fpr))\n\n    fprlist.reverse()\n    tprlist.reverse()\n    auc = compute_auc(fprlist, tprlist)\n    sys.stdout.write('\\n')\n    sys.stdout.write('# AUC = %5.3f\\n' % auc)", "fn_id": 2, "class_fn": false, "repo": "stivalaa/pro-origami", "file": "tsevalutils.py", "last_update_at": "2019-02-16T07:30:49+00:00", "question_id": "87c08181005716ca929b1a5364f26feaec9fff85_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def eval_fn(goldstd_positive_domains, searchresult, ignore_search_keyerror=False):\n    \"\"\"\n    Evaluate the false negative rate for different score cutoffs\n    and print table to stdout.\n    \n    Parameters:\n       goldstd_positive_domains - \n                       list of identifiers that the query\n                       should match i.e. the 'gold standard' list of \n                       hits.\n       searchresult -  list of (score, domainid), sorted by ascending score\n        ignore_search_keyerror - If True, ignore key errors in search result.\n                      Usually this should not happen, but when using external\n                      results i.e. those not from same database (ASTRAL subset)\n                      used here, it can. Eg. using TableauSearch webserver\n                      results which have older SCOP as database,\n                      so there are  SCOP sids in our database that are\n                      not in the serach results at all. Then this option\n                      just ignores them rather than raising exception KeyError.\n\n    Return value:\n       None - table written to stdout.\n       \n    \"\"\"\n    sys.stdout.write('score  fp_count     tpr     fpr\\n')\n    sys.stdout.write('#------------------------------\\n')\n    fprlist = []\n    tprlist = []\n    resultlist = searchresult\n    if ignore_search_keyerror:\n        search_dict = dict([(pdbid, (score, rank)) for rank, (score, pdbid) in enumerate(searchresult)])\n        our_goldstd_positive_domains = [scopdom for scopdom in goldstd_positive_domains if search_dict.has_key(scopdom)]\n    else:\n        our_goldstd_positive_domains = goldstd_positive_domains\n    goldstd_pos_dict = dict([(scopdom, True) for scopdom in our_goldstd_positive_domains])\n    tp_count = len(our_goldstd_positive_domains)\n    fp_count = len(resultlist) - len(our_goldstd_positive_domains)\n    for cutoff_rank in xrange(len(resultlist)):\n        cutoff_score = resultlist[cutoff_rank][0]\n        if cutoff_rank > 0:\n            prev_scopsid = resultlist[cutoff_rank - 1][1]\n            if goldstd_pos_dict.has_key(prev_scopsid):\n                tp_count -= 1\n            else:\n                fp_count -= 1\n        tpr = float(tp_count) / float(len(our_goldstd_positive_domains))\n        fpr = float(fp_count) / float(len(resultlist) - len(our_goldstd_positive_domains))\n        specificity = 1.0 - fpr\n        fprlist.append(fpr)\n        tprlist.append(tpr)\n        sys.stdout.write('%5.1f %8d    %5.3f   %5.3f\\n' % (cutoff_score, fp_count, tpr, fpr))\n    fprlist.reverse()\n    tprlist.reverse()\n    auc = compute_auc(fprlist, tprlist)\n    sys.stdout.write('\\n')\n"]]}
{"hexsha": "87bfda7300e1119f035696bfa7de46cc22a53763", "ext": "py", "lang": "Python", "content": "def delete(client, path):\n    \"\"\" Recursively delete a path\n\n    Args:\n        client: Pookeeper client\n        path: the path to recursively delete\n    \"\"\"\n    if not client.exists(path): return\n\n    children, stat = client.get_children(path)\n    for child in children:\n        delete(client, path + '/' + child)\n    client.delete(path, stat.version)\n    LOGGER.debug('Deleted %s', path)", "fn_id": 3, "class_fn": false, "repo": "maguro/pookeeper", "file": "toolazydogs/pookeeper/__init__.py", "last_update_at": "2019-01-05T17:12:43+00:00", "question_id": "87bfda7300e1119f035696bfa7de46cc22a53763_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def delete(client, path):\n    \"\"\" Recursively delete a path\n\n    Args:\n        client: Pookeeper client\n        path: the path to recursively delete\n    \"\"\"\n    if not client.exists(path):\n        return\n    children, stat = client.get_children(path)\n    for child in children:\n        delete(client, path + '/' + child)\n    client.delete(path, stat.version)\n"]]}
{"hexsha": "0d9729d4702a0197af9c0cf39b95180399c7dc21", "ext": "py", "lang": "Python", "content": "def print_Connections(Connections_arr):\n    print(\"Connections:\")\n    for x in range(len(Connections_arr)):\n        print(\"   Id:\", Connections_arr[x].id, \" From:\", Connections_arr[x].fromCardinality, \" To:\",\n              Connections_arr[x].toCardinality)\n        print(\"  \", Connections_arr[x].connection_type_name, \":\")\n        print(\"      \", Connections_arr[x].from_type, \":\", Connections_arr[x].from_id)\n        print(\"      \", Connections_arr[x].to_type, \":\", Connections_arr[x].to_id)\n    print(\"=========================================\")", "fn_id": 7, "class_fn": false, "repo": "stepantuzil/DemoToBpmn", "file": "Parse_DEMO.py", "last_update_at": "2019-07-24T21:16:41+00:00", "question_id": "0d9729d4702a0197af9c0cf39b95180399c7dc21_7", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def print_Connections(Connections_arr):\n    print('Connections:')\n    for x in range(len(Connections_arr)):\n        print('   Id:', Connections_arr[x].id, ' From:', Connections_arr[x].fromCardinality, ' To:', Connections_arr[x].toCardinality)\n        print('  ', Connections_arr[x].connection_type_name, ':')\n        print('      ', Connections_arr[x].from_type, ':', Connections_arr[x].from_id)\n        print('      ', Connections_arr[x].to_type, ':', Connections_arr[x].to_id)\n"]]}
{"hexsha": "93c02bf2c69318452dd7ebff355916cd25c30b4e", "ext": "py", "lang": "Python", "content": "def create_main_window(settings):\n    sg.theme(settings['theme'])\n    menu_def = [['&Menu', ['&Settings', 'E&xit']],\n                ['&Help', '&About...']]\n\n    right_click_menu = ['Unused', ['&Copy', '&Paste','Settings', 'E&xit']]\n\n    layout =  [[sg.Menu(menu_def)],\n               [sg.Image('enc.png'),sg.Text('Encrypt and decrypt files', size=[21, 1]), sg.Button('', key='paypal', size=(12,1), font=('Helvetica', 9), button_color=(sg.theme_background_color(), sg.theme_background_color()),\n                           image_filename='paypal.png', image_size=(80, 50), image_subsample=2, border_width=0),\n                 sg.Button('', key='bitcoin', size=(12,1), font=('Helvetica', 9), button_color=(sg.theme_background_color(), sg.theme_background_color()),\n                           image_filename='bitcoin.png', image_size=(80, 60), image_subsample=2, border_width=0)],         \n               [sg.Output(size=(60, 20), key='out')],\n               [sg.Text('Password',size=(10,1)),sg.In(size=(49,1), key=('pass'))],\n               [sg.Text('Select file', size=(10,1)),sg.In(size=(40, 1),key='-in-'), sg.FileBrowse()],\n               [sg.Button('Encrypt'), sg.Button('Decrypt')]]\n\n    return sg.Window('Crypter', default_element_size=(11, 2)).Layout(layout)      ", "fn_id": 3, "class_fn": false, "repo": "adrijano/crypter-master", "file": "crypter.py", "last_update_at": "2019-11-24T17:24:09+00:00", "question_id": "93c02bf2c69318452dd7ebff355916cd25c30b4e_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def create_main_window(settings):\n    sg.theme(settings['theme'])\n    menu_def = [['&Menu', ['&Settings', 'E&xit']], ['&Help', '&About...']]\n    right_click_menu = ['Unused', ['&Copy', '&Paste', 'Settings', 'E&xit']]\n    layout = [[sg.Menu(menu_def)], [sg.Image('enc.png'), sg.Text('Encrypt and decrypt files', size=[21, 1]), sg.Button('', key='paypal', size=(12, 1), font=('Helvetica', 9), button_color=(sg.theme_background_color(), sg.theme_background_color()), image_filename='paypal.png', image_size=(80, 50), image_subsample=2, border_width=0), sg.Button('', key='bitcoin', size=(12, 1), font=('Helvetica', 9), button_color=(sg.theme_background_color(), sg.theme_background_color()), image_filename='bitcoin.png', image_size=(80, 60), image_subsample=2, border_width=0)], [sg.Output(size=(60, 20), key='out')], [sg.Text('Password', size=(10, 1)), sg.In(size=(49, 1), key='pass')], [sg.Text('Select file', size=(10, 1)), sg.In(size=(40, 1), key='-in-'), sg.FileBrowse()], [sg.Button('Encrypt'), sg.Button('Decrypt')]]\n"]]}
{"hexsha": "9a773e8f298f148474d228615c69ac551e2e3b1e", "ext": "py", "lang": "Python", "content": "def chunks(l, n):\n    \"\"\" Yield successive n-sized chunks from l.\n    \"\"\"\n    for i in xrange(0, len(l), n):\n        yield l[i:i+n]", "fn_id": 0, "class_fn": false, "repo": "F483/bikesurf.org", "file": "apps/common/shortcuts.py", "last_update_at": "2019-06-26T20:02:05+00:00", "question_id": "9a773e8f298f148474d228615c69ac551e2e3b1e_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def chunks(l, n):\n    \"\"\" Yield successive n-sized chunks from l.\n    \"\"\"\n    for i in xrange(0, len(l), n):\n"]]}
{"hexsha": "ae7158d6c11da91ba8f01310a5aad3a671b9e9ee", "ext": "py", "lang": "Python", "content": "def polish_string(title, useless_ending='xxx'):\n    \"\"\"Return a safe directory name.\"\"\"\n    title = re.sub(\"\u300a|\u300b\", \"\", title).strip()\n    title = re.sub(\"[/\\\\\\?\\|<>:\\\"\\*]\", \"_\", title).strip()\n    uselessEndings = [\".txt\", \"txt\", '\u5168\u6587\u9605\u8bfb', '\u6700\u65b0\u7ae0\u8282', useless_ending]\n    # for ending in uselessEndings:\n    #     if title[-len(ending):] == ending:\n    #         title = title[0:-len(ending)]\n    for ending in uselessEndings:\n        position = title.find(ending)\n        position = position if position != -1 else len(title)\n        # print('{0}-{1}-{2}'.format(ending, title, position))\n        title = title[0:position]\n    return title", "fn_id": 0, "class_fn": false, "repo": "yytang2012/novels-crawler", "file": "libs/polish.py", "last_update_at": "2019-03-28T09:24:28+00:00", "question_id": "ae7158d6c11da91ba8f01310a5aad3a671b9e9ee_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def polish_string(title, useless_ending='xxx'):\n    \"\"\"Return a safe directory name.\"\"\"\n    title = re.sub('\u300a|\u300b', '', title).strip()\n    title = re.sub('[/\\\\\\\\?\\\\|<>:\"\\\\*]', '_', title).strip()\n    uselessEndings = ['.txt', 'txt', '\u5168\u6587\u9605\u8bfb', '\u6700\u65b0\u7ae0\u8282', useless_ending]\n    for ending in uselessEndings:\n        position = title.find(ending)\n        position = position if position != -1 else len(title)\n        title = title[0:position]\n"]]}
{"hexsha": "96e75851e0f2b6848587bc6bd77bfae25227348f", "ext": "py", "lang": "Python", "content": "def test_implicit_label():\n    nlp = Language()\n    nlp.add_pipe(\"tagger\")\n    train_examples = []\n    for t in TRAIN_DATA:\n        train_examples.append(Example.from_dict(nlp.make_doc(t[0]), t[1]))\n    nlp.initialize(get_examples=lambda: train_examples)", "fn_id": 5, "class_fn": false, "repo": "snosrap/spaCy", "file": "spacy/tests/pipeline/test_tagger.py", "last_update_at": "2019-05-17T02:43:33+00:00", "question_id": "96e75851e0f2b6848587bc6bd77bfae25227348f_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_implicit_label():\n    nlp = Language()\n    nlp.add_pipe('tagger')\n    train_examples = []\n    for t in TRAIN_DATA:\n        train_examples.append(Example.from_dict(nlp.make_doc(t[0]), t[1]))\n"]]}
{"hexsha": "735e4ce2966a57519a06731bb9fa8b1621e352e4", "ext": "py", "lang": "Python", "content": "def multipolygons(geometries):\n    \"\"\"Create multipolygons from arrays of polygons\n\n    Parameters\n    ----------\n    geometries : array_like\n        An array of polygons or coordinates (see polygons).\n    \"\"\"\n    geometries = np.asarray(geometries)\n    if not isinstance(geometries, Geometry) and np.issubdtype(\n        geometries.dtype, np.number\n    ):\n        geometries = polygons(geometries)\n    return lib.create_collection(geometries, GeometryType.MULTIPOLYGON)", "fn_id": 8, "class_fn": false, "repo": "mattijn/pygeos", "file": "pygeos/creation.py", "last_update_at": "2019-11-11T16:28:15+00:00", "question_id": "735e4ce2966a57519a06731bb9fa8b1621e352e4_8", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def multipolygons(geometries):\n    \"\"\"Create multipolygons from arrays of polygons\n\n    Parameters\n    ----------\n    geometries : array_like\n        An array of polygons or coordinates (see polygons).\n    \"\"\"\n    geometries = np.asarray(geometries)\n    if not isinstance(geometries, Geometry) and np.issubdtype(geometries.dtype, np.number):\n        geometries = polygons(geometries)\n"]]}
{"hexsha": "5f06325672cf4e056618b4384cfdf4036ccab257", "ext": "py", "lang": "Python", "content": "def parse_args():\n    \"\"\"\n    Parse Arguments from component\n    :return:\n    \"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--input-model\", help=\"Path of input model to create\")\n    parser.add_argument(\"--input-file\", help = \"Path of the file to process\")\n    parser.add_argument(\"--threshold\", help = \"Threshold on minimum distance from closes center\")\n    parser.add_argument(\"--temp-shared-path\", help=\"Temporary shared path for model transfer\")\n    options = parser.parse_args()\n    return options", "fn_id": 2, "class_fn": false, "repo": "mlpiper/mlhub", "file": "components/Python/PySpark/kmeans-predict/main.py", "last_update_at": "2019-02-22T03:41:56+00:00", "question_id": "5f06325672cf4e056618b4384cfdf4036ccab257_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def parse_args():\n    \"\"\"\n    Parse Arguments from component\n    :return:\n    \"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--input-model', help='Path of input model to create')\n    parser.add_argument('--input-file', help='Path of the file to process')\n    parser.add_argument('--threshold', help='Threshold on minimum distance from closes center')\n    parser.add_argument('--temp-shared-path', help='Temporary shared path for model transfer')\n    options = parser.parse_args()\n"]]}
{"hexsha": "3915d19ecd09e5ec36b6ebd18aaee67a5effccd6", "ext": "py", "lang": "Python", "content": "def rename_pipeline(repo_dir):\n    nimbusml_path = os.path.join(repo_dir, 'src', 'python', 'nimbusml')\n    os.rename(os.path.join(nimbusml_path, 'pipeline.py'),\n              os.path.join(nimbusml_path, '_pipeline.py'))\n\n    replace_file_contents(os.path.join(nimbusml_path, '__init__.py'),\n                          'from .pipeline import Pipeline',\n                          'from ._pipeline import Pipeline')\n\n    replace_file_contents(os.path.join(nimbusml_path, '__init__.py.in'),\n                          'from .pipeline import Pipeline',\n                          'from ._pipeline import Pipeline')\n\n    replace_file_contents(os.path.join(repo_dir, 'src', 'python', 'nimbusml.pyproj'),\n                          r'nimbusml\\pipeline.py',\n                          r'nimbusml\\_pipeline.py')\n\n    replace_file_contents(os.path.join(nimbusml_path, 'tests', 'test_syntax_expected_failures.py'),\n                          'from nimbusml.pipeline import TrainedWarning',\n                          'from nimbusml._pipeline import TrainedWarning')", "fn_id": 12, "class_fn": false, "repo": "montehoover/NimbusML", "file": "src/python/tools/temp_docs_updater.py", "last_update_at": "2019-05-04T11:30:08+00:00", "question_id": "3915d19ecd09e5ec36b6ebd18aaee67a5effccd6_12", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def rename_pipeline(repo_dir):\n    nimbusml_path = os.path.join(repo_dir, 'src', 'python', 'nimbusml')\n    os.rename(os.path.join(nimbusml_path, 'pipeline.py'), os.path.join(nimbusml_path, '_pipeline.py'))\n    replace_file_contents(os.path.join(nimbusml_path, '__init__.py'), 'from .pipeline import Pipeline', 'from ._pipeline import Pipeline')\n    replace_file_contents(os.path.join(nimbusml_path, '__init__.py.in'), 'from .pipeline import Pipeline', 'from ._pipeline import Pipeline')\n    replace_file_contents(os.path.join(repo_dir, 'src', 'python', 'nimbusml.pyproj'), 'nimbusml\\\\pipeline.py', 'nimbusml\\\\_pipeline.py')\n"]]}
{"hexsha": "d9e89989f24ddd8018772c7d57dea385966e9438", "ext": "py", "lang": "Python", "content": "def table_generic(dbse, serrors,\n    mtd, bas, columnplan, rowplan=['bas', 'mtd'],\n    opt=['CP'], err=['mae'], sset=['default'],\n    landscape=False, standalone=True, subjoin=True, suppressblanks=False,\n    footnotes=[], title='', indextitle='',\n    plotpath='', theme=''):\n    \"\"\"\n    Arrays *mtd* and *bas* contain the keys to the qcdb.Method and\n    qcdb.BasisSet objects that span all those that the table may\n    encompass. If method and basis are to be scanned over, the arrays\n    should be in the desired order.\n\n    \"\"\"\n    def table_header(kw, abbr, head1, head0, head2):\n        \"\"\"Form table header\"\"\"\n        ref = r\"\"\"tbl:qcdb-%s-%s\"\"\" % (theme, '-'.join([kw[bit] for bit in tag]))\n        fancy_kw = {k: (mc_archive[k][v].latex if k in mc_archive else v) for k, v in items(kw)}\n        text.append('')\n        text.append(r\"\"\"\\begingroup\"\"\")\n        text.append(r\"\"\"\\squeezetable\"\"\")\n        text.append(r\"\"\"\\begin{%s}[h!tp]\"\"\" % ('sidewaystable' if landscape else 'table'))\n        text.append(r\"\"\"\\renewcommand{\\baselinestretch}{1}\"\"\")\n        text.append(r\"\"\"\\caption{%s\"\"\" % (title.format(**fancy_kw).replace('_', '\\\\_')))\n        text.append(r\"\"\"\\label{%s}}\"\"\" % (ref))\n        indices.append(r\"\"\"\\scriptsize \\ref{%s} & \\scriptsize %s \\\\ \"\"\" % \\\n            (ref, indextitle.format(**fancy_kw)))\n        text.append(r\"\"\"\\begin{ruledtabular}\"\"\")\n        text.append(r\"\"\"\\begin{tabular}{%s}\"\"\" % (abbr))\n        text.append(head1)\n        text.append(head0)\n        text.append(head2)\n        text.append(hline)\n\n    def table_footer():\n        \"\"\"Form table footer\"\"\"\n\n        # search-and-replace footnotes\n        fnmatch = re.compile(r\"\"\"(?P<cellpre>.*)\"\"\" + r\"\"\"(\\\\footnotemark)\\{(?P<fntext>.*)\\}\"\"\" + r\"\"\"(?P<cellpost>.*)\"\"\")\n        otfcounter = len(footnotes) + 1\n        lines2replace = {}\n        otffootnotes = collections.OrderedDict()\n        for idx, line in enumerate(text):\n            newcells = []\n            changed = False\n            for cell in line.split('&'):\n                res = fnmatch.match(cell)\n                if res:\n                    if res.group('fntext') in otffootnotes:\n                        localcounter = otffootnotes[res.group('fntext')]\n                    else:\n                        localcounter = otfcounter\n                        if localcounter == 52:  # fn symbols run out at \"zz\"\n                            otffootnotes['Missing some reactions'] = localcounter\n                        else:\n                            otfcounter += 1\n                            otffootnotes[res.group('fntext')] = localcounter\n                    newcells.append(res.group('cellpre') + r\"\"\"\\footnotemark[\"\"\" + str(localcounter) + ']' + res.group('cellpost'))\n                    changed = True\n                else:\n                    newcells.append(cell)\n            if changed:\n                lines2replace[idx] = '&'.join(newcells)\n        for idx, line in items(lines2replace):\n            text[idx] = line\n\n        # search-and-suppress \"blank\" lines\n        if suppressblanks:\n            for idx, line in enumerate(text):\n                if line.strip().endswith('\\\\'):\n                    innards = ''.join(line.rstrip(\"\"\" \\\\\"\"\").split('&')[1:])\n                    if innards.isspace():\n                        text[idx] = '%' + text[idx]\n\n        # finish out table\n        text.append(r\"\"\"\\end{tabular}\"\"\")\n        text.append(r\"\"\"\\end{ruledtabular}\"\"\")\n        for idx, fn in enumerate(footnotes):\n            text.append(r\"\"\"\\footnotetext[%d]{%s}\"\"\" % (idx + 1, fn))\n        for fn, idx in items(otffootnotes):\n            text.append(r\"\"\"\\footnotetext[%d]{%s}\"\"\" % (idx, fn))\n        text.append(r\"\"\"\\end{%s}\"\"\" % ('sidewaystable' if landscape else 'table'))\n        text.append(r\"\"\"\\endgroup\"\"\")\n        text.append(r\"\"\"\\clearpage\"\"\")\n        text.append('')\n\n    def matelem(dict_row, dict_col):\n        \"\"\"Return merge of index dictionaries *dict_row* and *dict_col* (precedence) with error string from serrors appended at key 'matelem'.\"\"\"\n        kw = dict(dict_row, **dict_col)\n        errpiece = serrors['-'.join([kw[bit] for bit in ['mtd', 'opt', 'bas']])][kw['sset']][kw['dbse']]\n        kw['matelem'] = errpiece[kw['err']]\n        if 'tgtcnt' in errpiece:\n            kw['count'] = errpiece['tgtcnt']\n        if 'misscnt' in errpiece and errpiece['misscnt'] != 0 and 'tgtcnt' in errpiece:\n            kw['footnote'] = r\"\"\"\\footnotemark{Missing %d of %d reactions.}\"\"\" % (errpiece['misscnt'], errpiece['tgtcnt'])\n        else:\n            kw['footnote'] = ''\n        return kw\n\n    # avoid misunderstandings\n    keysincolumnplan = set(sum([col[-1].keys() for col in columnplan], []))\n    for key in ['dbse', 'sset', 'mtd', 'opt', 'bas', 'err']:\n        if len(locals()[key]) > 1:\n            if key not in rowplan and key not in keysincolumnplan:\n                print(\"\"\"Warning: non-first values in argument '{0}' won't \"\"\"\n                      \"\"\"get used. Add '{0}' to rowplan to iterate over \"\"\"\n                      \"\"\"the values or add to columnplan to access\"\"\"\n                      \"\"\"different values.\"\"\".format(key))\n                sys.exit()\n\n    # form LaTeX reference tag\n    tag = []\n    for key in ['dbse', 'sset', 'mtd', 'opt', 'bas', 'err']:\n        if len(locals()[key]) == 1 or (key == rowplan[0] and not subjoin):\n            tag.append(key)\n    tag = set(tag)\n    for col in columnplan:\n        tag -= set(col[4].keys())\n\n    # form column headers\n    start = 1\n    stop = 1\n    head0 = ''\n    for index in range(2, len(columnplan)):\n        if columnplan[index][1] == columnplan[index - 1][1]:\n            stop = index\n        else:\n            head0 += r\"\"\"\\cline{%d-%d}\"\"\" % (start + 1, stop + 1)\n            start = index\n            stop = index\n        if index + 1 == len(columnplan):\n            head0 += r\"\"\"\\cline{%d-%d}\"\"\" % (start + 1, stop + 1)\n\n    abbr = ''.join([col[0] for col in columnplan])\n    h1 = [(k, len(list(g))) for k, g in itertools.groupby([col[1] for col in columnplan])]\n    head1 = ' & '.join([r\"\"\"\\multicolumn{%d}{c}{\\textbf{%s}}\"\"\" % (repeat, label) for (label, repeat) in h1]) + r\"\"\" \\\\ \"\"\"\n    h2 = [(k, len(list(g))) for k, g in itertools.groupby([col[2] for col in columnplan])]\n    head2 = ' & '.join([r\"\"\"\\multicolumn{%d}{c}{\\textbf{%s}}\"\"\" % (repeat, label) for (label, repeat) in h2]) + r\"\"\" \\\\ \"\"\"\n\n    # form table body\n    text = []\n    indices = []\n    nH = len(rowplan)\n    hline = r\"\"\"\\hline\"\"\"\n    kw = {'plotpath': plotpath, 'sset': sset[0], 'dbse': dbse[0], 'err': err[0],\n          'mtd': mtd[0], 'opt': opt[0], 'bas': bas[0]}\n\n    if standalone:\n        text += begin_latex_document()\n\n    if nH == 1:\n        subjoin = True\n\n    if subjoin:\n        table_header(kw, abbr, head1, head0, head2)\n        if text[-1] != hline:\n            text.append(hline)\n\n    for hier0 in locals()[rowplan[0]]:\n        kw[rowplan[0]] = hier0\n        kw['target'] = rowplan[0]\n        if nH > 1:\n\n            if not subjoin:\n                table_header(kw, abbr, head1, head0, head2)\n            if text[-1] != hline:\n                text.append(hline)\n            #text.append(r\"\"\"\\textbf{%s} \\\\ \"\"\" % (mc_archive[rowplan[0]][hier0].latex))\n            text.append(r\"\"\"\\textbf{%s} \\\\ \"\"\" % (label2(hier0)))\n\n            for hier1 in locals()[rowplan[1]]:\n                kw[rowplan[1]] = hier1\n                kw['target'] = rowplan[1]\n                if nH > 2:\n                    #text.append(r\"\"\"\\enspace\\textbf{%s} \\\\ \"\"\" % (mc_archive[rowplan[1]][hier1].latex))\n                    text.append(r\"\"\"\\enspace\\textbf{%s} \\\\ \"\"\" % (label2(hier1)))\n\n                    for hier2 in locals()[rowplan[2]]:\n                        kw[rowplan[2]] = hier2\n                        kw['target'] = rowplan[2]\n\n                        text.append(r\"\"\"\\enspace\\enspace\"\"\" + ' & '.join([col[3](matelem(kw, col[4])) for col in columnplan]) + r\"\"\" \\\\ \"\"\")\n                else:\n                    text.append(r\"\"\"\\enspace\"\"\" + ' & '.join([col[3](matelem(kw, col[4])) for col in columnplan]) + r\"\"\" \\\\ \"\"\")\n            if not subjoin:\n                table_footer()\n        else:\n            text.append(' & '.join([col[3](matelem(kw, col[4])) for col in columnplan]) + r\"\"\" \\\\ \"\"\")\n\n    if subjoin:\n        table_footer()\n\n    if standalone:\n        text += end_latex_document()\n\n    return text, indices", "fn_id": 3, "class_fn": false, "repo": "nuwandesilva/qcdb", "file": "qcdb/textables.py", "last_update_at": "2019-02-20T20:18:02+00:00", "question_id": "d9e89989f24ddd8018772c7d57dea385966e9438_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def table_generic(dbse, serrors, mtd, bas, columnplan, rowplan=['bas', 'mtd'], opt=['CP'], err=['mae'], sset=['default'], landscape=False, standalone=True, subjoin=True, suppressblanks=False, footnotes=[], title='', indextitle='', plotpath='', theme=''):\n    \"\"\"\n    Arrays *mtd* and *bas* contain the keys to the qcdb.Method and\n    qcdb.BasisSet objects that span all those that the table may\n    encompass. If method and basis are to be scanned over, the arrays\n    should be in the desired order.\n\n    \"\"\"\n\n    def table_header(kw, abbr, head1, head0, head2):\n        \"\"\"Form table header\"\"\"\n        ref = 'tbl:qcdb-%s-%s' % (theme, '-'.join([kw[bit] for bit in tag]))\n        fancy_kw = {k: mc_archive[k][v].latex if k in mc_archive else v for k, v in items(kw)}\n        text.append('')\n        text.append('\\\\begingroup')\n        text.append('\\\\squeezetable')\n        text.append('\\\\begin{%s}[h!tp]' % ('sidewaystable' if landscape else 'table'))\n        text.append('\\\\renewcommand{\\\\baselinestretch}{1}')\n        text.append('\\\\caption{%s' % title.format(**fancy_kw).replace('_', '\\\\_'))\n        text.append('\\\\label{%s}}' % ref)\n        indices.append('\\\\scriptsize \\\\ref{%s} & \\\\scriptsize %s \\\\\\\\ ' % (ref, indextitle.format(**fancy_kw)))\n        text.append('\\\\begin{ruledtabular}')\n        text.append('\\\\begin{tabular}{%s}' % abbr)\n        text.append(head1)\n        text.append(head0)\n        text.append(head2)\n        text.append(hline)\n\n    def table_footer():\n        \"\"\"Form table footer\"\"\"\n        fnmatch = re.compile('(?P<cellpre>.*)' + '(\\\\\\\\footnotemark)\\\\{(?P<fntext>.*)\\\\}' + '(?P<cellpost>.*)')\n        otfcounter = len(footnotes) + 1\n        lines2replace = {}\n        otffootnotes = collections.OrderedDict()\n        for idx, line in enumerate(text):\n            newcells = []\n            changed = False\n            for cell in line.split('&'):\n                res = fnmatch.match(cell)\n                if res:\n                    if res.group('fntext') in otffootnotes:\n                        localcounter = otffootnotes[res.group('fntext')]\n                    else:\n                        localcounter = otfcounter\n                        if localcounter == 52:\n                            otffootnotes['Missing some reactions'] = localcounter\n                        else:\n                            otfcounter += 1\n                            otffootnotes[res.group('fntext')] = localcounter\n                    newcells.append(res.group('cellpre') + '\\\\footnotemark[' + str(localcounter) + ']' + res.group('cellpost'))\n                    changed = True\n                else:\n                    newcells.append(cell)\n            if changed:\n                lines2replace[idx] = '&'.join(newcells)\n        for idx, line in items(lines2replace):\n            text[idx] = line\n        if suppressblanks:\n            for idx, line in enumerate(text):\n                if line.strip().endswith('\\\\'):\n                    innards = ''.join(line.rstrip(' \\\\').split('&')[1:])\n                    if innards.isspace():\n                        text[idx] = '%' + text[idx]\n        text.append('\\\\end{tabular}')\n        text.append('\\\\end{ruledtabular}')\n        for idx, fn in enumerate(footnotes):\n            text.append('\\\\footnotetext[%d]{%s}' % (idx + 1, fn))\n        for fn, idx in items(otffootnotes):\n            text.append('\\\\footnotetext[%d]{%s}' % (idx, fn))\n        text.append('\\\\end{%s}' % ('sidewaystable' if landscape else 'table'))\n        text.append('\\\\endgroup')\n        text.append('\\\\clearpage')\n        text.append('')\n\n    def matelem(dict_row, dict_col):\n        \"\"\"Return merge of index dictionaries *dict_row* and *dict_col* (precedence) with error string from serrors appended at key 'matelem'.\"\"\"\n        kw = dict(dict_row, **dict_col)\n        errpiece = serrors['-'.join([kw[bit] for bit in ['mtd', 'opt', 'bas']])][kw['sset']][kw['dbse']]\n        kw['matelem'] = errpiece[kw['err']]\n        if 'tgtcnt' in errpiece:\n            kw['count'] = errpiece['tgtcnt']\n        if 'misscnt' in errpiece and errpiece['misscnt'] != 0 and ('tgtcnt' in errpiece):\n            kw['footnote'] = '\\\\footnotemark{Missing %d of %d reactions.}' % (errpiece['misscnt'], errpiece['tgtcnt'])\n        else:\n            kw['footnote'] = ''\n        return kw\n    keysincolumnplan = set(sum([col[-1].keys() for col in columnplan], []))\n    for key in ['dbse', 'sset', 'mtd', 'opt', 'bas', 'err']:\n        if len(locals()[key]) > 1:\n            if key not in rowplan and key not in keysincolumnplan:\n                print(\"Warning: non-first values in argument '{0}' won't get used. Add '{0}' to rowplan to iterate over the values or add to columnplan to accessdifferent values.\".format(key))\n                sys.exit()\n    tag = []\n    for key in ['dbse', 'sset', 'mtd', 'opt', 'bas', 'err']:\n        if len(locals()[key]) == 1 or (key == rowplan[0] and (not subjoin)):\n            tag.append(key)\n    tag = set(tag)\n    for col in columnplan:\n        tag -= set(col[4].keys())\n    start = 1\n    stop = 1\n    head0 = ''\n    for index in range(2, len(columnplan)):\n        if columnplan[index][1] == columnplan[index - 1][1]:\n            stop = index\n        else:\n            head0 += '\\\\cline{%d-%d}' % (start + 1, stop + 1)\n            start = index\n            stop = index\n        if index + 1 == len(columnplan):\n            head0 += '\\\\cline{%d-%d}' % (start + 1, stop + 1)\n    abbr = ''.join([col[0] for col in columnplan])\n    h1 = [(k, len(list(g))) for k, g in itertools.groupby([col[1] for col in columnplan])]\n    head1 = ' & '.join(['\\\\multicolumn{%d}{c}{\\\\textbf{%s}}' % (repeat, label) for label, repeat in h1]) + ' \\\\\\\\ '\n    h2 = [(k, len(list(g))) for k, g in itertools.groupby([col[2] for col in columnplan])]\n    head2 = ' & '.join(['\\\\multicolumn{%d}{c}{\\\\textbf{%s}}' % (repeat, label) for label, repeat in h2]) + ' \\\\\\\\ '\n    text = []\n    indices = []\n    nH = len(rowplan)\n    hline = '\\\\hline'\n    kw = {'plotpath': plotpath, 'sset': sset[0], 'dbse': dbse[0], 'err': err[0], 'mtd': mtd[0], 'opt': opt[0], 'bas': bas[0]}\n    if standalone:\n        text += begin_latex_document()\n    if nH == 1:\n        subjoin = True\n    if subjoin:\n        table_header(kw, abbr, head1, head0, head2)\n        if text[-1] != hline:\n            text.append(hline)\n    for hier0 in locals()[rowplan[0]]:\n        kw[rowplan[0]] = hier0\n        kw['target'] = rowplan[0]\n        if nH > 1:\n            if not subjoin:\n                table_header(kw, abbr, head1, head0, head2)\n            if text[-1] != hline:\n                text.append(hline)\n            text.append('\\\\textbf{%s} \\\\\\\\ ' % label2(hier0))\n            for hier1 in locals()[rowplan[1]]:\n                kw[rowplan[1]] = hier1\n                kw['target'] = rowplan[1]\n                if nH > 2:\n                    text.append('\\\\enspace\\\\textbf{%s} \\\\\\\\ ' % label2(hier1))\n                    for hier2 in locals()[rowplan[2]]:\n                        kw[rowplan[2]] = hier2\n                        kw['target'] = rowplan[2]\n                        text.append('\\\\enspace\\\\enspace' + ' & '.join([col[3](matelem(kw, col[4])) for col in columnplan]) + ' \\\\\\\\ ')\n                else:\n                    text.append('\\\\enspace' + ' & '.join([col[3](matelem(kw, col[4])) for col in columnplan]) + ' \\\\\\\\ ')\n            if not subjoin:\n                table_footer()\n        else:\n            text.append(' & '.join([col[3](matelem(kw, col[4])) for col in columnplan]) + ' \\\\\\\\ ')\n    if subjoin:\n        table_footer()\n    if standalone:\n        text += end_latex_document()\n"]]}
{"hexsha": "f7cd31781b011723ebdc34860cfef948b5991c38", "ext": "py", "lang": "Python", "content": "def get_relative_path(filepath, root, return_name_if_fail=True):\n    # without '/' in head/foot\n    filepath = same_slash(filepath)\n    root = same_slash(root)\n    if filepath and root and filepath.startswith(root+'/'):\n        return filepath.replace(root, '').strip('/')\n    elif filepath == root:\n        return ''\n    else:\n        if return_name_if_fail:\n            return os.path.split(filepath)[-1]\n        else:\n            return filepath", "fn_id": 7, "class_fn": false, "repo": "hepochen/Bitcron-CLI", "file": "bitcron/utils/path.py", "last_update_at": "2019-01-14T03:05:18+00:00", "question_id": "f7cd31781b011723ebdc34860cfef948b5991c38_7", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_relative_path(filepath, root, return_name_if_fail=True):\n    filepath = same_slash(filepath)\n    root = same_slash(root)\n    if filepath and root and filepath.startswith(root + '/'):\n        return filepath.replace(root, '').strip('/')\n    elif filepath == root:\n        return ''\n    elif return_name_if_fail:\n        return os.path.split(filepath)[-1]\n    else:\n"]]}
{"hexsha": "8f1aca9e6196f7def8e8a7695baa06c4092d0d61", "ext": "py", "lang": "Python", "content": "def test_Thompson2003Spatial():\n    # Thompson2003Spatial automatically sets `radius`:\n    model = Thompson2003Spatial(engine='serial', xystep=5)\n    # User can set `radius`:\n    model.radius = 123\n    npt.assert_equal(model.radius, 123)\n    model.build(radius=987)\n    npt.assert_equal(model.radius, 987)\n\n    # Nothing in, None out:\n    npt.assert_equal(model.predict_percept(ArgusI()), None)\n\n    # Converting ret <=> dva\n    model2 = Thompson2003Spatial(retinotopy=Watson2014DisplaceMap())\n    npt.assert_equal(isinstance(model2.retinotopy, Watson2014DisplaceMap),\n                     True)\n\n    implant = ArgusI(stim=np.zeros(16))\n    # Zero in = zero out:\n    percept = model.predict_percept(implant)\n    npt.assert_equal(isinstance(percept, Percept), True)\n    npt.assert_equal(percept.shape, list(model.grid.x.shape) + [1])\n    npt.assert_almost_equal(percept.data, 0)\n\n    # Multiple frames are processed independently:\n    model = Thompson2003Spatial(engine='serial', radius=200, xystep=5,\n                                xrange=(-20, 20), yrange=(-15, 15))\n    model.build()\n    percept = model.predict_percept(ArgusI(stim={'A1': [1, 0], 'B3': [0, 2]}))\n    npt.assert_equal(percept.shape, list(model.grid.x.shape) + [2])\n    pmax = percept.data.max(axis=(0, 1))\n    npt.assert_almost_equal(percept.data[2, 3, 0], pmax[0])\n    npt.assert_almost_equal(percept.data[2, 3, 1], 0)\n    npt.assert_almost_equal(percept.data[3, 4, 0], 0)\n    npt.assert_almost_equal(percept.data[3, 4, 1], pmax[1])\n    npt.assert_almost_equal(percept.time, [0, 1])", "fn_id": 0, "class_fn": false, "repo": "narenberg/pulse2percept", "file": "pulse2percept/models/tests/test_thompson2003.py", "last_update_at": "2019-07-18T02:19:01+00:00", "question_id": "8f1aca9e6196f7def8e8a7695baa06c4092d0d61_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_Thompson2003Spatial():\n    model = Thompson2003Spatial(engine='serial', xystep=5)\n    model.radius = 123\n    npt.assert_equal(model.radius, 123)\n    model.build(radius=987)\n    npt.assert_equal(model.radius, 987)\n    npt.assert_equal(model.predict_percept(ArgusI()), None)\n    model2 = Thompson2003Spatial(retinotopy=Watson2014DisplaceMap())\n    npt.assert_equal(isinstance(model2.retinotopy, Watson2014DisplaceMap), True)\n    implant = ArgusI(stim=np.zeros(16))\n    percept = model.predict_percept(implant)\n    npt.assert_equal(isinstance(percept, Percept), True)\n    npt.assert_equal(percept.shape, list(model.grid.x.shape) + [1])\n    npt.assert_almost_equal(percept.data, 0)\n    model = Thompson2003Spatial(engine='serial', radius=200, xystep=5, xrange=(-20, 20), yrange=(-15, 15))\n    model.build()\n    percept = model.predict_percept(ArgusI(stim={'A1': [1, 0], 'B3': [0, 2]}))\n    npt.assert_equal(percept.shape, list(model.grid.x.shape) + [2])\n    pmax = percept.data.max(axis=(0, 1))\n    npt.assert_almost_equal(percept.data[2, 3, 0], pmax[0])\n    npt.assert_almost_equal(percept.data[2, 3, 1], 0)\n    npt.assert_almost_equal(percept.data[3, 4, 0], 0)\n    npt.assert_almost_equal(percept.data[3, 4, 1], pmax[1])\n"]]}
{"hexsha": "717ad56f2bb129120333fd8ab53bc274dbd8aea0", "ext": "py", "lang": "Python", "content": "def join_path(src_cls, dest_cls):\n    from collections import defaultdict\n    from django.apps import apps\n\n    models = apps.get_models()\n\n    def key(m):\n        return m._meta.db_table\n\n    def join_graph():\n        edges = defaultdict(list)\n        edge_fields = defaultdict(dict)\n        for model in models:\n            for field in model._meta.get_fields():\n                if field.is_relation and hasattr(field, 'column') and not field.null:\n                    edges[key(model)].append(key(field.related_model))\n                    edge_fields[key(model)][key(field.related_model)] = field\n\n        return edges, edge_fields\n\n    def bfs(join_graph):\n        frontier = set([key(src_cls)])\n        visited = set()\n        paths = {key(src_cls): []}\n\n        while len(frontier) > 0:\n            new_frontier = set()\n            for node in frontier:\n                adjacent_unvisited = set(join_graph[node]) - visited - frontier\n                for other in adjacent_unvisited:\n                    paths[other] = paths[node] + [node]\n                new_frontier |= adjacent_unvisited\n\n            visited |= frontier\n            frontier = new_frontier\n\n        return {k: v + [k] for k, v in paths.items()}\n\n    keymap = {key(m): m for m in models}\n    graph, fields = join_graph()\n    paths = bfs(graph)\n    path = paths[key(dest_cls)]\n    return [\n        fields[path[i]][path[i+1]]\n        for i in range(len(path) - 1)\n    ]", "fn_id": 0, "class_fn": false, "repo": "DanFu09/esper", "file": "app/esper/scannerutil.py", "last_update_at": "2019-01-04T10:35:02+00:00", "question_id": "717ad56f2bb129120333fd8ab53bc274dbd8aea0_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def join_path(src_cls, dest_cls):\n    from collections import defaultdict\n    from django.apps import apps\n    models = apps.get_models()\n\n    def key(m):\n        return m._meta.db_table\n\n    def join_graph():\n        edges = defaultdict(list)\n        edge_fields = defaultdict(dict)\n        for model in models:\n            for field in model._meta.get_fields():\n                if field.is_relation and hasattr(field, 'column') and (not field.null):\n                    edges[key(model)].append(key(field.related_model))\n                    edge_fields[key(model)][key(field.related_model)] = field\n        return (edges, edge_fields)\n\n    def bfs(join_graph):\n        frontier = set([key(src_cls)])\n        visited = set()\n        paths = {key(src_cls): []}\n        while len(frontier) > 0:\n            new_frontier = set()\n            for node in frontier:\n                adjacent_unvisited = set(join_graph[node]) - visited - frontier\n                for other in adjacent_unvisited:\n                    paths[other] = paths[node] + [node]\n                new_frontier |= adjacent_unvisited\n            visited |= frontier\n            frontier = new_frontier\n        return {k: v + [k] for k, v in paths.items()}\n    keymap = {key(m): m for m in models}\n    graph, fields = join_graph()\n    paths = bfs(graph)\n    path = paths[key(dest_cls)]\n"]]}
{"hexsha": "ee11deaec446d784f5f955b46864d0df98eee2e0", "ext": "py", "lang": "Python", "content": "def is_numeric(s):\n\n    try:\n        x = int(s)\n    except:\n        try:\n            x = float(s)\n        except:\n            x = None\n    return x", "fn_id": 2, "class_fn": false, "repo": "kwoolter/PyCricket", "file": "kwutils.py", "last_update_at": "2019-08-20T09:35:40+00:00", "question_id": "ee11deaec446d784f5f955b46864d0df98eee2e0_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def is_numeric(s):\n    try:\n        x = int(s)\n    except:\n        try:\n            x = float(s)\n        except:\n            x = None\n"]]}
{"hexsha": "95754b0d82888e92ec67beda7a4ca0f430c704ca", "ext": "py", "lang": "Python", "content": "def mocked_get_user_profiles(usernames, token=None):\n    \"\"\"\n    mocks get_user_profiles in src/utils/user_profiles.py\n\n    :param usernames:\n    :return:\n    \"\"\"\n    profiles = []\n    for username in usernames:\n        found, profile = get_data(f'UserProfile/get_profile/{username}.json')\n        if not found:\n            profiles.append(None)\n        else:\n            profiles.append(profile)\n    return profiles", "fn_id": 2, "class_fn": false, "repo": "kbase/search_api_deluxe", "file": "tests/unit/mocks/mocked.py", "last_update_at": "2019-04-17T20:31:52+00:00", "question_id": "95754b0d82888e92ec67beda7a4ca0f430c704ca_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def mocked_get_user_profiles(usernames, token=None):\n    \"\"\"\n    mocks get_user_profiles in src/utils/user_profiles.py\n\n    :param usernames:\n    :return:\n    \"\"\"\n    profiles = []\n    for username in usernames:\n        found, profile = get_data(f'UserProfile/get_profile/{username}.json')\n        if not found:\n            profiles.append(None)\n        else:\n            profiles.append(profile)\n"]]}
{"hexsha": "4c8f26472ed09522208b73357645ffd2a4092d1f", "ext": "py", "lang": "Python", "content": "def handlefile(file):\n    if this.usefilesize:\n        tuple = (str(os.path.basename(file)), max(1, int(os.path.getsize(file))))\n        return tuple\n    else:\n        return str(os.path.basename(file))", "fn_id": 2, "class_fn": false, "repo": "Benthem/FDGPT", "file": "inputgenerator.py", "last_update_at": "2019-10-25T00:36:55+00:00", "question_id": "4c8f26472ed09522208b73357645ffd2a4092d1f_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def handlefile(file):\n    if this.usefilesize:\n        tuple = (str(os.path.basename(file)), max(1, int(os.path.getsize(file))))\n        return tuple\n    else:\n"]]}
{"hexsha": "397459c21ff9f5f55b327438544d98c86fdd12ea", "ext": "py", "lang": "Python", "content": "def build(capi_home):\n    CAPIDependency.set_lib_install_base(capi_home)\n    build_libpython(capi_home)\n    build_builtin_exts(capi_home)", "fn_id": 3, "class_fn": false, "repo": "transposit/graalpython", "file": "graalpython/com.oracle.graal.python.cext/setup.py", "last_update_at": "2019-05-28T13:04:32+00:00", "question_id": "397459c21ff9f5f55b327438544d98c86fdd12ea_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def build(capi_home):\n    CAPIDependency.set_lib_install_base(capi_home)\n    build_libpython(capi_home)\n"]]}
{"hexsha": "c27de865ef89a22739952ae7e78078d815b3e39b", "ext": "py", "lang": "Python", "content": "@patch('fix_rpath_osx.add_loader_path')\n@patch('fix_rpath_osx.add_id')\n@patch('fix_rpath_osx.get_file_object_from_prefix')\n@patch('subprocess.check_call')\ndef test_main(\n        mock_call,\n        mock_get_files,\n        mock_get_id,\n        mock_add_loader_path,\n        amber_src, libcpptraj):\n    mock_get_files.return_value = [os.path.join(amber_src, libcpptraj)]\n    fix_rpath_osx.main([amber_src])\n    mock_get_id.assert_called_with(libcpptraj)\n    mock_add_loader_path.assert_called_with(libcpptraj, amberhome, 'lib')", "fn_id": 4, "class_fn": false, "repo": "Amber-MD/ambertools-binary-build", "file": "conda_tools/test/test_fix_rpath_osx.py", "last_update_at": "2019-12-14T01:15:50+00:00", "question_id": "c27de865ef89a22739952ae7e78078d815b3e39b_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@patch('fix_rpath_osx.add_loader_path')\n@patch('fix_rpath_osx.add_id')\n@patch('fix_rpath_osx.get_file_object_from_prefix')\n@patch('subprocess.check_call')\ndef test_main(mock_call, mock_get_files, mock_get_id, mock_add_loader_path, amber_src, libcpptraj):\n    mock_get_files.return_value = [os.path.join(amber_src, libcpptraj)]\n    fix_rpath_osx.main([amber_src])\n    mock_get_id.assert_called_with(libcpptraj)\n"]]}
{"hexsha": "afa3041a17765426e295369c955004ec3b8f9e91", "ext": "py", "lang": "Python", "content": "@pytest.fixture()\ndef AnsibleDefaults(Ansible):\n    \"\"\" Load default variables into dictionary.\n\n    Args:\n        Ansible - Requires the ansible connection backend.\n    \"\"\"\n    return Ansible(\"include_vars\", \"./defaults/main.yml\")[\"ansible_facts\"]", "fn_id": 0, "class_fn": false, "repo": "alessandrolulli/ansible-role-scala", "file": "tests/test_scala.py", "last_update_at": "2019-08-11T13:27:29+00:00", "question_id": "afa3041a17765426e295369c955004ec3b8f9e91_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.fixture()\ndef AnsibleDefaults(Ansible):\n    \"\"\" Load default variables into dictionary.\n\n    Args:\n        Ansible - Requires the ansible connection backend.\n    \"\"\"\n"]]}
{"hexsha": "494506121809d3d96d257bf22d7ebd5a197aa68b", "ext": "py", "lang": "Python", "content": "def first3(set):\n    p = newPoint()\n    while (p == set[0]):\n        p = newPoint()\n    set.append(p)\n    p = newPoint()\n    while(p == set[0] or p == set[1]):\n        p = newPoint()\n    set.append(p)\n    find_max_min(set)", "fn_id": 1, "class_fn": false, "repo": "apletea/MMF_Labs", "file": "Computational Geometry/dynamic_hull.py", "last_update_at": "2019-01-11T08:11:39+00:00", "question_id": "494506121809d3d96d257bf22d7ebd5a197aa68b_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def first3(set):\n    p = newPoint()\n    while p == set[0]:\n        p = newPoint()\n    set.append(p)\n    p = newPoint()\n    while p == set[0] or p == set[1]:\n        p = newPoint()\n    set.append(p)\n"]]}
{"hexsha": "2eb5701c07a0400a66b1bcc8bf35e6b0c13cef54", "ext": "py", "lang": "Python", "content": "def _precision_v_cost():\n    import math\n\n    #\n    LOOPS = 10**6\n    #\n    print(\"time.time_ns(): %s\" % time.time_ns())\n    print(\"time.time():    %s\\r\\n\" % time.time())\n    #\n    starts = time.time_ns()\n    min_dt = [abs(time.time_ns() - time.time_ns()) for _ in range(LOOPS)]\n    min_dt = min(filter(bool, min_dt))\n    print(\"min delta   time_ns(): %s ns\" % min_dt)\n    print(\"duration    time_ns(): %s ns\\r\\n\" % (time.time_ns() - starts))\n    #\n    starts = time.time_ns()\n    min_dt = [abs(time.time() - time.time()) for _ in range(LOOPS)]\n    min_dt = min(filter(bool, min_dt))\n    print(\"min delta      time(): %s ns\" % math.ceil(min_dt * 1e9))\n    print(\"duration       time(): %s ns\\r\\n\" % (time.time_ns() - starts))\n    #\n    starts = time.time_ns()\n    min_dt = [abs(timestamp() - timestamp()) for _ in range(LOOPS)]\n    min_dt = min(filter(bool, min_dt))\n    print(\"min delta timestamp(): %s ns\" % math.ceil(min_dt * 1e9))\n    print(\"duration  timestamp(): %s ns\\r\\n\" % (time.time_ns() - starts))\n    #\n    LOOPS = 10**4\n    #\n    starts = time.time_ns()\n    min_td = [abs(dt.now() - dt.now()) for _ in range(LOOPS)]\n    min_td = min(filter(bool, min_td))\n    print(\"min delta dt.now(): %s ns\" % math.ceil(min_dt * 1e9))\n    print(\"duration  dt.now(): %s ns\\r\\n\" % (time.time_ns() - starts))\n    #\n    starts = time.time_ns()\n    min_td = [abs(dt_now() - dt_now()) for _ in range(LOOPS)]\n    min_td = min(filter(bool, min_td))\n    print(\"min delta dt_now(): %s ns\" % math.ceil(min_dt * 1e9))\n    print(\"duration  dt_now(): %s ns\\r\\n\" % (time.time_ns() - starts))\n    #\n    starts = time.time_ns()\n    min_td = [\n        abs(\n            (dt_now if sys.platform == \"win32\" else dt.now)()\n            - (dt_now if sys.platform == \"win32\" else dt.now)()\n        )\n        for _ in range(LOOPS)\n    ]\n    min_td = min(filter(bool, min_td))\n    print(\"min delta dt_now(): %s ns\" % math.ceil(min_dt * 1e9))\n    print(\"duration  dt_now(): %s ns\\r\\n\" % (time.time_ns() - starts))\n    #\n    dt_nov = dt_now if sys.platform == \"win32\" else dt.now\n    starts = time.time_ns()\n    min_td = [abs(dt_nov() - dt_nov()) for _ in range(LOOPS)]\n    min_td = min(filter(bool, min_td))\n    print(\"min delta dt_now(): %s ns\" % math.ceil(min_dt * 1e9))\n    print(\"duration  dt_now(): %s ns\\r\\n\" % (time.time_ns() - starts))", "fn_id": 17, "class_fn": false, "repo": "zxdavb/evohome", "file": "ramses_rf/protocol/helpers.py", "last_update_at": "2019-06-23T22:36:33+00:00", "question_id": "2eb5701c07a0400a66b1bcc8bf35e6b0c13cef54_17", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _precision_v_cost():\n    import math\n    LOOPS = 10 ** 6\n    print('time.time_ns(): %s' % time.time_ns())\n    print('time.time():    %s\\r\\n' % time.time())\n    starts = time.time_ns()\n    min_dt = [abs(time.time_ns() - time.time_ns()) for _ in range(LOOPS)]\n    min_dt = min(filter(bool, min_dt))\n    print('min delta   time_ns(): %s ns' % min_dt)\n    print('duration    time_ns(): %s ns\\r\\n' % (time.time_ns() - starts))\n    starts = time.time_ns()\n    min_dt = [abs(time.time() - time.time()) for _ in range(LOOPS)]\n    min_dt = min(filter(bool, min_dt))\n    print('min delta      time(): %s ns' % math.ceil(min_dt * 1000000000.0))\n    print('duration       time(): %s ns\\r\\n' % (time.time_ns() - starts))\n    starts = time.time_ns()\n    min_dt = [abs(timestamp() - timestamp()) for _ in range(LOOPS)]\n    min_dt = min(filter(bool, min_dt))\n    print('min delta timestamp(): %s ns' % math.ceil(min_dt * 1000000000.0))\n    print('duration  timestamp(): %s ns\\r\\n' % (time.time_ns() - starts))\n    LOOPS = 10 ** 4\n    starts = time.time_ns()\n    min_td = [abs(dt.now() - dt.now()) for _ in range(LOOPS)]\n    min_td = min(filter(bool, min_td))\n    print('min delta dt.now(): %s ns' % math.ceil(min_dt * 1000000000.0))\n    print('duration  dt.now(): %s ns\\r\\n' % (time.time_ns() - starts))\n    starts = time.time_ns()\n    min_td = [abs(dt_now() - dt_now()) for _ in range(LOOPS)]\n    min_td = min(filter(bool, min_td))\n    print('min delta dt_now(): %s ns' % math.ceil(min_dt * 1000000000.0))\n    print('duration  dt_now(): %s ns\\r\\n' % (time.time_ns() - starts))\n    starts = time.time_ns()\n    min_td = [abs((dt_now if sys.platform == 'win32' else dt.now)() - (dt_now if sys.platform == 'win32' else dt.now)()) for _ in range(LOOPS)]\n    min_td = min(filter(bool, min_td))\n    print('min delta dt_now(): %s ns' % math.ceil(min_dt * 1000000000.0))\n    print('duration  dt_now(): %s ns\\r\\n' % (time.time_ns() - starts))\n    dt_nov = dt_now if sys.platform == 'win32' else dt.now\n    starts = time.time_ns()\n    min_td = [abs(dt_nov() - dt_nov()) for _ in range(LOOPS)]\n    min_td = min(filter(bool, min_td))\n    print('min delta dt_now(): %s ns' % math.ceil(min_dt * 1000000000.0))\n"]]}
{"hexsha": "827137b7e453645a2d2939d239b6c97417cdd5d8", "ext": "py", "lang": "Python", "content": "def test_cooper_nathans():\n    \"\"\"Test Cooper Nathans method\n    \"\"\"\n    R0 = 2117.45739160280\n    RMS = np.array([[9154.39386475516, 7.32203491574463e-11, 0, 7.11894676107400e-12],\n                    [2.68712790277282e-10, 340628.383580632, 0, -32536.7077302429],\n                    [0, 0, 634.724632931705, 0],\n                    [2.58004722905037e-11, -32536.7077302429, 0, 3114.58144514260]])\n    ResVol0 = (2 * np.pi) ** 2 / np.sqrt(np.linalg.det(RMS)) * 2\n    angles0 = np.array([-20.58848852, -41.17697704, -78.6627354, 22.67452921, -20.58848852, -41.17697704])\n    BraggWidths0 = np.array(\n        [0.0492235489748347, 0.00806951257792662, 0.186936902874783, 1.82137589975272, 0.0843893950600324])\n\n    EXP = EXP_coopernathans\n    hkle = [1., 0., 0., 0.]\n\n    EXP.calc_resolution(hkle)\n\n    NP = EXP.RMS\n    R = EXP.R0\n    BraggWidths = instrument.tools.get_bragg_widths(NP)\n    angles = EXP_coopernathans.get_angles_and_Q(hkle)[0]\n    ResVol = (2 * np.pi) ** 2 / np.sqrt(np.linalg.det(NP)) * 2\n\n    assert (np.all(np.abs((RMS - NP)) < 100))\n    assert (abs(R - R0) < 1e-3)\n    assert (abs(ResVol - ResVol0) < 1e-5)\n    assert (np.all(np.abs((BraggWidths - BraggWidths0)) < 0.1))\n    assert (np.all(np.abs((angles0 - angles)) < 0.1))", "fn_id": 6, "class_fn": false, "repo": "neutronpy/neutronpy", "file": "tests/test_resolution_tas.py", "last_update_at": "2019-05-28T03:47:32+00:00", "question_id": "827137b7e453645a2d2939d239b6c97417cdd5d8_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_cooper_nathans():\n    \"\"\"Test Cooper Nathans method\n    \"\"\"\n    R0 = 2117.4573916028\n    RMS = np.array([[9154.39386475516, 7.32203491574463e-11, 0, 7.118946761074e-12], [2.68712790277282e-10, 340628.383580632, 0, -32536.7077302429], [0, 0, 634.724632931705, 0], [2.58004722905037e-11, -32536.7077302429, 0, 3114.5814451426]])\n    ResVol0 = (2 * np.pi) ** 2 / np.sqrt(np.linalg.det(RMS)) * 2\n    angles0 = np.array([-20.58848852, -41.17697704, -78.6627354, 22.67452921, -20.58848852, -41.17697704])\n    BraggWidths0 = np.array([0.0492235489748347, 0.00806951257792662, 0.186936902874783, 1.82137589975272, 0.0843893950600324])\n    EXP = EXP_coopernathans\n    hkle = [1.0, 0.0, 0.0, 0.0]\n    EXP.calc_resolution(hkle)\n    NP = EXP.RMS\n    R = EXP.R0\n    BraggWidths = instrument.tools.get_bragg_widths(NP)\n    angles = EXP_coopernathans.get_angles_and_Q(hkle)[0]\n    ResVol = (2 * np.pi) ** 2 / np.sqrt(np.linalg.det(NP)) * 2\n    assert np.all(np.abs(RMS - NP) < 100)\n    assert abs(R - R0) < 0.001\n    assert abs(ResVol - ResVol0) < 1e-05\n    assert np.all(np.abs(BraggWidths - BraggWidths0) < 0.1)\n"]]}
{"hexsha": "8d4a49565b30a8d5c68c86e60ba2796eb53b98bd", "ext": "py", "lang": "Python", "content": "@app.route('/hello/')\n@app.route('/hello/<name>')\ndef hello_world(name=None):\n    return 'Hello World! Welcome ' + str(name)\n", "fn_id": 1, "class_fn": false, "repo": "zerbobo/fdsns", "file": "fdsns/server/web_site.py", "last_update_at": "2019-05-31T06:09:54+00:00", "question_id": "8d4a49565b30a8d5c68c86e60ba2796eb53b98bd_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@app.route('/hello/')\n@app.route('/hello/<name>')\ndef hello_world(name=None):\n"]]}
{"hexsha": "cd1363d9ddd3a2c959305968ea85e71439df7ac8", "ext": "py", "lang": "Python", "content": "def test_get_receipts_without_node_url(mocker):\n    \"\"\"\n    Case: get a list of the transaction's receipts without passing node URL.\n    Expect: a list of the transaction's receipts is returned from a node on localhost.\n    \"\"\"\n    expected_list_of_receipts = [\n        {\n            'data': [],\n            'events': [],\n            'id': 'e79a883581c184787360de8607c5f970cdeeaa684af3e50d8532aa9dd07afa8e'\n                  '7fc92f0dc509b41b9695e795704bdd50455bebd1ed327a5330710ba40698b492',\n            'state_changes': [\n                {\n                    'address': '00b10c0100000000000000000000000000000000000000000000000000000000000000',\n                    'type': 'SET',\n                    'value': 'CL0BGIACIKwC',\n                },\n                {\n                    'address': '00b10c00000000000000000000000000000000000000000000000000000000000000bd',\n                    'type': 'SET',\n                    'value': 'CL0BEoABZmQ3ODBjZTA3NjQwYmE0MTEyMjQ4NjkxNTgxYTU5NTg0NWZlNzYyYmYzZmViNDliODQzOTc0Y'\n                             'WFlNTc4NDc4YzZiZjUxODczOWVjZGM0OWQ3MDE5MzgzZDNiZDllM2FhNmZhMGFmODM4NGI0NDkxOGYwYm'\n                             'ZmMzc0MDJiNTEwYjIaQjAyZDFmYmRhNTBkYmNkMGQzYzI4NmE2YTlmYTcxYWE3Y2UyZDk3MTU5YjkwZGR'\n                             'kNDYzZTA4MTY0MjJkNjIxZTEzNSKAAWZlNTZhMTZkYWIwMDljYzk2ZTcxMjVjNjQ3YjZjNzFlYjEwNjM4'\n                             'MThjZjhkZWNlMjgzYjEyNTQyM2VjYjE4NGY3ZjFlNjE4MDJiZjY2MzgyZGE5MDQ2OTg0MTNmODA4MzEwM'\n                             'zFmOGExYjI5MTUwMjYwYzNmYTRkYjUzN2ZkZjRjKIzggeYF',\n                },\n            ],\n        },\n        {\n            'data': [],\n            'events': [],\n            'id': '6593d21046519022ba32c98e934d7dfc81e8b4edf6c064dbf70feb13db431087'\n                  '3ec00816bce8660cafd4fa2a8c80d0147d63cf616c624babd03142c694272017',\n            'state_changes': [\n                {\n                    'address': '00b10c00000000000000000000000000000000000000000000000000000000000000bc',\n                    'type': 'SET',\n                    'value': 'CLwBEoABOWI4Y2NhODk3Nzk2NDJiYWEyMGMwZWUyZjEzOWVlMGNlMWNjYjEwMjY5OTVjNDY3NDYzZDEzOT'\n                             'I0ZDg3YTg3NjNlODMzOWI2YzIyMzNmMTZiY2I5ZDVjNjEwMzVmNzAzY2FiNjBiNzQxMGJlMjJkZjkzNWEy'\n                             'YWE4YmIzNGE1NTcaQjAyZDFmYmRhNTBkYmNkMGQzYzI4NmE2YTlmYTcxYWE3Y2UyZDk3MTU5YjkwZGRkND'\n                             'YzZTA4MTY0MjJkNjIxZTEzNSKAAWZkNzgwY2UwNzY0MGJhNDExMjI0ODY5MTU4MWE1OTU4NDVmZTc2MmJm'\n                             'M2ZlYjQ5Yjg0Mzk3NGFhZTU3ODQ3OGM2YmY1MTg3MzllY2RjNDlkNzAxOTM4M2QzYmQ5ZTNhYTZmYTBhZj'\n                             'gzODRiNDQ5MThmMGJmZjM3NDAyYjUxMGIyKMzfgeYF',\n                },\n                {\n                    'address': '00b10c0100000000000000000000000000000000000000000000000000000000000000',\n                    'type': 'SET',\n                    'value': 'CLwBGIACIKwC',\n                },\n            ],\n        },\n    ]\n\n    mock_get_receipts = mocker.patch('cli.receipt.service.loop.run_until_complete')\n    mock_get_receipts.return_value = expected_list_of_receipts\n\n    runner = CliRunner()\n    result = runner.invoke(cli, [\n        'receipt',\n        'get',\n        '--ids',\n        TRANSACTION_IDENTIFIERS_PRESENTED_ON_THE_TEST_NODE,\n    ])\n\n    expected_node_information = {\n        'result': expected_list_of_receipts,\n    }\n\n    assert PASSED_EXIT_FROM_COMMAND_CODE == result.exit_code\n    assert expected_node_information == json.loads(result.output)", "fn_id": 2, "class_fn": false, "repo": "Remmeauth/remme-core-cli", "file": "tests/receipt/test_get.py", "last_update_at": "2019-08-27T05:32:33+00:00", "question_id": "cd1363d9ddd3a2c959305968ea85e71439df7ac8_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_get_receipts_without_node_url(mocker):\n    \"\"\"\n    Case: get a list of the transaction's receipts without passing node URL.\n    Expect: a list of the transaction's receipts is returned from a node on localhost.\n    \"\"\"\n    expected_list_of_receipts = [{'data': [], 'events': [], 'id': 'e79a883581c184787360de8607c5f970cdeeaa684af3e50d8532aa9dd07afa8e7fc92f0dc509b41b9695e795704bdd50455bebd1ed327a5330710ba40698b492', 'state_changes': [{'address': '00b10c0100000000000000000000000000000000000000000000000000000000000000', 'type': 'SET', 'value': 'CL0BGIACIKwC'}, {'address': '00b10c00000000000000000000000000000000000000000000000000000000000000bd', 'type': 'SET', 'value': 'CL0BEoABZmQ3ODBjZTA3NjQwYmE0MTEyMjQ4NjkxNTgxYTU5NTg0NWZlNzYyYmYzZmViNDliODQzOTc0YWFlNTc4NDc4YzZiZjUxODczOWVjZGM0OWQ3MDE5MzgzZDNiZDllM2FhNmZhMGFmODM4NGI0NDkxOGYwYmZmMzc0MDJiNTEwYjIaQjAyZDFmYmRhNTBkYmNkMGQzYzI4NmE2YTlmYTcxYWE3Y2UyZDk3MTU5YjkwZGRkNDYzZTA4MTY0MjJkNjIxZTEzNSKAAWZlNTZhMTZkYWIwMDljYzk2ZTcxMjVjNjQ3YjZjNzFlYjEwNjM4MThjZjhkZWNlMjgzYjEyNTQyM2VjYjE4NGY3ZjFlNjE4MDJiZjY2MzgyZGE5MDQ2OTg0MTNmODA4MzEwMzFmOGExYjI5MTUwMjYwYzNmYTRkYjUzN2ZkZjRjKIzggeYF'}]}, {'data': [], 'events': [], 'id': '6593d21046519022ba32c98e934d7dfc81e8b4edf6c064dbf70feb13db4310873ec00816bce8660cafd4fa2a8c80d0147d63cf616c624babd03142c694272017', 'state_changes': [{'address': '00b10c00000000000000000000000000000000000000000000000000000000000000bc', 'type': 'SET', 'value': 'CLwBEoABOWI4Y2NhODk3Nzk2NDJiYWEyMGMwZWUyZjEzOWVlMGNlMWNjYjEwMjY5OTVjNDY3NDYzZDEzOTI0ZDg3YTg3NjNlODMzOWI2YzIyMzNmMTZiY2I5ZDVjNjEwMzVmNzAzY2FiNjBiNzQxMGJlMjJkZjkzNWEyYWE4YmIzNGE1NTcaQjAyZDFmYmRhNTBkYmNkMGQzYzI4NmE2YTlmYTcxYWE3Y2UyZDk3MTU5YjkwZGRkNDYzZTA4MTY0MjJkNjIxZTEzNSKAAWZkNzgwY2UwNzY0MGJhNDExMjI0ODY5MTU4MWE1OTU4NDVmZTc2MmJmM2ZlYjQ5Yjg0Mzk3NGFhZTU3ODQ3OGM2YmY1MTg3MzllY2RjNDlkNzAxOTM4M2QzYmQ5ZTNhYTZmYTBhZjgzODRiNDQ5MThmMGJmZjM3NDAyYjUxMGIyKMzfgeYF'}, {'address': '00b10c0100000000000000000000000000000000000000000000000000000000000000', 'type': 'SET', 'value': 'CLwBGIACIKwC'}]}]\n    mock_get_receipts = mocker.patch('cli.receipt.service.loop.run_until_complete')\n    mock_get_receipts.return_value = expected_list_of_receipts\n    runner = CliRunner()\n    result = runner.invoke(cli, ['receipt', 'get', '--ids', TRANSACTION_IDENTIFIERS_PRESENTED_ON_THE_TEST_NODE])\n    expected_node_information = {'result': expected_list_of_receipts}\n    assert PASSED_EXIT_FROM_COMMAND_CODE == result.exit_code\n"]]}
{"hexsha": "eba58f8d38f385cdc8f40025b6685d14d849ee19", "ext": "py", "lang": "Python", "content": "def simulate_quantities_of_interest_superoperator2(U_final):\n    \"\"\"\n    Calculates the quantities of interest from the propagator U_final\n\n    Args:\n        U_final = propagator (either unitary or superoperator)\n\n    Returns\n        phi_cond (float):   conditional phase (deg)\n        L1      (float):    leakage\n        L2      (float):    seepage\n        avgatefid (float):  average gate fidelity in full space\n        avgatefid_compsubspace (float):  average gate fidelity only in the computational subspace\n\n    \"\"\"\n\n    phases = phases_from_superoperator(U_final)\n    phi_cond = phases[-1]\n    L1 = leakage_from_superoperator(U_final)\n    L2 = seepage_from_superoperator(U_final)\n    avgatefid = pro_avfid_superoperator_phasecorrected(U_final,phases)\n    avgatefid_compsubspace = pro_avfid_superoperator_compsubspace_phasecorrected(U_final,L1,phases)     # leakage has to be taken into account, see Woods & Gambetta\n\n    return {'phi_cond': phi_cond, 'L1': L1, 'L2': L2, 'avgatefid_pc': avgatefid, 'avgatefid_compsubspace_pc': avgatefid_compsubspace}", "fn_id": 17, "class_fn": false, "repo": "ZW7436/PycQED_py3", "file": "pycqed/simulations/cz_superoperator_simulation_qdots.py", "last_update_at": "2019-07-05T13:41:51+00:00", "question_id": "eba58f8d38f385cdc8f40025b6685d14d849ee19_17", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def simulate_quantities_of_interest_superoperator2(U_final):\n    \"\"\"\n    Calculates the quantities of interest from the propagator U_final\n\n    Args:\n        U_final = propagator (either unitary or superoperator)\n\n    Returns\n        phi_cond (float):   conditional phase (deg)\n        L1      (float):    leakage\n        L2      (float):    seepage\n        avgatefid (float):  average gate fidelity in full space\n        avgatefid_compsubspace (float):  average gate fidelity only in the computational subspace\n\n    \"\"\"\n    phases = phases_from_superoperator(U_final)\n    phi_cond = phases[-1]\n    L1 = leakage_from_superoperator(U_final)\n    L2 = seepage_from_superoperator(U_final)\n    avgatefid = pro_avfid_superoperator_phasecorrected(U_final, phases)\n    avgatefid_compsubspace = pro_avfid_superoperator_compsubspace_phasecorrected(U_final, L1, phases)\n"]]}
{"hexsha": "43a8676f30b9618e6a6407d51d65db865b9b4523", "ext": "py", "lang": "Python", "content": "def process_message_file(realm_id: int,\n                         slim_mode: bool,\n                         fn: str,\n                         fn_id: str,\n                         files_dir: str,\n                         get_recipient_id: Callable[[ZerverFieldsT], int],\n                         message_key: str,\n                         subscriber_map: Dict[int, Set[int]],\n                         data_dir: str,\n                         output_dir: str,\n                         is_pm_data: bool,\n                         masking_content: bool,\n                         user_id_mapper: IdMapper,\n                         user_handler: UserHandler,\n                         attachment_handler: AttachmentHandler) -> None:\n\n    def get_raw_messages(fn: str) -> List[ZerverFieldsT]:\n        with open(fn) as f:\n            data = ujson.load(f)\n\n        flat_data = [\n            d[message_key]\n            for d in data\n            if message_key in d\n        ]\n\n        def get_raw_message(d: Dict[str, Any]) -> Optional[ZerverFieldsT]:\n            sender_id = get_hipchat_sender_id(\n                realm_id=realm_id,\n                slim_mode=slim_mode,\n                message_dict=d,\n                user_id_mapper=user_id_mapper,\n                user_handler=user_handler,\n            )\n\n            if sender_id is None:\n                return None\n\n            if is_pm_data:\n                # We need to compare with str() on both sides here.\n                # In Stride, user IDs are strings, but in HipChat,\n                # they are integers, and fn_id is always a string.\n                if str(sender_id) != str(fn_id):\n                    # PMs are in multiple places in the Hipchat export,\n                    # and we only use the copy from the sender\n                    return None\n\n            content = d['message']\n\n            if masking_content:\n                content = re.sub('[a-z]', 'x', content)\n                content = re.sub('[A-Z]', 'X', content)\n\n            return dict(\n                fn_id=fn_id,\n                sender_id=sender_id,\n                receiver_id=d.get('receiver', {}).get('id'),\n                content=content,\n                mention_user_ids=d.get('mentions', []),\n                pub_date=str_date_to_float(d['timestamp']),\n                attachment=d.get('attachment'),\n                files_dir=files_dir,\n            )\n\n        raw_messages = []\n\n        for d in flat_data:\n            raw_message = get_raw_message(d)\n            if raw_message is not None:\n                raw_messages.append(raw_message)\n\n        return raw_messages\n\n    raw_messages = get_raw_messages(fn)\n\n    def process_batch(lst: List[Any]) -> None:\n        process_raw_message_batch(\n            realm_id=realm_id,\n            raw_messages=lst,\n            subscriber_map=subscriber_map,\n            user_id_mapper=user_id_mapper,\n            user_handler=user_handler,\n            attachment_handler=attachment_handler,\n            get_recipient_id=get_recipient_id,\n            is_pm_data=is_pm_data,\n            output_dir=output_dir,\n        )\n\n    chunk_size = 1000\n\n    process_list_in_batches(\n        lst=raw_messages,\n        chunk_size=chunk_size,\n        process_batch=process_batch,\n    )", "fn_id": 12, "class_fn": false, "repo": "alexandraciobica/zulip", "file": "zerver/data_import/hipchat.py", "last_update_at": "2019-06-04T09:07:47+00:00", "question_id": "43a8676f30b9618e6a6407d51d65db865b9b4523_12", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def process_message_file(realm_id: int, slim_mode: bool, fn: str, fn_id: str, files_dir: str, get_recipient_id: Callable[[ZerverFieldsT], int], message_key: str, subscriber_map: Dict[int, Set[int]], data_dir: str, output_dir: str, is_pm_data: bool, masking_content: bool, user_id_mapper: IdMapper, user_handler: UserHandler, attachment_handler: AttachmentHandler) -> None:\n\n    def get_raw_messages(fn: str) -> List[ZerverFieldsT]:\n        with open(fn) as f:\n            data = ujson.load(f)\n        flat_data = [d[message_key] for d in data if message_key in d]\n\n        def get_raw_message(d: Dict[str, Any]) -> Optional[ZerverFieldsT]:\n            sender_id = get_hipchat_sender_id(realm_id=realm_id, slim_mode=slim_mode, message_dict=d, user_id_mapper=user_id_mapper, user_handler=user_handler)\n            if sender_id is None:\n                return None\n            if is_pm_data:\n                if str(sender_id) != str(fn_id):\n                    return None\n            content = d['message']\n            if masking_content:\n                content = re.sub('[a-z]', 'x', content)\n                content = re.sub('[A-Z]', 'X', content)\n            return dict(fn_id=fn_id, sender_id=sender_id, receiver_id=d.get('receiver', {}).get('id'), content=content, mention_user_ids=d.get('mentions', []), pub_date=str_date_to_float(d['timestamp']), attachment=d.get('attachment'), files_dir=files_dir)\n        raw_messages = []\n        for d in flat_data:\n            raw_message = get_raw_message(d)\n            if raw_message is not None:\n                raw_messages.append(raw_message)\n        return raw_messages\n    raw_messages = get_raw_messages(fn)\n\n    def process_batch(lst: List[Any]) -> None:\n        process_raw_message_batch(realm_id=realm_id, raw_messages=lst, subscriber_map=subscriber_map, user_id_mapper=user_id_mapper, user_handler=user_handler, attachment_handler=attachment_handler, get_recipient_id=get_recipient_id, is_pm_data=is_pm_data, output_dir=output_dir)\n    chunk_size = 1000\n"]]}
{"hexsha": "74bab1cf6d76463e3de0c503106e22b9ce29949a", "ext": "py", "lang": "Python", "content": "def add_cp_cs(data, Ncp, Ncs):\n    if Ncp > 0 :\n        return np.concatenate([data[-Ncp:],data,data[:Ncs]])\n    else :\n        return add_cs(data, Ncs)", "fn_id": 2, "class_fn": false, "repo": "jdemel/GFDM-PHY-Reference", "file": "simulation/modem/util/cyclic_prefix_suffix.py", "last_update_at": "2019-10-08T15:49:30+00:00", "question_id": "74bab1cf6d76463e3de0c503106e22b9ce29949a_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def add_cp_cs(data, Ncp, Ncs):\n    if Ncp > 0:\n        return np.concatenate([data[-Ncp:], data, data[:Ncs]])\n    else:\n"]]}
{"hexsha": "8fc1e85b663356eedcd79653007e1c7b80cec659", "ext": "py", "lang": "Python", "content": "def runserver():\n    parse_command_line()\n    app = tornado.web.Application(handlers=get_routes(), debug=settings.DEBUG)\n    app.listen(address=options.host, port=options.port)\n    tornado.ioloop.IOLoop.current().start()", "fn_id": 0, "class_fn": false, "repo": "web-rest/tornado-rest-framework", "file": "app.py", "last_update_at": "2019-09-13T13:31:34+00:00", "question_id": "8fc1e85b663356eedcd79653007e1c7b80cec659_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def runserver():\n    parse_command_line()\n    app = tornado.web.Application(handlers=get_routes(), debug=settings.DEBUG)\n    app.listen(address=options.host, port=options.port)\n"]]}
{"hexsha": "72939b19bd35f96d1f6879c56d8535cbe02db51e", "ext": "py", "lang": "Python", "content": "def add_comment(old_method, self, *args, **kwds):\n    \"\"\"\n    for enhence methods\n\n    \"\"\"\n    # print '*** calling: %s%s, kwds=%s' % (old_method.__name__, args, kwds)\n    return_value = old_method(self, *args, **kwds)                  # call the original method\n    v_number = return_value.get_all_vertexes()\n    comment = {\n        k:str(k).encode(\"utf-8\").decode(\"utf-8\")  + \" is a good place\"         # comment\n        for k in v_number\n    }\n    score = {\n        k: 5*random.uniform(0, 1) \n        for k in v_number\n    }\n    return (score, comment)                                 # as the return value of load_csv", "fn_id": 1, "class_fn": false, "repo": "Pantynopants/pyGraph", "file": "Vgraph/recommend.py", "last_update_at": "2019-08-18T06:30:09+00:00", "question_id": "72939b19bd35f96d1f6879c56d8535cbe02db51e_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def add_comment(old_method, self, *args, **kwds):\n    \"\"\"\n    for enhence methods\n\n    \"\"\"\n    return_value = old_method(self, *args, **kwds)\n    v_number = return_value.get_all_vertexes()\n    comment = {k: str(k).encode('utf-8').decode('utf-8') + ' is a good place' for k in v_number}\n    score = {k: 5 * random.uniform(0, 1) for k in v_number}\n"]]}
{"hexsha": "83580f3439dcb18afd5e21eaeff7665a7ba78a05", "ext": "py", "lang": "Python", "content": "def into_ranked_dataframe(similar_from_docvec):\n\t    \"\"\" Takes the output of doc2vec most_similar and puts it into\n\t    a dataframe thats nice to work with \"\"\"\n\t    tmp = pd.DataFrame(similar_from_docvec,columns = ['product_label','sim_score'])\n\t    tmp['rank'] = tmp.index\n\t    tmp['name'] = tmp['product_label'].apply(lambda r: label_decoder[r])\n\t    \n\t    return tmp[['name','rank']].set_index('name')", "fn_id": 0, "class_fn": false, "repo": "dbz10/teefies", "file": "teefies/flask_app/pickykitty/model/predict.py", "last_update_at": "2019-06-26T20:20:43+00:00", "question_id": "83580f3439dcb18afd5e21eaeff7665a7ba78a05_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def into_ranked_dataframe(similar_from_docvec):\n    \"\"\" Takes the output of doc2vec most_similar and puts it into\n\t    a dataframe thats nice to work with \"\"\"\n    tmp = pd.DataFrame(similar_from_docvec, columns=['product_label', 'sim_score'])\n    tmp['rank'] = tmp.index\n    tmp['name'] = tmp['product_label'].apply(lambda r: label_decoder[r])\n"]]}
{"hexsha": "0841c73dd70c1d4f6142fa61561322a01b38bdd0", "ext": "py", "lang": "Python", "content": "def test_gzz():\n    \"gravmag.sphere.gzz python vs cython implementation\"\n    py = _sphere_numpy.gzz(xp, yp, zp, model)\n    cy = sphere.gzz(xp, yp, zp, model)\n    diff = np.abs(py - cy)\n    assert np.all(diff <= precision), 'max diff: %g' % (max(diff))", "fn_id": 7, "class_fn": false, "repo": "silky/fatiando", "file": "test/test_gravmag_sphere.py", "last_update_at": "2019-06-27T11:32:56+00:00", "question_id": "0841c73dd70c1d4f6142fa61561322a01b38bdd0_7", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_gzz():\n    \"\"\"gravmag.sphere.gzz python vs cython implementation\"\"\"\n    py = _sphere_numpy.gzz(xp, yp, zp, model)\n    cy = sphere.gzz(xp, yp, zp, model)\n    diff = np.abs(py - cy)\n"]]}
{"hexsha": "0858bdf07307dd7bb8a3aca228e2e86a3fd595f6", "ext": "py", "lang": "Python", "content": "def test_message_handler_commands_two_handlers(bot: vk_bot.VkBot):\n    @bot.message_handler(commands=['start'])\n    def command_handler(message):\n        message.text_lower = 'not got'\n\n    @bot.message_handler(commands=['help'])\n    def help_handler(message):\n        message.text_lower = 'got'\n\n    msg = vk_bot.Message.from_dict(create_message(text='!help something'))\n    bot._process_new_message(msg)\n\n    assert msg.command == 'help' and msg.text == 'something' and msg.text_lower == 'got'", "fn_id": 1, "class_fn": false, "repo": "Platun0v/VkBotLib", "file": "test/test_bot_pytest.py", "last_update_at": "2019-11-15T17:02:33+00:00", "question_id": "0858bdf07307dd7bb8a3aca228e2e86a3fd595f6_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_message_handler_commands_two_handlers(bot: vk_bot.VkBot):\n\n    @bot.message_handler(commands=['start'])\n    def command_handler(message):\n        message.text_lower = 'not got'\n\n    @bot.message_handler(commands=['help'])\n    def help_handler(message):\n        message.text_lower = 'got'\n    msg = vk_bot.Message.from_dict(create_message(text='!help something'))\n    bot._process_new_message(msg)\n"]]}
{"hexsha": "658885ee39fbcc21373a5c5ce565d321c36d0786", "ext": "py", "lang": "Python", "content": "@warehouse_router.get(\"/\", response_model=List[str])\ndef get_warehouse_names():\n    \"\"\" Gets all unique names of warehouses\n    Returns:\n        list of names (strings), STATUS 200 (list can be empty)\n    \"\"\"\n    return warehouse_database.warehouse_names()", "fn_id": 0, "class_fn": false, "repo": "CVUT-FS-12110/Python-for-scientific-computation-and-control", "file": "courses/E375004/webapp_database/warehouse_app/warehouse/controller.py", "last_update_at": "2019-12-09T10:59:20+00:00", "question_id": "658885ee39fbcc21373a5c5ce565d321c36d0786_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@warehouse_router.get('/', response_model=List[str])\ndef get_warehouse_names():\n    \"\"\" Gets all unique names of warehouses\n    Returns:\n        list of names (strings), STATUS 200 (list can be empty)\n    \"\"\"\n"]]}
{"hexsha": "aa093c98adeec96dee4cb7f2bf5f0ca109010e44", "ext": "py", "lang": "Python", "content": "def pip_upgrade():\n    import pip\n    for dist in pip.get_installed_distributions():\n        local(\"pip install --upgrade {0}\".format(dist.project_name))", "fn_id": 0, "class_fn": false, "repo": "haraldschilly/panobbgo", "file": "fabfile.py", "last_update_at": "2019-03-16T19:23:44+00:00", "question_id": "aa093c98adeec96dee4cb7f2bf5f0ca109010e44_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def pip_upgrade():\n    import pip\n    for dist in pip.get_installed_distributions():\n"]]}
{"hexsha": "fe8e83568da2ce47771ba805d32005c8947cc724", "ext": "py", "lang": "Python", "content": "def add_CustomerServiceServicer_to_server(servicer, server):\n  rpc_method_handlers = {\n      'GetCustomer': grpc.unary_unary_rpc_method_handler(\n          servicer.GetCustomer,\n          request_deserializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.GetCustomerRequest.FromString,\n          response_serializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_resources_dot_customer__pb2.Customer.SerializeToString,\n      ),\n      'MutateCustomer': grpc.unary_unary_rpc_method_handler(\n          servicer.MutateCustomer,\n          request_deserializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.MutateCustomerRequest.FromString,\n          response_serializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.MutateCustomerResponse.SerializeToString,\n      ),\n      'ListAccessibleCustomers': grpc.unary_unary_rpc_method_handler(\n          servicer.ListAccessibleCustomers,\n          request_deserializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.ListAccessibleCustomersRequest.FromString,\n          response_serializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.ListAccessibleCustomersResponse.SerializeToString,\n      ),\n      'CreateCustomerClient': grpc.unary_unary_rpc_method_handler(\n          servicer.CreateCustomerClient,\n          request_deserializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.CreateCustomerClientRequest.FromString,\n          response_serializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.CreateCustomerClientResponse.SerializeToString,\n      ),\n  }\n  generic_handler = grpc.method_handlers_generic_handler(\n      'google.ads.googleads.v3.services.CustomerService', rpc_method_handlers)\n  server.add_generic_rpc_handlers((generic_handler,))", "fn_id": 0, "class_fn": false, "repo": "andy0937/google-ads-python", "file": "google/ads/google_ads/v3/proto/services/customer_service_pb2_grpc.py", "last_update_at": "2019-11-30T23:42:39+00:00", "question_id": "fe8e83568da2ce47771ba805d32005c8947cc724_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def add_CustomerServiceServicer_to_server(servicer, server):\n    rpc_method_handlers = {'GetCustomer': grpc.unary_unary_rpc_method_handler(servicer.GetCustomer, request_deserializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.GetCustomerRequest.FromString, response_serializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_resources_dot_customer__pb2.Customer.SerializeToString), 'MutateCustomer': grpc.unary_unary_rpc_method_handler(servicer.MutateCustomer, request_deserializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.MutateCustomerRequest.FromString, response_serializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.MutateCustomerResponse.SerializeToString), 'ListAccessibleCustomers': grpc.unary_unary_rpc_method_handler(servicer.ListAccessibleCustomers, request_deserializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.ListAccessibleCustomersRequest.FromString, response_serializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.ListAccessibleCustomersResponse.SerializeToString), 'CreateCustomerClient': grpc.unary_unary_rpc_method_handler(servicer.CreateCustomerClient, request_deserializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.CreateCustomerClientRequest.FromString, response_serializer=google_dot_ads_dot_googleads__v3_dot_proto_dot_services_dot_customer__service__pb2.CreateCustomerClientResponse.SerializeToString)}\n    generic_handler = grpc.method_handlers_generic_handler('google.ads.googleads.v3.services.CustomerService', rpc_method_handlers)\n"]]}
{"hexsha": "f290e9e8755f5bde9581a5b137a4dc4d624fc213", "ext": "py", "lang": "Python", "content": "def valid_local_author(author_host, author_id):\n    try:\n        tmp = author_id.split(\"author/\")\n        author_short_id = tmp[1]\n        request_user = AuthorProfile.objects.filter(host=author_host, id=author_short_id)\n        if not (request_user.exists()):\n            return False\n    except:\n        return False\n    return True", "fn_id": 1, "class_fn": false, "repo": "forgeno/CMPUT404-group-project", "file": "backend/api/view/FriendsView.py", "last_update_at": "2019-04-08T04:44:55+00:00", "question_id": "f290e9e8755f5bde9581a5b137a4dc4d624fc213_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def valid_local_author(author_host, author_id):\n    try:\n        tmp = author_id.split('author/')\n        author_short_id = tmp[1]\n        request_user = AuthorProfile.objects.filter(host=author_host, id=author_short_id)\n        if not request_user.exists():\n            return False\n    except:\n        return False\n"]]}
{"hexsha": "703434e34b608837513e9f98daee6a3d5d0ed0b9", "ext": "py", "lang": "Python", "content": "@stub\n@pytest.mark.parametrize('stage_attributes', [{'instance_type': 'SOLR_CLOUD'}])\ndef test_zookeeper_connection_string(sdc_builder, sdc_executor, stage_attributes):\n    pass", "fn_id": 15, "class_fn": false, "repo": "Sentienz/datacollector-tests", "file": "stage/configuration/test_solr_destination.py", "last_update_at": "2019-04-24T11:06:38+00:00", "question_id": "703434e34b608837513e9f98daee6a3d5d0ed0b9_15", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@stub\n@pytest.mark.parametrize('stage_attributes', [{'instance_type': 'SOLR_CLOUD'}])\ndef test_zookeeper_connection_string(sdc_builder, sdc_executor, stage_attributes):\n"]]}
{"hexsha": "727dd09d0225f5fb80118f341167b00f79332277", "ext": "py", "lang": "Python", "content": "def load_svhn(folder, max_train, max_test):\n    '''\n    Loads SVHN dataset from file\n\n    Arguments:\n\n\n    Returns:\n    train_X, np array (num_train, 32, 32, 3) - training images\n    train_y, np array of int (num_train) - training labels\n    test_X, np array (num_test, 32, 32, 3) - test images\n    test_y, np array of int (num_test) - test labels\n    '''\n    train_X, train_y = load_data_mat(os.path.join(folder, \"train_32x32.mat\"), max_train)\n    test_X, test_y = load_data_mat(os.path.join(folder, \"test_32x32.mat\"), max_test)\n    return train_X, train_y, test_X, test_y", "fn_id": 1, "class_fn": false, "repo": "xDrgh/dlcourse_ai", "file": "assignments/assignment1/dataset.py", "last_update_at": "2019-07-11T08:07:59+00:00", "question_id": "727dd09d0225f5fb80118f341167b00f79332277_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def load_svhn(folder, max_train, max_test):\n    \"\"\"\n    Loads SVHN dataset from file\n\n    Arguments:\n\n\n    Returns:\n    train_X, np array (num_train, 32, 32, 3) - training images\n    train_y, np array of int (num_train) - training labels\n    test_X, np array (num_test, 32, 32, 3) - test images\n    test_y, np array of int (num_test) - test labels\n    \"\"\"\n    train_X, train_y = load_data_mat(os.path.join(folder, 'train_32x32.mat'), max_train)\n    test_X, test_y = load_data_mat(os.path.join(folder, 'test_32x32.mat'), max_test)\n"]]}
{"hexsha": "bb75d3a23dd736bed84f1c9bc6ca51b10c3a16f6", "ext": "py", "lang": "Python", "content": "def main():\n    if sys.argv[1] == 'dev':\n        dev()\n    else:\n        default()", "fn_id": 0, "class_fn": false, "repo": "ShengjunZhang/ShengjunZhang.github.io", "file": "demo.py", "last_update_at": "2019-03-30T21:26:29+00:00", "question_id": "bb75d3a23dd736bed84f1c9bc6ca51b10c3a16f6_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def main():\n    if sys.argv[1] == 'dev':\n        dev()\n    else:\n"]]}
{"hexsha": "836898327106636e7370abe32fcbefa43fbfffd1", "ext": "py", "lang": "Python", "content": "def _get_by_id(t, id_v):\n    for id_a in config.id_attributes:\n        log.debug(\"Looking for #%s using id attribute '%s'\" % (id_v, id_a))\n        elts = t.xpath(\"//*[@%s='%s']\" % (id_a, id_v))\n        if elts is not None and len(elts) > 0:\n            return elts[0]\n    return None", "fn_id": 2, "class_fn": false, "repo": "SUNET/pyXMLSecurity", "file": "src/xmlsec/__init__.py", "last_update_at": "2019-01-15T15:12:50+00:00", "question_id": "836898327106636e7370abe32fcbefa43fbfffd1_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _get_by_id(t, id_v):\n    for id_a in config.id_attributes:\n        log.debug(\"Looking for #%s using id attribute '%s'\" % (id_v, id_a))\n        elts = t.xpath(\"//*[@%s='%s']\" % (id_a, id_v))\n        if elts is not None and len(elts) > 0:\n            return elts[0]\n"]]}
{"hexsha": "82eeed4b8211d175a42bfc7fd9fda14a1a7bf571", "ext": "py", "lang": "Python", "content": "def problemThree():\n    '''\n    Plot y = x^2 * sin(x) using 1000 data points and x in [0,100]\n    '''\n    raise NotImplementedError(\"Problem 3 not implemented.\")", "fn_id": 2, "class_fn": false, "repo": "jaredawebb/Labs", "file": "Labs/Vol1A/DataVisualization/spec.py", "last_update_at": "2019-11-05T14:45:03+00:00", "question_id": "82eeed4b8211d175a42bfc7fd9fda14a1a7bf571_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def problemThree():\n    \"\"\"\n    Plot y = x^2 * sin(x) using 1000 data points and x in [0,100]\n    \"\"\"\n"]]}
{"hexsha": "b9249b59dfe9c8d8156dd7a2f2c974cf1978d44e", "ext": "py", "lang": "Python", "content": "@pytest.mark.vcr()\ndef test_workbench_assets_filter_type_unexpectedvalueerror(api):\n    with pytest.raises(UnexpectedValueError):\n        api.workbenches.assets(filter_type='NOT')", "fn_id": 2, "class_fn": false, "repo": "widnyana/pyTenable", "file": "tests/io/test_workbenches.py", "last_update_at": "2019-01-25T11:36:07+00:00", "question_id": "b9249b59dfe9c8d8156dd7a2f2c974cf1978d44e_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.mark.vcr()\ndef test_workbench_assets_filter_type_unexpectedvalueerror(api):\n    with pytest.raises(UnexpectedValueError):\n"]]}
{"hexsha": "ac24946cfeae81abae7e8a0419790e2c34948387", "ext": "py", "lang": "Python", "content": "@app.route('/', methods=['POST'])\ndef post_index():\n    # Process data sent from Comapi\n    try:\n        # Grab the body data\n        raw_body = request.get_data().decode(\"utf-8\")\n\n        if (raw_body is None):\n            # No body, bad request.\n            return \"Bad request - No JSON body found!\", status.HTTP_400_BAD_REQUEST\n\n        # We have a request body so lets look at what we have\n\n        # First lets ensure it hasn't been tampered with and it came from Comapi\n        # We do this by checking the HMAC from the X-Comapi-Signature header\n        request_hmac = request.headers.get(\"x-comapi-signature\")\n\n        if (request_hmac is None):\n            # No HMAC, invalid request.\n            return \"Invalid request: No HMAC value found!\", status.HTTP_401_UNAUTHORIZED\n        else:\n            # Validate the HMAC, ensure you has exposed the rawBody, see app.js for how to do this\n            hash = hmac_sha1(raw_body, \">>>YOUR SECRET<<<\")\n\n            if (request_hmac != hash):\n                # The request is not from Comapi or has been tampered with\n                return \"Invalid request: HMAC hash check failed!\", status.HTTP_401_UNAUTHORIZED\n\n        # Store the received event for later processing, remember you only have 10 secs to process, in this simple example we output to the console\n        eventObj = json.loads(raw_body)\n\n        print (\"\")        \n        print (\"Received a {0} event id: {1}\".format(eventObj.get('name',''), eventObj.get('eventId','')))\n        print(json.dumps(eventObj, indent=2)) # Pretty print the JSON\n        print (\"\")\n\n        # You could use queuing tech such as RabbitMQ, or possibly a distributed cache such as Redis       \n\n        # Send worked\n        return \"Data accepted\", status.HTTP_200_OK\n\n    except Exception as ex:\n        # Send failed\n        print (\"An error occurred: \")\n        print (\"{0}\".format(ex))\n        raise", "fn_id": 1, "class_fn": false, "repo": "comapi/Examples", "file": "OneAPI/Python/Webhook/webhook.py", "last_update_at": "2019-10-30T00:53:30+00:00", "question_id": "ac24946cfeae81abae7e8a0419790e2c34948387_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@app.route('/', methods=['POST'])\ndef post_index():\n    try:\n        raw_body = request.get_data().decode('utf-8')\n        if raw_body is None:\n            return ('Bad request - No JSON body found!', status.HTTP_400_BAD_REQUEST)\n        request_hmac = request.headers.get('x-comapi-signature')\n        if request_hmac is None:\n            return ('Invalid request: No HMAC value found!', status.HTTP_401_UNAUTHORIZED)\n        else:\n            hash = hmac_sha1(raw_body, '>>>YOUR SECRET<<<')\n            if request_hmac != hash:\n                return ('Invalid request: HMAC hash check failed!', status.HTTP_401_UNAUTHORIZED)\n        eventObj = json.loads(raw_body)\n        print('')\n        print('Received a {0} event id: {1}'.format(eventObj.get('name', ''), eventObj.get('eventId', '')))\n        print(json.dumps(eventObj, indent=2))\n        print('')\n        return ('Data accepted', status.HTTP_200_OK)\n    except Exception as ex:\n        print('An error occurred: ')\n        print('{0}'.format(ex))\n"]]}
{"hexsha": "c0357787df28351bf9d0dfc1d6097653540be386", "ext": "py", "lang": "Python", "content": "def supplyNamesEFOTU(ef_otu, ef_name, otu_name):\n    ef_otu_new = []\n    for pert in ef_otu:\n        ef1 = ef_name[pert[0]]\n        otu1 = otu_name[pert[1]]\n        weight = pert[2]\n        ef_otu_new.append([ef1, otu1, weight])\n    \n    return ef_otu_new", "fn_id": 22, "class_fn": false, "repo": "tinglab/kLDM", "file": "hierarchical_server/utils.py", "last_update_at": "2019-07-19T05:03:40+00:00", "question_id": "c0357787df28351bf9d0dfc1d6097653540be386_22", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def supplyNamesEFOTU(ef_otu, ef_name, otu_name):\n    ef_otu_new = []\n    for pert in ef_otu:\n        ef1 = ef_name[pert[0]]\n        otu1 = otu_name[pert[1]]\n        weight = pert[2]\n        ef_otu_new.append([ef1, otu1, weight])\n"]]}
{"hexsha": "6404f3d92896c73b18c929d102e95ee8d567e633", "ext": "py", "lang": "Python", "content": "def git_clone_repository(repositoryGit):\n    print_split.print_log(\"gitCloneRepository\")\n    respositoryDir = None\n    try:\n        (filepath, tempfilename) = os.path.split(repositoryGit)\n        (filename, extension) = os.path.splitext(tempfilename)\n        respositoryDir = settings.kAutoArchiveRepositoryRootPath + filename\n    except:\n        print_split.print_war(\"\u672a\u914d\u7f6egit\u4ed3\u5e93\u5730\u5740\")\n        return\n\n    if (not os.path.exists(respositoryDir)):\n        print_split.print_war('git clone ' + repositoryGit + ' ' + respositoryDir)\n        os.system('%s' % 'git clone ' + repositoryGit + ' ' + respositoryDir) \n    else:\n        print_split.print_war(\"\u68c0\u67e5\u5230\u672c\u5730git\u4ed3\u5e93\u5df2\u7ecf\u5b58\u5728\")", "fn_id": 0, "class_fn": false, "repo": "sghick/tools-AutoArchiveIPA", "file": "supports/pod_tool.py", "last_update_at": "2019-05-28T01:59:54+00:00", "question_id": "6404f3d92896c73b18c929d102e95ee8d567e633_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def git_clone_repository(repositoryGit):\n    print_split.print_log('gitCloneRepository')\n    respositoryDir = None\n    try:\n        filepath, tempfilename = os.path.split(repositoryGit)\n        filename, extension = os.path.splitext(tempfilename)\n        respositoryDir = settings.kAutoArchiveRepositoryRootPath + filename\n    except:\n        print_split.print_war('\u672a\u914d\u7f6egit\u4ed3\u5e93\u5730\u5740')\n        return\n    if not os.path.exists(respositoryDir):\n        print_split.print_war('git clone ' + repositoryGit + ' ' + respositoryDir)\n        os.system('%s' % 'git clone ' + repositoryGit + ' ' + respositoryDir)\n    else:\n"]]}
{"hexsha": "033285e745073ad33da98bba96cbfa2ebbc523f0", "ext": "py", "lang": "Python", "content": "def read_OIB_data(xy0, W, reread_file=None, hemisphere=-1, blockmedian_scale=100, SRS_proj4=None):\n    \"\"\"\n    Read indexed files for standard datasets\n    \"\"\"\n    sensor_dict={1:'ICESat1', 2:'ICESat2'}\n    if reread_file is None:\n        GI=geo_index().from_file(GI_files(hemisphere)['ICESat2'], read_file=False)\n        D = read_ICESat2(xy0, W, GI,  SRS_proj4=SRS_proj4)\n        GI=None    \n        GI=geo_index().from_file(GI_files(hemisphere)['ICESat1'], read_file=False)\n        D += read_ICESat(xy0, W, GI)    \n        GI=None\n        data=point_data(list_of_fields=['x','y','z','time','sigma','sigma_corr','sensor','cycle','rgt', 'BP','LR']).from_list(D)\n        data.assign({'day':np.floor(data.time)})\n        data.time=matlabToYear(data.time)\n        for field in data.list_of_fields:\n            setattr(data, field, getattr(data, field).astype(np.float64))\n        data.index(np.isfinite(data.z) & np.isfinite(data.sigma_corr) & np.isfinite(data.sigma))\n    else:\n        data=dict()\n        with h5py.File(reread_file,'r') as h5f:\n            for key in h5f['data'].keys():\n                data[key]=np.array(h5f['data'][key])\n        data=point_data(list_of_fields=data.keys()).from_dict(data)\n    return data, sensor_dict", "fn_id": 5, "class_fn": false, "repo": "SmithB/LSsurf", "file": "LSsurf/two_mission_dhdt.py", "last_update_at": "2019-12-25T09:46:08+00:00", "question_id": "033285e745073ad33da98bba96cbfa2ebbc523f0_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def read_OIB_data(xy0, W, reread_file=None, hemisphere=-1, blockmedian_scale=100, SRS_proj4=None):\n    \"\"\"\n    Read indexed files for standard datasets\n    \"\"\"\n    sensor_dict = {1: 'ICESat1', 2: 'ICESat2'}\n    if reread_file is None:\n        GI = geo_index().from_file(GI_files(hemisphere)['ICESat2'], read_file=False)\n        D = read_ICESat2(xy0, W, GI, SRS_proj4=SRS_proj4)\n        GI = None\n        GI = geo_index().from_file(GI_files(hemisphere)['ICESat1'], read_file=False)\n        D += read_ICESat(xy0, W, GI)\n        GI = None\n        data = point_data(list_of_fields=['x', 'y', 'z', 'time', 'sigma', 'sigma_corr', 'sensor', 'cycle', 'rgt', 'BP', 'LR']).from_list(D)\n        data.assign({'day': np.floor(data.time)})\n        data.time = matlabToYear(data.time)\n        for field in data.list_of_fields:\n            setattr(data, field, getattr(data, field).astype(np.float64))\n        data.index(np.isfinite(data.z) & np.isfinite(data.sigma_corr) & np.isfinite(data.sigma))\n    else:\n        data = dict()\n        with h5py.File(reread_file, 'r') as h5f:\n            for key in h5f['data'].keys():\n                data[key] = np.array(h5f['data'][key])\n        data = point_data(list_of_fields=data.keys()).from_dict(data)\n"]]}
{"hexsha": "2a47ed9898e2a53116482213b411096d827afda2", "ext": "py", "lang": "Python", "content": "def test_get_route_types(client):\n    \"\"\"Tests the GET RouteTypes endpoint\"\"\"\n    json = client.get_route_types()\n    assert isinstance(json, dict)\n    assert EXPECTED_ROUTE_TYPE_KEYS.issubset(json.keys())\n    assert json['status']['health'] == 1", "fn_id": 14, "class_fn": false, "repo": "lucky962/ptv-python-wrapper", "file": "tests/test_client.py", "last_update_at": "2019-08-29T06:27:35+00:00", "question_id": "2a47ed9898e2a53116482213b411096d827afda2_14", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_get_route_types(client):\n    \"\"\"Tests the GET RouteTypes endpoint\"\"\"\n    json = client.get_route_types()\n    assert isinstance(json, dict)\n    assert EXPECTED_ROUTE_TYPE_KEYS.issubset(json.keys())\n"]]}
{"hexsha": "8be0012372e23d7bba2f7554a9919a24bc4ffd81", "ext": "py", "lang": "Python", "content": "def _swig_getattr(self, class_type, name):\n    if (name == \"thisown\"):\n        return self.this.own()\n    method = class_type.__swig_getmethods__.get(name, None)\n    if method:\n        return method(self)\n    raise AttributeError(\"'%s' object has no attribute '%s'\" % (class_type.__name__, name))", "fn_id": 2, "class_fn": false, "repo": "ian-cooke/basilisk_mag", "file": "dist/Basilisk/simulation/mag_meter/mag_meter.py", "last_update_at": "2019-03-13T20:52:22+00:00", "question_id": "8be0012372e23d7bba2f7554a9919a24bc4ffd81_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _swig_getattr(self, class_type, name):\n    if name == 'thisown':\n        return self.this.own()\n    method = class_type.__swig_getmethods__.get(name, None)\n    if method:\n        return method(self)\n"]]}
{"hexsha": "d4afc171f6f5a693605ad970fb580faa87a94269", "ext": "py", "lang": "Python", "content": "def _tansfocator_guess_focal_position( s_target, p=5960., q=3800.0, sigmaz=6.46e-4, \\\n                                      alpha=0.66, lens_diameter=0.05, method=2):\n    x = 1e15\n    if method == 1: # simple sum\n        AA = 2.35*sigmaz/p\n        BB = -(s_target + alpha * lens_diameter)\n        CC = alpha*lens_diameter*q\n\n        cc = numpy.roots([AA,BB,CC])\n        x = cc[1]\n        return x\n\n    if method == 2: # sum in quadrature\n        AA = ( (2.35*sigmaz)**2)/(p**2)\n        BB = 0.0\n        CC = alpha**2 * lens_diameter**2 - s_target**2\n        DD = - 2.0 * alpha**2 * lens_diameter**2 * q\n        EE = alpha**2 * lens_diameter**2 * q**2\n        cc = numpy.roots([AA,BB,CC,DD,EE])\n        for i,cci in enumerate(cc):\n            if numpy.imag(cci) == 0:\n                return numpy.real(cci)\n\n    return x", "fn_id": 4, "class_fn": false, "repo": "srio/shadow3-scripts", "file": "transfocator_id30b_lighted.py", "last_update_at": "2019-10-30T10:06:15+00:00", "question_id": "d4afc171f6f5a693605ad970fb580faa87a94269_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _tansfocator_guess_focal_position(s_target, p=5960.0, q=3800.0, sigmaz=0.000646, alpha=0.66, lens_diameter=0.05, method=2):\n    x = 1000000000000000.0\n    if method == 1:\n        AA = 2.35 * sigmaz / p\n        BB = -(s_target + alpha * lens_diameter)\n        CC = alpha * lens_diameter * q\n        cc = numpy.roots([AA, BB, CC])\n        x = cc[1]\n        return x\n    if method == 2:\n        AA = (2.35 * sigmaz) ** 2 / p ** 2\n        BB = 0.0\n        CC = alpha ** 2 * lens_diameter ** 2 - s_target ** 2\n        DD = -2.0 * alpha ** 2 * lens_diameter ** 2 * q\n        EE = alpha ** 2 * lens_diameter ** 2 * q ** 2\n        cc = numpy.roots([AA, BB, CC, DD, EE])\n        for i, cci in enumerate(cc):\n            if numpy.imag(cci) == 0:\n                return numpy.real(cci)\n"]]}
{"hexsha": "e64a9f5014b7f60f1d621c753c983b102fbe3148", "ext": "py", "lang": "Python", "content": "def write_handoff_fxn(dispatchable_obj, cfile, local_handles):\n   cfile.write('{decl}\\n{{\\n'.format(**{'decl':_ws_text['handoff_fxn_decl'].format(name=abbr2name(dispatchable_obj.abbreviation))}))\n   _local_handles = ['handle_{name}'.format(name = abbr2name(l.abbreviation)) for l in local_handles.values()]\n   handles = set()\n   joins = [j for j in dispatchable_obj.children if isinstance(j, Register)]\n   for j in joins:\n      handles.add('handle_{name}'.format(name = abbr2name(j.parent.abbreviation)))\n   for h in handles:\n      if h not in _local_handles:\n         cfile.write('{indent}dissector_handle_t {handle};\\n'.format(indent = _ws_text['indent'], handle = h))\n   for j in joins:\n      if h not in _local_handles:\n         cfile.write('{indent}handle_{name} = find_dissector(\"{name}\");\\n'.format(indent = _ws_text['indent'], name=abbr2name(j.parent.abbreviation)))\n      cfile.write('{indent}dissector_add_uint(\"{table}\", {value}, handle_{name});\\n'.format(indent = _ws_text['indent'],\n                                                                                            table  = j.table,\n                                                                                            value  = j.value,\n                                                                                            name   = abbr2name(j.parent.abbreviation)))\n   cfile.write('}\\n\\n')\n   if ws_has_section(dispatchable_obj, 'messages'):\n      for m in dispatchable_obj.messages.values():\n         write_handoff_fxn(m, cfile, local_handles)", "fn_id": 15, "class_fn": false, "repo": "Rakankou/transmute", "file": "transmute/plugins/wireshark.py", "last_update_at": "2019-12-06T13:31:03+00:00", "question_id": "e64a9f5014b7f60f1d621c753c983b102fbe3148_15", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def write_handoff_fxn(dispatchable_obj, cfile, local_handles):\n    cfile.write('{decl}\\n{{\\n'.format(**{'decl': _ws_text['handoff_fxn_decl'].format(name=abbr2name(dispatchable_obj.abbreviation))}))\n    _local_handles = ['handle_{name}'.format(name=abbr2name(l.abbreviation)) for l in local_handles.values()]\n    handles = set()\n    joins = [j for j in dispatchable_obj.children if isinstance(j, Register)]\n    for j in joins:\n        handles.add('handle_{name}'.format(name=abbr2name(j.parent.abbreviation)))\n    for h in handles:\n        if h not in _local_handles:\n            cfile.write('{indent}dissector_handle_t {handle};\\n'.format(indent=_ws_text['indent'], handle=h))\n    for j in joins:\n        if h not in _local_handles:\n            cfile.write('{indent}handle_{name} = find_dissector(\"{name}\");\\n'.format(indent=_ws_text['indent'], name=abbr2name(j.parent.abbreviation)))\n        cfile.write('{indent}dissector_add_uint(\"{table}\", {value}, handle_{name});\\n'.format(indent=_ws_text['indent'], table=j.table, value=j.value, name=abbr2name(j.parent.abbreviation)))\n    cfile.write('}\\n\\n')\n    if ws_has_section(dispatchable_obj, 'messages'):\n        for m in dispatchable_obj.messages.values():\n"]]}
{"hexsha": "50ef350828166416e539b0ff90cc3d638a2d1f7f", "ext": "py", "lang": "Python", "content": "def romanToDecimal(str): \n    res = 0\n    i = 0\n  \n    while (i < len(str)): \n  \n        # Getting value of symbol s[i] \n        s1 = value(str[i]) \n  \n        if (i+1 < len(str)): \n  \n            # Getting value of symbol s[i+1] \n            s2 = value(str[i+1]) \n  \n            # Comparing both values \n            if (s1 >= s2): \n  \n                # Value of current symbol is greater \n                # or equal to the next symbol \n                res = res + s1 \n                i = i + 1\n            else: \n  \n                # Value of current symbol is greater \n                # or equal to the next symbol \n                res = res + s2 - s1 \n                i = i + 2\n        else: \n            res = res + s1 \n            i = i + 1\n  \n    return res ", "fn_id": 1, "class_fn": false, "repo": "vfrico/sample-programs", "file": "archive/p/python/roman-numeral.py", "last_update_at": "2019-09-03T12:28:10+00:00", "question_id": "50ef350828166416e539b0ff90cc3d638a2d1f7f_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def romanToDecimal(str):\n    res = 0\n    i = 0\n    while i < len(str):\n        s1 = value(str[i])\n        if i + 1 < len(str):\n            s2 = value(str[i + 1])\n            if s1 >= s2:\n                res = res + s1\n                i = i + 1\n            else:\n                res = res + s2 - s1\n                i = i + 2\n        else:\n            res = res + s1\n            i = i + 1\n"]]}
{"hexsha": "83f68b9586d37d5c9d44e476e2e2a6e285a3c124", "ext": "py", "lang": "Python", "content": "def parse_config_file(config_file_path, validate=False):\n    \"\"\"Parse the config file and return a mapping.\n\n    Arguments:\n        config_file_path {click.Path}   -- A path to a valid YAML config file.\n        validate {boolean}              -- Validate config file against schema\n\n    \"\"\"\n    with open(config_file_path, 'r') as stream:\n        try:\n            loguru.logger.info('Parse configuration file with path: {}'.format(config_file_path))\n            config = yaml.safe_load(stream)\n        except yaml.YAMLError as error:\n            raise exceptions.InvalidConfigFileException('Config file is invalid. '\n                                                        'Following error occured: {}'.format(error))\n        else:\n            try:\n                schemas.DOCKER_CONFIG_SCHEMA.validate(config['docker'])\n            except schema.SchemaError as error:\n                raise exceptions.InvalidConfigFileException('Config file is invalid. '\n                                                            'Following error occured: {}'.format(error))\n\n            else:\n                loguru.logger.success('Configuration file is valid.')\n                return config", "fn_id": 0, "class_fn": false, "repo": "airbusgeo/playground-to-up42", "file": "up42/functionnal.py", "last_update_at": "2019-12-04T15:16:59+00:00", "question_id": "83f68b9586d37d5c9d44e476e2e2a6e285a3c124_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def parse_config_file(config_file_path, validate=False):\n    \"\"\"Parse the config file and return a mapping.\n\n    Arguments:\n        config_file_path {click.Path}   -- A path to a valid YAML config file.\n        validate {boolean}              -- Validate config file against schema\n\n    \"\"\"\n    with open(config_file_path, 'r') as stream:\n        try:\n            loguru.logger.info('Parse configuration file with path: {}'.format(config_file_path))\n            config = yaml.safe_load(stream)\n        except yaml.YAMLError as error:\n            raise exceptions.InvalidConfigFileException('Config file is invalid. Following error occured: {}'.format(error))\n        else:\n            try:\n                schemas.DOCKER_CONFIG_SCHEMA.validate(config['docker'])\n            except schema.SchemaError as error:\n                raise exceptions.InvalidConfigFileException('Config file is invalid. Following error occured: {}'.format(error))\n            else:\n                loguru.logger.success('Configuration file is valid.')\n"]]}
{"hexsha": "3b2206a3c64fbcf5d5a7d28a82c6e758a7a76d84", "ext": "py", "lang": "Python", "content": "def no_response_from_crawl(stats: Optional[Dict]) -> bool:\n    \"\"\"\n    Check that the stats dict has received an HTTP 200 response\n\n    :param stats: Crawl stats dictionary\n    :return: True if the dict exists and has no 200 response\n    \"\"\"\n    if not stats or not isinstance(stats, Dict):\n        return False\n\n    status_codes = stats.get(\"status_codes\", {})\n    if not status_codes or not isinstance(status_codes, Dict):\n        return False\n\n    return 200 not in status_codes", "fn_id": 9, "class_fn": false, "repo": "DBeath/feedsearch-gateway", "file": "gateway/utils.py", "last_update_at": "2019-11-02T10:36:47+00:00", "question_id": "3b2206a3c64fbcf5d5a7d28a82c6e758a7a76d84_9", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def no_response_from_crawl(stats: Optional[Dict]) -> bool:\n    \"\"\"\n    Check that the stats dict has received an HTTP 200 response\n\n    :param stats: Crawl stats dictionary\n    :return: True if the dict exists and has no 200 response\n    \"\"\"\n    if not stats or not isinstance(stats, Dict):\n        return False\n    status_codes = stats.get('status_codes', {})\n    if not status_codes or not isinstance(status_codes, Dict):\n        return False\n"]]}
{"hexsha": "8e750dec9420b5672d2d12c2ffc899a7ef185fac", "ext": "py", "lang": "Python", "content": "def test_job_priority():\n    client = mock.MagicMock()\n    assert models.Job(client, \"1\", \"hive\", \"SELECT COUNT(1) FROM nasdaq\", priority=-2).priority == \"VERY LOW\"\n    assert models.Job(client, \"2\", \"hive\", \"SELECT COUNT(1) FROM nasdaq\", priority=-1).priority == \"LOW\"\n    assert models.Job(client, \"3\", \"hive\", \"SELECT COUNT(1) FROM nasdaq\", priority=0).priority == \"NORMAL\"\n    assert models.Job(client, \"4\", \"hive\", \"SELECT COUNT(1) FROM nasdaq\", priority=1).priority == \"HIGH\"\n    assert models.Job(client, \"5\", \"hive\", \"SELECT COUNT(1) FROM nasdaq\", priority=2).priority == \"VERY HIGH\"\n    assert models.Job(client, \"42\", \"hive\", \"SELECT COUNT(1) FROM nasdaq\", priority=42).priority == \"42\"", "fn_id": 1, "class_fn": false, "repo": "minchuang/td-client-python", "file": "tdclient/test/job_model_test.py", "last_update_at": "2019-02-25T10:09:46+00:00", "question_id": "8e750dec9420b5672d2d12c2ffc899a7ef185fac_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_job_priority():\n    client = mock.MagicMock()\n    assert models.Job(client, '1', 'hive', 'SELECT COUNT(1) FROM nasdaq', priority=-2).priority == 'VERY LOW'\n    assert models.Job(client, '2', 'hive', 'SELECT COUNT(1) FROM nasdaq', priority=-1).priority == 'LOW'\n    assert models.Job(client, '3', 'hive', 'SELECT COUNT(1) FROM nasdaq', priority=0).priority == 'NORMAL'\n    assert models.Job(client, '4', 'hive', 'SELECT COUNT(1) FROM nasdaq', priority=1).priority == 'HIGH'\n    assert models.Job(client, '5', 'hive', 'SELECT COUNT(1) FROM nasdaq', priority=2).priority == 'VERY HIGH'\n"]]}
{"hexsha": "c7b0744f4bc08d8ca77ed8c47d0ef8df25fa0f57", "ext": "py", "lang": "Python", "content": "def test_get_sorted_primes_list():\n    # arrange\n    from src.common.primes import get_sorted_primes_list\n\n    # act\n    actual_result = get_sorted_primes_list(100)\n\n    # assert\n    expected_result = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97]\n    assert actual_result == expected_result", "fn_id": 4, "class_fn": false, "repo": "FranzDiebold/project-euler-solutions", "file": "test/common/test_primes.py", "last_update_at": "2019-09-27T07:05:29+00:00", "question_id": "c7b0744f4bc08d8ca77ed8c47d0ef8df25fa0f57_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_get_sorted_primes_list():\n    from src.common.primes import get_sorted_primes_list\n    actual_result = get_sorted_primes_list(100)\n    expected_result = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97]\n"]]}
{"hexsha": "1a13cf7618edfa809c49c12f9e0aff8d2793bc88", "ext": "py", "lang": "Python", "content": "def get_mysql_client(cluster, port):\n    start_time = time.monotonic()\n    while True:\n        try:\n            return pymysql.connections.Connection(\n                host=cluster.get_instance_ip(\"instance\"),\n                user=\"default\",\n                password=\"\",\n                database=\"default\",\n                port=port,\n            )\n        except pymysql.err.OperationalError:\n            if time.monotonic() - start_time > 10:\n                raise\n            time.sleep(0.1)", "fn_id": 1, "class_fn": false, "repo": "zzachimed/ClickHouse", "file": "tests/integration/test_server_reload/test.py", "last_update_at": "2019-09-23T07:46:38+00:00", "question_id": "1a13cf7618edfa809c49c12f9e0aff8d2793bc88_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_mysql_client(cluster, port):\n    start_time = time.monotonic()\n    while True:\n        try:\n            return pymysql.connections.Connection(host=cluster.get_instance_ip('instance'), user='default', password='', database='default', port=port)\n        except pymysql.err.OperationalError:\n            if time.monotonic() - start_time > 10:\n                raise\n"]]}
{"hexsha": "56d74a577d16f0cada4e896799c573d4ab7e649c", "ext": "py", "lang": "Python", "content": "def dnf_base():\n    \"\"\"Return a fully configured dnf Base object.\"\"\"\n    base = dnf.Base()\n    # Configure base\n    conf = base.conf\n    conf.debuglevel = 0\n    conf.assumeyes = True\n    conf.read()\n\n    base.read_all_repos()\n    base.fill_sack(load_system_repo='auto')\n    return base", "fn_id": 0, "class_fn": false, "repo": "puppetlabs/libral", "file": "data/providers/dnf_provider.py", "last_update_at": "2019-03-16T01:56:41+00:00", "question_id": "56d74a577d16f0cada4e896799c573d4ab7e649c_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def dnf_base():\n    \"\"\"Return a fully configured dnf Base object.\"\"\"\n    base = dnf.Base()\n    conf = base.conf\n    conf.debuglevel = 0\n    conf.assumeyes = True\n    conf.read()\n    base.read_all_repos()\n    base.fill_sack(load_system_repo='auto')\n"]]}
{"hexsha": "c68b67c4fc305f84122bedd5c13bed700e413e69", "ext": "py", "lang": "Python", "content": "def annotations(pairs, s, p, o):\n    n0 = rdflib.BNode()\n    yield n0, rdf.type, owl.Axiom\n    yield n0, owl.annotatedSource, s\n    yield n0, owl.annotatedProperty, p\n    yield n0, owl.annotatedTarget, check_value(o)\n    for predicate, object in pairs:\n        yield n0, predicate, check_value(object)", "fn_id": 11, "class_fn": false, "repo": "memartone/pyontutils", "file": "pyontutils/combinators.py", "last_update_at": "2019-06-24T03:36:50+00:00", "question_id": "c68b67c4fc305f84122bedd5c13bed700e413e69_11", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def annotations(pairs, s, p, o):\n    n0 = rdflib.BNode()\n    yield (n0, rdf.type, owl.Axiom)\n    yield (n0, owl.annotatedSource, s)\n    yield (n0, owl.annotatedProperty, p)\n    yield (n0, owl.annotatedTarget, check_value(o))\n    for predicate, object in pairs:\n"]]}
{"hexsha": "539b5196056660971e87e7ecd99a26cba405a56a", "ext": "py", "lang": "Python", "content": "async def run_queue_nonblocking_test(dut, queue_type):\n    QUEUE_SIZE = 10\n\n    q = queue_type(maxsize=QUEUE_SIZE)\n\n    # queue empty\n    assert q.maxsize == QUEUE_SIZE\n    assert q.qsize() == 0\n    assert q.empty()\n    assert not q.full()\n\n    # put one item\n    q.put_nowait(0)\n\n    assert q.qsize() == 1\n    assert not q.empty()\n    assert not q.full()\n\n    # fill queue\n    if queue_type is PriorityQueue:\n        for k in range(QUEUE_SIZE - 1, 0, -1):\n            q.put_nowait(k)\n    else:\n        for k in range(1, QUEUE_SIZE):\n            q.put_nowait(k)\n\n    assert q.qsize() == QUEUE_SIZE\n    assert not q.empty()\n    assert q.full()\n\n    # overflow\n    with pytest.raises(QueueFull):\n        q.put_nowait(100)\n\n    # check queue contents\n    if queue_type is LifoQueue:\n        for k in range(QUEUE_SIZE - 1, -1, -1):\n            assert q.get_nowait() == k\n    else:\n        for k in range(QUEUE_SIZE):\n            assert q.get_nowait() == k\n\n    assert q.qsize() == 0\n    assert q.empty()\n    assert not q.full()\n\n    # underflow\n    with pytest.raises(QueueEmpty):\n        q.get_nowait()", "fn_id": 0, "class_fn": false, "repo": "lavanyajagan/cocotb", "file": "tests/test_cases/test_cocotb/test_queues.py", "last_update_at": "2019-07-12T09:08:17+00:00", "question_id": "539b5196056660971e87e7ecd99a26cba405a56a_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["async def run_queue_nonblocking_test(dut, queue_type):\n    QUEUE_SIZE = 10\n    q = queue_type(maxsize=QUEUE_SIZE)\n    assert q.maxsize == QUEUE_SIZE\n    assert q.qsize() == 0\n    assert q.empty()\n    assert not q.full()\n    q.put_nowait(0)\n    assert q.qsize() == 1\n    assert not q.empty()\n    assert not q.full()\n    if queue_type is PriorityQueue:\n        for k in range(QUEUE_SIZE - 1, 0, -1):\n            q.put_nowait(k)\n    else:\n        for k in range(1, QUEUE_SIZE):\n            q.put_nowait(k)\n    assert q.qsize() == QUEUE_SIZE\n    assert not q.empty()\n    assert q.full()\n    with pytest.raises(QueueFull):\n        q.put_nowait(100)\n    if queue_type is LifoQueue:\n        for k in range(QUEUE_SIZE - 1, -1, -1):\n            assert q.get_nowait() == k\n    else:\n        for k in range(QUEUE_SIZE):\n            assert q.get_nowait() == k\n    assert q.qsize() == 0\n    assert q.empty()\n    assert not q.full()\n    with pytest.raises(QueueEmpty):\n"]]}
{"hexsha": "698f02953478fff7d6e072a1e7d9ed8fc0f5214f", "ext": "py", "lang": "Python", "content": "@extra_info\ndef test(data: pandas.DataFrame):\n    some_var = 1\n    return some_var", "fn_id": 2, "class_fn": false, "repo": "nicoeinsidler/pigor2", "file": "pigor/library/decorators.py", "last_update_at": "2019-10-09T11:31:41+00:00", "question_id": "698f02953478fff7d6e072a1e7d9ed8fc0f5214f_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@extra_info\ndef test(data: pandas.DataFrame):\n    some_var = 1\n"]]}
{"hexsha": "4e47f325da8f0f87a8ea4a6ee5a0cdf303b80b3b", "ext": "py", "lang": "Python", "content": "def setLastPassword():\n    global OTPConfig\n    global Password\n    global LastPassword\n\n    LastPassword = Password\n    OTPConfig['LastPassword'] = LastPassword", "fn_id": 3, "class_fn": false, "repo": "PttCodingMan/PTT-One-Time-Password", "file": "PTTOTP/PTTOTP.py", "last_update_at": "2019-09-03T08:26:55+00:00", "question_id": "4e47f325da8f0f87a8ea4a6ee5a0cdf303b80b3b_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def setLastPassword():\n    global OTPConfig\n    global Password\n    global LastPassword\n    LastPassword = Password\n"]]}
{"hexsha": "2f813ea3cdb06fab295cc5987425bc681fbaf551", "ext": "py", "lang": "Python", "content": "def get_products(pclient, **kwargs):\n    \"\"\"Fetch pricing based on filter.\n    \"\"\"\n    filters = []\n    for k, v in kwargs.items():\n        if v is not None:\n            filters.append({\"Type\": \"TERM_MATCH\", \"Field\": k, \"Value\": v})\n\n    res = []\n    pager = pclient.get_paginator(\"get_products\").paginate\n    for page in pager(FormatVersion=\"aws_v1\", ServiceCode=kwargs.get(\"ServiceCode\"), Filters=filters):\n        for rec in page.get(\"PriceList\") or []:\n            res.append(json.loads(rec))\n    return res", "fn_id": 0, "class_fn": false, "repo": "markokr/vmtool", "file": "pricing/fetch_cache.py", "last_update_at": "2019-08-25T01:36:20+00:00", "question_id": "2f813ea3cdb06fab295cc5987425bc681fbaf551_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_products(pclient, **kwargs):\n    \"\"\"Fetch pricing based on filter.\n    \"\"\"\n    filters = []\n    for k, v in kwargs.items():\n        if v is not None:\n            filters.append({'Type': 'TERM_MATCH', 'Field': k, 'Value': v})\n    res = []\n    pager = pclient.get_paginator('get_products').paginate\n    for page in pager(FormatVersion='aws_v1', ServiceCode=kwargs.get('ServiceCode'), Filters=filters):\n        for rec in page.get('PriceList') or []:\n            res.append(json.loads(rec))\n"]]}
{"hexsha": "658b23bbf8aec7d5caf921a1991f906232e3f093", "ext": "py", "lang": "Python", "content": "@pytest.mark.asyncio\n@pytest.mark.messages_list\nasync def test_request_room_messages_that_do_not_exist(auth_token):\n    \"\"\"\n    ...\n    \"\"\"\n    communicator = WebsocketCommunicator(MessageConsumer, \"/ws/chat/\")\n    connected, _ = await communicator.connect()\n    assert connected\n\n    # Test sending json\n    await communicator.send_json_to(\n        {\n            \"method\": \"R\",\n            \"values\": {\"room_id\": 100},\n            \"token\": auth_token[\"super_user_admin\"],\n        }\n    )\n\n    await communicator.receive_json_from()\n    # response = await communicator.receive_json_from()\n    # assert response == 'y'\n\n    # Close\n    await communicator.disconnect()", "fn_id": 2, "class_fn": false, "repo": "magocod/django_chat", "file": "apps/chat/tests/message/test_message_list.py", "last_update_at": "2019-10-01T01:39:37+00:00", "question_id": "658b23bbf8aec7d5caf921a1991f906232e3f093_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.mark.asyncio\n@pytest.mark.messages_list\nasync def test_request_room_messages_that_do_not_exist(auth_token):\n    \"\"\"\n    ...\n    \"\"\"\n    communicator = WebsocketCommunicator(MessageConsumer, '/ws/chat/')\n    connected, _ = await communicator.connect()\n    assert connected\n    await communicator.send_json_to({'method': 'R', 'values': {'room_id': 100}, 'token': auth_token['super_user_admin']})\n    await communicator.receive_json_from()\n"]]}
{"hexsha": "fe0afc609e2786e16798981e25f86a20131701c7", "ext": "py", "lang": "Python", "content": "def get_node_info():\n  \"\"\" Creates a list of JSON objects that contain node information and are\n  needed to perform a backup/restore task on the current AppScale deployment.\n  \"\"\"\n\n  # TODO\n  # Add logic for choosing minimal set of nodes that need to perform a task.\n  # e.g. Only the node that owns the entire keyspace.\n\n  nodes = [{\n    NodeInfoTags.HOST: get_br_service_url(appscale_info.get_db_master_ip()),\n    NodeInfoTags.ROLE: 'db_master',\n    NodeInfoTags.INDEX: None\n  }]\n\n  index = 0\n  for node in appscale_info.get_db_slave_ips():\n    host = get_br_service_url(node)\n    # Make sure we don't send the same request on DB roles that reside on the\n    # same node.\n    if host not in nodes[0].values():\n      nodes.append({\n        NodeInfoTags.HOST: host,\n        NodeInfoTags.ROLE: 'db_slave',\n        NodeInfoTags.INDEX: index\n      })\n      index += 1\n\n  index = 0\n  for node in appscale_info.get_zk_node_ips():\n    nodes.append({\n      NodeInfoTags.HOST: get_br_service_url(node),\n      NodeInfoTags.ROLE: 'zk',\n      NodeInfoTags.INDEX: index\n    })\n    index += 1\n\n  return nodes", "fn_id": 5, "class_fn": false, "repo": "eabyshev/appscale", "file": "Hermes/helper.py", "last_update_at": "2019-01-15T10:18:19+00:00", "question_id": "fe0afc609e2786e16798981e25f86a20131701c7_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_node_info():\n    \"\"\" Creates a list of JSON objects that contain node information and are\n  needed to perform a backup/restore task on the current AppScale deployment.\n  \"\"\"\n    nodes = [{NodeInfoTags.HOST: get_br_service_url(appscale_info.get_db_master_ip()), NodeInfoTags.ROLE: 'db_master', NodeInfoTags.INDEX: None}]\n    index = 0\n    for node in appscale_info.get_db_slave_ips():\n        host = get_br_service_url(node)\n        if host not in nodes[0].values():\n            nodes.append({NodeInfoTags.HOST: host, NodeInfoTags.ROLE: 'db_slave', NodeInfoTags.INDEX: index})\n            index += 1\n    index = 0\n    for node in appscale_info.get_zk_node_ips():\n        nodes.append({NodeInfoTags.HOST: get_br_service_url(node), NodeInfoTags.ROLE: 'zk', NodeInfoTags.INDEX: index})\n        index += 1\n"]]}
{"hexsha": "6aa3d8a2d51ddee0c116a30642335f490fa0e9c1", "ext": "py", "lang": "Python", "content": "def get_perl_exports(tmpdir=None):\n    \"\"\"Environmental exports to use conda installed perl.\n    \"\"\"\n    perl_path = os.path.dirname(perl_cmd())\n    out = \"unset PERL5LIB && export PATH=%s:\\\"$PATH\\\"\" % (perl_path)\n    if tmpdir:\n        out += \" && export TMPDIR=%s\" % (tmpdir)\n    return out", "fn_id": 52, "class_fn": false, "repo": "Bpar1/bcbio-nextgen", "file": "bcbio/utils.py", "last_update_at": "2019-08-21T11:40:00+00:00", "question_id": "6aa3d8a2d51ddee0c116a30642335f490fa0e9c1_52", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_perl_exports(tmpdir=None):\n    \"\"\"Environmental exports to use conda installed perl.\n    \"\"\"\n    perl_path = os.path.dirname(perl_cmd())\n    out = 'unset PERL5LIB && export PATH=%s:\"$PATH\"' % perl_path\n    if tmpdir:\n        out += ' && export TMPDIR=%s' % tmpdir\n"]]}
{"hexsha": "4199cc03aaf7f34f0b78c80dab33d55347950cc7", "ext": "py", "lang": "Python", "content": "def clearDisplay():\n    \"\"\"\n        Connector function to clear OLED Display\n        :param img:\n        :return: None\n    \"\"\"\n    disp.clear()", "fn_id": 0, "class_fn": false, "repo": "adwuard/OP1_File_Organizer", "file": "GPIO_Init.py", "last_update_at": "2019-08-22T04:51:13+00:00", "question_id": "4199cc03aaf7f34f0b78c80dab33d55347950cc7_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def clearDisplay():\n    \"\"\"\n        Connector function to clear OLED Display\n        :param img:\n        :return: None\n    \"\"\"\n"]]}
{"hexsha": "9169fa35c114b645c37ad3dc3dd8e4f2affdbec5", "ext": "py", "lang": "Python", "content": "def dark_correction(msi, dark):\n    \"\"\"\" subtract dark current from multi spectral image.\n\n    The dark msi should either be of the same shape\n    as msi or 1xnr_wavelengths (see tests).\"\"\"\n    msi.set_image(msi.get_image() - dark.get_image())\n    return msi", "fn_id": 4, "class_fn": false, "repo": "SVRTK/MITK", "file": "Modules/Biophotonics/python/iMC/msi/msimanipulations.py", "last_update_at": "2019-04-17T15:04:07+00:00", "question_id": "9169fa35c114b645c37ad3dc3dd8e4f2affdbec5_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def dark_correction(msi, dark):\n    \"\"\"\" subtract dark current from multi spectral image.\n\n    The dark msi should either be of the same shape\n    as msi or 1xnr_wavelengths (see tests).\"\"\"\n    msi.set_image(msi.get_image() - dark.get_image())\n"]]}
{"hexsha": "477b5544eacaaded928575f9725294e6c1f34a72", "ext": "py", "lang": "Python", "content": "def create_directory(directory):\n    if not os.path.isdir(directory):\n        path = directory.rstrip('/').split('/')\n        for i in range(len(path)):\n            path_chunk = '/'.join(path[:i+1])\n            if not os.path.isdir(path_chunk):\n                os.mkdir(path_chunk)", "fn_id": 5, "class_fn": false, "repo": "olivercalder/sonic-signatures", "file": "Unsupervised/k_means.py", "last_update_at": "2019-06-24T16:18:08+00:00", "question_id": "477b5544eacaaded928575f9725294e6c1f34a72_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def create_directory(directory):\n    if not os.path.isdir(directory):\n        path = directory.rstrip('/').split('/')\n        for i in range(len(path)):\n            path_chunk = '/'.join(path[:i + 1])\n            if not os.path.isdir(path_chunk):\n"]]}
{"hexsha": "a680fd0271f4381d3a34de9ee580a642cbbd47ad", "ext": "py", "lang": "Python", "content": "def regExpIn(x):\n  \"\"\"show time-formatted countdown.\"\"\"\n  if x==None or x==False:\n    return \"INVALID KEY\"\n  secInDay=60*60*24\n  x=x-time.time()\n  if x<=0:\n    return \"EXPIRED\"\n  d=int(x/(60*60*24));  x-=(60*60*24)*d\n  h=int(x/(60*60));     x-=(60*60)*h\n  m=int(x/60);          x-=(60)*m\n  s=x\n  return \"%d days, %02d hours, %02d minutes, %02d seconds\"%(d,h,m,s)", "fn_id": 4, "class_fn": false, "repo": "toddsahagian/Microscopy", "file": "two-photon/software/scan-a-gator/scan-a-gator-3.56/default.py", "last_update_at": "2019-12-24T06:23:16+00:00", "question_id": "a680fd0271f4381d3a34de9ee580a642cbbd47ad_4", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def regExpIn(x):\n    \"\"\"show time-formatted countdown.\"\"\"\n    if x == None or x == False:\n        return 'INVALID KEY'\n    secInDay = 60 * 60 * 24\n    x = x - time.time()\n    if x <= 0:\n        return 'EXPIRED'\n    d = int(x / (60 * 60 * 24))\n    x -= 60 * 60 * 24 * d\n    h = int(x / (60 * 60))\n    x -= 60 * 60 * h\n    m = int(x / 60)\n    x -= 60 * m\n    s = x\n"]]}
{"hexsha": "dc1ca5c1a1684ab9b0b714b1f9c92bcaae0dc7ba", "ext": "py", "lang": "Python", "content": "def gen_output_by_receiver(receivers: dict):\n    if len(receivers.keys()) == 0:\n        return None\n    else:\n        outputs = []\n        for _add in receivers.keys():\n            _value = int(receivers[_add])\n            _output = t.TxOutput(address=_add, value=_value)\n            outputs.append(_output)\n        return outputs", "fn_id": 13, "class_fn": false, "repo": "bocheng0000/DposDistributer", "file": "utility/util.py", "last_update_at": "2019-10-15T03:07:04+00:00", "question_id": "dc1ca5c1a1684ab9b0b714b1f9c92bcaae0dc7ba_13", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def gen_output_by_receiver(receivers: dict):\n    if len(receivers.keys()) == 0:\n        return None\n    else:\n        outputs = []\n        for _add in receivers.keys():\n            _value = int(receivers[_add])\n            _output = t.TxOutput(address=_add, value=_value)\n            outputs.append(_output)\n"]]}
{"hexsha": "f425368a6dd7f12816034c1199455fe915409f79", "ext": "py", "lang": "Python", "content": "def remove_old_revisions_for_page(request, page_id):\n    page = get_object_or_404(Page, id=page_id)\n\n    perms = page.permissions_for_user(request.user)\n    if not request.user.is_superuser and not perms.can_edit():\n        return HttpResponseForbidden()\n\n    next = request.META.get(\"HTTP_REFERER\", None)\n\n    # get revisions for page\n    revisions = (\n        PageRevision.objects.filter(page_id=page.id)\n        .filter(submitted_for_moderation=False)\n        .filter(approved_go_live_at__isnull=True)\n        .exclude(id=page.live_revision_id)\n        .filter(created_at__lt=page.live_revision.created_at)\n    )\n\n    if request.POST:\n        revisions.delete()\n\n        messages.success(\n            request, ugettext('Old revisions of \"{}\" have been deleted.'.format(page))\n        )\n\n        next = request.POST.get(\"next\", next)\n\n        if next:\n            return redirect(next)\n\n        return redirect(reverse(\"wagtailadmin_pages:revisions_index\", args=[page_id]))\n\n    else:\n        return render(\n            request,\n            \"xr_wagtail/revisions/remove_for_page_confirm.html\",\n            context={\n                \"page\": page,\n                \"revisions\": revisions,\n                \"next\": reverse(\"wagtailadmin_pages:revisions_index\", args=[page_id]),\n            },\n        )", "fn_id": 0, "class_fn": false, "repo": "xr-web-de/xr-web", "file": "src/xr_wagtail/views.py", "last_update_at": "2019-08-11T19:31:35+00:00", "question_id": "f425368a6dd7f12816034c1199455fe915409f79_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def remove_old_revisions_for_page(request, page_id):\n    page = get_object_or_404(Page, id=page_id)\n    perms = page.permissions_for_user(request.user)\n    if not request.user.is_superuser and (not perms.can_edit()):\n        return HttpResponseForbidden()\n    next = request.META.get('HTTP_REFERER', None)\n    revisions = PageRevision.objects.filter(page_id=page.id).filter(submitted_for_moderation=False).filter(approved_go_live_at__isnull=True).exclude(id=page.live_revision_id).filter(created_at__lt=page.live_revision.created_at)\n    if request.POST:\n        revisions.delete()\n        messages.success(request, ugettext('Old revisions of \"{}\" have been deleted.'.format(page)))\n        next = request.POST.get('next', next)\n        if next:\n            return redirect(next)\n        return redirect(reverse('wagtailadmin_pages:revisions_index', args=[page_id]))\n    else:\n"]]}
{"hexsha": "829873fc6f1a1f642a59c1fafb6774755f276baf", "ext": "py", "lang": "Python", "content": "@pytest.mark.parametrize('varname, axis_name, to, roll, roll_axis, swap_order',\n    [('data_c', 'X', 'left', 1, 1, False),\n    ('data_c', 'Y', 'left', 1, 0, False),\n    ('data_g', 'X', 'center', -1, 1, True),\n    ('data_g', 'Y', 'center', -1, 0, True)]\n)\ndef test_axis_neighbor_pairs_2d(periodic_2d, varname, axis_name, to, roll,\n                                roll_axis, swap_order):\n    ds, periodic, expected = periodic_2d\n\n    axis = Axis(ds, axis_name)\n\n    data = ds[varname]\n    data_left, data_right = axis._get_neighbor_data_pairs(data, to)\n    if swap_order:\n        data_left, data_right = data_right, data_left\n    np.testing.assert_allclose(data_left, np.roll(data.data,\n                                                  roll, axis=roll_axis))\n    np.testing.assert_allclose(data_right, data.data)", "fn_id": 12, "class_fn": false, "repo": "raphaeldussin/xgcm", "file": "xgcm/test/test_grid.py", "last_update_at": "2019-06-13T13:36:42+00:00", "question_id": "829873fc6f1a1f642a59c1fafb6774755f276baf_12", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.mark.parametrize('varname, axis_name, to, roll, roll_axis, swap_order', [('data_c', 'X', 'left', 1, 1, False), ('data_c', 'Y', 'left', 1, 0, False), ('data_g', 'X', 'center', -1, 1, True), ('data_g', 'Y', 'center', -1, 0, True)])\ndef test_axis_neighbor_pairs_2d(periodic_2d, varname, axis_name, to, roll, roll_axis, swap_order):\n    ds, periodic, expected = periodic_2d\n    axis = Axis(ds, axis_name)\n    data = ds[varname]\n    data_left, data_right = axis._get_neighbor_data_pairs(data, to)\n    if swap_order:\n        data_left, data_right = (data_right, data_left)\n    np.testing.assert_allclose(data_left, np.roll(data.data, roll, axis=roll_axis))\n"]]}
{"hexsha": "83ea449458a6b6b0d591e3c4956d210a610d8344", "ext": "py", "lang": "Python", "content": "def test_types():\n    \"\"\"Ensure source code static typing.\"\"\"\n    result = PoeThePoet(Path(\".\"))([\"types\"])\n    assert result == 0", "fn_id": 1, "class_fn": false, "repo": "eyllanesc/copier", "file": "tests/test_tools.py", "last_update_at": "2019-09-13T20:41:07+00:00", "question_id": "83ea449458a6b6b0d591e3c4956d210a610d8344_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_types():\n    \"\"\"Ensure source code static typing.\"\"\"\n    result = PoeThePoet(Path('.'))(['types'])\n"]]}
{"hexsha": "ce393ab101de5c7a2c49b55dc56aa4e3b86fa56c", "ext": "py", "lang": "Python", "content": "def evaluate(model, path, iou_thres, conf_thres, nms_thres, img_size, batch_size):\n    model.eval()\n\n    # Get dataloader\n    dataset = ListDataset(path, img_size=img_size, augment=False, multiscale=False)\n    dataloader = torch.utils.data.DataLoader(\n        dataset, batch_size=batch_size, shuffle=False, num_workers=1, collate_fn=dataset.collate_fn\n    )\n\n    Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n\n    labels = []\n    sample_metrics = []  # List of tuples (TP, confs, pred)\n    itime=[]\n    results=[]\n    count = len(results)\n    for batch_i, (imname, imgs, targets) in enumerate(tqdm.tqdm(dataloader, desc=\"Detecting objects\")):\n        \n        # Extract labels\n        labels += targets[:, 1].tolist()\n        # Rescale target\n        targets[:, 2:] = xywh2xyxy(targets[:, 2:])\n        targets[:, 2:] *= img_size\n\n        imgs = Variable(imgs.type(Tensor), requires_grad=False)\n        prev_time = time.time()\n        with torch.no_grad():\n            outputs = model(imgs)\n            outputs = non_max_suppression(outputs, conf_thres=conf_thres, nms_thres=nms_thres)\n        current_time = time.time()\n        inference_time = current_time - prev_time\n        itime.append(inference_time) \n        sample_metrics += get_batch_statistics(outputs, targets, iou_threshold=iou_thres)\n        anns,count = get_results(outputs,imname,count)\n        if anns is not None:\n            results.append(anns)\n    print ('Mean inference time',np.mean(itime))\n    # Concatenate sample statistics\n    true_positives, pred_scores, pred_labels = [np.concatenate(x, 0) for x in list(zip(*sample_metrics))]\n    precision, recall, AP, f1, ap_class = ap_per_class(true_positives, pred_scores, pred_labels, labels)\n    json.dump(results, open('output/results.json','w'))\n    return precision, recall, AP, f1, ap_class", "fn_id": 1, "class_fn": false, "repo": "saketkunwar/cvcw2019_det", "file": "PyTorch-YOLOv3/test.py", "last_update_at": "2019-08-15T10:49:15+00:00", "question_id": "ce393ab101de5c7a2c49b55dc56aa4e3b86fa56c_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def evaluate(model, path, iou_thres, conf_thres, nms_thres, img_size, batch_size):\n    model.eval()\n    dataset = ListDataset(path, img_size=img_size, augment=False, multiscale=False)\n    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=1, collate_fn=dataset.collate_fn)\n    Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n    labels = []\n    sample_metrics = []\n    itime = []\n    results = []\n    count = len(results)\n    for batch_i, (imname, imgs, targets) in enumerate(tqdm.tqdm(dataloader, desc='Detecting objects')):\n        labels += targets[:, 1].tolist()\n        targets[:, 2:] = xywh2xyxy(targets[:, 2:])\n        targets[:, 2:] *= img_size\n        imgs = Variable(imgs.type(Tensor), requires_grad=False)\n        prev_time = time.time()\n        with torch.no_grad():\n            outputs = model(imgs)\n            outputs = non_max_suppression(outputs, conf_thres=conf_thres, nms_thres=nms_thres)\n        current_time = time.time()\n        inference_time = current_time - prev_time\n        itime.append(inference_time)\n        sample_metrics += get_batch_statistics(outputs, targets, iou_threshold=iou_thres)\n        anns, count = get_results(outputs, imname, count)\n        if anns is not None:\n            results.append(anns)\n    print('Mean inference time', np.mean(itime))\n    true_positives, pred_scores, pred_labels = [np.concatenate(x, 0) for x in list(zip(*sample_metrics))]\n    precision, recall, AP, f1, ap_class = ap_per_class(true_positives, pred_scores, pred_labels, labels)\n    json.dump(results, open('output/results.json', 'w'))\n"]]}
{"hexsha": "a258a8955ed91c65e8a9d1eb87848c8b38bd9c1c", "ext": "py", "lang": "Python", "content": "def run_trials(p, args):\n    \"\"\"\n    Run trials.\n\n    \"\"\"\n    # Model\n    m = p['model']\n\n    # ntrials: Number of trials for each condition\n    try:\n        ntrials = int(args[0])\n    except:\n        ntrials = 100\n\n    ntrials *= m.nconditions\n\n    # RNN\n    rng = np.random.RandomState(p['seed'])\n    rnn = RNN(p['savefile'], {'dt': p['dt']}, verbose=False)\n\n    # Trials\n    w = len(str(ntrials))\n    trials = []\n    backspaces = 0\n    try:\n        for i in xrange(ntrials):\n            b = i % m.nconditions\n            # All conditions\n            intensity = m.intensity_range[b]\n\n            # Trial\n            trial_func = m.generate_trial\n            trial_args = {\n                'name': 'test',\n                'catch': False,\n                'intensity': intensity,\n            }\n            info = rnn.run(inputs=(trial_func, trial_args), rng=rng)\n\n            # Display trial type\n            s = (\"Trial {:>{}}/{}: intentsity: {:>+3}\"\n                 .format(i + 1 , w, ntrials, info['intensity']))\n            sys.stdout.write(backspaces * '\\b' + s)\n            sys.stdout.flush()\n            backspaces = len(s)\n\n            # Save\n            dt = rnn.t[1] - rnn.t[0]\n            step = int(p['dt_save'] / dt)\n            trial = {\n                't': rnn.t[::step],\n                'u': rnn.u[:, ::step],\n                'r': rnn.r[:, ::step],\n                'z': rnn.z[:, ::step],\n                'info': info\n            }\n            trials.append(trial)\n    except KeyboardInterrupt:\n        pass\n    print(\"\")\n\n    # Save all\n    filename = get_trialsfile(p)\n    with open(filename, 'wb') as f:\n        pickle.dump(trials, f, pickle.HIGHEST_PROTOCOL)\n    size = os.path.getsize(filename) * 1e-9\n    print(\"[ {}.run_trials ] Trials saved to {} ({:.1f} GB)\".format(THIS, filename, size))", "fn_id": 2, "class_fn": false, "repo": "Rxie9596/pycog", "file": "custom/analysis/ana_reversal.py", "last_update_at": "2019-05-04T23:57:36+00:00", "question_id": "a258a8955ed91c65e8a9d1eb87848c8b38bd9c1c_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def run_trials(p, args):\n    \"\"\"\n    Run trials.\n\n    \"\"\"\n    m = p['model']\n    try:\n        ntrials = int(args[0])\n    except:\n        ntrials = 100\n    ntrials *= m.nconditions\n    rng = np.random.RandomState(p['seed'])\n    rnn = RNN(p['savefile'], {'dt': p['dt']}, verbose=False)\n    w = len(str(ntrials))\n    trials = []\n    backspaces = 0\n    try:\n        for i in xrange(ntrials):\n            b = i % m.nconditions\n            intensity = m.intensity_range[b]\n            trial_func = m.generate_trial\n            trial_args = {'name': 'test', 'catch': False, 'intensity': intensity}\n            info = rnn.run(inputs=(trial_func, trial_args), rng=rng)\n            s = 'Trial {:>{}}/{}: intentsity: {:>+3}'.format(i + 1, w, ntrials, info['intensity'])\n            sys.stdout.write(backspaces * '\\x08' + s)\n            sys.stdout.flush()\n            backspaces = len(s)\n            dt = rnn.t[1] - rnn.t[0]\n            step = int(p['dt_save'] / dt)\n            trial = {'t': rnn.t[::step], 'u': rnn.u[:, ::step], 'r': rnn.r[:, ::step], 'z': rnn.z[:, ::step], 'info': info}\n            trials.append(trial)\n    except KeyboardInterrupt:\n        pass\n    print('')\n    filename = get_trialsfile(p)\n    with open(filename, 'wb') as f:\n        pickle.dump(trials, f, pickle.HIGHEST_PROTOCOL)\n    size = os.path.getsize(filename) * 1e-09\n"]]}
{"hexsha": "756ad5c7ac0752f3a54427ce2fc2b1a0ec562221", "ext": "py", "lang": "Python", "content": "def stock(request):\n    \n    if request.method != 'GET':\n        return JsonResponse(status=405, data={\n            'error': 'Please use get request'\n        })\n\n    stockName = request.GET.get('NAME', '')\n    # without a name, hard to know what to request\n    if stockName == '':\n        return JsonResponse(status=400, data={\n            'error': 'Please include stock symbol'\n        })\n\n    # the \"2018-01-01\" is the default value if STARTDATE isn't set\n    startDate = request.GET.get('STARTDATE', \"2018-01-01\"\n                                )\n    try:\n        datetime.datetime.strptime(startDate, '%Y-%m-%d')\n    except ValueError:\n        return JsonResponse(status=400, data={\n            'error': 'Please include a valid date in the format YYYY-MM-DD'\n        })\n    endDate = request.GET.get('ENDDATE', \"2018-01-02\"\n                              )\n    try:\n        datetime.datetime.strptime(endDate, '%Y-%m-%d')\n    except ValueError:\n        return JsonResponse(status=400, data={\n            'error': 'Please include a valid date in the format YYYY-MM-DD'\n        })\n\n    # gets FIELDS, converts to uppercase, then splits into an array\n    fields = request.GET.get('FIELDS', \"Close\").upper().split(',')\n\n    # DL data from the Quandl API\n    quandl.ApiConfig.api_key = config('QUANDL_API_KEY')\n    try:\n        df = quandl.get(f\"WIKI/{stockName}\", start_date=startDate,\n                        end_date=endDate)\n    except:\n        # This might need to get changed to a more generic answer\n        print(\"Query error: please change your inputs (possibly invaild NAME, STARTDATE, ENDDATE) or check your API \"\n              \"key.\")\n        return JsonResponse(status=500, data={\n            'error': 'query error'\n        })\n    # frustratingly enough is quandl doesn't have data due to something be impossible it won't error, it'll just\n    # return an empty dataframe. For example requesting google stock from 1999, before they went public. This won't\n    # pop if the dates are set wrong, but sometimes will if they're set to the same day.\n    if df.empty:\n        return JsonResponse(status=404, data={\n            'error': 'Data was not found for this stock, please verify that the dates and stock symbol are valid and '\n                     'try again '\n        })\n\n    returnObj = {'symbol': stockName, 'startDate': startDate,\n                 'endDate': endDate, 'data': []}\n\n    # check if study exists in the database, if it does, then it returns the study\n    check_study = Study.objects.all().filter(stock_name=stockName, start_date=startDate, end_date=endDate)\n    if check_study:\n        print('already here')\n        temp = {}\n        for check_data in check_study.values(\"data\"):\n            # json.loads allow for our data to be \"unstringified\" so we can return it as readable data\n            temp = json.loads(check_data['data'])\n        returnObj['data'] = temp\n        return JsonResponse(status=200, data=returnObj)\n\n    # this moves the date from being a row key, to another column, then converts the whole dataframe to strings. Even\n    # all the numbers. This is to avoid problems with handling the date\n    df_r = df.reset_index().astype(str)\n\n    # this preps the return value by iterating over all the df rows then shoving them inside the data array in\n    # returnObj. I was unsure if I should use an object instead of an array but using a date as a key seemed much\n    # messier then letting an array preserve order\n    for index, row in df_r.iterrows():\n        rowObj = {'date': row['Date']}\n\n        # if 'OPEN' in fields:\n        rowObj['open'] = row['Open']\n        # if 'CLOSE' in fields:\n        rowObj['close'] = row['Close']\n        # if 'LOW' in fields:\n        rowObj['low'] = row['Low']\n        # if 'HIGH' in fields:\n        rowObj['high'] = row['High']\n        if 'EXDIVIDEND' in fields:\n            rowObj['exdividend'] = row['Ex-Dividend']\n        # if 'VOLUME' in fields:\n        rowObj['volume'] = row['Volume']\n        if 'SPLITRATIO' in fields:\n            rowObj['splitRatio'] = row['Split Ratio']\n        if 'ADJHIGH' in fields:\n            rowObj['adjHigh'] = row['Adj. High']\n        if 'ADJOPEN' in fields:\n            rowObj['adjOpen'] = row['Adj. Open']\n        if 'ADJCLOSE' in fields:\n            rowObj['adjClose'] = row['Adj. Close']\n        if 'ADJLOW' in fields:\n            rowObj['adjLow'] = row['Adj. Low']\n        if 'ADJVOLUME' in fields:\n            rowObj['adjVolume'] = row['Adj. Volume']\n\n        returnObj[\"data\"].append(rowObj)\n\n    string_json = json.dumps(returnObj[\"data\"])\n    stock = Stock.objects.all().filter(symbol=returnObj['symbol']).first()\n    if not stock:\n        stock = Stock(symbol=returnObj['symbol'])\n        stock.save()\n    # Data is being saved as a stringified json\n    new_study = Study(start_date=returnObj[\"startDate\"], end_date=returnObj[\"endDate\"], data=string_json)\n    new_study.save()\n    stock.study_set.add(new_study)\n\n    # TODO: Need to save study into user's portfolio when this route becomes protected.\n\n    return JsonResponse(status=200, data=returnObj)", "fn_id": 0, "class_fn": false, "repo": "BloomTech-Labs/labs9-stock-trainer", "file": "stockTrainerApp/views.py", "last_update_at": "2019-01-19T00:10:05+00:00", "question_id": "756ad5c7ac0752f3a54427ce2fc2b1a0ec562221_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def stock(request):\n    if request.method != 'GET':\n        return JsonResponse(status=405, data={'error': 'Please use get request'})\n    stockName = request.GET.get('NAME', '')\n    if stockName == '':\n        return JsonResponse(status=400, data={'error': 'Please include stock symbol'})\n    startDate = request.GET.get('STARTDATE', '2018-01-01')\n    try:\n        datetime.datetime.strptime(startDate, '%Y-%m-%d')\n    except ValueError:\n        return JsonResponse(status=400, data={'error': 'Please include a valid date in the format YYYY-MM-DD'})\n    endDate = request.GET.get('ENDDATE', '2018-01-02')\n    try:\n        datetime.datetime.strptime(endDate, '%Y-%m-%d')\n    except ValueError:\n        return JsonResponse(status=400, data={'error': 'Please include a valid date in the format YYYY-MM-DD'})\n    fields = request.GET.get('FIELDS', 'Close').upper().split(',')\n    quandl.ApiConfig.api_key = config('QUANDL_API_KEY')\n    try:\n        df = quandl.get(f'WIKI/{stockName}', start_date=startDate, end_date=endDate)\n    except:\n        print('Query error: please change your inputs (possibly invaild NAME, STARTDATE, ENDDATE) or check your API key.')\n        return JsonResponse(status=500, data={'error': 'query error'})\n    if df.empty:\n        return JsonResponse(status=404, data={'error': 'Data was not found for this stock, please verify that the dates and stock symbol are valid and try again '})\n    returnObj = {'symbol': stockName, 'startDate': startDate, 'endDate': endDate, 'data': []}\n    check_study = Study.objects.all().filter(stock_name=stockName, start_date=startDate, end_date=endDate)\n    if check_study:\n        print('already here')\n        temp = {}\n        for check_data in check_study.values('data'):\n            temp = json.loads(check_data['data'])\n        returnObj['data'] = temp\n        return JsonResponse(status=200, data=returnObj)\n    df_r = df.reset_index().astype(str)\n    for index, row in df_r.iterrows():\n        rowObj = {'date': row['Date']}\n        rowObj['open'] = row['Open']\n        rowObj['close'] = row['Close']\n        rowObj['low'] = row['Low']\n        rowObj['high'] = row['High']\n        if 'EXDIVIDEND' in fields:\n            rowObj['exdividend'] = row['Ex-Dividend']\n        rowObj['volume'] = row['Volume']\n        if 'SPLITRATIO' in fields:\n            rowObj['splitRatio'] = row['Split Ratio']\n        if 'ADJHIGH' in fields:\n            rowObj['adjHigh'] = row['Adj. High']\n        if 'ADJOPEN' in fields:\n            rowObj['adjOpen'] = row['Adj. Open']\n        if 'ADJCLOSE' in fields:\n            rowObj['adjClose'] = row['Adj. Close']\n        if 'ADJLOW' in fields:\n            rowObj['adjLow'] = row['Adj. Low']\n        if 'ADJVOLUME' in fields:\n            rowObj['adjVolume'] = row['Adj. Volume']\n        returnObj['data'].append(rowObj)\n    string_json = json.dumps(returnObj['data'])\n    stock = Stock.objects.all().filter(symbol=returnObj['symbol']).first()\n    if not stock:\n        stock = Stock(symbol=returnObj['symbol'])\n        stock.save()\n    new_study = Study(start_date=returnObj['startDate'], end_date=returnObj['endDate'], data=string_json)\n    new_study.save()\n    stock.study_set.add(new_study)\n"]]}
{"hexsha": "b941f20836b283bad2664e6fbca953fbea25b1b5", "ext": "py", "lang": "Python", "content": "def _get_type(s):\n    \"\"\"Reads a string to see if it can be converted into int or float.\n\n    Parameters\n    ----------\n    s : str\n        A string to be parsed.\n\n    Returns\n    -------\n    str, int or float\n        The parsed value.\n    \"\"\"\n    try:\n        float(s)\n        if '.' not in s:\n            return 'i'\n        else:\n            return 'f'\n    except ValueError:\n        return 's'", "fn_id": 19, "class_fn": false, "repo": "ryjmacdonell/geomtools", "file": "gimbal/fileio.py", "last_update_at": "2019-01-28T20:50:03+00:00", "question_id": "b941f20836b283bad2664e6fbca953fbea25b1b5_19", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _get_type(s):\n    \"\"\"Reads a string to see if it can be converted into int or float.\n\n    Parameters\n    ----------\n    s : str\n        A string to be parsed.\n\n    Returns\n    -------\n    str, int or float\n        The parsed value.\n    \"\"\"\n    try:\n        float(s)\n        if '.' not in s:\n            return 'i'\n        else:\n            return 'f'\n    except ValueError:\n"]]}
{"hexsha": "d5fd514c368625c8aa388aea35074a0228fce326", "ext": "py", "lang": "Python", "content": "def test_build_classifier_input_output_shapes():\n    classifier = build_classifier()\n    assert classifier.input.get_shape().as_list() == [None, None, None, 3]\n    assert classifier.output.get_shape().as_list() == [None, 2]", "fn_id": 7, "class_fn": false, "repo": "jg10545/decepticon", "file": "decepticon/tests/test_models.py", "last_update_at": "2019-12-15T07:57:11+00:00", "question_id": "d5fd514c368625c8aa388aea35074a0228fce326_7", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_build_classifier_input_output_shapes():\n    classifier = build_classifier()\n    assert classifier.input.get_shape().as_list() == [None, None, None, 3]\n"]]}
{"hexsha": "a81fb282ab8af0bfe6f5003c909b9087309fa022", "ext": "py", "lang": "Python", "content": "def run_uvcontsub(args):\n    args.outvis = args.uvdata[0]+'.contsub'\n    if args.noredo and os.path.isdir(args.outvis):\n        casalog.post('Skipping uvcontsub')\n    else:\n        uvcontsub(vis=args.uvdata[0], fitspw=args.fitspw, want_cont=False, \n                combine='spw', excludechans=True, fitorder=1)", "fn_id": 0, "class_fn": false, "repo": "folguinch/GoContinuum", "file": "run_uvcontsub.py", "last_update_at": "2019-04-27T14:16:59+00:00", "question_id": "a81fb282ab8af0bfe6f5003c909b9087309fa022_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def run_uvcontsub(args):\n    args.outvis = args.uvdata[0] + '.contsub'\n    if args.noredo and os.path.isdir(args.outvis):\n        casalog.post('Skipping uvcontsub')\n    else:\n"]]}
{"hexsha": "8b7cd38085bcad945d55ace6374f2cfb4247b0bd", "ext": "py", "lang": "Python", "content": "def test_no_class_type_in_event():\n    event = TransferEvent(web3_transfer_event, 10, 1000)\n\n    dumped = schemas.AnyEventSchema().dump(event)\n\n    assert dumped.get(schemas.AnyEventSchema.type_field) is None\n    assert dumped[\"amount\"] == str(event.value)\n    assert dumped[\"from\"] == event.from_\n    assert dumped[\"extraData\"] == event.extra_data.hex()", "fn_id": 5, "class_fn": false, "repo": "trustlines-network/relay-server", "file": "tests/unit/api/test_schemas.py", "last_update_at": "2019-03-06T05:38:45+00:00", "question_id": "8b7cd38085bcad945d55ace6374f2cfb4247b0bd_5", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def test_no_class_type_in_event():\n    event = TransferEvent(web3_transfer_event, 10, 1000)\n    dumped = schemas.AnyEventSchema().dump(event)\n    assert dumped.get(schemas.AnyEventSchema.type_field) is None\n    assert dumped['amount'] == str(event.value)\n    assert dumped['from'] == event.from_\n"]]}
{"hexsha": "a3400fed982201c13a6ae40f5aae4e5b1dc56603", "ext": "py", "lang": "Python", "content": "def not_none(arg_name):\n    def wrapper(func):\n        def inner(self, *args, **kwargs):\n            arg = getattr(self, arg_name)\n            if arg is None:\n                raise TypeError(\n                    arg_name + \" is not initialized! Use init_\" + arg_name + \"() or load_\"+ arg_name + \"() to initialize \"\n                    + arg_name + \" first.\")\n            return  func(self, *args, **kwargs)\n        return inner\n\n    return wrapper", "fn_id": 0, "class_fn": false, "repo": "ivanmilevtues/merinjei_bot", "file": "merinjeiweb/merinjei_classification/preprocess/decorators.py", "last_update_at": "2019-11-04T05:34:31+00:00", "question_id": "a3400fed982201c13a6ae40f5aae4e5b1dc56603_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def not_none(arg_name):\n\n    def wrapper(func):\n\n        def inner(self, *args, **kwargs):\n            arg = getattr(self, arg_name)\n            if arg is None:\n                raise TypeError(arg_name + ' is not initialized! Use init_' + arg_name + '() or load_' + arg_name + '() to initialize ' + arg_name + ' first.')\n            return func(self, *args, **kwargs)\n        return inner\n"]]}
{"hexsha": "abbf7c07f692163b76a1278b954739edd1aeedd2", "ext": "py", "lang": "Python", "content": "def get_curve_set(curves):\n    if isinstance(curves, str):\n        curves = curve_sets[curves]\n    return [get_curve(curve) for curve in curves]", "fn_id": 1, "class_fn": false, "repo": "iwiwi/darkopt", "file": "darkopt/learning_curve/skeletons.py", "last_update_at": "2019-09-11T10:02:24+00:00", "question_id": "abbf7c07f692163b76a1278b954739edd1aeedd2_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def get_curve_set(curves):\n    if isinstance(curves, str):\n        curves = curve_sets[curves]\n"]]}
{"hexsha": "535ed34734f101303343363d324bc1103c6c1f13", "ext": "py", "lang": "Python", "content": "@app.route('/make_video/<task_id>', methods=['POST'])\ndef make_video(task_id):\n  try:\n    os.mkdir(video_buffer)\n  except Exception as e:\n    print(e)\n  raw_files = sorted(os.listdir(frame_buffer))\n  files = map(lambda f: os.path.join(frame_buffer, f), raw_files)\n  taichi.tools.video.make_video(list(files), output_path=os.path.join(video_buffer, task_id + '.mp4'))\n  return ''", "fn_id": 3, "class_fn": false, "repo": "gonnavis/taichi", "file": "python/taichi/pakua/server.py", "last_update_at": "2019-06-25T02:12:48+00:00", "question_id": "535ed34734f101303343363d324bc1103c6c1f13_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@app.route('/make_video/<task_id>', methods=['POST'])\ndef make_video(task_id):\n    try:\n        os.mkdir(video_buffer)\n    except Exception as e:\n        print(e)\n    raw_files = sorted(os.listdir(frame_buffer))\n    files = map(lambda f: os.path.join(frame_buffer, f), raw_files)\n    taichi.tools.video.make_video(list(files), output_path=os.path.join(video_buffer, task_id + '.mp4'))\n"]]}
{"hexsha": "9f966f81f3e43e23777a3d2f9117cf5f67d333f7", "ext": "py", "lang": "Python", "content": "def _go_ids_accept_single_recursive(a, b, b_parents):\n    \"\"\"\n    2 outcomes:\n\n    * a is parent (direct or indirect) of b --> True\n    * else --> False\n    \"\"\"\n\n    if a == b:\n        return True\n\n    return any(_go_ids_accept_single_recursive(a, pp, GO_TREE.get(pp).parents) for pp in b_parents if pp in GO_TREE)", "fn_id": 9, "class_fn": false, "repo": "Rostlab/LocText", "file": "loctext/learning/evaluations.py", "last_update_at": "2019-02-19T02:54:32+00:00", "question_id": "9f966f81f3e43e23777a3d2f9117cf5f67d333f7_9", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def _go_ids_accept_single_recursive(a, b, b_parents):\n    \"\"\"\n    2 outcomes:\n\n    * a is parent (direct or indirect) of b --> True\n    * else --> False\n    \"\"\"\n    if a == b:\n        return True\n"]]}
{"hexsha": "7f566f4323956f8462afe9d022ea2bd119514e64", "ext": "py", "lang": "Python", "content": "def number_parser(num_str, num_type=float):\n    '''converts number strings using metric prefixes into numbers'''\n    postfixes = \" kMGTPE\"\n    power = 0\n    if num_str[-1] in postfixes:\n        power = postfixes.index(num_str[-1])\n        num_str = num_str[:-1]\n    return num_type(float(num_str.replace(',','')) * 1000**power)", "fn_id": 8, "class_fn": false, "repo": "fbi-octopus/biggles", "file": "python/biggles/_utilities.py", "last_update_at": "2019-11-15T14:01:59+00:00", "question_id": "7f566f4323956f8462afe9d022ea2bd119514e64_8", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def number_parser(num_str, num_type=float):\n    \"\"\"converts number strings using metric prefixes into numbers\"\"\"\n    postfixes = ' kMGTPE'\n    power = 0\n    if num_str[-1] in postfixes:\n        power = postfixes.index(num_str[-1])\n        num_str = num_str[:-1]\n"]]}
{"hexsha": "cb3525a7d07e02414bdc4f95e6b95eab2b68b284", "ext": "py", "lang": "Python", "content": "@airflow.command()\n@click.option('--name', prompt='What is the name of your dag?',\n              help=\"Name of the new dag to create\",\n              metavar='<DAG>')\n@click.option('-f', '--format', 'output_format',\n              help=\"format of the configuration file (default is hocon)\",\n              type=click.Choice(['json', 'hocon']),\n              default='hocon')\n@click.argument('path', type=click.Path())\n@click.version_option(version=__version__)\ndef new(name, output_format, path):\n    \"\"\"Create a new DAG job\"\"\"\n    # TODO to implement\n    logging.error(\"Not implemented yet %s %s %s\",\n                  name, output_format, path)", "fn_id": 6, "class_fn": false, "repo": "Aiscalate/aiscalator", "file": "src/aiscalator/airflow/cli.py", "last_update_at": "2019-10-30T09:50:26+00:00", "question_id": "cb3525a7d07e02414bdc4f95e6b95eab2b68b284_6", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@airflow.command()\n@click.option('--name', prompt='What is the name of your dag?', help='Name of the new dag to create', metavar='<DAG>')\n@click.option('-f', '--format', 'output_format', help='format of the configuration file (default is hocon)', type=click.Choice(['json', 'hocon']), default='hocon')\n@click.argument('path', type=click.Path())\n@click.version_option(version=__version__)\ndef new(name, output_format, path):\n    \"\"\"Create a new DAG job\"\"\"\n"]]}
{"hexsha": "3dcb8340aa86856ec9981efc2a42ec3178f7c664", "ext": "py", "lang": "Python", "content": "@bp.route('/search', methods=['GET'])\ndef search():\n    searchcontent = request.args.get(\"content\")\n    if searchcontent==\"\" or searchcontent is None:\n        return \"\"\n    try:\n      result=  zjb_search(browser, searchcontent)\n    except:\n        print(\"Error with searchcontent \" + searchcontent)\n        sys.exit(1)\n\n    content = json.dumps(result)\n    resp = httputil.Response_headers(content)\n    return resp", "fn_id": 3, "class_fn": false, "repo": "jiebinzhuang/insgraph-flask", "file": "insgraph/instagram.py", "last_update_at": "2019-04-23T03:14:29+00:00", "question_id": "3dcb8340aa86856ec9981efc2a42ec3178f7c664_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@bp.route('/search', methods=['GET'])\ndef search():\n    searchcontent = request.args.get('content')\n    if searchcontent == '' or searchcontent is None:\n        return ''\n    try:\n        result = zjb_search(browser, searchcontent)\n    except:\n        print('Error with searchcontent ' + searchcontent)\n        sys.exit(1)\n    content = json.dumps(result)\n    resp = httputil.Response_headers(content)\n"]]}
{"hexsha": "76341f6f83129e754888ee4c7c7b0c415cb48793", "ext": "py", "lang": "Python", "content": "def DWM_enable_blur_behind_window(widget, enable=True):\n    \"\"\"\n    Enable or disable blur behind window on a window.\n    \"\"\"\n    if not has_dwm:\n        return False\n\n    bb = DWM_BLURBEHIND()\n    bb.fEnable = c_bool(enable)\n    bb.dwFlags = DWM_BB_ENABLE\n    bb.hRgnBlur = None\n\n    widget.setAttribute(Qt.WA_TranslucentBackground, enable)\n    widget.setAttribute(Qt.WA_NoSystemBackground, enable)\n\n    result = _DwmEnableBlurBehindWindow(pythonapi.PyCObject_AsVoidPtr(\n                widget.winId()), bb)\n    \n    return not result", "fn_id": 3, "class_fn": false, "repo": "stendec/siding", "file": "siding/_aeroglass.py", "last_update_at": "2019-09-28T11:51:27+00:00", "question_id": "76341f6f83129e754888ee4c7c7b0c415cb48793_3", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def DWM_enable_blur_behind_window(widget, enable=True):\n    \"\"\"\n    Enable or disable blur behind window on a window.\n    \"\"\"\n    if not has_dwm:\n        return False\n    bb = DWM_BLURBEHIND()\n    bb.fEnable = c_bool(enable)\n    bb.dwFlags = DWM_BB_ENABLE\n    bb.hRgnBlur = None\n    widget.setAttribute(Qt.WA_TranslucentBackground, enable)\n    widget.setAttribute(Qt.WA_NoSystemBackground, enable)\n    result = _DwmEnableBlurBehindWindow(pythonapi.PyCObject_AsVoidPtr(widget.winId()), bb)\n"]]}
{"hexsha": "6a4d0f34aecce7494685901d6143e8f64efb9d1b", "ext": "py", "lang": "Python", "content": "@testing.requires_testing_data\ndef test_csr_csc(tmpdir):\n    \"\"\"Test CSR and CSC.\"\"\"\n    info = read_info(sss_ctc_fname)\n    info = pick_info(info, pick_types(info, meg=True, exclude=[]))\n    sss_ctc = info['proc_history'][0]['max_info']['sss_ctc']\n    ct = sss_ctc['decoupler'].copy()\n    # CSC\n    assert isinstance(ct, sparse.csc_matrix)\n    fname = tmpdir.join('test.fif')\n    write_info(fname, info)\n    info_read = read_info(fname)\n    ct_read = info_read['proc_history'][0]['max_info']['sss_ctc']['decoupler']\n    assert isinstance(ct_read, sparse.csc_matrix)\n    assert_array_equal(ct_read.toarray(), ct.toarray())\n    # Now CSR\n    csr = ct.tocsr()\n    assert isinstance(csr, sparse.csr_matrix)\n    assert_array_equal(csr.toarray(), ct.toarray())\n    info['proc_history'][0]['max_info']['sss_ctc']['decoupler'] = csr\n    fname = tmpdir.join('test1.fif')\n    write_info(fname, info)\n    info_read = read_info(fname)\n    ct_read = info_read['proc_history'][0]['max_info']['sss_ctc']['decoupler']\n    assert isinstance(ct_read, sparse.csc_matrix)  # this gets cast to CSC\n    assert_array_equal(ct_read.toarray(), ct.toarray())", "fn_id": 14, "class_fn": false, "repo": "massich/mne-python", "file": "mne/io/tests/test_meas_info.py", "last_update_at": "2019-10-04T11:11:29+00:00", "question_id": "6a4d0f34aecce7494685901d6143e8f64efb9d1b_14", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@testing.requires_testing_data\ndef test_csr_csc(tmpdir):\n    \"\"\"Test CSR and CSC.\"\"\"\n    info = read_info(sss_ctc_fname)\n    info = pick_info(info, pick_types(info, meg=True, exclude=[]))\n    sss_ctc = info['proc_history'][0]['max_info']['sss_ctc']\n    ct = sss_ctc['decoupler'].copy()\n    assert isinstance(ct, sparse.csc_matrix)\n    fname = tmpdir.join('test.fif')\n    write_info(fname, info)\n    info_read = read_info(fname)\n    ct_read = info_read['proc_history'][0]['max_info']['sss_ctc']['decoupler']\n    assert isinstance(ct_read, sparse.csc_matrix)\n    assert_array_equal(ct_read.toarray(), ct.toarray())\n    csr = ct.tocsr()\n    assert isinstance(csr, sparse.csr_matrix)\n    assert_array_equal(csr.toarray(), ct.toarray())\n    info['proc_history'][0]['max_info']['sss_ctc']['decoupler'] = csr\n    fname = tmpdir.join('test1.fif')\n    write_info(fname, info)\n    info_read = read_info(fname)\n    ct_read = info_read['proc_history'][0]['max_info']['sss_ctc']['decoupler']\n    assert isinstance(ct_read, sparse.csc_matrix)\n"]]}
{"hexsha": "ca1c6f902d469fc0533950126137c3edbfba755e", "ext": "py", "lang": "Python", "content": "def getusb():  \n    drives = []  \n    sign = win32file.GetLogicalDrives()\n    ALLDRIVES = [\"A:\\\\\",\"B:\\\\\",\"C:\\\\\",\"D:\\\\\",\"E:\\\\\",\"F:\\\\\",\"G:\\\\\",\"H:\\\\\",\n                 \"I:\\\\\",\"J:\\\\\",\"K:\\\\\",\"L:\\\\\",\"M:\\\\\",\"N:\\\\\",\"O:\\\\\",\"P:\\\\\",\n                 \"Q:\\\\\",\"R:\\\\\",\"S:\\\\\",\"T:\\\\\",\"U:\\\\\",\"V:\\\\\",\"W:\\\\\",\"X:\\\\\",\n                 \"Y:\\\\\",\"Z:\\\\\"]  \n    for i in range(25):  \n        if (sign&1<<i):  \n            if win32file.GetDriveType(ALLDRIVES[i]) == \\\n                win32file.DRIVE_REMOVABLE:  \n                drives.append(ALLDRIVES[i])  \n    return drives", "fn_id": 1, "class_fn": false, "repo": "Rabbytr/python_toolkit", "file": "pykit/diskop.py", "last_update_at": "2019-07-18T06:04:38+00:00", "question_id": "ca1c6f902d469fc0533950126137c3edbfba755e_1", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def getusb():\n    drives = []\n    sign = win32file.GetLogicalDrives()\n    ALLDRIVES = ['A:\\\\', 'B:\\\\', 'C:\\\\', 'D:\\\\', 'E:\\\\', 'F:\\\\', 'G:\\\\', 'H:\\\\', 'I:\\\\', 'J:\\\\', 'K:\\\\', 'L:\\\\', 'M:\\\\', 'N:\\\\', 'O:\\\\', 'P:\\\\', 'Q:\\\\', 'R:\\\\', 'S:\\\\', 'T:\\\\', 'U:\\\\', 'V:\\\\', 'W:\\\\', 'X:\\\\', 'Y:\\\\', 'Z:\\\\']\n    for i in range(25):\n        if sign & 1 << i:\n            if win32file.GetDriveType(ALLDRIVES[i]) == win32file.DRIVE_REMOVABLE:\n                drives.append(ALLDRIVES[i])\n"]]}
{"hexsha": "a7bcb84b6ba27514334838fadcbe124f27d5d9c4", "ext": "py", "lang": "Python", "content": "@pytest.mark.parametrize(\n    \"input_text, end_session\",\n    [\n        (\"Test\", False),\n        (\"Test\", True),\n        (\"\\n\\t\", False),\n        (1, False),\n        (True, False),\n        (0.5, False)\n    ]\n)\ndef test_build_text_response(input_text, end_session):\n    \"\"\"\n    response.text_response(text) should format the text for Alexa so that Alexa\n    will read the text to the user in response to their query\n    \"\"\"\n    res = response.plaintext_response(input_text, end_session=end_session)\n\n    res_json = json.loads(res)\n\n    assert res_json['body']['response']['outputSpeech']['type'] == 'PlainText'\n    assert res_json['body']['response']['outputSpeech']['text'] == str(input_text)\n    assert res_json['body']['response']['shouldEndSession'] == end_session", "fn_id": 0, "class_fn": false, "repo": "HackUCF/Alexa-Skill", "file": "test/test_alexa.py", "last_update_at": "2019-09-13T14:12:27+00:00", "question_id": "a7bcb84b6ba27514334838fadcbe124f27d5d9c4_0", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["@pytest.mark.parametrize('input_text, end_session', [('Test', False), ('Test', True), ('\\n\\t', False), (1, False), (True, False), (0.5, False)])\ndef test_build_text_response(input_text, end_session):\n    \"\"\"\n    response.text_response(text) should format the text for Alexa so that Alexa\n    will read the text to the user in response to their query\n    \"\"\"\n    res = response.plaintext_response(input_text, end_session=end_session)\n    res_json = json.loads(res)\n    assert res_json['body']['response']['outputSpeech']['type'] == 'PlainText'\n    assert res_json['body']['response']['outputSpeech']['text'] == str(input_text)\n"]]}
{"hexsha": "f4c3efeb6c030da5e3f6ad1c5681b47b79e8136e", "ext": "py", "lang": "Python", "content": "def check_filter(filt):\n    \"\"\"\\\n    Check that the low value of the filter is lower than the high.\n    If there is to be no filter, return 'None'.\n\n        >>> check_filter(())\n        >>> check_filter(False)\n        >>> check_filter(None)\n        >>> check_filter([(6, 7)])\n        [(6.0, 7.0)]\n        >>> check_filter([(6, 7), (2, 8)])\n        [(6.0, 7.0), (2.0, 8.0)]\n        >>> try:\n        ...    check_filter([(7, 2)])\n        ... except ValueError as e:\n        ...    print(e)\n        Error in --filter: low >= high\n\n    \"\"\"\n    # Quick return if no filter.\n    if not filt:\n        return None\n    try:\n        return [range_check(f[0], f[1]) for f in filt]\n    except ValueError as a:\n        raise ValueError('Error in --filter: '+py23_str(a))", "fn_id": 2, "class_fn": false, "repo": "iamsagar7/Final_Year", "file": "finalyear/lib/python3.7/site-packages/natsort/__main__.py", "last_update_at": "2019-06-14T10:15:33+00:00", "question_id": "f4c3efeb6c030da5e3f6ad1c5681b47b79e8136e_2", "category": "coding", "instruct": "Please complete the following code and only return the code.", "turns": [["def check_filter(filt):\n    \"\"\"    Check that the low value of the filter is lower than the high.\n    If there is to be no filter, return 'None'.\n\n        >>> check_filter(())\n        >>> check_filter(False)\n        >>> check_filter(None)\n        >>> check_filter([(6, 7)])\n        [(6.0, 7.0)]\n        >>> check_filter([(6, 7), (2, 8)])\n        [(6.0, 7.0), (2.0, 8.0)]\n        >>> try:\n        ...    check_filter([(7, 2)])\n        ... except ValueError as e:\n        ...    print(e)\n        Error in --filter: low >= high\n\n    \"\"\"\n    if not filt:\n        return None\n    try:\n        return [range_check(f[0], f[1]) for f in filt]\n    except ValueError as a:\n"]]}
